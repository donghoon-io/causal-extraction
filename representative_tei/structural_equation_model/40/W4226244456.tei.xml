<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Physics-informed Neural Networks (PINNs) for Wave Propagation and Full Waveform Inversions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Majid</forename><surname>Rasht-Behesht</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Earth Environmental and Planetary Sciences</orgName>
								<orgName type="institution">Brown University</orgName>
								<address>
									<postCode>02906</postCode>
									<settlement>Providence</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christian</forename><surname>Huber</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Earth Environmental and Planetary Sciences</orgName>
								<orgName type="institution">Brown University</orgName>
								<address>
									<postCode>02906</postCode>
									<settlement>Providence</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Khemraj</forename><surname>Shukla</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Division of Applied Mathematics</orgName>
								<orgName type="institution">Brown University</orgName>
								<address>
									<postCode>02906</postCode>
									<settlement>Providence</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">George</forename><forename type="middle">Em</forename><surname>Karniadakis</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Division of Applied Mathematics and School of Engineering</orgName>
								<orgName type="institution">Brown University</orgName>
								<address>
									<postCode>02906</postCode>
									<settlement>Providence</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Physics-informed Neural Networks (PINNs) for Wave Propagation and Full Waveform Inversions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T23:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a new approach to the solution of the wave propagation and full waveform inversions (FWIs) based on a recent advance in deep learning called Physics-Informed Neural Networks (PINNs). While PINNs have been successfully applied to several forward and inverse problems in science and engineering, their performance for solving the wave equation and FWIs, where labeled training data sets are often limited to observed data at the surface (boundary), has not been explored. In this study, we present an algorithm for PINNs applied to the 2D acoustic wave equation and test the model with both forward wave propagation and FWIs case studies. These synthetic case studies are designed to explore the ability of PINNs to handle varying degrees of structural complexity using both teleseismic plane waves and seismic point sources. PINNs' meshless formalism allows for a flexible implementation of the wave equation and different types of boundary conditions. For instance, our models demonstrate that PINN automatically satisfies absorbing boundary conditions, a serious computational challenge for common wave propagation solvers. Furthermore, a priori knowledge of the subsurface structure can be seamlessly encoded in PINNs' formulation. We find that the current state-of-the-art PINNs provide good results for the forward model, even though spectral element or finite difference methods are more efficient and accurate. More importantly, our results demonstrate that PINNs yield excellent results for inversions on all cases considered and with limited computational complexity. Using PINNs as a geophysical inversion solver offers exciting perspectives, not only for the full waveform seismic inversions, but also when dealing with other geophysical datasets (e.g., magnetotellurics, gravity) as well as joint inversions because of its robust framework and simple implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Glossary</head><p>Free-surface constraint: Stress-free condition imposed at the top of the model to simulate the surface of the Earth.</p><p>Boundary data: Any data for the wavefield located at the boundaries of the computational domain. This can be either in the form of observed data (seismograms), or in the form of imposed conditions such as a free-surface or absorbing conditions.</p><p>Early-time snapshots: Data from the snapshots of the wavefield recorded at t=0 and t=ï„t obtained here with a wave equation solver (SpecFem2D) that are used as inputs to the PINN to train for characteristics of the seismic source in space and time.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Seismic inversions are important tools for imaging heterogeneities in the earth's subsurface. However, the resolving power of seismic inversion techniques is strongly controlled by the type and extent of the data used from seismograms. Particularly, in scenarios where the dominant wavelength of the seismic wave is greater than the length-scale of the target heterogeneities, FWIs can provide significantly better results than, for instance, travel-time tomography <ref type="bibr" target="#b31">(Rasht-Behesht et al., 2020;</ref><ref type="bibr" target="#b9">Fichtner and Trampert, 2011;</ref><ref type="bibr" target="#b23">Marquering et al., 1999;</ref><ref type="bibr" target="#b6">Cassidy, 1992)</ref>. Regardless of their advantages, FWIs remain technically and computationally challenging. Adjoint methods <ref type="bibr">(Bozdag et al., 2016;</ref><ref type="bibr" target="#b40">Tromp et al., 2008;</ref><ref type="bibr" target="#b8">Fichtner et al., 2006;</ref><ref type="bibr" target="#b28">Plessix, 2006)</ref> offer an efficient strategy to reduce computational cost for FWIs from N forward simulations per optimization step (N= number of model parameters) to two forward simulations. However, the derivation and implementation of adjoint methods for FWIs remains challenging and must be treated on a case-by-case basis for different systems <ref type="bibr">(Bozdag et al., 2016;</ref><ref type="bibr" target="#b7">Cockett et al., 2015)</ref>.</p><p>With the successful application of machine learning, and in particular deep learning techniques, and the concurrent explosion of recorded seismic data made available over the past decade, seismologists have begun to search for modern efficient techniques <ref type="bibr" target="#b19">(Kong et al., 2019;</ref><ref type="bibr" target="#b2">Bergen et al., 2019)</ref> to tackle problems such as earthquake detection, automatic phase picking <ref type="bibr" target="#b27">(Mousavi et al., 2020;</ref><ref type="bibr" target="#b29">Ross et al., 2018;</ref><ref type="bibr" target="#b46">Yoon et al., 2015)</ref> and seismic signal denoising <ref type="bibr" target="#b47">(Zhu et al., 2019)</ref>. A common theme thus far in the majority of these applications has been the abundance of labeled/unlabeled training data sets. As a result, areas such as seismic imaging applications where one is limited to spatially sparse data sets (seismometers), have not benefited as much from these methodologies. However, under conditions where a computationally inexpensive forward model of the wave propagation exists, such as when considering a 1D layered earth structure, it is possible to generate large synthetic data sets to train a deep neural network (DNN) that can be then used as an efficient forward model surrogate <ref type="bibr">(Moseley et al., 2020;</ref><ref type="bibr" target="#b1">Araya-Polo et al., 2018)</ref>. The intent of this approach is to make the solution to the forward problem more cost effective than the numerical solution of the wave equation and thus accelerate the procedure for inverse problems in seismology. The drawback of this technique is that it heavily relies on preexisting fast forward solvers for training purposes, but once trained, the neural network (NN) can be used as an independent machinery. Another approach, to accelerate the calculations of the derivatives in gradient-based techniques such as adjoint-methods is the use of reverse-mode automatic differentiation efficiently implemented in current deep learning libraries such as TensorFlow <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref> and PyTorch <ref type="bibr">(Paszke et al., 2019)</ref> to solve the adjoint state FWIs <ref type="bibr" target="#b48">(Zhu et al., 2021)</ref>. <ref type="bibr" target="#b30">Raissi et al., 2019</ref> have introduced a new class of DNNs known as Physics-Informed Neural Networks (PINNs) that provide an improved framework to overcome the obstacles pertaining to the training of DNNs caused by challenges in training data acquisition. PINNs take advantage of the governing physical laws behind the processes that generate the data, hence reducing greatly the reliance of the DNN on the labeled data during the training process. PINNs simply bridge the gap between data-scarcity and the data-intensive nature of DNNs and have been successfully applied to various problems in engineering and biology with applications including but not limited to heat transfer <ref type="bibr">(Cai et al., 2021)</ref>, solution of Navier-Stokes equations in fluid mechanics <ref type="bibr" target="#b15">(Jin et al., 2021)</ref>, high speed fluid flow <ref type="bibr" target="#b22">(Mao et al., 2020)</ref> and solid mechanics <ref type="bibr" target="#b10">(Haghighat et al., 2021)</ref>. For a recent review of PINNs application see <ref type="bibr">Karniadakis et al., 2021</ref><ref type="bibr">. Haghighat et al., 2021</ref> explored PINNs' application to linear elasticity and nonlinear plasticity and showed that they can be efficiently applied to inversion and surrogate modeling in solid mechanics. <ref type="bibr" target="#b34">Shukla et al., 2020</ref><ref type="bibr">Shukla et al., &amp; 2021</ref> used PINNs for a nondestructive quantification of surface cracks and identification of microstructural properties of polycrystalline Nickle using ultrasound data. <ref type="bibr">Moseley et al., 2020, used</ref> PINNs as a solver for the forward acoustic wave propagation, while <ref type="bibr" target="#b36">Smith et al., 2020 and</ref><ref type="bibr">Waheed et al., 2021 applied</ref> PINNs to the Eikonal equation as a forward solver for first arrival-time prediction and travel time tomography, respectively. <ref type="bibr">Song et al., 2020</ref> solved the frequency-domain anisotropic acoustic wave equation with PINNs. Nevertheless, to our knowledge, we present the first FWI for seismological applications using PINNs. In this study, we focus on the development of acoustic FWI with PINNs and demonstrate its practical application to various synthetic case studies. The salient results of our study are: a) In most applications of PINNs, authors have incorporated training data sets from within the computational domain from other solvers or experimental data, which greatly facilitates the training process. In contrast, with seismic inversions, this is generally not possible (records of the wavefield are generally limited spatially to the surface or boreholes). We show that this limitation does not prevent PINNs from performing efficient and accurate seismic inversions. b) We discuss the implementation of various types of boundary data, including a stress-free constraint on the top surface of the physical domain and absorbing boundary layers necessary for the simulation of wave propagation in infinite media. We show that the implementation of these constraints can be seamlessly handled with PINNs. c) We present specific normalization guidelines that are crucial to PINNs' convergence as applied to the wave equation. d) We demonstrate how to handle multiple seismic sources to improve the illumination of complex structural heterogeneity at depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acoustic Wave Propagation</head><p>The propagation of acoustic waves in a 2D medium with negligible density variations and in the absence of body forces can be described in terms of the scalar wave potential ğœ™ as:</p><formula xml:id="formula_0">ğ›¼ 2 ğ›» 2 ğœ™ + ğ‘“ = ğœ• 2 ğœ™ ğœ•ğ‘¡ 2 , (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where</p><formula xml:id="formula_2">ğ›» 2 â‰¡ ğœ• 2 ğœ•ğ‘¥ 2 + ğœ• 2</formula><p>ğœ•ğ‘§ 2 is the Laplacian operator defined in the cartesian coordinate system, ğ‘“ is the external surface forces and ğ›¼ characterizes the acoustic wavespeed that strictly depends on the material properties of the medium through the relation ğ›¼ = âˆš ğ¾ ğœŒ with ğ¾ and ğœŒ being the material bulk modulus and density, respectively. Without loss of generality, we set ğ‘“ â‰¡ 0 and instead, enforce external forces through a perturbation of the initial field acting at some early time. The displacement field is retrieved from the gradient of the wave potential i.e., (ğ‘¢ ğ‘¥ , ğ‘¢ ğ‘§ ) = âˆ‡ğœ™.</p><p>The forward simulation of the wave propagation involves solving equation 1 given a set of boundary constraints and two early-time snapshots of the wave propagation as well as a precise knowledge of the material properties (wavespeed ğ›¼) of the medium in the computational domain. Note that the first timesnapshot constrains the shape of the seismic source whereas the second enforces its propagation direction. In the inverse problem, ğ›¼ is either unknown or there exists some a priori information and it is evaluated spatially from the recorded ground motion. In this study we will investigate how PINNs can be used to solve these two classes of problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural Network (NN)</head><p>PINNs' architecture has been almost exclusively based on fully connected feed-forward NN. In the absence of any justifiable reasons to do otherwise, we, therefore, define a fully connected feed-forward NN with an input layer consisting of the physical coordinates ğ‘¥, ğ‘§ and time ğ‘¡, ğ¿ hidden layers and an output layer representing the scalar acoustic wave potential ğœ™ âˆˆ â„ (Fig. <ref type="figure" target="#fig_0">1</ref>). The various other physical variables, such as displacement or pressure, are obtained through the automatic differentiation of the wave potential NN using TensorFlow <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref>. Note that the proper choice of the independent physical variable(s) that the output of the NN represents is problem-dependent. For instance, Haghighat et al., 2021 selected a separate NN for each component of the displacement field for problems in elasticity.</p><p>There are ğ‘ ğ‘™ number of neurons in the ğ‘™ ğ‘¡â„ hidden layer. A linear transformation followed by a nonlinear neuron-wise activation function (ğœ) is applied at the input ğ‘¥ ğ‘™-1 âˆˆ â„ ğ‘ ğ‘™-1 to the ğ‘™ ğ‘¡â„ layer:</p><formula xml:id="formula_3">ğ»(ğ‘¥ ğ‘™-1 ) = ğœ(ğ‘¤ ğ‘™ ğ‘¥ ğ‘™-1 + ğ‘ ğ‘™ ),</formula><p>where ğ‘¤ ğ‘™ âˆˆ â„ ğ‘ ğ‘™ Ã—ğ‘ ğ‘™-1 is the matrix of weights and ğ‘ ğ‘™ âˆˆ â„ ğ‘ ğ‘™ is the vector of biases corresponding to the ğ‘™ ğ‘¡â„ layer. The successive operation of this transformation law results in the final output of the NN with a total number of âˆ‘ (ğ‘ ğ‘™ Ã— ğ‘ ğ‘™-1 ) + ğ‘ ğ‘™ ğ‘™ 1 tunable parameters (ğ‘ 0 = 3). We choose ğœ = tanh (â€¢) or sin (â€¢) as the nonlinear activation function for all NNs used in this study. The activation function acting on the last hidden layer to yield the output is the identity function. The interested reader is directed to <ref type="bibr">Jagtap et al., 2020a&amp;b</ref> for a discussion of adaptive activation functions and their effect on convergence. The network's parameters are initialized from independent and identically distributed (iid) samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PINNs for the forward problem</head><p>We follow PINNs' original framework <ref type="bibr" target="#b30">(Raissi et al., 2019)</ref>, to obtain the parameters of a NN such that it closely approximates the acoustic wave potential ğœ™. To do so, we enforce this NN to satisfy the partial differential equation (1) with corresponding early-time snapshots of the wave propagation and boundary data computed on a set of randomly selected training data points (Fig. <ref type="figure" target="#fig_1">2</ref>). In the following, we define the various residual terms that we aim to minimize:</p><formula xml:id="formula_4">ğ‘… ğ‘ƒğ·ğ¸ â‰” ğ›¼ 2 ğ›» 2 ğœ™ - ğœ• 2 ğœ™ ğœ•ğ‘¡ 2 PDE ğ‘… ğ‘ƒ.ğ¶ â‰” ğœŒğ›¼ 2 ğ›» 2 ğœ™(ğ‘¥, ğ‘¡, ğ‘§ = 0)</formula><p>Free-Surface Constraint ğ‘… ğ‘ƒ.ğ¶ indicates the physical free-surface constraint at the top of the model where pressure is fixed to zero. Observed data refers to the recorded wavefield on a sparse set of receivers (seismograms). In this study, the observed data in the form of synthetic seismograms and the early-time snapshots are obtained from SpecFem2D simulations <ref type="bibr" target="#b17">(Komatitsch and Tromp, 1999;</ref><ref type="bibr" target="#b40">Tromp et al., 2008)</ref>, a spectral element model for solving the wave equations in elastic/acoustic media. For the sake of convenience, we choose the timesnapshot data in terms of displacement, however one could choose one of these to explicitly involve the velocity field as well. Alternatively, one could also pose the training problem as an initial value problem, where the wavefield snapshots for training are provided in the form of two initial conditions at ğ‘¡ = 0. It is important to note that modeling the wave propagation forward with only two early time snapshots of the wavefield cannot be implemented with traditional solvers, which illustrates the flexibility of PINNs in dealing with data at any time when applied to the wave equation.</p><p>The objective of the training process is to minimize the sum of mean squared errors:</p><formula xml:id="formula_5">ğ‘€ğ‘†ğ¸(Î˜) = ğœ† 1 ğ‘€ğ‘†ğ¸ ğ‘ƒğ·ğ¸ + ğœ† 2 ğ‘€ğ‘†ğ¸ ğ‘† + ğœ† 3 ğ‘€ğ‘†ğ¸ ğ‘ƒ.ğ¶ + ğœ† 4 ğ‘€ğ‘†ğ¸ ğ‘‚ğ‘ğ‘  ,<label>(2)</label></formula><p>Where Î˜ = ğ‘Š âˆª ğ‘ is the union of all the weights and biases of the NN.</p><formula xml:id="formula_6">ğ‘€ğ‘†ğ¸ ğ‘ƒğ·ğ¸ = 1 ğ‘ ğ‘ƒğ·ğ¸ âˆ‘ |ğ‘… ğ‘ƒğ·ğ¸ (ğ‘¥ ğ‘– , ğ‘§ ğ‘– , ğ‘¡ ğ‘– )| 2 ğ‘ ğ‘ƒğ·ğ¸ i=1</formula><p>is the loss term corresponding to the wave equation evaluated on a set of ğ‘ ğ‘ƒğ·ğ¸ randomly chosen PDE training data (ğ‘¥ ğ‘– , ğ‘§ ğ‘– , ğ‘¡ ğ‘– ) âŠ‚ ğ›º with ğ›º = â„ 2 Ã— â„ and</p><formula xml:id="formula_7">ğ‘€ğ‘†ğ¸ ğ‘† = 1 ğ‘ ğ‘† 1 âˆ‘|ğ‘… ğ‘† 1 (ğ‘¥ ğ‘– , ğ‘§ ğ‘– , ğ‘¡ ğ‘– = ğ‘¡ 1 0 )| 2 ğ‘ ğ‘† 1 ğ‘–=1 + 1 ğ‘ ğ‘† 2 âˆ‘|ğ‘… ğ‘† 2 (ğ‘¥ ğ‘– , ğ‘§ ğ‘– , ğ‘¡ ğ‘– = ğ‘¡ 2 0 )| 2 ğ‘ ğ‘† 2 i=1</formula><p>represents the loss terms corresponding to the two vectorial early-time snapshot data ğ‘ˆ 1 0 âƒ‘âƒ‘âƒ‘âƒ‘âƒ‘ and ğ‘ˆ 2 0 âƒ‘âƒ‘âƒ‘âƒ‘âƒ‘ in terms of displacement. Similarly, the free-surface constraint and the observed data loss terms are defined as,</p><formula xml:id="formula_8">ğ‘€ğ‘†ğ¸ ğ‘ƒ.ğ¶ = 1 ğ‘ ğ‘ƒ.ğ¶ âˆ‘ |ğ‘… ğ‘ƒ.ğ¶ (ğ‘¥ ğ‘– , ğ‘¡ ğ‘– , ğ‘§ ğ‘– )| 2 ğ‘ ğ‘ƒ.ğ¶ i=1</formula><p>and</p><formula xml:id="formula_9">ğ‘€ğ‘†ğ¸ ğ‘‚ğ‘ğ‘  = 1 ğ‘ ğ‘œğ‘ğ‘  âˆ‘ |ğ‘… ğ‘œğ‘ğ‘  (ğ‘¥ ğ‘– , ğ‘§ ğ‘– , ğ‘¡ ğ‘– )| 2 ğ‘ ğ‘œğ‘ğ‘  i=1</formula><p>, respectively. In contrast with standard partial differential equations solvers applied to the wave equation, PINNs essentially cast the forward (and inverse) problems as an optimization with optimal weights and biases Î˜ â‹† obtained by minimizing equation 2, i.e., Î˜ â‹† = ğ‘ğ‘Ÿğ‘”ğ‘šğ‘–ğ‘›{ğ‘€ğ‘†ğ¸(Î˜)}.</p><p>The hyperparameters ğœ† ğ‘–,ğ‘  &gt; 0 in equation 2 are set to normalize the different loss terms to guarantee a convergence to the correct solution. Failing to select proportionate loss terms would result in delayed convergence or possibly convergence to the wrong solution. Following the common practice in PINNs'</p><p>= 0 = = literature, we find the proper values of ğœ† ğ‘–,ğ‘  heuristically from trial and error; however, a more dynamic updating of these weights throughout the training process could be beneficial particularly for problems with persisting large residual errors at the boundaries <ref type="bibr">(Wang et al., 2020)</ref>. The learning rate annealing algorithm that Wang et al. proposed utilizes gradient statistics during the training process that would help maintaining a balance between different loss terms in equation 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PINNs for the seismic inverse problem</head><p>The goal of the inverse problem is to estimate the spatial distribution of the wavespeed ğ›¼ in equation 1 from the data collected at the surface or in a borehole by a set of seismometers. We use an additional NN with independent weights and biases to estimate the distribution of seismic wavespeed in the medium <ref type="bibr" target="#b39">(Tartakovsky et al., 2020;</ref><ref type="bibr" target="#b34">Shukla et al., 2020;</ref><ref type="bibr" target="#b10">Haghighat et al., 2021)</ref>. This secondary network is generally significantly smaller in size (depth and width of the network) than the primary network estimating the wavefield, since the structural complexity is much simpler in nature than the wavefield's variations in space and the distribution of wavespeed does not depend on time. We choose a fixed wavespeed NN architecture for all the inverse case studies in this paper, namely, a fully connected feed-forward NN with 5 hidden layers and 20 neurons per layer. An important outcome of the PINNs' formalism is that it eliminates the need for a user-defined parameterization of the computational domain for the inverse problem and the related biases imposed from such parametrization. However, one must make sure that the chosen inverse NN has enough layers and sufficient width for estimating the target structural heterogeneity one wishes to resolve-assuming that the observed data is not the limiting factor for the quality of the inversion.</p><p>It should be noted that enforcing both the free-surface constraint and the observed data from seismometers in the loss function (equation 2) might seem redundant at first glance. Although the data collected by the seismometers implicitly impose a free-surface condition, our numerical simulations show that it is necessary to include a loss term for the free-surface constraint for an accurate recovery of the reflected phases at the free surface. The main reason is that in practical scenarios, seismometers are limited to only sparse spatial coordinates on the surface while information from the free-surface constraint is readily available through a differential equation, i.e., ğ›» 2 ğœ™(ğ‘¥, ğ‘¡, ğ‘§ = 0) = 0 that can be evaluated at any position on the free surface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Normalization</head><p>There are two important normalization steps in PINNs' implementation that are crucial to guarantee a convergence to the correct solution. First, the input and output variables of the network must be mapped to the interval [-1,1] âˆˆ â„. Second, the acoustic wave PDE must be scaled such that both terms in equation 1 are on the same order. See appendix 1 for the appropriate formulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimization</head><p>Optimal values for the weights and biases of the proposed PINNs are obtained with the Adam optimizer <ref type="bibr" target="#b16">(Kingma and Ba, 2014)</ref>, an enhanced variant of the stochastic gradient descent with a learning rate of 1e-4 and a suitably chosen batch size (BSGD) for each case study. We stop the gradient descent search when the improvement from the previous epoch (iteration) becomes negligible, or when we surpass a fixed number of iterations. We have tested our results with L-BFGS <ref type="bibr" target="#b20">(Liu and Nocedal, 1989)</ref>, a second-order optimizer that takes advantage of the Hessian matrix but did not observe significant improvement in the training.</p><p>Table <ref type="table" target="#tab_0">1</ref> summarizes the batch size for each of the specific loss terms from equation ( <ref type="formula" target="#formula_5">2</ref>) for each case study. Note that unlike the PDE and the free-surface condition, we choose a fixed training data set to enforce the two early-time snapshots and the observed data from the seismograms. This is because the variability in the two latter data types is small enough to be captured with a relatively small data size. The optimal density of the different training data sets depends strongly on the ratio of the wavelength of the propagating wave to the domain size and the length scale of the structural heterogeneities as well as the total computational time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Validation</head><p>We use numerical solutions obtained from SpecFem2D as the ground truth for the validation of the forward PINN model. We also use SpecFem2D to generate the early-time snapshot data and synthetic seismograms, so that we can test the PINN efficiency and accuracy. Any time-snapshots of the wavefield generated either analytically or with any numerical solver can be utilized and ultimately (in a future study) real data will replace the synthetically generated seismograms for the inversions. The SpecFem2D models are discretized on a 100x100 mesh spatially and we used a second-order explicit Newmark time stepping scheme with the time step-size 4e-5 seconds. We employed perfectly matched layers (PML) <ref type="bibr" target="#b18">(Komatitsch and Tromp, 2003)</ref> at the boundaries of the domain with a thickness of 10 nodes to simulate the absorbing boundary conditions for the point source cases, and the Stacey absorbing boundary conditions for the teleseismic plane wave source cases <ref type="bibr" target="#b38">(Stacey, 1988)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computational Experiments</head><p>In this section we examine the efficiency and accuracy of the PINN approach with the loss function given in (2). We present different case studies for forward and inverse modeling with the acoustic equation. We start with the forward simulation and then proceed to the inverse problems in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case 1. Application of PINNs to wave propagation in a heterogenous medium</head><p>Since our main focus in this paper is FWIs, we restrict our application of PINN forward acoustic wave propagation to a single case of heterogeneous medium. Fig. <ref type="figure" target="#fig_8">3</ref> shows the wavespeed distribution in the domain with a background of 3 ğ‘˜ğ‘š/ğ‘  perturbed with Gaussian heterogeneity of a minimum velocity of 2 ğ‘˜ğ‘š/ğ‘  and a width (standard deviation) of 2.5 km. We choose a network with 4 hidden layers and 50 neurons per layer. The size of the training data set for the PDE loss term is 20,000 points while 3600 points are set for each of the early-time snapshot data, picked from a normal distribution in space and time. We note that, for this particular case study, we do not impose a free-surface condition at the top of the domain, since our objective here is to observe how well PINNs can capture the wave propagation and interaction with the prescribed heterogeneity in the forward problem. The weights for different loss terms in equation ( <ref type="formula" target="#formula_5">2</ref>) are ğœ† 1 = 0.1, ğœ† 2 = 1, ğœ† 3 = ğœ† 4 = 0. We simulate 5 seconds of wave propagation. Fig. <ref type="figure">4</ref> shows the evolution of the history of convergence of loss terms in equation ( <ref type="formula" target="#formula_5">2</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Application of PINNs to inverse modeling</head><p>In this section, we present the application of PINNs to FWIs. For all case scenarios, we follow the same strategy outlined here. We build a 2-D domain with prescribed wavespeed distribution and simulate the acoustic wave propagation using SpecFem2D. We then use the generated seismograms as the data (observation) to run the inversion. Again, we use two early-time snapshots of the displacement field from SpecFem2D as the training data. It is important to note that we only use snapshots taken before the wave interacts with any heterogeneities in the ground truth model, so as to avoid providing more information into PINN than would normally be available in practical inverse problems encountered in seismology. In all but the last example, we impose a free-surface condition at the top of the domain. We test the PINN's performance on recovering discontinuous as well as continuous velocity anomalies with various seismic source types such as a single point source, collection of point sources and teleseismic plane waves. We also assess the PINN's ability to capture free-surface reflections and absorbing boundary conditions in these case studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case 2. Crosswell experiment: Homogeneous velocity model with a single point source</head><p>We start with the simplest case study, a homogeneous domain with wavespeed 3 ğ‘˜ğ‘š/ğ‘ . We use PINNs to retrieve the wavespeed across the domain in a synthetic crosswell experiment given the set of training data outlined above. We choose a network with 4 hidden layers and 50 neurons in each. The size of the training data set for the PDE loss is 10,000, each of the early wavefield time-snapshots adds 3600 data points, and the free-surface constraint finally adds another 5000, all chosen from normal distributions in space and time. We use data points from a 0.4 second time window with a sampling frequency of 200 Hz from each component of the seismograms' time series and from 20 equally distanced seismometers (total 3240 data points from all seismometers) with depths ranging from the top of the model and extending to 450 m (Fig. <ref type="figure" target="#fig_5">7a</ref>). The seismic wavefield is generated from one point-source with a Gaussian source time function and a dominant frequency of 20 Hz located on the left side of the domain (Fig. <ref type="figure" target="#fig_6">8</ref>). The weight values for different loss terms in equation 2 are ğœ† 1 = ğœ† 3 = 0.1, ğœ† 2 = ğœ† 4 = 1. Fig. <ref type="figure" target="#fig_4">6</ref> shows the evolution of the different loss terms until convergence.  Despite the relatively poor initial guess for the wavespeed, we can see that PINN successfully recovers an accurate estimate of the domain's wavespeed (Fig. <ref type="figure" target="#fig_5">7</ref>) as well as the wavefield (Fig. <ref type="figure" target="#fig_6">8</ref>). The quality of the solution is further supported by the great match between the synthetic (observation) and calculated seismograms (Fig. <ref type="figure" target="#fig_7">9</ref>). At the top surface, where we imposed free-surface constraints, we observe a good match between the reflected wave simulated with SpecFem2D applied to the true wavespeed model and the PINN solution in terms of amplitude, waveform, and timing (Fig. <ref type="figure" target="#fig_6">8</ref>). It is important to emphasize that we have not explicitly enforced absorbing conditions in the loss function. The ability of PINN to manage automatically absorbing conditions stem from PINNs solutions being smooth and infinitely differentiable functions. Both components of the time series of the synthetic seismograms (observations) are also matched accurately by the PINNs solution (Fig. <ref type="figure" target="#fig_7">9</ref>).    A comparison of the wavefield after 0.15 seconds is provided in fig. <ref type="figure" target="#fig_11">11</ref>. It shows that the inverted solution matches the wavefield of the synthetic true solution accurately. The match between observed and modeled seismograms for each of the 20 seismometers is also excellent (Fig. <ref type="figure" target="#fig_12">12</ref>). For some of the seismograms, the slightly larger discrepancies between the input data and the outputs from PINN around the end of the time window analyzed is a regression artifact independent of the method. There, the optimization close to the final time is not perfect. Nevertheless, the prominent parts of the time series have been closely matched by PINNs solution and increasing the sampling frequency would improve the remaining misfit. We have also performed this inversion with a smaller NN with 4 hidden layers and 50 neurons per layer. The smaller network still yields a good estimate of the wavespeed distribution, however the recovered wavefield is less accurate and justifies the choice of a deeper network for an improved accuracy (See Supporting Information).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case 4. Ellipsoidal anomaly with two incident plane waves</head><p>In teleseismic imaging, plane waves from multiple incidence angles are generally required for a suitable ray coverage of the area under study. In the next example, we demonstrate how to incorporate multiple events into PINNs' formulation in a consistent manner such that it avoids substantial increase in computational costs. Exploiting the linearity of the acoustic wave equations, we superpose multiple events and design a network to simulate the resulting superposition of all events at once. This approach avoids defining a network for each event, which can become prohibitively expensive.</p><p>In this case study, we generate two compressional plane waves with a ricker source time function and a dominant frequency of 2 Hz with incidence angles + 20 and -20 degrees (with respect to the vertical axis).</p><p>The two plane waves propagate through an ellipsoidal low velocity anomaly (wavespeed of 2 ğ‘˜ğ‘š/ğ‘ ) embedded in a homogeneous background model with 3 ğ‘˜ğ‘š/ğ‘ . We set up 17 equally spaced seismometers at the top surface of the model starting from the top leftmost corner of the domain and extending 15 km to the right (Fig. <ref type="figure" target="#fig_13">13a</ref>). We record 5 seconds of the seismic signal with a sampling frequency of 20 Hz for training the PINN (3400 training data from the seismometers' time series). A PINN with 8 hidden layers and 100 neurons per layer is used for the wavefield neural network. The training data sets for the loss terms corresponding to PDE, free-surface constraint on top and each of the wavefield early time-snapshots consist of 40,000, 5000 and 3600 data points, chosen from a normal distribution in space and time, respectively. Furthermore, we set the weights of the misfit function ğœ† 1 = 0.01, ğœ† 2 = ğœ† 3 = ğœ† 4 = 1. Fig. <ref type="figure" target="#fig_13">13</ref> demonstrates the excellent agreement in terms of location, dimensions, and magnitude of the anomaly between the ground truth and PINN's inversion results.</p><p>The amplitude and structure of the recovered wavefield from PINN follows closely the forward simulations obtained from the numerical solver (Fig. <ref type="figure" target="#fig_14">14</ref>). However, we observe a slight timing difference at different parts of the wavefield at later times (Fig 14, lower most right panel). This time-difference is due to the fact that PINN recovers a smooth version of the structural heterogeneity (as in any other inverse technique), and since it solves the forward and inverse problems in a coupled fashion, the forward solution (wavefield) takes effect from the smoothed inverted structure. The smoothening associated with the inversion is also responsible for the absence of certain phases reflected off the anomaly. On the other hand, PINN is able to capture the reflected waves off the free surface on top (Fig. <ref type="figure" target="#fig_14">14</ref>). This shows that when the interface condition is explicitly enforced, PINN can capture reflections. Moreover, we observe the PINNs' great ability in simulating absorbing boundary layers at the left, right and bottom edges of the computational domain, without explicitly enforcing them (Fig. <ref type="figure" target="#fig_14">14</ref>). Our results show that the bulk of the training is spent on improving small discrepancies, while PINN converges to a satisfying velocity model in less than 70,000 epochs, instead of the 400,000 used for a complete training in this case (See supporting information).   From Fig. <ref type="figure" target="#fig_15">15</ref>, we observe that PINN finds a precise fit to the observed synthetic seismograms ensuring a correct capture of the physics of the wave's interaction with different parts of the domain. For instance, there is a sharp deficit in the recorded energy from the observed vertical component seismograms at around 9 km, signaling a "shadow" region affected by a low velocity anomaly at depth, which is impressively captured by PINNs as well. On the other hand, the absolute zero energy on the radial component seismograms, signature of a free-surface physical constraint in acoustic media is also correctly retrieved by PINN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case 5. Checkerboard test with nine point-sources</head><p>For the last case study, we test PINNs' performance when inverting for a sinusoidal checkerboard model velocity with alternating positive and negative anomalies, as depicted in Fig. <ref type="figure" target="#fig_16">16a</ref>. We also aim to see if a reasonably sized NN can capture the complex response of the system to as many as nine point-sources.</p><p>The point locations for 20 seismometers are set at the top surface at equal distance from each other, starting at 2.6 km from the left side of the domain extending to 17.6 km to the right. We use nine pointsources all with a Gaussian source time function and a dominant frequency of 2 Hz (Fig. <ref type="figure" target="#fig_17">17</ref>). We use a NN with 10 hidden layers and 100 neurons per layer. The size of the training data sets for the PDE, and each of the early-time snapshots are 60,000 and 3600, respectively. We also use data from the seismometers with a sampling frequency of 50 Hz (11600 total data points from seismometers' time series). The different loss term weights are set ğœ† 1 = 0.1, ğœ† 2 = ğœ† 3 = 1, ğœ† 4 = 0. For this case we do not impose a free-surface constraint at the top of the domain. From fig. <ref type="figure" target="#fig_16">16</ref> and 17 we observe that PINN is capable of recovering a complex oscillatory velocity gradient and the corresponding wavefield. The synthetic seismograms from SpecFem2D have also been successfully matched by PINN's outputs with negligible misfit.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We have shown that PINNs are able to accurately solve the forward and inverse modeling of the acoustic wave equation in complex media. PINNs are meshless and have impressive generalization capability and given only a set of two early-time snapshots they can predict the wavefield solution much later in time. Also, with minimal observed data only at the surface, and without any training data within the computational domain (other than the early-time snapshots) PINNs yield excellent results for seismic inversions. This shows that the PINN formalism can be implemented independent of other numerical solvers that require more complex implementation.</p><p>We extended the original approach by <ref type="bibr" target="#b30">Raissi et al., 2019</ref> by incorporating multiple seismic events into one NN and hence greatly optimizing the inverse problem for practical applications. Different seismic sources (plane waves and point sources) with variable frequencies can be implemented with limited effort. However, it must be noted that if the energy from the superposition of seismic sources interferes destructively at the site of a seismometer, superposition must be avoided because of the loss of information and the consequent deterioration of the solution. In this case, a possible approach is to define different groups of non-destructively interfering events and then define an independent NN for each group. This approach will still decrease the computational costs compared to defining a NN for each event.</p><p>Our study shows that the computational costs (size of the NNs and number of epochs to reach convergence) of the problem is strongly influenced by the frequency of the source and the complexity of the wavespeed structures. We observe that a smaller NN is capable of yielding satisfactory results for an inverse problem if the structure of the medium is simple. For instance, the NN for the homogenous inversion model (Case 2) is significantly smaller than the NN for the model with an ellipsoidal anomaly (Case 3). The NN's setup is also influenced by the frequency content of the source. Modeling higher frequencies (for the same physical dimensions) requires a larger training data set for the PDE loss to capture finer features such as refracted waves which are more pronounced at higher frequencies.</p><p>PINNs are a meshless method. They offer great flexibility in terms of implementation and if a priori knowledge is available for inverse problems. Moreover, our results show that PINNs perform well even without a priori knowledge or in the absence of an educated starting model. Nevertheless, one can easily implement a priori constraints on the wavespeed distribution. For instance, if we expect a medium with dominantly vertical variations in acoustic/seismic velocities, it is straightforward to set the functional form of the inverse NN to explicitly depend only on one spatial variable, namely z. This can be achieved with no fundamental change to the original algorithm.</p><p>PINN's implementation is made simple and compact thanks to modern python's libraries such as TensorFlow and PyTorch. For example, the script (available on <ref type="url" target="https://doi.org/10.26300/x3wd-4k56">https://doi.org/10.26300/x3wd-4k56</ref>) utilizes only a few hundred lines to run both the wave propagation and optimization for the inversion. It is also easy to modify or change the constraints imposed at the boundaries of the domain as they are expressed only in the definition of one of the loss terms in equation (2).</p><p>For the case studies with a discontinuous true model, reducing the smoothening effect of the inversion is possible if one uses a significantly larger training data set for the PDE part of the loss function and includes a priori knowledge of the presence of a discontinuity or a supervised distribution of many training data around the discontinuity. Moreover, a different type of minimization norm, e.g. L1, may lead to sharper discontinuities.</p><p>A challenge when using PINN comes from the heuristics nature of the algorithm when selecting the proper weights for each loss terms or selecting the proper network size. Work remains necessary to better constrain the factors that control the convergence of PINNs and the criteria for choosing the minimum density of the training data for the PDE to guarantee convergence to the correct solution <ref type="bibr" target="#b32">(Shin et al., 2020;</ref><ref type="bibr">Wang et al., 2020)</ref>; see also the recent work of <ref type="bibr" target="#b24">McClenny and Braga-Neto (2020)</ref>. Moreover, for large computational domains, efficient strategies to implement PINNs on GPUs are required to deal with the large memory cost involved. The implementation of PINNs with a domain decomposition in space and space-time domain is successfully studied by <ref type="bibr">Jagtap et al. (2020)</ref> and <ref type="bibr">Jagtap and Karniadakis (2020)</ref>, which is further extended to a multi-GPU platform by <ref type="bibr">Shukla et al. (2021)</ref>. Therefore, the computational efficiency of proposed method for larger and elastic approximation can be successfully tamed .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We have demonstrated that physics-informed neural networks are able to solve the wave propagation and full waveform inversions by relying on information from governing partial differential laws when there is limited data available. We have shown how inversions with multiple events can be performed with PINNs with limited additional memory or computational cost. PINNs' seamless ability to handle diverse sets of constraints, their meshless nature and the simplicity in formulation/implementation open new perspectives as the next generation of inverse solvers for geophysical applications. They provide a flexible framework to incorporate multiple data types and/or any apriori knowledge of the structure imaged and hence offer a great potential for joint and Bayesian inversions <ref type="bibr" target="#b45">(Yang et al., 2021)</ref>. We use the same wavespeed NN for all the case studies here with 4 layers and 20 neurons in each. NSeismograms is the total number of training data from all the input seismograms in both x and z directions. All the input data sizes denote the batch size for the corresponding loss term.</p><p>To understand the effect of a shorter training episode, we record the results of the inversion for the ellipsoidal anomaly with two teleseismic plane waves (Case 4 from the main text) after 70,000 epochs, instead of 400,000. Fig. <ref type="figure">S4</ref> shows that even with a shorter training process, the inverted wavespeed is acceptable, however with slightly larger smearing at the boundaries of the velocity anomaly compared to fig. <ref type="figure" target="#fig_13">13c</ref> in the main text. Furthermore, fig. <ref type="figure" target="#fig_3">S5</ref> shows that the overall shape of the waveforms is well preserved, however with slightly bent wavefronts (instead of straight plane waves) at later times. From fig. <ref type="figure" target="#fig_3">S5</ref> we can also see that the free-surface constraint and hence the resulting reflection is well captured by a shorter training process. Additionally, there is no noticeable violation of the absorbing boundary conditions at the right, left and bottom boundaries. We can also see that the seismograms are fit equally well for the shorter training of PINNs (Fig. <ref type="figure" target="#fig_22">S6</ref>).    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Schematics of PINNs' workflow. Left: Fully connected feed-forward neural network, the output of which approximates the solution to the forward and inverse problems. Right: The governing physical laws and the observed real-world data, i.e., seismograms, used to optimize the parameters of the PINN. The training stops when the loss error becomes smaller than a threshold, or the number of iterations goes beyond a set value.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Schematic representation of a hypothetical computational domain (x, z and t) with PINN. The two time-snapshots at times 0 and Î”ğ‘¡ are the only labeled data used from within the computational domain. The time-snapshots are color-coded for displacement amplitude. The white dashed line encloses a hypothetical heterogeneity. The grey hyperplane represents domain where the training data to apply, for example, a free-surface condition at the top of the domain. The two yellow stars represent the position of seismometers. ğ‘¡ ğ‘š is the duration of the time domain. The PDE training data is selected randomly from the entire computational domain. Note that for some of the case studies we only use a subset of the various data sets illustrated here.</figDesc><graphic coords="6,308.24,444.18,115.27,66.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .Figure 4 .</head><label>34</label><figDesc>Figure 3. The distribution of the input wavespeed ğ›¼ for the forward problem</figDesc><graphic coords="9,163.24,72.00,287.98,238.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Ground truth versus predicted magnitude of the wavefields from PINN for the forward problem. The first two wavefield snapshots from SpecFem2D at ğ‘¡ = 0, ğ‘¡ = 0.1 ğ‘  are used as the training data. The misfits show the absolute pointwise error.</figDesc><graphic coords="10,123.00,72.00,365.75,287.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Evolution of the different loss terms in equation 2 as well as the total loss for the synthetic crosswell experiment in a homogeneous domain.</figDesc><graphic coords="11,162.00,399.92,287.98,281.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. (a) True domain, (b) Initial guess (c) PINN's inversion results after convergence. The black rectangles in (b) and (c) show the area where the inversion is performed with PINN. The red dots in (a) show the locations of the seismometers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Comparison between ground truth and modeled wavefields and their absolute pointwise differences for the synthetic crosswell experiment with a homogeneous wavespeed distribution. The first two wavefield snapshots from SpecFem2D at ğ‘¡ = 0, ğ‘¡ = 0.01 ğ‘  are used as training data.</figDesc><graphic coords="12,126.00,137.96,359.98,221.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. The comparison between ground truth (black line) and PINN's prediction (red dashed line) of the vertical and radial component seismograms for the synthetic crosswell experiment with a homogeneous wavespeed distribution. Locations of the seismometers are shown in fig. 7a.</figDesc><graphic coords="12,162.00,464.07,287.94,192.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Case 3 .</head><label>3</label><figDesc>Crosswell experiment: Ellipsoidal velocity anomaly with a single point source This case study is designed to test the ability of PINNs to recover sharp 2-D anomalies from a synthetic crosswell experiment. An ellipsoidal low velocity anomaly with wavespeed of 2 ğ‘˜ğ‘š/ğ‘  is embedded in a homogeneous background model (3 ğ‘˜ğ‘š/ğ‘ ). The velocity contrast between the anomaly and background is sharp (step function). The size of the domain, the location of the source and seismometers and the sampling frequency of the training data are the same as the previous case (Fig.10a). We design a network with 8 hidden layers and 100 neurons per layer for the wavefield NN. The size of the training data set for the PDE loss is increased to 40,000 points and remains 3600 and 5000 for each of the early-time snapshot data and the free-surface constraint, respectively, again chosen from a normal distribution in space and time. Furthermore, we set the weights of the misfit function ğœ† 1 = ğœ† 3 = 0.1, ğœ† 2 = ğœ† 4 = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. (a) True domain, (b) Initial guess (c) PINN's inversion results after convergence. The black rectangles in (b) and (c) show the area where the inversion is performed with PINN. The red dots in (a) show the locations of the seismometers. Note in the true domain the wavespeed transition from the ellipsoidal anomaly to the background is discontinuous.</figDesc><graphic coords="13,162.00,289.81,287.98,281.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10</head><label>10</label><figDesc>Fig. 10 shows the inverted solution for the acoustic wavespeed in comparison to the ground truth and the starting model. PINN successfully retrieves the location, dimension, and magnitude of the anomaly. The inverted solution is smoothed instead of the sharp discontinuous transition in material property of the true model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Comparison between ground truth and modeled wavefields and their absolute pointwise differences for the synthetic crosswell experiment with a discontinuous ellipsoidal anomaly. The first two wavefield snapshots from SpecFem2D at ğ‘¡ = 0, ğ‘¡ = 0.01 ğ‘  are used as the training data.</figDesc><graphic coords="14,116.25,72.00,378.99,232.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. The comparison between ground truth (black line) and PINN's prediction (red dashed line) of the vertical and radial component seismograms for the synthetic crosswell experiment with a discontinuous ellipsoidal anomaly. Locations of the seismometers are shown in fig. 10a.</figDesc><graphic coords="14,162.00,481.26,287.94,192.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. (a) True domain, (b) Initial guess (c) PINN's inversion results after convergence for the teleseismic case study. The black rectangles in (b) and (c) show the area where the inversion is performed with PINN. The red dots in (a) show the locations of the seismometers.</figDesc><graphic coords="16,162.00,72.00,287.98,367.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 14 .</head><label>14</label><figDesc>Figure 14. Comparison between ground truth and modeled wavefields and their absolute pointwise differences. The first two snapshots from SpecFem2D at ğ‘¡ = 0, ğ‘¡ = 0.05 ğ‘  are used as the training data.</figDesc><graphic coords="17,126.00,72.00,359.97,281.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 15 .</head><label>15</label><figDesc>Figure 15. The comparison between ground truth (black line) and PINN's prediction (red dashed line) of the vertical and radial component seismograms for the teleseismic case study. Locations of the seismometers are shown in fig. 13a.</figDesc><graphic coords="17,162.00,408.20,288.00,212.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 16 .</head><label>16</label><figDesc>Figure 16. (a) True domain, (b) Initial guess (c) PINN's inversion results after convergence. The black rectangles in (b) and (c)show the area where the inversion is performed with PINN. The red dots in (a) show the locations of the seismometers.</figDesc><graphic coords="19,126.00,126.20,359.96,283.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 17 .</head><label>17</label><figDesc>Figure 17. Comparison between ground truth and modeled wavefields and their absolute pointwise differences. The first two snapshots from SpecFem2D at ğ‘¡ = 0, ğ‘¡ = 0.1 ğ‘  are used as the training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 18 .</head><label>18</label><figDesc>Figure 18. The comparison between ground truth (black line) and PINN's prediction (red dashed line) of the vertical and radial component seismograms for the checkerboard case study. Locations of the seismometers are shown in fig. 16a.</figDesc><graphic coords="19,162.00,450.63,288.00,212.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure S1 .</head><label>S1</label><figDesc>Figure S1. (a) Ground truth, (b) Initial guess (c) Inversion results for the synthetic crosswell experiment. A PINN with 4 hidden layers and 50 neurons in each layer has been used. The black rectangles in (b) and (c) show the area that we have inverted for with PINN. The red dots in (a) show the locations of the seismometers.</figDesc><graphic coords="26,162.00,247.40,287.99,286.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure S2 .</head><label>S2</label><figDesc>Figure S2. Wavefields for the synthetic crosswell experiment. Ground truth versus predicted magnitude of the wavefields from PINN and their absolute pointwise differences with a NN with 4 hidden layers and 50 neurons in each layer.</figDesc><graphic coords="27,162.00,333.78,287.94,192.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure S3 .</head><label>S3</label><figDesc>Figure S3. Vertical (left) and radial (right) motion seismograms for the synthetic crosswell experiment. black line: input, red dashed line: PINNs' prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure S6 .</head><label>S6</label><figDesc>Figure S6. Vertical (top) and radial (bottom) motion seismograms after 70,000 epochs, for the teleseismic case study. black line: input, red dashed line: PINNs' prediction.</figDesc><graphic coords="29,162.00,72.00,288.00,212.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="5,82.74,146.08,448.94,306.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="18,162.00,335.52,287.98,371.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="28,162.00,72.00,287.98,277.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="28,126.00,390.68,359.97,281.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Parameters used for the simulations. [50]*4 indicates 4 hidden layers and 50 neurons in each. Note that the NNs in this table indicate the forward NN.</figDesc><table><row><cell>Type</cell><cell>Inhomogeneity</cell><cell>Source</cell><cell>Network</cell><cell>Activation</cell><cell>Npde</cell><cell>NS</cell><cell cols="2">NP.C NSeismograms</cell></row><row><cell></cell><cell>type</cell><cell>type &amp;</cell><cell>[Width]*Depth</cell><cell>function</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Frequency</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Forward</cell><cell>Gaussian</cell><cell>1 Point</cell><cell>[50]*4</cell><cell>Sin()</cell><cell cols="2">20,000 2 *3600</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell></cell><cell>Anomaly</cell><cell>source 2Hz</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Inverse</cell><cell>Homogeneous</cell><cell>1 Point</cell><cell>[50]*4</cell><cell>tanh()</cell><cell cols="3">10,000 2 *3600 5000</cell><cell>2*1620</cell></row><row><cell></cell><cell></cell><cell>source 20Hz</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Inverse</cell><cell>Ellipsoidal</cell><cell>1 Point</cell><cell>[100]*8</cell><cell>tanh()</cell><cell cols="3">40,000 2 *3600 5000</cell><cell>2*1620</cell></row><row><cell></cell><cell>Anomaly</cell><cell>source 20Hz</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Inverse</cell><cell>Ellipsoidal</cell><cell>2 Plane</cell><cell>[100]*8</cell><cell>tanh()</cell><cell cols="3">60,000 2 *3600 5000</cell><cell>2*1700</cell></row><row><cell></cell><cell>Anomaly</cell><cell>waves 2Hz</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Inverse</cell><cell>Sinusoidal</cell><cell>9 Point</cell><cell>[100]*10</cell><cell>Sin()</cell><cell cols="2">60,000 2 *3600</cell><cell>N/A</cell><cell>2*5800</cell></row><row><cell></cell><cell>Checkerboard</cell><cell>sources 2Hz</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgment: We thank <rs type="person">Victor C. Tsai</rs> for the helpful discussions on the set-ups of the synthetic case studies. This research was conducted using computational resources and services at the <rs type="institution">Center for Computation and Visualization, Brown University</rs>. A sample script in python for this study can be found on <rs type="institution">Brown University</rs>'s data repository: <ref type="url" target="https://doi.org/10.26300/x3wd-4k56">https://doi.org/10.26300/x3wd-4k56</ref>.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A</head><p>Here we show the two important normalizations used in PINN's formulation in this study: a) We map each input variable to the neural network onto the interval [-1,1] âˆˆ â„ <ref type="bibr" target="#b30">(Raissi et al., 2019)</ref>:</p><p>We scale the wave PDE in equation ( <ref type="formula">1</ref>) to constrain the wavespeed in the [0,1] âˆˆ â„ interval. Using the scaled spatial coordinates ğ‘¥ = max(ğ›¼) ğ‘¥ â‹† , ğ‘§ = max(ğ›¼) ğ‘§ â‹† , yields,</p><p>where Î± â‹† = ğ›¼/ max(ğ›¼) and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supporting information</head><p>In this section we discuss two main points regarding training PINNs for FWIs: (a) How does using a smaller NN affect the inversion results? (b) How accurate is a PINN that has been trained for a smaller number of epochs for the same number of hidden layers and neurons? We perform two additional inversions to address each of these questions.</p><p>To address the first question, we design a smaller NN with 4 hidden layers and 50 neurons in each layer to redo the inversion for the case study with an ellipsoidal anomaly and a 20 Hz point source (Case 2. In the main text). All parameters of the system and PINN's setup are the same as in Case 2. From fig. <ref type="figure">S1</ref> we can see that the main features of the anomaly (location, approximate size, and strength) have been recovered well by PINNs, despite an uneducated initial guess. However, the smearing at the boundaries of the anomaly is larger than Case 2 in the main text with the larger NN. From fig. <ref type="figure">S2</ref> we can also see that the estimation error for the wavefield has slightly increased compared to Case 2 in areas close to the boundaries of the velocity anomaly. The fit to the seismograms has not been affected greatly, which is confirmed from fig. <ref type="figure">S3</ref>. This exercise shows that it is important for the chosen NN to be expressive enough (large enough number of layers and neurons) for a correct estimation of the ground truth wavespeed and the wavefield.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} symposium on operating systems design and implementation</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep-learning tomography</title>
		<author>
			<persName><forename type="first">M</forename><surname>Araya-Polo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jennings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dahlke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Leading Edge</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="66" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Machine learning for data-driven discovery in solid Earth geoscience</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maarten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Beroza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">6433</biblScope>
			<biblScope unit="page">363</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Global adjoint tomography: first-generation model</title>
		<author>
			<persName><forename type="first">E</forename><surname>BozdaÄŸ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Komatitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tromp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Podhorszki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pugmire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysical Journal International</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1739" to="1766" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.09506</idno>
		<title level="m">Physics-informed neural networks (PINNs) for fluid mechanics: A review</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Physics-informed neural networks for heat transfer problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perdikaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Heat Transfer</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">60801</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Numerical experiments in broadband receiver function analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Cassidy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of the Seismological Society of America</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1453" to="1474" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SimPEG: An open source framework for simulation and gradient based parameter estimation in geophysical applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Heagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pidlisecky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Oldenburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Geosciences</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="142" to="154" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The adjoint method in seismology: I. Theory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fichtner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Bunge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics of the Earth and Planetary Interiors</title>
		<imprint>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="86" to="104" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Resolution analysis in full waveform inversion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fichtner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Trampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysical Journal International</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1604" to="1624" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A physics-informed deep learning framework for inversion and surrogate modeling in solid mechanics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Haghighat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Juanes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Methods in Applied Mechanics and Engineering</title>
		<imprint>
			<biblScope unit="volume">379</biblScope>
			<biblScope unit="page">113741</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive activation functions accelerate convergence in deep and physics-informed neural networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Jagtap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kawaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">404</biblScope>
			<biblScope unit="page">109136</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Locally adaptive activation functions with slope recovery for deep and physics-informed neural networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Jagtap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kawaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society A</title>
		<imprint>
			<biblScope unit="volume">476</biblScope>
			<biblScope unit="page">20200334</biblScope>
			<date type="published" when="2020">2020. 2239</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Extended physics-informed neural networks (xpinns): A generalized space-time domain decomposition based deep learning framework for nonlinear partial differential equations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Jagtap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Computational Physics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2002" to="2041" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Conservative physics-informed neural networks on discrete domains for conservation laws: Applications to forward and inverse problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Jagtap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kharazmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Methods in Applied Mechanics and Engineering</title>
		<imprint>
			<biblScope unit="volume">365</biblScope>
			<biblScope unit="page">113028</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">NSFnets (Navier-Stokes flow nets): Physics-informed neural networks for the incompressible Navier-Stokes equations</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Kevrekidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perdikaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">426</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="422" to="440" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note>Nature Reviews Physics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Introduction to the spectral element method for three-dimensional seismic wave propagation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Komatitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tromp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysical journal international</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="806" to="822" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A perfectly matched layer absorbing boundary condition for the second-order seismic wave equation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Komatitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tromp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysical Journal International</title>
		<imprint>
			<biblScope unit="volume">154</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="146" to="153" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Machine learning in seismology: Turning data into insights</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Trugman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">E</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Bianco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Meade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gerstoft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Seismological Research Letters</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the limited memory BFGS method for large scale optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical programming</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="503" to="528" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Physics-informed neural networks for high-speed flows</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Jagtap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Methods in Applied Mechanics and Engineering</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="page">112789</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Three-dimensional sensitivity kernels for finite-frequency traveltimes: the banana-doughnut paradox</title>
		<author>
			<persName><forename type="first">H</forename><surname>Marquering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Dahlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nolet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysical Journal International</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="805" to="815" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Self-adaptive physics-informed neural networks using a soft attention mechanism</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mcclenny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Braga-Neto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.04544</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep learning for fast simulation of seismic waves in complex media</title>
		<author>
			<persName><forename type="first">B</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nissen-Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Markham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Solid Earth</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1527" to="1549" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Solving the wave equation with physics-informed deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Markham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nissen-Meyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.11894</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Earthquake transformeran attentive deep-learning model for simultaneous earthquake detection and phase picking</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Ellsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Beroza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A review of the adjoint-state method for computing the gradient of a functional with geophysical applications</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Plessix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysical Journal International</title>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="495" to="503" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Generalized seismic phase detection with deep learning</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">E</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hauksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Heaton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of the Seismological Society of America</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">5A</biblScope>
			<biblScope unit="page" from="2894" to="2901" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Raissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perdikaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">378</biblScope>
			<biblScope unit="page" from="686" to="707" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Detectability of Melt-Rich Lenses in Magmatic Reservoirs From Teleseismic Waveform Modeling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rasht-Behesht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Mancinelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Geophysical Research: Solid Earth</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>p.e2020JB020264</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Error estimates of residual minimization using neural networks for linear PDEs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.08019</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Jagtap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Blackshire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sparkman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14104</idno>
		<title level="m">A physics-informed neural network for quantifying the microstructure properties of polycrystalline Nickel using ultrasound data</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Physics-informed neural network for ultrasound nondestructive quantification of surface breaking cracks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Di Leoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blackshire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sparkman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Nondestructive Evaluation</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Jagtap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.10013</idno>
		<title level="m">Parallel physics-informed neural networks via domain decomposition</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Eikonet: Solving the eikonal equation with deep neural networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Azizzadenesheli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">E</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Solving the frequency-domain acoustic VTI wave equation using physics-informed neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Alkhalifah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">B</forename><surname>Waheed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysical Journal International</title>
		<imprint>
			<biblScope unit="volume">225</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="846" to="859" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Improved transparent boundary formulations for the elastic-wave equation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Stacey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of the Seismological Society of America</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2089" to="2097" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Physicsinformed deep neural networks for learning parameters and constitutive relationships in subsurface flow problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Tartakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">O</forename><surname>Marrero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perdikaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Tartakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barajas-Solano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Water Resources Research</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2020">2020. 2019WR026731</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Spectral-element and adjoint methods in seismology</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tromp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Komatitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Computational Physics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">B</forename><surname>Waheed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Alkhalifah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Haghighat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Virieux</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.01588</idno>
		<title level="m">PINNtomo: Seismic tomography using physics-informed neural networks</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Understanding and mitigating gradient pathologies in physicsinformed neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perdikaris</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.04536</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">When and why pinns fail to train</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perdikaris</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.14527</idno>
	</analytic>
	<monogr>
		<title level="m">A neural tangent kernel perspective</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Physics-informed machine learning approach for augmenting turbulence models: A comprehensive framework</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Paterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Fluids</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">74602</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">B-PINNs: Bayesian physics-informed neural networks for forward and inverse PDE problems with noisy data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">425</biblScope>
			<biblScope unit="page">109913</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Earthquake detection through computationally efficient similarity search</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Beroza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science advances</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">e1501057</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Seismic signal denoising and decomposition using deep neural networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Beroza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="9476" to="9488" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A general approach to seismic inversion with automatic differentiation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Darve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Beroza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Geosciences</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page">104751</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
