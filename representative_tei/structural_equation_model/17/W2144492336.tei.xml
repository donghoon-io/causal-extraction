<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Facing off with Scylla and Charybdis: a comparison of scalar, partial, and the novel possibility of approximate measurement invariance</title>
				<funder ref="#_CEmkGsM">
					<orgName type="full">Netherlands</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2013-10-23">23 October 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rens</forename><surname>Van De Schoot</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Methods and Statistics</orgName>
								<orgName type="department" key="dep2">Faculty of Social Sciences</orgName>
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<settlement>Utrecht</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Optentia Research Program</orgName>
								<orgName type="department" key="dep2">Faculty of Humanities</orgName>
								<orgName type="institution">North-West University</orgName>
								<address>
									<settlement>Vanderbijlpark</settlement>
									<country key="ZA">South Africa</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anouck</forename><surname>Kluytmans</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Methods and Statistics</orgName>
								<orgName type="department" key="dep2">Faculty of Social Sciences</orgName>
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<settlement>Utrecht</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lars</forename><surname>Tummers</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Public Administration</orgName>
								<orgName type="institution">Erasmus University Rotterdam</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Center for the Study of Law &amp; Society</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Lugtig</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Methods and Statistics</orgName>
								<orgName type="department" key="dep2">Faculty of Social Sciences</orgName>
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<settlement>Utrecht</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joop</forename><surname>Hox</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Methods and Statistics</orgName>
								<orgName type="department" key="dep2">Faculty of Social Sciences</orgName>
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<settlement>Utrecht</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bengt</forename><surname>Muthén</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Graduate School of Education</orgName>
								<orgName type="laboratory">International Labaratory for Socio-Cultural Research HSE Moscow</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country>USA Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Schmidt</surname></persName>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Jelte M. Wicherts</orgName>
								<orgName type="institution" key="instit1">Oi-Man Kwok</orgName>
								<orgName type="institution" key="instit2">Texas A&amp;M University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">Department of Methods and Statistics</orgName>
								<orgName type="institution" key="instit1">Rens van de Schoot</orgName>
								<orgName type="institution" key="instit2">Utrecht University</orgName>
								<address>
									<addrLine>Padualaan 14</addrLine>
									<postBox>P.O. Box 80.140</postBox>
									<postCode>3584CH 3508TC</postCode>
									<settlement>Utrecht</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Facing off with Scylla and Charybdis: a comparison of scalar, partial, and the novel possibility of approximate measurement invariance</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013-10-23">23 October 2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3389/fpsyg.2013.00770</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>measurement invariance</term>
					<term>Bayesian structural equation modeling</term>
					<term>Mplus</term>
					<term>informative/subjective prior</term>
					<term>prior variance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Measurement invariance (MI) is a pre-requisite for comparing latent variable scores across groups. The current paper introduces the concept of approximate MI building on the work of Muthén and Asparouhov and their application of Bayesian Structural Equation Modeling (BSEM) in the software Mplus. They showed that with BSEM exact zeros constraints can be replaced with approximate zeros to allow for minimal steps away from strict MI, still yielding a well-fitting model. This new opportunity enables researchers to make explicit trade-offs between the degree of MI on the one hand, and the degree of model fit on the other. Throughout the paper we discuss the topic of approximate MI, followed by an empirical illustration where the test for MI fails, but where allowing for approximate MI results in a well-fitting model. Using simulated data, we investigate in which situations approximate MI can be applied and when it leads to unbiased results. Both our empirical illustration and the simulation study show approximate MI outperforms full or partial MI In detecting/recovering the true latent mean difference when there are (many) small differences in the intercepts and factor loadings across groups. In the discussion we provide a step-by-step guide in which situation what type of MI is preferred. Our paper provides a first step in the new research area of (partial) approximate MI and shows that it can be a good alternative when strict MI leads to a badly fitting model and when partial MI cannot be applied.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>If scores on a latent variable are to be compared across groups or time in a meaningful way, the underlying measurement model should be equivalent. Measurement invariance (MI) implies that (for continuous observed variables), conditional on the latent trait scores, the covariances and the intercepts are equal across groups (cf. <ref type="bibr" target="#b11">Mellenbergh, 1989)</ref>. In other words, the relationships between the latent trait scores and the observed variables do not depend on group membership. Studies of so-called "measurement invariance" have often shown that the underlying constructs are, however, not equivalent (e.g., <ref type="bibr" target="#b35">Vandenberg and Lance, 2000;</ref><ref type="bibr" target="#b23">Schmitt and Kuljanin, 2008;</ref><ref type="bibr" target="#b12">Millsap, 2011)</ref>. The current paper discusses approximate MI as a possible solution to these situations, thereby building on the work of <ref type="bibr">Muthén and</ref><ref type="bibr">Asparouhov (2012b, 2013)</ref>. Muthén and Asparouhov describe a novel method where, using Bayesian structural equation models (BSEM), exact zero constraints can be replaced with approximate zero constraints based on substantive theories. For example, cross-loadings in confirmatory factor analysis are traditionally constrained to be zero, but using the procedure of <ref type="bibr" target="#b15">Muthén and Asparouhov (2012b)</ref> these parameters can be estimated with some, as we call it, "wiggle room" <ref type="bibr">(Muthén and Asparouhov, 2012a)</ref>, implying that very small cross-loadings are allowed. The novel possibility of approximate zero constraints is an interesting alternative to the use of exact zeros which has proven to be unrealistic at times (see for example <ref type="bibr" target="#b29">van Zuiden et al., 2011)</ref>. The current paper discusses another area where approximate zeros might have an advantage: when full MI across groups is too strict and small differences in factor loadings or intercepts are allowed to make the model fit well. Possibly differences in use of the response scale are described in <ref type="bibr" target="#b13">Morren et al. (2011)</ref>. <ref type="bibr" target="#b16">Muthén and Asparouhov (2013)</ref> use the BSEM approach as a way to get the non-invariance information as you would get by Maximum Likelihood (ML) modification indices. They propose a two-step procedure where one first uses BSEM's approximate MI analysis to get modification indices and then free those noninvariant parameters in a regular Bayes run as a final, second step. BSEM modification indices are helpful, for example, when having categorical items where no ML modification indices exist, or with a large number of groups. This is often the case in the context of large scale international studies. In the current paper we focus on the benefits or dangers when applying approximate invariance when it is actually applied in a CFA model. As we will show with both an empirical illustration and a simulation study, approximate MI enables the researchers to make explicit tradeoffs between the degree of MI on the one hand, and the degree of model fit on the other. However, as our simulation results demonstrate, some bias in the estimated parameters occurs due to the alignment issue (see also <ref type="bibr" target="#b16">Muthén and Asparouhov, 2013)</ref>, which can be corrected using a method available in Mplus v7.1 <ref type="bibr" target="#b0">(Asparouhov and Muthén, 2013)</ref>.</p><p>In what follows we first illustrate issues with applying MI, followed by an introduction of approximate MI. Thereafter, we provide an empirical illustration where the test for strict MI fails, but where approximate MI results in a well-fitting model. Then, with a simulation study, we investigate whether approximate MI can lead to unbiased estimates for differences in latent scores across groups. Thereafter, we introduce the correction method and show its influence on the parameters in our simulation study. We conclude with a discussion and practical recommendations for scholars who aim to meaningfully compare scores on latent variables. Note that the application of approximate MI in the current paper is limited to situations with a small number of groups, continuous variables, and "almost" invariant models. For a more general approach see <ref type="bibr" target="#b16">Muthén and Asparouhov (2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>THE ISSUE OF APPROXIMATE MEASUREMENT INVARIANCE: SCYLLA OR CHARYBDIS</head><p>Questionnaires are often used to assess latent constructs, such as human attitudes and behavior, with the goal to compare groups. For such a comparison to be valid MI should apply, see <ref type="bibr" target="#b12">(Millsap, 2011)</ref> or <ref type="bibr" target="#b35">Vandenberg and Lance (2000)</ref> for a comprehensive overview on possible methods testing MI. That is, a questionnaire should measure identical constructs with the same factor structure across different groups. Stated differently, factor loadings, intercepts, and residual variances should be identical to get the label "full measurement invariance." If one wants to compare latent means the intercepts are of major importance and therefore, we focus on the intercepts. <ref type="bibr" target="#b32">Van de Schoot et al. (2012)</ref> stated that "When MI does not hold, groups or subjects <ref type="bibr">[. . .]</ref> respond differently to the items and as a consequence factor means cannot reasonably be compared" (p. 487). This statement refers to a potential bias in the latent mean comparison when full MI is assumed, but not supported by the data, or when MI is not assumed and the latent means are (incorrectly) compared. In order to meaningfully compare latent means across groups, at least the factor loadings and intercepts should be equal; this is the situation of scalar invariance <ref type="bibr" target="#b35">(Vandenberg and Lance, 2000)</ref>. Henceforth, when (full) MI is used we refer to scalar invariance. After testing for scalar MI it might be that such a model does not fit the data. What to do in such a situation? One solution is to allow for partial MI. <ref type="bibr" target="#b25">Steenkamp and Baumgartner (1998)</ref> suggested that as long as at least two of the factor loadings and intercepts are constrained to be equal across groups or time, the difference in the latent mean between the groups is unbiased (see also <ref type="bibr" target="#b26">Steinmetz, 2013)</ref>. However, this procedure has been debated much <ref type="bibr" target="#b34">(Vandenberg, 2002)</ref>, for example how to choose the reference category <ref type="bibr" target="#b21">(Rensvold and Cheung, 2001)</ref>. At least partial invariance for the factor loadings before one can proceed to test invariance of the intercepts <ref type="bibr" target="#b25">(Steenkamp and Baumgartner, 1998)</ref>. This paper focuses on comparison of latent means, so we present approximate MI in the context of the intercepts.</p><p>To sum up, if MI is used to either see if measurement instruments are equivalent across populations, or to compare the latent means to each other, possible outcomes of MI are:</p><p>(1) (full or) scalar MI, where all intercepts are constrained to be equal across groups.</p><p>(2) partial MI, where some of the intercepts between groups are allowed to be freely estimated, while others are held constant (see e.g., <ref type="bibr" target="#b25">Steenkamp and Baumgartner, 1998;</ref><ref type="bibr" target="#b26">Steinmetz, 2013)</ref>; or (3) No invariance, where all intercepts between groups are freely estimated, because such a model fits the data best. Consequently, the questionnaire cannot be used for comparing groups.</p><p>In the current paper we add a fourth option, initiated by <ref type="bibr">Muthén and</ref><ref type="bibr">Asparouhov (2012b, 2013)</ref> and introduced in more detail below:</p><p>(4) Approximate MI, a Bayesian solution allowing for some wiggle room for the intercept differences between groups, where the wiggle room is determined by the degree of precision of the prior.</p><p>Metaphorically speaking, in testing for MI one has to choose between Scylla and Charybdis, two mythical Greek sea monsters<ref type="foot" target="#foot_0">foot_0</ref> .</p><p>In the current paper we apply this metaphor to the procedure of testing for MI. On the one hand, there is the six-headed sea monster Scylla, who metaphorically represents imposing full MI on the model with as a result that the model fit indices indicate a bad fit to the data. On the other hand, however, we could fall victim to Charybdis if we release the constraints. By not imposing MI, our model will fit the data, but it will be impossible to compare groups. This paper illustrates the third option, using approximate MI, which could turn out to be the way to escape both threats. Consider a CFA model with two groups, see Figure <ref type="figure">1</ref>. Suppose the difference between the intercepts of item 1 is 0.10. Now, we impose MI on this model, by constraining the two intercepts to be equal. As a result, the difference between both will be exactly zero, that is, we are imposing a difference of zero on the parameter estimates for the intercepts. In Figure <ref type="figure">2</ref> the likelihood function (which is a function of the distribution of the data) is shown for the difference between both intercepts, which is denoted by δ. In this case there is a small difference in the intercepts between both groups. When applying MI, the difference is forced to be zero (δ = 0). By doing this, we have established MI and we are allowed to compare the latent factor means between the two groups. However, the estimated intercepts no longer resembles their unconstrained counterparts. Stated differently, δ is forced to be zero, whereas in the data δ &gt; 0. The discrepancy between δ in our model and δ in the data will probably result in poor model fit. A bad model fit means we have to reject our model and cannot interpret our model parameters.</p><p>Meanwhile, on the other side of the narrow channel between Italy and Sicily, Charybdis lurks, forced to live in a cave beneath the sea causing whirlpools. If we would analyze our hypothetical model without any constraints on the intercepts the model will fit the data. As a consequence, however, we are lost in the whirlpools caused by the furious Charybdis, because we can no longer compare the latent means due to different intercepts across the groups.</p><p>There we are, trapped between Scylla and Charybdis, and are forced to choose between either a model with MI and a terrible fit to the data, or a well-fitting model that we cannot use for comparing the latent means across groups. However, just like Odysseus, we believe we can pass in safety through the narrow channel. One passage may be provided by imposing partial MI allowing for one or two differences. Partial MI seems attractive when relatively large differences (δ &gt;&gt; 0) exist for one or only a few items. However, when differences are small and occur for multiple items in a factor analysis, partial MI is not able to provide a safe passage and approximate MI offers an attractive alternative. With approximate MI, instead of forcing intercepts to be exactly equal across groups, see Figure <ref type="figure">2</ref>, a substantive prior distribution is used to bring the parameters close to one another while allowing for some wiggle room. Such a model falls in between full and no MI, which could mean that we can still compare the means (as MI holds approximately) while the model also fits well, allowing an escape from Scylla and Charybdis. But how does this work?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USING BAYESIAN PRIORS ON INTERCEPT DIFFERENCES</head><p>To estimate a model with approximate MI we need Bayesian statistics, which has been discussed in many papers and textbooks (see, among others, <ref type="bibr" target="#b9">Kruschke et al., 2012;</ref><ref type="bibr">Van de Schoot et al., 2013)</ref>. There are three essential ingredients underlying Bayesian statistics. The first ingredient is prior distributions which represent background knowledge about the parameters of a model; for example that the difference between two intercepts is close to zero. Second, there is the likelihood function of the data containing the information about the parameters from the data. Thirdly, both prior and likelihood are summarized by the socalled posterior distribution, which is a compromise of the prior knowledge and the likelihood function. Stated otherwise, the posterior distribution contains one's updated knowledge balancing prior knowledge with observed data.</p><p>The crucial ingredient of Bayesian statistics is the specification of the prior distribution. In Figure <ref type="figure" target="#fig_1">3</ref>, four different priors are specified and combined with the likelihood function of the difference between two intercepts which is denoted by δ. When combining prior and likelihood, the posterior difference score is obtained, denoted by δ . Figure <ref type="figure" target="#fig_1">3A</ref> displays a flat uninformative prior for the difference between the two intercepts. Because such a prior does not contain any information, the posterior estimate for the difference will not be influenced and the results are similar to a model without MI, that is δ = δ . If, for example, a normal prior distribution is used, see Figure <ref type="figure" target="#fig_1">3B</ref>, the posterior estimate for the difference, δ , will be slightly pulled toward the mean of the prior, in this case zero. If we decrease the prior variance, see Figure <ref type="figure" target="#fig_1">3C</ref>, the posterior difference comes closer to zero. If the prior variance is very small, the posterior difference will approximate zero, δ ∼ 0, and we establish approximate MI allowing for some wiggle room. To get back to our metaphor: if a small difference between the intercepts is allowed, we can escape Charybdis because the difference between intercepts is smaller than in the unconstrained model, Figure <ref type="figure" target="#fig_1">3A</ref>. We also escape Scylla, because a model with some wiggle room is less restrictive than full MI and will therefore, still fit the data acceptably well, Figure <ref type="figure">2</ref>. In conclusion, approximate MI finds a compromise between zero and no constraints, through which both model fit and latent mean comparison can be established.</p><p>Approximate MI is expected to be especially useful when there are many small deviations from strict MI <ref type="bibr" target="#b6">(De Boeck, 2008;</ref><ref type="bibr" target="#b16">Muthén and Asparouhov, 2013)</ref>. In the current paper we focus on studying the differences between strict, partial and approximate MI in a set of populations. In the current paper we assume that the main goal of applying MI is to compare latent means and, therefore, focus on the potential bias in the latent mean comparison when different degrees of MI are applied. There are two indicators to keep in mind: (1) model fit and (2) a small enough difference between either factor loadings or intercepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EMPIRICAL ILLUSTRATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>The empirical illustration looks at the experiences of psychologists (group 1) and psychiatrists (group 2) with a new policy in Dutch mental healthcare: Diagnosis Related Groups (DRGs; <ref type="bibr" target="#b27">Tummers et al., 2012)</ref>. Diagnosis Related Groups were introduced in January 2008 and were part of a process to convert the Dutch healthcare system into one based on a regulated market. The DRG policy differs significantly from the prior method in which each medical action resulted in a financial claim, a socalled fee-for-service system. Before 2008, the number of sessions a professional had with a patient related directly to the amount of money claimed from the health insurer. According to some standpoints, this could lead to inefficiencies <ref type="bibr">(Busse et al., 2011)</ref>. The DRG policy changed the situation by stipulating a standard rate for each disorder. For instance, for a mild depression, the mental healthcare professional gets a standard rate for treating the patient (direct and indirect time) between 250-800 min.</p><p>Psychologists and psychiatrists had to implement these DRGs, and we will investigate their willingness to do so. This is important, as many of them opposed the DRG policy, set up websites agitating against it, or even in a few cases quit their jobs <ref type="bibr" target="#b20">(Palm et al., 2008)</ref>. The following quote of a healthcare professional [cited in <ref type="bibr" target="#b28">Tummers (2012)</ref>: 516], illustrates their point of view:</p><p>"We experience the DRG policy as a disaster. I concentrate as much as possible on treating my own patients, in order to derive some satisfaction from my work." Furthermore, psychiatrists were far more resistant than psychologists. One of the reasons was that especially psychiatrists considered the DRGs as a threat to their autonomy <ref type="bibr" target="#b24">(Smullen, 2013)</ref>. It is important to analyze the difference between the two groups, in order to provide guidance to policy makers in their attempts to adapt the policy and increase the satisfaction of professional health workers. We would expect minor violations of MI given that the both groups of professionals were expected to be quite negative about the specific policy and also have slightly different attributes to the concepts used in the questionnaires because of their professional training and working environment (see for instance <ref type="bibr" target="#b20">Palm et al., 2008;</ref><ref type="bibr" target="#b18">Neukrug, 2011;</ref><ref type="bibr" target="#b24">Smullen, 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHODS</head><p>The sampling frame consisted of 5199 professionals, all members of the two main nationwide mental healthcare associations: the Dutch Association of Psychologists (NIP) and the Netherlands Association for Psychiatry (NVvP), who would, in principle, all of them be required to work with the DRG policy. Using an email and two reminders, 1307 questionnaires were returned; a response rate of 25% with 1074 valid cases for the specific scale we used. Despite the select sample the demographical composition of the respondent group was representative for the Dutch population of mental healthcare professionals <ref type="bibr" target="#b20">(Palm et al., 2008)</ref>.</p><p>Willingness to implement the DRG policy was measured using a validated four-item scale developed by <ref type="bibr" target="#b8">Metselaar (1997)</ref>, which is based on the notion of "intention to act" in the theory of planned behavior <ref type="bibr" target="#b1">(Ajzen, 1991)</ref>. The items use five-point Likertscale response categories (strongly disagree, disagree, neutral, agree, and strongly agree). The items use templates in which one can specify the change being assessed, for example, the item "I intend to make time to implement the change" was changed into "I intend to make time to implement the DRG-policy." All item descriptions, its means, variances, and correlations are included in Table <ref type="table" target="#tab_0">1</ref> and the data and all syntax files are available on the website of the first author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head><p>If we want to compare psychologists and psychiatrists on the willingness to implement DRGs, we could simply compare the mean scores based on the four items. It appeared that, using a T-test in SPSS, psychiatrists (M = 2.23; SD = 0.81; n = 504) indeed scored significantly lower compared to psychologists (M = 2.46; SD = 0.76; n = 570; M dif = 0.23; t = 4.83; p &lt; 0.001). However, by using the mean score we assume that each item reflects the underlying construct in the same way and, even more importantly, that there is no measurement bias <ref type="bibr" target="#b26">(Steinmetz, 2013)</ref>. To accommodate these unwanted side-effects we conducted a series of confirmatory factor analyses (CFA) using the software Mplus v7 <ref type="bibr">(Muthén and</ref><ref type="bibr" target="#b16">Muthén, 1998-2012)</ref>. The data and all syntax files are available as supplementary materials.</p><p>In the first model, a 2-group configural model, because of the (slightly) non-normal distributed items estimated with ML estimator with robust standard errors (i.e., MLR), we allowed the factor loadings and intercepts to vary across groups resulted in a well-fitting model (χ 2 = 12.982; df = 4; p = 0.011; RMSEA = 0.065; CFI = 0.992; TLI = 0.976) with standardized factor loadings ranging between 0.56-0.87. We tested for MI using the new option in Mplus v7.11 ANALYSIS: MODEL = CONFIGURAL METRIC SCALAR.</p><p>A model forcing scalar MI, i.e., factor loadings and intercepts were constrained across groups, appeared to fit the data well (χ 2 = 32.032; df = 10; p &lt; 0.001; RMSEA = 0.064; CFI = 0.980; TLI = 0.976), but not better compared to the configural model ( χ 2 = 19.479; df = 6; p = 0.003). Also the metric model, where only the factor loadings were held equal across groups, fitted the data (χ 2 = 18.605; df = 7; p = 0.009; RMSEA = 0.056; CFI = 0.990; TLI = 0.982) and not any worse compared to the configural model ( χ 2 = 5.019; df = 3; p = 0.170). We also ran a comparison between the scalar and metric model and it appeared that the scalar model fits the data worse compared to the metric model ( χ 2 = 13.988; df = 3; p = 0.003). According to most fit indices (e.g., χ 2 not significantly worse than the configural model, but significantly better than the scalar model) the best model appeared to be the metric model where the factor loadings are constrained while the intercepts are allowed to differ across groups.</p><p>A solution offered by, for example <ref type="bibr" target="#b2">Byrne et al. (1989;</ref><ref type="bibr"></ref> see also <ref type="bibr" target="#b25">Steenkamp and Baumgartner, 1998)</ref>, is to apply partial MI. To establish partial invariance, one studies the size of the unconstrained loadings and/or intercepts, and constrains all loadings and intercepts except for the one loading/intercept with the largest unstandardized difference, which is released. It appeared that psychiatrists have lower intercepts than the psychologists, with the differences being 0.193, 0.235, 0.167, and 0.324, respectively. We applied partial MI, that is, constraining the intercepts of items 1 and 3 while releasing the constraints on intercepts 2 and 4 (χ 2 = 20.271; df = 8; p = 0.009; RMSEA = 0.053; CFI = 0.989; TLI = 0.983). Using the procedure described on the website of Mplus to compute MLR chi-square difference testing, it appeared that the partial model did not result in a better fit compared to the metric model ( χ 2 = 1.502; df = 1; p = 0.203), but better compared to the scalar model ( χ 2 = 12.313; df = 2; p = 0.002).</p><p>We re-analyzed the two models, constrained and unconstrained intercepts, using the ML and Bayesian estimator using the default prior settings [i.e., normal prior distributions for the intercepts and factor loadings with a prior mean of zero and a prior variance of 10 10 , and an inverse gamma distribution for the (residual) variance terms with hyperparameters -1 and zero], but with a stricter cut-off value for convergence to reduce any bias caused by precision [i.e., Chains = 8, Bconvergence = 0.01 and Biterations( <ref type="formula">20000</ref>)]. Table <ref type="table" target="#tab_1">2</ref> shows the results for the intercepts, the difference between the intercepts, and the Bayesian model fit information. These  results show that a model with strict MI assumed does not fit the data. This is shown by the fact that (1) the posterior predictive p-value is significant, and (2) the 95% CI of the replicated Chi Square values does not include zero. Hence, the model without MI does fit the data, but we are not allowed to compare the latent means between psychiatrists and psychologist.</p><p>The new option is to use approximate MI. Using Bayesian statistics parameters can be restricted by specifying a prior distribution. We would like the difference between the intercepts to approximate zero, but to allow for some wiggle room (prior variance) to maintain a fitting model. That is, the difference in an intercept between the two groups is allowed to exist, but is restricted to be very small, which is established by specifying a specific prior distribution of that difference. We used the new DIFF option available in Mplus v7 within the MODEL PRIOR part of the syntax where subjective priors can be specified. The full syntax is shown in the Appendix A, but the most important part is:</p><formula xml:id="formula_0">MODEL:[Veran1-Veran4] (nu#_1 -nu#_4); MODEL PRIOR: DO(1,4) DIFF(nu1_#-nu2_#)~N(0,0.50);</formula><p>where (nu#_1 -nu#_4) defines labels for the four intercepts. Because we used #,the labels are automatically specified for both groups separately. The DO(1,4) option is a loop statement telling Mplus to apply the function which comes after the DO statement for items 1 through 4: #=1 to #=4. The DIFF statement refers to the difference between the first intercept of the psychiatrists, for example nu1_1, and the same intercept for psychologists, for example nu1_2. Because we used the DO option this is automatically repeated for all four intercepts. Furthermore, ~N(0, 0.50) indicates the intercept differences between groups to be normally distributed (N) with mean 0 and prior variance of 0.5 for all pairs of items. Note that we parametrized the model by forcing both latent means to zero and the variance to one.</p><p>The results for this specific model are shown in Table <ref type="table" target="#tab_1">2</ref> in the column labeled Model C. We varied the prior variance by using σ 2 = 0.05 (Model D), σ 2 = 0.01 (Model E), σ 2 = 0.005 (Model F), and σ 2 = 0.0005 (Model G).In Model C, with a large prior variance, the difference between intercepts appeared not to be smaller compared to the unconstrained Model B. In Model D, however, the influence of the prior specification can be observed: the difference between intercepts becomes smaller. In Model E the intercepts are even closer, in Model F they are very close and in Model G they are almost similar. However, the latter two models do not fit the data very well; i.e., the 95% CI for the difference between the observed and the replicated χ 2 does not include zero and the ppp-value (i.e., posterior predictive pvalue) is &lt; 0.01. In sum, allowing for a prior variance of 0.01 between the intercepts, as is the case in Model E, resulted in an acceptable model fit. Also, the confidence interval of χ 2 does include zero. However, the posterior predictive p-value is significant, and preferably should be closer to 0.50. A larger reduction, which would be a model closer to scalar invariance, did not fit the data.</p><p>To summarize, we have established MI using the newly available approximate MI method. Now, we can finally conclude that psychiatrists score significantly lower on the willingness to implement DRGs than psychologists. The mean difference equals 0.21 (p &lt; 0.001), which would indeed be somewhat different had we used full MI (M dif = 0.19) or an unconstrained model (M dif = 0.14).</p><p>However, little is known about the bias of parameters as a result of approximate MI. Therefore, in the next section we will conduct a simulation study to find out if we are truly allowed to interpret the mean difference of the latent mean between groups if we apply approximate MI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SIMULATION STUDY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHOD</head><p>To investigate the possible bias in the comparison of latent means as a result of applying the approximate MI model we performed a simulation study. Seven populations were specified from which we obtained 1000 datasets each. The difference in intercepts between both groups varied across these seven populations, see Table <ref type="table" target="#tab_2">3</ref>. All other parameters were kept constant across populations; see Appendix B for the syntax and model specifications. Most importantly, the mean of the latent variable in group 1 was set to 0 and in group 2 to 0.5. Both latent factors were specified to have a population variance of 1. All items are standardized Population 7 -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 making the latent mean difference between the two groups of 0.5 a medium effect size <ref type="bibr" target="#b5">(Cohen, 1992)</ref>. The sample size per group was specified as being 500.</p><p>The seven populations described in Table <ref type="table" target="#tab_2">3</ref> were confronted with a set of models:</p><p>-Model 1: scalar MI is applied to the intercepts and factor loadings. Results were obtained with ESTIMATOR = ML and with ESTIMATOR = BAYES. For the latter we used BCONVERGENCE = 0.01, BITERATIONS = (5000), and the default priors [i.e., normal prior distributions for the intercepts and factor loadings with a prior mean of zero and a prior variance of 10 10 , and an inverse gamma distribution for the (residual) variance terms with hyperparameters -1 and zero]. -Model 2: partial MI is applied to those intercepts that are not similar in the population. For population 1 no partial MI can be applied, since all intercepts are similar in the population, for populations 2-4 partial MI is applied to the intercepts of items 3 and 4, and for populations 5-7 partial MI is applied to all intercepts. Note that the factor loadings are held equal across groups. Results were obtained with ESTIMATOR = ML and with ESTIMATOR = BAYES. For the latter, we used BCONVERGENCE = 0.01, BITERATIONS = (5000), and the default priors. -Model 3: approximate MI is applied only to the intercepts.</p><p>We varied the prior variance: σ 2 = 0.5 (Model 3a), σ 2 = 0.05 (Model 3b), σ 2 = 0.01 (Model 3c), and σ 2 = 0.005 (Model 3d). For all other parameters we used the default prior settings. -Model 4: partial approximate MI, where wiggle room is applied only to those intercepts that are not equal in the population; populations 2-4. We varied the amount of prior variance: σ 2 = 0.5 (Model 4a), σ 2 = 0.05 (Model 4b), σ 2 = 0.01 (Model 4c), and σ 2 = 0.005 (Model 4d).</p><p>The simulated differences in intercepts may cause an alignment issue, i.e., a biased estimate of the latent mean difference across groups, which will be discussed in more details in the next section.</p><p>Because researchers usually wish to compare latent means across groups, we focus on whether or not the estimated difference in latent means is biased. We focused on four outcome criteria that might indicate the degree to which the mean difference is biased:</p><p>(1) the empricial standard deviation of the 1000 estimated mean differences, which should be &lt;0.10. (2) the relative mean bias defined as ((M -0.5)/0.5) * 100, where M is the average mean obtained from the simulation study.</p><p>We used a cut-off value of &lt;10% as a criterion, as suggested by Hoogland and Boomsma (1998) for "reasonable" accuracy.</p><p>(3) The proportion of replications with a ppp-value smaller than pre-specified cut-off values. 95% coverage of the population value and its 95% significance.</p><p>Note that, concerning (3), the ppp-value, which defined as the proportion of chi-square values obtained in the simulated data that exceed that of the actual data and ppp-values around 0.50 indicate a well-fitting model.</p><p>To determine whether the simulation results resemble a good model fit, the proportion of replications where the critical value of 0.05 is exceeded should be close to 0.05, as p-values are expected to be uniformly distributed. The 95% coverage is defined as the percentage of replications for which the 95% CI included the population value of M = 0.5. The significance criterion was defined as the percentage of datasets for which the 95% CI did not include zero, i.e., the percentage of datasets for which we would have concluded that M is larger than zero in the population, which it was for all populations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head><p>Table <ref type="table" target="#tab_3">4</ref> provides the results for Model 1 and 2 with ML and Bayesian estimation, Table <ref type="table" target="#tab_4">5</ref> provides the results for Models 3a-3d and Table <ref type="table" target="#tab_5">6</ref> provides the results for Models 4a-4d. We will first discuss the results row wise, i.e., per model, followed by a column wise comparison, i.e., per population.</p><p>When full MI (Model 1) is applied to populations where there are differences on the intercepts between the groups (Pop. 2-7) there is a bias in the latent factor means, which does not occur when applied to a population with no differences (Pop. 1). The only exception is Population 5 with many small intercept differences. However, the coverage is smaller than 95% in this case. When partial MI (Model 2) is applied to populations with intercept differences between all intercepts (Pop. 5-7) there is a large bias, which does not occur when applied to populations with only 2 intercepts having differences between the groups (Pop. 2-4) or without any intercept differences (Pop. 1). Applying approximate MI to all intercepts (Model 3) leads to no bias when applied to a population with no differences (Pop. 1), or a population with small differences (Pop. 5). It does lead to a bias in the other populations with moderate or large intercept differences no matter which prior variance was used <ref type="bibr">(Pop. 2,</ref><ref type="bibr">4,</ref><ref type="bibr">6,</ref><ref type="bibr">7)</ref>. Applying approximate MI to only those intercepts that are different in the population (Model 4 applied to Pop. 2 and 3) leads to a bias, where the magnitude of the bias is dependent on the prior variance specified.</p><p>In population 1, with no intercept differences, the bias is smallest for the Model with strict MI, but the coverage is higher for the models with approximate MI and a high precision of the prior (Models 3c and 3d). In the population with 2 small differences, approximate MI with a high precision of the prior (Models 3c and 3d) modestly outperforms strict and partial MI in terms of bias and coverage. For the populations with moderate and large differences, and invariance on either 2 or 4 items, partial MI is clearly the best model. Also, for the model with many small differences, approximate MI with a high precision of the prior (Models 3c and 3d) just outperforms strict MI and clearly outperforms partial MI. The models with a low precision of the prior were never unbiased.</p><p>As pointed out by one of the reviewers, comparing Table <ref type="table" target="#tab_2">3</ref> and Table <ref type="table" target="#tab_3">4</ref> on Population 5, partial MI using both ML and Bayes gave smaller relative bias, smaller standard errors, and more accurate 95% coverage than model 3c and model 3d. Indeed, the coverage of model 3c and 3d is too high because in an ideal situation the 95% confidence interval should cover the true parameter value in exactly 95% of the times. The coverage of almost 100% is probably caused by the standard error in model 3c to be overestimated, which can result in the reduction of statistical power. In conclusion, approximate MI should not be applied when full MI holds in the population. If large differences exist in the population on only a few intercepts, partial MI outperforms approximate MI, but partial approximate MI with a large prior variance can also be used. If moderate or small differences exist in the population on only a few intercepts, partial approximate MI is preferred. If small differences exist in the population on many intercepts, approximate MI outperforms applying full MI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESOLVING THE ALIGNMENT ISSUE</head><p>In the previous section we have seen that some of the parameter values, in our case the difference between the latent means, that generated the data are not recovered due to the alignment problem, which reflects an indeterminacy in the CFA. Applying approximate invariance using the DIFF statement tends to pull the deviating parameter toward the average of the parameters across all groups. As a result the deviating parameter will be underestimated and the invariant parameters overestimated, see also the simulation results in <ref type="bibr" target="#b0">Asparouhov and Muthén (2013)</ref>.</p><p>With biased intercepts the latent factor means will be biased as well and this is what we call the alignment issue <ref type="bibr" target="#b0">(Asparouhov and Muthén, 2013;</ref><ref type="bibr">in preparation)</ref>. If one would use plain BSEM the results of the CFA model might be biased in the estimates of the latent mean difference scores, especially when the precision of the DIFF prior is low (i.e., large prior variance), which is undesirable. There are two options to deal with the alignment issues:</p><p>(1) Freeing the parameters found not invariant (as in <ref type="bibr" target="#b0">Asparouhov and Muthén, 2013)</ref>, or (2) using the alignment methods available in Mplus v7.1. In the current paper we will focus on the second option, for a comparison of both methods see Asparouhov and Muthén (in preparation for the special issue). In Mplus v7.1 the alignment-method handles the issue of alignment through rotation. The rotation for the alignmentmethod uses the same principles as for EFA <ref type="bibr" target="#b7">(Jennrich, 2006)</ref> and is described in more details in <ref type="bibr" target="#b0">Asparouhov and Muthén (2013)</ref>.</p><p>As stated in the version 7.1 Mplus language addendum <ref type="bibr">(Muthén and Muthén, 2013, p.</ref> 2): "the alignment optimization method consists of three steps:</p><p>(1) Analysis of a configural model with the same number of factors and same pattern of zero factor loadings in all groups.</p><p>(2) Alignment optimization of the measurement parameters, factor loadings and intercepts/thresholds according to a simplicity criterion that favors few non-invariant measurement parameters.</p><p>(3) Adjustment of the factor means and variances in line with the optimal alignment."</p><p>The third step in this procedure is expected to decrease the bias in the latent variable means as we discussed above. We included the syntax ANALYSIS: ALIGNMENT = FIXED (BSEM); where FIXED enforces the first latent mean to be zero and the second latent mean to be estimated. When FREE would have been specified all latent means would have been estimated, which is only recommended if more than two groups are specified <ref type="bibr">(Asparouhov and Muthén, 2013. p. 16)</ref>. Furthermore, BSEM refers to the combination of the alignment-method with the DIFF statements.</p><p>To explore the performance of the BSEM-alignment method we ran additional models on population 5 where groups exhibit small differences on the intercepts of all four items (see Table <ref type="table" target="#tab_2">3</ref>).</p><p>Recall that the bias for this population when applying plain BSEM was 7.36% (SE = 0.1353) with the DIFF statement imposed upon all intercepts, but where the factor loadings were constrained across groups (denoted by Model 5a). When population 5 was confronted with a model that imposed plain-BSEM with the DIFF statement on both intercepts and factor loadings (Model 5b) we encountered a bias of 3.62% (SE = 0.1279). When the ALIGNMENT = FIXED(BSEM) command was added on top of DIFF statements (Model 5c) the bias appeared to be 4.28% with a lower SE of 0.1174. Thus, in this situation the alignment method leads to less bias. Note that these findings are all conditional on normal priors for the DIFF statements with a prior variance of 0.01.</p><p>Since prior variance turned out to influence bias and SE's in previous runs we ran Model 5b and Model 5c with prior variances of 0.5 and 0.05 in the DIFF statements. Model 5b with a prior variance of 0.05 yielded a bias of -1.35% (SE = 0.2039) and Model 5c yielded a bias of 4.02% (SE = 0.1413). Just as with a prior variance of 0.01, if the ALIGNMENT command is added to the DIFF commands, the standard error decreased. When the prior variance of the DIFF statements is increased to 0.5 Model 5b yielded a bias of -43.46% (SE = 0.4035), whereas Model 5c with the alignment method performed much better in terms of relative bias and SE : -1.34% and a SE of 0.1413.</p><p>Similar findings were obtained for a population with large differences on all intercepts across groups (Population 7). For this population the bias and SE's were even higher: 399% (SE = 0.2011), 391% (SE = 0.1940) and 394% (SE = 0.3057) for Models 5a, 5b, and 5c with prior variances of 0.01, respectively. It appeared the alignment method, just like plain BSEM, does not resolve the incurred bias when group intercept differences are moderate or high, especially if many items are affected. Since we only used four items in our simulation design more research is needed to investigate whether it is the magnitude of the non-invariance or the number of items affected.</p><p>Finally, we ran simulations with models 5a, 5b and 5c for the populations where only two of the items in the population were dissimilar (Populations 1-3, see Table <ref type="table" target="#tab_2">3</ref>), again with a prior variance of 0.01 for the DIFF priors. The results were comparable with the results discussed above (results not shown but these can be requested from the first author). With the ALIGNMENT command we obtained slightly smaller SEs with only small differences in the population compared to approximate MI without the ALIGNMENT command. However, with moderate or large intercept differences between groups the bias and SE for all models were once more too high.</p><p>Taken together, DIFF statements imposed upon parameters without the support of an ALIGNMENT command (i.e., plain BSEM) introduced slightly higher standard errors compared to DIFF statements that are combined with the ALIGNMENT command.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>If a researcher wants to compare latent means across groups or over time one has four options:</p><p>(1) Impose (full or) scalar MI. When a full MI structure results in approporiate model fit any difference in latent means respresents true, unbiased difference between groups/timepoints. (2) Impose partial MI, where one studies the size of the differences between unconstrained loadings and/or intercepts, and constrains all loadings and intercepts except for the one loading/intercept with the largest difference, which is released.</p><p>If the fit statistics are satisfied, any difference in the latent means is indicative of true mean differences. Sumscores, however, are biased due to the items where differences in the intercepts/factor loadings are allowed <ref type="bibr" target="#b26">(Steinmetz, 2013)</ref>. (3) Impose no MI, leading to the conclusion that the latent means cannot be used for comparing groups because any difference in the latent means can be caused by many differences.</p><p>With Muthén and Asparouhov's introduction of approximate <ref type="bibr">MI (2012a;</ref><ref type="bibr" target="#b15">2012b;</ref><ref type="bibr">2013)</ref>, a fourth option for testing MI became available.</p><p>(4a) Approximate MI salvages MI in the case of seemingly ignorable (i.e., near zero) differences between parameters.</p><p>Or when combined with partial MI:</p><p>(4b) Partial approximate MI, which is a hybrid form of partial MI and approximate MI.</p><p>The results of our paper have shown that applying approximate MI might provide a safe passage through the narrow channel between Italy and Sicily in order to facilitate the escape from the mythical sea monsters Scylla and Charybdis, just as Odysseus was able to. The whirlpools caused by Charybdis, who dislikes comparing latent mean scores if the factor loadings/intercepts are dissimilar across groups, can be avoided. The reason is that with approximate MI, parameters are restricted to be closer to each other than with partial MI. The use of Bayesian statistics on the difference in parameters introduces a posterior distribution, which tries to find a compromise between the ideal situation (difference = zero) and the situation we find in the data. The willingness to compromise between ideology and reality has the following effect: the posterior difference in parameters across groups is close enough to its ideal zero to allow latent mean comparisons, yet close enough to the reality of the data to result in acceptable model fit. As was noted by one of the reviewers, a crucial distinction between partial invariance factor models and the Bayesian approach involving priors is that the former typically is coupled with a substantive interpretation of the group differences in the parameters of interest. Although substantive considerations may certainly help inform the nature of group differences, there is always a risk of ad hoc reasoning in applications. The Bayesian approach may do more justice to the unexpected and possibly inexplicable failures of invariance. In a related vein, partial measurement models have often been criticized for lacking specificity in the sense that large modification indices of certain items/indicators may actually reflect failures of invariance of other items/indicators (see e.g., <ref type="bibr" target="#b22">Reise et al., 1993)</ref>. Likewise it is possible to avoid Scylla, who will devour badly fitting models resulting from forcing scalar MI on a model where differences do exist. Both our empirical example and the simulation study have taught us that there seems to be an optimum specification of the prior variance. The alignment method provides promising results for decreasing the influence of the prior specifications, but more research is warranted.</p><p>We recommend the following procedure if the test for full MI fails. First, determine which parameters are different between groups, for example by using modification indices or by using the DIFFERENCE OUTPUT which is obtained when the DIFF statement is used in Mplus. The latter output provides each parameter with a significance test for its deviance with its constrained counterpart. Do not impose MI when there are large parameter differences across groups, or impose approximate MI when you are able to locate just a few deviating parameters. If there are (many) small differences we recommend to apply full approximate MI. Use the ALIGNMENT method when you don't want to use small prior variances in the DIFF statements. We acknowledge the issue of defining "small differences." With "small" we imply that parameters of substantive interest do not change in a meaningful way if MI does not fully hold (cf. <ref type="bibr" target="#b19">Oberski, 2013)</ref>. We note that the choice of the priors is extremely important and since the field of approximate MI is rather unexplored we advise always do sensitivity analyses and never just "choose" a prior value. One aspect influencing the definition of a "small difference" is that the prior are sensible for a given data set, and hence, that the choice of the prior variance does have huge implications on the parameter estimates. In particular, because the difference in intercepts is a function of the scaling of the observed variable, as was noted by one of the reviewers, it may be helpful to relate the variances of the normal priors to the scaling (or variability) of the observed variables. For example, for a prior with hyperparameters N (0, 0.01) indicates there is a (subjective belief of) 95% chance that the absolute intercept difference is equal or smaller than 0.01 [i.e., sqrt(0.01) = 0.1].</p><p>Since the field of approximate MI is relatively new we propose the following research agenda. First, there are two variables influencing the performance of MI: (1) the number of items with differences on the factor loading or intercepts and (2) the size of the difference itself. What we do not know is what the exact cut-off values are for these decisions (number of items and magnitude of differences). This topic needs further attention, given that it can help researchers make informed choices about applying partial or approximate MI without having to test them both. Second, more simulation studies have to be performed to find out which prior specification in which model is to be advised, since the optimum prior specification is model and data dependent. Third, the bias in substantive results if the incorrect type of MI is used should be investigated in more detail. Fourth, more research is needed to study the effects of the alignment method. Fifth, misspecification of the baseline model should be further investigated. A fifth area for further exploration is the comparison of the approximate MI procedure with alternative approaches, for example the commonly used delta-goodness-of-fit-indexes (i.e., GFI; <ref type="bibr" target="#b4">Cheung and Rensvold, 2002;</ref><ref type="bibr" target="#b3">Chen, 2007)</ref>. And finally, in our simulation study we used a relative large sample size in relation to the degrees of freedom. It should be investigated which sample sizes vis-à-vis model DFs are needed for the Bayesian analysis to work properly. It is expected that the Bayesian test for MI can deal with smaller sample sizes compared to the ML counterparts, as was also the case for regular SEM models, see <ref type="bibr" target="#b10">Lee and Song (2004)</ref> and <ref type="bibr">Van de Schoot et al. (submitted)</ref>.</p><p>It should be noted that approximate MI might be an interesting alternative approach for testing MI, but it does not replace the original MI test which is based on, for example chi-square difference testing. Approximate MI, as introduced in our paper provides a first step in this challenging and promising new area of testing and exploring MI if the chi-square test, or any other test, rejects the invariance model. Also, our paper provides a warning not to use approximate MI in all situations where MI is tested, but this warning message also applies to strict MI and partial MI.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE</head><label></label><figDesc>FIGURE 1 | A hypothetical model.</figDesc><graphic coords="3,96.44,67.86,141.84,118.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 3 |</head><label>3</label><figDesc>FIGURE 3 | Four different prior distributions to demonstrate the influence of the prior on the posterior parameter estimates. (A) Uninformative prior; (B) Wide normal prior; (C) Narrow normal prior; (D) Highly peaked prior.</figDesc><graphic coords="4,62.36,67.55,467.52,302.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 | Correlation matrix for Psychologists (n = 570) and Psychiatrists (n = 504) with the means (variances) on the diagonal.</head><label>1</label><figDesc></figDesc><table><row><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 | The results for the intercepts of the latent variable Willingness to Implement DRGs.</head><label>2</label><figDesc></figDesc><table><row><cell>Model G</cell><cell>Approximate MI</cell><cell>σ 2 = 0.0005</cell><cell>ν (SE ) 95% CI</cell><cell>1.935 1.885-</cell><cell>(0.027) 1.990</cell><cell>2.545 2.483-</cell><cell>(0.033) 2.610</cell><cell>2.269 2.212-</cell><cell>(0.029) 2.723</cell><cell>2.660 2.596-</cell><cell>(0.032) 2.723</cell><cell>1.925 1.873-</cell><cell>(0.027) 1.978</cell><cell>2.533 2.468-</cell><cell>(0.034) 2.600</cell><cell>2.275 2.217-</cell><cell>(0.030) 2.336</cell><cell>2.629 2.566-</cell><cell>(0.033) 2.695</cell><cell>0.010</cell><cell>0.012</cell><cell>-0.006</cell><cell>0.031</cell><cell>18.248-60.600</cell><cell></cell><cell>0.000</cell></row><row><cell>Model F</cell><cell>Approximate MI</cell><cell>σ 2 = 0.005</cell><cell>ν (SE ) 95% CI</cell><cell>1.961 1.904-</cell><cell>(0.030) 2.021</cell><cell>2.577 2.506-</cell><cell>(0.037) 2.649</cell><cell>2.286 2.224-</cell><cell>(0.032) 2.349</cell><cell>2.716 2.642-</cell><cell>(0.036) 2.783</cell><cell>1.896 1.836-</cell><cell>(0.032) 1.961</cell><cell>2.496 2.420-</cell><cell>(0.040) 2.578</cell><cell>2.257 2.188-</cell><cell>(0.036) 2.329</cell><cell>2.564 2.489-</cell><cell>(0.039) 2.643</cell><cell>0.065</cell><cell>0.081</cell><cell>0.029</cell><cell>0.152</cell><cell>3.573-48.979</cell><cell></cell><cell>0.012</cell></row><row><cell>Model E</cell><cell>Approximate MI</cell><cell>σ 2 = 0.01</cell><cell>ν (SE ) 95% CI</cell><cell>1.979 1.957-</cell><cell>(0.034) 2.090</cell><cell>2.597 2.569-</cell><cell>(0.041) 2.729</cell><cell>2.305 2.285-</cell><cell>(0.035) 2.424</cell><cell>2.739 2.704-</cell><cell>(0.040) 2.859</cell><cell>1.881 1.917-</cell><cell>(0.062) 2.162</cell><cell>2.477 2.503-</cell><cell>(0.066) 2.765</cell><cell>2.241 2.287-</cell><cell>(0.069) 2.562</cell><cell>2.539 2.549-</cell><cell>(0.058) 2.777</cell><cell>0.098</cell><cell>0.120</cell><cell>0.064</cell><cell>0.200</cell><cell>-5.543-39.921</cell><cell></cell><cell>0.031</cell></row><row><cell>Model D</cell><cell>Approximate MI</cell><cell>σ 2 = 0.05</cell><cell>ν (SE ) 95% CI</cell><cell>2.006 1.943-</cell><cell>(0.034) 2.072</cell><cell>2.631 2.550-</cell><cell>(0.041) 2.712</cell><cell>2.334 2.264-</cell><cell>(0.036) 2.402</cell><cell>2.775 2.697-</cell><cell>(0.040) 2.851</cell><cell>1.847 1.771-</cell><cell>(0.037) 1.919</cell><cell>2.434 2.346-</cell><cell>(0.046) 2.526</cell><cell>2.204 2.124-</cell><cell>(0.041) 2.285</cell><cell>2.492 2.404-</cell><cell>(0.045) 2.581</cell><cell>0.159</cell><cell>0.197</cell><cell>0.130</cell><cell>0.283</cell><cell>-4.369-38.364</cell><cell></cell><cell>0.062</cell></row><row><cell>Model C</cell><cell>Approximate MI</cell><cell>σ 2 = 0.50</cell><cell>ν (SE ) 95% CI</cell><cell>2.020 1.954-</cell><cell>(0.034) 2.088</cell><cell>2.647 2.565-</cell><cell>(0.042) 2.731</cell><cell>2.349 2.278-</cell><cell>(0.037) 2.420</cell><cell>2.792 2.713-</cell><cell>(0.041) 2.868</cell><cell>1.831 1.758-</cell><cell>(0.038) 1.905</cell><cell>2.415 2.323-</cell><cell>(0.048) 2.509</cell><cell>2.186 2.103-</cell><cell>(0.043) 2.269</cell><cell>2.472 2.382-</cell><cell>(0.046) 2.563</cell><cell>0.189</cell><cell>0.232</cell><cell>0.163</cell><cell>0.320</cell><cell>-5.516-40.199</cell><cell></cell><cell>0.057</cell></row><row><cell>Model B</cell><cell>No constraints</cell><cell>on the intercepts</cell><cell>ν (SE ) 95% CI</cell><cell>2.022 1.955-</cell><cell>(0.035) 2.091</cell><cell>2.650 2.569-</cell><cell>(0.042) 2.733</cell><cell>2.352 2.281-</cell><cell>(0.036) 2.425</cell><cell>2.795 2.713-</cell><cell>(0.041) 2.876</cell><cell>1.830 1.757-</cell><cell>(0.039) 1.908</cell><cell>2.413 2.323-</cell><cell>(0.048) 2.508</cell><cell>2.185 2.103-</cell><cell>(0.043) 2.270</cell><cell>2.472 2.383-</cell><cell>(0.046) 2.562</cell><cell>0.192</cell><cell>0.237</cell><cell>0.167</cell><cell>0.323</cell><cell>-4.164 34.566</cell><cell></cell><cell>0.067</cell></row><row><cell>Model A</cell><cell>Measurement</cell><cell>invariance</cell><cell>ν (SE ) 95% CI</cell><cell>2.022 1.961-</cell><cell>(0.032) 2.085</cell><cell>2.634 2.563-</cell><cell>(0.037) 2.709</cell><cell>2.372 2.308-</cell><cell>(0.034) 2.440</cell><cell>2.724 2.657</cell><cell>(0.035) (2.792)</cell><cell>2.022 1.961-</cell><cell>(0.032) 2.085</cell><cell>2.634 2.563-</cell><cell>(0.037) 2.709</cell><cell>2.372 2.308-</cell><cell>(0.034) 2.440</cell><cell>2.724 2.657</cell><cell>(0.035) (2.792)</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>5.128 44.154</cell><cell></cell><cell>0.008</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Item 1</cell><cell></cell><cell>Item 2</cell><cell></cell><cell>Item 3</cell><cell></cell><cell>Item 4</cell><cell></cell><cell>Item 1</cell><cell></cell><cell>Item 2</cell><cell></cell><cell>Item 3</cell><cell></cell><cell>Item 4</cell><cell></cell><cell>Item 1</cell><cell>Item 2</cell><cell>Item 3</cell><cell>Item 4</cell><cell>95% CI for the</cell><cell>difference</cell><cell>between the</cell><cell>observed and</cell><cell>the replicated</cell><cell>χ 2</cell><cell>Posterior</cell><cell>predictive</cell><cell>p-value</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>=</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>=</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Intercepts group</cell><cell>psychologists</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Intercepts group</cell><cell>psychiatrists</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Difference in</cell><cell>intercept</cell><cell></cell><cell></cell><cell>Model fit</cell><cell></cell></row></table><note><p>Frontiers in Psychology | Quantitative Psychology and Measurement October 2013 | Volume 4 | Article 770 | 6</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 | Population values for the intercepts.</head><label>3</label><figDesc></figDesc><table><row><cell>Intercepts</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 | Simulation results for Model 1 and 2. Model</head><label>4</label><figDesc></figDesc><table><row><cell>Population 7:</cell><cell>4 items</cell><cell>with large</cell><cell>differences</cell><cell>ML Bayes</cell><cell>2.6222 2.6619</cell><cell>(0.1679) (0.1837)</cell><cell>100% 100%</cell><cell>424.44 432.38</cell><cell></cell><cell>0% 0%</cell><cell>100% 100%</cell><cell></cell><cell>2.0493 1.9829</cell><cell>(0.148) (0.123)</cell><cell>100% 100%</cell><cell>309.86 296.58</cell><cell>0% 0%</cell><cell>100% 100%</cell></row><row><cell>Population 6:</cell><cell>4 items</cell><cell>with moderate</cell><cell>differences</cell><cell>ML Bayes</cell><cell>0.8786 0.8768</cell><cell>(0.0995) (0.1086)</cell><cell>100% 100%</cell><cell>75.72 75.72</cell><cell></cell><cell>2.2% 1.5%</cell><cell>100% 100%</cell><cell></cell><cell>0.7904 0.8079</cell><cell>(0.103) (0.104)</cell><cell>100% 100%</cell><cell>58.08 61.58</cell><cell>17.3% 13.9%</cell><cell>100% 100%</cell></row><row><cell>Population 5:</cell><cell>4 items</cell><cell>with small</cell><cell>differences</cell><cell>ML Bayes</cell><cell>0.5362 0.5341</cell><cell>(0.0923) (0.0989)</cell><cell>100% 100%</cell><cell>7.24 6.82</cell><cell></cell><cell>93.9% 91.2%</cell><cell>100% 100%</cell><cell></cell><cell>0.5298 0.5169</cell><cell>(0.0984) (0.0992)</cell><cell>100% 100%</cell><cell>5.96 3.38</cell><cell>94.6% 94.4%</cell><cell>100% 100%</cell></row><row><cell>Population 4:</cell><cell>2 items</cell><cell>with large</cell><cell>differences</cell><cell>ML Bayes</cell><cell>2.3699 2.3366</cell><cell>(0.2192) (0.2224)</cell><cell>100% 100%</cell><cell>373.98 367.32</cell><cell></cell><cell>0% 0%</cell><cell>100% 100%</cell><cell></cell><cell>0.4990 0.4863</cell><cell>(0.0979) (0.0988)</cell><cell>100% 100%</cell><cell>-0.2 -2.74</cell><cell>94.8% 94.3%</cell><cell>99.9% 99.9%</cell></row><row><cell>Population 3:</cell><cell>2 items</cell><cell>with moderate</cell><cell>differences</cell><cell>ML Bayes</cell><cell>0.6501 0.6488</cell><cell>(0.0976) (0.1061)</cell><cell>100% 100%</cell><cell>30.02 29.76</cell><cell></cell><cell>65.3% 56.9%</cell><cell>100% 100%</cell><cell></cell><cell>0.4990 0.4863</cell><cell>(0.0979) (0.0988)</cell><cell>100% 100%</cell><cell>-0.2 -2.74</cell><cell>94.8% 94.3%</cell><cell>99.9% 99.9%</cell></row><row><cell>Population 2:</cell><cell>2 items</cell><cell>with small</cell><cell>differences</cell><cell>ML Bayes</cell><cell>0.5117 0.5097</cell><cell>(0.0920) (0.0985)</cell><cell>100% 100%</cell><cell>2.34 1.94</cell><cell></cell><cell>96.1% 94%</cell><cell>100% 100%</cell><cell></cell><cell>0.4990 0.4863</cell><cell>(0.0979) (0.0988)</cell><cell>100% 100%</cell><cell>-0.2 -2.74</cell><cell>94.8% 94.3%</cell><cell>99.9% 99.9%</cell></row><row><cell>Population 1:</cell><cell>No differences</cell><cell></cell><cell></cell><cell>ML Bayes</cell><cell>0.4995 0.4976</cell><cell>(0.0917) (0.0980)</cell><cell>100% 100%</cell><cell>-0.1 -0.48</cell><cell></cell><cell>95.9% 95.1%</cell><cell>100% 100%</cell><cell></cell><cell>0.4990 0.4863</cell><cell>(0.0979) (0.0988)</cell><cell>100% 100%</cell><cell>-0.2 -2.74</cell><cell>94.8% 94.3%</cell><cell>99.9% 99.9%</cell></row><row><cell>Outcome</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Estimated M</cell><cell>and SE</cell><cell>Convergence</cell><cell>Relative bias</cell><cell>M%</cell><cell>95% coverage</cell><cell>95%</cell><cell>significance</cell><cell>Estimated M</cell><cell>and SE</cell><cell>Convergence</cell><cell>Relative bias</cell><cell>M%</cell><cell>95% coverage</cell><cell>95%</cell><cell>significance</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>#1 Full</cell><cell>measurement</cell><cell>invariance</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>#2 Partial</cell><cell>measurement</cell><cell>invariance</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 | Simulation results for Model 3. Model Outcome Population 1: Population 2: Population 3: Population 4: Population 5: Population 6: Population 7:</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="2">No differences 2 items</cell><cell>2 items</cell><cell>2 items</cell><cell>4 items</cell><cell>4 items</cell><cell>4 items</cell></row><row><cell></cell><cell></cell><cell></cell><cell>with small</cell><cell cols="2">with moderate with large</cell><cell>with small</cell><cell cols="2">with moderate with large</cell></row><row><cell></cell><cell></cell><cell></cell><cell>differences</cell><cell>differences</cell><cell>differences</cell><cell>differences</cell><cell>differences</cell><cell>differences</cell></row><row><cell>#3a N∼(0, 0.5)</cell><cell>Estimated M</cell><cell>0.0404</cell><cell>0.8537</cell><cell>0.6417</cell><cell>1.1153</cell><cell>0.8779</cell><cell>0.9018</cell><cell>2.3347</cell></row><row><cell></cell><cell>and SE</cell><cell>(0.5161)</cell><cell>(0.5923)</cell><cell>(0.6627)</cell><cell>(0.7033)</cell><cell>(0.5924)</cell><cell>(0.6975)</cell><cell>(0.7101)</cell></row><row><cell></cell><cell>Convergence</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>99.4%</cell><cell>99.8%</cell></row><row><cell></cell><cell>Relative bias</cell><cell>-91.92</cell><cell>70.74</cell><cell>28.34</cell><cell>123.06</cell><cell>75.58</cell><cell>80.36</cell><cell>366.94</cell></row><row><cell></cell><cell>M(%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>95% coverage</cell><cell>92.9%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>0%</cell></row><row><cell></cell><cell cols="2">95% significance 0%</cell><cell>0.1%</cell><cell>0%</cell><cell>2.1%</cell><cell>0.1%</cell><cell>0%</cell><cell>100%</cell></row><row><cell cols="2">#3b N∼(0, 0.05) Estimated M</cell><cell>0.4143</cell><cell>0.5378</cell><cell>0.6125</cell><cell>1.1672</cell><cell>0.5622</cell><cell>0.8560</cell><cell>2.3644</cell></row><row><cell></cell><cell>and SE</cell><cell>(0.2294)</cell><cell>(0.2239)</cell><cell>(0.2393)</cell><cell>(0.2612)</cell><cell>(0.2240)</cell><cell>(0.2409)</cell><cell>(0.2709)</cell></row><row><cell></cell><cell>Convergence</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell></row><row><cell></cell><cell>Relative bias</cell><cell>-17.14</cell><cell>7.56</cell><cell>22.5</cell><cell>133.44</cell><cell>12.44</cell><cell>71.2</cell><cell>372.88</cell></row><row><cell></cell><cell>M(%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>95% coverage</cell><cell>100%</cell><cell>100%</cell><cell>99.9%</cell><cell>7.3%</cell><cell>99.9%</cell><cell>87.6%</cell><cell>0%</cell></row><row><cell></cell><cell cols="2">95% significance 45.9%</cell><cell>89.5%</cell><cell>97.1%</cell><cell>100%</cell><cell>94.2%</cell><cell>100%</cell><cell>100%</cell></row><row><cell cols="2">#3c N∼(0, 0.01) Estimated M</cell><cell>0.4554</cell><cell>0.5124</cell><cell>0.6167</cell><cell>1.6506</cell><cell>0.5368</cell><cell>0.8596</cell><cell>2.4984</cell></row><row><cell></cell><cell>and SE</cell><cell>(0.1246)</cell><cell>(0.1352)</cell><cell>(0.1320)</cell><cell>(0.2169)</cell><cell>(0.1353)</cell><cell>(0.1368)</cell><cell>(0.2011)</cell></row><row><cell></cell><cell>Convergence</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell></row><row><cell></cell><cell>Relative bias</cell><cell>-8.92</cell><cell>2.48</cell><cell>23.34</cell><cell>230.12</cell><cell>7.36</cell><cell>71.92</cell><cell>399.68</cell></row><row><cell></cell><cell>M(%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>95% coverage</cell><cell>98.2%</cell><cell>99.7%</cell><cell>94.7%</cell><cell>0%</cell><cell>99.7%</cell><cell>17.2%</cell><cell>0%</cell></row><row><cell></cell><cell cols="2">95% significance 99.4%</cell><cell>99.8%</cell><cell>100%</cell><cell>100%</cell><cell>99.9%</cell><cell>100%</cell><cell>100%</cell></row><row><cell cols="2">#3d N∼(0, 0.005) Estimated M</cell><cell>0.4671</cell><cell>0.5084</cell><cell>0.6218</cell><cell>1.9494</cell><cell>0.5328</cell><cell>0.8611</cell><cell>2.5453</cell></row><row><cell></cell><cell>and SE</cell><cell>(0.1072)</cell><cell>(0.1173)</cell><cell>(0.1122)</cell><cell>(0.2205)</cell><cell>(0.1175)</cell><cell>(0.1142)</cell><cell>(0.1900)</cell></row><row><cell></cell><cell>Convergence</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell></row><row><cell></cell><cell>Relative bias</cell><cell>-6.58</cell><cell>1.68</cell><cell>24.36</cell><cell>289.88</cell><cell>6.56</cell><cell>72.22</cell><cell>409.06</cell></row><row><cell></cell><cell>M(%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>95% coverage</cell><cell>97.3%</cell><cell>98.9%</cell><cell>86.9%</cell><cell>0%</cell><cell>98.6%</cell><cell>7.7%</cell><cell>0%</cell></row><row><cell></cell><cell cols="2">95% significance 99.8%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 | Simulation results for Model 4.</head><label>6</label><figDesc></figDesc><table><row><cell>Model</cell><cell>Outcome</cell><cell>Population 2:</cell><cell>Population 3:</cell><cell>Population 4:</cell></row><row><cell></cell><cell></cell><cell>2 items with</cell><cell>2 items with</cell><cell>2 items with</cell></row><row><cell></cell><cell></cell><cell>small differences</cell><cell>moderate differences</cell><cell>large differences</cell></row><row><cell>#4a (N∼(0, 0.5))</cell><cell>Estimated M and SE</cell><cell>0.4926 (0.0993)</cell><cell>0.4939 (0.0994)</cell><cell>0.4998 (0.1000)</cell></row><row><cell></cell><cell>Convergence</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell></row><row><cell></cell><cell>Relative bias M(%)</cell><cell>-1.48</cell><cell>-1.22</cell><cell>-0.04</cell></row><row><cell></cell><cell>95% coverage</cell><cell>95%</cell><cell>95%</cell><cell>95.5%</cell></row><row><cell></cell><cell>95% significance</cell><cell>99.9%</cell><cell>99.9%</cell><cell>99.9%</cell></row><row><cell>#4b (N∼(0, 0.05))</cell><cell>Estimated M and SE</cell><cell>0.4931 (0.0985)</cell><cell>0.5051 (0.0996)</cell><cell>0.5703 (0.1072)</cell></row><row><cell></cell><cell>Convergence</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell></row><row><cell></cell><cell>Relative bias M(%)</cell><cell>-1.38</cell><cell>1.02</cell><cell>14.09</cell></row><row><cell></cell><cell>95% coverage</cell><cell>95.7%</cell><cell>95.6%</cell><cell>90.9%</cell></row><row><cell></cell><cell>95% significance</cell><cell>99.9%</cell><cell>99.9%</cell><cell>100%</cell></row><row><cell>#4c (N∼(0, 0.01))</cell><cell>Estimated M and SE</cell><cell>0.4952 (0.0966)</cell><cell>0.5403 (0.0999)</cell><cell>1.4388 (0.2410)</cell></row><row><cell></cell><cell>Convergence</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell></row><row><cell></cell><cell>Relative bias M(%)</cell><cell>-0.96</cell><cell>8.06</cell><cell>187.76</cell></row><row><cell></cell><cell>95% coverage</cell><cell>96.4%</cell><cell>93.6%</cell><cell>3.6%</cell></row><row><cell></cell><cell>95% significance</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell></row><row><cell>#4d(N∼(0, 0.005))</cell><cell>Estimated M and SE</cell><cell>0.4971 (0.0954)</cell><cell>0.5656 (0.0999)</cell><cell>1.9635 (0.2390)</cell></row><row><cell></cell><cell>Convergence</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell></row><row><cell></cell><cell>Relative bias M(%)</cell><cell>-0.58</cell><cell>13.12</cell><cell>292.7</cell></row><row><cell></cell><cell>95% coverage</cell><cell>96.4%</cell><cell>91.4%</cell><cell>0%</cell></row><row><cell></cell><cell>95% significance</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The two monsters occur in an episode of the adventures of Odysseus; their location is believed to have been at the Strait of Messina between Sicily and the Italian mainland. Scylla, a six-headed sea monster, lived on one end of this strait, while on the other Charybdis resided, causing huge whirlpools. The two monsters were living so close to each other that they created an inescapable threat. Sailors who avoided Charybdis were doomed to meet Scylla and vice versa; it seemed almost impossible to pass the sea strait without being confronted with either of the two mythical monsters.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>www.frontiersin.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Frontiers in Psychology | Quantitative Psychology and Measurement</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>Frontiers in Psychology | Quantitative Psychology and Measurement October 2013 | Volume 4 | Article 770 | 10</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>Frontiers in Psychology | Quantitative Psychology and Measurement October 2013 | Volume 4 | Article 770 | 12</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>Frontiers in Psychology | Quantitative Psychology and Measurement October 2013 | Volume 4 | Article 770 | 14</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The first author was supported by a grant from the <rs type="funder">Netherlands</rs> organization for scientific research: <rs type="grantNumber">NWO-VENI-451-11-008</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CEmkGsM">
					<idno type="grant-number">NWO-VENI-451-11-008</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest Statement:</head><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B</head><p>The population input file for the population 3:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>POPULATION:</head><p>f1 by y1@.7 y2@.6 y3@.4 y4@.2; f1@1; [f1@0]; y1-y4@1; [y1@0]; [y2@0]; [y3@-.1]; [y4@-.1];</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MODEL POPULATION-g2:</head><p>f1 by y1@.7 y2@.6 y3@.4 y4@.2; f1@1; [f1@.5]; y1-y4@1; [y1@0]; [y2@0]; [y3@.1]; [y4@.1]</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multiple Group Factor Analysis Alignment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
		<ptr target="http://statmodel.com/examples/webnotes/webnote18.pdf" />
	</analytic>
	<monogr>
		<title level="s">Mplus Web Notes</title>
		<imprint>
			<biblScope unit="issue">18</biblScope>
			<date type="published" when="2013-05-30">2013. May 30, 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The theory of planned behavior</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ajzen</surname></persName>
		</author>
		<idno type="DOI">10.1016/0749-5978(91)90020-TBusse</idno>
	</analytic>
	<monogr>
		<title level="m">Diagnosis Related Groups in Europe. Moving Towards Transparency, Efficiency and Quality in Hospitals</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Geissler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Quentin</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Wiley</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Open University Press</publisher>
			<date type="published" when="1991">1991. 2011</date>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="179" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Testing for the equivalence of factor covariance and mean structures: the issue of partial measurement invariance</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Shavelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.105.3.456</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Bull</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="456" to="466" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sensitivity of goodness of fit indexes to lack of measurement invariance</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705510701301834</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equ. Modeling</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="464" to="504" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluating goodness-of-fit indexes for testing measurement invariance</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Rensvold</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15328007SEM0902_5</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equ. Modeling</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="233" to="255" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A power primer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.112.1.155</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Bull</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="155" to="159" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Random item IRT models</title>
		<author>
			<persName><forename type="first">P</forename><surname>De Boeck</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11336-008-9092</idno>
		<idno>doi: 10. 1177/0049124198026003003</idno>
	</analytic>
	<monogr>
		<title level="m">Robustness studies in covariance structure modeling: an overview and a meta-analysis</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hoogland</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Boomsma</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1998">2008. 1998</date>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="329" to="367" />
		</imprint>
	</monogr>
	<note>Psychometrika</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rotation to simple loadings using component loss function: the orthogonal case</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Jennrich</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11336-003-1136-B</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="173" to="191" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Assessing the Willingness to Change: Construction and Validation of the DINAMO. Doctoral dissertation</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Metselaar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<pubPlace>Free University of Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The time has come! Bayesian methods for data analysis in the organizational sciences</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Aguinis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Joo</surname></persName>
		</author>
		<idno type="DOI">10.1177/1094428112457829</idno>
	</analytic>
	<monogr>
		<title level="j">Organ. Res. Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="722" to="752" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Evaluation of the bayesian and maximum likelihood approaches in analyzing structural equation models with small sample sizes</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-Y</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15327906mbr3904_4</idno>
	</analytic>
	<monogr>
		<title level="j">Multivar. Behav. Res</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="653" to="686" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Item bias and item response theory</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Mellenbergh</surname></persName>
		</author>
		<idno type="DOI">10.1016/0883-0355</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Educ. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="90002" to="90005" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Millsap</surname></persName>
		</author>
		<title level="m">Statistical Approaches to Measurement Invariance. New Y ork</title>
		<meeting><address><addrLine>NY</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dealing with extreme response style in cross-cultural research: a restricted latent class factor analysis approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Morren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P T M</forename><surname>Gelissen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vermunt</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9531.2011.01238.x</idno>
	</analytic>
	<monogr>
		<title level="j">Sociol. Methodol</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="13" to="47" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<ptr target="http://mplus.fss.uu.nl/2012/09/12/.the-workshop-new-features-of-mplus" />
		<title level="m">New Features in Mplus v7 Lecture 3</title>
		<imprint>
			<date type="published" when="2012-11-06">2012. November 6, 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bayesian SEM: a more flexible representation of substantive theory</title>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0026802</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="313" to="335" />
			<date type="published" when="2012">2012b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BSEM Measurement Invariance Analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Muthén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Muthén</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mplus User&apos;s Guide. 7th Edn</title>
		<title level="s">Mplus Web Notes</title>
		<meeting><address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Muthén and Muthén</publisher>
			<date type="published" when="1998">2013. 1998-2012</date>
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
	<note>Available online at: www.statmodel</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Muthén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Muthén</surname></persName>
		</author>
		<title level="m">Version 7.1 Mplus Language Addendum. Available online at: www.statmodel.com</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The World of the Counselor: An Introduction to the Counseling Profession</title>
		<author>
			<persName><forename type="first">E</forename><surname>Neukrug</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Thomson Brooks/Cole</publisher>
			<pubPlace>Belmont, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Evaluating sensitivity of parameters of interest to measurement invariance in latent variable models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Oberski</surname></persName>
		</author>
		<idno type="DOI">10.1093/pan/mpt014</idno>
	</analytic>
	<monogr>
		<title level="j">Political Analysis</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">De GGz ontwricht: Een praktijkonderzoek naar de gevolgen van het nieuwe zorgstelsel in de geestelijke gezondheidszorg (Problems in mental health care: An applied research on the impact of the Health Insurance Law in mental health care)</title>
		<author>
			<persName><forename type="first">I</forename><surname>Palm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Leffers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Emons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Van Egmond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zeegers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>SP</publisher>
			<pubPlace>Den Haag</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Testing for metric invariance using structural equation models: Solving the standardization problem</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Rensvold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Research in Management</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Schriesheim</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Neider</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="21" to="50" />
			<date type="published" when="2001">2001</date>
			<pubPlace>Greenwich, CT</pubPlace>
		</imprint>
	</monogr>
	<note>Information Age</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Confirmatory factor analysis and item response theory: two approaches for exploring measurement invariance</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Widaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Pugh</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.114.3.552</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Bull</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="552" to="566" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Measurement invariance: review of practice and implications</title>
		<author>
			<persName><forename type="first">N</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kuljanin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.hrmr.2008.03.003</idno>
	</analytic>
	<monogr>
		<title level="j">Hum. Resour. Manage. Rev</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="210" to="222" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Institutionalizing professional conflicts through financial reforms: The case of DBC&apos;s in dutch mental healthcare</title>
		<author>
			<persName><forename type="first">A</forename><surname>Smullen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Professionals Under Pressure: The Reconfiguration of Professional Work in Changing Public</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Noordegraaf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Steijn</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Amsterdam University Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="92" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Assessing measurement invariance in cross national consumer research</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Steenkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Baumgartner</surname></persName>
		</author>
		<idno type="DOI">10.1086/209528</idno>
	</analytic>
	<monogr>
		<title level="j">J. Consum. Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="78" to="90" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Analyzing observed composite differences across groups. Is partial measurement invariance enough?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Steinmetz</surname></persName>
		</author>
		<idno type="DOI">10.1027/1614-2241/a000049</idno>
	</analytic>
	<monogr>
		<title level="j">Methodology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Explaining willingness of public professionals to implement public policies: content, context, and personality characteristics</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Tummers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Steijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J J M</forename><surname>Bekkers</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9299.2011.02016.x</idno>
	</analytic>
	<monogr>
		<title level="j">Public Adm</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="716" to="736" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Policy alienation public professionals: the construct and its measurement</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Tummers</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1540-6210.2011.02550.x</idno>
	</analytic>
	<monogr>
		<title level="j">Public Adm. Rev</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="516" to="525" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cytokine production by leukocytes of military personnel with depressive symptoms after deployment to a combat-zone: a prospective, longitudinal study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van Zuiden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Heijnen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Amarouchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vermetten</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0029142</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">29142</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Denissen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Asendorpf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Van Aken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A gentle introduction to bayesian analysis: applications to developmental research</title>
		<author>
			<persName><forename type="first">G</forename></persName>
		</author>
		<idno type="DOI">10.1111/cdev.12169</idno>
	</analytic>
	<monogr>
		<title level="j">Child Dev</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A checklist for testing measurement invariance</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lugtig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Eur</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title/>
		<idno type="DOI">10.1080/17405629.2012.686740</idno>
	</analytic>
	<monogr>
		<title level="j">J. Dev. Psychol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="486" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Toward a further understanding of and improvement in measurement invariance methods and procedures</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Vandenberg</surname></persName>
		</author>
		<idno type="DOI">10.1177/1094428102005002001</idno>
	</analytic>
	<monogr>
		<title level="j">Organ. Res. Methods</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="139" to="158" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A review and synthesis of the measurement invariance literature: suggestions, practices, and recommendations for organizational research</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Vandenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Lance</surname></persName>
		</author>
		<idno type="DOI">10.1177/109442810031002</idno>
	</analytic>
	<monogr>
		<title level="j">Organ. Res. Methods</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="4" to="70" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
