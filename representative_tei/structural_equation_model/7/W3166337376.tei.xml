<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Trek Separation in Linear Structural Equation Models</title>
				<funder ref="#_5z7tgsY">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-07-18">18 Jul 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Elina</forename><surname>Robeva</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of British Columbia † Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jean-Baptiste</forename><surname>Seby</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of British Columbia † Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Trek Separation in Linear Structural Equation Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-07-18">18 Jul 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2001.10426v2[math.ST]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graphical models</term>
					<term>Independent Component Analysis</term>
					<term>Trek Separation</term>
					<term>High-order cumulants MSC2020 Subject Classification: 62R01</term>
					<term>62H22</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Building on the theory of causal discovery from observational data, we study interactions between multiple (sets of) random variables in a linear structural equation model with non-Gaussian error terms. We give a correspondence between structure in the higher order cumulants and combinatorial structure in the causal graph. It has previously been shown that low rank of the covariance matrix corresponds to trek separation in the graph. Generalizing this criterion to multiple sets of vertices, we characterize when determinants of subtensors of the higher order cumulant tensors vanish. This criterion applies when hidden variables are present as well. For instance, it allows us to identify the presence of a hidden common cause of k of the observed variables.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Although randomized experiments are the most commonly used method for causal inference, they are sometimes not feasible for practical or ethical reasons. Because of these constraints, scientists often need to learn the structure of the graph underlying the relationships between variables based on purely observational data. Suppose that G = (V, D) is a directed acyclic graph (or DAG) with vertex set V = {1, ..., p} and edge set D ⊆ V × V . The graph G gives rise to a linear structural equation model (LSEM), which consists of joint distributions of a random vector X = (X 1 , . . . , X p ) in which the variable X i associated to vertex i ∈ V is a linear function of X j , where j varies over the parent set pa(i) of i (i.e., all vertices j ∈ V such that j → i ∈ D), and a noise term ε i ,</p><formula xml:id="formula_0">X i = j∈pa(i) λ ji X j + ε i , i ∈ V.<label>(1)</label></formula><p>If no hidden variables are present, we assume that the noise terms ε i are mutually independent. To encode the presence of hidden variables, we allow dependencies between the ε i variables, and graphically we depict this via multi-directed edges (see Figure <ref type="figure" target="#fig_0">1a</ref>). These encode a hidden common cause of a few of the observed variables. We represent this more complicated hidden structure via a mixed graph G = (V, D, H), where H is the set of multi-directed (hyper)edges (see <ref type="bibr">Section 4)</ref>. When the noise terms ε i are Gaussian, then so are the X i variables. In this setting, the linear structural equation model given by a graph G corresponds to the set of covariance matrices M (2) (G) of a Gaussian distribution consistent with the graph G <ref type="bibr" target="#b10">[11]</ref>. This is precisely the set of covariance matrices that possess a certain parametrization arising from the structure of G. Furthermore, bidirected edges suffice to parametrize the model M (2) (G) when hidden variables are present. For example, the mixed graphs G 1 and G 2 in the figure above give rise to the same model in Zariski closure M (2) (G 1 ) = M (2) (G 2 ), because the two models have the same parametrization (via the trek rule <ref type="bibr">[20]</ref>). When the variables are non-Gaussian, we can depict the model using covariances as well as higher-order moments/cumulants of the random vector X. We denote by M (k) (G) the set of cumulants of order k consistent with the graph G, and by M (≤k) (G) the set of cumulants of order i for 2 ≤ i ≤ k. These sets can also be parametrized using the graph (Definition 4), and provide a more refined description of the graph structure. For instance, the two graphs above give rise to different models M (≤3) (G 1 ) = M (≤3) (G 2 ).</p><p>A parametrization of the model, however, may not always be sufficient. Statistical problems like model selection, model equivalence, and constraint based statistical inference often require an implicit description of the model in terms of (polynomial) equations which can be read off from the graph G, e.g., via a combinatorial criterion.</p><p>When G is a DAG and the variables are Gaussian, the implicit description of the model M (2) (G) is given by the vanishing of specific subdeterminants of the covariance matrix which can be read off from the graph via d-separation and the more general trek-separation criteria <ref type="bibr">[20]</ref>. In fact, the trek-separation criterion helps describe the vanishing of all subdeterminants of the covariance matrix in any (not necessarily Gaussian) LSEM. It turns out that covariance information is only sufficient to identify the graph up to Markov equivalence. That is, if two graphs G and G give rise to the same contidional independence relations, then they produce the same sets of covariance matrices M (2) (G) = M (2) (G ) <ref type="bibr" target="#b15">[16]</ref>. Therefore, when the graph G is a DAG and the variables are Gaussian, we can only recover G up to Markov equivalence given observational data. Finding an implicit description of M (2) (G) in the presence of hidden variables is more challenging, although there has been promising recent progress. In particular, the authors of <ref type="bibr" target="#b25">[25]</ref> prove that the minimal generators for the vanishing ideal I(G) containing all the constraints for a Gaussian Acyclic Directed Mixed Graph G are in one-to-one correspondence with the pairs of non-adjacent vertices in the graph, and provide an algorithm to find all these generators. The paper <ref type="bibr" target="#b4">[5]</ref> points out that the generators of I(G) are given by nested determinants.</p><p>When the variables are non-Gaussian, the graph G can be recovered uniquely from observational data. In particular, <ref type="bibr" target="#b16">[17]</ref> use Independent Component Analysis (ICA) <ref type="bibr" target="#b2">[3]</ref> to estimate the graph structure via the Linear non-Gaussian Acyclic Model (LiNGAM). This framework and its derived versions DirectLiNGAM and PairwiseLiNGAM <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b17">18]</ref> make it possible to distinguish graphs within Markov equivalence classes. Furthermore, <ref type="bibr" target="#b22">[22]</ref> provide an algorithm that extends causal discovery of the causal structure in the highdimensional setting based on higher-order moments, under a maximum in-degree condition.</p><p>In this paper, we also work under the framework of a non-Gaussian LSEM. Building on the trek rule <ref type="bibr">[20]</ref>, we define the multi-trek rule (Proposition 7) which gives a polynomial parametrization of the higher-order moments/cumulants, and enables us to study LSEMs via their higher-order cumulant representation M (k) (G) from the perspective of algebraic statistics <ref type="bibr">[20]</ref> which has so far only been used for Gaussian and discrete graphical models. By analogy with the vanishing of subdeterminants in the covariance matrix, we give a necessary and sufficient combinatorial criterion, called multi-trek separation, for the vanishing of subdeterminants of the tensor C (k) of k-th order cumulants (Theorem 18), which extends to the hidden variable case (Theorem 32). Our multi-trek separation criterion, for example, enables us to identify the presence of a hidden common cause of multiple observed variables. The rest of the paper is organized as follows. In Section 2, we define linear structural equation models (LSEMs) and their cumulant tensors. In Section 3, we introduce the notion of a multi-trek and we state our main theorem for DAG models that establishes a combinatorial criterion for the vanishing of subdeterminants of the k th -order cumulant tensor. In Section 4 we consider the case of hidden variables. Graphically we encode the presence of such variables via multi-directed edges, and we show that our results generalize to this case. In Section 5, we conjecture that our multi-trek criterion is also equivalent to the vanishing of subdeterminants of higher-order moment (rather than cumulant) tensors. In section 6, we conclude and discuss directions for further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In this section we provide the necessary background on linear structural equation models, and their higherorder cumulants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Linear structural equation models</head><p>Let G = (V, D) be a directed acyclic graph (DAG) with finite vertex set V = {1, . . . , p} and edge set D ⊆ V × V . Here acyclic means that there are no directed cycles, i.e., no sequences of the form i 0 → i 1 → • • • → i s = i 0 , where i j → i j+1 ∈ D. The edge set is always assumed to be free of self-loops, so i → i ∈ D for all i ∈ V . For each vertex i, define its set of parents as pa(i) = {j ∈ V : j → i ∈ D}. The graph G induces a statistical model, called a linear structural equation model, for the joint distribution of a collection of random variables (X i , i ∈ V ), indexed by the graph's vertices. The model hypothesizes that each variable is a linear function of the parent variables and a noise term ε i :</p><formula xml:id="formula_1">X i = λ 0i + j∈pa(i) λ ji X j + ε i , i ∈ V.<label>(2)</label></formula><p>The ε i variables for i ∈ V , are independent and centered. The coefficients λ 0i and λ ji are unknown real parameters that are assumed to be such that the system (2) admits a unique solution X = (X i : i ∈ V ). Typically termed a system of structural equations, (2) specifies cause-effect relations whose straightforward interpretability explains the wide-spread use of the models <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b14">15]</ref>.</p><p>The random vector X that solves the system (2) may have an arbitrary mean depending on the choice of parameters λ 0i . Since the mean can easily be learned from data, and we are mainly concerned with learning the underlying graph structure, we disregard the offsets λ 0i , and the system (2) becomes</p><formula xml:id="formula_2">X = Λ T X + ε.<label>(3)</label></formula><p>Here Λ = (λ ij ) ∈ R D , and R D is the set of V × V matrices Λ with support D,</p><formula xml:id="formula_3">R D = {Λ ∈ R V ×V : λ ij = 0 if i → j / ∈ D}.</formula><p>Since G is acyclic, the matrix I -Λ is always invertible and the solution of the system (3) is: </p><formula xml:id="formula_4">X = (I -Λ) -T ε.<label>(4</label></formula><formula xml:id="formula_5">(-1) L-1 (L -1)! E   j∈A1 Z j   E   j∈A2 Z j   • • • E   j∈A L Z j   ,</formula><p>where the sum is taken over all partitions (A 1 , . . . , A L ) of the set {i 1 , . . . , i k }. If each of the variables Z i is centered, i.e., has mean 0, then we can restrict to summing over partitions for which each A i has size at least 2. For example, the first four cumulants are given as follows:</p><formula xml:id="formula_6">cum(Z i ) = E[Z i ] = 0, cum(Z i1 , Z i2 ) = E[Z i1 Z i2 ], cum(Z i1 , Z i2 , Z i3 ) = E[Z i1 Z i2 Z i3 ],</formula><p>and</p><formula xml:id="formula_7">cum(Z i1 , Z i2 , Z i3 , Z i4 ) = E[Z i1 Z i2 Z i3 Z i4 ] -E[Z i1 Z i2 ]E[Z i3 Z i4 ] -E[Z i1 Z i3 ]E[Z i2 Z i4 ] -E[Z i1 Z i4 ]E[Z i2 Z i3 ].</formula><p>Now, let k ≥ 2, and let E (k) and C (k) be the k-th order cumulant tensors of the random vectors ε and X, respectively. The linear structural equation model, and, particularly, the expression (4) yield the following relationship between C (k) and E (k) .</p><p>Lemma 1 ([4, <ref type="bibr">Chapter 5]</ref>). The tensor C (k) of k-th order cumulants of X equals</p><formula xml:id="formula_8">C (k) = E (k) • (I -Λ) -k ,<label>(5)</label></formula><p>where E (k) • (I -Λ) -k denotes the Tucker product of the order-k tensor E (k) and the matrix (I -Λ) -1 along each of its k dimensions. In other words,</p><formula xml:id="formula_9">E (k) • (I -Λ) -k i1,...,i k = j1,...,j k E (k) j1,...,j k ((I -Λ) -1 ) j1,i1 • • • ((I -Λ) -1 ) j k ,i k .</formula><p>When the entries of the noise vector ε are mutually independent, its cumulants E (k) are diagonal tensors.</p><p>Lemma 2 ([4, <ref type="bibr">Chapter 5]</ref>). If the variables Z 1 , . . . , Z p are independent, then the k-th order cumulant tensor of Z = (Z 1 , . . . , Z p ) is diagonal, i.e., the entry at position (i 1 , . . . , i k ) is 0 unless i 1 , . . . , i k are all equal.</p><p>Remark 3. (a) We originally considered the moments of X and ε, instead of their cumulants. Lemma 1 also applies to the factorization of the moments, however, the k-th moment tensors of ε for k ≥ 4 are no longer diagonal, i.e., Lemma 2 does not apply. We give further details of this study in Section 6. (b) Lemma 2 is the reason cumulants are widely used for Independent Component Analysis (ICA) <ref type="bibr" target="#b3">[4]</ref>. Indeed, finding the CP-decomposition <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref> of the cumulant tensor C (k) can recover the matrix (I -Λ) -1 . For an extended study of cumulants in ICA, we refer the reader to <ref type="bibr" target="#b3">[4]</ref>.</p><p>Lemmas 1 and 2 provide a means to parametrize the set of all cumulant tensors of the distributions in a given graphical model. Definition 4. Let G = (V, D) be a DAG, and let k ≥ 2 be an integer. The set</p><formula xml:id="formula_10">M (2) (G) = {(I -Λ) -T E (2) (I -Λ) -1 : Λ ∈ R D , E (2) 0 diagonal}</formula><p>consists of all covariance matrices of distributions in the graphical model given by G. For k ≥ 3, define</p><formula xml:id="formula_11">M (k) (G) = {E (k) • (I -Λ) -k : Λ ∈ R D , E (k) diagonal}</formula><p>to be the set of cumulants of order k consistent with the graph G. And finally, let</p><formula xml:id="formula_12">M (≤k) (G) = M (2) (G) × • • • × M (k) (G)</formula><p>be the set all cumulants up to order k of a distribution in the graphical model given by G.</p><p>When the error terms ε i are Gaussian, the random vector X also follows a Gaussian distribution and all of its cumulants of order k ≥ 3 equal 0. Therefore, the model equals M (2) (G). In this case, different DAGs G 1 and G 2 that lie in the same Markov equivalence class can give rise to the same models M (2) </p><formula xml:id="formula_13">(G 1 ) = M (2) (G 2 ).</formula><p>An implicit description of M (2) (G) is well-known when G is a DAG and is given by conditional independences <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref>. These correspond to d-separations in the graph G <ref type="bibr" target="#b13">[14]</ref>.</p><p>When the noise terms ε i are not Gaussian, the higher-order moments will not necessarily vanish, and we can obtain more information about the distribution from them. It turns out that M (≤k) (G) uniquely identifies the DAG G <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b22">22]</ref>. An implicit description of M (≤k) (G) is not known completely, although <ref type="bibr" target="#b22">[22]</ref> discover enough of the defining equations to identify the DAG G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Multi-trek separation for directed acyclic graphs</head><p>In this section we present our main result, a particular type of constraint on the model M (k) (G) that corresponds to a combinatorial criterion in the graph G. Given data, one can check whether the constraint holds for the sample cumulant tensors in order to obtain information about the structure of the unknown DAG G. Our result generalizes to the case of hidden variables as shown in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multi-treks and the multi-trek rule</head><p>We begin by generalizing the notion of a trek <ref type="bibr">[20]</ref>.</p><formula xml:id="formula_14">Definition 5. A k-trek in a DAG G between k nodes v 1 , . . . , v k is an ordered collection of k directed paths (P 1 , ..., P k )</formula><p>, where P i has sink v i , and P 1 , ..., P k have the same source vertex, called the top of the k-trek and denoted by top(P 1 , ..., P k ).</p><p>Note that a 2-trek is exactly the same as the usual notion of a trek <ref type="bibr">[20]</ref>. Example 6. In the directed acyclic graph from Figure <ref type="figure" target="#fig_2">3b</ref>,</p><formula xml:id="formula_15">v v 1 v 2 v 3 v 4 P 1 P 2 P 3 P 4 (a) (b)</formula><formula xml:id="formula_16">(2 → 6, 2 → 8</formula><p>) is a 2-trek between 6 and 8 with top 2;</p><p>(1 → 7, 1 → 6, 1 → 4 → 5) is a 3-trek between 7, 6, and 5 with top 1;</p><p>(1 → 7, 1 → 6, 1, 1 → 6) is a 4-trek between 7, 6, 1, and 6 with top 1.</p><p>Note that the paths P i can consist of a single vertex.</p><p>We now generalize the trek rule, which originates in the work of <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b24">24]</ref> and relies on the observation that (I -Λ)</p><formula xml:id="formula_17">-1 = I + Λ + Λ 2 + • • • .</formula><p>Since the graph G is acyclic, this formal sum is finite, and each of the entries of (I -Λ) -1 can be expressed as</p><formula xml:id="formula_18">(I -Λ) -1 ji = P ∈P(j,i) λ P<label>(6)</label></formula><p>where P(j, i) is the set of all directed paths from j to i, and λ P is the product of the coefficients λ uv along the edges u → v on a directed path P (e.g., if P is the path 1 → 2 → 4, then λ P is λ 12 λ 24 ). Note that, since we only consider acyclic graphs, for any i ∈ V , P(i, i) consists of the trivial path from i to i consisting of just the vertex i, and the monomial for this path is equal to 1.</p><p>Proposition 7 (The multi-trek rule). When the entries of the noise vector ε are independent, the entries of the k-th order cumulant tensor C (k) of X can be expressed as a sum over k-trek monomials,</p><formula xml:id="formula_19">C (k) i1,...,i k = (P1,...,P k )∈T (i1,...,i k ) E (k)</formula><p>top(P1,...,P k ),...,top(P1,...,P k ) λ P1 ... λ P k ,</p><p>where T (i 1 , ..., i k ) is the set of all k-treks between i 1 , ..., i k .</p><p>Proof. By Lemma 1, we can express the k-th cumulant tensor of X via the Tucker decomposition</p><formula xml:id="formula_21">C (k) = E (k) • (I -Λ) -k . Furthermore, by Lemma 2, the k-th cumulant tensor E (k) of ε is diagonal. Therefore, C (k) i1,...,i k = j1,...,j k E (k) j1,...,j k ((I -Λ) (-1) ) j1,i1 • • • ((I -Λ) (-1) ) j k ,i k = j E (k) j,...,j ((I -Λ) (-1) ) j,i1 • • • ((I -Λ) (-1) ) j,i k .</formula><p>Using equation ( <ref type="formula" target="#formula_18">6</ref>), we obtain</p><formula xml:id="formula_22">C (k) i1,...,i k = j E (k) j,...,j   P1∈P(j,i1) λ P1   • • •   P k ∈P(j,i k ) λ P k   ,</formula><p>which yields the result.</p><p>Example 8. Consider the DAG from Figure <ref type="figure" target="#fig_2">3b</ref>. According to the multi-trek rule, we have, for instance, the following relationships between the cumulants C (k) and E (k) of X and ε.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C</head><p>(2)</p><formula xml:id="formula_23">4,5 = E (2) 4,4 λ 45 + E (2)</formula><p>1,1 λ 2 14 λ 45 , C</p><p>5,6,7 = E</p><p>(3)</p><p>1,1,1 λ 14 λ 45 λ 16 λ 17 , C</p><p>5,6,8 = 0. These follow because there are two 2-treks between 4 and 5: (4, 4 → 5) and (1 → 4, 1 → 4 → 5). There is one 3-trek between 5, 6, and 7: (1 → 4 → 5, 1 → 6, 1 → 7). There are no 3-treks between 5, 6, and 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multi-trek systems and determinants of higher-order cumulants</head><p>We now generalize the multi-trek rule, giving an expression of the determinants of subtensors of C (k) in terms of multi-trek systems. We first recall the notion of a combinatorial hyperdeterminant <ref type="bibr" target="#b1">[2]</ref> of a tensor, which we simply refer to as determinant throughout the rest of the paper Definition 9. Let T be an order-k n × ... × n tensor. Then, its determinant is</p><formula xml:id="formula_26">det(T ) = σ2,...,σ k ∈S(n) sign(σ 2 ) • • • sign(σ k ) n i=1 T i,σ2(i),...,σ k (i) ,<label>(8)</label></formula><p>where S(n) is the set of permutations of the set {1, . . . , n}.</p><p>Next, we introduce the notion of a multi-trek system.</p><p>Definition 10. Given a collection of k sets of nodes S 1 , ..., S k ⊆ V such that #S 1 = ... = #S k = n, a k-trek system T is a collection of n k-treks between S 1 , ..., S k such that the ends of T on the i-th side equal S i . We define the top of this k-trek system, top(T ), to be the union of the tops of the k-treks. We allow repeated elements in top(T ). A k-trek system T has sided intersection if there exist two k-treks (P 1 , . . . , P k ) and (Q 1 , . . . , Q k ) in T and a number 1 ≤ i ≤ k so that the directed paths P i and Q i have a common vertex. We denote by T (S 1 , . . . , S k ) the set of k-trek systems between S 1 , . . . , S k that have no sided intersection.</p><p>Example 11. In Figure <ref type="figure">4</ref> below, the two 3-treks between S 1 , S 2 , S 3 (respectively in full and dashed line) form a 3-trek-system between S 1 , S 2 , S 3 . They have a sided intersection along the paths leading to the set S 1 .</p><p>Figure <ref type="figure">4</ref>: A tri-trek system with sided intersection.</p><p>Given a collection of k sets of nodes S 1 , ..., S k ⊆ V such that #S 1 = ... = #S k = n, and an ordering of the nodes in each set S i , a k-trek system T gives rise to a permutation of the nodes in each of S 2 , ..., S k (if we keep the ordering of S 1 fixed). More explicitly, the j-th k-trek in T connects the j-th vertex of S 1 with the σ i (j)-th vertex of S i for all i = 2, . . . , k, and σ 2 , . . . , σ k are the permutations induced by T . The sign of T is the product of the signs of those (k -1) permutations. The signs of the permutations are defined with respect to the ordering chosen initially.</p><p>Example 12. In Figure <ref type="figure">5 below</ref>,</p><formula xml:id="formula_27">S 1 = {v 1 , v 2 }, S 2 = {v 3 , v 4 }, S 3 = {v 5 , v 6 }. Assume that the initial ordering is (v 1 , v 2 ), (v 3 , v 4 ), (v 5 , v 6</formula><p>). The trek system in Figure <ref type="figure">5a</ref> has two 3-treks, one between v 1 , v 4 , v 5 and one between v 2 , v 3 , v 6 . Therefore, sign(T ) = (-1) × 1 = -1. The trek system in Figure <ref type="figure">5b</ref> has two 3-treks, one between v 1 , v 4 , v 6 and one between v 2 , v 3 , v 5 . Therefore, sign(T ) = (-1) × (-1) = +1. The determinant of the subtensor of k th order cumulants indexed by the sets S 1 , ..., S k can be expressed in terms of the trek systems involving S 1 , ..., S k .</p><formula xml:id="formula_28">Proposition 13. Let S 1 , . . . , S k ⊆ V be k sets of nodes such that #S 1 = ... = #S k = n. Then, det C (k) S1,...,S k = T ∈T (S1,...,S k ) sign(T) m T , ( * )</formula><p>where T (S 1 , . . . , S k ) is the set of k-trek systems between S 1 , . . . , S k , and m T is the trek-system monomial of the trek system T = {(P</p><p>1 , . . . , P</p><p>k ), . . . , (P</p><formula xml:id="formula_31">(n) 1 , . . . , P<label>(n)</label></formula><p>k )}, defined as</p><formula xml:id="formula_32">m T = n i=1 E (k) top((P (i) 1 ,...,P<label>(i)</label></formula><p>k )),...,top((P</p><formula xml:id="formula_33">(i) 1 ,...,P (i) k )) k j=1 λ P (i) j .</formula><p>In fact, the sum in ( * ) can be taken over treks T ∈ T (S 1 , . . . , S k ) without sided intersections, i.e., det</p><formula xml:id="formula_34">C (k) S1,...,S k = T ∈ T (S1,...,S k ) sign(T) m T .<label>(9)</label></formula><p>Proof of Proposition 13. From Propositon 7, we can write</p><formula xml:id="formula_35">C (k) i1,...,i k = T ∈T (i1,...,i k ) m T ,<label>(10)</label></formula><p>where m T is the k-trek monomial defined by m T = E In order to now prove the equation ( <ref type="formula" target="#formula_34">9</ref>)</p><formula xml:id="formula_36">det C (k) S1,...,S k = T ∈ T (S1,...,S k ) sign(T )m T ,</formula><p>we need to show that m T = 0 when T is a trek-system between S 1 , ..., S k with a sided intersection.</p><p>We first prove a tensor version of the Cauchy-Binet Theorem <ref type="bibr" target="#b0">[1]</ref> for the determinant of the product AB, where A is a tensor of order k and B is a matrix. The proof of Lemma 14 is presented in Appendix A. Recall that Lemma 1 gives the relationship between the k-th order cumulant tensors of the random vectors ε and X, C (k) = E (k) • (I -Λ) -k . We can apply the determinant operator to each side of this equation, using the tensor version of the Cauchy-Binet theorem proved above.</p><p>Lemma 15. Consider k subsets of vertices S 1 , ..., S k ⊂ V with #S 1 = ... = #S k . Then, the determinant of the subtensor of k th -order cumulants can be written as:</p><formula xml:id="formula_37">det C (k) S1,...,S k = R1,...,R k ⊆V, #Ri=#Si det E (k) R1,...,R k det (I -Λ) -1 R1,S1 ... det (I -Λ) -1 R k ,S k<label>(12)</label></formula><p>Proof. We apply the tensor version of the Cauchy-Binet Theorem stated in Proposition 14 k times to the Tucker product in equation ( <ref type="formula" target="#formula_8">5</ref>) and we obtain equation <ref type="bibr" target="#b11">(12)</ref>.</p><p>By Lemma 15, we have:</p><formula xml:id="formula_38">det C (k) S1,...,S k = R1,...,R k det E (k) R1,...,R k det(I -Λ) -1 R1,S1 ... det(I -Λ) -1 R k ,S k<label>(13)</label></formula><p>A nice tool to prove this is given by the Gessel-Viennot-Lindstrom Lemma. We use this Lemma is again in the proof of our main Theorem 18.</p><p>Lemma 16 <ref type="bibr">([8, 12]</ref>). Suppose G is a directed acyclic graph with vertex set [p] = {1, ..., p}. Let R and S be subsets of [p] with #R = #S = n. Then,</p><formula xml:id="formula_39">det (I -Λ) -1 R,S = P ∈N (R,S) (-1) P λ P ,</formula><p>where N (R, S) is the set of all collections of nonintersecting systems of n directed paths in G from R to S, and (-1) P is the sign of the induced permutation of elements from R to S. In particular, det</p><formula xml:id="formula_40">(I -Λ) -1 R,S</formula><p>is identically zero if and only if every system of n directed paths from R to S has two paths which share a vertex.</p><p>Thus, equation ( <ref type="formula" target="#formula_38">13</ref>) now yields det</p><formula xml:id="formula_41">C (k) S1,...,S k = R1,...,R k det E (k) R1,...,R k   P1∈N (R1,S1 (-1) P1 λ P1   • • •   P k ∈N (R k ,S k ) (-1) P k λ P k   . Since E (k) is diagonal, we have that det E (k) R1,...,R k is 0 unless R 1 = • • • = R k . Therefore, det C (k) S1,...,S k = R⊆V,#R=n det E (k) R,...,R   P1∈N (R,S1) (-1) P1 λ P1   • • •   P k ∈N (R,S k ) (-1) P k λ P k   = R⊆V,#R=n r∈R E (k) r,...,r   P1∈N (R,S1) (-1) P1 λ P1   • • •   P k ∈N (R,S k ) (-1) P k λ P k   ,</formula><p>which then yields the desired expression in <ref type="bibr" target="#b8">(9)</ref>.</p><p>Example 17. Consider, once again, the DAG from Figure <ref type="figure" target="#fig_2">3b</ref>. Then, we have that det C</p><p>(2) </p><formula xml:id="formula_42">46,78 = E (2) 1,1 E<label>(2</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Main result</head><p>Our main theorem shows that the non-existence of a trek system without sided intersection between k sets of vertices is equivalent to the vanishing of the corresponding subdeterminant of the k-th cumulant tensor C (k) .</p><p>Theorem 18. Let G = (V, D) be a DAG, and let S 1 , ..., S k be subsets of V with #S 1 = ... = #S k . Then, det C</p><p>(k) S1,...,S k = 0 for every C (k) from M (k) (G) if and only if every system of k-treks between S 1 , ..., S k has a sided intersection.</p><p>Before proving our main theorem, we need to introduce an additional intermediary result.</p><p>Lemma 19. Consider k subsets of vertices S 1 , ..., S k ⊆ V with #S 1 = ... = #S k = n. Then, det C (k) S1,...,S k is identically 0 (as a polynomial in the entries of E (k) and λ) if and only if for any set R ⊆ V such that #R = n, there exists i ∈ {1 . . . , k} with det (I -Λ) -1 R,Si = 0.</p><p>Proof. Let us suppose that det C (k) S1,...,S k is identically 0. From equation <ref type="bibr" target="#b11">(12)</ref> in Lemma 15, we have:</p><formula xml:id="formula_43">det C (k) S1,...,S k = R1,...,R k ⊆V, #Ri=#Si det E (k) R1,...,R k det(I -Λ) -1 R1,S1 • • • det(I -Λ) -1 R k ,S k ,</formula><p>where the sum runs over subsets R</p><formula xml:id="formula_44">1 , ..., R k of V of cardinality #R 1 = ... = R k = #S 1 = ... = #S k = n. However, since E (k) is a diagonal tensor, det E (k) R1,...,R k = 0 unless R 1 = R 2 = ... = R k = R. In this case, denoting det E (k) R1,...,R k = det E (k) R we get: det C (k) S1,...,S k = R⊆V det E (k) R det(I -Λ) -1 R,S1 • • • det(I -Λ) -1 R,S k<label>(14)</label></formula><p>Each monomial det E</p><p>R appears only once, therefore for any set R satisfying #R = #S 1 = ... = #S k = n, there exists i ∈ {1, . . . , k} such that det(I -Λ) -1 R,Si = 0, which proves the if-direction. Let us now suppose that for any set R satisfying #R = #S 1 = ... = #S k = n, there exists i ∈ {1, . . . , k} such that det(I -Λ) -1 R,Si = 0. Then from the expression (12), we conclude that det C (k) S1,...,S k = 0.</p><p>We now present the proof of Theorem 18 which relies mostly on the Gessel-Viennot-Lindstrom Lemma (Lemma 16) and Lemma 19.</p><p>Proof of Theorem 18. Let us first suppose that det C (k) S1,...,S k = 0 and let T be a k-trek system between S 1 , ..., S k .</p><p>• If all elements of the multiset top(T ) are distinct, then Lemma 19 implies that there exists an integer i ∈ [k] such that det(I -Λ) -1 top(T ),Si = 0. By Lemma 16, any path system from top(T ) to S i has a sided intersection, therefore T has a sided intersection.</p><p>• If top(T ) has repeated elements, then at least two k-treks in T intersect, namely at their top, hence T has a sided intersection.</p><p>Conversely, let's suppose that every k-trek system (T ) between S 1 , ..., S k has a sided intersection. Let's consider any set R ⊆ V that satisfies #R = #S 1 = ... = #S k .</p><p>• If R forms the top of a k-trek system that ends at S 1 , ..., S k , then there exists at least one integer i ∈ [k] such that there is a sided intersection in any path system between R and S i . By the Gessel-Viennot-Linstrom Lemma 16, det(I -Λ) -1 R,Si = 0, i.e., det(I -Λ) -1 R,S1 ... det(I -Λ) -1 R,S k = 0 and therefore det E</p><formula xml:id="formula_46">(k) R det(I -Λ) -1 R,S1 ... det(I -Λ) -1 R,S k = 0.</formula><p>• Alternatively, if R does not form the top of a k-trek system that ends at S 1 , ..., S k , then there is no k-path system from R to S 1 , ..., S k , i.e., there is no path system between R and at least one of S 1 , ..., S k . This implies that at least one of det (I -Λ) -1 R,Si = 0 and therefore det E</p><formula xml:id="formula_47">(k) R det(I -Λ) -1 R,S1 ... det(I - Λ) -1 R,S k = 0. Thus, det C (k) S1,...,S k = R⊆V det E (k) R det(I -Λ) -1 R,S1 • • • det(I -Λ) -1 R,S k = 0.</formula><p>Example 20. Theorem 18 enables us to determine whether random variables have a common cause. Consider the graphs in Figures <ref type="figure">6a</ref> and<ref type="figure">6b</ref> below. Let A = {1}, B = {2}, and C = {3}. In Figure <ref type="figure">6a</ref> there is one 3-trek joining A, B and C, thus, det(C</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABC ) = C</head><p>(3) 123 = 0. In Figure <ref type="figure">6b</ref> there is no 3-trek joining A, B, and C and, a fortiori, no 3-trek without sided intersection. Therefore, det(C</p><formula xml:id="formula_49">(3) ABC ) = 0.</formula><p>The seminal paper <ref type="bibr">[20]</ref> shows that the vanishing of determinants of the covariance matrix of X is equivalent to a 2-trek separation criterion in the graph G. In the rest of this section, we illustrate that a generalization of this criterion to the case k &gt; 2 only works in one direction.</p><p>Definition 21. The collection of sets (A 1 , ..., A k ) k-trek-separates S 1 , ..., S k if for every k-trek with paths (P 1 , ..., P k ) between S 1 , ..., S k , there exists j ∈ {1, ..., k} such that P j contains a vertex from A j . Example 22. In Figure <ref type="figure">7</ref>, the sets S 1 , S 2 and S 3 are 3-trek-separated by the sets A 1 , A 2 and A 3 .</p><p>Theorem 23 ([20, Theorem 2.8]). The submatrix Σ A,B has rank less than or equal to r for all covariance matrices consistent with the graph G if and only if there exist subsets</p><formula xml:id="formula_50">C A , C B ⊂ V with #C A + #C B ≤ r such that (C A , C B ) 2-trek-separates A from B. Consequently, rk(Σ A,B ) ≤ min{#C A + #C B : (C A , C B ) 2-trek-separates A from B}</formula><p>and equality holds for generic covariance matrices in the model M (2) (G).</p><p>In Corollary 24, we show that when k ≥ 3, k-trek-separation implies the vanishing of the corresponding cumulant tensor determinant (but not necessarily vice-versa).</p><p>Corollary 24. Consider k sets of vertices S 1 , ..., S k with #S 1 = ... = #S k = n. For all tensors C (k) of k th -order cumulants consistent with the graph G, the subtensor C (k) S1,...,S k has a null determinant if there exist subsets A 1 , ..., A k ⊂ V with #A 1 + ... + #A k &lt; n such that (A 1 , ..., A k ) k-trek separates S 1 , ..., S k .</p><p>Proof. Let us suppose that there exist A 1 , ..., A k such that #A 1 + ... + #A k &lt; n and (A 1 , ..., A k ) k-trekseparates S 1 , ..., S k . Consider a k-trek system T = (T 1 , . . . , T n ) between S 1 , . . . , S k . Then, for every i = 1, . . . , n, there exists m i such that the m i -th component of</p><formula xml:id="formula_51">T i intersects A mi . Since #A 1 + • • • + #A k &lt; n,</formula><p>by the Pigeon-Hole Principle, there exist i = j such that m = m i = m j , and the m-th components of T i and T j go through the same element s ∈ A m . Therefore, T has a sided intersection. Thus, every k-trek system between S 1 , . . . , S k has a sided intersection, and, therefore, by Theorem 18, det C (k) S1,...,S k = 0. Remark 25. When k ≥ 3, the reverse implication of Corollary 24 is not true, i.e., det (C (k) S1,...,S k ) = 0 does not imply that there exists (A 1 , ..., A k ) such that #A 1 + ... + #A k &lt; n and (A 1 , ..., A k ) k-trek-separates (S 1 , ..., S k ). Consider the graph in Figure <ref type="figure" target="#fig_8">8</ref> below. In this graph, #S 1 = #S 2 = #S 3 = 2. There is no system of two 3-treks between S 1 , S 2 , S 3 without sided intersection. However, it is not possible to find three sets</p><formula xml:id="formula_52">A 1 , A 2 , A 3 such that #A 1 + #A 2 + #A 3 &lt; 2 = #S i , i.e.</formula><p>, there is no such set that 3-trek-separates S 1 , S 2 , S 3 . Intuitively, this happens because "max flow" and "min cut" are no longer equal, while the reason the statement holds when k = 2 is precisely because of the min-cut max flow (Menger's) Theorem <ref type="bibr" target="#b12">[13]</ref>, which was used in the proof of the trek-separation theorem by <ref type="bibr">[20]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Hidden variables</head><p>We now consider the case where the structural equation model (3) involves some hidden (i.e., unobserved) variables. Alternatively, it is similar to think of the noise variables ε i as correlated. We represent such a case with a mixed graph G = (V, D, H), where V is the set of vertices, D ⊆ V × V is the set of directed edges, and H is the set of multidirected edges (see Definition 26 below), which signify the dependencies between the ε variables. We assume that G does not contain any cycle nor loop. Definition 26. A multidirected edge between nodes i 1 , ..., i k is the union of k directed edges with the same source and with sinks i 1 , ..., i k . The k-directed edges are merged at their source without an additional node. We call k the order of the multidirected edge. Remark 27. Note that this is a generalization of the notion of bidirected edges widely used in the literature.</p><p>As before, define E (k) to be the tensor of k-th order cumulants of the variables ε i . Since we do not assume the independence of the variables ε i , then any entry of the tensor E (k) may be non-zero. Specifically,</p><formula xml:id="formula_53">E (k) is a V × V × ... × V k</formula><p>tensor for which the entry w i1,...,i k is non-zero if there exists a multidirected edge between a 1 , ..., a l such that {i 1 , ..., i k } ⊆ {a 1 , ..., a l }. Note that some of the elements i 1 , . . . , i k could be equal.</p><p>We now define the notion of a k-trek in this setting.</p><p>Definition 28. A k-trek between vertices i 1 , ..., i k in a mixed graph G is composed of k directed paths (P 1 , . . . , P k ) where P s goes from j s to i s , and the tops j 1 , . . . , j k are connected in one of the following ways.</p><p>(a) Either the vertices j 1 , . . . , j k coincide to form the top of the trek; or (b) There exist an l-directed edge between a 1 , ..., a l such that {j 1 , ..., j k } ⊆ {a 1 , ..., a l }.</p><p>Example 29. In the mixed graph from Figure <ref type="figure" target="#fig_0">10a</ref>, (1 → 7, 1 → 6, 1 → 4 → 5) is a 3-trek between 7, 6 and 5. The tops of the paths going to the nodes 7, 6 and 5 coincide with node 1. In the mixed graph from Figure <ref type="figure" target="#fig_0">10b</ref>, (7, 6, 4 → 5) is a 3-trek between 7, 6 and 5. The tops of the paths are connected by a 3-directed edge between 4, 6, and 7. Definition 30. The linear structural equation model</p><formula xml:id="formula_54">X j = i∈pa(j) λ ij X i + ε j given by a mixed graph G = (V, D, H), where V = [p],</formula><p>is the family of distributions on R p with tensor of k th -order cumulants in the set:</p><formula xml:id="formula_55">M (k) (G) = {E (k) • (I -Λ) -k : Λ = (λ ij ) ∈ R D , E (k) ∈ (R ⊗k ) H }<label>(15)</label></formula><p>where (R ⊗k ) H denotes the set of p × • • • × p (k-times) cumulant tensors of ε, which are zero at all entries (i 1 , . . . , i k ) unless i 1 = • • • = i k or there exists a multi-directed edge (j 1 , . . . , j ) ∈ H such that {i 1 , . . . , i k } ⊆ {j 1 , . . . , j }.</p><p>Extending the k-trek rule, Proposition 7, to the hidden variable case, we show that every entry of the tensor C (k) can be expressed as a sum of k-trek monomials as well.</p><p>Corollary 31. For a noise vector ε whose entries are dependent, the entries of the k-th order cumulant tensor C (k) of X can be expressed as a sum over k-trek monomials,</p><formula xml:id="formula_56">C (k) i1,...,i k = (P1,...,P k )∈T (i1,...,i k ) E (k) top(P1),...,top(P k ) λ P1 ... λ P k , (<label>16</label></formula><formula xml:id="formula_57">)</formula><p>where T (i 1 , ..., i k ) is the set of all k-treks between i 1 , ..., i k .</p><p>Proof. By Lemma 1, we can express the k-th cumulant tensor of X via the Tucker decomposition</p><formula xml:id="formula_58">C (k) = E (k) • (I -Λ) -k . Therefore, C (k) i1,...,i k = j1,...,j k E (k) j1,...,j k ((I -Λ) (-1) ) j1,i1 • • • ((I -Λ) (-1) ) j k ,i k = j1,...,j k E (k) j1,...,j k ( P1∈P(j1,i1) λ P1 ) • • • ( P k ∈P(j k ,i k ) λ P1 ) = j<label>1</label></formula><p>,...,j k , P 1 ∈P(j 1 ,i 1 ),...,P k ∈P(j k ,i k )</p><formula xml:id="formula_59">E (k) j1,...,j k λ P1 • • • λ P k .</formula><p>Note that E (k) j1,...,j k is the cumulant of X j1 , . . . , X j k which is nonzero if and only if there exists a multidirected edge connecting (at least) j 1 , . . . , j k , which is exactly when j 1 , . . . , j k could be at the top of a k-trek. Therefore, C (k) i1,...,i k = (P1,...,P k )∈T (i1,...,i k ) E (k) top(P1),...,top(P k ) λ P1 ... λ P k .</p><p>In a similar fashion to the directed acyclic case, we obtain the following result.</p><p>Theorem 32. Consider a mixed graph G(V, D, H). Let S 1 , ..., S k be subsets of V with #S 1 = ... = #S k . Then, det C</p><p>(k) S1,...,S k = 0 if and only if every system of k-treks between S 1 , ..., S k has a sided intersection.</p><p>Proof. Theorem 32 extends Theorem 18 to the case of mixed graphs. We use a common argument in the graphical models literature that enables us to convert the multidirected case to the directed case. We replace every multidirected edge joining i 1 , ..., i k with a vertex v and a directed edge between v and each of the vertices i 1 , ..., i k . We call this graph G, also known as the canonical DAG associated to G. S1,...,S k is zero for all cumulant tensors C ∈ M (k) ( G). In other words, if there is no k-trek system without sided intersection between S 1 , ..., S k in G, then there is no k-trek system without sided intersection between S 1 , ..., S k in G, and vice-versa.</p><p>Proof. Let M (k) (G) and M (k) ( G) be the sets of k th -order cumulant tensors of G and G, respectively. We will prove that M (k) (G) and M (k) ( G) have the same Zariski closure, i.e., a polynomial equation vanishes on M (k) (G) if and only if it vanishes on M (k) ( G). Note that G has more vertices than G, so when comparing the Zariski closures of M (k) (G) and M (k) ( G), we implicitly assume that we are only considering cumulants between vertices in G, i.e., we are projecting the cumulants onto the vertices of G. To do this, let us show that the two parametrizations give the same family of tensors near the identity tensor. Note that there exist distributions of independent variables X 1 , ..., X p for which the k th -order cumulant is the identity tensor. As shown in Proposition 39, C (k) i1,...i k can be expressed as a sum of the trek monomials of all ktreks in T (i 1 , ..., i k ) between i 1 , ..., i k in G as C </p><formula xml:id="formula_60">E (k) i1,...,i k = E (k) v,...,v λ v,i1 ... λ v,i k<label>(17)</label></formula><p>if there is a multi-directed edge between i 1 , . . . , i k in G, i.e., there is a directed edge from the vertex v to each of the nodes i l , l ∈ {1, . . . , k} in G, and let</p><formula xml:id="formula_61">E (k) i,...,i = E (k) i,...,i + v∈H E (k) v,...,v λ k v,i<label>(18)</label></formula><p>for each i ∈ [p]. As we initially assumed we are near the identity tensor I (k) , we can switch from one parametrization to the other as follows. First, note that I (k) ∈ M (k) (G) and I (k) ∈ M (k) ( G). Then, given E (k) and λ, we can find E (k) from equations ( <ref type="formula" target="#formula_60">17</ref>) and ( <ref type="formula" target="#formula_61">18</ref>), and λ ij = λ ij for i → j, i.e., given C (k) ∈ M (k) ( G), using equation ( <ref type="formula" target="#formula_60">17</ref>) and equation ( <ref type="formula" target="#formula_61">18</ref>), we get that the corresponding</p><formula xml:id="formula_62">C (k) ∈ M (k) (G), therefore M (k) ( G) ⊆ M (k) (G). Conversely, given E (k) i1,...,i k and λ ij small enough, we can choose E (k) v,...,v = ε &gt; 0, λ ij = λ ij for i → j in D, and λ v,i l = k |E (k) i 1 ,...,i k | ε</formula><p>for l ∈ {1, . . . , k}. Therefore, equation ( <ref type="formula" target="#formula_60">17</ref>) is satisfied.</p><p>Since E (k) i1,...,i k is small and E (k) i,...,i is near 1, we can find E (k) i,...,i &gt; 0 such that equation ( <ref type="formula" target="#formula_61">18</ref>) is satisfied and such that E (k) is a diagonal tensor. This shows that if C (k) ∈ M (k) (G) is in a neighborhood of I (k) , then we can find the corresponding C (k) ∈ M (k) ( G) as well. Note that this correspondence between C (k) and C (k) is a bijection. Thus M (k) (G) and M (k) ( G) are equal in an open neighborhood and so they have the same Zariski closure, i.e., M (k) </p><formula xml:id="formula_63">(G) = M (k) ( G), where M (k) (G) denotes the Zariski closure of M (k) (G). Therefore the determinant of C (k) S1,...,S k vanishes on M (k) ( G) if and only if the determinant of C (k) S1,...,S k vanishes on M (k) (G).</formula><p>This is equivalent to saying that there is no system of k-treks without sided intersection between S 1 , ..., S k in G if and only if there is no system of k-treks without sided intersection between S 1 , . . . , S k in G.</p><p>Going back to the proof of Theorem 32, Proposition 33 enables us to reduce the multidirected setting to a directed acyclic graph for which we proved Theorem 18.</p><p>Example 34. The following example shows that Theorem 32 enables us to determine whether random variables have a common cause. </p><note type="other">Figure 12</note><p>In the two graphs from Figure <ref type="figure" target="#fig_1">12</ref>, let A = {1}, B = {2}, and C = {3}. In Figure <ref type="figure" target="#fig_1">12a</ref>, there is one 3-trek joining A, B, and C, hence det(C</p><p>ABC ) = C</p><p>(3) 123 = 0. In Figure <ref type="figure" target="#fig_1">12b</ref>, there is no 3-trek joining A, B and C and, a fortiori, no 3-trek without sided intersection. Therefore det(C</p><p>ABC ) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Determinants of higher-order moments and multi-trek systems</head><p>At the start of this project, we focused on tensors of higher-order moments rather than cumulants. However, contrary to cumulant tensors (cf. Lemma 2), moment tensors of order greater than 3 are not diagonal when the variables are independent. Extending Theorem 18 to higher-order moment tensors is therefore not straightforward. Nevertheless, we conjecture that the result still holds. Before stating this conjecture, we translate our results obtained for cumulant tensors to moment tensors.</p><p>Let Φ (k) be the tensor of k th -order moments of ε. Then, the k th -order moment tensor of X is given as follows.</p><p>Proposition 35 ([4, Chapter 5, Eq. (5.7)]). The tensor N (k) of k th -order moments of the random vector X with mean (0, ..., 0) equals</p><formula xml:id="formula_66">N (k) = Φ (k) • (I -Λ) -k .<label>(19)</label></formula><p>Let G = (V, D, H) as in Section 4. In order to account for the non-zero off-diagonal entries in the tensor Φ (k) of higher-order moments of ε, we need to adapt our definition of a k-trek as follows.</p><p>Definition 36. A k-split-trek in G between k nodes v 1 , . . . , v k is either:</p><p>(a) an ordered collection of k directed paths (P 1 , ..., P k ) where P i has sink v i , and P 1 , ..., P k have the same source; or (b) an ordered collection of k directed paths (P 1 , ..., P k ) where P i has sink v i , and P 1 , ..., P k may have different sources, but each source must be shared by at least two paths. (a) a node that is the source of each of the k paths P 1 , . . . , P k . (b) a set of j nodes where each of the j nodes is a source of j of the paths P 1 , . . . , P k such that j j = k and j ≥ 2 for all j.</p><p>Note that when k = 3, the notions of a 3-trek and a 3-split-trek coincide.</p><p>Example 38. In Figure <ref type="figure" target="#fig_2">13</ref>, subfigure (a) illustrates the first type of a top, while subfigures (b-f) illustrate the second type.</p><p>Using equation ( <ref type="formula" target="#formula_18">6</ref>), we rewrite the entries of (I -Λ) -1 in equation ( <ref type="formula" target="#formula_66">19</ref>) and thus express the entries of the tensor of k th -order moments as follows.</p><p>Proposition 39. We have that top(P1,...,P k ),...,top(P1,...,P k ) λ P1 ... λ P k (20)</p><p>where S(i 1 , ..., i k ) is the set of all k-split-treks between i 1 , ..., i k .</p><p>Proof. From equation <ref type="bibr" target="#b18">(19)</ref>, we have that N (k) = Φ (k) •(I -Λ) -k . The entries of Φ (k) are non-zero if and only if they are of the form E[ε x1 1 ...ε x k k ] where x 1 , ..., x k are integers either equal to 0, or strictly greater than 1.</p><p>Proof. We are going to show the contrapositive statement. Suppose that there exists 2 ≤ h ≤ k-2 and a partition {1, . . . , k} = {i 1 , . . . , i k } ∪ {j 1 , . . . , j k-h } such that both det N (h) Si 1 ,...,Si h = 0 and det N (k-h) Sj 1 ,...,Sj k-h = 0. Then, by Conjecture 42 there exists an h-split-trek system T 1 with no sided intersection between S i1 , . . . , S i h and a (k -h)-split-trek system T 2 with no sided intersection between S j1 , . . . , S j k-h . Then, combining together T 1 and T 2 , we get a valid k-split-trek system between S 1 , . . . , S k with no sided intersection, which then implies det N (k) S1,...,S k = 0. Example 44. We illustrate Proposition 43 for the case k = 4 and h = 2.. In the graph from Figure <ref type="figure" target="#fig_5">14</ref>  Proposition 43 would give a nice relationship between the vanishing of determinants of high-order moment tensors and low-order moment tensors. One of our initial hopes was that in the case of Gaussian random variables, the vanishing of high-order moment determinants would be able to explain constraints in the model that are not subdeterminants of the covariance matrix (sometimes called Verma constraints) <ref type="bibr" target="#b21">[21]</ref>. However, Proposition 43 implies that if a high-order moment determinant vanishes, then so does a lower-order one. On the other hand there are lots of Gaussian graphical models, for which there are no covariance determinants vanishing <ref type="bibr" target="#b4">[5]</ref>, thus the vanishing of determinants would not suffice to describe the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we give implicit constraints on linear non-Gaussian structural equation models by providing a relationship between the vanishing of subdeterminants of the tensors of k-th order cumulants and a combinatorial criterion on the corresponding graph. Specifically, we show that the determinant of the subtensor of the k-th order cumulants for k sets of vertices with equal cardinality vanishes if and only if there is no system of k-treks between these sets without sided intersection. One of the main contributions of our work is the introduction of multi-directed edges in the hidden variable case, and our multi-trek criterion which allows us to, for example, detect the presence of a common cause of multiple vertices.</p><p>A few questions for further research remain. As shown in Example 20, Theorem 18 gives a criterion for checking if random variables have a common cause or not. It would be interesting to build a test statistic based on this criterion. Furthermore, our criterion can be coupled with existing algorithms to recover a mixed graph with multi-directed edges from observational data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) A multi-directed edge between nodes 1,2 and 3; (b) Mixed graph G1; (c) Mixed graph G2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: By Theorem 32, (a) C (3) 123 = 0 (b) C (3) 123 = 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: (a). An example of a 4-trek; (b) Example DAG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>T</head><label></label><figDesc>,...,P k ) λ P1 ....λ P k , where λ Pj = k→l∈Pj λ kl . Assuming that #R 1 = ... = #R k = #S 1 = ... = #S k = n and using the Leibniz expansion formula for determinants, we then get:det C (k) S1,...,S k = σ2∈Sn 2 ,...,σ k ∈Sn k T1∈T (s1,s σ 2 (1) ,...,s σ k (1) ) ... ... Tn∈T (sn,s σ 2 (n) ,...,s σ k (n) ) sign(σ 2 ) • • • sign(σ k ) m T1 ...m Tn = σi∈Sn i i∈{2,...,k} Tj ∈T (sj ,s σ 2 (j) ,...,s σ k (j) ) ∈T (S1,...,S k ) sign(T ) m T ,(11)where S ni is the set of permutations of the nodes in S i , T runs over all k-trek systems between S 1 , ..., S k and sign(T ) = sign(σ 2 ) • • • sign(σ k ). In this expression, we have m T = n x=1 m Tx , where m Tx = E (k) top(Ps 1 ,...,Ps k ) λ Ps 1 • • • λ Ps k is the trek monomial corresponding to the trek T x .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Lemma 14 .</head><label>14</label><figDesc>Suppose that A is a p × n × p × ... × p k tensor of order k and B is a n × p matrix, I is a subset of {1, ..., p}. Then det (AB) = I⊆[n],#I=p det (A I )det (B I ), where the sum is over subsets I of {1, ..., n} such that #I = p, and A I denotes the subtensor of A given by A [p],I,[p],...,[p] , and B I denotes the submatrix of B given by B I,[p] .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>S 1 S 2 S 3 A 1 A 2 A 3 Figure 7</head><label>231237</label><figDesc>Figure 7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8</head><label>8</label><figDesc>Figure 8</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: A multidirected edge between i1, i2, i3, i4 of order 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Figure 10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>11 :</head><label>11</label><figDesc>Mixed graph G in (a) and its corresponding canonical DAG G in (b) Proposition 33. Let S 1 , ..., S k ⊂ V be k sets of vertices such that #S 1 = ... = #S k . Then the determinant of C (k) S1,...,S k is zero for all cumulant tensors C ∈ M (k) (G) if and only if the determinant of C (k)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>..,i k = (P1,...,P k )∈T (i1,...,i k )E (k) top(P1,...,P k ) λ P1 ... λ P k . Similarly, C (k)i1,...,i k is the sum of the trek monomials of all k-treks in T (i 1 , ..., i k ) between i 1 , ..., i k in G, i.e., C (k) i1,...,i k = ( P1,..., P k )∈ T (i1,...,i k ) E (k) top( P1,..., P k ) λ P1 ... λ P k . Now, let's set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 13 : 4 Definition 37 .</head><label>13437</label><figDesc>Figure 13: Types of k-split-treks for k = 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>N</head><label></label><figDesc>..,i k = (P1,...,P k )∈S(i1,...,i k )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>2 ) 2 )</head><label>22</label><figDesc>,S3,S4 = 0. In Figure14(b), det N (S1,S2 = 0 and in Figure 14(c), det N (S3,S4 = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Figure 14</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Recall that the k-th cumulant tensor of a random vector Z = (Z 1 , . . . , Z p ) is the p × • • • × p (k times) table with entry at position (i 1 , . . . , i k ) given by cum(Z i1 , . . . , Z i k ) =</figDesc><table><row><cell>2.2 Cumulants of linear structural equation models</cell></row><row><cell>(A1,...,A L )</cell></row><row><cell>)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>) 2,2 λ 14 λ 17 λ 26 λ 28 .</figDesc><table><row><cell cols="2">since there is only one 2-trek system between 46 and 78 without sided intersection, namely {(1 → 4, 1 →</cell></row><row><cell cols="2">7), (2 → 6, 2 → 8)}. Similarly, we have</cell></row><row><cell>det C</cell><cell>(3) 46,58,78 = E 1,1,1 E (3) 2,2,2 λ 2 (3) 14 λ 45 λ 17 λ 26 λ 2 28 ,</cell></row><row><cell cols="2">since there is only one 3-trek system between 46, 58, and 78, namely {(1 → 4, 1 → 4 → 5, 1 → 7), (2 →</cell></row><row><cell>6, 2 → 8, 2 → 8)}.</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="person">Mathias Drton</rs> for suggesting the problem. <rs type="person">Elina Robeva</rs> was partially supported by an <rs type="funder">NSF</rs> <rs type="grantName">Postdoctoral Fellowship</rs> (<rs type="grantNumber">DMS 1703821</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_5z7tgsY">
					<idno type="grant-number">DMS 1703821</idno>
					<orgName type="grant-name">Postdoctoral Fellowship</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Such entries correspond to the cases when there is a k-split-trek between i 1 , ..., i k as defined in Definition 36. Furthermore, we have (I -Λ) -1 ij = P ∈P(ij) λ P by equation <ref type="bibr" target="#b5">(6)</ref>, and replacing this expression in equation <ref type="bibr" target="#b18">(19)</ref>, we obtain equation <ref type="bibr">(20)</ref>, which completes the proof.</p><p>Similarly to the case of higher-order cumulants, the determinant of the subtensor of k th -order moments indexed by the sets S 1 , ..., S k can be rewritten in terms of the split-trek systems between S 1 , ..., S k .</p><p>Proposition 40. Let S 1 , . . . , S k ⊆ V be k sets of nodes such that #S 1 = ...</p><p>where m T is the split-trek-system monomial of the split-trek system T = {(P</p><p>k ), . . . , (P</p><p>Furthermore, the sum can be taken over the set S(S 1 , . . . , S k ) of k-split-trek-systems without sided intersection.</p><p>The proof of Proposition 40 can be found in Appendix B. We now prove an analog of Theorem 18 for the tensors of 3 rd -order moments (k = 3).</p><p>if and only if every system of 3-split-treks between S 1 , S 2 , S 3 has a sided intersection.</p><p>Proof. In order to prove Theorem 41, notice that in equation <ref type="bibr" target="#b24">(24)</ref>, Φ (k) is diagonal for k = 3. Furthermore, a 3-trek and a 3-split-trek are the same (and similarly for a 3-trek system and a 3-split-trek-system). Then the proof of Theorem 41 follows the same reasoning as that of Theorem 18.</p><p>Notice that for k &gt; 3, Φ (k) is not diagonal, and for that reason, we cannot easily extend Theorem 41 to higher-order moments. For higher-order moments (k &gt; 3), we conjecture the following theorem by analogy with Theorem 18.</p><p>Conjecture 42. Let S 1 , ..., S k be subsets of V with #S 1 = ... = #S k . Then, det N (k) S1,...,S k = 0 if and only if every system of k-split-treks between S 1 , ..., S k has a sided intersection.</p><p>Note that the if direction is straightforward since we can express the determinant as a sum of split-trek monomials of k-split-trek systems without sided intersection, as in Proposition 40. Provided Conjecture 42 is true, we can show the following relationship between moment tensors of different orders. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proof of Cauchy-Binet for tensors</head><p>We prove a tensor version of the Cauchy-Binet Theorem <ref type="bibr" target="#b0">[1]</ref> (Lemma 14) for the determinant of the product AB, where A is a tensor of k-th order and B is a matrix. We then apply this proposition to the Tucker decomposition of tensors E (k) • (I -Λ) -k in the proof of Proposition 13.</p><p>Proof of Lemma 14. We will present the proof assuming that we multiply the matrix B along the second dimension of A. Notice that the proof would have followed the same reasoning should we have multiplied along any other dimension. When we multiply B along the second dimension of A, the entry c i1...i k of the product C = AB is given by:</p><p>Let's adopt the following notation: </p><p>Using Definition 9 for the tensor determinant, we have:</p><p>from the definition of the product of a tensor by a matrix</p><p>by re-arranging terms</p><p>from the definition of the determinant of a matrix, and where B f is the submatrix B whose rows are selected by f </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Proof of Proposition 40</head><p>Proof. By applying the tensor version of the Cauchy-Binet Theorem k times to equation <ref type="bibr" target="#b18">(19)</ref>, we get:</p><p>Additionally, from equation <ref type="bibr" target="#b24">(24)</ref>, we can write</p><p>where m T is the k-split-trek monomial defined by m T = φ top(P1,...,P k ) λ P1 ....λ P k .</p><p>Assuming that #R  Similarly to the proof of Proposition 13, we can use the Gessel-Viennot-Lindstrom Lemma to show that the sum in the expression of det N (k) S1,...,S k can be taken over the set S(S 1 , . . . , S k ) of k-split-trek systems between S 1 , . . . , S k without sided intersection.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Comprehensive Introduction to Linear Algebra</title>
		<author>
			<persName><forename type="first">J</forename><surname>Broida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Williamson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the theory of determinants</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cayley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Collected Papers</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="63" to="80" />
			<date type="published" when="1889">1889</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Independent component analysis -a new concept</title>
		<author>
			<persName><forename type="first">P</forename><surname>Comon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="287" to="314" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Handbook of blind Source Separation: Independent Component Analysis and Applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Comon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jutten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Academic Press, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Nested covariance determinants and restricted trek separation in gaussian graphical models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Drton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Robeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Weihs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A link between the canonical decomposition in multilinear algebra and simultaneous matrix diagonalization</title>
		<author>
			<persName><forename type="first">L</forename><surname>De Lathauwer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal of Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="322" to="336" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Algebraic geometry of bayesian networks</title>
		<author>
			<persName><forename type="first">Luis</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garcia</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Stillman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Symbolic Computation</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="331" to="355" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Binomial determinants, paths, and hook length formulae</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Viennot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Advances in Mathematics</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="300" to="321" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recursive causal models</title>
		<author>
			<persName><forename type="first">Harri</forename><surname>Kiiveri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Speed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Australian Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="52" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Pairwise likelihood ratios for estimation of non-gaussian structural equation models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="111" to="152" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Lauritzen</surname></persName>
		</author>
		<title level="m">Graphical Models. The Clarendon Press</title>
		<meeting><address><addrLine>Oxford, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On the vector representations of induced matroids</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lindström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of the London Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="90" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">K</forename><surname>Menger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zur allgemeinen Kurventheorie. Fund. Math</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="96" to="115" />
			<date type="published" when="1927">1927</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fusion, propagation, and structuring in beliefs networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="241" to="288" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<idno>MR 2548166</idno>
		<title level="m">Causality. Models, reasoning, and inference</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Algebraic methods of classifying directed graphical models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Roozbehani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Polyanskiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Information Theory</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="2027" to="2031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A linear non-gaussian acyclic model for causal discovery</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kerminen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">DirectLiNGAM: A direct method for learning a linear non-gaussian structural equation model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Inazumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sogawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Washio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1225" to="1248" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">With additional material by</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<idno>MR 1815675</idno>
	</analytic>
	<monogr>
		<title level="m">Causation, prediction, and Search. Adaptive Computation and Machine Learning</title>
		<editor>
			<persName><forename type="first">David</forename><surname>Heckerman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gregory</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Richardson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bradford</forename><surname>Book</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Graduate Studies in Mathematics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sullivant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">194</biblScope>
		</imprint>
	</monogr>
	<note>Algebraic statistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Trek separation for gaussian graphical models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sullivant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talaska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Draisma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1665" to="1685" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Equivalence and synthesis of causal models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">In</forename><surname>Elsevier</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="255" to="268" />
			<date type="published" when="1991">1991</date>
		</imprint>
		<respStmt>
			<orgName>UCLA Cognitive Systems Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>R-150</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">High-dimensional causal discovery under non-gaussianity</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Drton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Correlation and causation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Agricultural Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="557" to="585" />
			<date type="published" when="1921">1921</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The method of path coefficients</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="161" to="215" />
			<date type="published" when="1934">1934</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Evans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.12754</idno>
		<title level="m">Constraints in gaussian graphical models</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
