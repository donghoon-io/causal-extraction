<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Parsimony in Model Selection: Tools for Assessing Fit Propensity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Carl</forename><forename type="middle">F</forename><surname>Falk</surname></persName>
							<email>carl.falk@mcgill.ca.</email>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Muthukrishna</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">London School of Economics and Political Science (LSE)</orgName>
								<orgName type="department" key="dep2">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">McGill University</orgName>
								<orgName type="institution" key="instit2">McGill University</orgName>
								<address>
									<postCode>2001</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">McGill College</orgName>
								<address>
									<addrLine>7th Floor</addrLine>
									<postCode>H3A 1G1</postCode>
									<settlement>Montreal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Parsimony in Model Selection: Tools for Assessing Fit Propensity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T23:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>fit indices</term>
					<term>parsimony</term>
					<term>model fit</term>
					<term>structural equation modeling</term>
					<term>formal theory</term>
					<term>SEM</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The authors would like to thank Victoria Savalei for her inspiration and early input on this project. We acknowledge the support of the Natural Science and Engineering Research Council of Canada (NSERC), (funding reference number RGPIN-2018-05357  and DGECR-2018-00083). Cette recherche a ete financee par le Conseil de recherches en sciences naturelles et en genie du Canada (CRSNG), [numero de reference RGPIN-2018-05357].</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Theories, no matter how beautiful, live and die on the back of data. Structural equation modeling offers a flexible framework for statistically representing complex theories <ref type="bibr" target="#b3">(Bollen &amp; Pearl, 2013;</ref><ref type="bibr" target="#b12">Grace &amp; Bollen, 2008)</ref>. Given a choice between two or more theoretically plausible structural equation models, the process of model selection and multimodel inference <ref type="bibr" target="#b7">(Burnham &amp; Anderson, 2002)</ref> typically involves asking which model is more consistent with the available empirical data. For example, there are many instances in psychological research where a broad (multifaceted) construct is defined, a test is created, and further psychometric work indicates that a multidimensional model fits better than a model that measures a single dimension. Some examples include the number and configuration of possible method factors on scales that include reverseworded items <ref type="bibr" target="#b32">(Reise, Kim, Mansolf, &amp; Widaman, 2016)</ref> or whether a random intercept model should be used to model acquiescence bias <ref type="bibr" target="#b37">(Savalei &amp; Falk, 2014)</ref>, the tradeoff between a correlated factor, hierarchical factor, and bifactor models for constructs such as self-compassion <ref type="bibr" target="#b23">(Neff, Whittaker, &amp; Karl, 2017)</ref>, alexithymia <ref type="bibr" target="#b30">(Reise, Bonifay, &amp; Haviland, 2013)</ref>, health outcomes <ref type="bibr" target="#b33">(Reise, Morizot, &amp; Hays, 2007)</ref>, and so on. In all cases, debates continue over which model is most correct. What is often overlooked is the counterfactual -that a model may not fit the empirical data better because it is a better description of reality, but simply because it has a tendency to fit any data better. That is, what is often overlooked is parsimony.</p><p>Occam's razor, or the principle of parsimony, is familiar to most scientists. As we teach our students: given the choice between two equally fitting models, all else being equal it is generally preferable to choose the simpler, or more parsimonious, model. What is less well understood is how one might quantify parsimony. One promising approach is the concept of model fit propensity (FP; <ref type="bibr" target="#b28">Preacher, 2006)</ref> or complexity <ref type="bibr" target="#b21">(Myung, Pitt, &amp; Kim, 2005;</ref><ref type="bibr" target="#b26">Pitt, Myung, &amp; Zhang, 2002)</ref>. Here we will use fit propensity to avoid confusion with other uses of the term complex. Fit propensity is sometimes described as the "complement" of parsimony <ref type="bibr">(Preacher, 2006, p. 230)</ref>. The basic idea behind fit propensity is that some models will simply do a better job of fitting a wider range of data. These models are less parsimonious. Thus, the process of model selection needs to consider not just model fit, but fit propensity. The ideal theoretically derived model will have both better fit and lower fit propensity than a competing model. But in practice, there is likely to be a tension between fit and fit propensity. In other words, for a model to be both useful and generalizable, a balance must be struck between fitting real data, and parsimony in not also fitting random data (fit propensity can be defined as the propensity to fit random data; <ref type="bibr" target="#b4">Bonifay, 2015;</ref><ref type="bibr" target="#b10">Cudeck &amp; Browne, 1983;</ref><ref type="bibr" target="#b18">Marsh &amp; Balla, 1994;</ref><ref type="bibr" target="#b30">Reise et al., 2013)</ref>.</p><p>Parsimony is sometimes described as a function of degrees of freedom. For example, <ref type="bibr" target="#b18">Marsh &amp; Balla (1994)</ref> defined parsimony as "the ratio of degrees of freedom in the model being tested and degrees of freedom in the null model <ref type="bibr">(James et al., 1982;</ref><ref type="bibr">Mulaik et al., 1989</ref>)" (p. 188). It is thus tempting to equate parsimony with the degrees of freedom of a model such that fewer estimated parameters (and higher df ) corresponds to more parsimony. However, it is possible to have models with the same number of estimated parameters, but where one has better propensity to fit random data <ref type="bibr" target="#b5">(Bonifay &amp; Cai, 2017;</ref><ref type="bibr" target="#b28">Preacher, 2006)</ref>. Indeed, a model may even have more estimated parameters than an alternative, but have lower fit propensity and therefore more parsimony <ref type="bibr" target="#b25">(Pearl &amp; Verma, 1995)</ref>. The configuration of the model (number of latent factors, paths among variables) and functional form of relationships among variables also affects fit propensity. In sum, prior research has identified both the number of estimated parameters and the functional form or configuration of the model as both contributing to fit propensity <ref type="bibr" target="#b21">(Myung et al., 2005;</ref><ref type="bibr" target="#b28">Preacher, 2006)</ref>. Thus, fit indices that adjust for degrees of freedom, such as Tucker-Lewis Index (TLI; <ref type="bibr" target="#b40">Tucker &amp; Lewis, 1973)</ref>, Comparative Fit Index (CFI; <ref type="bibr" target="#b0">Bentler, 1990)</ref>, and Root Mean Square Error of Approximation (RMSEA; <ref type="bibr" target="#b39">Steiger &amp; Lind, 1980)</ref> or commonly used information criterion, such as AIC and BIC that have adjustments based on the number of estimated parameters are coarse in how they treat the role of fit </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Fit Propensity and the Rosenberg Self-Esteem Scale</head><p>To understand the importance of fit propensity, consider the Rosenberg Self-Esteem Scale (RSES; <ref type="bibr" target="#b35">Rosenberg, 1965)</ref>. The RSES is perhaps the most widely used self-report instrument for the measurement of self-esteem. It contains ten 5-point Likert-type items.</p><p>The RSES is often used by applied researchers to represent a single construct: self-esteem.</p><p>Higher scores indicate higher self-esteem for five positively keyed items (items 1, 2, 4, 6, and 7), and five negatively worded or reverse keyed items (items 3, 5, 8, 9, and 10).</p><p>The RSES is regularly used, but is the subject of ongoing investigations to examine the confirmatory factor analysis models that may represent it; a single factor model rarely fits RSES data adequately. In a recent example, <ref type="bibr" target="#b11">Donnellan, Ackerman, &amp; Brecheen (2016)</ref> fit ten different models to RSES data (N = 1, 127). Of these, three models stood out as having superior fit: 1) A global factor with correlated residuals among positively and negatively worded items<ref type="foot" target="#foot_0">foot_0</ref> ; 2) A bifactor model with method factors for positively and negatively worded items; and 3) The same bifactor model, but with correlated method factors (Figure <ref type="figure">1</ref>). For illustration, we replicated the original analyses using lavaan <ref type="bibr" target="#b36">(Rosseel, 2012)</ref>, and results for these models and a single factor model are presented in Table <ref type="table" target="#tab_0">1</ref></p><formula xml:id="formula_0">. 2 Figure 1: Rosenberg Self-Esteem Models V 1 V 2 V 3 V 4 V 5 V 6 V 7 V 8 V 9 V η 1 Correlated Residual Model V 1 V 2 V 3 V 4 V 5 V 6 V 7 V 8 V 9 V η 2 η 3 η 1 Bifactor Model V 1 V 2 V 3 V 4 V 5 V 6 V 7 V 8 V 9 V η 2 η 3 η 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bifactor Model With Correlated Method Factors</head><p>On the one hand, such well-fitting models may make intuitive sense. All three models account for additional dependencies beyond a single factor, and may be appropriate to the extent that positively worded items share some dependency, as do negatively worded items. On the other hand, one might question whether these models fit for other reasons.</p><p>Are they parsimonious? The correlated residual model essentially accomplishes a similar task as the bifactor model in modeling dependencies among similar items, but does so with even more additional model parameters. Does this come with a cost to fit propensity?</p><p>Indeed, from a traditional standpoint, these models have the most estimated parameters of all ten models examined: 39, 30, and 31, respectively, with only 20 for the single factor  <ref type="bibr" target="#b6">Bonifay, Lane, &amp; Reise (2017)</ref> argued that the bifactor model may be good at fitting random noise-that it lacks parsimony. For instance, <ref type="bibr" target="#b5">Bonifay and Cai (2017)</ref> found that a bifactor model with two uncorrelated method factors had higher fit propensity in general than two hierarchical models with discrete latent variables with the same number of parameters. In also examining the RSES, <ref type="bibr" target="#b31">Reise, Kim, Manslof, &amp; Widaman (2016)</ref> found that the bifactor model with uncorrelated method factors helped explain inconsistent response patterns, but that a single factor model was sufficient for the majority of participants. Note that the fit propensity of the additional models considered by <ref type="bibr" target="#b11">Donnellan et al. (2016)</ref> have not been studied. One might then also wonder-how much more fit propensity does a correlated residual model have above and beyond a bifactor model? Or, does adding a single correlation among method factors substantially change fit propensity? How does the fit propensity of such models compare to a single factor model? Does fit propensity correlate with number of parameters? Is it possible that such models tend to fit the data well, not because they are close approximations of reality, but that such models tend to fit any data, even random data, very well? And even more broadly, does relative fit propensity depend on which fit index is examined?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Testing Fit Propensity</head><p>The types of questions we ask above provide clues about parsimony that are not easily answered by number of parameters or traditional fit indices. They can, however, be understood through a study of fit propensity. 3 A popular method of studying fit propensity requires repeated generation of random data from a data space and fitting the models of interest <ref type="bibr" target="#b28">(Preacher, 2006)</ref>. Information regarding model fit can then be recorded over a large number of replications and summarized to provide a sense of how well the models fit such random data. <ref type="bibr" target="#b28">Preacher (2006)</ref>  We aim to support further researchers in considering fit propensity of their models by providing an R package: ockhamSEM. The ockhamSEM package offers easy-to-use and highly flexible software built on the popular lavaan <ref type="bibr" target="#b36">(Rosseel, 2012)</ref> package. We hope that ockhamSEM will be used for the study of fit propensity by applied researchers 3 In our replication, an additional fit index, Stochastic Information Complexity (SIC; <ref type="bibr" target="#b13">Hansen &amp; Yu, 2001)</ref>, is reported and that could be used for adjustment of model fit that is more in line with fit propensity <ref type="bibr" target="#b5">(Bonifay &amp; Cai, 2017;</ref><ref type="bibr" target="#b28">Preacher, 2006)</ref>, but as we discuss later in this manuscript, does not immediately provide intuitive information regarding fit propensity. investigating models of interest, for classroom demonstrations, or the further study of fit propensity itself and related methodological challenges by quantitative methodologists.</p><p>Investigating fit propensity requires generating random correlation matrices, which are computationally intensive. The ockhamSEM package provides several innovations in terms of both computational efficiency and the reporting of fit propensity. In particular, random correlation matrices can be generated using the onion method by <ref type="bibr">Lewandowski and colleagues (2009)</ref>, as well as Preacher's original MCMC algorithm. The onion method exploits known properties of elliptically contoured distributions applied to a k-dimensional hypersphere to provide a space of correlation matrices that can be sampled. This sampling results in the generation of correlation matrices much faster than the MCMC method, which involves iteratively generated random draws, where as with many MCMC methods, most are discarded. Using the onion method, thousands of large correlation matrices can be generated in seconds. We discuss these methods in further detail with additional resources in the Appendix.</p><p>Calculations can be performed in parallel using the multiple processing cores common in modern personal computers and computing clusters. Random correlation matrices can be restricted to all positive correlations, or both positive and negative correlations (indeed, other arbitrary restrictions can also be implemented). We also provide support for the full range of fit indices available from lavaan. Finally, additional numerical and graphical summaries are provided, going beyond those originally presented by <ref type="bibr" target="#b28">Preacher (2006)</ref>.</p><p>Our work is related to some recent research on fit propensity and model similarity.</p><p>In particular, <ref type="bibr" target="#b5">Bonifay &amp; Cai (2017)</ref> describe methods for studying the fit propensity of item response models with categorical observed variables. Given the unification of item response models and SEM under a unified latent variable modeling framework (e.g., <ref type="bibr" target="#b38">Skrondal &amp; Rabe-Hesketh, 2004)</ref>, this work is related to the present research. However, it does not address continuous observed variables and none of the underlying code was provided. We take the "ameoba" plots presented by <ref type="bibr" target="#b5">Bonifay &amp; Cai (2017)</ref> as inspiration for some vizualizations we present later in this paper. In addition, <ref type="bibr">Lai and colleagues (2017)</ref> address methods for examining model similarity using mostly scatter plots and line graphs of fit indices, and may be helpful for visualizing whether some models are equivalent or nested (but see <ref type="bibr" target="#b2">Bentler &amp; Satorra, 2010)</ref>. These authors mention difficulty in generating data from random correlation matrices, and instead opt for data generation from a restricted space that is a mixture of the correlation matrices implied by two competing models. Thus, model similarity rather than fit propensity was the main focus of this previous work.</p><p>This paper is organized into the following sections. The first section provides a brief description of our implementation of the R code. We then illustrate concepts of fit propensity and basic features of the code in the context of several initial examples from <ref type="bibr" target="#b28">Preacher (2006)</ref>, and the RSES example. Finally, we conclude with a discussion of additional innovations and alternative ways to compare models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Illustrative Examples</head><p>We present three examples to illustrate the basic procedure and concepts used to study fit propensity, including visualization and summaries of results (Table <ref type="table" target="#tab_2">2</ref>). The first two examples expand upon those initially presented by <ref type="bibr" target="#b28">Preacher (2006)</ref>. We note that while the general pattern of results remains similar in our implementation, there may be minor discrepancies for a number of reasons. <ref type="foot" target="#foot_3">5</ref> The final example concentrates on the  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Example A: Fit Propensity Basics</head><p>We will use the two 3-variable models depicted in Figure <ref type="figure">2</ref> as our first example (See also <ref type="bibr">Preacher, 2006, p. 228)</ref>. In Model 1A,</p><formula xml:id="formula_1">V 3 is regressed on V 1 and V 2 , with the covariance among V 1 and V 2 restricted to zero. Model 2A represents a causal chain in which V 2 is regressed on V 3 , which is in turn regressed on V 1 , yet there is no direct path from V 1 to V 2 .</formula><p>These have the same number of estimated parameters (5) and do not represent equivalent models, despite the only difference being the direction of the relationship between V 2 and V 3 . The study of fit propensity is well suited for answering which model has a tendency to yield better fit. Although these models may seem trivially</p><p>simple, the answer to this question is not so easy to see without the additional work we present below.</p><p>Figure <ref type="figure">2</ref>: Two 3-variable models.</p><formula xml:id="formula_2">V 1 V 2 V 3 ε 3 β 1 β 2 φ 1 φ 2 ψ 3 Model 1A V 1 V 2 V 3 ε 3 ε 2 β 1 β 2 φ 1 φ 2 ψ 3 ψ 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model 2A</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">General Procedure and Code</head><p>The procedure to study fit propensity that we illustrate here follows several steps:</p><p>1. Definition of the model(s) of interest.</p><p>2. Generation of n random correlation matrices.</p><p>3. Fitting the models of interest to the n random correlation matrices.</p><p>4. Recording information regarding model fit for each model and correlation matrix.</p><p>5. Summaries of model fit using text, graphical displays, and measures of effect size (e.g., Komolgorov-Smirnov).</p><p>The core custom code used in this paper are included in the ockhamSEM package<ref type="foot" target="#foot_4">foot_4</ref> .</p><p>Underlying innovations and the methods for generating random correlation matrices are discussed in the Appendix. The package can be loaded with the following R code snippet: library(ockhamSEM) library(parallel)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Step 1</head><p>First use lavaan model syntax to define Model 1 and Model 2:</p><formula xml:id="formula_3">mod1a &lt;-'V3 ~V1 + V2 V1 ~~0 * V2' mod2a &lt;-'V3 ~V1 V2 ~V3'</formula><p>Next, two models are fit to data. We expect that this will be the most typical use of studies of fit propensity for applied researchers -two or more substantive models are of interest in particular, because of debates over which is most appropriate for real data. We simply require a fitted lavaan model using data that has the same variable names (V1 through V3 in this case) as the above syntax indicates. Alternatively, we may fit the data to some covariance matrix. The following uses the latter strategy in creating an identity matrix:<ref type="foot" target="#foot_5">foot_5</ref> </p><p>p&lt;-3 # number of variables temp_mat &lt;-diag(p) # identity matrix # set row and column names colnames(temp_mat) &lt;-rownames(temp_mat) &lt;-paste0("V", seq(1, p))</p><p>We then fit the two models using the sem function from the lavaan package, though note that any function that returns a fitted model of class lavaan could be used, such as the cfa, sem, or lavaan functions: mod1a.fit &lt;-sem(mod1a, sample.cov=temp_mat, sample.nobs=500) mod2a.fit &lt;-sem(mod2a, sample.cov=temp_mat, sample.nobs=500)</p><p>At this step, any special options regarding estimation can be passed to sem. Our later code will attempt to use these options when fitting models for investigating fit propensity. For instance, here we specify a particular number of observations for this data (sample.nobs=500), although for many fit indices of interest this information is inconsequential. One may ask lavaan to mimic a different SEM program, use normal theory or Wishart likelihood, use a different optimizer, change the iteration limit for estimation, scale sample covariance matrices by (N -1)/N, and so on (see help(lavOptions)).</p><p>As long as any of these options are implemented when defining and fitting initial models, they will be used when the models are fit to randomly generated correlation matrices.</p><p>However, the ability to do so-called robust corrections or use any estimation approach that requires raw data or a mean structure is not supported; the available options currently must work for model fitting when analyzing only a covariance matrix as input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Steps 2 through 4</head><p>Generation of random correlation matrices, fitting models to such matrices, and recording model fit are all accomplished by the run.fitprop function in the next code snippet:</p><p>res.on &lt;-run.fitprop(mod1a.fit, mod2a.fit, fit.measure="srmr", rmethod="onion",reps=5000,onlypos=TRUE)</p><p>The initial arguments to this function are any number of fitted lavaan models, such as mod1a.fit and mod2a.fit. Here, we save only standardized root mean square residual, as indicated by "srmr", which in this case is equivalent to RMSR since analyzed correlation matrices will already be standardized. RMSR is the fit index primarily studied by <ref type="bibr" target="#b28">Preacher (2006)</ref> in his work on fit propensity as it provides a sense of model fit, unadjusted for the number of estimated parameters. We generate random correlation matrices using the onion method (rmethod="onion"), requesting 5,000 replications (reps=5000), and restricting to only positive correlations (onlypos=TRUE).</p><p>The result of the run.fitprop command in the code above is saved to res.on which is an object of class fitprop with several options regarding output that will be illustrated shortly. Before we proceed, suppose we wished to see whether results differ if we had instead used the MCMC algorithm to generate random correlation matrices. This latter approach should provide replication of <ref type="bibr" target="#b28">Preacher (2006)</ref>, but may be computationally slow. In this case, we may wish to use parallel processing for faster computations:</p><p>cl &lt;-makeCluster(8) res.mcmc &lt;-run.fitprop(mod1a.fit,mod2a.fit,fit.measure="srmr", rmethod = "mcmc", reps = 5000, onlypos=TRUE, cluster=cl) stopCluster(cl)</p><p>We create a cluster with 8 processing cores with the makeCluster command. The result, cl, is then passed to the run.fitprop function using the cluster argument.</p><p>The change in rmethod to "mcmc" will result in use of the MCMC algorithm for correlation matrix generation. Finally, we shut down the cluster using the stopCluster command after we obtain the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">Step 5</head><p>There are multiple different ways to then summarize results. <ref type="bibr" target="#b28">Preacher (2006)</ref> primarily focused on empirical cumulative distribution function (ECDF) plots that we also illustrate here and will describe shortly. In particular, both res.on and res.mcmc are objects of class fitprop for which we have defined a default plot function. This allows us to simply use the plot command successively in order to generate ECDF plots (Figure <ref type="figure" target="#fig_2">3</ref>) of the requested fit indices and model(s): plot(res.on) plot(res.mcmc)</p><p>The argument savePlot=TRUE can also be specified and the result will be a list of ggplot objects containing ECDF plots corresponding to each fit index. This feature is useful if, for example, the user wishes to modify the legend, title, etc., of the resulting plot or otherwise customize output:<ref type="foot" target="#foot_6">foot_6</ref> For convenience, several additional options can be defined, such as to add custom names (mod.lab) for the two (or more) fitted models and the color palette used by RColorBrewer <ref type="bibr" target="#b24">(Neuwirth, 2014)</ref>. plot1&lt;-plot(res.on, savePlot=TRUE, mod.lab=c("Model 1A","Model 2A"), mod.brewer.pal="Set1") plot2&lt;-plot(res.mcmc, savePlot=TRUE, mod.lab=c("Model 1A","Model 2A"), mod.brewer.pal="Set1")</p><p>To explain ECDFs and Figure <ref type="figure" target="#fig_2">3</ref>, suppose we collect all RMSR estimates for the 5,000  fitted models for Model 1A. We then sort these 5,000 estimates in order from lowest to highest. Next, we count the number of RMSR estimates at or below a particular value.</p><p>For example, "what proportion of fitted models have an RMSR value of .25 or lower? .5</p><p>or lower?" Each curve in Figure <ref type="figure" target="#fig_2">3</ref> displays the answer to this question for each model separately and at many values of RMSR along the x-axis such that the lines appear to be continuous. For example, Model 2A had approximately 75% (or .75 as a proportion) of models that had an RMSR (or srmr) of .25 or better when correlation matrices were generated using the MCMC algorithm (see where .25 on the x-axis intersects with the dotted blue line on the left-hand panel). Model 1A had a smaller proportion (around .57 or so) of cases with an RMSR of .25 or better. This implies that the higher curve (for Model 2A) indicates better fit for more models, and therefore more fit propensity when examining RMSR.</p><p>For the most part, the results displayed here replicate those of <ref type="bibr" target="#b28">Preacher (2006)</ref>: Model 2A appears to have more fit propensity in that there is a higher proportion of RMSR values that are relatively small, and this result tends to hold for both MCMC and Onion methods. Had either correlation matrix generating method allowed for both positive and negative correlations, the basic pattern in fit propensity regarding Models 1A and 2A</p><p>would have been similar and the interested reader is encouraged to verify this assertion.</p><p>Default print and summary methods are also available for fitprop objects.</p><p>summary will provide some diagnostic information regarding whether any nonconvergent models were encountered, selected quantiles of the resulting fit statistics, and effect sizes to help quantify the differences in fit between estimated models. For example, instead of eyeballing Figure <ref type="figure" target="#fig_2">3</ref>, we can ask for the value of srmr that corresponds to a cumulative proportion of .25, .5, and .75 for both models using the following: RMSR. We also see that there were apparently no models where non-convergence was a problem, since there are no NA values for any srmr estimates.</p><formula xml:id="formula_4">summary(</formula><p>At the end of the output, differences between all estimated models and all recorded fit indices are quantified using three effect sizes: Cohen's d <ref type="bibr" target="#b9">(Cohen, 1988</ref>), Cliff's delta <ref type="bibr" target="#b8">(Cliff, 1996)</ref>, and a Komolgorov-Smirnov coefficient (K-S). Although additional effect sizes could be easily added, we initially chose these three for several reasons. First, Cohen's d is likely familiar to many researchers in the social sciences. Here, we see that a value of .61 is observed, which is typically considered as between a "medium" and "large" effect size in research settings. Here it is indicating that Model 1A's distribution for RMSR is on average .61 SD higher than Model 2A. Cohen's d has a nice conceptual interpretation as the number of standard deviation units that separate the RMSR distributions for Models 1A and 2A. Since Cohen's d is typically not considered a robust effect size measure (e.g., <ref type="bibr" target="#b41">Wilcox, 2012)</ref>, we included Cliff's delta, which is robust to outliers and skewness, and K-S as additionally sensitive to variability across two distributions. These may be more unfamiliar to researchers.</p><p>Conceptually, Cliff's delta is a difference between two probabilities: 1) the probability that a value in the first distribution is greater than that in the second; and 2) the probability that a value in the second distribution is greater than that in the first. It is computed in part by comparing each observation from ond distribution versus all observations in a second distribution. Cliff's delta ranges between -1 and 1, with values close to zero indicating no difference between two distributions. The K-S coefficient is the maximum difference between two ECDFs over all cumulative probabilities of some measure (in our case, a given fit index). Therefore, as ECDFs also are bound between 0 and 1, K-S ranges between 0 and 1, with 1 indicating a larger discrepancy between two distributions.<ref type="foot" target="#foot_7">foot_7</ref> To our knowledge, there are no accepted guidelines for Cliff's delta or the K-S statistic equivalent to "small", "medium" and "large" for Cohen's d, in part because the statistics are readily interpretable. For example, in the output above, the difference in probabilities is 51.2% with values tending to be higher in Model 1, and the largest discrepancy in ECDFs is .374.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Example B: Simplex model versus factor model</head><p>Next, we extend an example given by <ref type="bibr" target="#b28">Preacher (2006)</ref> in which we compare a simplex model (1B) with a single factor model with a loading equality constraint for the second and third loadings (2B; Figure <ref type="figure">4</ref>).</p><p>Figure <ref type="figure">4</ref>: Simplex and constrained factor analysis model.</p><formula xml:id="formula_5">V 1 V 2 V 3 V 4 V 5 V 6 ε 2 ε 3 ε 4 ε 5 ε 6 φ 1 β 1 β 2 β 3 β 4 β 5 ψ 2 ψ 3 ψ 4 ψ 5 ψ 6 Simplex Model (1B) V 1 V 2 V 3 V 4 V 5 V 6 η ε 1 ε 2 ε 3 ε 4 ε 5 ε 6 1 λ 2 λ 2 λ 4 λ 5 λ 6 φ 1 ψ 1 ψ 2 ψ 3 ψ 4 ψ 5 ψ 6</formula><p>Factor Model (with loading constraint; 2B)</p><p>Although it seems unlikely that researchers would consider these two alternative models for the same dataset, they have the same degrees of freedom and will yield different fit propensity. Furthermore, these examples are useful for demonstrating the impact of a restriction on the data space. In particular, we compared the fit propensity using srmr for these two models by crossing two conditions: Correlation matrix generation (MCMC versus Onion) and positivity of correlations (all positive versus positive and negative). The option for obtaining both positive and negative correlations can be achieved by setting onlypos=FALSE when using the run.fitprop command. 10 10 R code for this and for all following examples appears in Supplementary Materials. At minimum, such a restriction would likely only make sense if the correlations among these two items have the same sign. For example, if it were the case that item 2 tended to have negative correlations with other items, but item 3 had positive correlations, the two loadings would seem to have opposite signs. Model fit would then deteriorate due in part to constraining these loading estimates to be equal.</p><p>We also note that substantial estimation problems were encountered when the correlation matrices included both positive and negative values. In particular, 2462 models failed to converge for the factor model when negative correlations were allowed for the Onion method, but 0 and 16 failed to converge for the MCMC and Onion (only positive) conditions, respectively. Such convergence failures are indicated as NA values for particular fit indices. Such information regarding the number of valid replications is available via the summary command.</p><p>The above plots and summary information are based on replications where both models converged as this is the default behavior. We can, however, change output so that results are based on the available number of replications for either model, regardless of whether the replications are the same by setting samereps=FALSE when using the plot command (For example, summary(res.mcmc, samereps=FALSE)). Thus, the quantiles and plots for Model 1B could be based on a slightly different subset of random correlation matrices than Model 2B. However, this does not appear to substantially change the resulting plots or summary information, and the interested reader is encouraged to verify this observation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Models for the Rosenberg Self-Esteem Scale</head><p>In our final example, we return to the debate regarding an appropriate model for the RSES. In particular, we investigated the fit propensity of the four models considered in Table <ref type="table" target="#tab_0">1</ref>. For reference, we label these as follows: Correlated residuals (Model 1C), bifactor (Model 2C), bifactor with correlated method factors (Model 3C), and a single factor model (Model 4C). Due to more models and the possibility of nonconvergence, we increased the number of replications to 10,000. As the RSES items typically intercorrelate positively (after reverse-coding), we used the onion method with only positive correlations. For fit indices, we additionally demonstrate the performance of TLI, CFI, RMSEA, and RMSR.</p><p>The model chi-square is also saved to later check model nesting.</p><p>Since information is saved from four fit indices (TLI, RMSR, CFI, RMSEA) and the model chi-square test of fit, we illustrate two additional options for aiding in generating plots. First, we can either obtain plots for all fit indices (the default behavior), or request plots just for a particular fit index by passing the whichfit argument to the plot function. whichfit accepts a character vector in the same fashion as fit.measure (resulting in plots for selected fit indices being displayed successively), or may be left at its default setting (successively showing plots for all saved fit indices).</p><p>Second, an additional argument can be changed to aid in interpreting TLI and CFI.</p><p>Note that lower values of RMSR typically indicate better fit, but higher values of TLI and CFI correspond to better fit. The lower.tail argument accepts a logical vector of the same length as the number of stored fit indices (i.e., the same length as fit.measure).</p><p>By default, the vector sets all elements to TRUE. Setting the corresponding element to FALSE for CFI ensures that the ECDF plots start with higher numbers on the left-hand side of the x-axis, making interpretation of such plots visually similar to those for RMSR.</p><p>In the following code snippet, assuming results are stored in res.rses we only plot results for TLI, CFI, RMSEA and RMSR, and we make the above corresponding changes for the ECDF plot for TLI and CFI.</p><p>plot(res.rses, whichfit=c("tli","cfi","rmsea","srmr"), lower.tail=c(FALSE,FALSE,TRUE,TRUE))</p><p>We next examine each fit index separately (Figure <ref type="figure" target="#fig_5">6</ref>). CFI is perhaps the easiest to interpret, yet also raises the most concerns about its use as a measure of model fit. In particular, very clearly the four models are ordered in terms of the number of estimated parameters, with models with fewer degrees of freedom (more estimated parameters)</p><p>having more fit propensity according to CFI. This is intuitive to the extent that more parameters leads to better fit. However, this is concerning since the data are random and CFI should include an adjustment for parsimony. That is, the adjustment included in CFI does not appear to equate the fit of the resulting models. Even for some nontrivial percentage of replications, CFI even exceeds .80 or so (e.g., CFI averages around .79 for the correlated residual model). This large percentage of models that have good fit for random data should be concerning to researchers using CFI. Differences among the models are also more difficult to detect visually. Additionally, effect sizes for the differences across these distributions also tends to be smaller. For example, K-S yields values between .11 and .40 for all pair-wise differences for RMSEA. For RMSR, the bifactor model with correlated method factors yielded the best fit propensity with the other models mixed. For instance, the difference between the bifactor model and the correlated residual is negligible (Cliff's delta = .05, K-S = .11). However, we may also raise some concerns about the utility of RMSR for these studied models. For instance, many RMSR estimates were below .1, with a full 60% of the correlated bifactor models below this threshold.</p><p>Euler plots can further aid in helping visualize relative fit of the models for the same randomly generated correlation matrices and are similar to Venn diagrams. These are inspired by the "ameoba" plots of <ref type="bibr" target="#b5">Bonifay &amp; Cai (2017)</ref>. In Euler plots, the area of each circle (or ellipse) is proportional to the number of cases that meet some criteria. Overlap among circles indicates overlap in the sets of correlation matrices that meet this criteria. 11</p><p>Take for example, TLI. The ECDF plot seems to indicate that the correlated bifactor 11 Code using nVennR for generating plots is also currently in development. Are there some replications where the single factor model had a TLI better than .5, but the correlated bifactor model did not? This information regarding overlapping sets of replications that meet this TLI criterion is depicted in a Euler plot: plot(res.rses,type="euler",whichfit="tli", whichmod=c(3,4),cutoff=.5,lower.tail=FALSE)</p><p>Figure <ref type="figure" target="#fig_6">7</ref> was generated with the above code. Larger ellipses are conceptually similar to occupation of a wider area of the data space, or more fit propensity, and directly represent the proportion of correlation matrices for each model where TLI was better than .5. Here we see that the correlated bifactor model takes up the most space relative to the single factor model, indicating that it had a higher proportion of cases with TLI of .5 or better. If one model always fits better than another, we would expect that the worse fitting model would be completely contained within the better fitting model's ellipse. Such a case would indicate that the entire set of replications that met the TLI ≥ .5 criterion for the lesser fitting model was also met by the better fitting model. That each model has some part of the ellipse that is not covered by the other suggests that there are some replications where each model fits better than the others. Here we see that the single factor model is not completely contained within the correlated bifactor's space. This means that there are some correlation matrices for which the single factor model has TLI better than .5, but the bifactor model does not have TLI better than .5. In other words, there are some correlation matrices for which the single factor model has better TLI than the correlated bifactor model.</p><p>Although one might be under the impression that models with more factors should always fit better than a single Factor model, this result typically applies to the chi-square test of fit and to the case of nested models. We can, however, directly check to see if the 1-Factor model is nested with a correlated bifactor model by also examining Euler plots for the chi-square test of model fit (Figure <ref type="figure">8</ref>). Here, we used a cutoff value of χ 2 = 3, 000.</p><p>The single factor model has no unique set that is not completely encompassed by the correlated bifactor model. In other words, there do not appear to be any single factor models that are better than χ 2 = 3, 000 but for which a correlated bifactor model is not as good. These results are what we would expect with a unidimensional model being nested with the correlated bifactor model. <ref type="foot" target="#foot_8">12</ref>Finally, SIC as reported in 2017; see also <ref type="bibr" target="#b13">Hansen &amp; Yu, 2001;</ref><ref type="bibr" target="#b28">Preacher, 2006)</ref> as a computationally feasible index that is similar to AIC and BIC, but may make a more fine-grained adjustment than that based on the number of estimated parameters. <ref type="foot" target="#foot_9">13</ref> In this particular case, SIC suggests the same ordering of model fit, and therefore the same selected model, as these other more traditional indices. While semTools <ref type="bibr" target="#b15">(Jorgensen, Pornprasertmanit, Schoemann, &amp; Rosseel, 2019</ref>) now provides computation of SIC from fitted lavaan models, we note that SIC does not immediately provide us with the useful information regarding fit propensity and other fit indices that may be of interest. The method of studying fit propensity that we have discussed thus far also allows restriction of the data space, which is also not possible with SIC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Discussion and Conclusion</head><p>Structural Equation Models (SEMs) are a flexible method for representing complex theories, a useful tool in moving toward a formal theoretical approach to the psychological sciences <ref type="bibr" target="#b20">(Muthukrishna &amp; Henrich, 2019)</ref>. But in evaluating competing theories instantiated as different SEMs, researchers need to consider not only the fit of their models to the data, but the parsimony of that fit. Fit propensity is therefore an important consideration in evaluating the relative merit of competing theories.</p><p>We introduce and investigate fit propensity using several examples, including investigation of the Rosenberg Self Esteem Scale. These investigations reveal important caveats in evaluating model fit and multimodel inference. First, they make clear that model fit alone is not sufficient to select between competing models-fit propensity also needs to be considered. Second, they reveal that fit indices, particularly RMSR and CFI, evaluated in isolation can be misleading. For example, in the RSES example, CFI was found to fit a large percentage of random correlation matrices -as high as 80% in some cases. Finally, this investigation provides a replication of <ref type="bibr" target="#b28">Preacher's (2006)</ref> original findings regarding fit propensity, extending these beyond positive correlation matrices. These examples also illustrate the usefulness of the ockhamSEM package. The package is intended to support researchers in considering the fit propensity of their SEMs, but also support applied researchers and methodologists in further investigating fit propensity itself and refining methods for evaluating fit propensity.</p><p>Several challenges remain that we hope will be addressed by methodological researchers. One practical avenue for refinement is computational complexity. In <ref type="bibr" target="#b28">Preacher's (2006)</ref> original code generating random correlation matrices was a significant computational bottleneck. We solved this problem by using the onion method <ref type="bibr" target="#b14">(Joe, 2006;</ref><ref type="bibr" target="#b17">Lewandowski et al., 2009)</ref>. Model fitting, however, remains computationally intensive, and this problem increases with more variables. Models with more variables may also encounter more estimation problems. Some avenues for solving this problem include integrating our R code with a structural equation modeling program that might fit models faster (e.g., <ref type="bibr" target="#b1">Bentler, 2006;</ref><ref type="bibr">L. K. Muthèn &amp; Muthèn, 1998</ref><ref type="bibr" target="#b2">-2010;</ref><ref type="bibr" target="#b22">Neale et al., 2016)</ref>. OpenMx may be the most promising alternative as it also allows access to optimizers that better overcome local optimum or automate attempts at different starting values.</p><p>Another important area of further research is constraints on the space of data.</p><p>Example B reveals how restricting the data space to only positive correlations versus allowing positive and negative correlations can affect fit propensity. Ideally the data space could be restricted based on the universe of possible data for a particular research question. In future research, we hope to investigate the generation of random correlation matrices from specific data spaces for a fixed number of factors (where the number of factors is less than the number of items), or from the entire data space under a particular theoretical model of interest. <ref type="bibr" target="#b16">Lai et al. (2017)</ref> provided an initial attempt at something similar, but their approach is not guaranteed to generate uniformly from the entire data space under any given model. Additional tuning parameters are available under <ref type="bibr" target="#b17">Lewandowski et al. (2009)</ref>, but are challenging to translate for the applied researcher.</p><p>As our illustrations reveal, fit propensity and number of parameters should be interpreted independently when assessing parsimony. Researchers can only attribute the difference in fit propensity to model specification, or make general statements about types of model specifications and their relative fit propensity when number of parameters are the same. For instance, Examples 1 and 2 illustrate cases where fit propensity is different even though competing models have the same number of estimated parameters. This will of course not always be the case in the real world, for example, when assessing two theoretically derived model specifications, as is the case with the final RSES example.</p><p>Assessing fit propensity gives us another tool for claiming parsimony, even making the case for a model not only having fewer parameters, but also higher fit propensity <ref type="bibr" target="#b5">(Bonifay &amp; Cai, 2017;</ref><ref type="bibr" target="#b25">Pearl &amp; Verma, 1995)</ref>. For example, for some indices, the most unrestricted RSES model did not have the highest fit propensity. It is also not easy to separate the of observed variables from 3 to approximately 16.</p><p>Our modifications of the code included an increase to a default of 5 million iterations for the MCMC algorithm. Parallel processing can be used by creating m independent chains for generating correlation matrices. The total number of iterations is held constant where possible by dividing the total number of iterations and draws equally among the m chains. In the case of many processing cores, this could lead to very few iterations per chain. To prevent this, a minimum number of iterations per chain is set at 10,000.</p><p>In both cases, these options are modifiable by passing a list to an additional argument, mcmc.args, and documentation on possible options is provided in the ockhamSEM package. <ref type="bibr" target="#b17">Lewandowski et al. (2009)</ref> introduced the ability to generate correlation matrices with the vine and onion methods, which are faster than the MCMC algorithm. The MCMC algorithm may still generate many correlation matrices that must be discarded due to lack of positive definiteness. The vine method is based on work by <ref type="bibr" target="#b14">Joe (2006)</ref>, in which partial correlations are generated from a linearly transformed Beta distribution and transformed into product moment correlations. The computations involved can be illustrated using C-vines, which define the dependency structure among the variables using a graphical model. We do not pursue the vine method further due to the need to further study involved tuning parameters that may affect the space for the randomly generated matrices. The method we pursue in the current paper is the onion method which allows uniform sampling "over the space of correlation matrices" (p. 1998). The onion method constructs random correlation matrices recursively, starting with a single dimension and adding additional dimensions in later steps. <ref type="bibr" target="#b17">Lewandowski et al. (2009)</ref> provide a detailed description of the method as it relates to elliptical distributions. Either approach is computationally fast, and these authors report generation of many (5,000) large correlation matrices (e.g., 80 × 80), in only a few seconds (using compiled C code) or a minute or two (using Matlab). In the present application, we use the clusterGeneration package <ref type="bibr" target="#b29">(Qiu &amp; Joe, 2015)</ref>. As neither method requires iterations as does MCMC, parallel processing can be easily conducted by dividing the number of generated correlation matrices among m processing cores.</p><p>While we expect that most applications using the onion method will use correlation matrices generated as-is, we have also implemented the following ad-hoc procedure for restricting correlation matrix generation to the space of all positive correlations. Let R be a generated correlation matrix. To ensure all positive correlations, we compute a new correlation matrix by R = .5(R + 1), where 1 is a matrix of 1's of conformable dimensions.</p><p>We offer no proof at the moment that this results in uniform sampling from this data space, however, we note that this approach in many cases results in similar conclusions regarding fit propensity as the MCMC algorithm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>model. The original article primarily considered aforementioned fit indices that make adjustments based on degrees of freedom or the number of estimated parameters: TLI, CFI, RMSEA, AIC, and BIC. The only other information regarding model fit are the chi-square test of fit, and root mean square residuals (RMSR) -a transformation of the difference between sample covariances and recovery of covariances by the model. In all cases, there is either no adjustment for parsimony or only a coarse-grained adjustment for degrees of freedom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>debate around the RSES and what a study of fit propensity can provide. The first example is fully illustrated in-text with complete R code. The code for additional examples is available in the Supplementary Materials.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: ECDF plots comparing fit propensity of Models 1A and 2A</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: ECDF plots comparing fit propensity of Models 1B and 2B</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>TLI and RMSEA tend to have similar patterns of results to each other. Almost no replications are in the range of what is usually considered acceptable fit, and models are ordered in a non-intuitive way: The bifactor model with correlated method factors had the best fit propensity, followed by the bifactor model, correlated residual model, and finally the one factor model. Thus, the ordering of fit propensity is not in line with the df or number of estimated parameters in that the correlated residual model did not have the best fit propensity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: ECDF plots comparing fit propensity of Models 1C, 2C, 3C, and 4C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Euler plot for TLI at cutoff=.5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Rosenberg Self-Esteem Model Fit    </figDesc><table><row><cell>Model</cell><cell>χ 2</cell><cell cols="3">d f TLI CFI RMSEA AIC</cell><cell>BIC</cell><cell>SIC RMSR</cell></row><row><cell cols="3">1. Correlated Residual 60.59 16 0.97 0.99</cell><cell>0.05</cell><cell cols="2">26343 26589 26621</cell><cell>0.02</cell></row><row><cell>2. Bifactor</cell><cell cols="2">154.88 25 0.94 0.97</cell><cell>0.07</cell><cell cols="2">26437 26638 26652</cell><cell>0.03</cell></row><row><cell cols="3">3. Correlated Bifactor 135.09 24 0.95 0.97</cell><cell>0.06</cell><cell cols="2">26413 26619 26632</cell><cell>0.02</cell></row><row><cell>4. Single Factor</cell><cell cols="2">872.91 35 0.72 0.78</cell><cell>0.15</cell><cell cols="2">27346 27497 27508</cell><cell>0.08</cell></row><row><cell cols="2">propensity in model selection.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Overview of Examples</figDesc><table><row><cell cols="3">Example # Models Model Description</cell><cell>Main Purpose/Illustrated Features</cell></row><row><cell>A</cell><cell>2</cell><cell>Two 3-variable mod-</cell><cell>Basic use of code, algorithms for correla-</cell></row><row><cell></cell><cell></cell><cell>els</cell><cell>tion matrix generation, parallel process-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>ing, equal df models, empirical ECDF</cell></row><row><cell></cell><cell></cell><cell></cell><cell>plots, quantiles</cell></row><row><cell>B</cell><cell>2</cell><cell>Factor and simplex</cell><cell>Positive vs. negative correlations, equal</cell></row><row><cell></cell><cell></cell><cell>models</cell><cell>df models, model convergence</cell></row><row><cell>C</cell><cell>4</cell><cell>Four RSES Models</cell><cell>Other fit indices (CFI, RMSEA, TLI), Eu-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>ler plots, saving of correlation matrices</cell></row><row><cell></cell><cell></cell><cell></cell><cell>and fitted models</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>The remaining arguments must be named and are only required for taking explicit control over correlation matrix generation and saving of output.The fit.measure argument accepts a character vector that indicates what fit indices will be saved. Anything that matches named output from the fitMeasures command</figDesc><table /><note><p>from lavaan can be used. Users are encouraged to run this command on already fitted models to see what available fit indices are possible (e.g., fitMeasures(mod1a.fit)).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Table 1 has been suggested by others (Bonifay &amp; Cai,</figDesc><table><row><cell>4</cell></row><row><cell>Total</cell></row><row><cell>3</cell></row><row><cell>Figure 8: Euler plot for chi-square test at cutoff=3000</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>With one residual fixed to zero for identification.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>To account for ordered categorical data, maximum likelihood with robust corrections (i.e., estima-tor="MLR") was employed here and in the original paper.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>We thank Kris Preacher for graciously providing us this FORTRAN code, which also appears in his dissertation.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Different SEM program with different default estimation options, different handling of non-converging models (lavaan does not allow calculation of some fit indices), etc.<ref type="bibr" target="#b28">Preacher (2006)</ref> also used ordinary least squares (minimizing the square of the residuals) for estimation, whereas we used maximum likelihood. For this paper, we used lavaan version 0.6-5 and R version 3.6.0.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>https://github.com/falkcarl/ockhamSEM</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>Another viable alternative involves generating data from the true models for 1A and 2A, such as with lavaan's simulateData function.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>Which is how we added all of the plot titles, combined multiple plots into a single Figure, customized axis dimensions and labels, and so on in the present manuscript.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7"><p>Although K-S could also yield a p-value, this value would largely be dependent on the number of replications chosen for the fit propensity analysis.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_8"><p>As a small aside, proper examination of model nesting is contingent upon good starting values and successful estimation. For example, lavaan's defaults for starting values can sometimes converge on a local optimum and thereby yield a higher chi-square value even for a more general model. Should the researcher wish to examine particular replications, randomly generated correlation matrices and fitted models can be saved as lists to the res.rses object.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_9"><p>Like AIC and BIC, SIC is computed in part from the negative log-likelihood, but makes an adjustment based on the log of the determinant of the information matrix for the item parameters. Thus, more parameters may lead to a greater adjustment, but to the extent that parameter estimates are asymptotically correlated the adjustment may be less.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>effects on fit propensity due to the number of estimated parameters from the configural (or functional) form of the model. For instance, even though TLI, CFI, and RMSEA make some adjustment for df, they yielded different conclusions in the RSES example.</p><p>Beyond this tutorial, some researchers may desire additional reading on the background literature that gave rise to fit propensity and its relation to other fields. To briefly elaborate, the minimum description length (MDL; <ref type="bibr" target="#b34">Rissanen, 1978)</ref> principle is one key concept in information theoretic perspectives regarding model fit (e.g., see <ref type="bibr" target="#b4">Bonifay, 2015)</ref> and is often used in cognitive, computer science, and machine learning. MDL considers the data to be composed of both noisy and systematic components. The goal is often to find a way to encode the sytematic part in such a way that both systematic (i.e., model) and noisy parts (i.e., remaining error) can be most concisely encoded. Thus, MDL formalizes Occam's razor and the tradeoff between a complicated model (i.e., not concisely describing the systematic part) and poor model fit (i.e., too much remaining error to describe). Importantly, the MDL perspective does not require that there is a "true" population model. However, it is often used for inductive inference as the model that allows description of the data in the most concise manner is often one that allows us to learn much from the data (it is useful) and should be considered the best model.</p><p>Researchers wishing to have a better understanding of these concepts or indices more directly derived from MDL (such as normalized maximum likelihood) are referred to resources that we believe are accessible in part by focusing on such concepts within SEM and IRT frameworks <ref type="bibr" target="#b4">(Bonifay, 2015;</ref><ref type="bibr" target="#b5">Bonifay &amp; Cai, 2017;</ref><ref type="bibr">Preacher, 2005</ref><ref type="bibr" target="#b28">Preacher, , 2006))</ref>.</p><p>While there are practical considerations in evaluating fit propensity for model selection, it is clear that fit propensity cannot simply be ignored-parsimony is a crucial aspect of evaluating theories. That a model better fits the right data is insufficient evidence if the model also fits the wrong data. We hope to motivate researchers to always consider parsimony and fit propensity and provide them with the tools to do so.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Generation of Random Correlation Matrices</head><p>The original FORTRAN code for the MCMC algorithm was provided by Kristopher <ref type="bibr" target="#b27">Preacher (2003)</ref> and ported to R and modified slightly by the authors. Let r k be a p(p -1)/2 vector of correlations at iteration k, where p is the number of observed variables. In brief, this approach begins the MCMC chain with the correlation matrix set to an identity matrix, (i.e., r 0 = 0). 14 Candidate draws, are computed by r k+1 = r k + γz, where γ is a step size, and z = t 1/p x √ x x</p><p>, with x and t randomly drawn at each iteration from an independent normal distribution, x ∼ N p (0, I), and uniform distribution, t ∼ unif(0, 1). Candidate draws are only rejected if they result in a non-positive-definite matrix, or if correlation values exceed allowable values (i.e., within ±1). In order to reduce these possibilities with large correlation matrices, smaller step sizes are required, which in turn then requires more iterations between draws to reduce autocorrelations.</p><p>That is, as in typical MCMC applications a number determines thinning -or the number of iterations between saving random correlation matrices -and only a subset of iterations (e.g., n = 10, 000 out of 200, 000) are saved. The step size (from .56 to .1) and number of iterations (from 200,000 to 10 million) are pre-set under the original algorithm for a range 14 Or a matrix with .5 correlations if only positive correlations are desired, as in the original code.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Comparative fit indexes in structural models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.107.2.238</idno>
		<ptr target="http://doi.org/10.1037/0033-2909.107.2.238" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="238" to="246" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">EQS 6 structural equations program manual</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Multivariate Software Inc</publisher>
			<pubPlace>Encino, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Testing model nesting and equivalence</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Satorra</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0019625</idno>
		<ptr target="http://doi.org/10.1037/a0019625" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="123" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Eight myths about causality and structural equation models</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-94-007-6094-3_15</idno>
		<ptr target="http://doi.org/10.1007/978-94-007-6094-3_15" />
	</analytic>
	<monogr>
		<title level="m">Handbook of causal analysis for social research</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Morgan</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht; Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="301" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An integrative framework of model evaluation</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Bonifay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<pubPlace>Los Angeles</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Psychology, University of California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the complexity of item response theory models</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Bonifay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cai</surname></persName>
		</author>
		<idno type="DOI">10.1080/00273171.2017.1309262</idno>
		<ptr target="http://doi.org/10.1080/00273171.2017.1309262" />
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="465" to="484" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Three concerns with applying a bifactor model as a structure of psychopathology</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Bonifay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Psychological Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="184" to="186" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Burnham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<title level="m">Model selection and multimodel inference: A practical information-theoretic approach</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Answering ordinal questions with ordinal data using ordinal statistics</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cliff</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15327906mbr3103_4</idno>
		<ptr target="http://doi.org/10.1207/s15327906mbr3103_4" />
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="331" to="350" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<title level="m">Statistical power analysis for the behavioral sciences</title>
		<meeting><address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Cross-validation of covariance structures. Multivari-ate Behavioral Research</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cudeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="147" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Extending structural analyses of the Rosenberg self-esteem scale to consider criterion-related validity: Can composite self-esteem scores be good enough</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Donnellan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Ackerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brecheen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality Assessment</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="169" to="177" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Representing general theoretical concepts in structural equation models: The role of composite variables</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Grace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10651-007-0047-7</idno>
		<ptr target="http://doi.org/10.1007/s10651-007-0047-7" />
	</analytic>
	<monogr>
		<title level="j">Evironmental and Ecological Statistics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="191" to="213" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Model selection and the principle of minimum description length</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1198/016214501753168398</idno>
		<ptr target="http://doi.org/10.1198/016214501753168398" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="746" to="774" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generating random correlation matrices based on partial correlations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Joe</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmva.2005.05.010</idno>
		<ptr target="http://doi.org/10.1016/j.jmva.2005.05.010" />
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2177" to="2189" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">semTools: Useful tools for structural equation modeling</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Jorgensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pornprasertmanit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Schoemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=semTools" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Graphical displays for understanding SEM model similarity</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Levy</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2017.1334206</idno>
		<ptr target="http://doi.org/10.1080/10705511.2017.1334206" />
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="803" to="818" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generating random correlation matrices based on vines and extended onion method</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lewandowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kurowicka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Joe</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmva.2009.04.008</idno>
		<ptr target="http://doi.org/10.1016/j.jmva.2009.04.008" />
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="1989">2009. 1989-2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Goodness of fit in confirmatory factor analysis: The effects of sample size and model parsimony</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Marsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Balla</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF01102761</idno>
		<ptr target="http://doi.org/10.1007/BF01102761" />
	</analytic>
	<monogr>
		<title level="j">Quality and Quantity</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="185" to="217" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Muthèn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Muthèn</surname></persName>
		</author>
		<title level="m">Mplus user&apos;s guide (Sixth)</title>
		<meeting><address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Muthèn &amp; Muthèn</publisher>
			<date type="published" when="1998">1998-2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A problem in theory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Muthukrishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="229" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Model evaluation, testing and selection</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Myung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of cognition</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Lamberts</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Goldstone</surname></persName>
		</editor>
		<meeting><address><addrLine>Thousand Oaks, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Sage</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="422" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">OpenMx 2.0: Extended structural equation and statistical modeling</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Neale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Pritikin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zahery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Brick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Kickpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Boker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="535" to="549" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Examining the factor structure of the self-compassion scale in four distinct populations: Is the use of a total scale score justified</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Neff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Whittaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karl</surname></persName>
		</author>
		<idno type="DOI">10.1080/00223891.2016.1269334</idno>
		<ptr target="http://doi.org/10.1080/00223891.2016.1269334" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality Assessment</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="596" to="607" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">RColorBrewer: ColorBrewer palettes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Neuwirth</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=RColorBrewer" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A theory of inferred causation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Verma</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0049-237X(06)80074-1</idno>
		<ptr target="http://doi.org/https://doi.org/10.1016/S0049-237X" />
	</analytic>
	<monogr>
		<title level="m">Logic, methodology and philosophy of science ix</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Prawitz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Skyrms</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Westerstahl</surname></persName>
		</editor>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="80074" to="80075" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Toward a method of selecting among computational models of cognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Myung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295x.109.3.472</idno>
		<ptr target="http://doi.org/10.1037/0033-295x.109.3.472" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="472" to="491" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The role of model complexity in the evaluation of structural equation models</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Preacher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>The Ohio State University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Quantifying parsimony in structural equation modeling</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Preacher</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15327906mbr4103_1</idno>
		<ptr target="http://doi.org/10.1207/s15327906mbr4103_1" />
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="227" to="259" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">ClusterGeneration: Random cluster generation (with specified degree of separation)</title>
		<author>
			<persName><forename type="first">W</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Joe</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=clusterGeneration" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Scoring and modeling psychological measures in the presence of multidimensionality</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Bonifay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Haviland</surname></persName>
		</author>
		<idno type="DOI">10.1080/00223891.2012.725437</idno>
		<ptr target="http://doi.org/10.1080/00223891.2012.725437" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality Assessment</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="140" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Is the bifactor model a better model or is it just better at modeling implausible responses? Application of iteratively reweighted least squares to the Rosenberg self-esteem scale</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Manslof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Widaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="818" to="838" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Is the bifactor model a better model or is it just better at modeling implausible responses? Application of iteratively reweighted least squares to the rosenberg self-esteem scale</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mansolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Widaman</surname></persName>
		</author>
		<idno type="DOI">10.1080/00273171.2016.1243461</idno>
		<ptr target="http://doi.org/10.1080/00273171.2016.1243461" />
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morizot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The role of the bifactor model in resolving dimensionality issues in health outcomes measures</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="19" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Modeling by shortest data description</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rissanen</surname></persName>
		</author>
		<idno type="DOI">10.1016/0005-1098(78)90005-5</idno>
		<ptr target="http://doi.org/10.1016/0005-1098(78)90005-5" />
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="465" to="471" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Society and the adolescent self-image</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965">1965</date>
			<publisher>Princeton University Press</publisher>
			<pubPlace>Princeton, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">lavaan: An R package for structural equation modeling</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
		<ptr target="http://www.jstatsoft.org/v48/i02/" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Recovering substantive factor loadings in the presence of acquiescence bias: A comparison of three approaches</title>
		<author>
			<persName><forename type="first">V</forename><surname>Savalei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Falk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="407" to="424" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Generalized latent variable modeling: Multilevel, longitudinal, and structural equation models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Skrondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rabe-Hesketh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Chapman; Hall/CRC</publisher>
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Statistically based tests for the number of common factors</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Steiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lind</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980-05">1980. May</date>
			<publisher>Psychometric Society</publisher>
			<pubPlace>Iowa City, IA</pubPlace>
		</imprint>
	</monogr>
	<note>Paper presented at the annual Spring Meeting of the</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A reliability coefficient for maximum likelihood factor analysis</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02291170</idno>
		<ptr target="http://doi.org/10.1007/BF02291170" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Introduction to robust estimation and hypothesis testing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Wilcox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Academic Press</publisher>
			<pubPlace>Boston</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
