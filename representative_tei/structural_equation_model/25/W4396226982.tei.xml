<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robusti cation of Structural Equation Modelling via Global Sensitivity Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-04-29">April 29th, 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alessio</forename><surname>Lachi</surname></persName>
							<email>alessio.lachi@unifi.it</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics</orgName>
								<orgName type="department" key="dep2">Computer Science</orgName>
								<orgName type="institution" key="instit1">Applications &quot;Giuseppe Parenti&quot; (DiSIA)</orgName>
								<orgName type="institution" key="instit2">University of Florence</orgName>
								<address>
									<addrLine>Viale Giovanni Battista Morgagni 59/65</addrLine>
									<postCode>50134</postCode>
									<settlement>Florence</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Epidemiology and Health Research</orgName>
								<orgName type="department" key="dep2">Institute of Clinical Physiology</orgName>
								<orgName type="institution">Italian National Research Council (IFC-CNR)</orgName>
								<address>
									<addrLine>Via Giuseppe Moruzzi 1</addrLine>
									<postCode>56124</postCode>
									<settlement>Pisa</settlement>
									<country>Pisa</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Josep</forename><surname>Llach</surname></persName>
							<email>josep.llach@bsm.upf.edu</email>
							<affiliation key="aff2">
								<orgName type="department">UPF Barcelona School of Management (UPF-BSM)</orgName>
								<orgName type="institution">University Pompeu Fabra of Barcelona</orgName>
								<address>
									<addrLine>Carrer de Balmes</addrLine>
									<postCode>132-134 08008</postCode>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jordi</forename><surname>Perramon</surname></persName>
							<email>jordi.perramon@bsm.upf.edu</email>
							<affiliation key="aff2">
								<orgName type="department">UPF Barcelona School of Management (UPF-BSM)</orgName>
								<orgName type="institution">University Pompeu Fabra of Barcelona</orgName>
								<address>
									<addrLine>Carrer de Balmes</addrLine>
									<postCode>132-134 08008</postCode>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michela</forename><surname>Baccini</surname></persName>
							<email>michela.baccini@unifi.it</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics</orgName>
								<orgName type="department" key="dep2">Computer Science</orgName>
								<orgName type="institution" key="instit1">Applications &quot;Giuseppe Parenti&quot; (DiSIA)</orgName>
								<orgName type="institution" key="instit2">University of Florence</orgName>
								<address>
									<addrLine>Viale Giovanni Battista Morgagni 59/65</addrLine>
									<postCode>50134</postCode>
									<settlement>Florence</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Florence Center for Data Science</orgName>
								<orgName type="institution">University of Florence</orgName>
								<address>
									<addrLine>Viale Giovanni Battista Morgagni 59</addrLine>
									<postCode>50134</postCode>
									<settlement>Florence</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><surname>Saltelli</surname></persName>
							<email>andrea.saltelli@bsm.upf.edu</email>
							<affiliation key="aff2">
								<orgName type="department">UPF Barcelona School of Management (UPF-BSM)</orgName>
								<orgName type="institution">University Pompeu Fabra of Barcelona</orgName>
								<address>
									<addrLine>Carrer de Balmes</addrLine>
									<postCode>132-134 08008</postCode>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robusti cation of Structural Equation Modelling via Global Sensitivity Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-04-29">April 29th, 2024</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.21203/rs.3.rs-4328011/v1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Structural equations modelling</term>
					<term>Global sensitivity analysis</term>
					<term>Uncertainty modelling</term>
					<term>Uncertainty quanti cation</term>
					<term>Sobol indexes</term>
					<term>Robusti cation</term>
					<term>Bootstrap Structural equations modelling</term>
					<term>Global sensitivity analysis</term>
					<term>Uncertainty modelling</term>
					<term>Uncertainty quantification</term>
					<term>Sobol indexes</term>
					<term>Robustification</term>
					<term>Bootstrap</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a method for enhancing the robustness of structural equation modelling, a multivariate statistical analysis technique employed for analyzing causal relationships among different aspects of given phenomena. This enhancement is achieved through the integration of global sensitivity analysis, which assesses how uncertainties in model output can be attributed to various sources of input uncertainty. The robustification process involves several key steps, including bootstrapping evidence, error propagation, and uncertainty quantification. This method introduces a novel approach termed "modelling of the modelling process". To illustrate this approach, we apply it to a previously published test case where structural equation modelling is used to relate the impact of artificial intelligence adoption on employee engagement. By quantifying the uncertainty inherent in the inference from our test case, this procedure generates a more robust and defensible inference. The performed procedure significantly enhances the robustness of the results derived from the test case.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Background</head><p>The purpose of this paper is to propose a robustification of structural equation modelling (SEM), a key method used in the social sciences <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>. The robustification is achieved by modelling the assumption used in the data analysis, by allowing these assumptions to vary so that an uncertainty and sensitivity analysis can be performed on these variations. The approach, proposed by Piano et al. <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, is known as "modelling of the modelling process". It is based on subjecting the various stages of a model-building process to a coordinated and simultaneous variation in the modelling assumptions. This generates an error propagation analysis (uncertainty analysis, UA), followed by a global sensitivity analysis (GSA) Saltelli et al. <ref type="bibr" target="#b5">[6]</ref>. The key steps of the analysis are the data selection and the attribution of items to latent variables. The mechanic of the analysis entails the use of triggers that are selected at runtime, leading to different paths being taken by the analysis in different simulations. The input data are also bootstrapped, as proposed by Tibshirani and Efron <ref type="bibr" target="#b6">[7]</ref>, in each simulation, following the philosophy of "bootstrapping of the modelling process" in Chatfield <ref type="bibr" target="#b7">[8]</ref>. The relevance of this analysis is revealed by experiments such as that discussed by Breznau, N., et al. <ref type="bibr" target="#b8">[9]</ref>, where many teams (73 in fact) were given the same data and returned wildly different conclusion, non only on the value of a statistical effect, but also on its sign. What made the experiment of Breznau, N., et al. <ref type="bibr" target="#b8">[9]</ref> relevant for modellers and statisticians is that the teams differed in their work in apparently inconsequential aspects of the treatment of the data, and yet the combined effects of these modelling choices resulted dramatic. An author, commenting on this experiment, talks of "A universe of uncertainty hiding in plain sight" Engzell <ref type="bibr" target="#b9">[10]</ref>. Statistician Andrew Gelman <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> compares the statisticians running their analysis to subjects walking through a "garden of forking path" -Gelman makes reference here to a short fiction of writer Jorge Luis Borges <ref type="bibr" target="#b12">[13]</ref>.</p><p>GSA examines model output sensitivity when varying all uncertain inputs across their entire range simultaneously <ref type="bibr" target="#b13">[14]</ref>, helping modellers in exploring the impact of assumptions, identifying influential inputs, simplifying problems, and supporting model-based decisionmaking <ref type="bibr" target="#b14">[15]</ref>. While GSA is customarily used by sampling uncertain factors from distribution derived from the calibration or by experts, GSA can also sample assumptions made in the course of the analysis, thus simulating the present of different teams tackling the same problem. In other words, in the context of the present work, our GSA corresponds to a stroll in the garden of forking paths.</p><p>The most widespread GSA algorithms are variance-based methods, which decompose the output variance of a k-dimensional model into contributions from individual inputs, pairs of inputs, and so on with terms of increasing dimensionality till a k-th term, see <ref type="bibr" target="#b5">[6]</ref> for an introduction. The analysis leads to the estimation of so-called Sobol' indices <ref type="bibr" target="#b15">[16]</ref>.</p><p>Other GSA procedures are also available. When the output has extreme values, momentindependent methods may be preferred over variance-based methods because they do not assume normality or finite output variance <ref type="bibr" target="#b16">[17]</ref>. Another approach is the PAWN index, which differs from other moment-independent approaches in its reliance on cumulative distribution functions to characterize the output variance <ref type="bibr" target="#b17">[18]</ref>. The use of VARS and Shapley effects has also become more widespread in recent years <ref type="bibr" target="#b18">[19]</ref>. VARS are based on the use of variogram and covariogram functions to characterize the variability in the output at different scales. Instead, Shapley effects rely on Shapley values, which represent the average marginal contribution of a given feature/factor across all possible feature/factor combinations <ref type="bibr" target="#b19">[20]</ref>. Also, the concept of Kernel-based dependence has spread in recent years. This concept is based on the definition of the maximum mean discrepancy between the unconditional and conditional output distributions <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>. Despite this abundance of methods, the uptake of GSA in mathematical modelling in still in progress. "One variable at a time" (OAT) procedures, whereby individual factors are perturbed while keeping the other constants, are still very popular, due to their ease of interpretation <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b22">23]</ref>. The problem with OAT methods is that they do not explore efficiently the space of the input and do not capture interaction effects <ref type="bibr" target="#b23">[24]</ref>. For example, Lee and Wang <ref type="bibr" target="#b24">[25]</ref> proposes for structural equation modelling a sensitivity analysis based on first-order derivatives, which, however, only captures the local influence of small perturbations. Our contribution therefore provides modellers engaged in SEM and similar methods with a direct GSA tool, which allows them to explore the robustness of their inference to change in the assumptions. The proposed procedure is able to detect more influential parameters/assumptions as well as their interactions with one another.</p><p>The present investigation concerns an existing test case related to artificial intelligence (AI) adoption and its relationship with employee engagement explored in Theben et al. <ref type="bibr" target="#b25">[26]</ref>. Specifically, the test case considered here involves the mediating role of training provision in the relationship between AI adoption and three dimensions of employee engagement, vigour, dedication, and absorption, considering job complexity as a critical factor.</p><p>Our replication-cum-uncertainties of the analysis in Theben et al. <ref type="bibr" target="#b25">[26]</ref> simultaneously tests whether the original inference is reproduced while illustrating the applicability of the method to SEM in general. The present work feeds into the current debate over the fragility of model-based inference to modelling assumptions discussed above in relation to Breznau, N., et al. <ref type="bibr" target="#b8">[9]</ref>, Gelman and Loken <ref type="bibr" target="#b10">[11]</ref>; see also Saltelli and Di Fiore <ref type="bibr" target="#b26">[27]</ref> for a broader discussion of the topic in the context of modelling.</p><p>Our analysis broadly confirms the narrative of Theben et al. <ref type="bibr" target="#b25">[26]</ref> with some relevant and interesting differences in specific findings. In this paper, we solidify the non-significant or negative association between AI adoption and the three dimensions of employee engagement, as well as the significant association between the three dimensions and both complexity and training. The GSA also offers a richer insight into the relative influence of the items on the latent variables.</p><p>After a brief introduction to the data sources used in the analysis (Section 2.1), we describe the SEM approach (Section 2.2) and illustrate the uncertainty propagation of the error (Section 2.3). We then report our findings (Section 3), discuss them highlighting the merits and limitations of the study and finally draw our conclusions (Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Structure of the data</head><p>The data collection used in Theben et al. <ref type="bibr" target="#b25">[26]</ref> was conducted in November 2022. The questionnaire was structured into two sections. The first section included queries related to the profile of the respondent. The second section contained questions related to the respondents' perception of the training offered by their companies and to what extent the respondents felt engaged with their jobs. For all the variables, the authors in Theben et al. <ref type="bibr" target="#b25">[26]</ref> used a seven-level Likert scale <ref type="bibr" target="#b27">[28]</ref>. The initial sample size included 302 individuals. A key question concerned the respondent's opinion on whether AI adoption was strategic for the organization. Retaining only participants who considered AI adoption strategic for their companies, a sample of 211 employees was obtained. The items used in Theben et al. <ref type="bibr" target="#b25">[26]</ref> are listed in the Table <ref type="table" target="#tab_1">1</ref>.</p><p>An exploratory factor analysis (EFA), as proposed by <ref type="bibr" target="#b28">[29]</ref>, was performed in <ref type="bibr" target="#b25">[26]</ref> to check the psychometric validity of the questionnaire and of the items related to the dimensions. Exploratory factor analysis is a statistical technique used to reduce data to a smaller set of summary variables and explore the underlying theoretical structure <ref type="bibr" target="#b29">[30]</ref> of the phenomenon being considered. EFA tries to uncover the underlying structure of a relatively large set of variables <ref type="bibr" target="#b30">[31]</ref>. Five independent EFA, one for each class of question reported in Table <ref type="table" target="#tab_1">1</ref>, was done to identify the underlying relationships between measured variables <ref type="bibr" target="#b31">[32]</ref>.</p><p>We identify the following set of latent variables, constructed under a battery of related items as follows:</p><p>• a latent variable that measures the AI adoption in a company and is defined by four items {14 • a latent variable that measures the work complexity of a company and is defined on only one item {16 1 }. The reliability of these five dimensions was additionally verified through Cronbach's alpha <ref type="bibr" target="#b32">[33]</ref>. More information on the composition of the latent variables and on the items composing them is reported in Theben et al. <ref type="bibr" target="#b25">[26]</ref>. In each case, each item defines one aspect of its corresponding latent variable. My work may be performed by someone with variable compensation such as compensation based on the performance or results of the work 14 <ref type="bibr" target="#b2">3</ref> Payment for my work can be made on the basis of previously agreed results 14 <ref type="bibr" target="#b3">4</ref> My work can be done by someone who is paid by the hour 14 <ref type="bibr" target="#b4">5</ref> My work can be completed for a lower rate of pay Vigour aspect 17 1 I feel full of energy at work 17 <ref type="bibr" target="#b1">2</ref> I feel strong and energetic in my work 17 <ref type="bibr" target="#b2">3</ref> When I get up in the morning I feel like going to work 17 <ref type="bibr" target="#b3">4</ref> I can continue to work for long periods 17 <ref type="bibr" target="#b4">5</ref> I am very persistent in my work 17 <ref type="bibr" target="#b5">6</ref> Even when things don't go well, I keep working</p><formula xml:id="formula_0">Dedication aspect 17 7</formula><p>My work is full of meaning and purpose 17 <ref type="bibr" target="#b7">8</ref> I am enthusiastic about my work 17 <ref type="bibr" target="#b8">9</ref> My work inspires me 17 <ref type="bibr" target="#b9">10</ref> I am proud of the work I do 17 <ref type="bibr" target="#b10">11</ref> My work is challenging Absorption aspect 17 <ref type="bibr" target="#b11">12</ref> Time flies when I'm working 17 <ref type="bibr" target="#b12">13</ref> When I am working, I forget everything that is going on around me 17 <ref type="bibr" target="#b13">14</ref> I am happy when I am absorbed in my work 17 <ref type="bibr" target="#b14">15</ref> I am immersed in my work 17 <ref type="bibr" target="#b15">16</ref> I let myself be carried away by my work 17 <ref type="bibr" target="#b16">17</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I find it difficult to disconnect from my work</head><p>Training aspect 20 <ref type="bibr" target="#b0">1</ref> The training received is of high quality 20 <ref type="bibr" target="#b1">2</ref> Training is constantly reviewed and updated to meet the requirements of the changing work environment 20 <ref type="bibr" target="#b2">3</ref> Experienced employees receive regular training and training updates 20 <ref type="bibr" target="#b3">4</ref> Experienced employees receive training when new initiatives are launched 20 <ref type="bibr" target="#b4">5</ref> Employees receive sufficient training opportunities 20 <ref type="bibr" target="#b5">6</ref> Employees receive training on a systematic basis 20 <ref type="bibr" target="#b6">7</ref> Newly hired employees receive adequate training 20 <ref type="bibr" target="#b7">8</ref> The training provided in my organization exceeds the skill requirements to perform my job duties</p><p>Complexity aspect 15 1 I am assigned extraordinary and particularly difficult tasks</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Structural equations modelling</head><p>SEM is a well-established statistical method for investigating complex relationships between latent constructs. SEM's ability to simultaneously estimate direct, indirect (e.g., mediating), and moderating effects of multiple constructs while accounting for measurement error has enabled researchers to examine relationships that would otherwise be difficult to disentangle <ref type="bibr" target="#b33">[34]</ref>. SEM has two main approaches, covariance-based SEM (CB-SEM) and partial least squares-based SEM (PLS-SEM). Schuberth et al. <ref type="bibr" target="#b34">[35]</ref> provide a revision on the structural parameters of SEM under the two approaches. Theben et al. <ref type="bibr" target="#b25">[26]</ref> applied the CB-SEM approach using the software EQS 6.4 <ref type="bibr" target="#b35">[36]</ref> based on the maximum likelihood estimation method.</p><p>According to Kaplan <ref type="bibr" target="#b36">[37]</ref>, SEM can be defined as a class of methodologies aimed at testing hypotheses about the means, variances, and covariances of observed data in terms of a smaller number of structural parameters defined by a hypothesized underlying model. Thus, SEM, often called linear structural relations models, tries to explain relations between latent variables. The main advantage of SEM is its flexibility to deal not only with a single simple or multiple linear regression but also with several equations simultaneously as discussed in Nachtigall et al. <ref type="bibr" target="#b37">[38]</ref>.</p><p>Let us denote with:</p><p>• M = (M AI adoption , M vigour , M dedication , M absorption , M training , M complexity ) the matrix of data used in the analysis of Theben et al. <ref type="bibr" target="#b25">[26]</ref>; </p><formula xml:id="formula_1">• X = (X 1 , X 2 , X 3 ) = (M complexity , M training , M AI adoption ) represent the matrix of indepen- dent variable; • Y = (Y 1 ,Y 2 ,Y 3 ,Y 4 ) = (M</formula><formula xml:id="formula_2">β 3 γ 3 ω 3 α 3 γ 2 ω 2 α 2 γ 1 ω 1 α 1</formula><p>Fig. <ref type="figure">1</ref>: Graphical representation of the SEM of Theben et al. <ref type="bibr" target="#b25">[26]</ref>.</p><p>The model defined in Theben et al. <ref type="bibr" target="#b25">[26]</ref>, graphically represented in Figure <ref type="figure">1</ref>, is based on the following system of equations:</p><formula xml:id="formula_3">         Y 1 = β 3 X 3 Y 2 = γ 1 X 1 + γ 2 X 2 + γ 3 X 3 Y 3 = ω 1 X 1 + ω 2 X 2 + ω 3 X 3 Y 4 = α 1 X 1 + α 2 X 2 + α 3 X 3 .</formula><p>(1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Uncertainty assessment</head><p>In statistical modelling, uncertainty assessment is the process of quantifying the uncertainty associated with model assumptions, parameters, and predictions. Uncertainty arises from various sources, such as measurement errors, sampling variability, model misspecification, and unobserved variables.</p><p>Usually, a confidence interval for the inference is estimated, that provides range of plausible values for the parameter or prediction, along with a level of confidence in the interval's coverage, based on some parametric assumption distributions. If estimating confidence intervals is difficult, we can base our inference on the bootstrap procedure. The basic idea behind the bootstrap procedure proposed by Tibshirani and Efron <ref type="bibr" target="#b6">[7]</ref> is to create many random samples, with replacements, from the original sample of data. Each of these resamples has the same size as the original sample, and they are drawn independently from the original data. A statistic of interest, such as the mean or the standard deviation, is then calculated for each of these resamples. By repeating this resampling and calculation process many times, a distribution of the statistic can be estimated. This distribution represents the variability of the statistic and can be used to construct confidence intervals or to perform hypothesis tests.</p><p>It is appropriate in modelling studies to consider multiple candidate models that differ in their assumptions or specifications. A particularly radical version of this approach is the "modelling of the modelling process" proposed by Piano et al. <ref type="bibr" target="#b3">[4]</ref>. This exploration can be performed in a Monte Carlo framework, as discussed in Kroese et al. <ref type="bibr" target="#b38">[39]</ref>, by defining random "triggers" that determine the model to be followed in each simulation. In this way, we can combine the predictions from these models while accounting simultaneously for the uncertainty associated with each model's parameters.</p><p>UA works in tandem with sensitivity analysis, which involves examining the relative importance of model inputs or assumptions in determining the uncertainty in the model outputs. This can help identify which model assumptions are most critical for the results and quantify the impact of potential sources of uncertainty, as discussed by Leite et al. <ref type="bibr" target="#b39">[40]</ref>. We investigated the influence of each trigger on the model output, which in this case is represented by the estimates of the coefficients of the SEM, through the total sensitivity index S T i provided by GSA, a variance-based approach explained in Saltelli et al. <ref type="bibr" target="#b5">[6]</ref>.</p><p>Given K Z mutually independent inputs (Z 1 , Z 2 , ..., Z i , ..., Z K Z ) and a model which, given the inputs, returns K W outputs (W 1 ,W 2 , ...,W j , ...W K W ), this approach quantifies the relative importance of each input to the model's outcomes by propagating uncertainty from the inputs to the outputs and computing variance indices. Then we calculated, for each input Z i , where i ∈ {1, 2, ..., K Z }, the so-called total variance index, which S tot i, j measures the overall effect of the i-th input on the output W j , where j ∈ {1, 2, ..., K W }, including all the interactions of Z i with the other inputs. This index corresponds to the expected variance of W j that would be left on average when all the parameters but Z i , Z ∼i , are fixed:</p><formula xml:id="formula_4">S tot i, j = E Z∼i (Var Z i (W j |Z ∼i )) Var(W j ) .<label>(2)</label></formula><p>The "on average" in the preceding sentence refers to the fact that S tot i, j is averaged over all possible combinations of value fixed for the set of Z ∼i as discussed <ref type="bibr" target="#b5">[6]</ref>. A total variance index close to zero indicates that the parameter Z i does not influence W j . Instead, a large total variance index indicates that the parameter does have an impact on them. The estimation procedure for S tot i, j is given in <ref type="bibr" target="#b23">[24]</ref>. The focus of this paper is to test the robustness of the SEM-based latent variables using GSA and the "Modelling of the modelling process" just described. The approach includes adding or removing items to the composition of various latent variables and studying how these different compositions of latent variables impact the estimation of the SEM coefficients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model estimates</head><p>As a first step of our analysis, we compared, in the following Table <ref type="table">2</ref> and Figure <ref type="figure" target="#fig_1">2</ref>, model estimates of Equation ( <ref type="formula">1</ref>) provided by asymptotically inference with the confidence intervals derived from bootstrap <ref type="bibr" target="#b6">[7]</ref>.</p><p>Table <ref type="table">2</ref>: Model estimates of Equation (1) provided by asymptotically inference and bootstrap with their 95% percentage confidence intervals (* stands for a pvalue &lt; 0.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coefficient</head><p>Asymptotically Bootstrap  Table <ref type="table">2</ref> shows that central points of model estimates of Equation ( <ref type="formula">1</ref>), with their 95% confidence intervals provided by asymptotically inference are coherent with the one obtained from bootstrap. In general, the dimensions vigour, dedication, and absorption are better explained by the dimension complexity, and the relationship with AI adoption is non-significant. The model shows a significant positive effect of training quality and quantity on engagement, in all three of its dimensions. While higher levels of AI adoption in a company could be associated with lower training quality and quantity, this hypothesis is rejected as the relationship is non-significant. Instead, higher levels of work complexity were associated with higher vigour and absorption but did not show a significant relationship to the dedication dimension of engagement.</p><formula xml:id="formula_5">β</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Counterfactual analysis</head><p>The analysis performed in <ref type="bibr" target="#b25">[26]</ref> considered only individuals who considered AI adoption to be strategic for their companies. As a second step of our analysis, we performed a simple counterfactual analysis to verify the effect of including or not including individuals who consider AI adoption to be not strategic. The following table shows the SEM coefficient estimates produced by considering only individuals who consider AI adoption strategic and only individuals who consider AI adoption to be non-strategic for their companies: Table <ref type="table">3</ref>: Model estimates of Equation (1) provided by asymptotically inference with their 95% percentage confidence intervals. The model estimates compare individuals who considered AI adoption to be and not to be strategic for their companies (* stands for a pvalue &lt; 0.5). The results reported in Table <ref type="table">3</ref> show that the coefficient estimates of the two groups of individuals are very similar. The regression Y 1 = β 3 X 3 remain stable. In the regression Y 2 = γ 1 X 1 + γ 2 X 2 + γ 3 X 3 , we note that the inclusion of individuals who consider AI adoption nonstrategic make the relation with γ 2 non-significative. The regression Y 3 = ω 1 X 1 +ω 2 X 2 +ω 3 X 3 remain stable. In the regression Y 4 = α 1 X 1 + α 2 X 2 + α 3 X 3 , we note that the inclusion of individuals who consider AI adoption non-strategic make the relation with α 2 non-significative. In general, the inclusion of individuals who consider AI adoption non-strategic renders non-significative the relationship with the training dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coefficients</head><p>To better understand whether the assumption of not considering all the data is valid, it is necessary to go through the full uncertainty and sensitivity analysis as described in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Global sensitivity analysis</head><p>After comparing SEM estimates obtained via asymptotically inference and bootstrap and performing the counterfactual analysis, we implement here the third phase of our analysis. First, we propagate uncertainty in the SEM estimates through UA, and then we quantify the error propagation by providing total sensitivity indices of Sobol defined in Section 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Uncertainty analysis</head><p>In Equation ( <ref type="formula">1</ref>) we added as a source of uncertainty random triggers, independent indicator variables (1) that randomly assume a value equal to zero or to one for each item considered in the SEM, to determine whether the item is selected at any given simulation.</p><p>In this way, we define the latent variables as follows:</p><p>• the latent variable AI adoption is defined by {14 At each iteration, we sample randomly different combinations of triggers in an independent way, that leads to an identifiable model. Moreover, we use a trigger 1 Data = {0, 1} to test the data structural assumption used in <ref type="bibr" target="#b25">[26]</ref> to include in the analysis only individuals who consider the AI adoption strategic for their companies. If 1 Data = 0, we include only individuals who consider the AI adoption strategic for their companies, otherwise, we also include individuals who consider AI adoption to be non-strategic for their companies.</p><p>For one thousand iterations, we repeatedly bootstrap both data triggers independently. For each of these combinations, we estimate the SEM. The following table compares the classical confidence interval with our confidence interval that includes these sources of uncertainty, and that, from here on, we call 'plausible interval'.</p><p>Table <ref type="table">4</ref>: Model estimates of Equation ( <ref type="formula">1</ref>) provided by asymptotically inference and Uncertainty analysis with respectively their 95% percentage confidence and plausible intervals (* stands for a pvalue &lt; 0.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coefficient</head><p>Asymptotically (range) Uncertainty (plausible interval) The results in Table <ref type="table">4</ref> show that when a source of uncertainty in the model assumptions is considered, the plausible intervals are bigger than confidence intervals. In general, the central point estimates, given by the median of the distribution of the coefficients for the plausible intervals, remain stable. These results can be interpreted as the a confirmation of the model coefficient estimates provided by the original work of Theben et al. <ref type="bibr" target="#b25">[26]</ref>. More precisely, the regression Y 1 = β 3 X 3 remains quite stable. In the regression Y 2 = γ 1 X 1 + γ 2 X 2 + γ 3 X 3 , we note that the inclusion of a source of uncertainty makes the relation with γ 1 , γ 2 , and γ 3 non-significative. In the regression, Y 3 = ω 1 X 1 + ω 2 X 2 + ω 3 X 3 , the inclusion of a source of uncertainty makes the relation with ω 3 non-significative. The regression Y 4 = α 1 X 1 + α 2 X 2 + α 3 X 3 remain stable. The point of this analysis is that, if the study investigated <ref type="bibr" target="#b25">[26]</ref> resists, as it does, to the modelling of the modelling process, this is a validation of the work done by Theben et al. <ref type="bibr" target="#b25">[26]</ref>. This was not a foregone conclusions as shown by our discussion above of the results in Breznau, N., et al. <ref type="bibr" target="#b8">[9]</ref>.</p><formula xml:id="formula_6">β 3 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Sobol indices</head><p>We calculated the total sensitivity index defined in Equation ( <ref type="formula" target="#formula_4">2</ref>) for each of the coefficients estimated in SEM. Note that from the computational point of view, UA and uncertainty quantification are run simultaneously, so the results of the total index pertain to the same results discussed in the above uncertainty analysis Section 3.3.1.</p><p>For generating total indices, we define a design matrix (D) of dimension n × p. For the Monte Carlo simulation, we used quasi-random numbers, which provide a more efficient exploration of the sample space as suggested in <ref type="bibr" target="#b40">[41]</ref> and <ref type="bibr" target="#b41">[42]</ref>. In D, p represents the number of inputs of the model coming to play into GSA, and n, set to one thousand here, represents the different combinations of model input. More precisely, as defined in Section 3.3.1, we defined twenty triggers, one for each item that composed the latent variable (we do not need a trigger for the complexity dimension because it is composed of a single item), and one trigger for the selection of the data. In summary, we considered the following triggers: {1 14 1 , 1 14 2 , 1 <ref type="bibr" target="#b13">14</ref>  The following table shows for each trigger total sensitivities index calculated on the parameters defined in Equation ( <ref type="formula">1</ref>) estimated considering the source of uncertainty previously defined.</p><p>Note that our procedure of uncertainty propagation samples the triggers as independent from one another, which is an approximation but serve the purpose of testing robustness.</p><p>Table <ref type="table">5</ref>: Total sensitivity indexes S tot i, j for each trigger calculated on the parameters defined in Equation ( <ref type="formula">1</ref>) estimated considering the source of uncertainty defined in Section 3.3.1.</p><p>As we can see from Table <ref type="table">5</ref>, in general, the inclusion of individuals who consider AI adoption to not be strategic inside the analysis has a large impact on the estimation of the coefficient.</p><p>Let us focus on the coefficient dependent on the AI adoption dimension:</p><p>• the estimation of β 3 is more influenced by the presence of item 14 5 in the definition of the dimension AI adoption; • the estimation of γ 3 is more influenced by the presence of item 14 3 in the definition of the dimension AI adoption; • the estimation of ω 3 is more influenced by the presence of item 14 1 in the definition of the dimension AI adoption; • the estimation of α 3 is more influenced by the presence of item 14 1 in the definition of the dimension AI adoption. The other item has a marginal effect in the estimation of regression coefficients dependent on the AI adoption dimension, including item 14 2 , might not even be considered in the definition of the dimension.</p><p>Considering now the coefficient dependent on the complexity dimension:</p><p>• the estimation of γ 1 is more influenced by the presence of item 20 3 in the definition of the dimension training; • the estimation of ω 1 is more influenced by the presence of item 17 8 in the definition of the dimension dedication; • the estimation of α 1 is more influenced by the presence of item 17 14 in the definition of the dimension absorption. The other item has a marginal effect in the estimation of regression coefficients dependent on the complexity dimension.</p><p>Finally, let us give an interpretation of the coefficient dependent on the training dimension:</p><p>• the estimation of γ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and conclusion</head><p>SEM proposed by Bentler <ref type="bibr" target="#b42">[43]</ref>, is a widely used multivariate technique to test relations among observed and latent variables, while PLS-SEM is also quite used, as discussed above. Theben et al. <ref type="bibr" target="#b25">[26]</ref> used CB-SEM. This choice was maintained in the present analysis, which presents a new approach to provide sensitivity analysis on SEM when perturbations in the composition of latent variables are introduced.</p><p>Sensitivity analysis is a general statistical concept to evaluate the stability of estimators concerning parameters and model assumptions, as discussed in Saltelli et al. <ref type="bibr" target="#b5">[6]</ref> and Leamer <ref type="bibr" target="#b43">[44]</ref>. In this paper, the method proposed by Saltelli et al. <ref type="bibr" target="#b44">[45]</ref> is applied to robustify SEM estimates and detect the influential subsets of data or variables that seriously influence the analysis. Quantifying the impact of controlled perturbations to modeling conditions on study results is an important diagnostic tool given its direct implications on the inferences, especially in light of the present discussions on the possible fragility of model-based inference to modeling assumptions, as discussed in, e.g., Gelman and Loken <ref type="bibr" target="#b10">[11]</ref> and in the experiment <ref type="bibr" target="#b8">[9]</ref>.</p><p>As a first step of the analysis, we tested the inclusion of individuals who think that AI adoption is not strategic for their companies has on the coefficient estimates of the model. After bootstrapping the data to estimate the confidence intervals of the coefficients of SEM in Equation ( <ref type="formula">1</ref>), we added triggers as a source of uncertainty while simultaneously bootstrapping the data to insert sample variability in the model estimates. Finally, through GSA, we quantified the error propagation by providing total sensitivity indices defined in Section 2.3 in Equation <ref type="bibr" target="#b1">(2)</ref>.</p><p>The combination of uncertainty and sensitivity analysis presented here represents an attempt to engage with the "modeling of the modeling process" proposed by Piano et al. <ref type="bibr" target="#b3">[4]</ref>.</p><p>The current study substantially confirms the previous research taken as our test case Theben et al. <ref type="bibr" target="#b25">[26]</ref>:</p><p>• AI adoption has a negative and in general non-significant relationship with employee engagement and • the complexity dimension appears to have a positive and significant relationship with these dimensions. The only significant difference we register from Theben et al. <ref type="bibr" target="#b25">[26]</ref> is that the coefficient AI adoption of the regression Y 3 = ω 1 X 1 + ω 2 X 2 + ω 3 X 3 becomes non-significant, as shown in table <ref type="table">4</ref>. Also In the regression Y 2 = γ 1 X 1 + γ 2 X 2 + γ 3 X 3 , we note that the inclusion of a source of uncertainty makes the relation with γ 1 , γ 2 , and γ 3 non-significative.</p><p>The total index provided by GSA gives us a measure defined in [0, 1] to better understand the impact of a single item on the estimates of the coefficients of the regression. We note that including or not including individuals who think that AI adoption is not strategic for their companies makes a difference in the results; thus, Theben et al. <ref type="bibr" target="#b25">[26]</ref> were right to limit the sample to respondents who consider AI adoption strategic. In fact, for example, as we can see in Table <ref type="table">3</ref>, two of the significant relationships related to the training latent variable are lost.</p><p>Moreover, we note that for each coefficient of the latent variables of the regression, the more important items are those related to the same dimension.</p><p>This study corroborates and robustifies previous findings that AI adoption may be negatively linked and that complexity may be positively linked to employee engagement. Moreover, the current study shows that in the process of AI adoption, the quality and quantity of training offered to employees may not be adequate in the present situation.</p><p>The data used here have several limitations. The data were collected through a crosssectional design, which does not allow for causal conclusions to be drawn. Another limitation has to do with the data being collected only via self-report. However, the total index of each item provided by GSA shows that the dimension created via factor analysis and extensively discussed in Theben et al. <ref type="bibr" target="#b25">[26]</ref> is robust to model perturbations.</p><p>The present work demonstrates the feasibility and usefulness of a robustification analysis applied to SEM. Thanks to GSA, we are able to investigate the equifinality problem, in which multiple model structures are compatible with the same data <ref type="bibr" target="#b45">[46]</ref>.</p><p>Since our analysis was entirely based on open-source software, the procedure described here should be relatively easy to apply to cases where a similar methodology is employed. The GSA represents an optimal tool for validating the assumptions made by the modeler. Stopping the analysis at the estimation phase, turns out to be an incorrect procedure because the statistical inference is done with respect to a functional form of the model. It is important to reiterate the fact that all modelling choices done by modellers are explicit and subject to a process of estimation. In this application, we have for example varied the data used for the estimation procedure of SEM, we have created different definitions of latent variables, which are often a concept extremely subjective of the modeller, and we have included the phase of bootstrap of data. All these variations, which we could call "model assumptions", represents a typical case of something which might be assumed as inconsequential and that instead might affect the results. Future work, for example, could produce a comparison via GSA of the CB-SEM versus PLS-SEM approach, as already discussed by Dash and Paul <ref type="bibr" target="#b46">[47]</ref> and Astrachan et al. <ref type="bibr" target="#b47">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declarations</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>training , M vigour , M dedication , M absorption ) represent the matrix of dependent variable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Graphical representation of the SEM. The dashed arrow represents a significant dependence and the dotted arrow represents a non-significant dependence. Above the arrows, we report the regression coefficient (* stands for a pvalue &lt; 0.5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>2 is more influenced by the presence of item 20 3 in the definition of the dimension training; • the estimation of ω 2 is more influenced by the presence of item 20 3 in the definition of the dimension training; • the estimation of α 2 is more influenced by the presence of item 20 3 in the definition of the dimension training. The other item (γ 2 or ω 2 or α 2 ) has a marginal effect in the estimation of regression coefficients dependent on the training dimension; including items 20 2 , 20 5 , and 20 6 might not even be considered in the definition of the dimension. Regular training and training updates represent the more important aspect in the definition of the latent variable training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1 , 14 2 , 14 3 , 14 5 }; • a latent variable that measures the vigour of a worker and is defined on three items {17 1 , 17 2 , 17 3 }; • a latent variable that measures the dedication of a worker and is defined on four items {17 7 , 17 8 , 17 9 , 17 10 }; • a latent variable that measures the absorption of a worker and is defined on four items {17 12 , 17 14 , 17 15 , 17 16 }; • a latent variable that measures the training of a worker and is defined on four items {20 2 , 20 3 , 20 5 , 20 6 };</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Questionnaire used in the analysis of Theben et al.<ref type="bibr" target="#b25">[26]</ref>.</figDesc><table><row><cell>Question</cell><cell>Code</cell><cell>Item</cell></row><row><cell>Opinions for AI adoption</cell><cell>11 1</cell><cell>AI adoption is strategic for my organization</cell></row><row><cell>AI adoption aspect</cell><cell>14 1</cell><cell>My work can be completed by a zero-hour contractor such as a computer</cell></row><row><cell></cell><cell></cell><cell>program</cell></row><row><cell></cell><cell>14 2</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>1 1 14 1 , 14 2 1 14 2 , 14 3 1 14 3 , 14 5 1 14 5 } • the latent variable vigour is defined by {17 1 1 17 1 , 17 2 1 17 2 , 17 3 1 17 3 } • the latent variable dedication is defined by {17 7 1 17 7 , 17 8 1 17 8 , 17 9 1 17 9 , 17 10 1 17 10 } • the latent variable absorption is defined by {17 12 1 17 12 , 17 14 1 17 14 , 17 15 1 17 15 , 17 16 1 17 16 } • the latent variable training is defined by {20 2 1 20 2 , 20 3 1 20 3 , 20 5 1 20 5 , 20 6 1 20 6 }</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>3 , 1 14 5 , 1 17 1 , 1 17 2 , 1 17 3 , 1 17 7 , 1 17 8 , 1 17 9 , 1 17 10 , 1 17 12 , 1 17 14 , 1 17 15 , 1 17 16 , 1 20 2 , 1 20 3 , 1 20 5 , 1 20 6 , 1 Data }</figDesc><table /></figure>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Availability of data and materials. Data are available on request from the corresponding author.</p><p>Code availability. Codes, written totally in R, are available on request from the corresponding author.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dimension</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AI adoption complexity training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question</head><p>Trigger</p><p>AI adoption 1 <ref type="bibr" target="#b13">14</ref>  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pase: Program for analysis of structural equations</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Wolfle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods &amp; Instrumentation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="548" to="550" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Gemini: Program for analysis of structural equations with standard errors of indirect effects</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Wolfle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ethington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior research methods, instruments &amp; computers</title>
		<imprint>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A guide to multiple-sample structural equation modeling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Lomax</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods &amp; Instrumentation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="580" to="584" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unpacking the modeling process via sensitivity auditing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Piano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sheikholeslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Puy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saltelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Futures</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page">103041</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unpacking the modeling process for energy policy making</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Piano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Lőrincz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Puy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saltelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Sluijs</surname></persName>
		</author>
		<idno type="DOI">10.1111/risa.14248</idno>
		<ptr target="https://doi.org/10.1111/risa.14248" />
	</analytic>
	<monogr>
		<title level="j">Risk Analysis</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Saltelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ratto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Campolongo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cariboni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gatelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saisana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tarantola</surname></persName>
		</author>
		<title level="m">Global Sensitivity Analysis: the Primer</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<title level="m">An Introduction to the Bootstrap</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">57</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Model uncertainty, data mining and statistical inference</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chatfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series A: Statistics in Society</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="419" to="444" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Observing many researchers using the same data and hypothesis reveals a hidden universe of uncertainty</title>
		<author>
			<persName><forename type="first">N</forename><surname>Breznau</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2203150119</idno>
		<ptr target="https://doi.org/10.1073/pnas.2203150119" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">44</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A universe of uncertainty hiding in plain sight</title>
		<author>
			<persName><forename type="first">P</forename><surname>Engzell</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2218530120</idno>
		<ptr target="https://doi.org/10.1073/pnas.2218530120" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">2218530120</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The garden of forking paths: Why multiple comparisons can be a problem, even when there is no &quot;fishing expedition&quot; or &quot;p-hacking&quot; and the research hypothesis was posited ahead of time</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Loken</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">348</biblScope>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, Columbia University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Increasing transparency through a multiverse analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Steegen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tuerlinckx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Vanpaemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="702" to="712" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The Garden of Forking Paths, Penguin books edn</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Borges</surname></persName>
		</author>
		<ptr target="https://www.penguin.co.uk/books/308559/the-garden-of-forking-paths-by-borges-jorge-luis/9780241339053" />
		<imprint>
			<date type="published" when="1998">1998</date>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sensitivity analysis for importance assessment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saltelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Risk analysis</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="579" to="590" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The future of sensitivity analysis: An essential discipline for systems modeling and policy support</title>
		<author>
			<persName><forename type="first">S</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jakeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saltelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Prieur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Iooss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Borgonovo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Plischke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Piano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Iwanaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Environmental Modelling &amp; Software</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page">104954</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mathematical Modelling and Computational Experiment (Translated from Russian: I.M. Sobol&apos;, Sensitivity estimates for nonlinear mathematical models</title>
		<author>
			<persName><forename type="first">'</forename><surname>Sobol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matematicheskoe Modelirovanie</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="407" to="414" />
			<date type="published" when="1990">1990. 1993</date>
		</imprint>
	</monogr>
	<note>Sensitivity analysis for non-linear mathematical models</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A new uncertainty importance measure</title>
		<author>
			<persName><forename type="first">E</forename><surname>Borgonovo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reliability Engineering &amp; System Safety</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="771" to="784" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A simple and efficient method for global sensitivity analysis based on cumulative distribution functions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pianosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wagener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Environmental Modelling &amp; Software</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A new framework for comprehensive, robust, and efficient global sensitivity analysis: 1. theory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Water Resources Research</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="423" to="439" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sobol&apos;indices and shapley value</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Owen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM/ASA Journal on Uncertainty Quantification</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="245" to="251" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A generalized kernel method for global sensitivity analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rabitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM/ASA Journal on Uncertainty Quantification</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="54" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Kernel-based global sensitivity analysis obtained from a single data set</title>
		<author>
			<persName><forename type="first">J</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rabitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reliability Engineering &amp; System Safety</title>
		<imprint>
			<biblScope unit="volume">235</biblScope>
			<biblScope unit="page">109173</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sensitivity analysis of environmental models: A systematic review with practical workflow</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pianosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Beven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rougier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Stephenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wagener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Environmental Modelling &amp; Software</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="214" to="232" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Variance based sensitivity analysis of model output. design and estimator for the total sensitivity index</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saltelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Annoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Azzini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Campolongo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ratto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tarantola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer physics communications</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="259" to="270" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sensitivity analysis of structural equation models</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="93" to="108" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The impact of AI adoption on employee engagement: preparing the workforce for new realities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Theben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Plamenova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Perramon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Llach</surname></persName>
		</author>
		<ptr target="https://cms.bsm.upf.edu/sites/default/files/inline-files/2023-manuscript-ai-adoption-engagement.pdf" />
	</analytic>
	<monogr>
		<title level="m">UPF-BSM working paper</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Saltelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Fiore</surname></persName>
		</author>
		<title level="m">The Politics of Modelling: Numbers Between Science and Policy</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A technique for the measurement of attitudes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Likert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Archives of psychology</title>
		<imprint>
			<date type="published" when="1932">1932</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
		<author>
			<persName><surname>Fontaine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J.R.: Equivalence. Encyclopedia of social measurement</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="803" to="813" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Evaluating the use of exploratory factor analysis in developmental disability psychological research</title>
		<author>
			<persName><forename type="first">M</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lecavalier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of autism and developmental disorders</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="8" to="20" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Evaluating the use of exploratory factor analysis in psychological research</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Fabrigar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Wegener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Strahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological methods</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">272</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The investigation of personality structure: Statistical models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Finch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Research in Personality</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="439" to="485" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Coefficient alpha and the internal structure of tests</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Cronbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">psychometrika</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="334" />
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Partial least squares structural equation modeling in hrm research</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Ringle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Gudergan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Human Resource Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1617" to="1643" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Structural parameters under partial least squares and covariance-based structural equation modeling: A comment on yuan and deng (2021)</title>
		<author>
			<persName><forename type="first">F</forename><surname>Schuberth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rönkkö</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Trinchera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Kline</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henseler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="339" to="345" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Supplement to EQS 6.3 for Windows User&apos;s Guide</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Kaplan</surname></persName>
		</author>
		<title level="m">Structural Equation Modeling: Foundations and Extensions</title>
		<imprint>
			<publisher>SAGE publications</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Pros and cons of structural equation modeling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nachtigall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kroehne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Funke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Steyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods Psychological Research Online</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Why the monte carlo method is so important today</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kroese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brereton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Taimre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">I</forename><surname>Botev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Computational Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="386" to="392" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Using ant colony optimization for sensitivity analysis in structural equation modeling</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Leite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marcoulides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Fisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="56" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Exploring multi-dimensional spaces: A comparison of latin hypercube and quasi monte carlo sampling techniques</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kucherenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Albrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saltelli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.02350</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">A Primer for the Monte Carlo Method</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Sobol</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Some contributions to efficient statistics in structural models: Specification and estimation of moment structures</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="493" to="517" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Global sensitivity results for generalized least squares estimates</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Leamer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">388</biblScope>
			<biblScope unit="page" from="867" to="870" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Sensitivity analysis as an ingredient of modeling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saltelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tarantola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Campolongo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical science</title>
		<imprint>
			<biblScope unit="page" from="377" to="395" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<idno type="DOI">10.1017/CBO9780511660108</idno>
		<ptr target="https://www.cambridge.org/core/product/identifier/9780511660108/type/bookAccessed2023-09-15" />
		<title level="m">Models as Mediators: Perspectives on Natural and Social Science, 1st edn</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Morgan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Morrison</surname></persName>
		</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Cb-sem vs pls-sem methods for research in social sciences and technology forecasting</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Paul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technological Forecasting and Social Change</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page">121092</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A comparative study of cb-sem and plssem for theory development in family firm research</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Astrachan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wanzenried</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of family business strategy</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="128" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
