<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Top-N Recommendation with Counterfactual User Preference Simulation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2021-09-13">13 Sep 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mengyue</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University College London</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Quanyu</forename><surname>Dai</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<address>
									<country>Huawei</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<address>
									<country>Huawei</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenhua</forename><surname>Dong</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<address>
									<country>Huawei</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<address>
									<country>Huawei</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Beijing Key Laboratory of Big Data Management and Analysis Methods</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Gaoling School of Artificial Intelligence</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Beijing Key Laboratory of Big Data Management and Analysis Methods</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Gaoling School of Artificial Intelligence</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University College London</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<address>
									<country>Huawei</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Top-N Recommendation with Counterfactual User Preference Simulation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-09-13">13 Sep 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3459637.3482305</idno>
					<idno type="arXiv">arXiv:2109.02444v2[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T23:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommender Systems</term>
					<term>Bayesian Personalized Ranking</term>
					<term>Structure Causal Model</term>
					<term>Counterfactuals</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Top-N recommendation, which aims to learn user ranking-based preference, has long been a fundamental problem in a wide range of applications. Traditional models usually motivate themselves by designing complex or tailored architectures based on different assumptions. However, the training data of recommender system can be extremely sparse and imbalanced, which poses great challenges for boosting the recommendation performance. To alleviate this problem, in this paper, we propose to reformulate the recommendation task within the causal inference framework, which enables us to counterfactually simulate user ranking-based preferences to handle the data scarce problem. The core of our model lies in the counterfactual question: "what would be the user's decision if the recommended items had been different?". To answer this question, we firstly formulate the recommendation process with a series of structural equation models (SEMs), whose parameters are optimized based on the observed data. Then, we actively indicate many recommendation lists (called intervention in the causal inference terminology) which are not recorded in the dataset, and simulate user feedback according to the learned SEMs for generating new training samples. Instead of randomly intervening on the recommendation list, we design a learning-based method to discover more informative training samples. Considering that the learned SEMs can be not perfect, we, at last, theoretically analyze the relation between the number of generated samples and the model prediction error, based on which a heuristic method is designed to control the negative effect brought by the prediction error. Extensive experiments are conducted based on both synthetic and real-world datasets to demonstrate the effectiveness of our framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>â€¢ Information systems â†’ Recommender systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recommendation system basically aims to match a user with her most favorite items. In a typical recommendation process, the system firstly recommends an item list to a user, and then the user provides feedback on the recommendations. In real-world scenarios, people only access a small amount of items, which makes the observed dataset extremely sparse. Recommendation task is usually formulated as a ranking problem. Early models mostly base themselves on the simple matrix factorization method <ref type="bibr" target="#b25">[26]</ref>. In order to achieve better performance and adapt different scenarios, recent years have witnessed much effort on neuralizing the recommendation models <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b38">39]</ref>. However, the effectiveness of neural models usually depend on a large amount of training samples, which contradicts with the aforementioned sparse user behaviors.</p><p>In another research line, causal inference (CI) has been recently introduced into the machine learning community to augment the training data for more comprehensive model optimization <ref type="bibr" target="#b0">[1]</ref>. The basic idea is firstly assuming an underlying structure causal model (SCM), and then learning the model parameters based on the observed data. At last, the new training samples are generated by actively changing the input variables (called intervention) and collecting the cared outputs. Such sample enrichment method has been successfully applied to the fields of neural language processing (NLP) <ref type="bibr" target="#b40">[41]</ref> and computer vision (CV) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b11">12]</ref>. In this paper, we adapt this method to the recommendation domain, which is expected to alleviate the contradiction between the more and more heavier neural recommender architectures and the sparse user behaviors. In a nutshell, the main building block of our idea lies in the counterfactual question: "what would be the user's feedback if the recommendation list had been different?". More specifically, we formulate the recommendation task by a causal graph including three nodes (see Figure <ref type="figure" target="#fig_1">1</ref> While the counterfactual idea seems to be promising, there are many challenges when applying it to the recommendation domain: to begin with, how to formally define the recommendation task by a structure causal model is still unclear. Then, the space of the candidate recommendation lists (R) can be very large, and the samples induced from different recommendation lists (i.e., intervention) may vary on the effects of optimizing the target model <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b30">31]</ref>. How to design an effective method to select R remains to be an open problem. At last, the predefined structural equation models can be not perfect. How the prediction error influences the quality of the generated samples and how to lower the negative impact need to be carefully considered. For solving these challenges, in this paper, we propose a novel counterfactual personalized ranking framework (called CPR). In general, our framework is composed of two parts (see Figure <ref type="figure" target="#fig_1">1</ref>(a)), i.e., the target ranking model and the recommender simulator. The ranking model is leveraged to provide the final recommendation list, and the recommender simulator aims to assist the optimization of the ranking model by generating additional training samples. When building the recommender simulator, we follow Pearl's <ref type="bibr" target="#b22">[23]</ref> counterfactual framework to define the recommendation process, where the structural equation models (SEMs) between U, R and S are defined in a stochastic manner and learned by variational inference to capture the randomness in the recommender system. In order to handle the extremely large space of the recommendation list (i.e., R), we design a learning-based method to select R which can induce more informative training samples. Considering that the learned SEMs can be not perfect, we theoretically analyze the relation between its prediction error and the number of generated samples. Inspired by this theory, we propose a simple but effective strategy to control the quality of the generated samples.</p><p>The main contributions of this paper are summarized as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>In this section, we firstly recapitulate the key concepts and methodologies in Pearl's causal inference framework. Then, we briefly introduce the ranking-based recommender models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Pearl's Causal Inference Framework</head><p>Pearl's causal inference framework holds the promise of providing a complete and self-contained tool for studying causalities under both experimental and observational settings <ref type="bibr" target="#b24">[25]</ref>. It is famous for the proposed three layer causal hierarchy, i.e., association, intervention and counterfactual. In Pearl's causal inference framework, the first key concept is the structure causal model (SCM), which helps to formulate real-world problems with causal languages. Definition 1 (Structure Causal Model <ref type="bibr" target="#b22">[23]</ref>). A structural causal model ğ‘´ is composed of a causal graph ğ‘® and a set of structure equation models (SEMs) ğ‘­ . ğ‘® is usually a directed graph, where the edges indicate the causal relations between different variables. The nodes in ğ‘® are classified into two groups: (i) exogenous nodes ğ‘¼ = {ğ‘¢ 1 , ..., ğ‘¢ ğ‘ ğ‘ˆ }, which are independent with each other, and summarize the environment when the data was generated, and (ii) endogenous nodes ğ‘¿ = {ğ‘¥ 1 , ..., ğ‘¥ ğ‘ ğ‘‹ }, which corresponds the variables we need to model in the problem. ğ‘­ = {ğ‘“ ğ‘– } ğ‘ ğ‘–=1 basically parameterizes the node relations, that is, ğ‘¥ ğ‘– = ğ‘“ ğ‘– (ğ‘ƒğ´ ğ‘– , ğ‘¢ ğ‘– ), where ğ‘ƒğ´ ğ‘– is the parent of ğ‘¥ ğ‘– in ğ‘®.</p><p>The structure causal model builds the basis of studying the three layer causal hierarchy. In this paper, we mainly focus on counterfactual estimation. In general, this tool aims to predict the outcome if several input variables in the causal graph had been different. We briefly introduce the estimation process in the following definition: Definition 2 (Counterfactual Estimation <ref type="bibr" target="#b22">[23]</ref>). Suppose we have two variable sets ğ’€ , ğ’ âŠ‚ ğ‘¿ , and we use small letters ğ’š and ğ’› to denote their instantiations. The notation ğ‘ (ğ’š ğ‘€ ğ’ =ğ’› (ğ’› â€² )) defines the distribution of ğ‘Œ if ğ’ had been set as ğ’› in structural causal model ğ‘€ given that ğ’ is currently observed as ğ’› â€² . This distribution corresponds the counterfactual question "what would be ğ‘Œ if ğ’ had been set as ğ’› given its current observation ğ’› â€² ?", which is typically derived according to the following three steps: (i) Abduction: deriving the posterior of the exogenous variables ğ‘ (ğ‘¼ |ğ’ = ğ‘§ â€² ) based on the prior ğ‘ (ğ‘¼ ) and the observation ğ’ = ğ‘§ â€² . (ii) Action: modifying ğº by removing the edges going into ğ’ and set ğ’ = ğ‘§ (called intervention) to derive ğ‘ (ğ‘¦|ğ’ = ğ‘§, ğ‘¼ ). (iii) Prediction: computing the distribution ğ‘ƒ (ğ‘¦ ğ‘€ ğ’ =ğ‘§ (ğ‘§ â€² )) by</p><formula xml:id="formula_0">âˆ« ğ‘¼ ğ‘ (ğ‘¦|ğ’ = ğ‘§, ğ‘¼ )ğ‘ (ğ‘¼ |ğ’ = ğ‘§ â€² )dğ‘¼ .</formula><p>The key motivation of the above "abduction-action-prediction" procedure is to make sure that the new (counterfactual) and observed data enjoy the same generation environment, so that they can be compatible and just like to be produced at the same time <ref type="bibr" target="#b24">[25]</ref>. Since Pearl's causal inference framework is not the focus of this paper, we refer the readers to <ref type="bibr" target="#b22">[23]</ref> for more details. Based on the tool of counterfactual estimation, one can generate additional training samples to assist the downstream tasks, where a remaining problem is how to indicate ğ‘§ to obtain effective samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Ranking-based Recommender Models</head><p>Ranking-based recommender models are powerful tools for solving the Top-N recommendation task, which can be optimized in either pair-wise or point-wise manners. In the pair-wise method, there are usually three inputs, i.e., a user ğ‘¢ and a positive-negative item pair (ğ‘–, ğ‘—). The goal is to maximize the user preference margin between the positive and negative items. Suppose the user preference is estimated from a function ğ‘“ (â€¢), then the optimization target is:</p><formula xml:id="formula_1">ğ¿ 1 (ğ‘‚) = - âˆ‘ï¸ (ğ‘¢,ğ‘–,ğ‘—) âˆˆğ‘‚ log ğœ (ğ‘“ (ğ‘¢, ğ‘–) -ğ‘“ (ğ‘¢, ğ‘—)),<label>(1)</label></formula><p>where ğœ (â€¢) is the sigmoid function to avoid trivial solutions. ğ‘‚ = {(ğ‘¢, ğ‘–, ğ‘—)|ğ‘– âˆˆ I + ğ‘¢ , ğ‘— âˆˆ I \ I + ğ‘¢ } is the set of training samples. I is the whole item set, and I + ğ‘¢ indicates the set of items which have received ğ‘¢'s positive feedback. For the point-wise method, the input is a user-item pair (ğ‘¢, ğ‘–), and the user preference estimation is treated as a classification problem, where ğ‘“ is optimized by the following cross entropy objective:</p><formula xml:id="formula_2">ğ¿ 2 (ğ‘‚) = - âˆ‘ï¸ (ğ‘¢,ğ‘–) âˆˆğ‘‚ + log ğ‘“ (ğ‘¢, ğ‘–) - âˆ‘ï¸ (ğ‘¢,ğ‘–) âˆˆğ‘‚ - (1 -log(ğ‘“ (ğ‘¢, ğ‘–))),<label>(2)</label></formula><p>where ğ‘‚ + = {(ğ‘¢, ğ‘–)|ğ‘– âˆˆ I + ğ‘¢ } and ğ‘‚ -= {(ğ‘¢, ğ‘–)|ğ‘– âˆˆ I \ I + ğ‘¢ } are the sets of positive and negative samples. ğ‘‚ = ğ‘‚ + âˆªğ‘‚ -denotes the complete training set. Ranking-based recommender models differentiate themselves by the various implementation of ğ‘“ . Simple ğ‘“ can be realized by matrix factorization <ref type="bibr" target="#b25">[26]</ref>, and more advanced ğ‘“ includes multi-layer perception <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21]</ref>, attentive neural network <ref type="bibr" target="#b16">[17]</ref> and graph convolutional network <ref type="bibr" target="#b15">[16]</ref>, among others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE CPR FRAMEWORK</head><p>Our framework is composed of two parts (see Figure <ref type="figure" target="#fig_1">1</ref>(a)): one is the recommender simulator, which is responsible for generating new training samples. The other is the target ranking model, which is learned based on both of the observed and generated data and leveraged to provide the final recommendation list. Our framework can be applied to any ranking-based recommender models, and we detail the recommender simulator in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Recommender Simulator</head><p>To begin with, we reformulate the recommendation problem by a structure causal model ğ‘´ = {ğ‘®, ğ‘­ }. In specific, the causal graph ğ‘® is defined as follows (see Figure <ref type="figure" target="#fig_2">1(b)</ref>): (1) U, R and S are the nodes representing the user, the recommendation list and the positive items <ref type="foot" target="#foot_0">1</ref> selected by the user. (2) U â†’ R encodes the fact that the recommendation list is generated according to the user preference.</p><p>(3) U â†’ S and R â†’ S indicate that the positive items are jointly determined by the recommendation list and user preference.</p><p>The structure equation models ğ‘­ are defined in a stochastic manner as follows:</p><formula xml:id="formula_3">ğ‘­ : ï£± ï£´ ï£´ ï£´ ï£² ï£´ ï£´ ï£´ ï£³ ğ‘¹ âˆ¼ ğ‘ ğ‘¹ (ğ‘¹|ğ‘¼ , ğœ¶ ) ğ‘º âˆ¼ ğ‘ ğ‘º (ğ‘º |ğ‘¼ , ğ‘¹, ğœ·) ğœ¶ , ğœ· âˆ¼ N (0, ğ‘° )<label>(3)</label></formula><p>where ğ‘¼ , ğ‘¹ and ğ‘º are endogenous variables. ğœ¶ âˆˆ R | I | and ğœ· âˆˆ R ğ¾ are exogenous variables. ğ‘ ğ‘¹ is the probability of recommending item list ğ‘¹. ğ‘ ğ‘º is the probability of selecting ğ‘º as the positive feedback. N (0, ğ‘° ) is the standard Gaussian distribution.</p><p>Remark. <ref type="bibr" target="#b0">(1)</ref> In order to consider the potential noisy information and randomness in the recommender system, the structure equation models (i.e., ğ‘­ ) are defined in a stochastic manner, which helps to learn user preference in a more accurate and robust manner. <ref type="bibr" target="#b1">(2)</ref> The exogenous variables in the recommendation problem can be explained as the conditions (e.g., system status, user habit, etc.) which induces the currently observed data. Take movie recommendation as an example, the users may be more likely to watch movies in their leisure time. So if the data is collected at night, then the movie click probability should be higher. Such temporal condition is latent but can influence the data generation process, which is expected to be captured by the exogenous variables, and recovered by inferring the corresponding posteriors.</p><p>3.1.1 Specification of ğ‘­ . We implement ğ‘­ by considering the unique characters of the recommender system. Recall that ğ‘ ğ‘¹ is the probability of recommending item list ğ‘¹. Suppose we have |I| items in the system, then the number<ref type="foot" target="#foot_1">foot_1</ref> of candidate item lists is ğ¶</p><formula xml:id="formula_4">|ğ‘¹ | |I | ,</formula><p>which is extremely large in the recommendation task. To alleviate this problem, we ignore the combinatorial effect between different items, and the probability of recommending an item list can be factorized into the multiplication of the single item recommendation probabilities, that is:</p><formula xml:id="formula_5">ğ‘ ğ‘¹ (ğ‘¹ = ğ’“ |ğ‘¼ = ğ‘¢, ğœ¶ ) = ğ¾ ğ‘˜=1 ğ‘ (ğ‘… ğ‘˜ = ğ‘Ÿ ğ‘˜ |ğ‘¼ = ğ‘¢, ğœ¶ ) = ğ¾ ğ‘˜=1 exp (ğ‘· ğ‘‡ ğ‘¢ ğ‘¸ ğ‘Ÿ ğ‘˜ + ğ‘¤ ğ‘… ğ‘Ÿ ğ‘˜ ğ›¼ ğ‘Ÿ ğ‘˜ ) |I | ğ‘—=1 exp (ğ‘· ğ‘‡ ğ‘¢ ğ‘¸ ğ‘— + ğ‘¤ ğ‘… ğ‘— ğ›¼ ğ‘— )<label>(4)</label></formula><p>where ğ’“ = {ğ‘Ÿ 1 , ğ‘Ÿ 2 , ..., ğ‘Ÿ ğ¾ } is the recommendation list. For the single item recommendation probability, we predict it by a softmax operator. We use ğ‘· âˆˆ R |U |Ã—ğ‘‘ ğ‘… and ğ‘¸ âˆˆ R |I |Ã—ğ‘‘ ğ‘… to represent the embeddings of the users and items. They can be initialized by the ID or profile information of the users and items. ğ‘‘ ğ‘… is the embedding size, and ğ’˜ ğ‘… âˆˆ R |I | is a weighting parameter. ğ‘ ğ‘º represents the probability of selecting item set ğ‘º from ğ‘¹, which is specified as:</p><formula xml:id="formula_6">ğ‘ ğ‘º (ğ‘º = ğ’”|ğ‘ˆ = ğ‘¢, ğ‘¹ = ğ’“, ğœ·) = ğ‘€ ğ‘¡ =1 exp (ğ‘¿ ğ‘‡ ğ‘¢ ğ’€ ğ‘  ğ‘¡ + ğ‘¤ ğ‘† ğ‘¡ ğ›½ ğ‘¡ ) ğ¾ ğ‘—=1 exp (ğ‘¿ ğ‘‡ ğ‘¢ ğ’€ ğ‘Ÿ ğ‘— + ğ‘¤ ğ‘† ğ‘— ğ›½ ğ‘— )<label>(5)</label></formula><p>where </p><formula xml:id="formula_7">ğ’” = {ğ‘  1 , ğ‘  2 , ..., ğ‘  ğ‘€ } is the set of selected items. ğ’˜ ğ‘† âˆˆ R ğ¾</formula><formula xml:id="formula_8">= {(ğ‘¢ ğ‘– , ğ’“ ğ‘– , ğ’” ğ‘– )} ğ‘ ğ‘–=1</formula><p>, where ğ‘¢ ğ‘– is the target user, ğ’“ ğ‘– is the recommendation list, ğ’” ğ‘– is the item set selected by ğ‘¢ ğ‘– from ğ’“ ğ‘– , N is the sample number. For ğ‘ ğ‘¹ , since the number of items (i.e., |I|) can be very large, it is hard to directly optimize the softmax term in equation ( <ref type="formula" target="#formula_5">4</ref>). Thus we resort to the negative sampling technique <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b25">26]</ref>, which induces the following optimization target:</p><formula xml:id="formula_9">ğ¿ ğ‘… = ğ‘ âˆ‘ï¸ ğ‘–=1 âˆ‘ï¸ ğ‘˜ âˆˆğ’“ ğ‘– log (ğœ (ğ‘· ğ‘‡ ğ‘¢ ğ‘– ğ‘¸ ğ‘˜ +ğ‘¤ ğ‘… ğ‘˜ ğ›¼ ğ‘˜ )) + âˆ‘ï¸ ğ‘˜ -âˆˆğ’“ - ğ‘– log (1-ğœ (ğ‘· ğ‘‡ ğ‘¢ ğ‘– ğ‘¸ ğ‘˜ -+ğ‘¤ ğ‘… ğ‘˜ -ğ›¼ ğ‘˜ -))<label>(6)</label></formula><p>where {ğ‘·, ğ‘¸, ğ’˜ ğ‘… } are the parameters to be learned. ğ’“ - ğ‘– is the set of negative samples, which are randomly sampled from the nonrecommended items. ğœ¶ = [ğ›¼ ğ‘– ] is sampled <ref type="foot" target="#foot_2">3</ref> from N (0, ğ‘° ). With this objective, the parameters are optimized to maximize the recommended item probability and simultaneously minimize the ones which are not presented to the users.</p><p>For ğ‘ ğ‘º , since the length of the recommendation list (i.e., K) is usually not large, we directly maximize the following livelihood without approximation:</p><formula xml:id="formula_10">ğ¿ ğ‘† = ğ‘ âˆ‘ï¸ ğ‘–=1 ğ‘€ âˆ‘ï¸ ğ‘¡ =1 log( exp (ğ‘¿ ğ‘‡ ğ‘¢ ğ‘– ğ’€ ğ‘  ğ‘–ğ‘¡ + ğ’˜ ğ‘† ğ‘¡ ğ›½ ğ‘¡ ) ğ¾ ğ‘—=1 exp (ğ‘¿ ğ‘‡ ğ‘¢ ğ‘– ğ’€ ğ‘Ÿ ğ‘– ğ‘— + ğ’˜ ğ‘† ğ‘— ğ›½ ğ‘— ) )<label>(7)</label></formula><p>where {ğ‘¿, ğ’€ , ğ’˜ ğ‘† } are the parameters to be optimized. ğ‘  ğ‘–ğ‘¡ and ğ‘Ÿ ğ‘– ğ‘— are the ğ‘¡th and ğ‘—th items in ğ’” ğ‘– and ğ’“ ğ‘– , respectively. ğœ· = [ğ›½ ğ‘– ] is sampled from N (0, ğ‘° ). It seems that this objective only maximizes the probability of the items which are selected by the user, but with the softmax operator, the probabilities of the non-selected items are automatically lowered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Counterfactual estimation based on ğ¹ .</head><p>Once we have learned ğ‘ ğ‘¹ and ğ‘ ğ‘º , we follow Pearl's "abduction-action-prediction" procedure <ref type="bibr" target="#b23">[24]</ref> to conduct counterfactual estimation. In the step of abduction, we estimate the posterior of ğœ¶ and ğœ· given the observed dataset O. For ğœ·, the posterior can be derived based on the following Bayesian rules:</p><formula xml:id="formula_11">ğ‘ (ğœ· |O) âˆ ğ‘ (ğœ·, O) = ğ‘ (ğœ·)ğ‘ (O|ğœ·)<label>(8)</label></formula><p>where ğ‘ (O|ğœ·) can be easily derived based on equation <ref type="bibr" target="#b4">(5)</ref>. Recall that our goal is to sample from the posteriors. However, the result of equation ( <ref type="formula" target="#formula_11">8</ref>) is too complex for sampling, which motivates us to use variational inference <ref type="bibr" target="#b2">[3]</ref> for approximation. In specific, we firstly define a Gaussian distribution ğ‘ ğ“ (ğœ·) âˆ¼ N (ğ, ğˆ), where ğ“ = {ğ, ğˆ } is set of learnable parameters. Then we optimize ğ“ by minimizing the KL-divergence between ğ‘ ğ“ (ğœ·) and ğ‘ (ğœ· |O), where the evidence lower bound (ELBO) <ref type="bibr" target="#b2">[3]</ref> we need to maximize is:</p><formula xml:id="formula_12">ELBO = E ğ‘ ğ“ (ğœ·) [log ğ‘ (ğœ·, O)] -E ğ‘ ğ“ (ğœ·) [log ğ‘ ğ“ (ğœ·)]<label>(9)</label></formula><p>Similarly, we can learn a variational distribution for ğ‘ (ğœ¶ |O). Due to the space limitation, readers are referred to <ref type="bibr" target="#b2">[3]</ref> for more technical details of the variational inference.</p><p>In the action step, we select a user Ã», and set ğ‘¹ = r. When making prediction, we firstly sample Î² from ğ‘ ğ“ (ğœ·), and then compute the probability of item rğ‘˜ by:</p><formula xml:id="formula_13">ğ‘ ğ‘º ( rğ‘˜ |ğ‘ˆ = Ã», ğ‘¹ = r, Î²) = exp (ğ‘¿ ğ‘‡ Ã» ğ’€ rğ‘˜ + ğ’˜ ğ‘† ğ‘˜ Î²ğ‘˜ ) ğ¾ ğ‘—=1 exp (ğ‘¿ ğ‘‡ Ã» ğ’€ r ğ‘— + ğ’˜ ğ‘† ğ‘— Î²ğ‘— )<label>(10)</label></formula><p>At last, Å is predicted by collecting M items with the highest probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning-based Intervention</head><p>Based on the above designed recommender simulator, one can attempt different r's and derive the corresponding Å's to form new (counterfactual) training samples. A nature question is how to set r. Straightforwardly, one can explore r in a random manner (e.g., show the users with random recommendation lists). However, as mentioned before, the space of r can be extremely large, and it is well known that different training samples are not equally important for model optimization <ref type="bibr" target="#b30">[31]</ref>, thus the random method can be less effective in hitting the optimal samples. In order to achieve better optimization results, we design a learning-based method to select r. Our key idea is to make the generated samples more informative for the target ranking model. It has been studied in the previous work <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> that the samples with larger loss can usually provide more knowledge for the model to learn (i.e., more informative). They can well challenge the model and bring more inspirations to improve the performance. Following these studies, we use the loss of the target ranking model as the reward, and build a learning-based method to generate r. Formally, suppose the target ranking model is ğ‘“ , and we denote its loss function as ğ¿ ğ‘“ , which can be specified as equation ( <ref type="formula" target="#formula_1">1</ref>) or <ref type="bibr" target="#b1">(2)</ref>. The goal of the agent is to conduct actions (generating recommendation lists) which can lead to larger ğ¿ ğ‘“ . Considering that the action space can be very large, we follow the previous work <ref type="bibr" target="#b39">[40]</ref> to learn a Gaussian policy to generate the continuous item center of r, after which the discrete item IDs are recovered based on equation ( <ref type="formula" target="#formula_5">4</ref>). The final learning objective is:</p><formula xml:id="formula_14">ğ¿ Agent (ğœ½ ) = E Ï„ğ‘¡ âˆˆğœ‹ ( â€¢ | Ã»,ğœ½ ) [ ğ‘‡ âˆ‘ï¸ ğ‘¡ =1 ğ¿ ğ‘“ (ğ¶ ( Ï„ğ‘¡ ))] (<label>11</label></formula><formula xml:id="formula_15">)</formula><p>where ğœ‹ is the Gaussian policy implemented as a two-layer fully connected neural network with ReLU as the activation function. Ã» indicates the target user. ğ¿ ğ‘“ (ğ¶ ( Ï„ğ‘¡ )) denotes the loss of the generated training samples ğ¶ ( Ï„ğ‘¡ ). We generate T sets of training samples, and each one is derived from Ï„ğ‘¡ based on the following steps:</p><p>â€¢ Deriving r by selecting K items near the item center Ï„ğ‘¡ according to the scores {( Ï„ğ‘‡</p><formula xml:id="formula_16">ğ‘¡ ğ‘¸ ğ‘˜ + ğ’˜ ğ‘… ğ‘˜ ğ›¼ ğ‘˜ )} |I | ğ‘˜=1 .</formula><p>â€¢ Deriving Å by selecting M items with the largest probabilities of</p><formula xml:id="formula_17">ğ‘ ğ‘º ( rğ‘˜ |ğ‘ˆ = Ã», ğ‘¹ = r, Î²) (ğ‘˜ âˆˆ [1, ğ¾]) . â€¢ For objective (1), ğ¶ ( Ï„ğ‘¡ ) = {( Ã», ğ‘–, ğ‘—)|ğ‘– âˆˆ Å, ğ‘— âˆˆ r \Å}. For objective (2), ğ¶ ( Ï„ğ‘¡ ) = {( Ã», ğ‘–)|ğ‘– âˆˆ Å} âˆª {( Ã», ğ‘–)|ğ‘– âˆˆ r \ Å}.</formula><p>We summarize the complete learning process in Algorithm 1 and 2. In specific, the target ranking model is firstly trained based on the original dataset. And then, we generate many counterfactual training samples based on the Gaussian policy. At last, the target ranking model is retrained based on the generated datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Theoretical Analysis</head><p>In this section, we theoretically analyze the proposed framework within the probably approximately correct (PAC) learning framework. We focus on the pair-wise learning objective, and the conclusions can be easily extended to the point-wise case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Theoretical insights on the learning-based intervention method.</head><p>The key motivation of the learning-based method is to generate harder samples, so that the target model can be more informed and   achieve better performance. The effectiveness of this idea has been empirically demonstrated in the previous work <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b30">31]</ref>. Here, we provide a theoretical justification based on the following theory: Theorem 1. Suppose the users' feedback on an item pair (ğ‘–, ğ‘—) is probabilistic, and we can observe ğ‘– &gt; ğ‘— and ğ‘– &lt; ğ‘— with the probabilities of ğœ‚ and 1 -ğœ‚, respectively. Then, ğœ‚ can actually measure the hardness of the sample, when ğœ‚ is closer to 1  2 , then the sample is harder, since the propensity between the items is more ambiguous. Suppose ğœ–, ğ›¿ âˆˆ (0, 1), and we use a simple voting mechanism to determine the relation between ğ‘– and ğ‘—, then we need to have This theory suggests that we need to generate more samples (i.e., larger log 1 ğ›¿ 2(1-2ğœ‚) 2 ) for the harder (i.e., smaller ğœ‚) item pairs. It agrees with our goal in learning-based intervention method, where the produced samples are expected to be hard and can well challenge the target model. We present the proof of this theory in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Imperfection of SEMs.</head><p>Since the new samples are generated based on the learned SEMs, careful readers may have concerns on how would the approximation error of ğ‘­ influence the sample generation. To shed lights on this problem, we theoretically analyze the relation between the prediction error of ğ‘­ and the number of generated samples. To begin with, we assume that the recommender simulator can recover the true ranking of the item pairs with a noisy parameter ğœ âˆˆ (0, 0.5), i.e., suppose the true triplet is (ğ‘¢, ğ‘–, ğ‘—), then the recommender simulator generates the true (i.e., (ğ‘¢, ğ‘–, ğ‘—)) and wrong (i.e., (ğ‘¢, ğ‘—, ğ‘–)) samples with the probabilities of 1 -ğœ and ğœ , respectively. As the special cases, ğœ = 0 means the recommender simulator is perfect, and there is no noisy information in the produced samples. ğœ = 0.5 means the recommender simulator is a totally random predictor, and the generated data is nothing but noise. Then, we have the following theory: Theorem 2. Suppose ğœ–, ğ›¿ âˆˆ (0, 1), and ğ‘“ âˆˆ F is the target ranking model. If the number of training samples is larger than</p><formula xml:id="formula_18">2 log ( 2|F| ğ›¿ )</formula><p>ğœ– 2 (1-2ğœ ) 2 , then the estimation error of ğ‘“ in terms of ranking prediction is smaller than ğœ– with the probability larger than 1 -ğ›¿.</p><p>The proof of this theory is similar to that of theory 1 in <ref type="bibr" target="#b33">[34]</ref>. From this theory, we can see, as the noisy parameter ğœ becomes larger, more samples (i.e., 2 log ( 2|F| ğ›¿ )</p><p>ğœ– 2 (1-2ğœ ) 2 ) are needed to achieve sufficiently well performance (the prediction error is smaller than ğœ–). Extremely, when ğœ â†’ 0.5, we need to produce infinite training samples. This implies that if the recommender simulator is completely random, then we can not expect well performance by training on the generated data, which is aligned with the intuition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Controlling the noisy information.</head><p>Inspired by this theory, we propose a simple but effective method to control the noisy information. The general idea is to remain the samples with higher confidence. In specific, for a given recommendation list r, we use the selection probability ğ‘ ğ‘º ( rğ‘˜ |ğ‘ˆ = Ã», ğ‘¹ = r, Î²) to measure the confidence of the recommender simulator. We denote by Åğ‘˜ + and Åğ‘˜ -the sets of k items with the largest and smallest selection probabilities. Then the training set for the pair-wise objective is built as ğ¶ ( Ï„ğ‘¡ ) = {( Ã», ğ‘–, ğ‘—)|ğ‘– âˆˆ Åğ‘˜ + , ğ‘— âˆˆ Åğ‘˜ -}. For the point-wise objective, ğ¶ ( Ï„ğ‘¡ ) is set as {( Ã», ğ‘–)|ğ‘– âˆˆ Åğ‘˜ + } âˆª {( Ã», ğ‘–)|ğ‘– âˆˆ Åğ‘˜ -}. In this method, if ğ‘˜ is small, then the model has more confidence on the generated samples, which may reduce the noisy information, but at the same time, less samples can be generated, which may lead to insufficient model optimization. If ğ‘˜ is large, more samples will be generated, but the noisy level can also be high. In this sense, ğ‘˜ is actually a parameter to trade-off the noisy information and the number of generated samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we conduct extensive experiments to verify the effectiveness of our framework. In the following, we begin with the experiment setup, and then report and analyze the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Setup</head><p>4.1.1 Datasets. Our experiments are based on both synthetic and real-world datasets. With the synthetic dataset, we aim to evaluate our framework in a controlled manner under clean environment. By the real-world dataset, we try to verify our framework's effectiveness in real-world settings.</p><p>We follow the previous work <ref type="bibr" target="#b41">[42]</ref> to build the synthetic dataset, where we simulate ğ‘ ğ‘ˆ (= 600) users and ğ‘ ğ¼ (= 300) items. For each user ğ‘– (or item ğ‘—), the preferences ğ’‘ ğ‘– âˆˆ R ğ‘‘ (or properties ğ’’ ğ‘— âˆˆ R ğ‘‘ ) are generated from a multi-variable Gaussian distribution N (0, ğ‘° ), where ğ‘‘ and ğ‘° represent the vector size and unit matrix, respectively. In order to generate the recommendation list for user ğ‘–, we firstly compute the score of recommending item ğ‘— based on a neural network: ğ‘Ÿ ğ‘– ğ‘— = 1 -ğœ (ğ’‚ ğ‘‡ ğœ… 1 (ğœ… 2 ([ğ’‘ ğ‘– , ğ’’ ğ‘— ])) +ğ‘), where ğ’‚ âˆˆ R 2ğ‘‘ is specified as an all-one vector, and ğ‘ is set as zero. We follow <ref type="bibr" target="#b41">[42]</ref> to set ğœ… 1 (â€¢) and ğœ… 2 (â€¢) as piecewise functions, and ğœ… 1 (ğ‘¥) = ğ‘¥ -0.5 if ğ‘¥ &gt; 0, otherwise ğœ… 1 (ğ‘¥) = 0, ğœ… 2 (ğ‘¥) = ğ‘¥ if ğ‘¥ &gt; 0, otherwise ğœ… 2 (ğ‘¥) = 0. Given ğ‘Ÿ ğ‘– ğ‘— , the probability of recommending item ğ‘— is</p><formula xml:id="formula_19">ğ‘’ ğ‘Ÿ ğ‘– ğ‘— ğ‘ ğ¼ ğ‘˜=1 ğ‘’ ğ‘Ÿ ğ‘–ğ‘˜</formula><p>. For each user, we generate 25 impression lists, each of which is composed of 5 items.</p><p>When generating the feedback of a user ğ‘– on an item ğ‘—, we follow the previous work <ref type="bibr" target="#b41">[42]</ref> to explore both linear and non-linear user response models, that is:</p><formula xml:id="formula_20">ğ‘¥ 1 = ğ’‚ ğ‘‡ ğœ… 1 (ğœ… 2 ([ğ’‘ ğ‘– , ğ’’ ğ‘— ])) + ğ‘ ğ‘¥ 2 = ğ’‚ ğ‘‡ ğœ… 3 (ğœ… 2 ([-ğ’‘ ğ‘– , -ğ’’ ğ‘— ])) + ğ‘ ğ‘  lin ğ‘– ğ‘— = I(ğœ (ğ‘¥ 1 ) + ğ‘ ğ‘¦ -0.5) ğ‘  nonlin ğ‘– ğ‘— = I(ğœ (ğ‘¥ 1 + ğ‘¥ 1 â€¢ ğ‘¥ 2 ) + ğ‘ ğ‘¦ -0.5) (12)</formula><p>where ğœ… 3 (ğ‘¥) = ğ‘¥ + 0.5 if ğ‘¥ &lt; 0, otherwise ğœ… 3 (ğ‘¥) = 0. ğ‘ ğ‘¦ is used to set the noisy level of the datasets, and its default value is 0. I(ğ‘¥) is an indicator function, which is 1 if ğ‘¥ &gt; 0, and 0 otherwise.</p><p>The real-world experiments are based on the recently released MIND 4 dataset <ref type="bibr" target="#b34">[35]</ref>. This data is collected from the user behavior log of Microsoft News, and we uses the MIND-small dataset for experiments, where we are provided with 156,965 recommendation lists and 234,468 interactions between 50,000 users and 20,288 items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Baselines.</head><p>In order to evaluate the effectiveness of our proposed framework, we compare our model with the following representative methods: ItemPop is a non-personalized model, and the ranking score of an item is based on its popularity in the training set. ItemKNN <ref type="bibr" target="#b29">[30]</ref> is an item-based k-nearest-neighborhood (KNN) model. BPR <ref type="bibr" target="#b25">[26]</ref> is a well-known recommender model based user implicit feedback. GMF, MLP and NeuMF <ref type="bibr" target="#b17">[18]</ref> are neural recommender models, among which NeuMF is a combination between GMF and MLP. CDAE <ref type="bibr" target="#b35">[36]</ref> is a method based on denoising auto-encoder, which is proved to be the generalization of several well-known collaborative filtering models. LightGCN <ref type="bibr" target="#b15">[16]</ref> is a graph-based recommender model, where the user-item structure information is considered in the modeling process.</p><p>In order to verify the generality of our framework, we apply it to MF, GMF, MLP, NeuMF and LightGCN, respectively, which leads to the models of CPR-MF, CPR-GMF, CPR-MLP, CPR-NeuMF and CPR-LightGCN. To demonstrate the necessity of learningbased intervention method, we also evaluate the performance our framework with random intervention, where the recommendation list ğ‘¹ is assigned in a random manner. We denote the corresponding baselines as CPR-MF-r, CPR-GMF-r, CPR-MLP-r, CPR-NeuMF-r and CPR-LightGCN-r.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Implementation details.</head><p>We follow the previous work <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b25">26]</ref> to employ standard leave-one-out protocol for evaluation. 10 items are recommended from each model to compare with the users' actually interacted ones. We leverage the widely used metrics including Hit Ratio (HR) and Normalized Discounted Cumulative Gain (NDCG) to compare different models. Among these metrics, 4 <ref type="url" target="https://msnews.github.io/">https://msnews.github.io/</ref> HR aims to measure the overlapping between the predicted and ground truth items, while NDCG further takes the ranking of the prediction results into consideration, and higher ranked accurate items contribute more to the final score. The implementations of our model and all the baselines are based on PyTorch <ref type="bibr" target="#b21">[22]</ref> with mini-batch Adam <ref type="bibr" target="#b18">[19]</ref> optimizer. For ItemKNN and CDAE, we follow the settings of the original paper. For the other baselines, we determine their hyper-parameters based on grid search, and the search ranges for the embedding size, batch size, regularization coefficient and learning rate are set as {32, 64, 128, 256, 512}, {256, 512, 1024, 2048}, {2 Ã— 10 -2 , 10 -2 , 5 Ã— 10 -3 , 2 Ã— 10 -3 , 10 -3 , 5 Ã— 10 -4 , 10 -4 , 10 -5 } and {5 Ã— 10 -3 , 2 Ã— 10 -3 , 10 -3 }, respectively. The negative samples are selected from the whole item set or the impression list. When optimizing ğ‘ ğ‘¹ and ğ‘ ğ‘º , we empirically set the learning rate as 0.001, and the user/item embedding sizes are both tunned in {16, 32, 64, 128, 256, 512}. The length of the impression list (i.e., |ğ‘¹|) is set as 5, and the size of ğ‘º (i.e., ğ‘˜) is determined in {1, 2, 3}. The Gaussian policy is implemented as a two-layers fullyconnected neural network, where the hidden dimension is searched in {16, 32, 64}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiments with Synthetic Dataset</head><p>In this subsection, we present and analyze the experimental results on the synthetic dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Overall performance.</head><p>In the experiments, we explore different user/item representation dimensions as well as both linear and non-linear user response models. The overall comparison results are shown in Table <ref type="table" target="#tab_0">1</ref>. It is interesting to see that the relative simple baselines (e.g., ItemPop and ItemKNN) are competitive in many cases. This observation is consistent with the previous work <ref type="bibr" target="#b8">[9]</ref>, and suggests that simple methods may still be useful in some recommendation scenarios.</p><p>It is encouraging to see that our framework can consistently improve the performance of different target models. The improvement is consistent across different settings. In specific, our framework can on average improve the performance of the target model by about 10.08% and 11.17% on HR and NDCG, respectively. This result demonstrates the effectiveness of our framework. The reason can be that the recommender simulator enables us to explore the potential user preferences, which provides useful signals to widen the model visions and improve the performance. The importance of the learning-based intervention method is evidenced in the lowered performance when we use random strategy as a replacement, which verifies our claims in the introduction. It is interesting to see that the performance gains on neural models (e.g, MLP, NeuMF and LightGCN) are usually larger than that of the matrix factorization method. In many cases, the performance is even lowered for GMF and BPR after applying our framework, e.g., when we use nonlinear user response model and set ğ‘‘ = 32. This observation agrees with our expectation, that is, neural models need more training samples to display its strong expressiveness, and our framework should be more effective for them. Since most of the promising recommender models in practice are based on neural architectures, this observation demonstrates the potential of our framework in real-world settings.  In this section, we investigate the effectiveness of the noisy control method proposed in section 3.3. By this method, we hope our framework can adaptively tune itself to accommodate different noisy recommendation scenarios. In order to evaluate such capability, we set ğ‘ ğ‘¦ = 0 or sample it from N (0, 0.2) to simulate the settings where the data is observed with different noisy levels. We base the experiment on the nonlinear user response model, and we tune ğ‘˜ in the range of {1, 2, 3}.</p><p>The results are presented in table 2. It is not surprising to see that the performance of the same model is lowered when the noisy level is increased from 0 to sampling from N (0, 0.2). When ğ‘ ğ‘¦ is sampled from N (0, 0.2), the best performance is mostly achieved when ğ‘˜ = 1, while if we set ğ‘ ğ‘¦ = 0, ğ‘˜ = 2 or ğ‘˜ = 3 can usually lead to more favored results. We speculate that: when the dataset is noisy, the recommender simulator can be not trained well, thus the quality of the generated samples are not high. In such a scenario, removing the noisy samples seems to be more important. On the contrary, if the dataset is noise-free, then the recommender simulator can be more accurate. In this case, the sample quality is not the main issue, and more samples are favored to achieve sufficient model optimization and better performance. For different noisy-level datasets, our framework can always adapt itself to achieve better performance, which demonstrates the effectiveness of the noisy control method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiments with Real-World Dataset</head><p>The above synthetic experiments suggest that our idea is effective under ideal environment. In this section, we experiment with the real-world dataset, which is more challenging but more practical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Overall comparison.</head><p>To begin with, we compare our model with the baselines introduced in section 4.1.2. The results are presented in Table <ref type="table" target="#tab_2">3</ref>, from which we can see: similar to the synthetic dataset, our CPR framework can consistently lead to improved performances comparing with the target models, and the learningbased intervention method outperforms the random strategy in most cases. The performance gains on neural models are usually larger than that of the shallow ones, which again demonstrates the potential of our model for deep recommender models. Remarkably, the improvement of our framework is not that large comparing with the results on the synthetic dataset. We speculate that the real-world dataset can be noisy. Training based on it can lead to imperfect recommender simulator, which lowers the quality of the generated samples and limits the final recommendation performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.3.2</head><p>Performance on the items with different coldness. Cold start has long been a fundamental problem in the recommendation domain. In this section, we study the effectiveness of our framework on the items with different coldnesses. More specifically, we first run the models based on the original training set, and then evaluate their performances on three different testing sets varying on the item coldness. For the first testing set (denoted as "Low"), each item has less than 5 interactions with the users in the training set, which means the model is trained in a quite insufficient manner on these items. In the second testing set (denoted as "Middle"), each item has 5 to 15 interactions, thus the model is provided with more knowledge during the training process. In the last testing set (denoted as "High"), each item has more than 15 interactions, which is the "warmest" setting in the experiment. The model parameters are set as their optimal values tunned in the above experiments.</p><p>From Table <ref type="table" target="#tab_3">4</ref> we can see: our framework can enhance the performance of the target models in most cases, which demonstrates its effectiveness under different cold start settings. An interesting observation is that the performance improvement on the "Low" and "Middle" testing sets are much larger than that of the "High" dataset. For example, CPR-LightGCN can produce a remarkable 151.74% and 162.75% improvements over LightGCN on HR@10 and NDCG@10 for the "Low" dataset, and the improvements on the "Middle" dataset is about 40%-50%. However, on the "High" dataset, the performance is even lowered on the metric of HR@10, and the improvement on NDCG@10 is also limited. We speculate that, in the "Low" dataset, the testing items are trained in a quite insufficient manner. A large amount of knowledge has been ignored by the target model, which provides more opportunities for the generated samples to introduce useful signals and improve the performance. In real-world recommendation scenarios, cold-start is a notorious problem obsessing people for a long time, this experiment demonstrates the potential of our framework in alleviating this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>In this section, we compare our model with the previous work to highlight the contributions of this paper. Relation with causal recommendation. Recent years have witnessed many contributions on incorporating causal inference into the recommendation domain <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b36">37]</ref>. For example, <ref type="bibr" target="#b27">[28]</ref> explains the recommendation problem by a treatment-effect model, and designs a re-weighting method to remove the bias in the observed data. However, this method is based on user explicit feedback, and the loss function is restricted to root mean square error (RMSE). In order to handle user implicit feedback, <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b36">37]</ref> extend this method by incorporating cross-entropy loss and designing tailored debiasing models. In addition, <ref type="bibr" target="#b19">[20]</ref> proposes a general knowledge distillation framework to debias the training data. <ref type="bibr" target="#b4">[5]</ref> provides a thorough discussion on the recent progress on debiased recommendation. <ref type="bibr" target="#b3">[4]</ref> leverages uniform data to learn causal user/item embeddings for more fair and unbiased recommendation. These methods have achieved many successes in the recommendation domain. However, they mostly leverage causal inference to debias the training data, which is different from our data augmentation purpose. In addition, previous work mostly follow Rubin's potential outcome framework. However, our idea is inspired from Pearl's structure causal models, where we can explicitly model the data generated environment to ensure compatibleness between the generated and observed data. Relation with counterfactual data augmentation. Counterfactual data augmentation stems from the human introspection behavior. It has been recently leveraged to alleviate the training data insufficiency problem in the machine learning community. In the past few years, this idea has achieved great successes in the fields of neural language processing (NLP) <ref type="bibr" target="#b40">[41]</ref> and computer vision (CV) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b11">12]</ref>. In this paper, we apply it to the top-N recommendation task, which, to the best of our knowledge, is the first time in this field. The major differences between our framework and the previous work is: (i) we design a leaning-based intervention method to encourage the informativeness of the generated samples.</p><p>(ii) We theoretically analyze the noisy information in the generated samples, and design a tailored noise control method.</p><p>Relation with ranking based recommendation model. Ranking based recommender models have been widely studied for the Top-N recommendation task. The most famous model in early years is Bayesian personalized ranking (BPR), which is optimized by maximizing the user preference margin between the positive and negative items. This method has inspired many promising models. For example, CKE <ref type="bibr" target="#b37">[38]</ref> proposes a hybrid model to integrate collaborative filtering and knowledge base for recommendation. <ref type="bibr" target="#b9">[10]</ref> improves BPR with a better negative sampler which leverages additional data in E-commerce. AMF <ref type="bibr" target="#b16">[17]</ref> applies adversarial training method to enhance the performance of BPR. With the ever prospering of deep neural network, recent years have witnessed the surge of neural recommender models <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b31">32]</ref>. For example, NeuMF <ref type="bibr" target="#b17">[18]</ref> is designed to capture the non-linear user-item correlations. NGCF <ref type="bibr" target="#b32">[33]</ref> and LightGCN <ref type="bibr" target="#b15">[16]</ref> regard the user-item interactions as a graph, and explicitly incorporate the structure information to enhance the utilization of the collaborative filtering signals. By looking back the history of ranking based recommendation models, it is evident that the model architectures are becoming deeper and heavier. While the comprehensive parameters can indeed lead to improved recommendation performance, an unprecedented problem is also emerging, that is, more training data is needed to satisfy the heavy architectures, which contradicts with the sparse user behaviors in realities. In this paper, we propose a solution to this problem based on causal inference, which is parallel with the previous model-drive research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we propose to enhance Top-N recommendation with Pearl's causal inference framework, where we can simulate user preference and generate counterfactual samples for alleviating the training data insufficiency problem. We design a learning-based intervention method for discovering the informative samples, and conduct theoretical analysis to reveal the relation between the number of generated samples and the potential model prediction error. Extensive experiments based on both synthetic and real-world datasets are conducted to verify our model's effectiveness.</p><p>This paper actually opens the door of incorporating Pearl's causal inference framework into the recommendation domain. There is still much room for improvement. For example, one can design more advanced exogenous node structures to introduce more reasonable prior knowledge for different recommendation scenarios. In addition, it should be also interesting to incorporate side information into the structure equation models, which can help to capture more comprehensive user preference and obtain more accurate recommender simulators.   Proof. Without loss of generality, we suppose ğœ‚ &gt; 1 2 . We define the random variable ğ‘‹ ğ‘– as the ğ‘–th observation of the relation between ğ‘– and ğ‘—. We use ğ‘‹ ğ‘– = 1 to represent ğ‘– &gt; ğ‘—, and ğ‘‹ ğ‘– = 0 to indicate ğ‘– &lt; ğ‘—. Suppose, we have N observations, and we define ğ‘‹ = 1 ğ‘ ğ‘ ğ‘–=1 ğ‘‹ ğ‘– . Following the voting mechanism, if ğ‘‹ &lt; 1 2 , then the prediction is wrong, since it contradicts with ğœ‚ &gt; 1 2 . Obviously,</p><formula xml:id="formula_21">ğ¸ [ğ‘‹ ] = 1 ğ‘ ğ‘ âˆ‘ï¸ ğ‘–=1 ğ¸ [ğ‘‹ ğ‘– ] = ğœ‚.<label>(13)</label></formula><p>According to the Hoeffding's inequality <ref type="bibr" target="#b28">[29]</ref>, we have:</p><formula xml:id="formula_22">ğ‘ (ğ‘‹ &lt;<label>1</label></formula><p>2</p><formula xml:id="formula_23">) = ğ‘ (ğ‘‹ -ğ¸ [ğ‘‹ ] &lt; 1 2 -ğœ‚) &lt; exp (-2ğ‘ (<label>1 2</label></formula><p>-ğœ‚) 2 ). ( <ref type="formula">14</ref>)</p><p>By setting ğ›¿ = exp (-2ğ‘ ( 1 2 -ğœ‚) 2 ), we have when ğ‘ is larger than Proof. For a hypothesis ğ‘“ âˆˆ F , suppose its prediction error is ğ‘  (i.e., I(ğ‘” ğ‘“ â‰  ğ‘”) = ğ‘ ) <ref type="foot" target="#foot_3">5</ref> , then the mis-matching probability between the observed and predicted results comes from two parts:</p><p>â€¢ The observed result is true, but the prediction is wrong, that is, ğ‘  (1 -ğœ ).</p><p>â€¢ The observed result is wrong, but the prediction is right, that is (1 -ğ‘ )ğœ . Thus, the total mis-matching probability is ğœ +ğ‘  (1 -2ğœ ). Suppose the prediction error of ğ‘“ (i.e., ğ‘ ) is larger than ğœ–, Then, at least one of the following statements hold:</p><p>â€¢ The empirical mis-matching rate of ğ‘“ is smaller than ğœ + ğ‘ (1-2ğœ ) 2 .</p><p>â€¢ The empirical mis-matching rate of the optimal ğ‘“ * is larger than ğœ + ğœ– (1-2ğœ ) 2</p><p>. These statements are easy to understand, since if both of them do not hold, we can conclude that the empirical loss of ğ‘“ is larger than that of ğ‘“ * , which does not agree with the ERM definition. However, according to the Hoffding inequality <ref type="bibr" target="#b28">[29]</ref>, both of the above statements hold with the probability smaller than ğ›¿, which implies that the prediction error of ğ‘“ is smaller than ğœ– with the probability larger than 1 -ğ›¿. â–¡</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(b)): U represents the user profiles, R is the recommendation list, and S indicates the selection of the user from R. The new training samples are generated by collecting the user feedback S with different interventions on R.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) is the general framework of our idea. (b) is the structure causal model of the recommender simulator. (c) and (d) are two different intervention methods.</figDesc><graphic coords="2,58.68,83.69,228.23,156.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 1 )</head><label>1</label><figDesc>We formulate the recommendation problem within Pearl's causal inference framework, which allows us to generate more training samples for more sufficient model optimization. (2) We design a learning-based intervention method, which can lead to more informative training samples for optimizing the target ranking model. (3) We theoretically analyze the relation between the potential prediction error of the structural equation models and the number of generated samples. (4) Inspired by the above theory, we propose a heuristic method to control the quality of the generated samples. (5) We conduct extensive experiments based on both synthetic and real-world datasets to verify the effectiveness of our model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>is a weighting parameter. The user and item properties are encoded by the metrics of ğ‘¿ âˆˆ R |U |Ã—ğ‘‘ ğ‘† and ğ’€ âˆˆ R |I |Ã—ğ‘‘ ğ‘† , respectively, and ğ‘‘ ğ‘† is the embedding size. In ğ‘ ğ‘¹ and ğ‘ ğ‘º , we represent the users and items with different embedding metrics. This can more flexibly characterize the system impression model (i.e., U â†’ R in Figure1(b)) and the user response model (i.e., U â†’ S in Figure1(b)), which usually hold different promises in real recommender systems. 3.1.2 Learning ğ¹ . Suppose the training set is O</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 1 : 5 for each user Ã» do 6 7 Derive 8 Train</head><label>15678</label><figDesc>Learning algorithm of CPR1 Learn the SEMs based on objective (6) and<ref type="bibr" target="#b6">(7)</ref>. 2 Train the target model ğ‘“ based the original dataset. 3 Pre-train the Gaussian policy ğœ‹ according to Algorithm 2. 4 for Iteration number k in [1, K] do Select an action Ï„ğ‘¡ according to ğœ‹ ( Ï„ğ‘¡ | Ã», ğœ½ ). ğ¶ ( Ï„ğ‘¡ ) based on Ï„ğ‘¡ . ğ‘“ based on ğ¶ ( Ï„ğ‘¡ ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>11 Algorithm 2 : 6 Sample 7 Derive</head><label>11267</label><figDesc>Making recommendation based on the ranking model ğ‘“ . Learning algorithm of ğœ‹ 1 Initialize the parameter set ğœ½ in the Gaussian policy. 2 for episode number in [1, K] do 3 for t in [1, T] do 4 Sample a user Ã». 5 Select an action Ï„ğ‘¡ according to ğœ‹ ( Ï„ğ‘¡ | Ã», ğœ½ ) + ğ‘ ğ‘¡ , where ğ‘ ğ‘¡ is an exploration noise. ğœ¶ and ğœ· from their posteriors. ğ¶ ( Ï„ğ‘¡ ) and the reward ğ¿ ğ‘“ (ğ¶ ( Ï„ğ‘¡ )) based on Ï„ğ‘¡ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>8 end 9 ğœ½</head><label>89</label><figDesc>â† ğœ½ + ğ›¼ [ ğ‘‡ ğ‘¡ =1 ğ¿ ğ‘“ (ğ¶ ( Ï„ğ‘¡ ))âˆ‡ ğœƒ log (ğœ‹ (ğ’“ ğ‘¡ |ğœƒ ))]. 10 end</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>log 1 ğ›¿ 2 ( 1 -</head><label>121</label><figDesc>2ğœ‚) 2 samples on (ğ‘–, ğ‘—) to ensure that the prediction error is smaller that ğ›¿.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>7 APPENDIX 7 . 1</head><label>771</label><figDesc>Proof of the Theories in Section 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>3</head><label>3</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>7. 1 . 1</head><label>11</label><figDesc>Proof of theory 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>log 1 ğ›¿ 2 ( 1 - 7 . 1 . 2</head><label>121712</label><figDesc>2ğœ‚) 2 , ğ‘ (ğ‘‹ &lt; 1 2 ) &lt; ğ›¿, which means the prediction error is smaller than ğ›¿.â–¡ Proof of theory 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Performance comparison based on the synthetic dataset. We present the relative improvements of our framework over the target model in the parentheses.</figDesc><table><row><cell>Feedback Function</cell><cell></cell><cell cols="2">Linear</cell><cell></cell><cell></cell><cell cols="2">Non-Linear</cell><cell></cell></row><row><cell>User/Item Dimension</cell><cell cols="2">d=16</cell><cell cols="2">d=32</cell><cell></cell><cell>d=16</cell><cell cols="2">d=32</cell></row><row><cell>Metrics</cell><cell>HR@10</cell><cell>NDCG@10</cell><cell>HR@10</cell><cell>NDCG@10</cell><cell>HR@10</cell><cell>NDCG@10</cell><cell>HR@10</cell><cell>NDCG@10</cell></row><row><cell>ItemPop</cell><cell>0.1450</cell><cell>0.0695</cell><cell>0.1219</cell><cell>0.0597</cell><cell>0.3522</cell><cell>0.1849</cell><cell>0.3289</cell><cell>0.1727</cell></row><row><cell>ItemKNN</cell><cell>0.1351</cell><cell>0.0632</cell><cell>0.1188</cell><cell>0.0544</cell><cell>0.3477</cell><cell>0.1663</cell><cell>0.3289</cell><cell>0.1626</cell></row><row><cell>CDAE</cell><cell>0.1179</cell><cell>0.0550</cell><cell>0.1071</cell><cell>0.0507</cell><cell>0.1869</cell><cell>0.0917</cell><cell>0.1421</cell><cell>0.0661</cell></row><row><cell>BPR</cell><cell>0.1567</cell><cell>0.0852</cell><cell>0.1388</cell><cell>0.0712</cell><cell>0.3799</cell><cell>0.2162</cell><cell>0.3636</cell><cell>0.2052</cell></row><row><cell>CPR-BPR-r</cell><cell>0.1632</cell><cell>0.0861</cell><cell>0.1465</cell><cell>0.0788</cell><cell>0.3748</cell><cell>0.2118</cell><cell>0.3615</cell><cell>0.2017</cell></row><row><cell>CPR-BPR</cell><cell>0.1652 (+5.4%)</cell><cell>0.0937 (+9.9%)</cell><cell>0.1482 (+6.7%)</cell><cell cols="3">0.0760 (+6.7%) 0.4024 (+5.9%) 0.2268 (+4.9%)</cell><cell>0.3705 (+1.8%)</cell><cell>0.2028 (-1.1%)</cell></row><row><cell>GMF</cell><cell>0.1498</cell><cell>0.0796</cell><cell>0.1304</cell><cell>0.0646</cell><cell>0.3654</cell><cell>0.1927</cell><cell>0.3487</cell><cell>0.1909</cell></row><row><cell>CPR-GMF-r</cell><cell>0.1573</cell><cell>0.0760</cell><cell>0.1373</cell><cell>0.0640</cell><cell>0.3830</cell><cell>0.2014</cell><cell>0.3606</cell><cell>0.1886</cell></row><row><cell>CPR-GMF</cell><cell>0.1624 (+8.4%)</cell><cell>0.0744 (-6.5%)</cell><cell>0.1344 (+3.0%)</cell><cell>0.0642 (-0.6%)</cell><cell cols="2">0.3808 (+4.2%) 0.1944 (+0.8%)</cell><cell>0.3576 (+2.5%)</cell><cell>0.1891 (-0.9%)</cell></row><row><cell>MLP</cell><cell>0.1421</cell><cell>0.0705</cell><cell>0.1174</cell><cell>0.0582</cell><cell>0.3603</cell><cell>0.1886</cell><cell>0.3286</cell><cell>0.1718</cell></row><row><cell>CPR-MLP-r</cell><cell>0.1422</cell><cell>0.0641</cell><cell>0.1197</cell><cell>0.0593</cell><cell>0.3842</cell><cell>0.1949</cell><cell>0.3626</cell><cell>0.1861</cell></row><row><cell>CPR-MLP</cell><cell cols="8">0.1592 (+12.0%) 0.0802 (+13.7%) 0.1331 (+13.3%) 0.0608 (+4.4%) 0.3831 (+6.3%) 0.1940 (+2.8%) 0.3668 (+11.6%) 0.1897 (+10.4%)</cell></row><row><cell>NeuMF</cell><cell>0.1524</cell><cell>0.0758</cell><cell>0.1203</cell><cell>0.0598</cell><cell>0.3679</cell><cell>0.1917</cell><cell>0.3350</cell><cell>0.1754</cell></row><row><cell>CPR-NeuMF-r</cell><cell>0.1731</cell><cell>0.0937</cell><cell>0.1582</cell><cell>0.0815</cell><cell>0.3915</cell><cell>0.2122</cell><cell>0.3701</cell><cell>0.1971</cell></row><row><cell>CPR-NeuMF</cell><cell cols="8">0.1851 (+21.4%) 0.0963 (+27.0%) 0.1667 (+38.5%) 0.0835 (+39.6%) 0.4007 (+8.9%) 0.2166 (+12.9%) 0.3724 (+11.1%) 0.2019 (+15.1%)</cell></row><row><cell>LightGCN</cell><cell>0.1503</cell><cell>0.0725</cell><cell>0.1262</cell><cell>0.0605</cell><cell>0.3732</cell><cell>0.1915</cell><cell>0.3451</cell><cell>0.1744</cell></row><row><cell>CPR-LightGCN-r</cell><cell>0.1600</cell><cell>0.0834</cell><cell>0.1317</cell><cell>0.0643</cell><cell>0.3759</cell><cell>0.2008</cell><cell>0.3482</cell><cell>0.1817</cell></row><row><cell>CPR-LightGCN</cell><cell cols="6">0.1677 (+11.6%) 0.0879 (+21.2%) 0.1551 (+22.9%) 0.0836 (+38.2%) 0.3829 (+2.5%) 0.2016 (+5.3%)</cell><cell>0.3576 (+3.6%)</cell><cell>0.1862 (+6.7%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Effects of the noisy control parameter ğ‘˜, the best performance for each method and setting are labeled by bold fonts. Effects of the noisy control parameter ğ‘˜.</figDesc><table><row><cell></cell><cell>ğ‘ ğ‘¦</cell><cell></cell><cell cols="2">N (0, 0.2)</cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Dimension</cell><cell></cell><cell>p=16</cell><cell></cell><cell>p=32</cell><cell></cell><cell>p=16</cell><cell></cell><cell>p=32</cell></row><row><cell></cell><cell>Metrics</cell><cell>HR@10</cell><cell>NDCG@10</cell><cell>HR@10</cell><cell>NDCG@10</cell><cell>HR@10</cell><cell>NDCG@10</cell><cell>HR@10</cell><cell>NDCG@10</cell></row><row><cell></cell><cell>ğ‘˜ = 1</cell><cell>0.3591</cell><cell>0.1876</cell><cell>0.3119</cell><cell>0.1780</cell><cell>0.4024</cell><cell>0.2268</cell><cell>0.3663</cell><cell>0.1971</cell></row><row><cell>CPR-BPR</cell><cell>ğ‘˜ = 2</cell><cell>0.3609</cell><cell>0.2011</cell><cell>0.3098</cell><cell>0.1762</cell><cell>0.3936</cell><cell>0.2250</cell><cell>0.3705</cell><cell>0.2028</cell></row><row><cell></cell><cell>ğ‘˜ = 3</cell><cell>0.3580</cell><cell>0.1891</cell><cell>0.3011</cell><cell>0.1665</cell><cell>0.3877</cell><cell>0.2090</cell><cell>0.3647</cell><cell>0.1914</cell></row><row><cell></cell><cell>ğ‘˜ = 1</cell><cell>0.3437</cell><cell>0.1827</cell><cell>0.2994</cell><cell>0.1593</cell><cell>0.3725</cell><cell>0.1983</cell><cell>0.3470</cell><cell>0.1869</cell></row><row><cell>CPR-GMF</cell><cell>ğ‘˜ = 2</cell><cell>0.3402</cell><cell>0.1762</cell><cell>0.2941</cell><cell>0.1575</cell><cell>0.3808</cell><cell>0.1944</cell><cell>0.3576</cell><cell>0.1891</cell></row><row><cell></cell><cell>ğ‘˜ = 3</cell><cell>0.3354</cell><cell>0.1709</cell><cell>0.2948</cell><cell>0.1588</cell><cell>0.3564</cell><cell>0.1841</cell><cell>0.3800</cell><cell>0.1945</cell></row><row><cell></cell><cell>ğ‘˜ = 1</cell><cell>0.3580</cell><cell>0.1812</cell><cell>0.3051</cell><cell>0.1560</cell><cell>0.3592</cell><cell>0.1868</cell><cell>0.3625</cell><cell>0.1853</cell></row><row><cell>CPR-MLP</cell><cell>ğ‘˜ = 2</cell><cell>0.3537</cell><cell>0.1794</cell><cell>0.2878</cell><cell>0.1465</cell><cell>0.3820</cell><cell>0.1937</cell><cell>0.3611</cell><cell>0.1840</cell></row><row><cell></cell><cell>ğ‘˜ = 3</cell><cell>0.3574</cell><cell>0.1798</cell><cell>0.2886</cell><cell>0.1469</cell><cell>0.3831</cell><cell>0.1940</cell><cell>0.3668</cell><cell>0.1897</cell></row><row><cell></cell><cell>ğ‘˜ = 1</cell><cell>0.3559</cell><cell>0.1800</cell><cell>0.3046</cell><cell>0.1607</cell><cell>0.3865</cell><cell>0.2005</cell><cell>0.3631</cell><cell>0.1851</cell></row><row><cell>CPR-NeuMF</cell><cell>ğ‘˜ = 2</cell><cell>0.3511</cell><cell>0.1799</cell><cell>0.2870</cell><cell>0.1412</cell><cell>0.3939</cell><cell>0.2115</cell><cell>0.3724</cell><cell>0.2019</cell></row><row><cell></cell><cell>ğ‘˜ = 3</cell><cell>0.3552</cell><cell>0.1793</cell><cell>0.2990</cell><cell>0.1644</cell><cell>0.4007</cell><cell>0.2166</cell><cell>0.3643</cell><cell>0.1883</cell></row><row><cell></cell><cell>ğ‘˜ = 1</cell><cell>0.3512</cell><cell>0.1805</cell><cell>0.2935</cell><cell>0.1556</cell><cell>0.3739</cell><cell>0.1952</cell><cell>0.3550</cell><cell>0.1886</cell></row><row><cell>CPR-LightGCN</cell><cell>ğ‘˜ = 2</cell><cell>0.3365</cell><cell>0.1764</cell><cell>0.2794</cell><cell>0.1499</cell><cell>0.3818</cell><cell>0.2014</cell><cell>0.3528</cell><cell>0.1876</cell></row><row><cell></cell><cell>ğ‘˜ = 3</cell><cell>0.3489</cell><cell>0.1791</cell><cell>0.2962</cell><cell>0.1569</cell><cell>0.3583</cell><cell>0.1874</cell><cell>0.3462</cell><cell>0.1813</cell></row><row><cell>4.2.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Overall results on the real-world dataset.</figDesc><table><row><cell>Model</cell><cell>H@10</cell><cell>NDCG@10</cell></row><row><cell>ItemPop</cell><cell>0.3374</cell><cell>0.1608</cell></row><row><cell>ItemKNN</cell><cell>0.2403</cell><cell>0.1299</cell></row><row><cell>CDAE</cell><cell>0.3403</cell><cell>0.1637</cell></row><row><cell>BPR</cell><cell>0.3440</cell><cell>0.1685</cell></row><row><cell>CPR-BPR-r</cell><cell>0.3524</cell><cell>0.1718</cell></row><row><cell>CPR-BPR</cell><cell>0.3526 (+2.50%)</cell><cell>0.1810 (+7.41%)</cell></row><row><cell>GMF</cell><cell>0.3453</cell><cell>0.1651</cell></row><row><cell>CPR-GMF-r</cell><cell>0.3525</cell><cell>0.1686</cell></row><row><cell>CPR-GMF</cell><cell>0.3519 (+1.91%)</cell><cell>0.1713 (+3.75%)</cell></row><row><cell>MLP</cell><cell>0.3469</cell><cell>0.1662</cell></row><row><cell>CPR-MLP-r</cell><cell>0.3560</cell><cell>0.1702</cell></row><row><cell>CPR-MLP</cell><cell>0.3526 (+1.64%)</cell><cell>0.1747 (+5.11%)</cell></row><row><cell>NeuMF</cell><cell>0.3381</cell><cell>0.1630</cell></row><row><cell>CPR-NeuMF-r</cell><cell>0.3466</cell><cell>0.1662</cell></row><row><cell>CPR-NeuMF</cell><cell>0.3512 (+3.87%)</cell><cell>0.1755 (+7.66%)</cell></row><row><cell>LightGCN</cell><cell>0.3451</cell><cell>0.1658</cell></row><row><cell>CPR-LightGCN-r</cell><cell>0.3521</cell><cell>0.1719</cell></row><row><cell>CPR-LightGCN</cell><cell>0.3688 (+6.86%)</cell><cell>0.1830 (+10.4%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Performances on the items with different coldnesses.</figDesc><table><row><cell>Popularity</cell><cell cols="2">Low</cell><cell cols="2">Middle</cell><cell></cell><cell>High</cell></row><row><cell>Metrics</cell><cell>HR@10</cell><cell>NDCG@10</cell><cell>HR@10</cell><cell>NDCG@10</cell><cell>HR@10</cell><cell>NDCG@10</cell></row><row><cell>BPR</cell><cell>0.0367</cell><cell>0.0113</cell><cell>0.4165</cell><cell>0.1426</cell><cell>0.8966</cell><cell>0.4937</cell></row><row><cell>CPR-BPR</cell><cell>0.0380 (3.54%)</cell><cell>0.0121 (7.08%)</cell><cell>0.4494 (7.90%)</cell><cell>0.1602 (12.34%)</cell><cell cols="2">0.8930 (-0.40%) 0.5027 (1.82%)</cell></row><row><cell>GMF</cell><cell>0.0079</cell><cell>0.0023</cell><cell>0.3715</cell><cell>0.1163</cell><cell>0.9157</cell><cell>0.4793</cell></row><row><cell>CPR-GMF</cell><cell>0.0092 (16.46%)</cell><cell>0.0027 (17.39%)</cell><cell>0.4028 (8.43%)</cell><cell>0.1270 (9.20%)</cell><cell cols="2">0.9152 (-0.05%) 0.4810 (0.35%)</cell></row><row><cell>MLP</cell><cell>0.0154</cell><cell>0.0046</cell><cell>0.3531</cell><cell>0.1130</cell><cell>0.9240</cell><cell>0.4845</cell></row><row><cell>CPR-MLP</cell><cell>0.0196 (27.27%)</cell><cell cols="5">0.0059 (28.26%) 0.4091 (15.86%) 0.13656 (20.85%) 0.9261 (0.23%) 0.4870 (0.52%)</cell></row><row><cell>NeuMF</cell><cell>0.0246</cell><cell>0.0075</cell><cell>0.3010</cell><cell>0.0970</cell><cell>0.9018</cell><cell>0.4782</cell></row><row><cell>CPR-NeuMF</cell><cell>0.0277 (12.60%)</cell><cell cols="3">0.0085 (13.33%) 0.3940 (30.90%) 0.1271 (31.03%)</cell><cell cols="2">0.9182 (1.82%) 0.4872(1.88%)</cell></row><row><cell>LightGCN</cell><cell>0.0172</cell><cell>0.0051</cell><cell>0.3385</cell><cell>0.1061</cell><cell>0.9171</cell><cell>0.4781</cell></row><row><cell cols="5">CPR-LightGCN 0.0433 (151.74%) 0.0134 (162.75%) 0.4769 (40.89%) 0.1601 (50.90%)</cell><cell cols="2">0.9115 (-0.61%) 0.4860 (1.65%)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In practice, the positive feedback can be click, purchase, download, and etc.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Here, if we consider the order of the recommended item, the candidate item space can be even larger.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>For improving the accuracy, ğœ¶ is sampled multiple times for implementation, and the loss is averaged across different ğœ¶ 's.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>ğ‘” ğ‘“ is the prediction from ğ‘“ , and ğ‘” is the ground truth.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">FairyTED: A Fair Rating Predictor for TED Talk Data</title>
		<author>
			<persName><forename type="first">Rupam</forename><surname>Acharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shouman</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankani</forename><surname>Chattoraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Iftekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanveer</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="338" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Specifying object attributes and relations in interactive scene generation</title>
		<author>
			<persName><forename type="first">Oron</forename><surname>Ashual</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4561" to="4569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Variational inference: A review for statisticians</title>
		<author>
			<persName><forename type="first">Alp</forename><surname>David M Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><forename type="middle">D</forename><surname>Kucukelbir</surname></persName>
		</author>
		<author>
			<persName><surname>Mcauliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American statistical Association</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="859" to="877" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Causal embeddings for recommendation</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Bonner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Flavian</forename><surname>Vasile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM conference on recommender systems</title>
		<meeting>the 12th ACM conference on recommender systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="104" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hande</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.03240</idno>
		<title level="m">Fuli Feng, Meng Wang, and Xiangnan He. 2020. Bias and Debias in Recommender System: A Survey and Future Directions</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Counterfactual critic multi-agent training for scene graph generation</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiliang</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shih-Fu</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4613" to="4623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Wide &amp; deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">Heng-Tze</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Levent</forename><surname>Koc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremiah</forename><surname>Harmsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrishi</forename><surname>Aradhye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glen</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Ispir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st workshop on deep learning for recommender systems</title>
		<meeting>the 1st workshop on deep learning for recommender systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep neural networks for youtube recommendations</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM conference on recommender systems</title>
		<meeting>the 10th ACM conference on recommender systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Are we really making much progress? A worrying analysis of recent neural recommendation approaches</title>
		<author>
			<persName><forename type="first">Maurizio</forename><surname>Ferrari Dacrema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dietmar</forename><surname>Jannach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM Conference on Recommender Systems</title>
		<meeting>the 13th ACM Conference on Recommender Systems<address><addrLine>RecSys; Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-09-16">2019. 2019. September 16-20, 2019</date>
			<biblScope unit="page" from="101" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An improved sampler for bayesian personalized ranking by leveraging view data</title>
		<author>
			<persName><forename type="first">Jingtao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanghui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Depeng</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the The Web Conference</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="13" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Counterfactual learning for recommender system</title>
		<author>
			<persName><forename type="first">Zhenhua</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengxiang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinhua</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohao</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jirong</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourteenth ACM Conference on Recommender Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="568" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Counterfactual Vision-and-Language Navigation via Adversarial Path Sampler</title>
		<author>
			<persName><forename type="first">Tsu-Jui</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">F</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><forename type="middle">P</forename><surname>Scott T Grafton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Eckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="71" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Self-paced network embedding</title>
		<author>
			<persName><forename type="first">Hongchang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1406" to="1415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Yash</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07451</idno>
		<title level="m">Counterfactual visual explanations</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Deepfm: An end-to-end wide &amp; deep learning framework for CTR prediction</title>
		<author>
			<persName><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhua</forename><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.04950</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong-Dong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR conference on research and development in Information Retrieval<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020-07-25">2020. July 25-30, 2020</date>
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
	<note>SIGIR 2020, Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adversarial personalized ranking for recommendation</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhankui</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
	<note>Xiaoyu Du, and Tat-Seng Chua</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th international conference on world wide web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th international conference on world wide web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations, ICLR 2015</title>
		<editor>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07">2015. May 7-9, 2015</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A general knowledge distillation framework for counterfactual recommendation via uniform data</title>
		<author>
			<persName><forename type="first">Dugang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengxiang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhua</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weike</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhong</forename><surname>Ming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="831" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural personalized ranking for image recommendation</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Caverlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haokai</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Eleventh ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="423" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-Performance Deep Learning Library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>KÃ¶pf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08">2019. 2019. 2019. December 8-14, 2019</date>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Causality</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Causal inference in statistics: A primer</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madelyn</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">P</forename><surname>Jewell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Elements of causal inference: foundations and learning algorithms</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence</title>
		<meeting>the twenty-fifth conference on uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unbiased Pairwise Learning from Implicit Feedback</title>
		<author>
			<persName><forename type="first">Yuta</forename><surname>Saito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2019 Workshop on Causal Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashudeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navin</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.05352</idno>
		<title level="m">Recommendations as treatments: Debiasing learning and evaluation</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Understanding machine learning: From theory to algorithms</title>
		<author>
			<persName><forename type="first">Shai</forename><surname>Shalev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Shwartz</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unifying userbased and item-based collaborative filtering approaches by similarity fusion</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjen</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcel</forename><forename type="middle">J T</forename><surname>Reinders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR 2006: Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting><address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006-08-06">2006. August 6-11, 2006</date>
			<biblScope unit="page" from="501" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Irgan: A minimax game for unifying generative and discriminative information retrieval models</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lantao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinghui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dell</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="515" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep &amp; cross network for ad click predictions</title>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingliang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ADKDD&apos;17</title>
		<meeting>the ADKDD&apos;17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Neural Graph Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Counterfactual Data-Augmented Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Zhenlei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingsen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongteng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="347" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">MIND: A Large-scale Dataset for News Recommendation</title>
		<author>
			<persName><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiun-Hung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuhan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Winnie</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">July 5-10, 2020</date>
			<biblScope unit="page" from="3597" to="3606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Collaborative Denoising Auto-Encoders for Top-N Recommender Systems</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Ninth ACM International Conference on Web Search and Data Mining<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016-02-22">2016. February 22-25, 2016</date>
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unbiased offline recommender evaluation for missing-not-atrandom implicit feedback</title>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM Conference on Recommender Systems</title>
		<meeting>the 12th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
	<note>Serge Belongie, and Deborah Estrin</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Collaborative Knowledge Base Embedding for Recommender Systems</title>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Jing Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<editor>
			<persName><forename type="first">Balaji</forename><surname>Krishnapuram</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mohak</forename><surname>Shah</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Charu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dou</forename><surname>Aggarwal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rajeev</forename><surname>Shen</surname></persName>
		</editor>
		<editor>
			<persName><surname>Rastogi</surname></persName>
		</editor>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016-08-13">2016. August 13-17, 2016</date>
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">RecBole: Towards a Unified, Comprehensive and Efficient Framework for Recommendation Algorithms</title>
		<author>
			<persName><forename type="first">Shanlei</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiyuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushuo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changxin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingyu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqian</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoling</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Wen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.01731</idno>
		<ptr target="https://arxiv.org/abs/2011.01731" />
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoye</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.00209</idno>
		<title level="m">Deep reinforcement learning for list-wise recommendations</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Ran</forename><surname>Zmigrod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabrina</forename><forename type="middle">J</forename><surname>Mielke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanna</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.04571</idno>
		<title level="m">Counterfactual data augmentation for mitigating gender stereotypes in languages with rich morphology</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Focused Context Balancing for Robust Offline Policy Evaluation</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peixuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<idno type="DOI">10.1145/3292500.3330852</idno>
		<ptr target="https://doi.org/10.1145/3292500.3330852" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<editor>
			<persName><forename type="first">Ankur</forename><surname>Teredesai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vipin</forename><surname>Kumar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ying</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">RÃ³mer</forename><surname>Rosales</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Evimaria</forename><surname>Terzi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</editor>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining<address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-08-04">2019. 2019. August 4-8, 2019</date>
			<biblScope unit="page" from="696" to="704" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
