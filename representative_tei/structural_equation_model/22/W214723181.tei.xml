<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HYPER-PARAMETER SELECTION IN BAYESIAN STRUCTURAL EQUATION MODELS</title>
				<funder>
					<orgName type="full">Japan Society for the Promotion of Science. Research Fellow of the Japan Society for the Promotion of Science</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kei</forename><surname>Hirose</surname></persName>
							<email>k-hirose@math.kyushu-u.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Mathematics</orgName>
								<orgName type="institution">Kyushu University</orgName>
								<address>
									<addrLine>744 Motooka Nishi-ku</addrLine>
									<postCode>819-0395</postCode>
									<settlement>Fukuoka</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuichi</forename><surname>Kawano</surname></persName>
							<email>skawano@ims.u-tokyo.ac.jp</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Medical Science</orgName>
								<orgName type="institution">University of Tokyo</orgName>
								<address>
									<addrLine>4-6-1 Shirokanedai Minato-ku</addrLine>
									<postCode>108-8639</postCode>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daisuke</forename><surname>Miike</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Graduate School of Mathematics</orgName>
								<orgName type="institution">Kyushu University</orgName>
								<address>
									<addrLine>744 Motooka Nishi-ku</addrLine>
									<postCode>819-0395</postCode>
									<settlement>Fukuoka</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sadanori</forename><surname>Konishi</surname></persName>
							<email>konishi@math.chuo-u.ac.jp</email>
							<affiliation key="aff3">
								<orgName type="department">Soft service Co</orgName>
								<address>
									<addrLine>Ltd. 3-3-22 Hakataeki-Higashi Hakata-ku</addrLine>
									<postCode>812- 0013</postCode>
									<settlement>Fukuoka</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Chuo University</orgName>
								<address>
									<addrLine>1-3-27 Bunkyo-ku</addrLine>
									<postCode>112-8551</postCode>
									<settlement>Kasuga Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">HYPER-PARAMETER SELECTION IN BAYESIAN STRUCTURAL EQUATION MODELS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.5109/25906</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian approach</term>
					<term>Improper solutions</term>
					<term>Model selection criterion</term>
					<term>Prior distribution</term>
					<term>Structural equation modeling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the structural equation models, the maximum likelihood estimates of error variances can often turn out to be zero or negative. In order to overcome this problem, we take a Bayesian approach by specifying a prior distribution for variances of error variables. Crucial issues in this modeling procedure include the selection of hyper-parameters in the prior distribution. Choosing these parameters can be viewed as a model selection and evaluation problem. We derive a model selection criterion for evaluating a Bayesian structural equation model. Monte Carlo simulations are conducted to investigate the effectiveness of the proposed modeling procedure. A real data example is also given to illustrate our procedure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Structural equation models that include the factor analysis model and model in path analysis play an essential role in various fields of research such as social, educational, behavioral and biological sciences, public health, and medical research (see, e.g., <ref type="bibr" target="#b2">Bentler and Stein, 1992;</ref><ref type="bibr">Jörekog and Sörbom, 1996;</ref><ref type="bibr" target="#b23">Pugesek et al., 2003;</ref><ref type="bibr" target="#b27">Xiong et al., 2004;</ref><ref type="bibr" target="#b17">Liu et al., 2008)</ref>.</p><p>The structural equation model is usually estimated by maximum likelihood methods under the assumption that the observations are normally distributed. In practice, however, the maximum likelihood estimates of error variances can often turn out to be zero or negative. Such estimates are known as improper solutions, and many authors have studied these inappropriate estimates both from a theoretical point of view and also by means of numerical examples (see, e.g., <ref type="bibr" target="#b26">van Driel, 1978;</ref><ref type="bibr" target="#b1">Anderson and Gerbing, 1984;</ref><ref type="bibr" target="#b5">Boomsma, 1985;</ref><ref type="bibr" target="#b9">Gerbing and Anderson, 1987;</ref><ref type="bibr" target="#b7">Chen et al., 2001;</ref><ref type="bibr" target="#b8">Flora and Curran, 2004)</ref>. In order to prevent the occurrence of improper solutions in structural equation model, we employ a Bayesian approach by specifying a prior distribution for error variances.</p><p>An essential point in the Bayesian approach is the choice of a prior distribution. In the factor analysis model which is the special case of structural equation model, some prior distributions have been proposed by earlier authors (see, e.g., <ref type="bibr" target="#b18">Martin and McDonald, 1975;</ref><ref type="bibr" target="#b0">Akaike, 1987;</ref><ref type="bibr" target="#b10">Hirose et al., 2010;</ref><ref type="bibr" target="#b28">Yoshida and West, 2010)</ref>. <ref type="bibr" target="#b0">Akaike (1987)</ref> introduced a spherical normal distribution of the standardized factor loadings, which is theoretically derived from the information extracted from the knowledge of the likelihood function, and numerical examples show that it can prevent the occurrence of improper solutions. Thus, <ref type="bibr" target="#b0">Akaike's (1987)</ref> prior distribution seems to be attractive. It is, however, difficult to apply his prior distribution directly to the structural equation models, since the covariance structure of structural equation model is too complex to derive the standardized spherical normal distribution. <ref type="bibr" target="#b10">Hirose et al. (2010)</ref> considered a prior distribution for unique variances in factor analysis model and used exponential distributions for the inverses of unique variances. In this paper we derive an inverse exponential distribution for error variances in the structural equation models according to the basic idea given by <ref type="bibr" target="#b0">Akaike (1987)</ref> and <ref type="bibr" target="#b10">Hirose et al. (2010)</ref>. The model is then estimated by posterior modes.</p><p>In the Bayesian structural equation models, the hyper-parameters in the prior distribution are often subjectively given. However, the modeling procedure based on such subjective hyper-parameters does not always provide appropriate estimates. Therefore, it is important to select suitable values of hyper-parameters by using an information extracted from the data. Choosing these parameters can be viewed as a model selection and evaluation problem. The AIC <ref type="bibr" target="#b0">(Akaike, 1987)</ref>, BIC <ref type="bibr" target="#b24">(Schwarz, 1978)</ref> and other selection criteria (e.g., <ref type="bibr" target="#b6">Bozdogan, 1987;</ref><ref type="bibr" target="#b21">Ninomiya et al., 2008)</ref> cannot be directly applied to the Bayesian structural equation model since these criteria cover only models estimated by the maximum likelihood methods. In this paper, we derive a model selection criterion from a Bayesian point of view <ref type="bibr" target="#b13">(Konishi et al., 2004)</ref> for evaluating Bayesian structural equation models. The proposed modeling procedure is investigated by conducting Monte Carlo simulations and analyzing a real data. Numerical results show that our modeling strategy prevents the occurrence of improper solutions and often yields stable estimates.</p><p>The remainder of this paper is organized as follows: Section 2 describes maximum likelihood methods for structural equation model. In Section 3, we introduce a Bayesian structural equation modeling. Section 4 describes Monte Carlo simulations to investigate the performance of our modeling procedure. Section 5 illustrates the proposed procedure with a real data example. Some concluding remarks are given in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Maximum likelihood procedure for structural equation model</head><p>A number of models for the analysis of covariance structure, such as LISREL <ref type="bibr" target="#b4">(Bock and Bargmann, 1966;</ref><ref type="bibr" target="#b11">Jöreskog, 1970)</ref>，EQS <ref type="bibr" target="#b3">(Bentler and Weeks, 1980)</ref> and RAM <ref type="bibr" target="#b19">(McArdle, 1980;</ref><ref type="bibr" target="#b20">McArdle and McDonald, 1984)</ref>, have been proposed. We use the RAM model because the description of this model is quite simple and it generalizes the LISREL and EQS.</p><p>First, we define p-dimensional observable random vector, m-dimensional latent vari-ables and p-dimensional error variables given in the following: </p><formula xml:id="formula_0">f = (f 1 , • • • , f m ) ′ ： m-dimensional latent random vector, x = (x 1 , • • • , x p ) ′ ： p-dimensional observable random vector, t = (f ′ , x ′ ) ′ : q (= m+p)-dimensional</formula><formula xml:id="formula_1">= At + u, (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>where A = (a ij ) is a q × q-coefficient matrix for structural variables．Note that the diagonal elements of A are zeros because the path from a variable to the same variable does not make any sense. Next, we calculate the variance-covariance matrix of x. Suppose that there exists an inverse matrix T = (I q -A) -1 , where I q is a q × q identity matrix. From Equation (1), we have t = T u.</p><p>The observable random vector x is then given by</p><formula xml:id="formula_3">x = GT u,</formula><p>where G is a p × q-matrix which extracts the observable variables from the structural variables:</p><formula xml:id="formula_4">G = [O p×m I p ],</formula><p>with O p×m being p × m 0-matrix. Then, the variancecovariance matrix of x is given by</p><formula xml:id="formula_5">Σ(θ) = GT Σ u T ′ G ′ ,</formula><p>where θ is a k-dimensional unknown parameter vector. The unknown parameters in the structural equation models are the coefficient matrix A and a lower triangular part of variance-covariance matrix Σ u . Note that most of the elements of A and Σ u are fixed by 0 or 1 according to researcher's hypothesis. The parameter vector θ is constructed by eliminating these fixed parts.</p><p>The structural equation model is usually estimated by the maximum likelihood procedure. Suppose that we have a random sample of</p><formula xml:id="formula_6">N observations x 1 , • • • , x N from the p-dimensional normal population N p (0, GT Σ u T ′ G ′ ). The log-likelihood function is then given by log f (x 1 , • • • , x N |θ) = - N 2 { p log(2π) + log |Σ(θ)| + tr(Σ(θ) -1 S) } , (<label>2</label></formula><formula xml:id="formula_7">)</formula><p>where S is a sample variance-covariance matrix</p><formula xml:id="formula_8">S = 1 N N ∑ n=1 x n x ′ n .</formula><p>The maximum likelihood estimates of θ are given as the solutions of</p><formula xml:id="formula_9">∂ log f (x 1 , • • • , x N |θ) ∂θ = 0.</formula><p>Since the solutions cannot be expressed in a closed form, the quasi-Newton's method is usually used to obtain the maximum likelihood estimates.</p><p>In practice, however, the maximum likelihood estimates of error variances can often turn out to be zero or negative, which have been called improper solutions. In order to overcome this difficulty, we take a Bayesian approach by specifying a prior distribution for error variances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Bayesian structural equation modeling</head><p>In this section, we investigate the prior distribution for the variances of error variables, and then illustrate a selection procedure of the hyper-parameters in the prior distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Prior distributions</head><p>An important point in the Bayesian structural equation models is the selection of a prior distribution. In the factor analysis model, <ref type="bibr" target="#b10">Hirose et al. (2010)</ref> derived exponential distributions for the inverses of unique variances according to the basic idea given by <ref type="bibr" target="#b0">Akaike (1987)</ref>, and numerical examples showed that their prior distributions can prevent the occurrence of improper solutions. On the basis of their prior distributions, we use an inverse exponential distribution for error variances given by</p><formula xml:id="formula_10">π(θ|λ) = v ∏ i=1 N λ i (σ u i ) 2 exp ( - N λ i σ u i ) (σ u i &gt; 0 for i = 1, • • • , v),<label>(3)</label></formula><p>where</p><formula xml:id="formula_11">λ = (λ 1 , • • • , λ v ) ′ is a v-dimensional hyper-parameter vector with λ i &gt; 0 (i = 1, • • • , v).</formula><p>Note that this prior distribution is an inverse gamma prior distribution</p><formula xml:id="formula_12">π(σ u i |α, β) = β α Γ(α) (σ u i ) -(α+1) exp ( - β σ u i )</formula><p>with α = 1 and β = N λ i , where Γ(•) is a gamma function. Figure <ref type="figure">1</ref> shows the inverse exponential distribution when N = 100 and λ i = 0.005. It can be seen from Figure <ref type="figure">1</ref> that a probability that σ u i is close to 0 is extremely low. Thus, this prior distribution may prevent the occurrence of improper solutions.</p><p>The posterior distribution based on the prior distribution in (3) is</p><formula xml:id="formula_13">π(θ|x 1 , • • • , x N ; λ) = f (x 1 , • • • , x N |θ)π(θ|λ) ∫ f (x 1 , • • • , x N |θ)π(θ|λ)dθ ∝ f (x 1 , • • • , x N |θ)π(θ|λ).</formula><p>In this paper, the parameters θ are estimated through modes of the posterior distribution. The procedure is equivalent to obtain estimates by maximizing the penalized log-likelihood function</p><formula xml:id="formula_14">ℓ λ (θ) = log f (x 1 , • • • , x N |θ) -H N,λ (θ),<label>(4)</label></formula><p>Figure <ref type="figure">1</ref>: The inverse exponential distribution when N = 100 and λ i = 0.005.</p><p>where H N,λ (θ) is a penalty term given by the following:</p><formula xml:id="formula_15">H N,λ (θ) = v ∑ i=1 ( N λ i σ u i + 2 log σ u i ) ,</formula><p>and the hyper-parameters λ can be considered as regularization parameters. Since it is difficult to obtain the parameters that maximize the function in (4) analytically, we use a quasi-Newton's method to obtain the maximum penalized likelihood estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Model selection criterion</head><p>This subsection describes a selection process of hyper-parameters in the prior distribution. For example, the maximum likelihood estimate of σ u 1 becomes negative. When the value of λ 1 is very small, the penalized maximum likelihood estimate of σ u 1 may be close to 0. On the other hand, when the value of λ 1 is large, the penalized maximum likelihood estimate of σ u 1 also becomes large. Therefore, a crucial aspect of model construction is the choice of the regularization parameter λ 1 , • • • , λ v . In this paper, we derive a model selection criterion GBIC <ref type="bibr" target="#b13">(Konishi et al., 2004)</ref> for evaluating Bayesian structural equation models. The proposed procedure enables us to choose adjusted hyper-parameters λ 1 , • • • , λ v . For model selection criteria we refer to <ref type="bibr" target="#b14">Konishi and Kitagawa (2008)</ref> and references given therein.</p><p>The model selection criterion GBIC for evaluating the Bayesian structural equation model is given by GBIC</p><formula xml:id="formula_16">= -k log(2π) + k log N + log |J λ ( θ)| + N { p log(2π) + log |Σ( θ)| + tr(Σ( θ) -1 S) } -2 v ∑ i=1 log { N λ i (σ u i ) 2 } + 2 v ∑ i=1 N λ i σu i , (<label>5</label></formula><formula xml:id="formula_17">)</formula><p>where θ and σu i (i = 1, • • • , v) are the posterior modes, and</p><formula xml:id="formula_18">J λ ( θ) is k × k matrix J λ ( θ) = - 1 N [ ∂ 2 ∂θ∂θ ′ { log f (x 1 , • • • , x N |θ) + log π(θ|λ) } θ ] . (<label>6</label></formula><formula xml:id="formula_19">)</formula><p>The derivation of J λ (θ) is given by (A6) in Appendix A.</p><p>When we have several candidates for hyper-parameter vectors λ = (λ 1 , • • • , λ v ) ′ , the GBIC is calculated for each candidate, and then the model which minimizes the value of GBIC is selected. However, if the dimension of hyper-parameters v is large, it is difficult to calculate the GBIC for all possible candidates because it requires extremely computational load. Thus, we restrict the number of hyper-parameters as follows: PMLE 1 : All error variances have the same hyper-parameter λ 1 .</p><p>PMLE 2 : The error variances for observable variables have a hyper-parameter λ 1 and those for latent variables have a hyper-parameter λ 2 .</p><p>It can be seen that PMLE 1 is useful when all of the variances have similar values while PMLE 2 can be used when the error variances for observable variables and those for latent variables are completely different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Monte Carlo simulations</head><p>Monte Carlo simulations are conducted to investigate the performance of our proposed procedure．In this simulation study, latent variables are ξ, η, and observable variables are given by y 1 , y 2 , x 1 , x 2 . The true model is</p><formula xml:id="formula_20">          ξ η y 1 y 2 x 1 x 2           =           0</formula><p>0 0 0 0 0 0.5 0 0 0 0 0 0 1.0 0 0 0 0 0 0.6 0 0 0 0 0.7 0 0 0 0 0 0.7 0 0 0 0 0</p><formula xml:id="formula_21">                    ξ η y 1 y 2 x 1 x 2           +           ε ξ ε η ε y1 ε y2 ε x1 ε x2           , (<label>7</label></formula><formula xml:id="formula_22">)</formula><p>and the true variance-covariance matrix Σ u of u is Σ u = diag(1.0, 0.6, 0.1, 0.7, 0.5, 0.5). ( <ref type="formula">8</ref>) To estimate the true model, we assume the hypothetic model</p><formula xml:id="formula_23">          ξ η y 1 y 2 x 1 x 2           =           0 0 0 0 0 0 γ 0 0 0 0 0 0 1 0 0 0 0 0 a y2 0 0 0 0 a x1 0 0 0 0 0 a x2 0 0 0 0 0                     ξ η y 1 y 2 x 1 x 2           +           ε ξ ε η ε y1 ε y2 ε x1 ε x2          </formula><p>, with variance-covariance matrix</p><formula xml:id="formula_24">Σ u = diag(1, σ η , σ y1 , σ y2 , σ x1 , σ x2 ).</formula><p>In this case, the parameter vector is given by θ = (γ, a y2 , a x1 , a x2 , σ η , σ y1 , σ y2 , σ x1 , σ x2 ) ′ . The true variance-covariance matrix Σ = GT Σ u T ′ G ′ is calculated by using Equations ( <ref type="formula" target="#formula_21">7</ref>) and ( <ref type="formula">8</ref>), and then the data were generated 100 times with sample size N (N = 100, 150, 200). We compare the performance of our proposed procedure with that of maximum likelihood method. Table <ref type="table" target="#tab_1">1</ref> shows the frequency of improper solutions, mean squared error (MSE) for parameters, mean value of hyper-parameters (λ 1 and λ 2 ), and the mean value of the GBIC (GBIC) for MLE, PMLE 1 and PMLE 2 . The mean squared error (MSE) is given by</p><formula xml:id="formula_25">MSE = 1 100 100 ∑ d=1 ∥ θ(d) -θ 0 ∥ 2 ,</formula><p>where θ 0 are true values of θ, i.e. θ 0 = (0.5, 0.6, 0.7, 0.7, 0.6, 0.1, 0.7, 0.5, 0.5) ′ , and θ(d) are the estimates of parameters for d-th dataset. From Table <ref type="table" target="#tab_1">1</ref>, we can see that each procedure becomes better in terms of minimizing the MSE as N increase. For each N ，we obtained improper solutions several times for maximum likelihood procedure, whereas our proposed method prevented the occurrence of improper solutions for all datasets. Moreover, the MSE of PMLE 1 is much smaller than that of MLE, which means the Bayesian approach yields more stable estimates than maximum likelihood technique. In addition, the values of λ 1 , λ 2 for PMLE 2 are almost the same, and they are also similar to the value of λ 1 for PMLE 1 . Thus, it seems that PMLE 1 and PMLE 2 selected almost the same models. Tables <ref type="table" target="#tab_2">2</ref> and<ref type="table" target="#tab_3">3</ref> show the mean squared error (MSE) for each parameter. When we compared the MSE of PMLE 1 with that of MLE, a large difference occurred in σ η and σ y1 . Regarding the σ y1 , we obtained improper solutions several times since the true value of σ y1 is relatively small compared with other parameters of error variances. Consequently, the maximum likelihood estimate of σ y1 is very unstable. On the other hand, the proposed procedures PMLE 1 or PMLE 2 produced more stable estimates than MLE. For error variance σ η , the proposed methods also provide much better estimates As a result, our proposed method prevents the occurrence of improper solutions and also yields stable estimates. Also, the result of PMLE 1 is very similar to that of PMLE 2 . This is because the observable variables and exogenous variables are usually normalized and then they may not have completely different error variances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Real data example</head><p>We applied the proposed modeling procedure to the slump of personal consumption dataset <ref type="bibr" target="#b25">(Toyoda, 1998)</ref>. This data set was surveyed from 10/06/1998 to 15/07/1998. During this long period, Japan was suffering a slump. The aim of this analysis is to find out the cause of the recession by conducting a causality analysis. This dataset consists of N = 405 samples and p = 21 observable variables X 1 , • • • , X 21 , and Toyoda (1998) considered 8 latent variables F 1 , • • • , F 8 . The 8 latent variables and corresponding observable variables are given in Appendix B.</p><p>We made a hypothetic model based on <ref type="bibr" target="#b25">Toyoda (1998)</ref>, which is given in Figure <ref type="figure" target="#fig_0">2</ref>. First, the model of Figure <ref type="figure" target="#fig_0">2</ref> is estimated by maximum likelihood procedure, which is given in Figure <ref type="figure">3</ref>. This procedure produced improper solutions since the error variance for X 15 was -0.046. The standard error of error variance for X 15 was 0.649, and thus the 95% confidence interval includes 0. This means the cause of improper solutions might be sampling fluctuation (see, e.g., <ref type="bibr" target="#b26">van Driel, 1978;</ref><ref type="bibr" target="#b7">Chen et al., 2001)</ref>.</p><p>In order to prevent the occurrence of improper solutions, we applied the proposed procedures (PMLE 1 and PMLE 2 ) to this dataset. The estimates in PMLE 1 and PMLE 2 were respectively given in Figure <ref type="figure">4</ref> and Figure <ref type="figure">5</ref>. The result of GFI, AGFI and GBIC and corresponding hyper-parameters λ 1 and λ 2 for each procedure is also given in Table <ref type="table" target="#tab_4">4</ref>.</p><p>From Figure <ref type="figure">4</ref>, the penalized maximum likelihood estimate of error variance for X 15 was positive, which means the proposed procedure prevented the occurrence of improper solutions. Additionally, Figure <ref type="figure">4</ref> and 5 indicate the estimates in PMLE 2 and PMLE 1 are very similar. Moreover, the result of GFI and AGFI are also almost the same. This means it is not necessary to assume that error variances for observable variables and those for latent variables have different hyper-parameters.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Concluding and remarks</head><p>In the structural equation modeling, the maximum likelihood estimates of error variances can turn out to be zero or negative. In order to overcome this difficulty, the Bayesian approach is employed by specifying a prior distribution for error variances. Crucial issues in this modeling procedure include the choice of hyper-parameters in the prior distribution. We derived a model selection criterion from a Bayesian point of view to select these parameters. In order to reduce a computational load of the proposed modeling procedure, we considered two kinds of restrictions: all error variances have the same hyper-parameter (PMLE 1 ), and the error variances for observable variables and those for latent variables have different hyper-parameters (PMLE 2 ). The proposed procedure was applied to artificial data, and we found that our method prevents the occurrence of improper solutions and provides stable estimates. Our modeling strategy is applied to the slump of personal consumption data, and also prevented the occurrence of improper solutions. For both artificial and real data, PMLE 1 and PMLE 2 yield almost the same result. Therefore, from a practical point of view, the PMLE 1 may be preferable since it does not need computation time compared with PMLE 2 .</p><p>The structural equation modeling is usually used to investigate the linear relationships among observed variables and latent variable. However, models that have nonlinear structure are often encountered in social and behavioral sciences (see, e.g., <ref type="bibr" target="#b16">Lee and Zhu, 2003)</ref>. As a future research topic, it is interesting to propose a selection procedure of hyper-parameters for nonlinear structural equation modeling. Another important topic is to select not only the value of hyper-parameter, but also the structural equation model itself. The lasso <ref type="bibr" target="#b22">(Tibshirani, 1996)</ref> is one way to achieve this, since it can produce some coefficients that are exactly zero and then the corresponding paths are automatically eliminated. It is of our interest to apply the lasso and its related regularization methods to the structural equation models.</p><p>Appendix A: Derivation of J λ <ref type="bibr">(θ)</ref> This appendix derives the J λ (θ) included in the second differential of penalized log-likelihood function. First, we define a function F of θ:</p><formula xml:id="formula_26">F = log |Σ| + tr(Σ -1 S).</formula><p>The relationship between F and second differential of log-likelihood function in (2) can be obtained as follows:</p><formula xml:id="formula_27">∂ 2 log f (x 1 , • • • , x N |θ) ∂θ i ∂θ j = - N 2 ∂ 2 F ∂θ i ∂θ j (i, j = 1, • • • , k).</formula><p>Hence, if we derive a second differential of F , the second differential of log-likelihood function can be obtained. It is known that the second differential of F is given by <ref type="bibr" target="#b15">(Lee and Jennrich, 1979)</ref>:</p><formula xml:id="formula_28">∂ 2 F ∂θ i ∂θ j = trΣ -1 Σi Σ -1 Σj + trΣ -1 (Σ -S)Σ -1 ( Σij -2 Σi Σ -1 Σj ), where Σj = ∂Σ ∂θ j , (A1) Σij = ∂ 2 Σ ∂θ i ∂θ j . (A2)</formula><p>For structural equation modeling, Equations (A1) and (A2) are given by</p><formula xml:id="formula_29">∂Σ ∂a αβ = GT ∆ αβ T Σ u T ′ G ′ + GT Σ u T ′ ∆ βα T ′ G ′ , ∂Σ ∂σ u wx = GT ∆ wx T ′ G ′ , (A3) ∂ 2 Σ ∂a γδ ∂a αβ = GT (∆ γδ T ∆ αβ T Σ u + ∆ αβ T ∆ γδ T Σ u + ∆ αβ T Σ u T ′ ∆ δγ )T ′ G ′ +GT (∆ γδ T Σ u T ′ ∆ βα + Σ u T ′ ∆ δγ T ′ ∆ βα + Σ u T ′ ∆ βα T ′ ∆ δγ )T ′ G ′ , ∂ 2 Σ ∂σ u wx ∂a αβ = GT (∆ αβ T ∆ wx + ∆ wx T ′ ∆ βα )T ′ G ′ , (A4) ∂ 2 Σ ∂σ u yz ∂σ u wx = O p×p ,</formula><p>where ∆ ij is a matrix with one on (i, j)-th element and zeros elsewhere, and σ u xy is the (x, y)-th element of Σ u . Note that σ u xy corresponds to σ u i . For example, when the error variance σ u 1 is the (2, 3)-th element of Σ u , σ u 1 = σ u 23 . The reason why we use the notation σ u xy is that it is needed to derive the Equations ( <ref type="formula" target="#formula_10">A3</ref>) and (A4).</p><p>To derive J λ (θ), we need to obtain the second differential of the logarithm of prior distribution log π(θ) regarding error variances, which is given by</p><formula xml:id="formula_30">∂ 2 log π(θ) ∂(σ u i ) 2 = 2 (σ u i ) 2 - 2N λ i (σ u i ) 3 , (i = 1, • • • , v).</formula><p>(A5)</p><p>The second differential for other parameters is zero. Then, the (i, j)-th element of J λ (θ) in ( <ref type="formula" target="#formula_18">6</ref>) is given by</p><formula xml:id="formula_31">J λ (θ) = 1 2 ∂ 2 F ∂θ i ∂θ j - 1 N ∂ 2 log π(θ|λ) ∂θ i ∂θ j . (A6)</formula><p>The first term is calculated by using (A2), and the second term is given by (A5).</p><p>• F 2 : Fears of a recession -X 3 : Sense for the state of the economy -X 4 : Prospect of the state of the economy</p><p>• F 3 : Expectation for decrease in price -X 5 : Prospect of decrease in price -X 6 : The number of products that have a prospect of decrease in price</p><p>• F 4 : Saturation of consumption -X 7 : Getting away from from shopping -X 8 : Overmuch fullness -X 9 : Getting tired of shopping -X 10 : Lack of fascinating products</p><p>• F 5 : Prospect of future of society -X 11 : Society of guarantee for position -X 12 : Society of increase and decrease in income -X 13 : Society of guarantee for old people</p><p>• F 6 : Self-searching for life -X 14 : Self-searching for luxury -X 15 : Self-searching for shopping</p><p>• F 7 : Buyer motivate -X 16 : The number of goods that have appetites -X 17 : A great desire to buy -X 18 : The number of goods that have appetites if the price is down</p><p>• F 8 : Buyer behavior -X 19 : Limits on spending -X 20 : The number of goods that limit on spending -X 21 : The rate of realization for purchasing For detail of the explanation of each variables, we refer to <ref type="bibr" target="#b25">Toyoda (1998)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Hypothetic model for slump of personal consumption data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure</head><label></label><figDesc>Figure 5: PMLE 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Frequency of improper solutions (Freq), mean squared error for parameters (MSE), mean value of hyper-parameters (λ 1 and λ 2 ), and the mean value of the GBIC (GBIC)</figDesc><table><row><cell cols="6">Method Freq MSE (×10) λ 1 (×10 3 ) λ 2 (×10 3 ) GBIC (×10 -3 )</cell></row><row><cell>MLE</cell><cell>39</cell><cell>6.688</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>N = 100 PMLE 1</cell><cell>0</cell><cell>2.267</cell><cell>3.880</cell><cell>-</cell><cell>1.077</cell></row><row><cell>PMLE 2</cell><cell>0</cell><cell>2.516</cell><cell>4.112</cell><cell>3.836</cell><cell>1.077</cell></row><row><cell>MLE</cell><cell>24</cell><cell>4.223</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>N = 150 PMLE 1</cell><cell>0</cell><cell>1.485</cell><cell>2.588</cell><cell>-</cell><cell>1.612</cell></row><row><cell>PMLE 2</cell><cell>0</cell><cell>1.563</cell><cell>2.922</cell><cell>2.615</cell><cell>1.612</cell></row><row><cell>MLE</cell><cell>36</cell><cell>2.109</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>N = 200 PMLE 1</cell><cell>0</cell><cell>0.869</cell><cell>1.928</cell><cell>-</cell><cell>2.139</cell></row><row><cell>PMLE 2</cell><cell>0</cell><cell>0.879</cell><cell>2.420</cell><cell>1.808</cell><cell>2.139</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Mean squared error (MSE) for each parameter of coefficientsMethod γ (×10 3 ) a y2 (×10 2 ) a x1 (×10 2 ) a x2 (×10 2 )</figDesc><table><row><cell>MLE</cell><cell>8.738</cell><cell>5.479</cell><cell>1.435</cell><cell>1.255</cell></row><row><cell>N = 100 PMLE 1</cell><cell>8.813</cell><cell>5.011</cell><cell>1.320</cell><cell>1.138</cell></row><row><cell>PMLE 2</cell><cell>9.555</cell><cell>5.985</cell><cell>1.381</cell><cell>1.178</cell></row><row><cell>MLE</cell><cell>8.182</cell><cell>2.796</cell><cell>0.849</cell><cell>0.871</cell></row><row><cell>N = 150 PMLE 1</cell><cell>8.671</cell><cell>2.091</cell><cell>0.905</cell><cell>0.936</cell></row><row><cell>PMLE 2</cell><cell>8.873</cell><cell>2.192</cell><cell>0.941</cell><cell>0.964</cell></row><row><cell>MLE</cell><cell>4.649</cell><cell>1.848</cell><cell>0.446</cell><cell>0.682</cell></row><row><cell>N = 200 PMLE 1</cell><cell>4.666</cell><cell>1.005</cell><cell>0.503</cell><cell>0.712</cell></row><row><cell>PMLE 2</cell><cell>4.688</cell><cell>0.960</cell><cell>0.533</cell><cell>0.756</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Mean squared error (MSE) for each parameter of error variancesMethod σ η (×10) σ y1 (×10) σ y2 (×10 2 ) σ x1 (×10 2 ) σ x2 (×10 2 )</figDesc><table><row><cell>MLE</cell><cell>2.545</cell><cell>2.463</cell><cell>2.047</cell><cell>3.182</cell><cell>2.523</cell></row><row><cell>N = 100 PMLE 1</cell><cell>0.292</cell><cell>0.411</cell><cell>2.465</cell><cell>2.668</cell><cell>2.154</cell></row><row><cell>PMLE 2</cell><cell>0.361</cell><cell>0.459</cell><cell>2.418</cell><cell>2.806</cell><cell>2.243</cell></row><row><cell>MLE</cell><cell>1.691</cell><cell>1.551</cell><cell>1.069</cell><cell>1.662</cell><cell>1.754</cell></row><row><cell>N = 150 PMLE 1</cell><cell>0.257</cell><cell>0.285</cell><cell>1.152</cell><cell>1.677</cell><cell>1.807</cell></row><row><cell>PMLE 2</cell><cell>0.288</cell><cell>0.298</cell><cell>1.147</cell><cell>1.755</cell><cell>1.872</cell></row><row><cell>MLE</cell><cell>0.780</cell><cell>0.686</cell><cell>0.708</cell><cell>0.861</cell><cell>1.409</cell></row><row><cell>N = 200 PMLE 1</cell><cell>0.135</cell><cell>0.154</cell><cell>0.739</cell><cell>0.940</cell><cell>1.435</cell></row><row><cell>PMLE 2</cell><cell>0.139</cell><cell>0.144</cell><cell>0.703</cell><cell>0.997</cell><cell>1.540</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>The result of GFI, AGFI and GBIC and corresponding hyper-parameters λ 1 and λ 2 for MLE, PMLE 1 and PMLE 2 for the hypothetic model given in Figure2.</figDesc><table><row><cell></cell><cell cols="3">MLE PMLE 1 PMLE 2</cell></row><row><cell>GFI</cell><cell cols="2">0.9037 0.9038</cell><cell>0.9038</cell></row><row><cell cols="3">AGFI 0.8736 0.8738</cell><cell>0.8738</cell></row><row><cell>λ 1</cell><cell>-</cell><cell>0.0014</cell><cell>0.0006</cell></row><row><cell>λ 2</cell><cell>-</cell><cell>-</cell><cell>0.0017</cell></row><row><cell>GBIC</cell><cell>-</cell><cell>23494</cell><cell>23492</cell></row><row><cell>than MLE.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>The authors would like to thank the anonymous reviewer for the helpful comments and suggestions.</p></div>
			</div>


			<div type="funding">
<div><p>Research Fellow of the <rs type="funder">Japan Society for the Promotion of Science. Research Fellow of the Japan Society for the Promotion of Science</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B: Description of real data</head><p>The 8 latent variables and corresponding observable variables for the slump of personal consumption dataset are given in the following:</p><p>• F 1 : Changes in income -X 1 : Increase and decrease in income -X 2 : Consciousness of joy and sorrow for life</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Factor analysis and AIC</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="317" to="332" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The effect of sampling error on convergence, improper solutions, and goodness-of-fit indices for maximum likelihood confirmatory factor analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Gerbing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="155" to="173" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Structural equation models in medical research</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Methods Med. Res</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="159" to="181" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Linear structural equations with latent variables</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Weeks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="289" to="308" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Analysis of covariance structures</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Bock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bargmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="507" to="534" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Nonconvergence, improper solutions, and starting values in lisrel maximum likelihood estimation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Boomsma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="229" to="242" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Model selection and Akaike&apos;s Information Criterion (AIC): The general theory and its analytical extensions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bozdogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="345" to="370" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improper solutions in structural equation models, causes, consequences, and strategies</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Paxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kirby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soc. Methods Res</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="468" to="508" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An empirical evaluation of alternative methods of estimation for confirmatory factor analysis with ordinal data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Flora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="466" to="491" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improper solutions in the analysis of covariance structures: Their interpretability and a comparison of alternate respecifications</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Gerbing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bayesian information criterion and selection of the number of factors in factor analysis models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kawano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Konishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ichikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Data Science</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>To appear in</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A general method for analysis of covariance structures</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Jöreskog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="239" to="251" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Jöreskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sörbom</surname></persName>
		</author>
		<title level="m">LISREL 8: Structural Equation Modeling with the SIMPLIS Command Language. Scientific Software International: Hove and London</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bayesian information criteria and smoothing parameter selection in radial basis function networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Konishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Imoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="27" to="43" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Konishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kitagawa</surname></persName>
		</author>
		<title level="m">Information Criteria and Statistical Modeling</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A study of algorithms for covariance structure analysis with specific comparisons using factor analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Jennrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="99" to="113" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Statistical analysis of nonlinear structural equation models with continuous and polytomous data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Br. J. Math. Stat. Psychol</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="209" to="232" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gene network inference via structural equation modeling in genetical genomics experiments</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De La Fuente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Hoeschele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="page" from="1763" to="1776" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bayesian estimation in unrestricted factor analysis: A treatment for Heywood cases</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="505" to="517" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Causal modeling applied to psychonomic systems simulation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Mcardle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behav. Res. Methods Instrum</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="193" to="209" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Some algebraic properties of the reticular action model for moment structures</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Mcardle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Br. J. Math. Stat. Psychol</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="234" to="251" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Selecting the number of factors in exploratory factor analysis via locally conic parameterization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ninomiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yanagihara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research Memorandum</title>
		<imprint>
			<biblScope unit="volume">1078</biblScope>
			<date type="published" when="2008">2008</date>
			<pubPlace>Tokyo</pubPlace>
		</imprint>
		<respStmt>
			<orgName>The Institute of Statistical Mathematics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statist. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Pugesek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tomer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Von Eye</surname></persName>
		</author>
		<title level="m">Structural Equation Modeling Applications in Ecological and Evolutionary Biology</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Covariance Structure Analysis [Case Examples] -Structural Equation Modeling</title>
		<author>
			<persName><forename type="first">H</forename><surname>Toyoda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>．Kitaohji-shobo Publishing Co., Ltd</publisher>
		</imprint>
	</monogr>
	<note>in Japanese</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On various causes of improper solutions in maximum likelihood factor analysis</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">P</forename><surname>Van Driel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="225" to="243" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Identification of genetic networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page" from="1037" to="1052" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Bayesian learning in sparse graphical factor models via annealed entropy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1771" to="1798" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
