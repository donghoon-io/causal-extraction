<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Under consideration for publication in Theory and Practice of Logic Programming</title>
				<funder ref="#_efTbW8d">
					<orgName type="full">Spanish</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2016-02-22">22 Feb 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Pedro</forename><surname>Cabalar</surname></persName>
							<email>cabalar@udc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Corunna</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jorge</forename><surname>Fandinno</surname></persName>
							<email>jorge.fandino@udc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Corunna</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Under consideration for publication in Theory and Practice of Logic Programming</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-02-22">22 Feb 2016</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1602.06897v1[cs.LO]</idno>
					<note type="submission">submitted October 21 2015; revised January 26 2016; accepted February 22 2016</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>causal justifications</term>
					<term>well-founded semantics</term>
					<term>stable models</term>
					<term>answer set programming</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To appear in Theory and Practice of Logic Programming (TPLP). In this paper we propose an extension of logic programming (LP) where each default literal derived from the well-founded model is associated to a justification represented as an algebraic expression. This expression contains both causal explanations (in the form of proof graphs built with rule labels) and terms under the scope of negation that stand for conditions that enable or disable the application of causal rules. Using some examples, we discuss how these new conditions, we respectively call enablers and inhibitors, are intimately related to default negation and have an essentially different nature from regular cause-effect relations. The most important result is a formal comparison to the recent algebraic approaches for justifications in LP: Why-not Provenance (WnP) and Causal Graphs (CG). We show that the current approach extends both WnP and CG justifications under the Well-Founded Semantics and, as a byproduct, we also establish a formal relation between these two approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The strong connection between Non-Monotonic Reasoning (NMR) and Logic Programming (LP) semantics for default negation has made possible that LP tools became nowadays an important paradigm for Knowledge Representation (KR) and problem-solving in Artificial Intelligence (AI). In particular, Answer Set Programming (ASP) <ref type="bibr">(Niemelä 1999;</ref><ref type="bibr">Marek and Truszczyńki 1999)</ref> has established as a preeminent LP paradigm for practical NMR with applications in diverse areas of AI including planning, reasoning about actions, diagnosis, abduction and beyond. The ASP paradigm is based on the stable models semantics <ref type="bibr" target="#b9">(Gelfond and Lifschitz 1988)</ref> and is also closely related to the other mainly accepted interpretation for default negation, well-founded semantics (WFS) <ref type="bibr">(Van Gelder et al. 1991)</ref>. One interesting difference between these two LP semantics and classical models (or even other NMR approaches) is that true atoms in LP must be founded or justified by a given derivation. These justifications are not provided in the semantics itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches <ref type="bibr" target="#b32">(Specht 1993;</ref><ref type="bibr" target="#b4">Denecker and Schreye 1993;</ref><ref type="bibr" target="#b29">Pemmasani et al. 2004;</ref><ref type="bibr" target="#b8">Gebser et al. 2008;</ref><ref type="bibr" target="#b30">Pontelli et al. 2009;</ref><ref type="bibr" target="#b27">Oetsch et al. 2010;</ref><ref type="bibr" target="#b31">Schulz and Toni 2013)</ref>.</p><p>Rather than manipulating justifications as mere syntactic objects, two recent approaches have considered extended multi-valued semantics for LP where justifications are treated as algebraic constructions: Why-not Provenance (WnP) <ref type="bibr">(Damásio et al. 2013)</ref> and Causal Graphs (CG) <ref type="bibr">(Cabalar et al. 2014a)</ref>. Although these two approaches present formal similarities, they start from different understandings of the idea of justification. On the one hand, WnP answers the query "why literal L might hold" by providing conjunctions of hypothetical modifications on the program that would allow deriving L. These modifications include rule labels, expressions like not(A) with A an atom, or negations '¬' of the two previous cases. As an example, a justification for L like r 1 ∧ not(p) ∧ ¬r 2 ∧ ¬not(q) means that the presence of rule r 1 and the absence of atom p would allow deriving L (hypothetically) if both rule r 2 were removed and atom q were added to the program. If we want to explain why L actually holds, we have to restrict to justifications without '¬', that is, those without program modifications (which will be the focus of this paper).</p><p>On the other hand, CG-justifications start from identifying program rules as causal laws so that, for instance, (p ← q) can be read as "event q causes effect p." Under this viewpoint, (positive) rules offer a natural way for capturing the concept of causal production, i.e. a continuous chain of events that has helped to cause or produce an effect <ref type="bibr" target="#b11">(Hall 2004;</ref><ref type="bibr" target="#b12">Hall 2007)</ref>. The explanation of a true atom is made in terms of graphs formed by rule labels that reflect the ordered rule applications required for deriving that atom. These graphs are obtained by algebraic operations exclusively applied on the positive part of the program. Default negation in CG is understood as absence of cause and, consequently, a false atom has no justification.</p><p>The explanation of an atom A in CG is more detailed than in WnP, since the former contains graphs that correspond to all relevant proofs of A whereas in WnP we just get conjunctions that do not reflect any particular ordering among rule applications. However, as explained before, CG does not capture the effect of default negation in a given derivation and, sometimes, this information is very valuable, especially if we want to answer questions of the form "why not."</p><p>As in the previous paper on CG <ref type="bibr">(Cabalar et al. 2014a)</ref>, our final goal is to achieve an elaboration tolerant representation of causality that allows reasoning about cause-effect relations. Under this perspective, although WnP is more oriented to program debugging, its possibility of dealing with hypothetical reasoning of the form "why not" would be an interesting feature to deal with counterfactuals, since several approaches to causality (see Section 5) are based on this concept. To understand the kind of problems we are interested in, consider the following example. A drug d in James Bond's drink causes his paralysis p provided that he was not given an antidote a that day. We know that Bond's enemy, Dr. No, poured the drug:</p><formula xml:id="formula_0">p ← d, not a (1) d (2)</formula><p>In this case it is obvious that d causes p, whereas the absence of a just enables the application of the rule. Now, suppose we are said that Bond is daily administered an antidote by the MI6, unless it is a holiday h:</p><formula xml:id="formula_1">a ← not h (3)</formula><p>Adding this rule makes a become an inhibitor of p, as it prevents d to cause p by rule (1). But suppose now that we are in a holiday, that is, fact h is added to the program (1)-(3). Then, the inhibitor a is disabled and d causes p again. However, we do not consider that the holiday h is a (productive) cause for Bond's paralysis p although, indeed, the latter counterfactually depends on the former: "had not been a holiday h, Bond would have not been paralysed." We will say that the fact h, which disables inhibitor a, is an enabler of p, as it allows applying rule (1).</p><p>In this work we propose dealing with these concepts of enablers and inhibitors by augmenting CG justifications with a new negation operator '∼' in the CG causal algebra. We show that this new approach, which we call Extended Causal Justifications (ECJ), captures WnP justifications under the Well-founded Semantics, establishing a formal relation between WnP and CG as a byproduct.</p><p>The rest of the paper is structured as follows. The next section defines the new approach. Sections 3 and 4 explain the formal relations to CG and WnP through a running example. Section 5 studies several examples of causal scenarios from the literature and finally, Section 6 concludes the paper. Appendix A contains an auxiliary figure depicting some common algebraic properties and Appendix B contains the formal proofs of theorems from the previous sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Extended Causal Justifications (ECJ)</head><p>A signature is a pair At, Lb of sets that respectively represent atoms (or propositions) and labels. Intuitively, each atom in At will be assigned justifications built with rule labels from Lb. In principle, the intersection At ∩ Lb does not need to be empty: we may sometimes find it convenient to label a rule using an atom name (normally, the head atom). Justifications will be expressions that combine four different algebraic operators: a product ' * ' representing conjunction or joint causation; a sum '+' representing alternative causes; a non-commutative product '•' that captures the sequential order that follows from rule applications; and a non-classical negation '∼' which will precede inhibitors (negated labels) and enablers (doubly negated labels).</p><p>Definition 1 (Terms) Given a set of labels Lb, a term, t is recursively defined as one of the following expressions t</p><formula xml:id="formula_2">::= l | ∏ S | ∑ S | t 1 • t 2 | ∼t 1</formula><p>where l ∈ Lb, t 1 ,t 2 are in their turn terms and S is a (possibly empty and possibly infinite) set of terms. A term is elementary if it has the form l, ∼l or ∼∼l with l ∈ Lb being a label.</p><p>When S = {t 1 , . . . ,t n } is finite we simply write ∏ S as t 1 * • • • * t n and ∑ S as t 1 + • • •+t n . Moreover, when S = / 0, we denote ∏ S by 1 and ∑ S by 0, as usual, and these will be the identities of the product ' * ' and the addition '+', respectively. We assume that '•' has higher priority than ' * ' and, in turn, ' * ' has higher priority than '+'.</p><p>Definition 2 (Values) A (causal) value is each equivalence class of terms under axioms for a completely distributive (complete) lattice with meet ' * ' and join '+' plus the axioms of Figures <ref type="figure" target="#fig_2">1</ref> and<ref type="figure">2</ref>. The set of (causal) values is denoted by V Lb .</p><p>Note that V Lb , +, * , ∼ , 0, 1 is a completely distributive Stone algebra (a pseudo-complemented, completely distributive, complete lattice which satisfies the weak excluded middle axiom) whose meet and join are, as usual, the product ' * ' and the addition '+'. Informally speaking, this means that these two operators satisfy the properties of a Boolean algebra but without negation.</p><p>Note also that all three operations, ' * ', '+' and '•' are associative. Product ' * ' and addition '+' are also commutative, and they hold the usual absorption and distributive laws with respect to infinite sums and products of a completely distributive lattice.</p><formula xml:id="formula_3">Associativity t • (u•w) = (t•u) • w Absorption t = t + u • t • w u • t • w = t * u • t • w Identity t = 1 • t t = t • 1 Annihilator 0 = t • 0 0 = 0 • t Idempotency x • x = x Addition distributivity t • (u+w) = (t•u) + (t•w) (t + u) • w = (t•w) + (u•w) Product distributivity c • d • e = (c • d) * (d • e) with d = 1 c • (d * e) = (c • d) * (c • e) (c * d) • e = (c • e) * (d • e)</formula><p>Fig. <ref type="figure" target="#fig_0">1</ref>. Properties of the '•' operator (c, d, e are terms without '+' and x is an elementary term). Distributivity is also satisfied over infinite sums and products.</p><formula xml:id="formula_4">Pseudo-complement t * ∼t = 0 ∼∼∼t = ∼t De Morgan ∼(t+u) = (∼t * ∼u) ∼(t * u) = (∼t+∼u) Weak excl. middle ∼t + ∼∼t = 1 appl. negation ∼(t • u) = ∼(t * u) Fig. 2. Properties of the '∼' operator.</formula><p>The axioms for '•' in Figure <ref type="figure" target="#fig_0">1</ref> are directly extracted from the CG algebraic structure. For a more detailed explanation on their induced behaviour see <ref type="bibr">(Cabalar et al. 2014a)</ref>. The new contribution in this paper with respect to the CG algebra is the introduction of the '∼' operator whose meaning is captured by the axioms in Figure <ref type="figure">2</ref>. As we can see, this operator satisfies De Morgan laws and acts as a complement for the product t * ∼t = 0. However, it diverges from a classical Boolean negation in some aspects. In the general case, the axioms ∼∼t = t (double negation) and t + ∼t = 1 (excluded middle) are not valid. Instead<ref type="foot" target="#foot_0">foot_0</ref> , we can replace a triple negation ∼∼∼t by ∼t, and we have a weak version of the excluded middle axiom ∼t + ∼∼t = 1. The negation of an application is defined as the negation of the product ∼(t • u) def = ∼(t * u) which, in turn, is equivalent to ∼(u * t), since * is commutative. In other words, under negation, the rule application ordering is disregarded. It is not difficult to see that we can apply the axioms of negation to reach an equivalent expression that avoids its application to other operators. We say that a term is in negation normal form (NNF) if no other operator is in the scope of negation '∼'. Moreover, an NNF term is in disjuntive normal form (DNF) if: (1) no sum is in the scope of another operator;</p><p>(2) only elementary terms are in the scope of application; and (3) every product is transitively closed, that is, of the form of a•b * b•c * a•c. Without loss of generality, we assume from now that all functions defined over causal terms are applied over their DNF form, although, we will usually write them in NNF for short.</p><p>The lattice order relation is defined as usual in the following way:</p><formula xml:id="formula_5">t ≤ u iff (t * u = t) iff (t + u = u)</formula><p>Consequently 1 and 0 are respectively the top and bottom elements with respect to relation ≤.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 3 (Labelled logic program)</head><p>Given a signature At, Lb , a (labelled logic) program P is a set of rules of the form:</p><formula xml:id="formula_6">r i : H ← B 1 , . . . , B m , notC 1 , . . . , notC n (4)</formula><p>where r i ∈ Lb is a label or r i = 1, H (the head of the rule) is an atom, and B i 's and C i 's (the body of the rule) are either atoms or terms.</p><p>When n = 0 we say that the rule is positive, furthermore, if in addition m = 0 we say that the rule is a fact and omit the symbol '←.' When r i ∈ Lb we say that the rule is labelled; otherwise r i = 1 and we omit both r i and ':'. By these conventions, for instance, an unlabelled fact A is actually an abbreviation of (1 : A ←). A program P is positive when all its rules are positive, i.e. it contains no default negation. It is uniquely labelled when each rule has a different label or no label at all. In this paper, we will assume that programs are uniquely labelled. Furthermore, for the sake of clarity, we also assume that, for every atom A ∈ At, there is an homonymous label A ∈ Lb, and that each fact A in the program actually stands for the labelled rule (A : A ←). For instance, following these conventions, a possible labelled version for the James Bond's program could be program P 1 below:</p><formula xml:id="formula_7">r 1 : p ← d, not a r 2 : a ← not h d h</formula><p>where facts d and h stand for rules (d : d ←) and (h : h ←), respectively.</p><p>An ECJ-interpretation is a mapping I : At -→ V Lb assigning a value to each atom. For interpretations I and J we say that I ≤ J when I(A) ≤ J(A) for each atom A ∈ At. Hence, there is a ≤-bottom interpretation 0 (resp. a ≤-top interpretation 1) that stands for the interpretation mapping each atom A to 0 (resp. 1). The value assigned to a negative literal not A by an interpretation I, denoted as I(not A), is defined as I(not A) def = ∼I(A), as expected. Similarly, for a term t, I(t) def = [t] is the equivalence class of t.</p><p>Definition 4 (Model) An interpretation I satisfies a rule like (4) iff</p><formula xml:id="formula_8">I(B 1 ) * . . . * I(B m ) * I(notC 1 ) * . . . * I(notC n ) • r i ≤ I(H) (5)</formula><p>and I is a (causal) model of P, written I |= P, iff I satisfies all rules in P.</p><p>As usual in LP, for positive programs, we may define a direct consequence operator T P s.t.</p><formula xml:id="formula_9">T P (I)(H) def = ∑ I(B 1 ) * . . . * I(B n ) • r i | (r i : H ← B 1 , . . . , B n ) ∈ P</formula><p>for any interpretation I and atom H ∈ At. We also define T P ↑ α (0) def = T P (T P ↑ α-1 (0)) for any successor ordinal α and</p><formula xml:id="formula_10">T P ↑ α (0) def = ∑ β &lt;α T P ↑ β (0)</formula><p>for any limit ordinal alpha. As usual, ω denotes the smallest infinite limit ordinal. Note that 0 is considered a limit ordinal and, thus, T P ↑ 0 (0) = ∑ β &lt;0 T P ↑ β (0) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1</head><p>Let P be a (possibly infinite) positive logic program. Then, (i) the least fixpoint of the T P operator, denoted by lfp(T P ), satisfies lfp(T P ) = T P ↑ ω (0) and it is the least model of P, (ii) furthermore, if P is positive and has n rules, then lfp(T P ) = T P ↑ ω (0) = T P ↑ n (0).</p><p>Theorem 1 asserts that, as usual, positive programs have a ≤-least causal model. As we will see later, this least model coincides with the traditional least model (of the program without labels) when one just focuses on the set of true atoms, disregarding the justifications explaining why they are true. For programs with negation we define the following reduct.</p><p>Definition 5 (Reduct) Given a program P and an interpretation I we denote by P I the positive program containing a rule of the form</p><formula xml:id="formula_11">r i : H ← B 1 , . . . , B m , I(notC 1 ), . . . , I(notC n ) (6)</formula><p>for each rule of the form (4) in P.</p><p>Program P I is positive and, from Theorem 1, it has a least causal model. By Γ P (I) we denote the least model of program P I . The operator Γ P is anti-monotonic and, consequently, Γ 2 P is monotonic (Proposition 4 in the appendix) so that, by Knaster-Tarski's theorem, it has a least fixpoint L P and a greatest fixpoint U P def = Γ P (L P ). These two fixpoints respectively correspond to the justifications for true and for non-false atoms in the (standard) well-founded model (WFM), we denote as W P .</p><p>For instance, in our running example,</p><formula xml:id="formula_12">L P 1 (d) = Γ 2 P 1 ↑ α (0)(d) = d for 1 ≤ α points out that</formula><p>atom d is true because of fact d. Similarly, L P 1 (h) = h and L P 1 (a) = ∼h•r 2 reveals that atom h is true because of fact h, and that atom a is not true because fact h has inhibited rule r 2 .</p><p>Furthermore,</p><formula xml:id="formula_13">L P 1 (p) = Γ 2 P 1 ↑ α (0)(p) = (∼(∼h•r 2 ) * d)•r 1 = (∼∼h * d)•r 1 + (∼r 2 * d)•r 1</formula><p>for 2 ≤ α. That is, Bond has been paralysed because fact h has enabled drug d to cause the paralysis by means of rule r 1 . This corresponds to the justification (∼∼h * d)•r 1 . Notice how the real cause d is a positive label (not in the scope of negation) whereas the enabler h is in the scope of a a double negation ∼∼h. Justification (∼r 2 * d)•r 1 means that d•r 1 would have been sufficient to cause p, had not been present r 2 . This example is also useful for illustrating the importance of axiom appl. negation. By directly evaluating the body of rule r 1 , we have seen that</p><formula xml:id="formula_14">Γ 2 P 1 ↑ 2 (0)(p) = (∼(∼h • r 2 ) * d) • r 1 .</formula><p>Then, axiom appl. negation allows us to break the dependence between ∼h and r 2 into enablers and inhibitors: ∼(∼h • r 2 ) = ∼(∼h * r 2 ) = ∼∼h + ∼r 2 and, applying distributivity, we obtain one enabled justification, (∼∼h * d)•r 1 , and one disabled one, (∼r 2 * d)•r 1 .</p><p>In our previous example, the least and greatest fixpoint coincided</p><formula xml:id="formula_15">L P 1 = U P 1 = Γ 2 P 1 ↑ 2 (0).</formula><p>To illustrate the case where this does not hold consider, for instance, the program P 2 formed by the following negative cycle:</p><formula xml:id="formula_16">r 1 : a ← not b r 2 : b ← not a</formula><p>In this case, the least fixpoint of Γ 2 P assigns L P 2 (a) = ∼r 2 •r 1 and L P 2 (b) = ∼r 1 •r 2 , while, in its turn, the greatest fixpoint of Γ 2 P corresponds to U P 2 (a) = r 1 and U P 2 (b) = r 2 . If we focus on atom a, we can observe that it is not concluded to be true, since the least fixpoint L P has only provided one disabled justification ∼r 2 •r 1 meaning that r 2 is acting as a disabler for a. But, on the other hand, a cannot be false either since the greatest fixpoint provides an enabled justification r 1 for being non-false (remember that U P provides justifications for non-false atoms). As a result, we get that a is left undefined because r 2 prevents it to become true while r 1 can still be used to conclude that it is not false.</p><p>To capture these intuitions, we provide some definitions. A query literal (q-literal) L is either an atom A, its default negation 'not A' or the expression 'undef A' meaning that A is undefined.</p><p>Definition 6 (Causal well-founded model) Given a program P, its causal well-founded model W P is a mapping from q-literals to values s.t.</p><formula xml:id="formula_17">W P (A) def = L P (A) W P (not A) def = ∼U P (A) W P (undef A) def = ∼W P (A) * ∼W P (not A)</formula><p>Let l be a label occurrence in a term t in the scope of n ≥ 0 negations. We say that l is an odd or an even occurrence if n is odd or even, respectively. We further say that l is a strictly even occurrence if it is even and n &gt; 0.</p><p>Definition 7 (Justification) Given a program P and a q-literal L we say that a term E with no sums is a (sufficient causal) justification for L iff E ≤ W P (L). Odd (resp. strictly even) labels<ref type="foot" target="#foot_2">foot_2</ref> in E are called inhibitors (resp. enablers) of E. A justification is said to be inhibited if it contains some inhibitor and it is said to be enabled otherwise.</p><p>True atoms will have at least one enabled justification, whereas false atoms only contain disabled justifications. As an example of a query for a plain atom A, take the already seen explanation for p in Bond's example program P 1 :</p><formula xml:id="formula_18">W P 1 (p) = L P 1 (p) = (∼∼h * d)•r 1 + (∼r 2 * d)•r 1 .</formula><p>We have here two justifications for atom p, let us call them</p><formula xml:id="formula_19">E 1 = (∼∼h * d)•r 1 and E 2 = (∼r 2 * d)•r 1 .</formula><p>Justification E 1 is enabled because it contains no inhibitors (in fact, E 1 is the unique real support for p). Moreover, h is an enabler in E 1 because it is strictly even (it is in the scope of double negation) whereas d is a productive cause, since it is not in the scope of any negation. On the contrary, E 2 is disabled because it contains the inhibitor r 2 (it occurs in the scope of one negation). Intuitively, r 2 has prevented d•r 1 to become a justification of p. On the other hand, for atom a we had W P 1 (a) = ∼h • r 2 that only contains an inhibited justification (being h the inhibitor), and so, atom a is not true. Now, if we query about the negative q-literal not a, we obtain W P 1</p><p>(not a) = ∼U P 1 (a) which in this case happens to be ∼L P 1 (a) = ∼(∼h • r 2 ) = ∼∼h + ∼r 2 . That is, q-literal not a holds, being enabled by h. Moreover, ∼r 2 points out that removing r 2 would suffice to cause not a too. It is easy to see that the explanations we can get for q-literals not A or undef A will have all their labels in the scope of negation (either as inhibitors or as enablers).</p><p>To illustrate a query for undef A, let us return to program P 2 whose standard well-founded model left both a and b undefined. Given the values we obtained in the least and greatest fixpoints, the causal WFM will assign W P 2 (a) = ∼r 2 •r 1 and W P 2 (b) = ∼r 1 •r 2 , that is, r 2 prevents r 1 to cause a and r 1 prevents r 2 to cause b. Furthermore, the values assigned to their respective negations, W P 2</p><p>(not a) = ∼r 1 and W P 2 (not b) = ∼r 2 , point out that atoms a and b are not false because rules r 1 and r 2 have respectively prevented them to be so. Finally, we obtain that undef a is true because</p><formula xml:id="formula_20">W P (undef a) = ∼W P 2 (a) * ∼W P 2 (not a) = (∼∼r 2 + ∼r 1 ) * ∼∼r 1 = ∼∼r 2 * ∼∼r 1</formula><p>that is, rules r 1 and r 2 together have made a undefined. Similarly, b is also undefined because of rules r 1 and r 2 , W P (undef b) = ∼∼r 1 * ∼∼r 2 .</p><p>The next theorem shows that the literals satisfied by the standard WFM are precisely those ones containing at least one enabled justification in the causal WFM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 2</head><p>Let P be a labelled logic program over a signature At, Lb where Lb is a finite set of labels and let W P its (standard) well-founded model. A q-literal L holds with respect to W P if and only if there is some enabled justification E of L, that is, E ≤ W P (L) and E does not contain odd negative labels.</p><p>Back to our example program P 1 , as we had seen, atom p had a unique enabled justification</p><formula xml:id="formula_21">E 1 = (∼∼h * d)•r 1 .</formula><p>The same happens for atoms d and h whose respective justifications are just their own atom labels. Therefore, these three atoms hold in the standard WFM, W P 1 . On the contrary, as we discussed before, the only justification for a, W P 1 (a) = ∼h•r 2 , is inhibited by h, and thus, a does not hold in W P 1</p><p>. The interest of an inhibited justification for a literal is to point out "potential" causes that have been prevented by some abnormal situation. In our case, the presence of ∼h in W P 1 (a) = ∼h•r 2 points out that an exception h has prevented r 2 to cause a. When the exception is removed, the inhibited justification (after removing the inhibitors) becomes an enabled justification.</p><p>In our running example, if we consider a program P 3 obtained by removing the fact h from P 1 , then W P 3 (a) = r 2 points out that a has been caused by rule r 2 in this new scenario. This intuition about inhibited justifications is formalized as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 8</head><p>Given a term t in DNF, by ρ x : V CG Lb -→ V CG Lb , we denote the function that removes the elementary term x from t as follows:</p><formula xml:id="formula_22">ρ x (t) def =        ρ x (u) ⊗ ρ x (w) if t = u ⊗ v with ⊗ ∈ {+, * , •} 1 if ∼∼t is equivalent to ∼∼x 0 if t is equivalent to ∼x</formula><p>Note that we have assumed that t is in DNF. Otherwise, ρ x (t) def = ρ x (u) where u is an equivalent term in DNF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3</head><p>Let P be a program over a signature At, Lb where Lb is a finite set of labels. Let Q be the result of removing from P all rules labelled by some r i ∈ Lb. Then, the result of removing r i from the justifications of some atom A with respect to program P are justifications of A with respect to Q, that is,</p><formula xml:id="formula_23">ρ ∼r i (W P (A)) ≤ W Q (A).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Relation to Causal Graph Justifications</head><p>We discuss now the relation between ECJ and CG approaches. Intuitively, ECJ extends CG causal terms by the introduction of the new negation operator '∼'. Semantically, however, there are more differences than a simple syntactic extension. A first minor difference is that ECJ is defined in terms of a WFM, whereas CG defines (possibly) several causal stable models. In the case of stratified programs, this difference is irrelevant, since the WFM is complete and coincides with the unique stable model. A second, more important difference is that CG exclusively considers productive causes in the justifications, disregarding additional information like the inhibitors or enablers from ECJ. As a result, a false atom in CG has no justification -its causal value is 0 because there was no way to derive the atom. For instance, in program P 1 , the only CG stable model I just makes I(a) = 0 and we lose the inhibited justification ∼h • r 2 (default r 2 could not be applied). True atoms like p also lose any information about enablers: I(p) = d•r 1 and nothing is said about ∼∼h. Another consequence of the CG orientation is that negative literals not A are never assigned a cause (different from 0 or 1), since they cannot be "derived" or produced by rules. In the example, we simply get I(not a) = 1 and I(not p) = 0.</p><p>To further illustrate the similarities and differences between ECJ and CG, consider the following program P 4 capturing a variation of the Yale Shooting Scenario. plus the following rules corresponding inertia axioms</p><formula xml:id="formula_24">d t+1 : dead t+1 ← shoot t ,</formula><formula xml:id="formula_25">F t+1 ← F t , not F t+1 F t+1 ← F t , not F t+1</formula><p>for F ∈ {loaded, ab, dead}. Atoms of the form A represent the strong negation of A and we disregard models satisfying both A and A. Atom dead 9 does not hold in the standard WFM of P 4 , and so there is no CG-justification for it. Note here the importance of default reasoning. On the one hand, the default flow of events is that the turkey, Fred, continues to be alive when nothing threats him. Hence, we do not need a cause to explain why Fred is alive. On the other hand, shooting a loaded gun would normally kill Fred, being this a cause of its death. But, in this example, another exceptional situation -water spilled out -has inhibited this existing threat and allowed the world to flow as if nothing had happened (that is, following its default behaviour).</p><p>In the CG-approach, dead 9 is simply false by default and no justification is provided. However, a gun shooter could be "disappointed" since another conflicting default (shooting a loaded gun normally kills) has not worked. Thus, an expected answer for the shooter's question "why not dead 9 ?" is that water 3 broke the default, disabling d 9 . In fact, ECJ yields the following inhibited justification for dead 9 :</p><formula xml:id="formula_26">W P 4 (dead 9 ) = (∼water 3 * shoot 8 * load 1 •l 2 ) • d 9 (7)</formula><p>meaning that dead 9 could not be derived because inhibitor water 3 prevented the application of rule d 9 to cause the death of Fred. Note that inertia rules are not labelled, which, as mentioned before, is syntactic sugar for rules with label 1. Since 1 is the identity of product and application, this has the effect of not being traced in the justifications. Note also that, according to Theorem 3, if we remove fact water 3 (the inhibitor) from P 4 leading to a new program P 5 , then we get:</p><formula xml:id="formula_27">W P 5 (dead 9 ) = (shoot 8 * load 1 •l 2 ) • d 9 (8)</formula><p>which is nothing else but the result of removing ∼water 3 from (7). In fact, the only CG stable model of P 5 makes this same assignment (8) which also corresponds to the causal graph depicted in Figure <ref type="figure">3</ref>. In the general case, CG-justifications intuitively correspond to enabled justifications after forgetting all the enablers. Formally, however, there is one more difference in the definition of causal values: CG causal values are defined as ideals for the poset of a type of graphs formed by rule labels.</p><p>Definition 9 (Causal graph)</p><formula xml:id="formula_28">shoot 8 A A load 1 shoot 8 A A Ö Ö load 1 Ö Ö l 2 t t l 2 t t e e d 9 d 9 p p G 2 G * 2 Fig. 3. G 2 is the cause of dead 9 in program P 4 while G *</formula><p>2 is its associated causal graphs, that is, its reflexive and transitive closure.</p><p>Given some set Lb of (rule) labels, a causal graph (c-graph) G ⊆ Lb × Lb is a reflexively and transitively closed set of edges. By G Lb , we denote the set of causal graphs. Given two c-graphs</p><formula xml:id="formula_29">G and G ′ , we write G ≤ G ′ when G ⊇ G ′ .</formula><p>Intuitively, causal graphs, like G 2 in Figure <ref type="figure">3</ref>, are directed graphs representing the causal structure that has produced some event. Furthermore, G ≤ G ′ means that G contains enough information to yield the same effect as G ′ , but perhaps more than needed (this explains G ⊇ G ′ ). For this reason, we sometimes read G ≤ G ′ as "G ′ is stronger than G." Causes will be ≤maximal (or ⊆-minimal) causal graphs. Formally, including reflexive and transitive edges allows to capture this intuitive relation simply by the subgraph relation. Note that, since causal graphs are reflexively closed, every vertex has at least one edge (the reflexive one) and, thus, we can omit the set of vertices. Besides, for the sake of clarity, we only depict the minimum set of edges necessary for defining a causal graph (transitive and reflexive reduction). For instance, graph G 2 in Figure <ref type="figure">3</ref> is the transitive and reflexive reduction of the causal graph G * 2 .</p><p>Definition 10 (CG Values in <ref type="bibr">Cabalar et al. 2014a</ref>) Given a set of labels Lb, a CG causal value is any ideal (or lower-set) for the poset G Lb , ≤ . By I CG Lb , we denote the set of CG causal values. Product ' * ', sums '+' and the ≤-order relation are defined as the set intersection, union and the subset relation, respectively. Application is given by U</p><formula xml:id="formula_30">•U ′ def = { G ′′ ≤ G • G ′ G ∈ U and G ′ ∈ U ′ }.</formula><p>It has been shown in <ref type="bibr">(Fandinno 2015a</ref>) that CG values can be alternatively characterised as a free algebra generated by rule labels under the axioms of a complete distributive lattice plus the axioms of Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 11 (CG Values in Fandinno 2015a)</head><p>Given a set of labels Lb, a CG term is a term without negation '∼'. CG causal values are the equivalence classes of CG terms for a completely distributive (complete) lattice with meet ' * ' and join '+' plus the axioms of Figure <ref type="figure" target="#fig_0">1</ref>. By V CG Lb , we denote the set of CG causal values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 4 (Causal values isomorphism from Fandinno 2015a)</head><p>The function term :</p><formula xml:id="formula_31">I CG Lb -→ V CG Lb given by term(U) → ∑ G∈U ∏ (v 1 ,v 2 )∈G v 1 •v 2 is an isomorphism between algebras I CG Lb , +, * , •, G Lb , / 0 and V CG Lb , +, * , •, 1, 0 .</formula><p>Theorem 4 states that CG causal values can be equivalently described either as ideals of causal graphs or as elements of an algebra of terms. Furthermore, by abuse of notation, by G we also denote the ideal whose maximum element is G, corresponding to term(G) as well. For instance, for the causal graph G 2 in Figure <ref type="figure">3</ref>, it follows G 2 = term(G 2 ) = term(↓G 2 ) with ↓G 2 the ideal whose maximum element is G 2 . Moreover, from the equivalences in Figure <ref type="figure" target="#fig_0">1</ref>, it also follows that</p><formula xml:id="formula_32">G 2 = shoot 8 •d 9 * load 1 •l 2 * l 2 •d 9 * α = shoot 8 •d 9 * load 1 •l 2 * l 2 •d 9 = shoot 8 •d 9 * load 1 •l 2 •d 9 = (shoot 8 * load 1 •l 2 )•d 9 where α = load 1 •d 9 * shoot 8 •shoot 8 * d 9 •d 9 * load 1 •load 1 * l 2 •l 2 * d 9 •d 9</formula><p>is a term that, as we can see, can be ruled out and corresponds to the transitive and reflexive doted edges in G * 2 . That is, justification (8) associated to atom dead 9 by the causal well-founded model of program P 5 actually corresponds to causal graph G 2 .</p><p>Theorem 4 also formalises the intuition that opens this section: ECJ extends CG causal terms by the introduction of the new negation operator '∼'. We formalise next the correspondence between CG and ECJ justifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 12 (CG mapping)</head><p>We define a mapping λ c : V Lb -→ V CG Lb from ECJ values into CG values in the following recursive way:</p><formula xml:id="formula_33">λ c (t) def =            λ c (u) ⊗ λ c (w) if t = u ⊗ v with ⊗ ∈ {+, * , •} 1 if t = ∼∼l with l ∈ Lb 0 if t = ∼l with l ∈ Lb l if t = l with l ∈ Lb</formula><p>Note that we have assumed that t is in DNF. Otherwise, λ c (t) def = λ c (u) where u is an equivalent term in DNF.</p><p>Function λ c maps every negated label ∼l to 0 (which is the annihilator of both product ' * ' and application '•' and the identity of addition '+'). Hence λ c removes all the inhibited justifications. Furthermore λ c maps every doubly negated label ∼∼l to 1 (which is the identity of both product ' * ' and application '•'). Therefore λ c removes all the enablers (i.e. doubly negated labels ∼∼l) for the remaining (i.e. enabled) justifications.</p><p>A CG interpretation is a mapping Ĩ : At -→ V CG Lb . The value assigned to a negative literal not A by a CG interpretation Ĩ, denoted as Ĩ(not A), is defined as: Ĩ(not</p><formula xml:id="formula_34">A) def = 1 if Ĩ(A) = 0; Ĩ(not A) def = 0 otherwise. A CG interpretation Ĩ is a CG model of rule like (4) iff Ĩ(B 1 ) * . . . * Ĩ(B m ) * Ĩ(notC 1 ) * . . . * Ĩ(notC n ) • r i ≤ Ĩ(H) (9)</formula><p>Notice that the value assigned to a negative literal by CG and ECJ interpretations is different.</p><p>According to <ref type="bibr">(Cabalar et al. 2014a</ref>), a CG interpretation Ĩ is a CG stable model of a program P iff Ĩ is the least model of the program P Ĩ . In the following, we provide an ECJ based characterisation of the CG stable models that will allow us to relate both approaches. By λ c (I) we will denote a CG interpretation Ĩ s.t. Ĩ(A) = λ c (I(A)) for every atom A.</p><p>Definition 13 (CG stable models) Given a program P, a CG interpretation Ĩ is a CG stable model of P iff there exists a fixpoint I of the operator Γ 2 P , i.e. Γ P (Γ P (I)) = I, such that Ĩ = λ c (I) = λ c (Γ P (I)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 5</head><p>Let P be a program over a signature At, Lb where Lb is a finite set of labels. Then, the CG stable models (Definition 13) are exactly the causal values and causal stable models defined in <ref type="bibr">(Cabalar et al. 2014a</ref>).</p><p>Theorem 5 shows that Definition 13 is an alternative definition of CG causal stable models. Furthermore, it settles that every causal model corresponds to some fixpoint of the operator Γ 2 P . Therefore, for every enabled justification there is a corresponding CG-justification common to all stable models. In order to formalise this idea we just take the definition of causal explanation from <ref type="bibr">(Cabalar et al. 2014b)</ref>.</p><p>Definition 14 (CG-justification) Given an interpretation I we say that a c-graph G is a (sufficient) CG-justification for an atom A iff term(G) ≤ Ĩ(A).</p><p>Since term(•) is a one-to-one correspondence, we can define its inverse graph(v</p><formula xml:id="formula_35">) def = term -1 (v) for all v ∈ V CG Lb .</formula><p>Theorem 6</p><p>Let P be a program over a signature At, Lb where Lb is a finite set of labels. For any enabled justification E of some atom A w.r.t. W P , i.e. E ≤ W P (A), there is a CG-justification G def = graph(λ c (E)) of A with respect to any stable model Ĩ of P.</p><p>As happens between the (standard) well-founded and stable model semantics, the converse of Theorem 6 does not hold in general. That is, we may get a justification that is common to all CG-stable models but does not occur in the ECJ well-founded model. For instance, let P 6 be the program consisting on the following rules:</p><formula xml:id="formula_36">r 1 : a ← not b r 2 : b ← not a, not c c r 3 : c ← a r 4 : d ← b, not d</formula><p>The (standard) WFM of program P 6 is two-valued and corresponds to the unique (standard) stable model {a, c}. Furthermore, there are two causal explanations of c with respect to this unique stable model: the fact c and the pair of rules r 1 •r 3 . Note that when c is removed {a, c} is still the unique stable model, but all atoms are undefined in the WFM. Hence, r 1 •r 3 is a justification with respect to the unique stable model of the program, but not with respect to its WFM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Relation to Why-not Provenance</head><p>An evident similarity between ECJ and WnP approaches is the use of an alternating fixpoint operator (Van Gelder 1989) which has been actually borrowed from WnP. However, there are some slight differences. A first one is that we have incorporated from CG the non-commutative operator '•' which allows capturing not only which rules justify a given atom, but also the dependencies among these rules. The second is the use of a non-classical negation '∼' that is crucial to distinguish between productive causes and enablers. This distinction cannot be represented with the classical negation '¬' in WnP since double negation can always be removed. Apart from the interpretation of negation in both formalisms, there are other differences too. As an example, let us compare the justifications we obtain for dead 9 in program P 5 . While for ECJ we obtained (8) (or graph G 2 in Figure <ref type="figure">3</ref>), the corresponding WnP justification has the form:</p><formula xml:id="formula_37">l 2 ∧ d 9 ∧ load 1 ∧ shoot 8 ∧ not(ab 1 ) ∧ not(ab 2 ) ∧ . . . ∧ not(ab 7 ) ∧ not(water 0 ) ∧ . . . ∧ not(water 6 )<label>(10)</label></formula><p>A first observation is that the subexpression l 2 ∧d 9 ∧load 1 ∧shoot 8 constitutes, informally speaking, a "flattening" of (8) (or graph G 2 ) where the ordering among rules has been lost. We get, however, new labels of the form not(A) meaning that atom A is required not to be a program fact, something that is not present in CG-justifications. For instance, (10) points out that water can not be spilt on the gun along situations 0, . . . , 7. Although this information can be useful for debugging (the original purpose of WnP) its inclusion in a causal explanation is obviously inconvenient from a Knowledge Representation perspective, since it explicitly enumerates all the defaults that were applied (no water was spilt at any situation) something that may easily blow up the (causally) irrelevant information in a justification.</p><p>An analogous effect happens with the enumeration of exceptions to defaults, like inertia. Take program P 7 obtained from P 4 by removing all the performed actions, i.e., facts load 1 , water 3 , and shoot 7 . As expected, Fred will be alive, dead t , at any situation t by inertia. ECJ will assign no cause for dead t , not even any inhibited one, i.e. W P (dead t ) = 1 and W P (dead t ) = 0 for any t. The absence of labels in W P (dead t ) = 1 is, of course, due to the fact that inertia axioms are not labelled, as they naturally represent a default and not a causal law. Still, even if inertia were labelled, say, with in k per each situation k, we would obtain a unique cause for W P (dead t ) = in 1 • . . . • in t for any t &gt; 0 while maintaining no cause for W P (dead t ) = 0. However, the number of minimal WnP justifications of dead t grows quadratically, as it collects all the plans for killing Fred in t steps loading and shooting once. For instance, among others, all the following:</p><formula xml:id="formula_38">d 9 ∧ ¬not(load 0 ) ∧ r 2 ∧ ¬not(shoot 1 ) ∧ not(water 0 ) ∧ not(ab 1 ) d 9 ∧ ¬not(load 0 ) ∧ r 2 ∧ ¬not(shoot 2 ) ∧ not(water 0 ) ∧ not(water 1 ) ∧ not(ab 1 ) ∧ not(ab 2 ) d 9 ∧ ¬not(load 1 ) ∧ r 2 ∧ ¬not(shoot 3 ) ∧ not(water 0 ) ∧ ∧ not(water 1 ) ∧ not(water 2 ) ∧ not(ab 1 ) ∧ not(ab 2 ) ∧ not(ab 3 ) . . .</formula><p>are WnP-justifications for dead 9 . The intuitive meaning of expressions of the form ¬not(A) is that dead 9 can be justified by adding A as a fact to the program. For instance, the first conjunction means that it is possible to justify dead 9 by adding the facts load 0 and shoot 1 and not adding the fact water 0 . We will call these justifications, which contain a subterm of the form ¬not(A), hypothetical in the sense that they involve some hypothetical program modification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 15 (Provenance values)</head><p>Given a set of labels Lb, a provenance term t is recursively defined as one of the following expressions t ::= l | ∏ S | ∑ S | ¬t 1 where l ∈ Lb, t 1 is in its turn a provenance term and S is a (possibly empty and possible infinite) set of provenance terms. Provenance values are the equivalence classes of provenance terms under the equivalences of the Boolean algebra. We denote by B Lb the set of provenance values over Lb.</p><p>Informally speaking, with respect to ECJ, we have removed the application '•' operator, whereas product ' * ' and addition '+' hold the same equivalences as in Definition 2 and negation '∼' has been replaced by '¬' from Boolean algebra. Thus, '¬' is classical and satisfies all the axioms of '∼' plus ¬¬t = t. Note also that, in the examples, we have followed the convention from (Damásio et al. 2013) of using the symbols '∧' and ∨ to respectively represent meet and join. However, in formal definitions, we will keep respectively using ' * ' and '+' for that purpose. We define a mapping λ p : V Lb -→ B Lb in the following recursive way:</p><formula xml:id="formula_39">λ p (t) def =            λ p (u) ⊗ λ p (w) if t = u ⊗ v with ⊗ ∈ {+, * } λ p (u) * λ p (w) if t = u • v ¬λ p (u) if t = ∼u l if t = l with l ∈ Lb</formula><p>Definition 16 (Provenance) Given a program P, the why-not provenance program P(P) def = P ∪ P ′ where P ′ contains a labelled fact of the form (∼not(A) : A) for each atom A ∈ At not occurring in P as a fact. We will write P instead of P(P) when the program P is clear by the context. We denote by W hy P (L) def = λ p (W P (L)) the why-not provenance of a q-literal L. We also say that a justification is hypothetical when not(A) occurs oddly negated in it, non-hypothetical otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 7</head><p>Let P be program over a finite signature At, Lb . Then, the provenance of a literal according to Definition 16 is equivalent to the provenance defined by <ref type="bibr">(Damásio et al. 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 8</head><p>Let P be program over a finite signature At, Lb . W P is the result of removing all non-hypothetical justification from W P and each occurrence of the form ∼∼not(A) for the remaining ones, that is, W P = ρ(W P ) where ρ is the result of removing every label of the form not</p><formula xml:id="formula_40">(A), that is ρ is the composition of ρ not(A 1 ) • ρ not(A 2 ) • . . . • ρ not(A n ) with At = {A 1 , A 2 , . . . , A n }.</formula><p>On the one hand, Theorem 7 shows that the provenance of a literal can be obtained by replacing the negation '∼' by '¬' and '•' by ' * ' in the causal WFM of the augmented program P. On the other hand, Theorem 8 asserts that non-hypothetical justifications of a program and its augmented one coincide when subterms of the form ∼∼not(A) are removed from justifications of the latter. Consequently, we can establish the following correspondence between the ECJ justifications and the non-hypothetical WnP justifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 9</head><p>Let P be program over a finite signature At, Lb . Then, the ECJ justifications of some atom A (after replacing "•" by " * " and "∼" by "¬") correspond to the WnP justifications of A (after removing every label of the form not(B) with B ∈ At), that is, λ p (W P )(A) = ρ(W hy P )(A) where ρ is the result of removing every label of the form not(A) as in Theorem 8.</p><p>Theorem 9 establishes a correspondence between non-hypothetical WnP-justifications and (flattened) ECJ justifications. In our running example, ( <ref type="formula">7</ref>) is the unique causal justification of dead 9 , while (11) (below) is its unique non-hypothetical WnP justification.</p><formula xml:id="formula_41">¬water 3 ∧ shoot 8 ∧ load 1 ∧ l 2 ∧ d 9 ∧ ∧ not(dead 1 ) ∧ . . . ∧ not(dead 9 ) ∧ not(ab 1 ) ∧ . . . ∧ not(ab 8 )<label>(11)</label></formula><p>It is easy to see that, by applying λ p to (7) we obtain</p><formula xml:id="formula_42">λ p (∼water 3 * shoot 8 * load 1 •l 2 ) • d 9 = ¬water 3 ∧ shoot 8 ∧ load 1 ∧ l 2 ∧ d 9 (12)</formula><p>which is just the result of removing all labels of the form 'not(A)' from <ref type="bibr">(11)</ref>. The correspondence between the ECJ justification (8) and the WnP justification (10) for program P 5 can be easily checked in a similar way. Hypothetical justifications are not directly captured by ECJ, but can be obtained using the augmented program P as stated by Theorem 7. As a byproduct we establish a formal relation between WnP and CG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 10</head><p>Let P be a program over a finite signature At, Lb . Then, every non-hypothetical and enabled WnP-justification D of some atom A (after removing every label of the form not(B) with B ∈ At) is a justification with respect to every CG stable model Ĩ (after replacing "•" by " * " and "∼" by "¬"), that is D ≤ W hy P (A) implies ρ(D) ≤ λ p ( Ĩ)(A) where ρ is the result of removing every label of the form not(B) as in Theorem 8.</p><p>Note that, as happened between the ECJ and CG justifications, the converse of Theorem 10 does not hold in general due to the well-founded vs stable model difference in their definitions. As an example, the explanation for atom c at program P 6 has a unique WnP justification c as opposed to the two CG justifications, c and r 1 •r 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Contributory causes</head><p>Intuitively, a contributory cause is an event that has helped to produce some effect. For instance, in program P 5 , it is easy to identify both actions, load 1 and shoot 8 , as events that have helped to produce dead 9 and, thus, they are both contributory causes of Fred's death. We may define the above informal concept of contributory cause as: any non-negated label l that occurs in a maximal enabled justification of some atom A. Similarly, a contributory enabler can be defined as a doubly negated label ∼∼l that occurs in a maximal enabled justification of some atom A. These definitions correctly identify load 1 and shoot 8 as contributory causes of dead 9 in program P 5 and d as a contributory cause of p in program P 1 . Fact h is considered a contributory enabler of p. These definitions will also suffice for dealing with what <ref type="bibr" target="#b12">Hall (2007)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>calls trouble cases: nonexistent threats, short-circuits, late-preemption and switching examples.</head><p>It is worth to mention that, in the philosophic and AI literature, the concept of contributory cause is usually discussed in the broader sense of actual causation which tries to provide an unique everyday-concept of causation. <ref type="bibr" target="#b29">Pearl (2000)</ref> studied actual and contributory causes relying on causal networks. In this approach, it is possible to conclude cause-effect relations like "A has been an actual (resp. contributory) cause of B" from the behaviour of structural equations by applying, under some contingency (an alternative model in which some values are fixed) the counterfactual dependence interpretation from (Hume 1748): "had A not happened, B would not have happened." Consider the following example which illustrates the difference between contributory and actual causes under this approach.</p><p>Example 1 (Firing Squad) Suzy and Billy form a two-man firing squad that responds to the order of the captain. The shot of any of the two riflemen would kill the prisoner. Indeed, the captain gives the order, both riflemen shoot together and the prisoner dies.</p><p>On the one hand, the captain is an actual cause of the prisoner's death: "had the captain not given the order, the riflemen would not have shot and the prisoner would not have died." On the other hand, each rifleman alone is not an actual cause: "had one rifleman not shot, the prisoner would have died anyway because of the other rifleman." However, each rifleman's shot is a contributory cause because, under the contingency where the other rifleman does not shoot, the prisoner's death manifests counterfactual dependence on the first rifleman's shot. Later approaches like <ref type="bibr" target="#b17">(Halpern and Pearl 2001;</ref><ref type="bibr" target="#b18">Halpern and Pearl 2005;</ref><ref type="bibr" target="#b11">Hall 2004;</ref><ref type="bibr" target="#b12">Hall 2007)</ref> have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner's death, while <ref type="bibr" target="#b15">(Halpern 2015)</ref> considers the captain and the conjunction of both riflemen's shoots, but not each of them alone, as actual causes. We will focus here on representing the above concept of contributory cause and leave to the reader whether this agrees with the concept of cause in the every-day discourse or not.</p><p>As has been slightly discussed in the introduction, <ref type="bibr" target="#b11">Hall (2004;</ref><ref type="bibr" target="#b12">2007)</ref>, has emphasized the difference between two types of causal relations: dependence and production. The former relies on the idea that "counterfactual dependence between wholly distinct events is sufficient for causation." The latter is characterised by being transitive, intrinsic (two processes following the same laws must be both or neither causal) and local (causes must be connected to their effects via sequences of causal intermediates).</p><p>These two concepts can be illustrated in Bond's example by observing the difference between pouring the drug (atom d), which is a cause under both understandings, and being a holiday (atom h), which is not considered a cause under the production viewpoint, although it is considered a cause under the dependence one.</p><p>In this sense, all the above approaches to actual causation, but <ref type="bibr" target="#b11">(Hall 2004)</ref>, can be classified in the dependence category. ECJ and CG do not consider h a productive cause of d because the default (or normal) behaviour of rule (1) is that "d causes p." This default criterion is also shared by <ref type="bibr" target="#b12">(Hall 2007;</ref><ref type="bibr" target="#b13">Halpern 2008;</ref><ref type="bibr" target="#b19">Hitchcock and Knobe 2009;</ref><ref type="bibr" target="#b16">Halpern and Hitchcock 2011)</ref>. Note that, ECJ (but not CG) captures the fact that d counterfactually depends on h, as it considers it an enabler. In <ref type="bibr" target="#b11">(Hall 2004</ref>), the author relies on intrinsicness for rejecting h as a productive cause of d: any causal structure (justification) including h and p would have to include the absence of the antidote (atom a), and it would be enough that Bond had taken the antidote by another reason to break the counterfactual dependence between h and p. By applying the above contributory cause definition to the WnP justification h ∧ d ∧ r 1 of Bond's paralysis (atom p) in program P 1 , we can easily identify that h is being considered a cause in WnP, thus, a causal interpretation of WnP clearly follows the dependence-based viewpoint. On the other hand, the unique CG justification d•r 1 only considers d as a cause, which illustrates the fact that CG is mostly related to the concept of production. ECJ combines both understandings, and what is a cause under the dependence viewpoint is either an enabler or a cause under the production viewpoint.</p><p>In order to illustrate how ECJ can be used for representing the so-called non-existent threat scenarios, consider a variation of Bond's example where today is not a holiday and, thus, Bond takes the antidote. The poured drug d is a threat to Bond's safety, represented as s, but that threat is prevented by the antidote. We may represent this scenario by program P 8 below:</p><formula xml:id="formula_43">r 1 : p ← d, not a r 2 : a ← not h r 3 : s ← not p a d</formula><p>The causal WFM of program P 8 assigns</p><formula xml:id="formula_44">W P 8 (s) = ∼∼r 2 •r 3 + ∼d•r 3 + ∼r 1 •r 3</formula><p>which recognises rule r 2 (taking the antidote) as a contributory enabler of Bond's safety. The difficulty in this kind of scenarios consists in avoiding the wrong recognition of r 2 as an enabler when the threat d does not exist. If we remove fact d from P 8 to get the new program P 9 then we obtain that W P 9 (d) = 0 and, consequently, W P 9 (s) = r 3 . Intuitively, in the absence of any threat, Bond is just safe because that is his default behaviour as stated by rule r 3 .</p><p>Short-circuit examples consist in avoiding the wrong recognition of an event as a contributory enabler that provokes a threat that eventually prevents itself. Consider the program P 10 below:</p><formula xml:id="formula_45">r 1 : p ← a, not f r 2 : f ← c, not b r 3 : b ← c a c</formula><p>Here, c is a threat to p, since it may cause f through rule r 2 . However, c eventually prevents r 2 , since it also causes b through rule r 3 . The causal WFM of program P 10 assigns</p><formula xml:id="formula_46">W P 10 (p) = (a * ∼∼r 3 )•r 1 + (a * ∼r 2 )•r 1 + (a * ∼c)•r 1</formula><p>which correctly avoids considering c as a contributory enabler of p and recognises r 3 as the enabler of p. Note that c is actually considered an inhibitor due to justification (a * ∼c)•r 1 pointing out that, had c not happened, then a•r 1 would have been an enabled justification. But then, (a * ∼∼r 3 )•r 1 would stop being a justification since (a * ∼∼r 3 )•r 1 + a•r 1 = a•r 1 .</p><p>To illustrate late-preemention consider the following example from <ref type="bibr" target="#b21">(Lewis 2000)</ref>.</p><p>Example 2 (Rock Throwers) Billy and Suzy throw rocks at a bottle. Suzy throws first and her rock arrives first. The bottle shattered. When Billy's rock gets to where the bottle used to be, there is nothing there but flying shards of glass. Who has caused the bottle to shatter?</p><p>The key of this example is to recognise that Suzy, and not Billy, has caused the shattering. The usual way of representing this scenario in the actual causation literature is by introducing two new fluents hit suzy and hit billy in the following way <ref type="bibr" target="#b12">(Hall 2007;</ref><ref type="bibr" target="#b16">Halpern and Hitchcock 2011;</ref><ref type="bibr" target="#b14">Halpern 2014;</ref><ref type="bibr" target="#b15">Halpern 2015)</ref>: It is easy to see that such a representation mixes, in law ( <ref type="formula">14</ref>), both the description of the world and the narrative fact asserting that Suzy threw first. This may easily lead to a problem of elaboration tolerance. For instance, if we have N shooters and they shoot sequentially we would have to modify the equations for all of them in an adequate way, so that the last shooter's equation would have the negation of the preceding N-1 and so on. Moreover, all these equations would have to be reformulated if we simply change the shooting order. On the one hand, the first addend points out that fact throw(suzy) 0 has caused shattered 2 by means of rule s 1 . On the other hand, the second addend indicates that throw(billy) 1 has not caused it because Suzy's throw has prevented it. Finally, the third addend means that throw(billy) 1 would have caused the shattering if it were not for rule s 1 . This example shows how our semantics is able to recognise that it was Suzy, and not Billy, who caused the bottle shattering. Furthermore, it also explains that Billy did not cause it because Suzy did it first. Finally, consider the following example from <ref type="bibr" target="#b10">(Hall 2000)</ref>.</p><formula xml:id="formula_47">hit</formula><p>Example 3 (The Engineer) An engineer is standing by a switch in the railroad tracks. A train approaches in the distance. She flips the switch, so that the train travels down the right-hand track, instead of the left. Since the tracks reconverge up ahead, the train arrives at its destination all the same; let us further suppose that the time and manner of its arrival are exactly as they would have been, had she not flipped the switch.</p><p>This has been a controversial example. In <ref type="bibr" target="#b10">(Hall 2000)</ref>, the author has argued that the switch should be considered a cause of the arrival because switch has contributed to the fact that the train has travelled down the right-hand track. In a similar manner, it seems clear that the train travelling down the right-hand track has contributed to the train arrival. If causality is considered to be a transitive relation, as <ref type="bibr" target="#b10">(Hall 2000)</ref> does, the immediate consequence of the above reasoning is that flipping the switch has contributed to the train arrival. In <ref type="bibr" target="#b12">(Hall 2007</ref>) he argues otherwise and points out that commonsense tells that the switch is not a cause of the arrival. <ref type="bibr" target="#b18">(Halpern and Pearl 2005)</ref> had considered switch a cause of arrival depending on whether the train travelling down the tracks is represented by one or two variables in the model. Although our understanding of causality is closer to the one expressed in <ref type="bibr" target="#b12">(Hall 2007)</ref>, it is not the aim of this work to go more in depth in this discussion, but to show instead how both understandings can be represented in ECJ. Consider the following program P 12 where switch represents the strong negation of switch. The two unlabelled rules capture the idea that the switch behaves classically, that is, it must be activated or not. The literal not switch in the body of rule r 3 points out that the switch position is an enabler and not a cause of the track taken by the train. This representation can be arguable, but the way in which the rule has been written would be expressing that if a train is coming, then a train will cross the right track by default unless switch prevents it. In that sense, the only productive cause for right (a train in the right track) is train (a train is coming) whereas the switch position just enables the causal rule to be applied. A similar default r 4 is built for the left track, flipping the roles of switch and switch.</p><p>The causal WFM of program P 12 corresponds to</p><formula xml:id="formula_48">W P 12 (arrival) = (train * ∼∼switch)•r 3 •r 1 + (train * ∼switch)•r 4 •r 2</formula><p>It is easy to see that switch is a doubly-negated label occurring in the maximal enabled justification E 1 = (train * ∼∼switch)•r 3 •r 1 and, thus, we may identify it as a contributory enabler of arrival, but not its productive cause. On the other hand, by looking at the inhibited justification E 2 = (train * ∼switch)•r 4 •r 2 , we observe that switch is also preventing rules r 4 and r 2 to produce the same effect, arrival, that is helping to produce in E 1 .</p><p>If we want to ignore the way in which the train arrives, one natural possibility is using the same label for all the rules for atom arrival, reflecting in this way that we do not want to trace whether r 1 or r 2 has been actually used. Suppose we label r 2 with r 1 instead, leading to the new program P 13 </p><formula xml:id="formula_49">W P 12 (arrival) = (train * ∼∼switch)•r 3 •r 1 + (train * ∼switch)•r 3 •r 1 = train•r 3 •r 1</formula><p>As we can see, this justification does not consider switch at all as a cause of the arrival (nor even a contributory enabler, as before). In other words, switch is irrelevant for the train arrival, which probably coincides with the most common intuition. However, we do not find this solution fully convincing yet, because the explanation we obtain for right, W P 13 (right) = (train * ∼∼switch)•r 3 is showing that switch is just acting as an enabler, as we commented before. If we wanted to represent switch as a contributory cause of right, we would have more difficulties to simultaneously keep switch irrelevant in the explanation of arrival. One possibility we plan to explore in the future is allowing the declaration of a given atom or fluent, like our switch, as classical so that we include both, the the rule: switch ← not not switch in the logic program<ref type="foot" target="#foot_3">foot_3</ref> and the axiom ∼∼switch = switch in the algebra. The latter immediately implies switch + ∼switch = 1 (due to the weak excluded middle axiom).</p><p>Then, P 13 could be simply expressed as </p><formula xml:id="formula_50">W P (right) = (train * switch)•r 3 W P (le f t) = (train * ∼switch)•r 3</formula><p>pointing out that switch is a cause (resp. an inhibitor) of the train travelling down the right (resp. left) track. Then, the justification of arrival would be</p><formula xml:id="formula_51">W P (arrival) = (train * switch)•r 3 •r 1 + (train * ∼switch)•r 3 •r 1 = train•r 3 •r 1</formula><p>We leave the study of this possibility for a future deeper analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and other related work</head><p>In this paper we have introduced a unifying approach that combines causal production with enablers and inhibitors. We formally capture inhibited justifications by introducing a "non-classical" negation '∼' in the algebra of causal graphs (CG). An inhibited justification is nothing else but an expression containing some negated label. We have also distinguished productive causes from enabling conditions (counterfactual dependences that are not productive causes) by using a double negation '∼∼' for the latter. The existence of enabled justifications is a sufficient and necessary condition for the truth of a literal. Furthermore, our justifications capture, under the Well-Founded Semantics, both Causal Graph and Why-not Provenance justifications. As a byproduct we established a formal relation between these two approaches.</p><p>We have also shown how several standard examples from the literature on actual causation can be represented in our formalism and illustrated how this representation is suitable for domains which include dynamic defaults -those whose behaviour are not predetermined, but rely on some program condition -as for instance the inertia axioms. As pointed out by <ref type="bibr" target="#b24">(Maudlin 2004)</ref>, causal knowledge can be structured by a combination of inertial laws -how the world would evolve if nothing intervened -and deviations from these inertial laws.</p><p>In addition to the literature on actual causes cited in Section 5, our work also relates to papers on reasoning about actions and change <ref type="bibr" target="#b22">(Lin 1995;</ref><ref type="bibr" target="#b25">McCain and Turner 1997;</ref><ref type="bibr" target="#b33">Thielscher 1997</ref>). These works have been traditionally focused on using causal inference to solve representational problems (such as, the frame, ramification and qualification problems) without paying much attention to the derivation of cause-effect relations. Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches <ref type="bibr" target="#b32">(Specht 1993;</ref><ref type="bibr" target="#b4">Denecker and Schreye 1993;</ref><ref type="bibr" target="#b29">Pemmasani et al. 2004;</ref><ref type="bibr" target="#b8">Gebser et al. 2008;</ref><ref type="bibr" target="#b30">Pontelli et al. 2009;</ref><ref type="bibr" target="#b27">Oetsch et al. 2010;</ref><ref type="bibr" target="#b31">Schulz and Toni 2013)</ref>. The most important difference of these works with respect to ECJ, and also WnP and CG, is that the last three provide fully algebraic semantics in which justifications are embedded into program models. A formal relation between <ref type="bibr" target="#b30">(Pontelli et al. 2009</ref>) and WnP was established in <ref type="bibr">(Damásio et al. 2013</ref>) and so, using Theorems 7 and 9, it can be directly extended to ECJ, but at the cost of flattening the graph information (i.e. losing the order among rules).</p><p>Interesting issues for future study are incorporating enabled and inhibited justifications to the stable model semantics and replacing the syntactic definition in favour of a logical treatment of default negation, as done for instance with the Equilibrium Logic <ref type="bibr" target="#b28">(Pearce 1996</ref>) characterisation of stable models. Other natural steps would be the consideration of syntactic operators, for capturing more specific knowledge about causal information as done in <ref type="bibr">(Fandinno 2015b</ref>) capturing sufficient causes in the CG approach, and also the representation of non-deterministic causal laws, by means of disjunctive programs or the incorporation of probabilistic knowledge. <ref type="bibr">VAN</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 3</head><p>Given any term t, it can be rewritten as an equivalent term u in negation and disjuntive normal forms.</p><p>Proof . This is a trivial proof by structural induction using the DeMorgan laws and negation of application axiom. Furthermore, using the axiom ∼∼∼t = t no more than two nested negations are required. Furthermore, it is easy to see that by applying distributivity of "•" and " * " over "+," every term can be equivalently represented as a term "+" is not in the scope of any other operation. Moreover, applying distributivity of "•" over " * " every such term can be represented as one in every application subterm is elementary. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma B.2</head><p>Let t be a term. Then λ p (∼t) = ¬λ p (t).</p><p>Proof . We proceed by structural induction assuming that t is in negated normal form. In case that t = a is elementary, it follows that λ p (∼a) = ¬a = ¬λ p (a). In case that t = ∼a with a elementary, λ p (∼t) = λ p (∼∼a) and λ p (∼∼a) = a = ¬¬a = ¬λ p (∼a) = λ p (t). In case that t = ∼∼a, with a elementary, λ p (∼t) = λ p (∼∼∼a) and λ p (∼∼∼a) = λ p (∼a) = ¬a = ¬λ p (∼∼a) = ¬λ p (t)</p><p>In case that t = u + v. Then λ p (∼t) = λ p (∼u * ∼v) = λ p (∼u) ∧ λ p (∼v)</p><p>By induction hypothesis λ p (∼u) = ¬λ p (u) and λ p (∼v) = ¬λ p (v) and, therefore, it holds that λ p (∼t) = ¬λ p (u) ∧ ¬λ p (v). Thus, ¬λ p (t) = ¬(λ p (u) ∨ λ p (v)) = ¬λ p (u) ∧ ¬λ p (v) = λ p (∼t).</p><p>In case that t = u ⊗ v with ⊗ ∈ { * , •}. Then λ p (∼t) = λ p (∼u + ∼v) = λ p (∼u) ∨ λ p (∼v) and by induction hypothesis λ p (∼u) = ¬λ p (u) and λ p (∼v) = ¬λ p (v). Consequently it holds that λ p (∼t) = ¬λ p (t).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma B.3</head><p>Let t be a term and φ a provenance term. If φ ≤ λ p (t), then λ p (∼t) ≤ ¬φ and if λ p (t) ≤ φ , then ¬φ ≤ λ p (∼t).</p><p>Proof . If φ ≤ λ p (t), then φ = λ p (t) * φ and then ¬φ = ¬λ p (t) + ¬φ and, by Lemma B.2, it follows that ¬φ = λ p (∼t) + ¬φ . Hence λ p (∼t) ≤ ¬φ . Furthermore if λ p (t) ≤ φ , then φ = λ p (t) + φ and then ¬φ = ¬λ p (t) * ¬φ and, by Lemma B.2, it follows that ¬φ = λ p (∼t) * ¬φ .</p><p>Hence ¬φ ≤ λ p (∼t).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B.2. Proof of Theorem 1</head><p>The proof of Theorem 1 will relay on the definition of the following direct consequence operator</p><formula xml:id="formula_52">TP ( Ĩ)(H) def = ∑ Ĩ(B 1 ) * . . . * Ĩ(B n ) • r i | (r i : H ← B 1 , . . . , B n ) ∈ P</formula><p>for any CG interpretation Ĩ and atom H ∈ At. Note that the definition of this direct consequence operator TP is analogous to the T P operator, but the domain and image of TP are the set of CG interpretations while the domain and image of T P are the set of ECJ interpretations.</p><p>Theorem 11 (Theorem 2 from <ref type="bibr">Cabalar et al. 2014a)</ref> Let P be a (possibly infinite) positive logic program with n causal rules. Then, (i) lfp( TP ) is the least model of P, and (ii) lfp( TP ) = TP ↑ ω (0) = TP ↑ n (0).</p><p>Proof of Theorem 1. Assume that every term occurring in P is NNF and let Q be the program obtained by renaming in P each occurrence of ∼l as l ′ and each occurrence of ∼∼l as l ′′ with l ′ and l ′′ new symbols. Note that this renaming implies that ∼l and ∼∼l are treated as completely independent symbols from l and, thus, all equalities among terms derived from program Q are also satisfied by P, although the converse does not hold. Note also that, since ∼ does not occur in Q, this is also a CG program. From Theorem 11, lfp( TQ ) = TQ ↑ ω (0) is the least model of Q. By renaming back l ′ and l ′′ as ∼l and ∼∼l in TQ ↑ k (0) we obtain T P ↑ k (0) for any k. Hence, lfp(T P ) = T P ↑ ω (0) is the least model of P. Statement (ii) is proved in the same manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B.3. Proof of Proposition 4</head><p>Lemma B.4</p><p>Let P 1 and P 2 be two programs and let U 1 and U 2 be two interpretations such that P 1 ⊇ P 2 and U 1 ≤ U 2 . Let also I 1 and I 2 be the least models of P U 1 1 and P U 2 2 , respectively. Then I 1 ≥ I 2 .</p><p>Proof . First, for any rule r i and pair of interpretations J 1 and J 2 such that J 1 ≥ J 2 ,</p><formula xml:id="formula_53">J 1 (body + (r U 1 i )) ≥ J 2 (body + (r U 2 i )) Furthermore, since U 1 ≤ U 2 , by Proposition 1, it follows U 1 (body -(r U 1 i )) ≥ U 2 (body -(r U 2 i ))</formula><p>and, since by Definition 5 J j (body -(r</p><formula xml:id="formula_54">U 1 i )) def = U j (body -(r U 1 i )), it follows that J 1 (body -(r U 1 i )) ≥ J 2 (body -(r U 2 i ))</formula><p>Hence, we obtain that J 1 (body(r U 1 i )) ≥ J 2 (body(r U 2 i )). Since P 1 ⊇ P 2 , it follows that every rule r i ∈ P 2 is in P 1 as well. Thus,</p><formula xml:id="formula_55">T P U 1 1 (J 1 )(H) ≥ T P U 2 2 (J 2 )(H)</formula><p>for every atom H. Furthermore, since</p><formula xml:id="formula_56">T P U 1 1 ↑ 0 (0)(H) = T P U 2 2 ↑ 0 (0)(H) = 0 it follows T P U 1 1 ↑ i (0)(H) ≥ T P U 2 2</formula><p>↑ i (0)(H) for all 0 ≤ i. Finally,</p><formula xml:id="formula_57">T P U j j ↑ ω (0)(H) def = ∑ i≤ω T P U j j ↑ i (0)(H) = 0 and hence T P U 1 1 ↑ ω (0)(H) ≥ T P U 2 2</formula><p>↑ ω (0)(H). By Theorem 1, these are respectively the least models of P U 1 1 and P U 2 2 . That is</p><formula xml:id="formula_58">I 1 ≥ I 2 .</formula><p>Proposition 4 Γ P operator is anti-monotonic and operator Γ 2 P is monotonic. That is, Γ P (U 1 ) ≥ Γ P (U 2 ) and Γ 2 P (U 1 ) ≤ Γ 2 P (U 2 ) for any pair of interpretations U 1 and U 2 such that U 1 ≤ U 2 .</p><p>Proof . Since U 1 ≤ U 2 , by Lemma B.4, it follows I 1 ≥ I 2 with I 1 and I 2 being respectively the least models of P U 1 and P U 2 . Then, Γ P (U 1 ) = I 1 and Γ P (U 2 ) = I 2 and, thus, Γ P (U 1 ) ≥ Γ P (U 2 ). Since Γ P is anti-monotonic it follows that Γ 2 P is monotonic.</p><p>and, by induction hypothesis, E B j ≤ λ c T P J ↑ α-1 (0)(B j ) for all B j . Furthermore, by definition</p><formula xml:id="formula_59">T P J ↑ α-1 (0)(B 1 ) * . . . * T P J ↑ α-1 (0)(B m ) * J(notC 1 ) * . . . * J(notC m ) • r i ≤ T P J ↑ α (0)(H)</formula><p>From the fact that Ĩ(C j ) = 0 and the lemma's hypothesis Ĩ ≥ λ c (J), it follows that 0 ≥ λ c (J(C j )) and, thus, 1 ≤ λ c (∼J(C j )) = λ c (J(notC j )). Hence,</p><formula xml:id="formula_60">λ c (T P J ↑ α-1 (0)(B 1 ) * . . . * T P J ↑ α-1 (0)(B m ) * J(notC 1 ) * . . . * J(notC m )) • r i = = λ c (T P J ↑ α-1 (0)(B 1 ) * . . . * T P J ↑ α-1 (0)(B m ) * λ c J(notC 1 ) * . . . * λ c J(notC m ) • r i = λ c (T P J ↑ α-1 (0)(B 1 ) * . . . * T P J ↑ α-1 (0)(B m ) * 1 * . . . * 1 • r i = λ c (T P J ↑ α-1 (0)(B 1 ) * . . . * T P J ↑ α-1 (0)(B m ) • r i</formula><p>and, thus,</p><formula xml:id="formula_61">λ c (T P J ↑ α-1 (0)(B 1 ) * . . . * T P J ↑ α-1 (0)(B m ) • r i ≤ λ c T P J ↑ α (0)(H) Since E B j ≤ λ c T P J ↑ α-1 (0)(B j ) for all B j , it follows that E ≤ (E B 1 * . . . * E B m ) • r i ≤ λ c (T P J ↑ α (0))(H)</formula><p>Finally, in case that α is a limit ordinal, it follows from Theorem 1 that α = ω. Furthermore, since Ĩ is a CG interpretation, it follows that P Ĩ is a CG program and, thus, E ≤ T P Ĩ ↑ ω (0) iff E ≤ T P Ĩ ↑ n (0) for some n &lt; ω (see <ref type="bibr">Cabalar et al. 2014a</ref>). Hence, by induction hypothesis, it follows that E ≤ T P J ↑ n (0) ≤ T P J ↑ ω (0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma B.7</head><p>Let P be a labelled logic program over a signature At, Lb where Lb is a finite set of labels, Ĩ and J respectively be a CG and a ECJ interpretation such that Ĩ ≤ λ c (J). Then ΓP ( Ĩ) ≥ λ c (Γ P (J)).</p><p>Proof . Since Lb is finite, it follows that V Lb is also finite. Furthermore, since V Lb is a finite distributive lattice, every element t ∈ V Lb can be represented as a unique sum of join irreducible elements (Proposition 5).</p><p>Assume as induction hypothesis that u ≤ T P J ↑ β (0)(H) implies λ c (u) ≤ TP Ĩ ↑ β (0)(H) for every join irreducible u, atom H ∈ At and ordinal β &lt; α.</p><p>In case that α is a successor ordinal. For any join irreducible justification u ≤ T P J ↑ α (0)(H) there is a rule R J in P J of the form (6) and there are join irreducible terms u B j ≤ T P J ↑ α-1 (0)(B j ) and u C j ≤ ∼J(C j ) for all B j and C j such that</p><formula xml:id="formula_62">u ≤ (u B 1 * . . . * u B m * u C 1 * . . . * u C n ) • r i</formula><p>If u C j contains an oddly negated label for some C j , then λ c (u C j ) = 0 and it consequently follows that λ c (u) = 0 ≤ TP Ĩ ↑ α (0)(H). Thus, we assume that u C j only contains evenly negated labels for any C j . Note that, since u C j ≤ ∼J(C j ), then u C j cannot contain any non-negated label, that is, all occurrences of labels in u C j are strictly evenly negated and, thus, every term u ′ C j ≤ J(C j ) must contain some oddly negated label. Hence, Ĩ(C j ) ≤ λ c (J(C j )) = 0 for any C j and there is a rule R Ĩ in Q Ĩ of the form</p><formula xml:id="formula_63">r i : H ← B 1 , . . . , B m</formula><p>By induction hypothesis, u B j ≤ T P J ↑ α-1 (0)(B j ) implies λ c (u B j ) ≤ TP Ĩ ↑ α-1 (0)(B j ) and, con- sequently, λ c (u) ≤ TP Ĩ ↑ α (0)(H).</p><p>Since T P J ↑ α (0)(H) = ∑ u∈U H u where every u ∈ U H is join irreducible and every u ∈ U H satisfies u ≤ T P J ↑ α (0)(H), it follows that λ c (u) ≤ TP Ĩ ↑ α (0)(H) and, thus, ∑ u∈U H λ c (u) ≤ TP Ĩ ↑ α (0)(H). Note that, by definition, λ c (∑ u∈U H u) = ∑ u∈U H λ c (u) and, thus,</p><formula xml:id="formula_64">λ c (T P J ↑ α (0)(H)) = λ c ( ∑ u∈U H u) ≤ TP Ĩ ↑ α (0)(H)</formula><p>In case that α is a limit ordinal, it follows u ≤ T P J ↑ α (0)(H) iff u ≤ T P J ↑ β (0)(H) for some β &lt; ω and, by induction hypothesis, it follows that λ c (u) ≤ TP Ĩ ↑ β (0)(H) ≤ TP Ĩ ↑ α (0)(H) and, thus, TP Ĩ ↑ α (0) ≥ λ c (T P J ↑ α (0)).</p><p>Finally, by definition ΓP ( Ĩ) and Γ P (J) are respectively the least models of P Ĩ and P J and, from Theorem 11, these are precisely TP Ĩ ↑ ω (0) and T P J ↑ ω (0). Hence, TP Ĩ ↑ ω (0) ≥ λ c (T P J ↑ ω (0)) implies ΓP ( Ĩ) ≥ λ c (Γ P (J)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 6</head><p>Given a program P over a signature At, Lb where Lb is a finite set of labels, any ECJ interpretation I satisfies ΓP (λ c (I)) = λ c (Γ P (I))).</p><p>Proof of Proposition 6. Let Ĩ be a CG interpretation such that I(H) = Ĩ(H) for every atom H. Then, it follows that Ĩ = λ c (I). Hence, from Lemmas B.6 and B.7, it respectively follows that ΓP ( Ĩ) ≤ λ c ( Γ P (I)) and ΓP ( Ĩ) ≥ λ c ( Γ P (I)). Then, ΓP ( Ĩ) = ΓP (λ c (I)) = λ c ( Γ P (I)).</p><p>Proof of Theorem 5. According to <ref type="bibr">(Cabalar et al. 2014a</ref>), a CG interpretation Ĩ is a CG stable model of P iff Ĩ is the least model of the program P Ĩ . Then, the CG stable models are just the fixpoints of the ΓP operator.</p><p>Let Ĩ be a CG stable model according to <ref type="bibr">(Cabalar et al. 2014a</ref>), let I be a ECJ interpretation such that I(H) = Ĩ(H) for every atom H ∈ At and let J def = Γ 2 P ↑ ∞ (I) be the least fixpoint of Γ 2 P iterating from I. Since I(H) = Ĩ(H) for every atom H ∈ At, it follows that Ĩ = λ c (I) and, by definition of CG stable model, it follows that Ĩ = ΓP ( Ĩ). Thus, from Proposition 6, it follows that Ĩ = λ c (Γ P (I)). Applying ΓP to both sides of this equality, we obtain that ΓP ( Ĩ) = ΓP (λ c (Γ P (I))).</p><p>From Proposition 6 again, it follows that ΓP (λ c (Γ P (I))) = λ c (Γ P (Γ P (I))) = λ c (Γ 2 P (I)) and, thus, ΓP ( Ĩ) = λ c (Γ 2 P (I)). Furthermore, since Ĩ = ΓP ( Ĩ), it follows that Ĩ = λ c (Γ 2 P (I)). Inductively applying this argument, it follows that Ĩ = λ c (Γ 2 P ↑ α (I)) for any successor ordinal α. Moreover, for a limit ordinal α,</p><formula xml:id="formula_65">λ c Γ 2 P ↑ α (I) = λ c ∑ β &lt;α Γ 2 P ↑ β (I) = ∑ β &lt;α λ c Γ 2 P ↑ β (I) = Ĩ</formula><p>Then, since we have defined J = Γ 2 P ↑ ∞ (I), it follows that Ĩ = λ c (J) = λ c (I) and, since we also have that Ĩ = λ c (Γ P (I)), we obtain that λ c (I) = λ c (Γ P (I)).</p><p>The other way around. Let I be a fixpoint of Γ 2 P such that λ c (I) = λ c (Γ P (I)) and let Ĩ def = λ c (I). In the same way as above, it follows that ΓP ( Ĩ) = λ c (Γ P (I)) = λ c (I) = Ĩ. That is, ΓP ( Ĩ) = Ĩ and so that Ĩ is a causal stable model of P according to <ref type="bibr">(Cabalar et al. 2014a)</ref>.</p><p>In case that α = 0, it follows that λ p (T P I ↑ 0 (0)(H)) = T P I ↑ 0 (⊥)(H) = 0 for every atom H. We assume as induction hypothesis that λ p (T P I ↑ β (0)) ≤ T P I ↑ β (⊥) for all β &lt; α.</p><p>In case that α is a successor ordinal. Assume that u ≤ T P I ↑ α-1 (0)(H) for some join irreducible u and atom H. Then there is a rule r i ∈ P of the form (4) and</p><formula xml:id="formula_66">u ≤ (u B 1 * . . . * u B 1 * u C 1 * . . . * u C 1 ) • r i</formula><p>where u B j ≤ T P I ↑ α-1 (0)(B j ) and u C j ≤ ∼I(C j ). Hence, by induction hypothesis, it follows that λ p (u B j ) ≤ T P I ↑ α-1 (⊥)(B j ) and, since u C j ≤ ∼I(C j ), it also follows that λ p (u C j ) ≤ ¬I(C j ) for all C j . Consequently, we have that λ p (u) ≤ T P I ↑ α (⊥)(H).</p><p>In case that α is a limit ordinal, u ≤ T P I ↑ α (0) iff u ≤ T P I ↑ β (0) for some β &lt; α and all join irreducible u. Hence, by induction hypothesis, it follows that λ p (u) ≤ T P J ↑ β (0) ≤ T P J ↑ α (0) and, thus, λ p (T P I ↑ α (0)) ≤ T P J ↑ α (⊥).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma B.9</head><p>Let P be a labelled logic program over a signature At, Lb where Lb is a finite set of labels and let I and I be respectively a ECJ and a WnP interpretation such that λ p (I) ≤ I. Therefore, λ p (Γ P (I)) ≥ G P (I).</p><p>Proof . The proof is similar to the proof of Lemma B.8 and we just show the case in which α is a successor ordinal.</p><p>Assume that u ≤ T P I ↑ α (⊥)(H) for some join irreducible u and atom H. Hence, there is some rule r i ∈ P of the form (4) and where u B j ≤ T P I ↑ α-1 (⊥)(B j ) for each B j and u C j ≤ ¬I(C j ) for each C j . By induction hypothesis, u B j ≤ λ p (T P I ↑ α-1 (0))(B j ) for all B j . Furthermore, since λ p (I) ≤ I it follows, from Lemma B.3, that λ p (∼I) ≥ ¬I and, since u C j ≤ ¬I(C j ), it also follows that u C j ≤ λ p (∼I(C j )). Hence, λ (u) ≤ (λ p (u B 1 ) * . . . * λ p (u B 1 ) * λ p (u C 1 ) * . . . * λ p (u C 1 )) * r i ≤ λ p (T P I ↑ α (0)(H)) Thus, T P I ↑ α (⊥)(B j ) ≤ λ p (T P I ↑ α (0)(B j )).</p><p>Note that the image of λ p is a boolean algebra and the set of causal values corresponding to negated terms { ∼t t ∈ V Lb } are also a boolean algebra. Consequently, we define a function λ q (t) = ∼∼t which is analogous to λ p but whose image is in V Lb .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma B.10</head><p>Let P be a labelled logic program and let I be an ECJ interpretation. Then, Γ P (I) = Γ P (λ q (I)) and λ p (t) = λ p (λ q (t)).</p><p>Proof . For Γ P (I) = Γ P (λ q (I)). Since λ q (t) = ∼∼t and ∼∼∼t = ∼t, it follows that λ q (∼I) = ∼∼∼I = ∼I and, thus, P I = P λ q (I) . Since by definition Γ P (I) and Γ P (λ q (I)) are respectively the least models of programs P I and P λ q (I) it is clear that Γ P (I) = Γ P (λ q (I)).</p><p>For λ p (t) = λ p (λ q (t)), just note λ p (λ q (t)) = λ p (∼∼t) = ¬¬λ p (t) = λ p (t).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 7</head><p>Let P be a program over a signature At, Lb where Lb is a finite set of labels. Then, any causal interpretation I satisfies:</p><p>(i). G P (λ p (I)) = λ p (Γ P (I)), (ii). Γ P (λ q (I)) = Γ P (I) and (iii). λ p (t) = λ p (λ q (t)).</p><p>Proof . (i) From Lemmas B.8 and B.9, it respectively follows that λ p ( Γ P (I)) ≤ G P (λ p (I)) and that λ p ( Γ P (I)) ≥ G P (λ p (I)). Then, G P (λ p (I)) = λ p ( Γ P (I)). (ii) and (iii) follow from Lemma B.10.</p><p>Proof of Theorem 7. Note that W hy P (A) = T P (A) and that, by λ p definition, it follows that λ p (0) = 0 and thus, from Proposition 7 (i), it follows that G P (⊥) = G P (λ p (0)) = λ p (Γ P (0)) and G P (⊥) = G P (λ p (0)) = λ p (Γ P (0)) = λ p (λ q (Γ P (0)))</p><p>Hence, from Proposition 7, it follows that G 2 P (⊥) = G P (G P (⊥)) = G P (λ p (λ q (Γ P (0)))) = λ p (Γ P (λ q (Γ P (0)))) = λ p (Γ P (Γ P (0))) = λ p (Γ 2 P (0)) Inductively applying this reasoning it follows that G 2 P ↑ ∞ (0) = λ p (Γ 2 P ↑ ∞ (0)) which, by Knaster-Tarski theorem are the least fixpoints of the operators, that is, T P = λ p (L P ) and, consequently, W hy P (A) = T P (A) = λ p (L P (A)) = λ p (W P (A)) = W hy P (A). Similarly, by definition, it fol- lows that W hy P (not A) = ¬TU P (A) where TU P is the greatest fixpoint of the operator G 2 P . Thus, W hy P (not A) = ¬G P (T P ) = λ p (∼Γ P (L P )) = λ p (∼U P (A)) = λ p (W P (not A))</p><p>Finally, W hy P (undef A) = ¬T P (A) * TU P (A) and, thus W hy P (undef A) = λ p (∼L P (A)) * λ p (∼∼U P (A)) = λ p (∼L P (A) * ∼∼U P (A)) = λ p (∼W P (A) * ∼W P (not A)) = λ p (W P (undef A)) and, thus, W hy P (undef A) = λ p (W P (undef A)) = W hy P (not A).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B.9. Proof of Theorem 8</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma B.11</head><p>Let P be a labelled logic program over a signature At, Lb where Lb is a finite set of labels and no rule is a labelled by not(A) nor ∼∼not(A). Let Q be the result of removing all rules labelled by ∼not(A) for some atom A. Let I and J be two interpretations such that J = ρ not(A) (I). Then, Γ Q (J) = ρ not(A) (Γ P (I)).</p><p>Proof . In the sake of simplicity, we just write ρ instead of ρ not <ref type="bibr">(A)</ref> . By definition Γ P (I) and Γ Q (J) are respectively the least model of P I and Q J . The proof follows then by induction on the steps of the T P operator assuming that ρ(T P I ↑ β (0)) = T Q J ↑ β (0) for all β &lt; α.</p><p>Proof of Theorem 8. By definition, program P is the result of removing all rules labelled with ∼not(A) in P. In case that L is some atom H, by definition, it follows that W P (H) = L P (H) and W P (H) = L P (H) and, from Proposition 8, it follows that L P = ρ(L P ) and, thus W P = ρ(W P ).</p><p>Similarly, in case that L is a negative literal (L = not H), then W P (H) = ∼U P (H) and W P (H) = ∼U P (H) and, from Proposition 8, it follows that U P = ρ(U P ). Just note tha ρ x (∼u) = ∼ρ x (u) for any elementary term x and any value u. Hence, U P = ρ(U P ) implies that ∼U P = ρ(∼U P ) and, consequently, W P = ρ(W P ).</p><p>In case that L is an undefined literal (L = undef H), by definition, it follows that W P (H) = ∼W P (H) * ∼W P (not H) = ∼L P (H) * ∼∼U P (H) and W P (H) = ∼L P (H) * ∼∼U P (H) and the result follows as before from Proposition 8. any enabled justification E ≤ W P (not L) iff there is some enabled justification E ≤ ∼W P (L) and there is some enabled justification E ≤ ∼W P (not L) iff there is some enabled justification W P (undef A) = ∼W P (A) * ∼W P (not A).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B.12. Proof of Theorem 10</head><p>Lemma B.13 Let t and u be two causal terms such that no-sums occur in t ant t ≤ u. Then, ρ x (t) ≤ ρ x (u).</p><p>Proof . By definition t ≤ u if and only if t = t * u. Then, ρ x (t) = ρ x (t * u) = ρ x (t) * ρ x (u) and, thus if follows that ρ x (t) ≤ ρ x (u).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma B.14</head><p>Let t be a causal term. Then, λ c (λ p (t)) ≤ λ p (λ c (t)).</p><p>Proof . If t ∈ Lb is a label, then λ c (t) = t and λ p (t) = t and, thus, λ c (λ p (t)) = t ≤ t = λ p (λ c (t)). If t = ∼l with l ∈ Lb a label, then λ c (t) = 0 and λ p (t) = ¬l and, thus, λ c (λ p (t)) = 0 ≤ 0 = λ p (λ c (t)). If t = ∼∼l with l ∈ Lb a label, then λ c (t) = 1 and λ p (t) = l and, thus, λ c (λ p (t)) = l ≤ 1 = λ p (λ c (t)).</p><p>Assume as induction hypothesis that λ c (λ p (u)) ≤ λ p (λ c (u)) for every subterm u of t. Proof of Theorem 10. From Theorem 9, it follows that ρ(W hy P (A)) = λ p (W P )(A). Furthermore, since D ≤ W hy P (A), from Lemma B.13, it follows that ρ(D) ≤ ρ(W hy P (A)) = λ p (W P )(A) = λ p (L P )(A) and, thus, λ c (ρ(D)) ≤ λ c (λ p (L P ))(A). Let Ĩ be any CG stable model. Then, since Ĩ = λ c (I) for some fixpoint I of Γ 2 P , it follows that λ c (L P ) ≤ Ĩ and, thus, λ p (λ c (L P )) ≤ λ p ( Ĩ). Furthermore, from Lemma B.14, it follows that λ c (λ p (L P )) ≤ λ p (λ c (L P )) and, thus λ c (ρ(D)) ≤ λ c (λ p (L P ))(A) ≤ λ p (λ c (L P ))(A) ≤ λ p ( Ĩ)(A) Note that, since D is non-hypothetical and enabled, it does not contain negated labels and, thus, λ c (ρ(D)) = ρ(D). Consequently, ρ(D) ≤ λ p ( Ĩ)(A).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>r 1 :</head><label>1</label><figDesc>arrival ← right r 2 : arrival ← le f t r 3 : right ← train, not switch r 4 : le f t ← train, not switch switch ← not switch switch ← not switch train switch</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>r 1 :</head><label>1</label><figDesc>arrival ← right r 1 : arrival ← le f t r 3 : right ← train, not switch r 3 : le f t ← train, not switch switch ← not switch switch ← not switch train switch whose causal WFM corresponds to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>r 1 :</head><label>1</label><figDesc>arrival ← right r 1 : arrival ← le f t r 3 : right ← train, switch r 3 : le f t ← train, not switch train switch and the justification of right and le f t would become</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>u</head><label></label><figDesc>≤ u B 1 * . . . * u B m * u C 1 * . . . * u C n * r i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>If t = u 1 •u 2 , then λ c (λ p (u 1 •u 2 )) = λ c (λ p (u 1 ) * λ c (λ p (u 2 ) ≤ λ p (λ c (u 1 ) * λ p (λ c (u 2 ) = λ p (λ c (u 1 •u 2 )) Similarly, if t = ∑ u∈U u, then λ c (λ p ( ∑ u∈U u) = ∑ u∈U λ c (λ p (u) ≤ ∑ u∈U λ p (λ c ((u)) = λ p (λ c ( ∑ u∈U u)) and if t = ∏ u∈U u, then λ c (λ p ( ∏ u∈U u) = ∏ u∈U λ c (λ p (u) ≤ ∏ u∈U λ p (λ c ((u)) = λ p (λ c ( ∏ u∈U u))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>loaded t , not ab t l t+1 : loaded t+1 ← load t</figDesc><table><row><cell></cell><cell></cell><cell>loaded 0</cell><cell>load 1</cell></row><row><cell></cell><cell></cell><cell>dead 0</cell><cell>water 3</cell></row><row><cell>a t+1 : ab t+1</cell><cell>← water t</cell><cell>ab 0</cell><cell>shoot 8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>On the other hand, we may represent this scenario by a program P 11 consisting of the following rules</figDesc><table><row><cell>s t+1 : shattered t+1 ← throw(A) t , not shattered t</cell><cell>throw(suzy) 0</cell></row><row><cell>shattered 0</cell><cell>throw(billy) 1</cell></row><row><cell cols="2">with A ∈ {suzy, billy}, plus the following rules corresponding to the inertia axioms</cell></row><row><cell>shattered t+1 ← shattered t , not shattered t+1</cell><cell></cell></row><row><cell>shattered t+1 ← shattered t , not shattered t+1</cell><cell></cell></row><row><cell cols="2">Atom shattered 2 holds in the standard WFM of P 11 and its justification corresponds to</cell></row><row><cell>throw(suzy)</cell><cell></cell></row></table><note><p>0 •s 1 + (∼throw(suzy) * throw(billy) 1 )•s 2 + (∼s 1 * throw(billy) 1 )•s 2</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>GELDER, A., ROSS, K. A., AND SCHLIPF, J. S. 1991. The well-founded semantics for general logic programs. Journal of the ACM (JACM) 38, 3, 620-650. is, t → ∼∼t is idempotent. Finally, note that, by definition, t ≤ ∼∼t iff t * ∼∼t = t and</figDesc><table><row><cell>t  *  ∼∼t = t  *  ∼∼t + 0</cell><cell>(identity)</cell></row><row><cell>= t  *  ∼∼t + t  *  ∼t</cell><cell>(pseudo-complement)</cell></row><row><cell>= (t  *  ∼∼t + t)  *  (t  *  ∼∼t + ∼t)</cell><cell>(distributivity)</cell></row><row><cell>= (t + t)  *  (∼∼t + t)  *  (t + ∼t)  *  (∼∼t + ∼t)</cell><cell>(distributivity)</cell></row><row><cell>= t  *  (∼∼t + t)  *  (t + ∼t)  *  (∼∼t + ∼t)</cell><cell>(idempotency)</cell></row><row><cell>= t  *  (t + ∼t)  *  (∼∼t + t)  *  1</cell><cell>(w. excluded middle)</cell></row><row><cell>= t  *  (t + ∼t)  *  (∼∼t + t)</cell><cell>(identity)</cell></row><row><cell>= t  *  (∼∼t + t)</cell><cell>(absorption)</cell></row><row><cell>= t</cell><cell>(absorption)</cell></row><row><cell>Hence, t → ∼∼t is a closure.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>B.1Let t be a join irreducible causal value. Then, either t * ∼∼u = 0 or t * ∼∼u is join irreducible for every causal value u ∈ V Lb .Proof . Suppose that t * u is not join irreducible and let W ⊆ V Lb a set of causal values such that w = t * ∼∼u for every w ∈ W and t * ∼∼u = ∑ w∈W w. Since t * ∼∼u = ∑ w∈W w, it follows that w ≤ t * ∼∼u for every w ∈ W and, since w = t * ∼∼u, it follows that w &lt; t * ∼∼u for every w ∈ W . Furthermore, t * ∼∼u+ t * ∼u = t * (∼∼u + ∼u) = t.Since t is join irreducible, it follows that either t = t * ∼∼u or t = t * ∼u. If t = t * ∼u, then t * ∼∼u = (t * ∼u) * ∼∼u = 0. Otherwise, t = t * ∼∼u and t is join irreducible by hypothesis.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>This behaviour coincides indeed with the properties for default negation obtained in Equilibrium Logic<ref type="bibr" target="#b28">(Pearce 1996)</ref> or the equivalent General Theory of Stable Models(Ferraris et al.  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2007).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>We just mention labels, and not their occurrences because terms are in NNF and E contains no sums. Thus, having odd and even occurrences of a same label at a same time would mean that E = 0.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>This implication actually corresponds to a choice rule 0{switch}1, commonly used in Answer Set Programming.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We are thankful to <rs type="person">Carlos Damásio</rs> for his suggestions and comments on earlier versions of this work. We also thank the anonymous reviewers for their help to improve the paper. This research was partially supported by <rs type="funder">Spanish</rs> Project <rs type="grantNumber">TIN2013-42149-P</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_efTbW8d">
					<idno type="grant-number">TIN2013-42149-P</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Auxiliary figures</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Proofs of Theorems and Implicit Results</head><p>In the following, by abuse of notation, for every function f : V Lb -→ V Lb , we will also denote by f a function over the set of interpretations such that f (I)(A) = f (I(A)) for every atom A ∈ At. We have organized the proofs into different subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B.1. Proofs of Propositions 1 to 3</head><p>Proposition 1 Negation '∼' is anti-monotonic. That is t ≤ u holds if and only if ∼t ≥ ∼u for any given two causal terms t and u.</p><p>Proof . By definition t ≤ u iff t * u = t. Furthermore, by De Morgan laws, ∼(t * u) = ∼t + ∼u and, thus, ∼(t * u) = ∼t iff ∼t + ∼u = ∼t. Finally, just note that ∼t + ∼u = ∼t iff ∼t ≥ ∼u. Hence, t ≤ u holds iff ∼t ≥ ∼u.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 2</head><p>The map t → ∼∼t is a closure. That is, it is monotonic, idempotent and it holds that t ≤ ∼∼t for any given causal term t. Proof . To show that t → ∼∼t is monotonic just note that t → ∼t is antimonotonic (Proposition 1) and then t ≤ u iff ∼t ≥ ∼u iff ∼∼t ≤ ∼∼u. Furthermore, ∼∼(∼∼t) = ∼(∼∼∼t) = ∼∼t, that</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B.4. Proof of Theorem 2</head><p>The proof of Theorem 2 will rely on the relation between ECJ justifications and non-hypothetical WnP justifications established by Theorem 9 and it can be found below the proof of that theorem in page 36.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B.5. Proof of Theorem 3</head><p>Definition 17 A term t ∈ V Lb is join irreducible iff t = ∑ u∈U u implies that u = t for some u ∈ U and it is join prime iff t ≤ ∑ u∈U u implies that u ≤ t for some u ∈ U.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 5</head><p>The following results hold:</p><p>1. A term is join irreducible iff is join prime.</p><p>2. If Lb is finite, then every term t can be represented as a unique finite sum of pairwise incomparable join irreducible terms.</p><p>Proof . The first result directly follows from Theorem 1 in <ref type="bibr">(Balbes and Dwinger 1975, page 65)</ref>. Furthermore, from Theorem 2 in <ref type="bibr">(Balbes and Dwinger 1975, page 66)</ref>, in every distributive lattice satisfying the descending chain condition, any element can be represented as a unique finite sum of pairwise incomparable join irreducible elements and it is clear that every finite lattice satisfies the descending chain condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma B.5</head><p>Let P be a positive program over a signature At, Lb where Lb is a finite set of labels and Q be the result of removing all rules labelled by some label l ∈ Lb. Let I and J be two interpretations such that J such that ρ ∼l (I) ≥ J. Then, ρ ∼l (Γ P (I)) ≤ Γ Q (J).</p><p>Proof . By definition Γ P (I) and Γ Q (J) are the least models of programs P I and Q J , respectively. Furthermore, from Theorem 1, the least model of any program P is the least fixpoint of the T P operator, that is, Γ X (Y ) = T X Y ↑ ω (0) with X ∈ {P, Q} and X Y ∈ {P I , P J }. Then, the proof follows by induction assuming that u ≤ T Q J ↑ β (0)(H) implies ρ ∼l (u) ≤ T Q I ↑ β (0)(H) for any join irreducible u, atom H and every ordinal β &lt; α.</p><p>Note that T Q J ↑ 0 (0)(H) = 0 = ρ ∼l (0) = T P I ↑ 0 (0)(A) for any atom H and, thus, the statement holds vacuous.</p><p>If α is a successor ordinal, since u ≤ T P I ↑ α (0)(H), there is a rule in P of the form (4) such that</p><p>where u B j ≤ T P I ↑ α-1 (0)(B j ) and u C j ≤ ∼I(C j ) for each positive literal B j and each negative literal not C j in the body of rule r i . Then, 1. By induction hypothesis, it follows that ρ ∼l (u B j ) ≤ T Q J ↑ α-1 (0)(B j ), and 2. from ρ ∼l (I(H)) ≥ J(H), it follows that u C j ≤ ∼I(C j ) implies ρ ∼l (u C j ) ≤ ∼J(C j ).</p><p>Furthermore, if r i = l, then r i ∈ Q and, thus,</p><p>In case that α is a limit ordinal, u ≤ T P I ↑ α (0) iff u ≤ T P I ↑ β (0) for some β &lt; α and any join irreducible u. Hence, by induction hypothesis, it follows that ρ ∼l (u)</p><p>Proof of Theorem 3. In the sake of simplicity, we just write ρ instead of ρ ∼r i . Note that, by definition, for any atom H, it follows that W X (H) = L X (H) with X ∈ {P, Q}. The proof follows by induction in the number of steps of the Γ 2 operator assuming as induction hypothesis that</p><p>and, thus, the statement trivially holds for α = 0 .</p><p>In case that α is a successor ordinal, by induction hypothesis, it follows that</p><p>and, from Lemma B.5, it follows that</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B.6. Proof of Theorem 5</head><p>By ΓP ( Ĩ) we denote the least model of a program P Ĩ . Note that the relation between ΓP and Γ P is similar to the relation between TP and T P : the ΓP operator is a function in the set of CG interpretations while Γ P is a function in the set of ECJ interpretations. Note also that the evaluation of negated literals with respect to CG and ECJ interpretations and, thus, the reducts P Ĩ and P I may be different even if Ĩ(A) = I(A) for every atom A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma B.6</head><p>Let P be a labelled logic program, Ĩ and J be respectively an CG and a ECJ interpretation such that Ĩ ≥ λ c (J). Then ΓP ( Ĩ) ≤ λ c ( Γ P (J)).</p><p>Proof . By definition ΓP ( Ĩ) and Γ P (J) are respectively the least model of the programs P Ĩ and P J . Furthermore, from Theorem 1 the least model of any program P is the least fixpoint of the T P operator, that is, ΓP ( Ĩ) = TP Ĩ ↑ ω (0) and Γ P (J) = T P J ↑ ω (0). In case that α = 0, it follows that TP Ĩ ↑ 0 (0)(H) = 0 ≤ λ c (T P J ↑ 0 (0))(H) for every atom H. We assume as induction hypothesis that TP Ĩ ↑ β (0) ≤ λ c (T P J ↑ β (0)) for all β &lt; α.</p><p>In case that α is a successor ordinal, E ≤ TP Ĩ ↑ α (0)(H) = TP Ĩ ( TP Ĩ ↑ α-1 (0))(H) if and only if there is a rule R I in P Ĩ of the form</p><p>which is the reduct of a rule R of the form (4) in P and that satisfies</p><p>) and Ĩ(C j ) = 0 for all B j and C j in body(R). Hence there is a rule in P J of the form</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Proof of Theorem 6</head><p>Proof of Theorem 6 . Let Ĩ be a causal stable model of P and I be the correspondent fixpoint of Γ 2 P with Ĩ = λ c (I). Since E is a enabled justification of A, i.e. E ≤ W P (A), then E ≤ L P (A) with L P the least fixpoint of Γ 2 P . Since, I is a fixpoint of Γ 2 P , if follows that E ≤ L P (A) ≤ I(A) and, thus, λ c (E) ≤ λ c (I(A)) = Ĩ(A). Then G def = graph(λ c (E)) is, by definition, a causal explanation of the atom A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B.8. Proof of Theorem 7</head><p>The proof of Theorem 7 will need the following definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 18</head><p>Given a program P, a WnP interpretation is a mapping I : At -→ B Lb assigning a Boolean formula to each atom. The evaluation of a negated literal not A with respect to a WnP interpretation is given by I(not A) = ¬I(A). An interpretation I is a WnP model of rule like (4) iff</p><p>The operator G P (I) maps a WnP interpretation I to the least model of the program P I .</p><p>Note that the only differences in the model evaluation between ECJ and WnP comes from the valuation of negative literals and the use of ' * ' instead of '•' for keeping track of rule application. Besides, we will also use the following facts whose proof is addressed in an appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 19</head><p>Given a positive program P, we define a direct consequence operator T P such that</p><p>for any WnP interpretation I and atom H ∈ At. Definition 20 <ref type="bibr">(From Damásio et al. 2013</ref>) Given a program P, its why-not program is given by P def = P ∪ P ′ here P ′ contains a labelled fact of the form ¬not(A) : A for each atom A ∈ At not occurring in P as a fact. The why-not provenance information under the well-founded semantics is defined as follows: W hy P (H) = [T P (H)]; W hy P (H) = [¬TU P (H)]; and W hy P (undef A) = [¬T P (H) ∧ TU Q (H)] where T P and TU P = G P (T P ) be the least and greates fixpoints of G 2 P , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma B.8</head><p>Let P be a labelled logic program over a signature At, Lb where Lb is a finite set of labels and let I and I be respectively a ECJ and a WnP interpretation such that λ p (I) ≥ I. Then, λ p (Γ P (I)) ≤ G P (I).</p><p>Proof . By definition Γ P (I) and G P (I) are the least model of the programs P I and P I , respectively. Furthermore, the least model of programs P I and P I are the least fixpoint of the T P I and T P J operators, that is, Γ P (I) = T P I ↑ ω (0) and G P (J) = T P I ↑ ω (⊥).</p><p>Note that, T X ↑ 0 (0)(H) = 0 for any program X and atom H and, thus, the statement trivially holds.</p><p>In case that α is a successor ordinal. Let u ∈ V Lb be a join irreducible causal value such that u ≤ T P I ↑ α (0)(H). Then, there is a rule in P of the form (4) such that</p><p>where u B j ≤ T P I ↑ α-1 (0)(B j ) and u C j ≤ ∼I(C j ) for each positive literal B j and each negative literal notC j in the body of rule r i .</p><p>If</p><p>1. By induction hypothesis, it follows that ρ(u B j ) ≤ T Q ↑ α-1 (0)(B j ), and 2. from J(H) = ρ(I(H)) and u C j ≤ ∼I(C j ), it follows that ρ(u C j ) ≤ ∼J(C j ).</p><p>Furthermore, no rule in the program P is labelled with not(A) nor ∼∼not(A) and, thus, r i = not(A) and r i = ∼∼not(A). Hence, ρ(u</p><p>The other way around is similar. Since</p><p>) and u C j ≤ ∼J(C j ) for each positive literal B j and each negative literal notC j in the body of rule r i . By induction hypothesis, u B j ≤ ρ(T P I ↑ α-1 (0)(B j )) for each B j with 1 ≤ j ≤ m and, since J(H) = ρ(I(H)) and u C j ≤ ∼J(C j ), it follows that u C j ≤ ρ(∼I(C j )).</p><p>Then, u ≤ ρ(T P I ↑ α (0)(H)).</p><p>In case that α is a limit ordinal T X ↑ α (0) = ∑ β &lt;α T X ↑ β (0)(H) and, thus, u ≤ T X ↑ α (0) if and only if u ≤ T X ↑ β (0)(H) with β &lt; α. By induction hypothesis, ρ(T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 8</head><p>Let P be a labelled logic program over a signature At, Lb where Lb is a finite set of labels where no rule is a labelled by not(A) nor ∼∼not(A). Let Q be the result of removing all rules labelled by ∼not(A) for some atom A. Then,</p><p>)) with X ∈ {P, Q} and, thus, the statement follows from Lemma B.11. In case that α is a limit ordinal</p><p>Finally, note that U X = Γ X (L X ) with X ∈ {P, Q} and, thus, the statement follows directly from Lemma B.11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B.10. Proof of Theorem 9</head><p>Proof of Theorem 9. Note that ρ(λ p (u)) = λ p (ρ(u)) for any causal value u ∈ V Lb . By definition W hy P (L) = λ p (W P )(L) and, thus</p><p>From Theorem 8, it follows that W P = ρ(W P ) and, thus, ρ(W hy P (L)) = λ p (W P )(L).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B.11. Proof of Theorem 2</head><p>The proof of Theorem 2 will rely on the relation between ECJ justifications and non-hypothetical WnP justifications established by Theorem 9 plus the following result from <ref type="bibr">(Damásio et al. 2013)</ref>. First, we need some notation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 21</head><p>Given a positive program P, we define a direct consequence operator TP such that</p><p>for any standard interpretation interpretation Î and atom H ∈ At.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma B.12</head><p>Let P be a labelled logic program over a signature At, Lb where Lb is a finite set of labels and let I and Î be respectively a ECJ and a standard interpretation satisfying that there is some enable justification E ≤ ∼I(H) for every atom H such that Î(H) = 0. Then, every atom H satisfies ΓP ( Î)(H) = 1 iff there is some enabled justification E ≤ Γ P (I)(H).</p><p>Proof . By definition Γ P (I) and ΓP ( Î) are the least model of the programs P I and P Î , respectively. Furthermore, the least model of programs P I and P Î are the least fixpoint of the T P and TP operators, that is, Γ P (I) = T P I ↑ ω (0) and ΓP (J) = TP Î ↑ ω (0). In case that α = 0, it follows that TP Î ↑ 0 (0)(H) for every atom H and, thus, the statement holds vacuous. We assume as induction hypothesis that for every atom H and ordinal β &lt; α such that TP Î ↑ β (0)(H) = 1, there is some enabled justification E ≤ T P I ↑ β (0)(H).</p><p>In case that α is a successor ordinal. If TP I ↑ α-1 (0)(H) = 1, then there is a rule r i ∈ P of the form (4) such that TP I ↑ α-1 (0)(B j ) = 1 and I(C j ) = 0. On the one hand, by induction hypothesis, it follows that there is some enabled justification E B j ≤ T P I ↑ α-1 (0)(B j ) and, by hypothesis, there is some enabled justification E C j ≤ ∼I(C j ). Hence,</p><p>The other way around, let E be some join irreducible justification. If E ≤ T P I ↑ α (0)(H), then there is a rule r i ∈ P of the form (4) such that</p><p>In case that α is a limit ordinal, TP Ĩ ↑ α (0) = 1 iff TP Ĩ ↑ β (0) = 1 for some β &lt; α iff there is a join irreducible enabled justification E ≤ T P I ↑ β (0)) ≤ λ p (T P I ↑ α (0).</p><p>Proof of Theorem 2. Let E ≤ W P (L) be an enabled justification of L ∈ {A, not A, undef A}. From Theorem 9, it follows that λ p (E) ≤ λ p (W P (L)) = ρ(W hy P (L)), that is, λ p (E) ≤ ρ(W hy P (L)).</p><p>Note that the minimum causal value t such that ρ(t) = ρ(W hy P (L)) is W hy P (L) ∧ A∈At not(A) and, thus, D ≤ W hy P (L) where D is defined by D = λ p (E) ∧ A∈At not(A). Furthermore, since E is an enabled justification, λ p (E) is a positive conjunction and, thus, so it is D. Hence, there is a positive conjunction D such that D ≤ W hy P (L) and, from Theorem 12, it follows that L holds with respect to the standard WFM of P.</p><p>The other way around. If L = A is an atom, then L holds with respect to the standard WFM iff lfp( Γ2 P )(L) = 1. Furthermore, Γ2 P ↑ 0 (0)(H) = Γ 2 P ↑ 0 (0) = 0 for any atom H and, thus, there is an enabled justification E ≤ ∼Γ 2 P ↑ 0 (0) = ∼0 = 1 for any atom H. Then, from Lemma B.12, for any atom H , there is an enabled justification E ≤ Γ P (Γ 2 P ↑ 0 (0))(H) iff ΓP ( Γ2 P ↑ 0 (0))(H) = 1. Applying this result again, it follows that E ≤ Γ 2 P ↑ 1 (0)(H) = Γ 2 P (Γ 2 P ↑ 0 (0))(H) if and only if Γ2</p><p>P ↑ 1 (0))(H) = Γ2 P ( Γ2 P ↑ 0 (0))(H) = 1. Inductively applying this reasoning it follows that Γ2 P ↑ ∞ (0)(H) = 1 iff there is an enabled justification E ≤ Γ 2 P ↑ ∞ (0)(H) which, by Knaster-Tarski theorem are the least fixpoints respectively of the ΓP and Γ P operators.</p><p>Similarly, if L = not A, then L holds with respect to the standard WFM if and only if gfp( Γ2 P )(L) = ΓP (lfp( Γ2 P ))(L) = 0 iff there is not any an enabled justification E ≤ Γ P (lfp(Γ 2 P ))(L) = gfp(Γ 2 P )(L) iff there is an enabled justification E ≤ W P (L) = ∼gfp(Γ 2 P )(L). Finally, if L = undef A, then L holds with respect to the standard WFM iff lfp( Γ2 P )(L) = 0 and gfp( Γ2 P )(L) = 1 if and only if there is not any enabled justification E ≤ W P (L) and there is not</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Distributive lattices</title>
		<author>
			<persName><forename type="first">R</forename><surname>Balbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dwinger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>Melinda Inn</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Causal graph justifications of logic programs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cabalar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fandinno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Practice of Logic Programming TPLP</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="603" to="618" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A complexity assessment for queries involving sufficient and necessary causes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cabalar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fandinno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Logics in Artificial Intelligence -14th European Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Proceedings</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Fermé</surname></persName>
		</editor>
		<editor>
			<persName><surname>Leite</surname></persName>
		</editor>
		<meeting><address><addrLine>Funchal, Madeira, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-09-24">2014. 2014. September 24-26, 2014</date>
			<biblScope unit="volume">8761</biblScope>
			<biblScope unit="page" from="297" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Justifications for logic programming</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Ásio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Analyti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Logic Programming and Nonmonotonic Reasoning</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Proceedings</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Cabalar</surname></persName>
		</editor>
		<editor>
			<persName><surname>Son</surname></persName>
		</editor>
		<meeting><address><addrLine>Corunna, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013-09-15">2013. 2013. September 15-19, 2013</date>
			<biblScope unit="volume">8148</biblScope>
			<biblScope unit="page" from="530" to="542" />
		</imprint>
	</monogr>
	<note>Twelfth International Conference</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Justification semantics: A unifiying framework for the semantics of logic programs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Denecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Schreye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Logic Programming and Non-monotonic Reasoning, 2nd International Workshop, LPNMR 1993</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1993-06">1993. June 1993</date>
			<biblScope unit="page" from="365" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A causal semantics for logic programming</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fandinno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>University of Corunna</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Towards deriving conclusions from cause-effect relations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fandinno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>In ASPOCP</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new perspective on stable models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ferraris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lifschitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Veloso</surname></persName>
		</editor>
		<meeting><address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-01-06">2007. January 6-12, 2007</date>
			<biblScope unit="page" from="372" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A meta-programming technique for debugging answer-set programs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gebser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ührer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tompits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence, AAAI 2008</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</editor>
		<meeting>the Twenty-Third AAAI Conference on Artificial Intelligence, AAAI 2008<address><addrLine>Chicago, Illinois, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2008-07-13">2008. July 13-17, 2008</date>
			<biblScope unit="page" from="448" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The stable model semantics for logic programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gelfond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lifschitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Logic Programming, Proceedings of the Fifth International Conference and Symposium</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Kowalski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bowen</surname></persName>
		</editor>
		<meeting><address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1988-08-15">1988. August 15-19</date>
			<biblScope unit="page" from="1070" to="1080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Causation and the price of transitivity</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Philosophy</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="198" to="222" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Two concepts of causation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hall</surname></persName>
		</author>
		<editor>Causation and counterfactuals, J. Collins, N. Hall, and L. A. Paul</editor>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="225" to="276" />
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Structural equations and causation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Studies</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page" from="109" to="136" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Defaults and normality in causal structures</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Halpern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Principles of Knowledge Representation and Reasoning: Proceedings of the Eleventh International Conference</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Brewka</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Lang</surname></persName>
		</editor>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2008-09-16">2008. 2008. September 16-19, 2008</date>
			<biblScope unit="page" from="198" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Appropriate causal models and stability of causation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Halpern</surname></persName>
			<affiliation>
				<orgName type="collaboration">KR 2014</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">Principles of Knowledge Representation and Reasoning: Proceedings of the Fourteenth International Conference</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Baral</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Giacomo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Eiter</surname></persName>
		</editor>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2014-07-20">2014. July 20-24, 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A modification of the halpern-pearl definition of causality</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Halpern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence, IJCAI 2015</title>
		<editor>
			<persName><forename type="first">Yang</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Wooldridge</surname></persName>
		</editor>
		<meeting>the Twenty-Fourth International Joint Conference on Artificial Intelligence, IJCAI 2015<address><addrLine>Buenos Aires, Argentina</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015-07-25">2015. July 25-31, 2015</date>
			<biblScope unit="page" from="3022" to="3033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Actual causation and the art of modeling</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hitchcock</surname></persName>
		</author>
		<idno>CoRR abs/1106.2652</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Causes and explanations: A structural-model approach. part I: Causes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference in Uncertainty in Artificial Intelligence</title>
		<meeting>the Seventeenth Conference in Uncertainty in Artificial Intelligence<address><addrLine>University of Washington, Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="0202">2001. 2001. August 2-5, 194-202</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Causes and explanations: A structural-model approach. part I: Causes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal for Philosophy of Science</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="843" to="887" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cause and norm</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hitchcock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Knobe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Philosophy</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="587" to="612" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">An enquiry concerning human understanding</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hume</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1748">1748. 1958</date>
			<publisher>Open Court Press</publisher>
			<pubPlace>LaSalle, IL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Causation as influence</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Philosophy</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Embracing causality in specifying the indirect effects of actions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Fourteenth International Joint Conference on Artificial Intelligence<address><addrLine>Montréal Québec, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1995-08-20">1995. August 20-25 1995</date>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="1985" to="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Stable models and an alternative logic programming paradigm</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">W</forename><surname>Marek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Truszczy Ńki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Logic Programming Paradigm</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Apt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><forename type="middle">W</forename><surname>Marek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Truszczyński</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Warren</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="375" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Causation, counterfactuals, and the third factor</title>
		<author>
			<persName><forename type="first">T</forename><surname>Maudlin</surname></persName>
		</author>
		<editor>Causation and Counterfactuals, J. Collins, E. J. Hall, and L. A. Paul</editor>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Causal theories of action and change</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mccain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth National Conference on Artificial Intelligence and Ninth Innovative Applications of Artificial Intelligence Conference, AAAI 97, IAAI 97</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Kuipers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Webber</surname></persName>
		</editor>
		<meeting>the Fourteenth National Conference on Artificial Intelligence and Ninth Innovative Applications of Artificial Intelligence Conference, AAAI 97, IAAI 97<address><addrLine>Providence, Rhode Island</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press / The MIT Press</publisher>
			<date type="published" when="1997-07-27">1997. July 27-31, 1997</date>
			<biblScope unit="page" from="460" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Logic programs with stable model semantics as a constraint programming paradigm</title>
		<author>
			<persName><forename type="first">I</forename><surname>Niemel Ä</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematics and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="241" to="273" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Catching the ouroboros: On debugging non-ground answer-set programs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Oetsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ührer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tompits</surname></persName>
		</author>
		<idno>CoRR abs/1007.4986</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A new logical characterisation of stable models and answer sets</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pearce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Non-Monotonic Extensions of Logic Programming</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Papers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Dix</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><surname>Przymusinski</surname></persName>
		</editor>
		<meeting><address><addrLine>Bad Honnef, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996-09-05">1996. 1996. September 5-6, 1996</date>
			<biblScope unit="volume">1216</biblScope>
			<biblScope unit="page" from="57" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Online justification for tabled logic programs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pemmasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Causality: models, reasoning, and inference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Proceedings</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Kameyama</surname></persName>
		</editor>
		<editor>
			<persName><surname>Stuckey</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY, USA; Nara, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000. 2004. April 7-9, 2004</date>
			<biblScope unit="volume">2998</biblScope>
			<biblScope unit="page" from="24" to="38" />
		</imprint>
	</monogr>
	<note>Seventh International Symposium, FLOPS 2004</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Justifications for logic programs under answer set semantics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pontelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>El-Khatib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Practice of Logic Programming TPLP</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="56" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Aba-based answer set justification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Toni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Practice of Logic Programming TPLP</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="4" to="5" />
			<date type="published" when="2013">2013</date>
			<publisher>Online-Supplement</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Generating explanation trees even for negations in deductive database systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Workshop on Logic Programming Environments (LPE 1993)</title>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Charlier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">Ü</forename><surname>Yalc ¸inalp</surname></persName>
		</editor>
		<meeting>the Fifth Workshop on Logic Programming Environments (LPE 1993)<address><addrLine>Vancouver, British Columbia, Canada; Campus de Beaulieu, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-10-29">1993. October 29-30, 1993</date>
			<biblScope unit="page" from="8" to="13" />
		</imprint>
	</monogr>
	<note>conjunction with ILPS 1993</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Ramification and causality</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thielscher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="317" to="364" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The alternating fixpoint of logic programs with negation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems</title>
		<meeting>the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems<address><addrLine>Philadelphia, Pennsylvania, USA, A. Silberschatz</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1989-03-29">1989. March 29-31, 1989</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
