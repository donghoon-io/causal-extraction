<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Causal-DFQ: Causality Guided Data-free Network Quantization</title>
				<funder>
					<orgName type="full">Cisco</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-09-24">24 Sep 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuzhang</forename><surname>Shang</surname></persName>
							<email>yshang4@hawk.iit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Illinois Institute of Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Cisco Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bingxin</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Illinois Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gaowen</forename><surname>Liu</surname></persName>
							<email>gaoliu@cisco.com</email>
							<affiliation key="aff1">
								<orgName type="department">Cisco Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ramana</forename><surname>Rao Kompella</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Cisco Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Illinois Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Causal-DFQ: Causality Guided Data-free Network Quantization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-09-24">24 Sep 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2309.13682v1[cs.CV]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Model quantization, which aims to compress deep neural networks and accelerate inference speed, has greatly facilitated the development of cumbersome models on mobile and edge devices. There is a common assumption in quantization methods from prior works that training data is available. In practice, however, this assumption cannot always be fulfilled due to reasons of privacy and security, rendering these methods inapplicable in real-life situations. Thus, data-free network quantization has recently received significant attention in neural network compression. Causal reasoning provides an intuitive way to model causal relationships to eliminate data-driven correlations, making causality an essential component of analyzing datafree problems. However, causal formulations of data-free quantization are inadequate in the literature. To bridge this gap, we construct a causal graph to model the data generation and discrepancy reduction between the pre-trained and quantized models. Inspired by the causal understanding, we propose the Causality-guided Data-free Network Quantization method, Causal-DFQ, to eliminate the reliance on data via approaching an equilibrium of causality-driven intervened distributions. Specifically, we design a contentstyle-decoupled generator, synthesizing images conditioned on the relevant and irrelevant factors; then we propose a discrepancy reduction loss to align the intervened distributions of the pre-trained and quantized models. It is worth noting that our work is the first attempt towards introducing causality to data-free quantization problem. Extensive experiments demonstrate the efficacy of Causal-DFQ. The code is available at Causal-DFQ.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>There have been significant advances in deep learning models in the fields of computer vision <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15]</ref> and natural language processing <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b45">47]</ref>. To accommodate the increasing demand for equipping cumbersome models on resource-constrained edge devices, researchers have pro-posed several network quantization methods <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b58">60]</ref>, in which high-precision parameters are converted into lowprecision ones. To mitigate the performance degradation induced by model quantization, fine-tuning approaches are extensively studied to optimize quantized models on the full training datasets <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b42">44,</ref><ref type="bibr" target="#b49">51]</ref>. However, original training data is sometimes inaccessible in real-world situations due to the privacy and security concerns. A patient's electronic health record, for instance, is typically inaccessible because the information contained is private. Hence, the fine-tuning methods requiring training data are no longer applicable in such real-life scenarios.</p><p>To address this issue, researchers have proposed datafree quantization to quantize models without requiring access to real data <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b43">45,</ref><ref type="bibr" target="#b51">53,</ref><ref type="bibr" target="#b55">57]</ref>. For example, Ze-roQ <ref type="bibr" target="#b1">[2]</ref> is proposed to generate 'optimal' fake data, which learns an input data distribution to best match the batch normalization statistics of the FP32 model. Nevertheless, most data-free quantization methods attempt to reconstruct the original data from the pre-trained model utilizing prior statistical distribution information of the underlying data, such as BNS <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b51">53,</ref><ref type="bibr" target="#b52">54]</ref>, Dirichlet distribution <ref type="bibr" target="#b29">[30]</ref> and category information <ref type="bibr" target="#b2">[3]</ref>. However, those methods ignore a powerful tool in the human cognition, i.e., causal reasoning, which commonly aids humans in learning without relying upon data collection. Human cognitive systems are immune to the data deficiency because humans are more sensitive to causal relations than data-driven statistical associations <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b56">58]</ref>. Using causal language, causal reasoning can extract causal relationship from the pre-trained models and ignore irrelevant factors by interventions <ref type="bibr" target="#b34">[36]</ref>.</p><p>There are two significant challenges that need to be overcome before causality can be introduced to eliminate the reliance on data during the quantized model training. First, constructing an informative causal graph is the fundamental premise for causal reasoning <ref type="bibr">[32,</ref><ref type="bibr" target="#b34">36]</ref>, but how causal graphs should be constructed in a data-free situation is still inadequate in the literature. Second, using causal language to formalize data generation and network alignment is the key to connecting causality with data-free quantization, but it also remains unsolved. These two challenges are the fundamental obstacles that prevent us from employing causality in data-free quantization.</p><p>To address these challenges, we construct a causal graph to model the data-free quantization process, including datageneration and discrepancy reduction mechanisms, where the irrelevant factors in the pre-trained models are taken into consideration. Based on the causal graph, we propose a novel Causality-Guided Data Free Network Quantization method, Causal-DFQ, to remove the reliance on data during quantized model training. Specifically, we design a content-style-decoupled generator, synthesizing images conditioned on the relevant and irrelevant factors (content and style variables). Then we propose a discrepancy reduction loss to align the intervened distributions of the outputs from pre-trained and quantized models.</p><p>Overall, the contributions of this paper are four-fold: (i) We provide a causal perspective on data-free quantization, which is the first attempt towards using causality to facilitate data-free network compression; (ii) To leverage causality to facilitate data-free quantization, we construct a causal graph to model data generation process and discrepancy reduction process in data-free quantization mechanism; (iii) We propose a novel quantization method called Causality Guided Data-free Network Quantization, Causal-DFQ, in which we generate fake images conditioned on style and content variables, and align style-intervened distributions of pre-trained and quantized models. (iv) Extensive experiments demonstrate that the proposed method can significantly improve the performance of data-free low-bit models. Importantly, it is the first method where data-free finetuned models outperform the models fine-tuned with data on the ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Data-free Network Compression. Although model compression has become a hot topic recently, compressing model without training data still is a challenge. As pioneers, <ref type="bibr" target="#b44">[46]</ref> initially devise a channel pruning method without original training data. And then a large number of data-free (DF) or zero-shot compression methods were proposed, e.g. DF quantization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b51">53,</ref><ref type="bibr" target="#b55">57]</ref>, DF factorization <ref type="bibr" target="#b28">[29]</ref> and DF knowledge distillation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b26">27]</ref>. Especially for DF quantization, recent work <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b51">53,</ref><ref type="bibr" target="#b55">57]</ref> go further to data-free quantization, which requires neither training nor validation data for quantization. Most of the data-free KD methods attempt to reconstruct the original data from the pre-trained model utilizing prior information about the underlying data statistical distribution, such as BNS <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b51">53,</ref><ref type="bibr" target="#b52">54]</ref>, Dirichlet distribution <ref type="bibr" target="#b29">[30]</ref> and category information <ref type="bibr" target="#b2">[3]</ref>. However, all existing methods overlook causal reasoning, a powerful tool for humans to cognize even in situations where data are inaccessible. Causal Reasoning. One core purpose of causal reasoning is to pursue the causal effect of interventions, contributing to achieving the desired objective. Recent work shows the benefits of introducing causality into machine learning from various aspects <ref type="bibr" target="#b38">[40]</ref>. After the deep connections of causal systems and the concept of exogeneity having been successfully implemented in social science, such as in Economics and Genetics [32], Sch√∂lkopf et al. <ref type="bibr" target="#b37">[39]</ref> originally develop a technique, named independence mechanisms via introducing causal mechanisms to independently separate the exogenous and endogenous variables w.r.t. specific tasks in the field of machine learning <ref type="bibr" target="#b38">[40]</ref>.</p><p>However, thanks to the unique nature of data-free quantization, our data generation process is steerable, unlike previous works. Thus, we can design a content-styledecoupled generator where both content and style variables are accessible in the causal graph. Then we can easily implement do-calculus <ref type="bibr" target="#b31">[33]</ref> for causal reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>In this section, we elaborate on the methodology of Causality-guided Data-Free Quantization, named Causal-DFQ. Firstly, we review the idea of network quantization and the general framework of data-free compression. Secondly, we construct the causal graph model for the datafree network compression, which is adopted as a theoretical tool to bridge causality with data-free quantization. Thirdly, based on the causal graph, we observe that there is a unique property of data-free compression, where the data variable is completely accessible; thus we design a generator to synthesize images conditioned on style and content images for training quantized models. Next, we focus on the optimization formulation that converts the causal task into an optimizable problem. Finally, we discuss the potential insights for the Causal-DFQ. Note that we only elaborate on the key derivations in this section due to the space limitation. Detailed discussions, technical theorems, and implementation details in Codes can be found in the supplemental materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminary</head><p>Here, we revisit the basic ideas of network quantization and data-free network compression. Network Quantization. Network quantization is a popular technique for compressing neural networks. The quantization function is the key to train a neural network with low-precision weights and activations. The most common quantization function is called uniform quantization function, which is pioneerly proposed in <ref type="bibr" target="#b58">[60]</ref>. The uniform quantization function q(‚Ä¢) for k-bit quantization is defined as follows:</p><formula xml:id="formula_0">q(v) = round(L ‚Ä¢ (v -Z)),<label>(1)</label></formula><p>where v denotes a scalar value (full-precision, float32), L is the scaling factor, and Z is the zero point in float32. Ac-cording to whether the parameter Z is zero, uniform quantization can be categorized into symmetric quantization and asymmetric quantization. In our work, we use symmetric quantization, i.e., Z = 0, and then S is written as follows:</p><formula xml:id="formula_1">S = 2 k-1 -1 max(|x f |) ,<label>(2)</label></formula><p>where x f is the full-precision numbers.</p><p>Data-Free Compression. The key of most network compression methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b19">20]</ref> including quantization is to reduce the discrepancy D between the pre-trained fullprecision model f (‚Ä¢; Œ∏ P ) and the quantized model with lowprecision weights f (‚Ä¢; Œ∏ Q ) through optimizing Œ∏ Q . The idea of discrepancy reduction can be formalized as follows:</p><formula xml:id="formula_2">f (‚Ä¢; Œ∏ Q ) ‚ãÜ = min Œ∏ Q D(f (‚Ä¢; Œ∏ P ), f (‚Ä¢; Œ∏ Q )).<label>(3)</label></formula><p>This discrepancy reduction module can be considered as a knowledge distillation mechanism for aligning model f (‚Ä¢; Œ∏ P ) and f (‚Ä¢; Œ∏ Q ). Consequently, the integral framework of the data-free quantization can be considered as the incorporation of a generator and knowledge distillation <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b40">42]</ref>, and the core idea is to reconstruct some samples from full-precision models to fine-tune quantized models <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>. Therefore, to achieve the goal of data-free compression via causality, we modify the existing framework from the perspectives of generator and discrepancy reduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Causal Graph of Data-Free Compression</head><p>Humans can perform causal reasoning, an essential ability that makes humans learn differently from machine learning algorithms. The superiority of causal reasoning endows humans with the ability to identify causal relationships. This allows them to ignore irrelevant factors that are not causally related to the targeted task and removes the reliance on collecting data for learning <ref type="bibr" target="#b34">[36,</ref><ref type="bibr" target="#b38">40,</ref><ref type="bibr" target="#b54">56,</ref><ref type="bibr" target="#b56">58]</ref>. Contrary to this, neural networks are normally trained based on data-driven correlation. In other words, neural networks do not have the ability to distinguish causal relationships. In the absence of this ability, irrelevant factors in data are overfitted, further resulting in the overreliance of networks on data. For instance, in a car recognition case, road background is a data-driven irrelevant factor yet cannot reflect the causality w.r.t. the targeted task, i.e., human can recognize a car with causal reasoning even if it is not on the road. Moreover, data even are unavailable in our data-free case. Therefore, we desire to incorporate causal reasoning to remove the reliance on data, i.e., the pre-trained model guides the training of the quantized model via causality in a datafree manner. Before performing causal reasoning to guide the training in a data-free manner, we need to construct a causal graph since causal graphs are the key to formulating causal reasoning <ref type="bibr" target="#b34">[36,</ref><ref type="bibr" target="#b56">58]</ref>. In the context of data-free quantization, we desire a causal graph by which the distributions of the outputs of pre-trained and quantized models can be included. Besides, the graph is expected to reflect the impact of irrelevant factors on these two output distributions, and then we are able to align the distributions. Specifically, we investigate the difference in irrelevant factors between these two distributions and enforce the quantized models to focus on the relevant factors. Consequently, this encourages the quantized model to learn via causal reasoning.</p><formula xml:id="formula_3">C S Y ÔÄ• X ÔÄ• P Y Q Y ùúÉùúÉ ùëÉùëÉ ùúÉùúÉ ùê∫ùê∫ ùúÉùúÉ ùëÑùëÑ C S Y ÔÄ• X ÔÄ• Y ùúÉùúÉ Figure 1. Left:</formula><p>There are two general approaches to building a causal graph of the targeted learning mechanism. One approach is to use causal structure learning to infer causal graphs <ref type="bibr">[32,</ref><ref type="bibr" target="#b34">36,</ref><ref type="bibr" target="#b38">40]</ref>, but it is challenging to apply this approach to high-dimensional data. Using external knowledge to construct causal graphs is another approach <ref type="bibr" target="#b38">[40,</ref><ref type="bibr" target="#b46">48,</ref><ref type="bibr" target="#b56">58]</ref>. As automatically learning a precise causal graph is out of scope for this work, external human knowledge of the data generation process is employed to construct the causal graph. Here, we aim to construct a causal graph to model the data-free quantization process, including data-generation and discrepancy reduction mechanisms, where the irrelevant factors in the pre-trained models are also considered.</p><p>Specifically, we construct a causal graph G to formalize the general idea of data-free quantization process including an image generation mechanism and a discrepancy reduction mechanism to allow the pre-trained model f (‚Ä¢; Œ∏ P ) to guide the training of the quantized model f (‚Ä¢; Œ∏ Q ). In the previous studies <ref type="bibr" target="#b34">[36,</ref><ref type="bibr" target="#b38">40,</ref><ref type="bibr" target="#b56">58]</ref>, even though there is a number of different causes of natural data, researchers ideally and effectively divide all the causes into two categories for simplicity. We follow the existing work, and group contentrelated causes into one category, called content variable C. The rest causes, i.e., irrelevant factors, are grouped into another category, called style variable S, which is contentindependent, i.e., S ‚ä• ‚ä• C. This implies that C ‚Üí X ‚Üê S and C ‚Üí ·ª∏ . Then the generated data are fed into the pretrained model and quantized model. Under the supervision of the output of pre-trained model Y P and the generated label ·ª∏ , we obtain the output of quantized model Y Q . The causal graph is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Based on the causal graph, we first use a structural causal model <ref type="bibr" target="#b32">[34]</ref> to represent the data generating mechanism:</p><formula xml:id="formula_4">X := M(S, C, Œ∏ G ),<label>(4)</label></formula><p>where Œ∏ G is the parameters of generator.</p><p>After formulating the process of obtaining the generated data, we expect to define valid interventions and the corresponding intervention distributions <ref type="bibr">[32,</ref><ref type="bibr" target="#b38">40]</ref>. Defining valid interventions is equivalent to determining which variables or mechanisms in the causal graph can be intervened. The common practice is to utilize the independence mechanism <ref type="bibr" target="#b37">[39]</ref> to construct probabilistic relations in causal reasoning and discover the irrelevant factors as the intervened variable. This practice has been proven to be an effective way to realize causality reasoning by previous work <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b37">39]</ref>, in which the conditional (intervened) distribution does not change under the interventions on irrelevant variable (i.e., S). Theoretically, for an image generation mechanism (ideally even collected natural images are included), P ( ·ª∏ | C) is invariant to S. Therefore, we claim C as a representation of invariant content of data w.r.t. the ·ª∏ under interventions I on style domain S as shown Fig. <ref type="figure" target="#fig_0">1</ref>(left), and the relationship can be mathematically denoted as: <ref type="bibr" target="#b4">(5)</ref> where i l and i k form a pair of interventions in the domain of interventions I, and P do(S=i l ) stands for the distribution under intervention i l on S [32]. In the data-free compression literature, we also desire to access the intervened distributions of the outputs of the pre-trained model and quantized model and then derive a computationally reachable equilibrium between them. Because our data generation process is steerable, unlike the fixed datasets collected from natural distributions, we design a content-style-decoupled generator where both content and style variables are accessible in the causal graph.</p><formula xml:id="formula_5">P do(S=i l ) ( ·ª∏ | C) = P do(S=i k ) ( ·ª∏ | C) ‚àÄi l , i k ‚àà I,</formula><p>Therefore, based on the analysis of Eq.4, 5 and the above-mentioned nature of the data-free mechanism, the desirable equilibrium in data-free quantization can be formulated as follows:</p><formula xml:id="formula_6">‚àÄl, k ‚àà {1, 2, ‚Ä¢ ‚Ä¢ ‚Ä¢ , M }, P do(S=i l ) (Y P | f ( X; Œ∏ Q )) = P do(S=i k ) (Y P | f ( X; Œ∏ Q )),<label>(6)</label></formula><p>which can be reformed as follows: Targeted Causal Equilibrium: where M is the number of interventions in style domain S, f (‚Ä¢; Œ∏ P ) and f (‚Ä¢; Œ∏ Q ) are the pre-trained and quantized model with parameters Œ∏ P and Œ∏ Q , respectively. Straightforwardly, we desire the distribution, P (f ( X; Œ∏ P ) | f ( X; Œ∏ Q )) to be invariant over style variable change.</p><formula xml:id="formula_7">P do(S=i l ) (f ( X; Œ∏ P ) | f ( X; Œ∏ Q )) =P do(S=i k ) (f ( X; Œ∏ P ) | f ( X; Œ∏ Q )),<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Content-Style-Decoupled Generator</head><p>Here, we present the design of the content-styledecoupled generator, rendering accessibility to the content and style variables. Structural Equation Modeling (SEM) <ref type="bibr" target="#b32">[34,</ref><ref type="bibr" target="#b48">50]</ref> is a primary causal model, which is originally proposed to apply explicit causal interpretations to regression equations based on direct and indirect effects of observed variables in the fields of Genetics and Economics <ref type="bibr">[32]</ref>. SEM has two main components: the structural model showing potential causal dependencies between endogenous and exogenous variables and the measurement model showing the relations between latent variables and their indicators. SEM aims to obtain an informative representation of some observable output.</p><p>Inspired by the concepts of SEM, we naturally introduce the above two variables into the data-free scenarios and expect to enforce the outputs of quantized models exclusively correlated with the content variable in the view of causal reasoning. To realize the goal, we generalize three fundamental assumptions of SEM into the literature on datafree compression <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b31">33,</ref><ref type="bibr" target="#b37">39]</ref>. The generalized assumptions can be interpreted as follows: presented in Eq. 16, we design an image generator that can synthesize fake data conditioned on independent style and content variables. We call this generator a content-styledecoupled generator. Specifically, we assign every to-begenerated sample a content label and a style noise; then we feed this pair of content and style into the generator network to generate the sample. In this way, for each sample of the following discrepancy reduction process, we can access its style variable and perform interventions by keeping its content labels consistent and adjusting its style noise.</p><p>Here, we give a straightforward explanation of how our generator produces fake images conditioned on content and style variables (Algorithm 1). First, the integer function, content = randint() (function of randomly generating non-nagetive integer) generates the pseudo label based on the number of classes of the real dataset, which can be interpreted as a content variable for each generated image. Note that using the number of classes does not imply information leakage and is still within our data-free scenarios, as we can acquire the number of classes via accessing the pretrained model's classification head rather than accessing the labels. And the Gaussian noise generation function, style = randn() can assign a Gaussian noise to style variable. By pairing the content and style and then feeding them to a generator, we can synthesize fake data conditioned on the content and style. In this way, we can directly manipulate the style variable. More details can be found in the codes in the Supplemental Materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Style-Intervened Discrepancy Reduction</head><p>After accessing the style variable in the data-free quantization mechanism, the only remaining problem is to achieve the equilibrium of the intervened distributions as derived in Eq. 16. We maintain the invariance under interventions via a regularization term to address this. The optimization prob-lem is formalized as follows:</p><formula xml:id="formula_8">min E X‚ààD E {i lk ,iqt} L i lk (f (X; Œ∏ P ), f (X; Œ∏ Q )) +L iqt (f (X; Œ∏ P ), f (X; Œ∏ Q )) . s.t. KL P do(S=i lk ) (f (X; Œ∏ P ) | f (X; Œ∏ Q )), P do(S=iqt) (f (X; Œ∏ P ) | f (X; Œ∏ Q )) ‚â§ œÑ<label>(8)</label></formula><p>where i lk ‚âú i l √ó i k ‚àº I √ó I stands for a pair of interventions, L is the vanilla alignment loss, and KL(‚Ä¢, ‚Ä¢) is the KL-divergence. œÑ is a small threshold to adjust the similarity between two distributions. Any distance measure on distributions can be used in place of the KL divergence such as cross-entropy, since we only expect the intervened distributions P do(S=i lk ) (f (X; Œ∏ P ) | f (X; Œ∏ Q )) and P do(S=iqt) (f (X; Œ∏ P ) | f (X; Œ∏ Q )) to be similar. In practice, we define the output representations of pre-trained and quantized models (i.e., f (X; Œ∏ P ) and f (X; Œ∏ Q )) at the penultimate layer.</p><p>How to approach the conditional distribution under interventions P do(S=i lk ) (f ( X; Œ∏ P ) | f ( X; Œ∏ Q )) becomes the key problem. To estimate the distribution, we introduce the noise-contrastive estimation (NCE) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17]</ref>. Specifically, we take pairs of points (x i , x j ) to compute similarity scores and use pairs of intervention i lk to perform a style intervention. Given a batch of samples {x i } , i ‚àà {1, 2, ‚Ä¢ ‚Ä¢ ‚Ä¢ , N }, the conditional probability of the pair can be estimated as follows:</p><formula xml:id="formula_9">P do(S=i lk ) (f (X; Œ∏ P ) | f (X; Œ∏ Q )) ‚àù h(f (x S=i l j ; Œ∏ P ), f (x S=i k i ; Œ∏ Q )),<label>(9)</label></formula><p>in which h is the function to measure the similarity between the representations of the pre-trained model f (x S=i l j ; Œ∏ P ) and the one from quantized model f (x S=i k i ; Œ∏ Q ). Using this function to estimate the conditional distribution is originally proposed in NCE <ref type="bibr" target="#b13">[14]</ref>, also called the critic in contrastive learning <ref type="bibr" target="#b16">[17]</ref>. It is defined as below:</p><formula xml:id="formula_10">h(x, y) = exp( &lt; g(x), g(y) &gt; Œ≤ ), (<label>10</label></formula><formula xml:id="formula_11">)</formula><p>where Œ≤ is the temperature to adjust degree of concentration, and g is a fully-connected network <ref type="bibr" target="#b13">[14]</ref>. Combining all the equations, we obtain the optimizable objective function as follows:</p><formula xml:id="formula_12">L Causal-DFQ = E X‚ààD E {i lk ,iqt} L i lk (f (X; Œ∏ P ), f (X; Œ∏ Q )) + L iqt (f (X; Œ∏ P ), f (X; Œ∏ Q )) + i lk iqt KL P do(S=i lk ) (f (X; Œ∏ P ) | f (X; Œ∏ Q )), P do(S=iqt) (f (X; Œ∏ P ) | f (X; Œ∏ Q )) .</formula><p>(11) Concretely, the probability of a pair of samples in the conditional distribution P do(S=i lk ) (f (X; Œ∏ P ) | f (X; Œ∏ Q )) can be approximated by the critic function as follows <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b27">28]</ref>:</p><formula xml:id="formula_13">P do(S=i lk ) (f (x j ; Œ∏ P ) | f (x i ; Œ∏ Q )) = h(f (x S=i l j ; Œ∏ P ), f (x S=i k i ; Œ∏ Q )) i lk h(f (x S=i l j ; Œ∏ P ), f (x S=i k i ; Œ∏ Q )) .<label>(12)</label></formula><p>Overall Loss Function. Taking into account all the above discussions, the Causal-DFQ loss can be calculated with differentiability and the overall loss function can be written as follows:</p><formula xml:id="formula_14">L overall = L vanilla + Œª ‚Ä¢ L Causal-DFQ ,<label>(13)</label></formula><p>where L vanilla is the objective from the vanilla data-free quantization loss, and Œª is the parameter to balance the targeted task and the distillation task. In practice, we adopt and modify the codebase of GDFQ <ref type="bibr" target="#b51">[53]</ref> to achieve our causality-based data-free quantization baseline, thus more details about the L vanilla can be found in GDFQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Discussions on Causal-DFQ</head><p>Besides the derivation originated from the perspective of causality, we would like to give a straight-forward explanation of Causal-DFQ. Combining Eq.11 and Eq.12, we can observe that our method minimize the distributional distance between P do(S=i lk ) (f (x j ; Œ∏ P ) | f (x i ; Œ∏ Q )) and P do(S=iqt) (f (x j ; Œ∏ P ) | f (x i ; Œ∏ Q )). Specifically, with the critic function to estimate the conditional distribution, P do(S=i lk ) (f (x j ; Œ∏ P ) | f (x i ; Œ∏ Q ) acts as the similarity matrix between generated images with same content, i.e., a series of differences among samples with the same content and different styles. Finally, the similarity matrices of pre-trained and quantized models are aligned with KLdivergence as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. Difference with RELIC <ref type="bibr" target="#b27">[28]</ref>. From the perspective of causality, the most related work is RELIC <ref type="bibr" target="#b27">[28]</ref> which acts as a regularizer in self-supervised learning via the independence mechanisms <ref type="bibr" target="#b34">[36]</ref> to encourage networks to be invariant to different augmentations of the same instance. This self-supervised learning method also constructs a causal graph to model the data generation process. However, the focus of this work is on the content invariant property using data augmentations to stimulate inaccessible interventions <ref type="bibr" target="#b56">[58]</ref>, which varies from our data-free work, Causal-DFQ. Specifically, our work is different from RELIC (and most of the previous causality-guided computer vision models, such as <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b50">52]</ref>) for two significant reasons. Firstly, there is a unique nature in data-free scenarios where both the content and style variable are accessible, and thus we do not need to stimulate the interventions on the style domain. Secondly, the derived equilibrium is different where we focus on the distributions of outputs of pre-trained and quantized models. Detailed differences between our data-free approach and previous works are discussed in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>Datasets. We validate the Causal-DFQ on four wellknown data sets including CIFAR-10, CIFAR-100 <ref type="bibr" target="#b22">[23]</ref>, Im-ageNet <ref type="bibr" target="#b6">[7]</ref> for recognition, and PASCAL VOC 2012 <ref type="bibr" target="#b7">[8]</ref> for detection. More details about the datasets are in Supplemental Materials. Baselines. To evaluate the effectiveness and advantages of our proposed method, we compared it with both data-free fine-tuning methods and post-training quantization methods. The baselines are presented as follows. FP32: the full-precision pre-trained model. FT: we use real training data instead of fake data to fine-tune the quantized model by minimizing L2. ZeroQ <ref type="bibr" target="#b1">[2]</ref>: a data-free post-training quantization method. DFQ <ref type="bibr" target="#b28">[29]</ref>: a post-training quantization method uses a weight equalization scheme to remove outliers in both weights and activations. ZAQ <ref type="bibr" target="#b25">[26]</ref>: It is a fine-tuning method by optimizing the quantized models in an adversarial learning way. DSG <ref type="bibr" target="#b55">[57]</ref>: It is a fine-tuning method where the diversity of generated data is enhanced. GDFQ <ref type="bibr" target="#b51">[53]</ref>: It is also a fine-tuning method for recovering fake data via a conditional generator. SQuant <ref type="bibr" target="#b12">[13]</ref> and In-traQ <ref type="bibr" target="#b57">[59]</ref> are recently SoTA. Note that our code is modified from the code of GDFQ. Implementation Details. On CIFAR, we optimize the generator and quantized model using Adam <ref type="bibr" target="#b21">[22]</ref> and SGD with Nesterov <ref type="bibr" target="#b30">[31]</ref> respectively, where the momentum term and weight decay in Nesterov are set to 0.9 and 1√ó10 -4 . Moreover, the learning rates of quantized models and generators are initialized to 1√ó10 -4 and 1√ó10 -3 respectively. Both of them are decayed by 0.1 for every 100 epochs. In addition, we train the generator and quantized model for 400 epochs with 200 iterations per epoch. On ImageNet, we set the initial learning rate of the quantized model as 1 √ó 10 -6 . Other training settings are the same as those on CIFAR. More details can be found in Supplemental Materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison to SoTA</head><p>Image Classification. We quantize both weights and activations to 6-bit, and report the comparison results in Table 1. We also quantize them to 4-bit, and report the results in Table <ref type="table" target="#tab_2">2</ref>. In all three classification datasets, our method Causal-DFQ outperforms other existing state-ofthe-art methods with various network architectures. In particular, when the number of categories increases in CIFAR-100, our method suffers a much smaller accuracy degradation than other methods. The main reason is that our method based on causality gains more prior knowledge from the full-precision model. These results demonstrate the superiority of our method. Especially for the large-scale dataset, ImageNet, existing data-free quantization methods suffer from severe performance degradation. However, our generated images contain style-irrelevant information and satisfy the similar distribution of real data. As a result, our method recovers the accuracy of quantized models significantly with the help of the content-style-decoupled generator and style-intervened discrepancy reduction on three commonly-used networks. Importantly, Causal-DFQ comprehensively outperforms recent SoTA <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b57">[59]</ref> as shown in Fig. <ref type="figure" target="#fig_2">3</ref>. There is a breakthrough where the data-free quantized models fine-tuned by Causal-DFQ outperform the (quantized) ones re-trained with real data w.r.t. accuracy on the ImageNet dataset. In addition, data-free quantization is more efficient in terms of training time, e.g., fine-tuning 4-bit ResNet via our data-free quantization method costs 8.4 GPU hours while re-training in a data-given manner costs 29.6 hours. These experimental results demonstrate that data-free quantization can empirically replace the method of re-training low-bit networks. Object Detection. To demonstrate the application on object detection, we apply Causal-DFQ to the model Mo-bileNetV2 SSD <ref type="bibr" target="#b23">[24]</ref> and evaluate it on VOC2012.  ÂÖ•in Eq. 13 demonstrates the advantages of our method compared to other quantization methods. In particular, Causal-DFQ also outperforms FT that utilizes the original training dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablative Studies and analyses</head><p>Ablation Study.</p><p>We conducted a series of ablative studies of our proposed method on ImageNet with the ResNet18 and VGG16 architectures. By adjusting the coefficient Œª in the loss function (Eq. <ref type="bibr" target="#b12">13)</ref>, where Œª = 0 equals to no Causal-DFQ as our baseline (i.e., GDFQ <ref type="bibr" target="#b51">[53]</ref>). The results are shown in Fig. <ref type="figure" target="#fig_4">5</ref>. With Œª increasing, the performance improvements show the effectiveness of our method. However, when the ratio of L Causal-DFQ in L overall (Eq. 13) is greater than 10% (on average), data-free quantization performance drops. A welltrained quantized network should have both the ability to align low-level feature maps (i.e., aligning as GDFQ <ref type="bibr" target="#b51">[53]</ref>) and learn from causality (i.e., Causal-DFQ). Network Similarity between FP and Quantized Networks.</p><p>Centered kernel alignment (CKA) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b47">49]</ref> analyzing (hidden) layer representations of neural networks, enabling quantitative comparisons of representations within and across networks. It is a widely acknowledged tool for measuring the similarity between two networks <ref type="bibr" target="#b35">[37]</ref>. Higher similar score between two layers' output representations mean those two layers share more similarity. The visual-ization of CKA analysis is presented in Fig. <ref type="figure">6</ref>. More details about CKA for metricing network similarity are in Supplemental Materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GDFQ</head><p>Causal-DFQ <ref type="bibr">Figure 6</ref>. Cross model CKA <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b47">49]</ref> heatmaps between FP and quantized networks. The lighter the dot, the more similar of the two corresponding layers learned from different datasets. We can conclude that quantized network trained by Causal-DFQ is more similar to the FP network.</p><p>Attention of Quantized Model Analysis via Grad-Cam <ref type="bibr" target="#b39">[41]</ref> Visualization.</p><p>We analyze the attentions of several quantized models w.r.t. targeted task. The results are presented in 4. We can see that the quantized model created by our method behaves more similarly to the pre-trained model. Thus, we conclude that Causal-DFQ can quantized pre-trained FP model in a content-preserving manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we introduce causal reasoning into datafree quantization. We first formalize a causal graph to model the data-free quantization mechanism. Based on the causal graph, we propose the Causality-guided Data-free Network Quantization method to eliminate the reliance on data while training a quantized model. Specifically, we design a generator which can generate images conditioned on the content and style variables in the view of causality, and then we devise a discrepancy reduction loss to align the intervened distributions of the outputs of pre-trained and quantized models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Experimental Setup</head><p>Datasets. We validate the Causal-DFQ on four wellknown data sets including CIFAR-10, CIFAR-100 <ref type="bibr" target="#b22">[23]</ref>, Im-ageNet <ref type="bibr" target="#b6">[7]</ref> for recognition, and PASCAL VOC 2012 <ref type="bibr" target="#b7">[8]</ref> for detection. Specifically, CIFAR-10 consists of 60k images from 10 classes, with 6k per class. There are 50k images for training and 10k images for testing. CIFAR-100 has 100 classes, and each class contains 500 training images and 100 testing images. ImageNet is one of the most challenging and largest benchmark datasets for image classification, which has around 1.2 million real-world images for training and 50k images for validation. VOC 2012 contains 11,540 images, and each image contains a set of objects out of 20 different classes. Implementation Details. On CIFAR, we optimize the generator and quantized model using Adam <ref type="bibr" target="#b21">[22]</ref> and SGD with Nesterov <ref type="bibr" target="#b30">[31]</ref> respectively, where the momentum term and weight decay in Nesterov are set to 0.9 and 1√ó10 -4 . Moreover, the learning rates of quantized models and generators are initialized to 1√ó10 -4 and 1√ó10 -3 respectively. Both of them are decayed by 0.1 for every 100 epochs. In addition, we train the generator and quantized model for 400 epochs with 200 iterations per epoch. On ImageNet, we set the initial learning rate of the quantized model as 1 √ó 10 -6 . Other training settings are the same as those on CIFAR. More implementation details can be found in the codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Causal Reasoning</head><p>One core purpose of causal reasoning is to pursue the causal effect of interventions, contributing to achieving the desired objective. Recent work shows the benefits of introducing causality into machine learning from various aspects. After the deep connections of causal systems and the concept of exogeneity having been successfully implemented in social science, such as in Economics and Genetics [32], Sch√∂lkopf et al. <ref type="bibr" target="#b37">[39]</ref> originally develop a technique, named independence mechanisms via introducing casual mechanisms to independently separate the exogenous and endogenous variables w.r.t. specific tasks in the field of machine learning <ref type="bibr" target="#b38">[40]</ref>. Specifically, given two variables C and E, if P (E | C) remains invariant to changes in the process that generates C, then C can be defined as an exogenous variable. Huang et al. <ref type="bibr" target="#b18">[19]</ref> also prove that P (C) and P (E | C) change independently of each other when they both change. Besides the theoretical studies, there are several works implementing this mechanism into other tasks for not only improving the model performance but also understanding the tasks from the perspective of casual inference. For example, Mitrovic et al. <ref type="bibr" target="#b27">[28]</ref> propose to enforce invariant prediction w.r.t. style changes through an invariance regularizer, which yields improved generalization guarantees in self-supervised learning. Xie et al. <ref type="bibr" target="#b50">[52]</ref> bridge the causally independent hypothesis with the image-to-image translation. Chen et al. <ref type="bibr" target="#b3">[4]</ref> reveal that intra-domain style invariance is also of pivotal importance to improve domain generalization approaches. Apart from the independence mechanism, causal reasoning is also introduced to several CV fields <ref type="bibr" target="#b36">[38]</ref>, such as long-tail recognition <ref type="bibr" target="#b46">[48]</ref>, semantic segmentation <ref type="bibr" target="#b54">[56]</ref>, few-shot learning <ref type="bibr" target="#b53">[55]</ref> and class-incremental learning <ref type="bibr" target="#b17">[18]</ref>.</p><p>The most related work is RELIC <ref type="bibr" target="#b27">[28]</ref> which acts as a regularizer in self-supervised learning via the independence mechanisms <ref type="bibr" target="#b34">[36]</ref> to encourage networks to be invariant to different augmentations of the same instance. This selfsupervised learning method also constructs a causal graph to model the data generation process. However, the focus of this work is on the content invariant property using data augmentations to stimulate inaccessible interventions <ref type="bibr" target="#b56">[58]</ref>. However, our work is different from RELIC for two significant reasons. In summary, thanks to the unique nature of data-free quantization, our data generation process is steerable, unlike previous works. Thus, we can design a content-style-decoupled generator where both content and style variables are accessible in the causal graph. Then we can easily implement do-calculus <ref type="bibr" target="#b31">[33]</ref> for causal reasoning. In the following section, we will discuss the differences in causal literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Previous Causality-based Methods.</head><p>Existing works <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b50">52]</ref> on different tasks choose the invariant content C rather than the whole data X as the optimal node to extract representations. Since the content C is an informative representation for the data X and inference based on C is more stable against perturbations due to its causal dependency with the ground truth. Therefore, they expect that the information represented and extracted from data to the network f (‚Ä¢; Œ∏) should be invariant to style and correlated to content. We theoretically interpret this idea as follows: ‚àÄi l , i k ‚àà I P do(S=i l ) ( ·ª∏ | f ( X; Œ∏)) = P do(S=i k ) ( ·ª∏ | f ( X; Œ∏)), <ref type="bibr" target="#b13">(14)</ref> where f (‚Ä¢; Œ∏) is a model with parameters Œ∏.</p><p>However, the style domain S is practically inaccessible in the most learning scenarios such as supervised learning <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b37">39]</ref> and self-supervised learning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b50">52]</ref>, it is quite challenging to perform interventions on styles. To stimulate the interventions on the style domain S, previous works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b50">52]</ref> adopt the augmentation operations on data domain X . Specifically, the data augmentations (e.g., Gaussian blurring, flips, rotation, color distortions, and random cropping) on data X are utilized as interventions on the style variable S. Hence, the interventions i l and i k in the do-calculus of Eq. 14 can be replaced by augmentations a l and a k , and then we can derive the representation of invariant content by student networks. This relaxed equilibrium can be written as follows: ‚àÄl, k ‚àà {1, 2, ‚Ä¢ ‚Ä¢ ‚Ä¢ , M A }, P do(X=a l ) ( ·ª∏ | f ( X; Œ∏)) = P do(X=a k ) ( ·ª∏ | f ( X; Œ∏)) (15) where a l and a k form a pair of augmentations in the domain of interventions A, M A is the number of augmentations in A, and P do(X=a l ) stands for the distribution under augmentation a l on X <ref type="bibr" target="#b27">[28]</ref>. Then, the targeted representation of invariant content of the network in Eq.14 can be obtained by Eq.15. Finally, the causal dependency between invariant C and the output of network f (‚Ä¢; Œ∏) is discovered. Difference with Previous Works. In our data-free quantization scenario, via generating mechanism M in Eq.4 (Sec.3.2), we can access style domain S and content domain C. On the contrary, in most machine learning scenarios, content variable is computationally inaccessible as they use natural data, whose content variable is ill-defined.</p><p>Specifically, in the content of data-free quantization, we successfully escape from the aforementioned awful predicament where the style domain S is practically inaccessible. Thus we can directly operate the style domain S and obtain corresponding distribution P do(S=i l ) (f ( X; Œ∏ P ) | f ( X; Œ∏ Q )) as formulated in Targeted Causal Equilibrium (Eq.7 in Sec.3.2) P do(S=i l ) (f ( X; Œ∏ P ) | f ( X; Œ∏ Q )) =P do(S=i k ) (f ( X; Œ∏ P ) | f ( X; Œ∏ Q )), <ref type="bibr" target="#b15">(16)</ref> where M is the number of interventions in style domain S, f (‚Ä¢; Œ∏ P ) and f (‚Ä¢; Œ∏ Q ) are the pre-trained and quantized model with parameters Œ∏ P and Œ∏ Q , respectively. Straightforwardly, we desire the distribution, P (f ( X; Œ∏ P ) | f ( X; Œ∏ Q )) to be invariant over style variable change.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Algorithm 1</head><label>1</label><figDesc>Pseudo code of Content-Style-Decoupled Generator in a PyTorch-like style. def generator(S, C): # generator input = torch.mul(Embedding(C), S) # style &amp; content fusion x = conv blocks(input) # generate images via conv layers return x content = torch.randint(0, class number, (batch size),)) # define content style = torch.randn(batch size, latent dim) # define style generated x = generator(style, content) # generate images based on C and S</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Overview of the pipeline. To eliminate the reliance on data and utilize the causality in the discrepancy reduction stage, we disentangle the invariant content C and semantics-irrelevant style S in the view of causality. We propose a Content-Style-DecoupledGenerator to synthesize fake images conditioned on the independent content and style variables. Follow by the generator, we design Causal-DFQ loss to achieve knowledge exclusively based on content by intervening with the style variable. In particular, we use KLdivergence to minimize the distance between conditional distributions (similarity matrices, calculated in a contrastive way) of pre-trained and quantized models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Overall performance on 6-bit (Left, corresponding to Tab. 1) and 4-bit (Right, corresponding to Tab. 2) settings.</figDesc><graphic coords="7,423.61,289.64,121.14,103.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. What makes the data-free quantized network for detection on VOC think the pixel label is 'bicycle', visualized via Grad-Cam [41]. We can see that model quantized by Cuasal-DFQ is able to focus on task-specific Content.72 71 70 69 ÂÆÉ 68 ÂÖ∞ 67 u 66 ÔºúÔºö Â∑≤ , 65 CL O 64 I-</figDesc><graphic coords="8,12.80,168.03,330.31,185.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Ablation Study: Effect of Œª. Note that Œª = 0 equals to no Causal-DFQ as our baseline (i.e., GDFQ [53]).</figDesc><graphic coords="8,86.13,191.15,183.32,139.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Causal graph of the ideal data generation and model learning process. Right: Causal graph of the data-free quantization process. Each node represents a random variable, and shallow ones indicate observable variables, where C, S, X, ·ª∏ , YP , YQ, Œ∏G, Œ∏P , Œ∏Q are content variable, style variable, generated data, generated label, distilled label, output label, parameters of the generator, parameters of the pre-trained model, parameters of the quantized, respectively.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Comparisons on ImageNet. We quantize both the weights and activations of the models to 6-bits and report the top-1 accuracy.</figDesc><table><row><cell>Dataset</cell><cell>Model</cell><cell>Real Data FP32 FT</cell><cell>ZeroQ [2]</cell><cell>GDFQ [53]</cell><cell>Data Free DSG [57]</cell><cell cols="3">SQuant [13] IntraQ [59] Causal-DFQ</cell></row><row><cell></cell><cell>ResNet-18</cell><cell>71.47 70.76</cell><cell>69.84</cell><cell>70.13</cell><cell>70.46</cell><cell>70.74</cell><cell>70.60</cell><cell>71.01 ¬± 0.06</cell></row><row><cell></cell><cell>ResNet-50</cell><cell>77.74 77.70</cell><cell>72.93</cell><cell>76.59</cell><cell>76.07</cell><cell>77.05</cell><cell>76.90</cell><cell>77.45 ¬± 0.13</cell></row><row><cell>ImageNet</cell><cell>Inception-v3</cell><cell>78.80 78.80</cell><cell>74.94</cell><cell>77.20</cell><cell>-</cell><cell>78.30</cell><cell>77.46</cell><cell>78.40 ¬± 0.02</cell></row><row><cell></cell><cell>SqueezeNext</cell><cell>69.38 68.78</cell><cell>16.54</cell><cell>65.46</cell><cell>-</cell><cell>67.34</cell><cell>67.45</cell><cell>67.87 ¬± 0.11</cell></row><row><cell></cell><cell>ShuffleNet</cell><cell>65.07 64.55</cell><cell>35.21</cell><cell>60.12</cell><cell>-</cell><cell>60.25</cell><cell>60.18</cell><cell>60.83 ¬± 0.06</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Comparisons on CIFAR-10/100 and ImageNet with 4W4A quantization setting.</figDesc><table><row><cell>Dataset</cell><cell>Model</cell><cell>Real Data FP32 FT</cell><cell cols="7">Data Free DFQ [29] ZeroQ [2] GDFQ [53] DSG [57] SQuant [13] IntraQ [59] Causal-DFQ</cell></row><row><cell>CIFAR-10</cell><cell>ResNet-20</cell><cell>94.03 93.11</cell><cell>89.03</cell><cell>79.30</cell><cell>90.25</cell><cell>78.99</cell><cell>-</cell><cell>91.49</cell><cell>92.30 ¬± 0.08</cell></row><row><cell>CIFAR-100</cell><cell>ResNet-20</cell><cell>70.33 68.34</cell><cell>63.21</cell><cell>45.20</cell><cell>63.58</cell><cell>46.03</cell><cell>-</cell><cell>64.98</cell><cell>65.67 ¬± 0.28</cell></row><row><cell></cell><cell>BN-VGG16</cell><cell>74.28 68.83</cell><cell>45.56</cell><cell>1.15</cell><cell>67.10</cell><cell>31.06</cell><cell>68.32</cell><cell>68.73</cell><cell>71.09 ¬± 0.30</cell></row><row><cell></cell><cell>ResNet-18</cell><cell>71.47 67.84</cell><cell>55.78</cell><cell>26.04</cell><cell>60.60</cell><cell>34.53</cell><cell>66.14</cell><cell>66.47</cell><cell>68.11 ¬± 0.17</cell></row><row><cell>ImageNet</cell><cell>ResNet-50</cell><cell>77.74 72.89</cell><cell>47.34</cell><cell>-</cell><cell>70.23</cell><cell>-</cell><cell>70.80</cell><cell>70.65</cell><cell>72.49 ¬± 0.22</cell></row><row><cell></cell><cell>Inception-v3</cell><cell>78.80 73.80</cell><cell>49.62</cell><cell>26.84</cell><cell>70.39</cell><cell>34.89</cell><cell>73.26</cell><cell>73.12</cell><cell>73.35 ¬± 0.42</cell></row><row><cell></cell><cell>SqueezeNext</cell><cell>69.38 65.78</cell><cell>-</cell><cell>-</cell><cell>39.18</cell><cell>-</cell><cell>43.45</cell><cell>42.78</cell><cell>45.99 ¬± 0.13</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Comparisons on VOC 2012 for object detection. mAP is the metric, and higher is better.</figDesc><table><row><cell>Method</cell><cell cols="4">Bits W8A8 W4A8 W4A4 W2A2</cell></row><row><cell>FT</cell><cell>70.35</cell><cell>68.24</cell><cell>64.28</cell><cell>57.12</cell></row><row><cell>DFQ [29]</cell><cell>69.16</cell><cell>64.57</cell><cell>13.15</cell><cell>2.65</cell></row><row><cell>ZeroQ [2]</cell><cell>69.04</cell><cell>67.53</cell><cell>62.72</cell><cell>56.96</cell></row><row><cell>ZAQ [25]</cell><cell>70.02</cell><cell>68.12</cell><cell>64.44</cell><cell>56.96</cell></row><row><cell>Ours</cell><cell>70.63</cell><cell>68.45</cell><cell>66.10</cell><cell>57.26</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This research was supported by the gift donation from <rs type="funder">Cisco</rs>. This article solely reflects the opinions of its authors and not the funding agent.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Aciq: analytical clipping for integer quantization of neural networks</title>
		<author>
			<persName><forename type="first">Ron</forename><surname>Banner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yury</forename><surname>Nahshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elad</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Soudry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Zeroq: A novel zero shot quantization framework</title>
		<author>
			<persName><forename type="first">Yaohui</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhewei</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Gholami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Mahoney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007">2020. 1, 2, 6, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Data-free learning of student networks</title>
		<author>
			<persName><forename type="first">Hanting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaohui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanjian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A style and semantic memory mechanism for domain generalization</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingwei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Style-aware normalized loss for improving arbitrary style transfer</title>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayush</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prem</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Algorithms for learning kernels based on centered alignment</title>
		<author>
			<persName><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Afshin</forename><surname>Rostamizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Sm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Data-free adversarial distillation</title>
		<author>
			<persName><forename type="first">Gongfan</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengchao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingli</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A theory of causal learning in children: causal maps and bayes nets. Psychological review</title>
		<author>
			<persName><forename type="first">Alison</forename><surname>Gopnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Sobel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><forename type="middle">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamar</forename><surname>Kushnir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Danks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Knowledge distillation: A survey</title>
		<author>
			<persName><forename type="first">Jianping</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baosheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">J</forename><surname>Maybank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On-the-fly data-free quantization via diagonal hessian approximation</title>
		<author>
			<persName><forename type="first">Cong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxian</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingwen</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotian</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunxin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minyi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><surname>Squant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyv√§rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distilling causal effect of data in classincremental learning</title>
		<author>
			<persName><forename type="first">Xinting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian-Sheng</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Causal discovery from heterogeneous/nonstationary data</title>
		<author>
			<persName><forename type="first">Biwei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiji</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">D</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruben</forename><surname>Sanchez-Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ran El-Yaniv, and Yoshua Bengio. Binarized neural networks</title>
		<author>
			<persName><forename type="first">Itay</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Soudry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Quantization and training of neural networks for efficient integer-arithmetic-only inference</title>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skirmantas</forename><surname>Kligys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Single shot multibox detector</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><surname>Ssd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Zero-shot adversarial quantization</title>
		<author>
			<persName><forename type="first">Yuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Yuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.15278</idno>
		<title level="m">Data-free knowledge transfer: A survey</title>
		<imprint>
			<date type="published" when="2006">2021. 1, 2, 3, 6</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Data-free knowledge distillation for deep neural networks</title>
		<author>
			<persName><forename type="first">Gontijo</forename><surname>Raphael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thad</forename><surname>Fenu</surname></persName>
		</author>
		<author>
			<persName><surname>Starner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Representation learning via invariant causal mechanisms</title>
		<author>
			<persName><forename type="first">Jovana</forename><surname>Mitrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2021</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Data-free quantization through weight equalization and bias correction</title>
		<author>
			<persName><forename type="first">Markus</forename><surname>Nagel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mart</forename><surname>Van Baalen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tijmen</forename><surname>Blankevoort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Zero-shot knowledge distillation in deep networks</title>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Kumar Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konda</forename><surname>Reddy Mopuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaisakh</forename><surname>Shaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Venkatesh</forename><surname>Babu Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirban</forename><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A method for solving the convex programming problem with convergence rate o (1/kÀÜ2)</title>
		<author>
			<persName><forename type="first">E</forename><surname>Yurii</surname></persName>
		</author>
		<author>
			<persName><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">In Dokl. akad. nauk Sssr</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The do-calculus revisited</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2009">2012. 2, 4, 9</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Models, reasoning and inference</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Elements of causal inference: foundations and learning algorithms</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2017. 1, 3, 6, 9</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Do vision transformers see like convolutional neural networks?</title>
		<author>
			<persName><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Causality for machine learning</title>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10500</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On causal and anticausal learning</title>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eleni</forename><surname>Sgouritsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joris</forename><surname>Mooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2009">2012. 2, 4, 9</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Toward causal representation learning</title>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><forename type="middle">Rosemary</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Proceedings of the IEEE, 2021. 2, 3, 4, 9</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Grad-cam: Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ramprasaath R Selvaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakrishna</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devi</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Lipschitz continuity guided knowledge distillation</title>
		<author>
			<persName><forename type="first">Yuzhang</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziliang</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Lipschitz continuity retained binary neural network</title>
		<author>
			<persName><forename type="first">Yuzhang</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziliang</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Network binarization via contrastive learning</title>
		<author>
			<persName><forename type="first">Yuzhang</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziliang</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Post-training quantization on diffusion models</title>
		<author>
			<persName><forename type="first">Yuzhang</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihang</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingzhe</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Data-free parameter pruning for deep neural networks</title>
		<author>
			<persName><forename type="first">Suraj</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babu</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1507.06149</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Longtailed classification by keeping the good and removing the bad momentum causal effect</title>
		<author>
			<persName><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In NeurIPS, 2020. 3, 9</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Similarity-preserving knowledge distillation</title>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">The genetical structure of populations. Annals of eugenics</title>
		<author>
			<persName><forename type="first">Sewall</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1949">1949</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Quantized convolutional neural networks for mobile devices</title>
		<author>
			<persName><forename type="first">Jiaxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Unaligned image-to-image translation by learning to reweight</title>
		<author>
			<persName><forename type="first">Shaoan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanwu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Generative lowbitwidth data free quantization</title>
		<author>
			<persName><forename type="first">Shoukai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haokun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bohan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiezhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuangrun</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008">2020. 1, 2, 6, 7, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Dreaming to distill: Data-free knowledge transfer via deepinversion</title>
		<author>
			<persName><forename type="first">Pavlo</forename><surname>Hongxu Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhizhong</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Mallya</surname></persName>
		</author>
		<author>
			<persName><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Niraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Qianru Sun, and Xian-Sheng Hua. Interventional few-shot learning</title>
		<author>
			<persName><forename type="first">Zhongqi</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Xiansheng Hua, and Qianru Sun. Causal intervention for weakly-supervised semantic segmentation</title>
		<author>
			<persName><forename type="first">Dong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Diversifying sample generation for accurate data-free quantization</title>
		<author>
			<persName><forename type="first">Xiangguo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haotong</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruihao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinghua</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renshuai</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengwei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianglong</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007">2021. 1, 2, 6, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Adversarial robustness through the lens of causality</title>
		<author>
			<persName><forename type="first">Yonggang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
	<note>In ICLR, 2022. 1, 3, 6</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Intraq: Learning synthetic images with intra-class heterogeneity for zero-shot network quantization</title>
		<author>
			<persName><forename type="first">Yunshan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingbao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gongrui</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianzhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baochang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients</title>
		<author>
			<persName><forename type="first">Shuchang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zekun</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuheng</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06160</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
