<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neutral Utterances are Also Causes: Enhancing Conversational Causal Emotion Entailment with Social Commonsense Knowledge</title>
				<funder ref="#_hFg2nsD #_Z4U3Pc9">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiangnan</forename><surname>Li</surname></persName>
							<email>lijiangnan@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Joint work with Pattern Recognition Center</orgName>
								<orgName type="institution">Ten- cent Inc</orgName>
								<address>
									<addrLine>WeChat AI</addrLine>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
							<email>fandongmeng@tencent.com</email>
							<affiliation key="aff2">
								<orgName type="department">Pattern Recognition Center</orgName>
								<address>
									<addrLine>WeChat AI</addrLine>
									<region>Tencent Inc</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zheng</forename><surname>Lin</surname></persName>
							<email>linzheng@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rui</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peng</forename><surname>Fu</surname></persName>
							<email>fupeng@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yanan</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weiping</forename><surname>Wang</surname></persName>
							<email>wangweiping@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Pattern Recognition Center</orgName>
								<address>
									<addrLine>WeChat AI</addrLine>
									<region>Tencent Inc</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neutral Utterances are Also Causes: Enhancing Conversational Causal Emotion Entailment with Social Commonsense Knowledge</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conversational Causal Emotion Entailment aims to detect causal utterances for a non-neutral targeted utterance from a conversation. In this work, we build conversations as graphs to overcome implicit contextual modelling of the original entailment style. Following the previous work, we further introduce the emotion information into graphs. Emotion information can markedly promote the detection of causal utterances whose emotion is the same as the targeted utterance. However, it is still hard to detect causal utterances with different emotions, especially neutral ones. The reason is that models are limited in reasoning causal clues and passing them between utterances. To alleviate this problem, we introduce social commonsense knowledge (CSK) and propose a Knowledge Enhanced Conversation graph (KEC). KEC propagates the CSK between two utterances. As not all CSK is emotionally suitable for utterances, we therefore propose a sentiment-realized knowledge selecting strategy to filter CSK. To process KEC, we further construct the Knowledge Enhanced Directed Acyclic Graph networks. Experimental results show that our method outperforms baselines and infers more causes with different emotions from the targeted utterance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Conversation is the most omnipresent medium for people to express daily emotions. Capturing emotions is critical for machines to understand conversations, which leads to researchers <ref type="bibr" target="#b9">[Majumder et al., 2019;</ref><ref type="bibr" target="#b4">Ghosal et al., 2019;</ref><ref type="bibr">Shen et al., 2021b]</ref> devoting into emotion recognition in conversations (ERC). However, further reasoning why an emotion is aroused in conversations is still under explored <ref type="bibr">[Poria et al., 2021]</ref>. Understanding emotion causes is also a critical step for machines to understand conversations, which can Figure <ref type="figure">1</ref>: A case that the baseline DAG-ERC fails while the selected commonsense knowledge can help to make a right prediction. be further utilized in other high-level tasks like empathetic generation <ref type="bibr" target="#b6">[Kim et al., 2021]</ref>. <ref type="bibr">Therefore, Poria et al. [2021]</ref> propose a new task called Recognizing Emotion Cause in Conversations (RECCON). RECCON involves an important subtask called Conversational Causal Emotion Entailment (C 2 E 2 ). C 2 E 2 detects causal utterances for a targeted utterance from conversations where the emotion is given.</p><p>Implied by the name, C 2 E 2 is originally modeled as a "text pair" task by <ref type="bibr">Poria et al. [2021]</ref>. In this way, a candidate utterance and the targeted utterance are paired plus their conversational context and the emotion. They are concatenated and then processed by a pretrained model. However, this entailment style ignores the explicit interactions between utterances, thus contextual information from conversations not fully captured. To explicitly model the interactions between utterance representations, works <ref type="bibr" target="#b4">[Ghosal et al., 2019;</ref><ref type="bibr">Shen et al., 2021b]</ref> in ERC adopt various types of graphs for conversations, which can achieve decent performance.</p><p>As emotion plays a crucial role in C 2 E 2 , it is utilized in the entailment <ref type="bibr">[Poria et al., 2021]</ref>. When conversations are constructed as graphs, it is also critical to consider emotion information. An intuitive way is to represent emotion as emotion embedding <ref type="bibr" target="#b7">[Liang et al., 2021]</ref> and concatenate it with the node representation. Experiments show that emotion information can remarkably boost the performance. Specifically, we find that it can dramatically promote the detection of causal utterances whose emotion is the same as the targeted utterance. However, causal utterances with different emotions, especially neutral ones (neutral causal utterances occupy 87% of this kind of causes), is still hard to detect even with emotion information. We think the reason lies in that models are limited in reasoning causal clues and passing them between utterances. For example, in Fig. <ref type="figure">1</ref>, the 2nd utterance u 2 is a cause to the 3rd utterance u 3 . Models cannot reason why a neutral utterance about misdialing can evoke sadness to another utterance, leading to a wrong prediction.</p><p>To boost models' causal reasoning ability, we introduce social commonsense knowledge (CSK) <ref type="bibr">[Hwang et al., 2021]</ref> and propose a graph-based structure to properly utilize CSK. Therefore, causal utterances with different emotions from the targeted utterance can be further detected. Specifically, social CSK can infer a person's social interactions like mental states and reactions. Back to Fig. <ref type="figure">1</ref>, equipped with the knowledge, models can infer that u 2 makes the speaker of u 3 feel upset and then give a right prediction. To properly utilize knowledge, we propose a Knowledge Enhanced Conversation graph (KEC). KEC passes knowledge through edges. As the knowledge should align with speaker interactions and emotions, we therefore propose a speaker and sentiment realized knowledge selecting strategy, which can pick up suitable knowledge for utterances. Furthermore, to process the KEC, we extend the Directed Acyclic Graph networks (DAG) for ERC <ref type="bibr">[Shen et al., 2021b]</ref> to build Knowledge Enhanced DAG networks. To verify our method, we conduct experiments on the RECCON dataset. Our method significantly outperforms the baseline of RECCON and other highly related methods. In addition, our method promotes the detection of causal utterances with different emotions from the targeted utterance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Conversational Emotion Recognition (ERC) is a highly related task to C 2 E 2 . ERC tends to predict the emotion of utterances in conversations. In ERC, a main stream of works <ref type="bibr" target="#b9">[Majumder et al., 2019;</ref><ref type="bibr" target="#b4">Ghosal et al., 2019;</ref><ref type="bibr">Shen et al., 2021a]</ref> focuses on studying the speaker modelling. Although ERC is a hot-spot task for researchers to study conversations, further reasoning about emotions and understanding the causes in conversations is still lack of exploration.</p><p>Emotion Cause Extraction (ECE) is to extract the causal clause for an emotion clause from a document and Gui et al. <ref type="bibr">[2016]</ref> construct the most popular ECE dataset. <ref type="bibr" target="#b1">Ding et al. [2019]</ref>; <ref type="bibr" target="#b12">Xia et al. [2019]</ref> introduce position embeddings to model causal clauses appeared near the emotion clause. As emotion and cause are highly related, Turcan et al. <ref type="bibr">[2021]</ref> propose multi-task learning frameworks for emotion recognition and cause extraction. To simultaneously extract emotion and cause clauses from documents, <ref type="bibr" target="#b12">Xia and Ding [2019]</ref> propose a new task called Emotion Cause Pair Extraction (ECPE) and handle it in a two-stage style. To overcome the problems brought by two-stage processing, some works <ref type="bibr">[Ding et al., 2020a;</ref><ref type="bibr" target="#b11">Wei et al., 2020;</ref><ref type="bibr">Ding et al., 2020b]</ref> propose their novel joint frameworks. Both ECPE and ECE are only extract causes in articles, which does not extend to the scene of conversations. Conversations are more complicated due to the flowing emotion dynamics and speaker participation <ref type="bibr" target="#b4">[Ghosal et al., 2019]</ref>. To study the causal factor of emotion in conversations, <ref type="bibr">Poria et al. [2021]</ref> propose Recognizing Emotion Causes in Conversations (RECCON). RECCON involves two subtasks: Conversational Causal Span Extraction (C 2 SE) and Conversational Causal Emotion Entailment (C 2 E 2 ). C 2 SE focuses on extracting causal spans from conversations, which is modelled as a machine reading comprehension task by <ref type="bibr">Poria et al. [2021]</ref>. In this work, we focus on C 2 E 2 , the classification version of RECCON.</p><p>Commonsense Knowledge Utilization (CSK) can bring rational external knowledge for models. In ERC, some works <ref type="bibr" target="#b13">[Zhong et al., 2019;</ref><ref type="bibr" target="#b4">Ghosal et al., 2020;</ref><ref type="bibr" target="#b7">Li et al., 2021]</ref> study how to use CSK to help understand conversation context and mental states of speakers. In <ref type="bibr">ECE, Gui et al. [2021]</ref> propose Knowledge-Aware Graph using CSK to alleviate position bias brought by position embeddings. <ref type="bibr">Turcan et al. [2021]</ref> use CSK to enhance ECE and Emotion Detection. In the task of Sentence Ordering, sequential commonsense knowledge is structurally utilized by <ref type="bibr" target="#b5">Ghosal et al., [2021]</ref>. However, for C 2 E 2 , it is still under explored how to properly use CSK.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Definition</head><p>C 2 E 2 is to find causal utterances for a targeted utterance from the historical context. Given a conversation C = [u 1 , ..., u N ], with the corresponding emotion sequence E = [e 1 , ..., e N ] and speaker sequence P = [p 1 , ..., p N ], every utterance u i is paired with its contextual utterances u j (j ‚â§ i). If u i is a non-neutral utterance and u j is its causal utterance, the pair (u i , u j ) is labeled with 1. Otherwise, (u i , u j ) is labeled with 0. In our setting, neutral utterances are involved as targeted utterances, leading to more negative non-causal pairs and making the task more challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Utterance Encoder</head><p>Similar as other conversation-related tasks (e.g., ERC), utterances in a conversation are first encoded by an utterance encoder to form utterance representations. We utilize the pretrained model RoBERTa <ref type="bibr" target="#b8">[Liu et al., 2019]</ref> to encode an utterance u i = [w 1 , ..., w Lu ] with L u words. We then obtain the utterance representation by:</p><formula xml:id="formula_0">s i = Linear(Maxpooling(RoBERTa(u i ))),<label>(1)</label></formula><p>where s i ‚àà R du and d u is the dimension of utterance representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Conversation Encoder</head><p>As only reviewing conversation history for utterances, the conversation can be modelled as a directed acyclic graph when not considering self-loop edges. Based on the Directed Acylic Graph (DAG) networks <ref type="bibr">[Shen et al., 2021b]</ref>, we introduce our knowledge enhanced conversation graph, which is illustrated in Fig. <ref type="figure">2</ref>.</p><formula xml:id="formula_1">Knowledge Enhanced Conversation Graph Knowledge Enhanced Conversation graph (KEC) is formu- lated as G = (V, A c , A k ).</formula><p>V denotes the set of utterance nodes, A c denotes the adjacency matrix of conventional utterance interactions, and A k denotes the adjacency matrix of knowledge passing between utterances. Utterance nodes. V models all utterances as nodes v i in a conversation. v i contains the attribute rep to store the utterance representation (i.e., v i .rep= s i ).</p><formula xml:id="formula_2">‚Ñé 1 ùêø ‚Ñé 3 ùêø ‚Ñé 2 ùêø ‚Ñé 4 ùêø ‚Ñé 1 2 ‚Ñé 3 2 ‚Ñé 2 2 ‚Ñé 4 2 utterance1 RoBERTa ùë† 1 utterance2 RoBERTa ùë† 2 utterance3 RoBERTa ùë† 3 utterance4 RoBERTa ùë† 4 ‚Ñé 1 1 ‚Ñé 3 1 ‚Ñé 2 1 ‚Ñé 4 1 Neutral Neutral Sadness Surprise Neutral Surprise Knowledge Selection xEffect xReact "none" ùë† 1 ‚Ñé 1 ùêø ‚Ä¶ ‚Ñé 1 1 ùë† 3 ‚Ñé 3 ùêø ‚Ä¶ ‚Ñé 3</formula><p>Utterance interaction adjacency matrix. Conversational context modeling is crucial to conversation-related tasks, which can enrich targeted utterances with contextual messages passed from other utterances. As only the dialogue history is considered, we construct A c as a lower triangle matrix. A c contains two attributes: item and rel, where item stores 0 or 1 to denote the existence of an edge and rel stores the relation type of an edge.</p><formula xml:id="formula_3">For nodes v i , v j , A c [i, j].item = 1 is present if there is an edge from v j to v i , otherwise A c [i, j].item = 0.</formula><p>For a targeted utterance, it has been studied that local contextual information is more important than that in the remote context <ref type="bibr">[Shen et al., 2021b]</ref>. Therefore, a context window with size of w c is sliding through conversations. In the window, every contextual utterance sends an edge to the targeted one. Speaker information is another crucial factor. Speaker interactions can be modelled as two relations: self-dependency (SD) and inter-speaker dependency (ID) <ref type="bibr" target="#b4">[Ghosal et al., 2019]</ref>. For v i , v j , A c [i, j].rel = SD means that the speaker identity p i is the same as p j , otherwise A c [i, j].rel = ID. Knowledge passing adjacency matrix. We pass the knowledge through edges to enhance the ability of inferring causes. Similar as A c , A k is also a lower triangle matrix. A k contains two attributes: item and klg, where item plays the same role as A c .item and klg stores the knowledge attached on an edge.</p><p>The commonsense knowledge (CSK) we utilize is the social CSK provided by the CSK graph ATOMIC-2020 <ref type="bibr">[Hwang et al., 2021]</ref>. <ref type="bibr">Hwang et al., [2021]</ref> train a generating model called COMET <ref type="bibr" target="#b0">[Bosselut et al., 2019]</ref> on the CSK graph so that texts out of the scope of the CSK graph can be freely inferred. ATMOIC-2020 contains nine social-interaction relations while not all relations can be fit into our condition. According to the direction of inference and relevance, we pick four relations: xEffect, xReact, oEffect, and oReact. x(o)Effect reasons the effect on the speakerself (other speakers) after an utterance, and x(o)React describes how the speaker-self (other speakers) feels after an utterance. We exemplify these relations in Appendix A. Given Algorithm 1 Construction of Knowledge adjacency matrix end for 20: end for 21: return A k an utterance u i and one of the relations, COMET takes them as the input and generates knowledge with the beam search of 5. We denote the generation as CT(u i , xE), where CT and xE are the abbreviations of COMET and xEffect respectively.</p><formula xml:id="formula_4">Input: Dialog [u 1 , ..., u N ], emotion [e 1 , ..., e N ], speaker [p 1 , ..., p N ], COMET CT, window w k , func split(‚Ä¢), e2s(‚Ä¢). Output: Knowledge passing adjacency matrix A k . 1: ‚àÄi, j ‚àà [1, ..., N ], initializing A k with A k [i, j].item = 0, A k [i, j].klg ="none". (i: target, j: source) 2: for j in [1, N ] do 3: posK x , negK x , neuK x = split(CT(u j , xE/xR)) 4: posK o , negK o , neuK o = split(CT(u j , oE/oR)) 5: for i in [j, min(j + w k , N )] do 6: if p i == p j then 7: K = {pos: posK x , neg: negK x , neu: neuK x } 8:</formula><p>As COMET does not guarantee to generate emotionrelated knowledge, it is necessary to pick up the knowledge related to the emotion of the targeted utterance. Furthermore, knowledge passing should align with speakers' interactions. Therefore, we propose a knowledge selecting strategy, which is sentiment realized and fits the condition of conversations. The knowledge selection realizes two factors: Speaker realization. If p i of the target u i equals to p j of the source u j , knowledge of xEffect and xReact is chosen, otherwise knowledge of oEffect and oReact picked.</p><p>Sentiment realization. For the generated set of knowledge, we need to first identify its emotion, and then pick up emotion-related pieces for u i and u j . As no standard emotion lexicon resource is provided, we replace the emotion with the sentimental polarity. We utilize sentiwordnet to compute the sentimental polarity of every piece of knowledge. As sentiwordnet rates every word with scores of neutral, negative, and positive, we compute the sentimental score of a piece of knowledge by:</p><formula xml:id="formula_5">r s = r pos -r neg , |r pos -r neg | &gt; r neu 0, else<label>(2)</label></formula><p>where r pos is the average positive score of all words in the knowledge, and the knowledge is regarded as positiveness when r s &gt; 0. According to the r s , we split knowledge into three sets and concatenate the knowledge in a set with the token [sep] (denoted as a function split(‚Ä¢)). If a set is empty, the text "none" will be assigned to it. After splitting knowledge, we further map the emotion of u i and u j into the sentiment (denoted as a function e2s(‚Ä¢)). The emotion happiness is mapped to positive, neutral to neutral, and other emotions in the dataset to negative. With the mapped sentiment, we can select the related knowledge for utterances. The knowledge selection is processed simultaneously along the construction of A k , which is illustrated in Algorithm 1. In line 14 of Algorithm 1, we add the neutral knowledge, because we think that it can bring some reasoning information to help understand causes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge Enhanced DAG Networks</head><p>As the original DAG network considers no knowledge, we modify it and propose the Knowledge Enhanced DAG network to better process the KEC graph.</p><p>We first encode the knowledge into representations by using the shared RoBERTa of the utterance encoder and the same operation of encoding utterance. For an item of knowledge A k <ref type="bibr">[i, j]</ref>.klg, it is encoded as k i,j ‚àà R du .</p><p>For a targeted utterance u i , edge weights from neighboring nodes v j in the l th layer can be computed as:</p><formula xml:id="formula_6">Œ± i,j = Softmax j‚ààNi (W l w [h l-1 i ||(h l j + W l k k i,j )]),<label>(3)</label></formula><p>where h l-1 i is the node representation of the (l -1) th layer, h l j is the neighboring node representation that has been processed in the l th layer, W l w ‚àà R 1√ó2du and W l k ‚àà R du√ódu are trainable parameters. For h 0 i ‚àà R du , we initialize it by</p><formula xml:id="formula_7">h 0 i = Linear([s i ||eemb ei ])</formula><p>, where eemb ei is the trainable embedding of the emotion e i and is initialized by the weight vector in the MLM head of RoBERTa. Furthermore, the contextual message and knowledge message are aggregated from neighboring nodes according to the edge weight Œ± i,j :</p><formula xml:id="formula_8">msg i = j‚ààNi Œ± i,j W l A c[i,j].rel h l j ,<label>(4)</label></formula><formula xml:id="formula_9">nlg i = j‚ààNi Œ± i,j W l k k i,j ,<label>(5)</label></formula><p>where</p><formula xml:id="formula_10">W A c[i,j].rel ‚àà (W l SD , W l ID )</formula><p>with the size of R du√ódu is a trainable parameter. To capture the nodal and contextual information, DAG networks utilize two GRUs: nodal unit (GRU n ) and contextual unit (GRU c ). The information is obtained by:</p><formula xml:id="formula_11">nod i = GRU n (h l-1 i , msg i ),<label>(6)</label></formula><formula xml:id="formula_12">cxt i = GRU c (msg i , h l-1 i ).<label>(7)</label></formula><p>To further consider the effect of knowledge from the context and the utterance itself, we employ two additional GRUs: contextual knowledge unit (GRU k ) and self-loop knowledge unit (GRU s ). Therefore, knowledge-related information can be obtained by:</p><formula xml:id="formula_13">ckg i = GRU k (nlg i , h l-1 i ), (<label>8</label></formula><formula xml:id="formula_14">)</formula><formula xml:id="formula_15">skg i = GRU s (k i,i , h l-1 i ).<label>(9)</label></formula><p>Finally, the node representation of utterance u i in the l th layer is updated by summing the four types of information, i.e. h l i = nod i + cxt i + ckg i + skg i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Cause Predictor</head><p>After the encoding of two-level encoders, the final utterance representation is computed by <ref type="bibr">et al., 2021b]</ref>. Whether u j is the cause of u i is then computed by:</p><formula xml:id="formula_16">h i = || L l=0 h l i [Shen</formula><formula xml:id="formula_17">p i,j = sigmoid(MLP([h i ||h j ])), (<label>10</label></formula><formula xml:id="formula_18">)</formula><p>where MLP maps the concatenation of h i and h j from the dimension of 2d u to 1. We use the cross entropy loss to train our model, and the loss on a conversation is formulated as: <ref type="bibr">(11)</ref> where y i,j ‚àà {0, 1} is the cause label of the pair (u i , u j ).</p><formula xml:id="formula_19">L = i‚â§N j‚â§i (y i,j ‚Ä¢ logp i,j + (1 -y i,j ) ‚Ä¢ (1 -p i,j )),</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We conduct experiments on the dataset call RECCON-DD <ref type="bibr">[Poria et al., 2021]</ref>, which is collected from the popular dyadic dialogue dataset DailyDialog (DD) <ref type="bibr" target="#b7">[Li et al., 2017]</ref>. Preprocessing the original RECCON-DD, we only consider causes in the dialogue history for every utterance and remove the duplicated causal pairs. Statistics of the processed RECCON-DD are presented in Tab. 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Compared Methods</head><p>For the reason that C 2 E 2 is a new task proposed by <ref type="bibr">Poria et al. [2021]</ref>, there is only one baseline <ref type="bibr">[Poria et al., 2021]</ref>. Therefore, we additionally compare our model with other SOTA methods from conversation and emotion cause related tasks.  Entail is the baseline of C 2 E 2 . It utilizes RoBERTa to process the concatenation of utterances and their emotion and history context. The concatenation is formed by " <ref type="bibr">et al., 2021b]</ref> is the SOTA method of Conversational Emotion Recognition (ERC). Our method is based on it. SKAIG <ref type="bibr" target="#b7">[Li et al., 2021]</ref> is another SOTA method of ERC which utilize CSK to help the prediction. It passes knowledge through edges using graph transformers <ref type="bibr" target="#b10">[Shi et al., 2021]</ref>, while no knowledge selecting strategy is applied. For the fair comparison, we utilize the knowledge x/oEffect and x/oReact for SKAIG. <ref type="bibr">KAG [Yan et al., 2021]</ref> is the SOTA method of Emotion Cause Extraction (ECE) using CSK to overcome the position bias. It connects emotional utterances with a contextual utterance if a path is matched in Concept-Net. It uses relational GCNs to process their proposed graph. Knowledge used in KAG only participates in the computation of edge weights. As other methods add no position embeddings, we do not add position embeddings in KAG. Adapted <ref type="bibr">[Turcan et al., 2021]</ref> is another SOTA method of ECE. It directly concatenates CSK (xReact and oReact) after the utterance and utilizes RoBERTa to make prediction. For baselines from Emotion Cause Pair Extraction (ECPE), following and referring the results from Poria et al. <ref type="bibr">[2021]</ref>, we choose ECPE-2D <ref type="bibr">[Ding et al., 2020a]</ref>, ECPE-MLL <ref type="bibr">[Ding et al., 2020b]</ref>, and RankCP <ref type="bibr" target="#b11">[Wei et al., 2020]</ref>. To consider emotion information, in the re-implementation, all graph-related baselines utilize emotion embedding.</p><formula xml:id="formula_20">[cls] emo- tion [sep] u i [sep] u j [sep] history context [sep]". DAG- ERC [Shen</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation</head><p>All compared methods and our model use base-size pretrained models (e.g., RoBERTa-base) from huggingface Transformers. We train our model using the AdamW optimizer with 40 epochs, learning rate of 3e-5, L2 regularization of 1e-4. The batch is set to 4 and we step the gradient with the accumulating step of 2. For Conversation Encoder, we set the dimension of utterance to 300, the hidden size of GRUs to 300, the number of layers of DAG networks to 5. For emotion embeddings, we utilize a linear unit mapping the dimension of 768 to 200. For Cause Predictor, dimensions of MLP is set to <ref type="bibr">[600,</ref><ref type="bibr">300,</ref><ref type="bibr">300,</ref><ref type="bibr">1]</ref> and the dropout rate is set to 0.1. For the window size of knowledge and that of context, we find that our model achieves better performance when they are the  we report the F1 scores of both negative and positive causal pairs and the macro F1 score of them. Our experiments are conducted using 5 random seeds.<ref type="foot" target="#foot_1">foot_1</ref> </p><p>5 Results and Discussions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Main Results</head><p>The results of our method and baselines are listed in Tab. 2. We split the table into 4 rows: the 1st row for models of ECPE, the 2nd row for models using CSK, the 3rd row for models with no CSK, and the 4th row for our method.</p><p>From the 1st row, models of ECPE are not competitive to models in other rows. We think the reason is that the setting of ECPE is not suitable for C 2 E 2 . Compared with models in the 2nd row, our method can achieve better results. For KAG, we think the undesired performance can be attributed to that it is designed to resist position bias for news articles. Conversations in RECCON tends to be short and requires more sophisticated modeling than articles. In addition, knowledge is only used to compute edge weight in KAG, which does not propagate through edges like ours. For "Adapted", knowledge is directly concatenated after the utterance, and is not explicitly passed between utterances. For SKAIG, knowledge is also not selected, which leads to sentiment-nonaligned knowledge passed through the graph. On the contrary, our KEC selects proper knowledge to align with emotions, and explicitly models and propagates the knowledge in graphs. The comparison indicates that our method is more suitable for utilizing knowledge in C 2 E 2 .</p><p>As the baseline of RECCON, "Entail" is not comparable to the graph-based SKAIG and DAG-ERC, which demonstrates that explicit modeling of utterance interactions is critical for C 2 E 2 . DAG-ERC is the SOTA baseline for ERC with no knowledge involved. By introducing CSK and the knowledge selection, our method can achieve significant improvements against DAG-ERC. Therefore, it is critical to utilize proper knowledge for cause detection. To verify our knowledge enhanced DAG networks, we construct a variant that knowledge W l k k j,i is directly added on h l j in eq. 4 and no knowledge-related GRUs are involved.  demonstrates that, instead of being simply added in contextual messages, knowledge prefers to be exclusively modelled by gated units in our knowledge enhanced DAG networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ablation Study</head><p>To study the effect of different modules equipped in our model, we remove contextual knowledge unit GRU k , selfloop knowledge unit GRU s , neutral knowledge added when source utterances are neutral in line 14 of Algorithm 1, and emotion embedding respectively. The results are in Tab. 3.</p><p>The decreased performance by removing GRU k shows the necessity of controlling knowledge from the context. As for removing GRU s affects the performance, it indicates that self-knowledge enriching for targeted utterances is critical because 37% causal utterances are the targeted utterances themselves in RECCON. By taking off neutral knowledge, the performance shows decline. This manifests that neutral knowledge can help the model to better detect causes as it can provide some reasoning information.</p><p>When removing emotion embedding, the performance is still competitive to DAG-ERC who is equipped with emotion embedding. This can be attributed to that our knowledge selecting strategy can pick up sentiment related knowledge for the model. As emotion embedding and knowledge are all removed, the model becomes DAG-ERC without emotion information. The performance drops dramatically, which verify the claim that emotion information are important to C 2 E 2 . As for "Entail" without emotion, the performance is presented in Appendix C. In the next subsection, we will further show what causes are preferred by the emotion information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Performance on Cause Pairs</head><p>There is a question about whether our model can promote the detection of causal utterances with emotions different from that of the targeted utterance. We therefore present the recalls of causal pairs whose utterances are with the same emotion (SE pairs) and different emotions (DE pairs) in Fig. <ref type="figure">3</ref> for every targeted emotion. From the figure, we can see that DAG-ERC with emotion embedding can dramatically boost the detection of SE pairs while limited improvement is achieved on DE pairs. Specifically, emotion information increases the recall on all SE pairs by about 23% while only about 3% on DE pairs. By introducing CSK, our model, compared with DAG-ERC with emotion embedding, further increases the recall by 3% on SE pairs and by 12% on DE pairs (especially boosting the detection of neutral causal utterances by 12%). This manifests that our model can promote the detection of DE pairs, especially on pairs whose targeted utterances are with negative emotions like Anger, Sadness in Fig. <ref type="figure">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Effect of Window Size</head><p>To show the effect of the window size, we illustrate the trend of macro F1 scores with the window size increasing in Fig. <ref type="figure">4</ref>. The trend line shows that our model achieves the best performance with a small window. As the window size keeps increasing, the performance will drop and fluctuate. The reason for this can be attributed to that over 80% causal utterances are located near the targeted utterance in no more than 2 steps. It can be future work to solve the problem that models bias to neighboring utterances in C 2 E 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we study Conversational Causal Emotion Entailment. We find that adding emotion information into graphs cannot effectively detect causal utterances with different emotions from the targeted utterance due to models' limited causal reasoning ability. To alleviate this, we introduce social commonsense knowledge and propose a graph-based structure to properly utilize knowledge. Specifically, we propose a Knowledge Enhanced Conversation graph (KEC) with a designed knowledge selecting strategy. To process KEC, we construct Knowledge Enhanced Directed Acyclic Graph networks. Our method outperforms baselines and detects more causes with different emotions from the targeted utterance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>K</head><label></label><figDesc>= {pos: posK o , neg: negK o , neu: neuK o } e i ) Ã∏ = neu then 12: A k [i, j].item = 1 13:if e2s(e j ) == neu then 14:A k [i, j].klg = K[neu] + [sep] + K[e2s(e i )] k [i, j].klg = K[e2s(e i )]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure3: "Same Emotion" reports the recall of causal pairs whose causal utterances are with the same emotion as the targeted utterance. "Different Emotion" refers to different emotions from the targeted utterance. The number of a type of pairs is presented below the x-axis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The structure of our model. It contains 3 modules: (1) Utterance Encoder encodes every utterance; (2) KEC graph is constructed from a conversation and knowledge attached in KEC graph is picked up by the knowledge selecting strategy. Conversation Encoder then uses Knowledge Enhanced DAG networks to process KEC graph; (3) Cause Predictor pairs every two utterances to make predictions.</figDesc><table><row><cell cols="2">Utterance Encoder</cell><cell></cell><cell>Conversation Encoder</cell><cell>Cause Predictor</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Knowledge Enhanced</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>DAG networks</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Prediction</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell></row><row><cell>Speaker A</cell><cell>Speaker B</cell><cell>Edges in SD relation (ùî∏ ùëê )</cell><cell>Edges in ID relation (ùî∏ ùëê )</cell><cell>Edges of knowledge (ùî∏ ùëò )</cell></row><row><cell>Figure 2:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of RECCON-DD. "Positive" means the true causal pair.</figDesc><table><row><cell></cell><cell></cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell></row><row><cell>Num. of</cell><cell>Positive</cell><cell>7027</cell><cell>328</cell><cell>1767</cell></row><row><cell>Causal Pair</cell><cell cols="4">Negative 45392 2842 14052</cell></row><row><cell cols="2">Num. of Dialgoue</cell><cell>834</cell><cell>47</cell><cell>225</cell></row><row><cell cols="2">Num. of Utterance</cell><cell>8206</cell><cell>493</cell><cell>2405</cell></row><row><cell cols="2">Avg. Len. of Utterance</cell><cell>14</cell><cell>16</cell><cell>15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Results of all models on RECCON-DD. * denotes that our method is significant against the best baseline DAG-ERC (p-value&lt;0.05) with the paired T-test. ‚ñ≥ denotes the results referred from Poria et al.[2021].</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Ablation Study same, and we set them to 2. Following Poria et al. [2021],</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>The macro F1 and Pos. F1 achieved by the variant are80.38 and 65.24. This   </figDesc><table><row><cell>0.9</cell><cell>0.9</cell><cell></cell><cell>0.9</cell><cell></cell><cell>0.9</cell><cell></cell><cell>0.9</cell><cell></cell><cell>1.2</cell><cell></cell><cell>w/o emo emb</cell></row><row><cell>0.3 0.6</cell><cell>0.3 0.6</cell><cell></cell><cell>0.3 0.6</cell><cell></cell><cell>0.3 0.6</cell><cell></cell><cell>0.3 0.6</cell><cell></cell><cell>0.3 0.6 0.9</cell><cell></cell><cell>DAG-ERC KEC (ours)</cell></row><row><cell>0</cell><cell>0</cell><cell></cell><cell>0</cell><cell></cell><cell>0</cell><cell></cell><cell>0</cell><cell></cell><cell>0</cell><cell></cell><cell></cell></row><row><cell>Same Emotion</cell><cell>Different Emotion</cell><cell>Same Emotion</cell><cell>Different Emotion</cell><cell>Same Emotion</cell><cell>Different Emotion</cell><cell>Same Emotion</cell><cell>Different Emotion</cell><cell>Same Emotion</cell><cell>Different Emotion</cell><cell>Same Emotion</cell><cell>Different Emotion</cell></row><row><cell>824</cell><cell>249</cell><cell>193</cell><cell>99</cell><cell>119</cell><cell>62</cell><cell>32</cell><cell>3</cell><cell>56</cell><cell>82</cell><cell>41</cell><cell>7</cell></row><row><cell cols="2">Happiness</cell><cell cols="2">Anger</cell><cell cols="2">Sadness</cell><cell cols="2">Fear</cell><cell cols="2">Surprise</cell><cell cols="2">Disgust</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>The code and Appendix are available at https://github.com/ LeqsNaN/KEC Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by <rs type="funder">National Natural Science Foundation of China</rs> (No. <rs type="grantNumber">61976207</rs>, No. <rs type="grantNumber">61906187</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_hFg2nsD">
					<idno type="grant-number">61976207</idno>
				</org>
				<org type="funding" xml:id="_Z4U3Pc9">
					<idno type="grant-number">61906187</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">COMET: commonsense transformers for automatic knowledge graph construction</title>
		<author>
			<persName><surname>Bosselut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="4762" to="4779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">From independent prediction to reordered prediction: Integrating relative position and global label information to emotion cause identification</title>
		<author>
			<persName><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="6343" to="6350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ECPE-2D: emotion-cause pair extraction based on joint two-dimensional representation, interaction and prediction</title>
		<author>
			<persName><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="3161" to="3170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">End-to-end emotion-cause pair extraction based on sliding window multi-label learning</title>
		<author>
			<persName><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="3574" to="3583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dialoguegcn: A graph convolutional neural network for emotion recognition in conversation</title>
		<author>
			<persName><surname>Ghosal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<editor>
			<persName><forename type="first">Navonil</forename><surname>Ghosal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alexander</forename><forename type="middle">F</forename><surname>Majumder</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rada</forename><surname>Gelbukh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Soujanya</forename><surname>Mihalcea</surname></persName>
		</editor>
		<editor>
			<persName><surname>Poria</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019. 2019. 2020</date>
			<biblScope unit="page" from="2470" to="2481" />
		</imprint>
	</monogr>
	<note>EMNLP-IJCNLP</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">comet-) atomic 2020: On symbolic and neural commonsense knowledge graphs</title>
		<author>
			<persName><surname>Ghosal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<editor>
			<persName><surname>Hwang</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2016">2021. 2021. 2016. 2016. 2021</date>
			<biblScope unit="page" from="6384" to="6392" />
		</imprint>
	</monogr>
	<note>AAAI</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Perspective-taking and pragmatics for generating empathetic responses focused on emotion causes</title>
		<author>
			<persName><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="2227" to="2240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Past, present, and future: Conversational emotion recognition through structural modeling of psychological knowledge</title>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<imprint>
			<date type="published" when="2017">2017. 2017. 2021. 2021. 2021. 2021</date>
			<biblScope unit="page" from="8676" to="8686" />
		</imprint>
	</monogr>
	<note>AAAI</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Roberta: A robustly optimized BERT pretraining approach</title>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<idno>CoRR, abs/1907.11692</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dialogxl: All-in-one xlnet for multi-party conversation emotion recognition</title>
		<author>
			<persName><surname>Majumder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL/IJCNLP</title>
		<imprint>
			<date type="published" when="2019">2019. 2019. 2021. 2021. 2021. 2021</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1551" to="1560" />
		</imprint>
	</monogr>
	<note>AAAI</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Masked label prediction: Unified message passing model for semisupervised classification</title>
		<author>
			<persName><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL/IJCNLP</title>
		<editor>
			<persName><forename type="first">Shuai</forename><surname>Turcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rishita</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kasturi</forename><surname>Anubhai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yaser</forename><surname>Bhattacharjee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Smaranda</forename><surname>Al-Onaizan</surname></persName>
		</editor>
		<editor>
			<persName><surname>Muresan</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021. 2021. 2021</date>
			<biblScope unit="page" from="3975" to="3989" />
		</imprint>
	</monogr>
	<note>IJCAI</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effective inter-clause modeling for end-to-end emotion-cause pair extraction</title>
		<author>
			<persName><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Position bias mitigation: A knowledgeaware graph model for emotion cause extraction</title>
		<author>
			<persName><forename type="first">Ding</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zixiang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL/IJCNLP</title>
		<editor>
			<persName><forename type="first">Yan</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019. 2019. 2019. 2019. 2021</date>
			<biblScope unit="page" from="3364" to="3375" />
		</imprint>
	</monogr>
	<note>IJCAI</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Knowledge-enriched transformer for emotion detection in textual conversations</title>
		<author>
			<persName><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="165" to="176" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
