<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph-based Complexity for Causal Effect by Empirical Plug-in</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-11-15">15 Nov 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rina</forename><surname>Dechter</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of California</orgName>
								<orgName type="institution" key="instit2">Irvine Iowa State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Annie</forename><surname>Raichev</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of California</orgName>
								<orgName type="institution" key="instit2">Irvine Iowa State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Ihler</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of California</orgName>
								<orgName type="institution" key="instit2">Irvine Iowa State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jin</forename><surname>Tian</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of California</orgName>
								<orgName type="institution" key="instit2">Irvine Iowa State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Graph-based Complexity for Causal Effect by Empirical Plug-in</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-11-15">15 Nov 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2411.10008v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>V ′ 0</term>
					<term>V1</term>
					<term>V2</term>
					<term>V3</term>
					<term>V4</term>
					<term>V5</term>
					<term>V6 F (V ′ 0</term>
					<term>V1</term>
					<term>V2</term>
					<term>V3</term>
					<term>V4</term>
					<term>V5) V0</term>
					<term>V1</term>
					<term>V2</term>
					<term>V3</term>
					<term>V4</term>
					<term>V5 F (V0</term>
					<term>V1</term>
					<term>V2</term>
					<term>V3</term>
					<term>V4</term>
					<term>V5) V ′ 0</term>
					<term>V1</term>
					<term>V2</term>
					<term>V3</term>
					<term>V4 F (V ′ 0</term>
					<term>V1</term>
					<term>V2</term>
					<term>V3</term>
					<term>V4) V ′ 0</term>
					<term>V1</term>
					<term>V2 V0</term>
					<term>V1</term>
					<term>V2</term>
					<term>V3 F (V0</term>
					<term>V1</term>
					<term>V2</term>
					<term>V3) V0</term>
					<term>V1 F (V0</term>
					<term>V1) V1</term>
					<term>V2</term>
					<term>V3</term>
					<term>V4</term>
					<term>V5</term>
					<term>V6</term>
					<term>V7</term>
					<term>V8</term>
					<term>V9</term>
					<term>V10V11</term>
					<term>V12</term>
					<term>V13</term>
					<term>V14 F (V2</term>
					<term>V4</term>
					<term>V5</term>
					<term>V7</term>
					<term>V8</term>
					<term>V9</term>
					<term>V11</term>
					<term>V12</term>
					<term>V13</term>
					<term>V14) F (V1</term>
					<term>V3</term>
					<term>V4</term>
					<term>V6</term>
					<term>V7</term>
					<term>V8</term>
					<term>V10</term>
					<term>V11</term>
					<term>V12</term>
					<term>V13) V8</term>
					<term>V12</term>
					<term>V13 F (V8</term>
					<term>V12</term>
					<term>V13) V9</term>
					<term>V13</term>
					<term>V14 F (V9</term>
					<term>V13</term>
					<term>V14) V7</term>
					<term>V11</term>
					<term>V12 F (V7</term>
					<term>V11</term>
					<term>V12) V6</term>
					<term>V10</term>
					<term>V11 F (V6</term>
					<term>V10</term>
					<term>V11) V11</term>
					<term>V12</term>
					<term>V13 F (V11</term>
					<term>V12</term>
					<term>V13)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper focuses on the computational complexity of computing empirical plug-in estimates for causal effect queries. Given a causal graph and observational data, any identifiable causal query can be estimated from an expression over the observed variables, called the estimand. The estimand can then be evaluated by plugging in probabilities computed empirically from data. In contrast to conventional wisdom, which assumes that high dimensional probabilistic functions will lead to exponential evaluation time of the estimand. We show that computation can be done efficiently, potentially in time linear in the data size, depending on the estimand's hypergraph. In particular, we show that both the treewidth and hypertree width of the estimand's structure bound the evaluation complexity of the plug-in estimands, analogous to their role in the complexity of probabilistic inference in graphical models. Often, the hypertree width provides a more effective bound, since the empirical distributions are sparse.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Given a causal graph and data from the observed distribution of a Structural Causal Model (SCM), a causal effect query can be answered by a two step process: First, determine if the query is identifiable, namely if it can be answered uniquely given the graph and observational data, and if so generate an estimand for the query. The estimand is an algebraic expression over probabilistic functions that involve observed variables only. Second, the estimand is evaluated using However, the estimand expression often involves high dimensional conditional probability functions and marginalization over a large number of variables (e.g., see Eq. ( <ref type="formula">8</ref>)). A common assumption is that, for discrete models, the computation required is at least the size of the largest table, and thus exponential in the number of arguments of the largest term in the expression. This assumption suggests that the estimand expression is difficult or impossible to evaluate in highdimensional settings. However, taking into account the data size, the initial sizes of the empirical probability tables are bounded, regardless of the functions' dimension. So, the estimand evaluation can also be bounded in terms of the data size, in some cases linearly.</p><p>Our paper focuses on the complexity of computing plug-in estimates. We explore the impact of both the functions' dimension and the data size on the complexity of evaluation. We show that well-known graph parameters such as tree-width and hypertree width, which play a central role in the complexity of probabilistic inference, play a similar role in plug-in estimand evaluation. It is well known that probabilistic inference is exponential in the tree-width <ref type="bibr" target="#b0">[Dechter, 2003</ref><ref type="bibr" target="#b1">[Dechter, , 2013]]</ref>. However, when a graphical model's functions are sparse (e.g., have many zeros), the hypertree width can provide a tighter exponential bound than treewidth. <ref type="bibr" target="#b6">[Gottlob et al., 2000</ref><ref type="bibr" target="#b10">, Kask et al., 2005</ref><ref type="bibr" target="#b3">, Otten and Dechter, 2008]</ref>. We build on these results to show that the tree-width and hypertree width play a similar role in the complexity of plug-in estimand evaluation. Since, the empirical probabilities are inherently sparse, the hypertree width is often far more informative than the tree-width for this task. We associate an estimand expression with a subexpression hierarchy and show how the hypertree widths of subexpressions additively determine complexity bounds on estimand evaluation. Our bounds help characterize the computational feasibility of the empirical plugin scheme, establishing it as a simple and practical baseline for causal effect estimation. Moreover, since a causal query can have many candidate estimands, tree-width and hyperwidth-based bounds can be used as one metric to selecting among different estimands. Finally, we illustrate the effectiveness of the hypertreewidth in capturing the actual time and memory bounds of empirical plug-in estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>We begin with some useful definitions and notation.</p><p>Definition 1 (Structural Causal Model) A structural causal model (SCM) <ref type="bibr" target="#b14">[Pearl, 2009]</ref> is a 4-tuple M = ⟨U , V , F , P (U )⟩ where: (1) U = {U 1 , U 2 , ..., U k } is a set of exogenous (latent) variables whose values are affected by outside factors;</p><p>(2) V = {V 1 , V 2 , ..., V n } are endogenous, observable variables; (3) F = {f i : V i ∈ V } is a set of functions f i where each f i determines the value</p><formula xml:id="formula_0">v i of V i as a function of V i 's causal parents PA i ⊆ U ∪ (V \ V i ) so that v i ← f i (pa i ); (4) P (U )</formula><p>is a probability distribution over the latent variables. The latent variables are assumed to be mutually independent. i.e., P (U ) = U ∈U P (U ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Causal diagrams. The causal diagram of an SCM</head><p>M is a directed graph G = ⟨V ∪ U , E⟩, where each node represents a variable, and there is an arc in E from a node representing X to a node representing Y iff X is a parent of Y . We assume semi-Markovian SCMs in which latent variables connect to at most two observable variables <ref type="bibr" target="#b18">[Tian, 2002]</ref>. Here it is common to omit latent variables having a single child, and replace any latent variable with a bidirectional dashed arc between the children (see Figure <ref type="figure">2a,</ref><ref type="figure">2b,</ref><ref type="figure">2c</ref>).</p><formula xml:id="formula_1">An SCM M induces a Causal Bayesian Network (CBN) B = ⟨G, P⟩ specified by M's causal diagram G = ⟨V ∪ U , E⟩ along with its associated conditional probability distributions P = {P (V i |PA i ), P (U j )}.</formula><p>The distribution P (V , U ) factors according to the causal diagram:</p><formula xml:id="formula_2">P (V , U ) = Vi∈V P (V i |PA i ) • Uj ∈U P (U j ).</formula><p>(1)</p><p>The observational distribution, P (V ), is given by</p><formula xml:id="formula_3">P (V ) = U P (V , U ). (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>Causal effect and the truncation formula. An external intervention forcing variables X to take on value x, called do(X = x), is modeled by replacing the mechanism for each X ∈ X with the function X = x. Formally,</p><formula xml:id="formula_5">P (V \X, U | do(X = x)) = Vj / ∈X P (V j |PA j )•P (U )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X=x</head><p>(3) Namely, it is obtained from Eq. ( <ref type="formula">1</ref>) by truncating the factors corresponding to the variables in X and setting X = x. The effect of do(X) on a variable Y , denoted P (Y |do(X)), is defined by marginalizing all the variables other than Y .</p><p>The standard formulation of causal inference assumes that we only have access to the causal graph G and the observational distribution P (V ) (or a sample from it). The identifiability task is to determine if the query can be uniquely answered from G and P (V ). This occurs if the answer is unique for any full model that is consistent with the graph and P (V ) <ref type="bibr" target="#b14">[Pearl, 2009]</ref>. In such cases an estimand expression in terms of P (V ) can be generated and evaluated.</p><p>Definition 2 (Causal-effect query) Given a causal diagram G = ⟨V ∪ U , E⟩, data samples from the observational distribution P (V ), and an identifiable query P (Y | do(X)), the task is to compute the value of P (Y | do(X)).</p><p>Estimand-based approaches. The now-standard methodology for answering causal-effect queries is to break the task into two steps. The first is the identifiability step: given a causal diagram and a query P (Y | do(X)), determine if the query is identifiable and if so, generate an estimand, or algebraic expression in terms of the observational distribution P (V ) that answers the query. A complete polynomial algorithm called ID has been developed for this task <ref type="bibr">[Tian, 2002, Shpitser and</ref><ref type="bibr" target="#b17">Pearl, 2006]</ref>. The second step is estimation: use samples from the observational distribution P (V ) to estimate the value of the estimand expression. A number of approaches have been applied to estimation. A simple approach, called the plug-in estimator, replaces each term in the estimand with its empirical probability value in the observed data. More sophisticated approaches have been developed recently <ref type="bibr">[Jung et al., 2020a</ref><ref type="bibr">,b, Raichev et al., 2024]</ref>.</p><p>A CBN and SCM belong to the class of probabilistic graphical models. A graphical model is defined by a collection of functions over subsets of variables: Definition 3 A probabilistic graphical model is a triplet M = ⟨X, D, F ⟩ where X = {X 1 , . . . , X n } is a set of variables with finite domains D = {D 1 , . . . , D n }, and F = {f 1 , . . . , f r } is a set of discrete real-valued functions, each defined over a subset of variables S i ⊆  X, called its scope and denoted by scope(f i ). The product of all the function in the model defines a probability distribution (Bayesian networks or Markov network) and a variety of reasoning problems can be defined using marginalization operator such as sum X , max X . The primal graph of a graphical model is an undirected graph whose nodes are the variables and edges connect every two nodes that appear in the scope of a single function. The dual graph is a graph whose nodes are the scopes {S 1 , ..., S r } of the functions, with edges connecting any two nodes whose scopes share variables. The hypergraph of a graphical model has the variables as its nodes and the hyperedges are again the scopes of the functions.</p><p>A Bayesian network over X = {X 1 , . . . , X n } is a probabilistic graphical model with f i (X i , P A Xi ) = P (X i |P A Xi ) for i = 1, . . . , n.</p><p>Example 1 Consider the belief network in Figure <ref type="figure" target="#fig_1">1a</ref>. It contains variables A, B, C, D, F, G and functions</p><formula xml:id="formula_6">f (A, B), f (A, C), f (B, C, F ), f (A, B, D), f (F, G).</formula><p>The primal graph of the model is depicted in Figure ??. The dual graph and hypergraph are not explicitly illustrated here, for space reasons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph concepts</head><p>Graphs are an integral components of graphical models, so we next define well-known concepts over graphs and hypergraphs and their relation to graphical models. For more details see <ref type="bibr" target="#b10">Kask et al. [2005]</ref>, <ref type="bibr" target="#b1">Dechter [2013]</ref>, <ref type="bibr" target="#b7">Gottlob et al. [2014]</ref>.</p><p>Definition 4 (hypergraph) The hypergraph of a graphical model M =&lt; X, D, F &gt; is a pair H = (V , ST ) where V = X and is a set of subsets of V , called hyper-edges, The primal graph of a hypergraph H = (V , ST ) is an undirected graph G = (V , E) such that there is an edge (u, v) ∈ E for any two vertices u, v ∈ V that appear in the same hyperedge. The dual graph of a hypergraph is a graph where each hyperedge is a node, and two nodes are connected by an edge if their nodes have non-empty intersection.</p><p>Definition 5 (hypertree) A hypergraph is a hypertree, also called acyclic, if its dual graph has an edge subgraph that is a tree (called a join-tree) satisfying that all its nodes that contain a common variable form a connected subgraph. This condition is also known as the "running intersection property" or the "connectedness property". A join-graph is an edge subgraph of the dual graph that satisfies the conectedness property. If the hypergraph of a graphical model is a hypertree, the graphical model is called acyclic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tree and Hypertree Decompositions</head><p>Tree decomposition schemes have been widely used for constraint processing and probabilistic reasoning. The most popular variants are join-tree (also known as junction-tree) algorithms, which include variable elimination schemes <ref type="bibr" target="#b0">[Dechter, 2003</ref><ref type="bibr" target="#b6">, Gottlob et al., 2000</ref><ref type="bibr" target="#b1">, Dechter, 2013]</ref>. The methods vary somewhat in their graph definitions as well as the way the tree decomposition is processed. However, all involve a decomposition of a hypergraph of a graphical model into a hypertree:</p><p>Definition 6 (tree &amp; hypertree decompositions) <ref type="bibr" target="#b10">[Kask et al., 2005</ref><ref type="bibr" target="#b6">, Gottlob et al., 2000]</ref> A treedecomposition of a graphical model M = ⟨X, D, F ⟩ is a triplet ⟨T, χ, ψ⟩, where T = (V , E) is a tree, and χ and ψ are labeling functions that associate with each vertex v ∈ V two sets, χ(v) ⊆ X and ψ(v) ⊆ F , that satisfy the following conditions:</p><p>1. For each function f i ∈ F , there is exactly one</p><formula xml:id="formula_7">vertex v ∈ V such that f i ∈ ψ(v). 2. If f i ∈ ψ(v), then scope(f i ) ⊆ χ(v). 3. For each variable X i ∈ X, the set {v ∈ V |X i ∈ χ(v)</formula><p>} induces a connected subtree of T . This is also called the running intersection or the connectedness property.</p><p>The treewidth w of a tree-</p><formula xml:id="formula_8">decomposition τ = ⟨T, χ, ψ⟩ is max v∈V |χ(v)| -1.</formula><p>The treewidth of a graphical model is the minimum treewidth over all its tree-decompositions.</p><p>The tree-decomopsition τ is also called a hypertree decomposition of the graphical model if it satisfies the additional condition that the variables in each node, also called a cluster, are covered by the arguments of the functions in the cluster. Formally:</p><formula xml:id="formula_9">4. For each v ∈ V , χ(v) ⊆ ∪ fj ∈ψ(v) scope(f j ).</formula><p>In this case the hypertree width of τ is hw = max v |ψ(v)|. The hypertree-width of a graphical model is the minimum hypertree width over all possible hypertree decompositions of the graphical model.</p><p>Finding tree or hypertree decompositions having the minimal treewidth or hyperwidth is known to be NPhard. Although optimizing the hypertree width is harder in the sense that verifying that a graph has a hypertree width smaller than w is not polynomial like it is for treewidth <ref type="bibr">[Gottlob and</ref><ref type="bibr">Samer, 2008, Schidler and</ref><ref type="bibr" target="#b16">Szeider, 2023]</ref>. Heuristic algorithms are employed in practice for both parameters; most of these center on finding a good ordering of the variables that leads to a small treewidth or hyperwidth. For details see <ref type="bibr" target="#b0">Dechter [2003]</ref>, <ref type="bibr" target="#b11">Kask et al. [2011]</ref>, <ref type="bibr" target="#b7">Gottlob et al. [2014]</ref>, <ref type="bibr" target="#b4">Gogate and Dechter [2012]</ref>.</p><p>Example 2 (Taken from <ref type="bibr" target="#b10">Kask et al. [2005]</ref>) Consider the belief network in Figure <ref type="figure" target="#fig_1">1a</ref> with hypertree decomposition in Figure <ref type="figure" target="#fig_1">1b</ref>. Here the labeling χ is the set of variables in each node. The functions can be assigned to nodes whose χ variables contain their scopes.</p><p>For example, any function with scope {G} must be placed in vertex (GF ) because it is the only vertex that contains variable G. Alternatively, any function with scope {F } can be placed either in vertex (F G) or (BCF ).</p><p>Relational vs. tabular representation. The common brute-force method for specifying functions as a table is exponential in their scopes, where the base of the exponent is the maximum domain size k.</p><p>We can also assume a relational specification where all the tuples that are mapped to a value "0" are removed (e.g., zero probabilities) from the table. In this case, the function is specified by t tuples of length l for functions defined over scopes of size l variables. The value t is often referred to as the tightness of the function representation. Clearly, the size of the specification can be far smaller than the worst-case of O(k l ). In this paper we will assume that functions are always specified relationally.</p><p>Definition 7 (tightness) The tightness of a function f , t(f ), is the number of non-zero configuration in its domain. The tightness of a graphical model having the set of functions F is t = max f ∈F t(f ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Complexity of Tree Decomposition</head><p>Once a (hyper) tree-decomposition of a graphical model is generated, any sum-product query (e.g., P (X|Y = y) where X and Y are subsets of variables) can be answered by a message passing algorithm where each vertex of the tree sends a function to each of its neighbors. We will use Cluster-tree Elimination (CTE) <ref type="bibr" target="#b10">[Kask et al., 2005]</ref> as a generic name for a message passing algorithm over a tree-decomposition.</p><p>Algorithm CTE. The following 3 steps define the basics of the CT E algorithm <ref type="bibr" target="#b10">[Kask et al., 2005]</ref>. Given a hypertree decomposition, each node u has to send a single message to each neighbor v. We can compute m (u,v) as follows:</p><p>1. Combine all functions ψ(u) in node u yielding function h(u) = f ∈ψ(u) f , (assuming the combination is a product). This step can be done in time and space O(t |ψ(u)| ). In particular, the tightness of the product function is 3. Make m (u,v) ← h(u).</p><formula xml:id="formula_10">O(t |ψ(u)| ). 2. For each neighbor c of u, c ̸ = v iterate the follow- ing h(u) ← h(u) • χ(u)∩χ(c) m (c,</formula><p>The following bounds of algorithm CT E as a function of the treewidth and hyperwidth are restated from the literature, with a slight simplification to account for one way message-passing.</p><p>Theorem 1 (Graph-based complexity of CTE) <ref type="bibr" target="#b10">[Kask et al., 2005</ref>] Given a graphical model M = ⟨X, D, F ⟩ and a hypertree-decomposition ⟨T, χ, ψ⟩, let n be the number of variables in X, w its treewidth, hw its hypertree width and t its tightness, and k the maximum domain size of a variable. A sum-product query can be computed by CT E within the two following bounds: 1. as a function of the treewidth: Thus, if we have a hypertree decomposition and a tree T that can guide search algorithms such depth-first or best-first search with, caching yielding bounds that are exponentially in the hypertree width. In summary:</p><formula xml:id="formula_11">O(n • k w+1 ) time</formula><p>Theorem 3 Given a graphical model M, and a hypertree-decomposition having hypertree width hw, the sum-product query can be answered by searching the AND/OR search graph in O(n • t hw ) time and O(t hw ) space when t bounds the function tightness and n is the number of variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Causal Effect Estimand Evaluation</head><p>We use these results to analyze the plug-in evaluation of causal queries' estimands. The notion of empirical Bayesian networks is central to this evaluation.</p><p>Empirical Bayesian Network. Given a directed graph G whose nodes are discrete variables X = {X 1 , . . . , X n } and given a data set D = {d 1 , . . . d t } over the variables, the empirical Bayesian network, empBN (G, D), is the Bayesian network (BN) whose graph is G and its functions are the empirical CPTs extracted from the dataset D. That is, any entry (x, pa X ) in the empirical CPT P D (X = x|P A X = pa X ) for a variable X and its parents P A X in the G is obtained by counting the number of appearances</p><formula xml:id="formula_12">V0 V1 V2 V3 V4 V5 V6 (a) Chain V0 V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 (b) Cone Cloud V0 V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 (c) Diamond T X0 X1 X2 V0 V3 V6 V9 Z V1 V2 V4 V5 V7 V8 V10 V11 (d) 3-Layer Figure 2: Causal Graphs of (x, pa X ) in D, divided by the number of appear- ances of pa X in D. Formally, P D (x|pa X ) = #D(x,pa X ) #D(pa X )</formula><p>where #D(s) is the number of elements in D that are consistent with s.</p><p>It is easy to see that the number of non-zero configurations of any CPT Implication to estimands evaluation. We show a causal effect estimand can be associated with a hierarchy of empirical Bayesian networks so that evaluating the sum-product inference on each will yield the estimand evaluation. Applying a hypertree decomposition algorithm like CT E to each sub-expression will yield an effective estimand evaluation scheme whose performance would be bounded by the graph parameters of treewidth and hyperwidth. We first illustrate via several examples. Example 3 Consider the model in Figure <ref type="figure">2a</ref>. To evaluate the query P (V 6 | do(V 0 )), the ID algorithm <ref type="bibr">[Tian, 2002, Shpitser and</ref><ref type="bibr" target="#b17">Pearl, 2006]</ref> generates the expression:</p><formula xml:id="formula_13">F (V7, V ′ 10, V ′ 11, V ′ 12) V ′ 11, V ′ 12 F (V ′ 11, V ′ 12)</formula><formula xml:id="formula_14">P (V6 | do(V0)) = V 1 ,V 2 ,V 3 ,V 4 ,V 5</formula><p>P (V5|V0, V1, V2, V3, V4)× P (V3|V0, V1, V2) P (V1|V0)</p><p>V 0 P (V6|V0, V1, V2, V3, V4, V5)</p><p>× P (V4|V0, V1, V2, V3)P (V2|V0, V1) P (V0). ( <ref type="formula">6</ref>)</p><p>By variable renaming of the summation variables in the second sum and moving all summations to the head of the expression we get an equivalent expression (in this case we rename v 0 to v ′ 0 ), yielding:</p><formula xml:id="formula_15">P (V6 | do(V0)) = V 1 ,V 2 ,V 3 ,V 4 ,V 5 ,v ′ 0 P (V5|V0, V1, V2, V3, V4)</formula><p>× P (V3|V0, V1, V2) P (V1|V0)P (V6|V ′ 0 , V1, V2, V3, V4, V5) × P (V4|V ′ 0 , V1, V2, V3) P (V2|V ′ 0 , V1) P (V ′ 0 ). ( <ref type="formula">7</ref>)</p><p>The latter expression corresponds to a sum-product reasoning task over a Bayesian network defined by the 7 CPTs in Expression (7). A hypertree decomposition with hw = 1 is given in Figure <ref type="figure">3</ref>. By Theorem 4, the expression can be computed by CT E in time O(n • logt • t) where t is the data size (so t bounds the tightness of the Empirical BN). In contrast the treewidth of this tree-decomposition has w = 6, a potentially loose bound. Generally, for chains of length n, the treewidth is w = n-1, leading to an exponential bound of O(n • k n ) while the hyperwidth stays hw = 1.</p><p>Clearly, the hyperwidth provides a far tighter and more informative bound for large chains.</p><p>Example 4 Consider the estimand expression in Eq. ( <ref type="formula">8</ref>), obtained from a 15 variable cone-cloud graph (Figure <ref type="figure">2b</ref>). Once we rename the variables in the inner sums and move the summation variables to the head the first sum, we get the expression Eq. (9). Here Eq. (9) can be viewed as a sum-product inference over a probabilistic graphical model. In this case however the hypergraph is not a hypertree; but it can be embedded in a hypertree having hw = 2, depicted in Figure <ref type="figure" target="#fig_2">4</ref> (the top cluster includes 2 functions). Therefore the complexity of evaluating this expression by</p><formula xml:id="formula_16">CT E is O(n • log t • t 2 ).</formula><p>The treewidth is w = 14 (there is a cluster with 15 variables) leading to a bound of O(nk 15 ) time.</p><formula xml:id="formula_17">P (V0|do(V14, V10, V4)) = V 1 ,V 2 ,V 3 ,V 5 ,V 6 ,V 7 ,V 8 ,V 9 ,V 11 ,V 12 ,V 13 P (V2|V4, V5, V7, V8, V9, V11, V12, V13, V14)P (V9|V13, V14)× P (V8|V12, V13)P (V1|V3, V4, V6, V7, V8, V10, V11, V12, V13)P (V7|V11, V12)P (V6|V10, V11)P (V11, V12, V13)× V ′ 10 ,V 11 ,V 12 ,V 13 ,V ′ 14 P (V0|V1, V2, V3, V4, V5, V6, V7, V8, V9, V ′ 10 , V11, V12, V13, V ′ 14 )P (V3, V13|V6, V7, V ′ 10 , V11, V12)P (V11, V12)× P (V5|V1, V3, V4, V6, V7, V8, V9, V ′ 10 , V11, V12, V13, V ′ 14 )P (V ′ 14 |V1, V3, V4, V6, V7, V8, V ′ 10 , V11, V12, V13)P (V ′ 10 |V7, V11, V12) (8) K P (V0|do(V14, V10, V4)) = V 1 ,V 2 ,V 3 ,V 5 ,V 6 ,V 7 ,V 8 ,V 9 ,V 11 ,V 12 ,V 13 ,V ′ 10 ,V ′ 11 ,V ′ 12 ,V ′ 13 ,V ′ 14 P (V2|V4, V5, V7, V8, V9, V11, V12, V13, V14)</formula><p>× P (V9|V13, V14)P (V8|V12, V13)P (V1|V3, V4, V6, V7, V8, V10, V11, V12, V13)P (V7|V11, V12)P (V6|V10, V11)P (V11, V12, V13)</p><formula xml:id="formula_18">× P (V0|V1, V2, V3, V4, V5, V6, V7, V8, V9, V ′ 10 , V ′ 11 , V ′ 12 , V ′ 13 , V ′ 14 )P (V5|V1, V3, V4, V6, V7, V8, V9, V ′ 10 , V ′ 11 , V ′ 12 , V ′ 13 , V ′ 14 ) × P (V3, V ′ 13 |V6, V7, V ′ 10 , V ′ 11 , V ′ 12 )P (V ′ 14 |V1, V3, V4, V6, V7, V8, V ′ 10 , V ′ 11 , V ′ 12 , V ′ 13 )P (V ′ 10 |V7, V ′ 11 , V ′ 12 )P (V ′ 11 , V ′ 12 ) (9)</formula><p>Ratio estimands. It is sometime the case that estimands include ratios of expressions. How should we treat those? One option is to treat a denominator expression as a distinct sum-product expression which connects to its numerator by its "output function". This suggests a sub-expressions hierarchy which dictates a sum-product processing order. The components of the hierarchy are flattened sum-product subexpressions as seen in the previous examples, where each corresponds to a sum-product expression over a probabilistic graphical model. Each layer in the hierarchy is a single expression and its sum-product output function is processed by CT E over its own hypertree decomposition. These output functions will connect the layers in a chain heirarchy, where the output function from each layer is included in the sub-expression of its parent layer. We show the details in the next example followed by the general evaluation algorithm.</p><formula xml:id="formula_19">W R X Y (a) Causal Graph X, Y, R, W F (X, Y, R, W ) W F (W ) X, R g(X, R) W ′ F (W ′ ) X, R, W ′ F (X, R, W ′ ) X, R O1(X, R) X, Y O2(X, Y ) (b) Heirarchy Hypergraph</formula><p>Example 5 Consider the ratio estimand expression associated with the Napkin model of Figure <ref type="figure" target="#fig_3">5a</ref>.</p><formula xml:id="formula_20">P (Y |do(X)) = W P (X, Y |R, W )P (W ) W ′ P (X|R, W ′ )P (W ′ )</formula><p>The denominator expression is composed of 2 functions whose scopes are the two sets W ′ and X, R, W ′ . The corresponding dual graph is depicted underneath the red arrow in Figure <ref type="figure" target="#fig_3">5b</ref>. The output function for this sum-product is a new function O 1 (X, R) whose inverse g(X, R) = 1 O1(X,R) will be noted as a factor of its numerator. The red arrow emanating from node O 1 with arguments {X, R} indicates that the function will be generated in that child layer and will be used in the parent layer. The sum-product at the top layer of the hierarchy has 4 nodes corresponding to 4 functions; 2 in the numerator, one is the function g(X, R) generated by the child expression, and O 2 is the output function produced as a result of the summation over W . Since, the denominator expression has hw = 1, the tightness of the output function g(X, R) remains bounded by t 1 = t (the data size). Since the numerator's expression including the output function g(X, R) also has hw = 1, the overall hyperwidth of the hierarchy of this estimand is hw = 1 and since the tightness does not change, the computation would be linear in the tightness which is bounded by the data size.</p><p>Due to the flattening process each sum-product ex-pression will have a single sum-product child from a denominator (see the hierarchy graph in Figure <ref type="figure" target="#fig_3">5b</ref>). We next provide more details.</p><p>Definition 8 (sum-product chain hierarchy) Given an estimand whose expressions are all flattened. The nodes of the sum-product hierarchy are flat sum-product expressions. The top layer is the numerator sum-product expression. Each denominator sum-product expression is a child of its direct numerator sum-product expression.</p><p>The function generated by a sum-product computation is called its output function.</p><p>Algorithm 1 describes our plug-in hypertree evaluation (PI-HTE) algorithm. Its input is an estimand and a dataset. The first step is flattening, where for each sum-product expression the summation variables are renamed in all the functions within the summation's scope.</p><p>Step 2 creates the sum-product chain hieararchy as defined above. In steps 3-10 the algorithm processes the sum-product hierarchy in order from leaf to root. When layer i is processed, its empirical BN is well defined. Then a hypertree decomposition is created by a hypertree decomposition scheme, taking into account the output function obtained from its child level, to which CT E can be applied producing its own output function O i . The output function is then inverted (step 9) and incorporated into the dual graph of the parent, and computation continues with the parent layer. The answer is obtained in the output function of the root layer.</p><p>Theorem 5 (soundness) Algorithm PI-HTE is sound for estimand evaluation given a dataset.</p><p>Complexity. We associate the dual graph of level i with a hypertree decomposition having hyperwidth hw i and treewidth w i . The complexity of computing the output function in each level is dominated by t hwi and k wi . Thus, the overall complexity is controlled by the treewidths and hypertree widths over all the levels. This seems to imply that complexity is exponential in the largest hw and the largest w; however, for hypertree width the complexity can be more involved. The tightness of the output functions may no longer be bounded by the data size t. Rather, the worst-case tightness of O i is t hwi . The following theorem summarizes. Since the dominant factors in the complexity are t hw , and k w ), for simplicity we will drop the logt factor appearing in the complexity bound.</p><p>Theorem 6 (complexity) Given an estimand expression having sum-product hierarchy of depth l, algorithm PI-HTE has time and space complexity O(n • t l i=1 hwi ), where n is the number of variables, t the Algorithm 1 Plug-In Hypertree Evaluation (PI-HTE) Input: data D, and estimand expression for P (Y | do(X)) over a given DAG G. Output: an estimate of P (Y | do(X))</p><p>1. Flatten sum-products by renaming and moving all summations to the front. 2. Generate a hierarchy of sum product expressions. 3. Let P be the lowest sum-product expression. 4. While P has a parent expression do 5.</p><p>Let G be the DAG defined by functions in P 6.</p><p>Generate empBN (G, D) 7.</p><p>Generate a hypertree H P over empBN (P, D) aiming for min(hw P ). 8.</p><p>O P ← CT E(H P ) 9.</p><p>g P = 1 O P ; parent(P ) = parent(P ) ∪ {g P } 10. P ← parent(P ) 11. EndWhile 12: Return P (Y | do(X)) tightness, and hw i is the hypertree width of the expression at level i. The algorithm's complexity is also</p><formula xml:id="formula_21">O(n • k max l i=1 {(wi)}</formula><p>) where w i is the treewidth of the expression at level i.</p><p>Proof 2 (proof by induction) Case 1: It is clear that if we have no denominators the estimand has only one level. This defines a sum-product product expression. Since it can be viewed as an empirical Bayesian network having tightness t it can be processed in O(n•t hw ) (Theorem 4), or by O(n • t w+1 ). This proves the base case of l=1. When l &gt; 1 the inductive hypothesis for level i -1 assumes that the effective hyper-width for that level is i-1 j=1 hw j . This implies that its output function, O i-1 , computed at level i -1 has tightness bounded also by t i-1 j=1 hwj . The output function O i-1 is placed at the parent level i, and grouped in one of the clusters with at most hw i functions having tightness t in that level. The product of hw i functions of tightness t with the single O i-1 function having tightness t i-1 j=1 hwj yields computation of at most</p><formula xml:id="formula_22">O(t hwi • t i-1 j=1 hwj ) = O(t i j=1 hwj</formula><p>). Thus the effective hyperwidth grows additively with each level both time and memory, yielding the claim. The bound based on treewidth is not dependant on the tightness but only on the domain size and we therefore get that the relevant treewidth that dominates the computations is the maximum treewidth over the whole hierarchy. Note that when O i-1 resides in its own cluster in the tree decomposition of its parent level i, the effective hyperwidth of level i is just the max between the hyperwidth of the child expression and its parent expression. If this occurs at each level the effective hyperwidth of the whole computation is the maximum hyperwidth over all levels. In this case the bound is O(t max i j=1 hwj ). For benchmarks we used three semi-markovian examples, and one markovian (without latent confounding). The semi-markovian examples were taken from <ref type="bibr">Raichev et al. [2024]</ref>, and the markovian example was constructed to have higher hyperwidth. Since, O(t hw ) is a worst case bound we ran our algorithm on various data sets, and present results that are close to worst case. We sampled data different distributions: uniform, deterministic, Dirichlet, and their mixes. Queries were chosen to correspond to complex estimands that could pose computational challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Measures</head><p>We report the time and max </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>The empirical plug-in results with varying sample sizes are presented in Table <ref type="table" target="#tab_3">1</ref> on the Chain, Cone-cloud, Diamond, and 3-layer models (Figure <ref type="figure">2</ref>). We show that the complexity for estimand evaluation is reflected in the hyperwidth associated with the estimand, and it provides a much tighter bound than the treewidth.</p><p>The disparity between bounds is most evident in the Chain model where we have hyperwidth of one, thus computation is linear in the tightness; but the treewidth is 98, with max domain size k = 4. So bounding the space and time complexity in the treewidth we get O(k 99 ) ≈ 4 × 10 59 for time and O(k 98 ) ≈ 1×10 59 for space, giving us a loose and irrelevant bound. Even with 10,000 samples and t = 10, 000 the bound from the hyperwidth is O(t 1 ) = O(10, 000 1 ), showing it's a more informative bound.</p><p>We also show that the performance can be non-linear. For example, in the case of the Cone-cloud and Diamond models, both with hw = 2. Here t vs time and t vs max table size are both O(t 2 ). For example when t = 1, 000 the max table size for the cone-cloud and diamond, respectively, is 882,604 and 928,510, just under 1, 000 2 . We also see that t vs time grows faster than linearly, and is O(t 2 ). Again, the treewidth is much higher than the hyperwidth, and the max(k) is 10 and 50, so the treewidth bound is large and uninformative.</p><p>In the 3-layer model we have hyperwidth 4 and treewidth 15, with a max domain size of 50. The relationship of t vs time and t vs max table size appears roughly cubic. So, while the worst-case is not realized we see significant impact of the hyperwidth. On the other hand, we do not see any values getting as high as the treewidth suggests (O(50 15 )).</p><p>Since the tightness can increase with number of samples, the bound dictated by the hyperwidth can increase with number of samples. This is something to consider if you have a large number of samples with dense tables.</p><p>Hypertree decompositions and estimands for the 3layer and Diamond models are provided in the Supplemental.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The paper provides a new algorithm and analysis for evaluating plug-in estimands for causal effect queries. The approach uses structural parameters, the treewidth and hypertree width, in bounding the complexity of plug-in estimand evaluation, similar to their role in graphical models schemes. We show that the hypertree width is more informative for this task because of its sensitivity to function sparseness, and evaluating plug-in estimands from data yields sparse functions.</p><p>We introduce a new algorithm Plug-in hypertree evaluation (PI-HTE) which harnesses hypertree decomposition algorithms to efficiently estimate the estimand, and we evaluate its performance over several classes of benchmarks and causal effect queries. Our results confirm the significance of the hypertree parameter in capturing the algorithm's performance and its superiority over the treewidth parameter in the context of causal effect evaluation. In particular, it enables the evaluation of estimands previously thought to be computationally infeasible.</p><p>Our bounds help characterize the computational feasibility of the empirical plug-in scheme, establishing it as a simple and practical baseline for causal effect estimation. In particular, since a causal query can have many candidate estimands, tree-width and hyperwidth-based bounds can be used as one metric to selecting among different estimands. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graphical Model And Its Tree Decomposition</figDesc><graphic coords="3,63.00,72.00,105.30,100.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Cone-cloud Estimand's Hypertree with hw = 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Napkin Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>u) . This step can be accomplished in O(deg •hw •log t•t hw ) time and O(t hw ) space, deg can be dropped if messages are sent only from leaves to root.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>answered by traversing the AND/OR search graph in 1. O(n • k w+1 ) time and O(k w ) space, and 2. in O(n • t hw ) time and O(t hw ) space.</figDesc><table><row><cell>2.4 Complexity of AND/OR search It was shown that AND/OR search spaces can also reflect problem decomposition captured explicitly in the search space using AND nodes. When caching of nodes that root identical search subspace via what is known as context-identical nodes [Dechter and Ma-teescu, 2007] we get a compact AND/OR search space and it allows bounding the AND/OR search graph size by O(nk w+1 ) where w is the treewidth of the tree-decomposition of the model [Dechter and Ma-teescu, 2007]. It was subsequently shown [Dechter et al.Proof 1 We can build a pseudo-tree that corresponds to the join-tree underlying the acyclic hypergraph. The context size of each variable is at most the scope of each function in the acyclic graphical model. It is clear that only tuples over the context variables that appear in the relational specification of the function will be ac-counted for in the AND/OR search graph (the rest are associated with "0", so they are inconsistent, or their probability is "0"), yielding O(r • t) contexts and there-fore, nodes, in the context-minimal AND/OR search graph. Theorem 2 (Graph-based complexity of search) [Dechter and Mateescu, 2007, Otten and Dechter, 2008]</cell></row></table><note><p><p><p>and O(nk w ) space (4) 2. as a function of the hyperwidth:</p>O(n • hw • log t • t hw )</p>time and O(t hw ) space (5) , 2008] that the hypertree width can also be used to bound the AND/OR search graph size. Consequently, search algorithms such as depth-first or bestfirst search that traverse the AND/OR search graph inherit those bounds, which turns out to be very similar to those obtained by CT E. Any sum-product query can be M = ⟨X, D, F ⟩ and a hypertree-decomposition τ = ⟨T, χ, ψ⟩, having hypertree width hw, treewidth w, t is the tightness, k the domain size, and n is the number of vertices. Then, any sum-product query can be answered by traversing the AND/OR search graph in 1. O(n • k w+1 ) time and O(k w ) space, and 2. in O(n • t hw ) time and O(t hw ) space.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Empirical plug-in results for different sample sizes. Here t is the tightness of the data, and k is the variables' domain sizes.</figDesc><table><row><cell></cell><cell cols="4">(a) Chain: P (V99|do(V0))</cell></row><row><cell></cell><cell cols="5">|V | = 99; |U | = 49 hw = 1, tw=98</cell></row><row><cell></cell><cell cols="4">P (V98|V 0, . . . V97)-largest factor</cell></row><row><cell>#Samples</cell><cell>time</cell><cell cols="2">Max table size</cell><cell>t</cell><cell>density</cell></row><row><cell>100</cell><cell>11.2</cell><cell></cell><cell>100</cell><cell>100</cell><cell>9.9 × 10 -34</cell></row><row><cell>200</cell><cell>19.7</cell><cell></cell><cell>200</cell><cell>200</cell><cell>2.0 × 10 -33</cell></row><row><cell>400</cell><cell>31.4</cell><cell></cell><cell>400</cell><cell>400</cell><cell>3.9 × 10 -33</cell></row><row><cell>800</cell><cell>53.7</cell><cell></cell><cell>800</cell><cell>800</cell><cell>7.9 × 10 -33</cell></row><row><cell>1,000</cell><cell>69.5</cell><cell></cell><cell>1,000</cell><cell>1,000</cell><cell>1.0 × 10 -32</cell></row><row><cell>1,600</cell><cell>97.5</cell><cell></cell><cell>1,600</cell><cell>1,600</cell><cell>1.6 × 10 -32</cell></row><row><cell>3,200</cell><cell>192.4</cell><cell></cell><cell>3,200</cell><cell>3,200</cell><cell>3.2 × 10 -32</cell></row><row><cell>6,400</cell><cell>369.2</cell><cell></cell><cell>6,400</cell><cell>6,400</cell><cell>6.4 × 10 -32</cell></row><row><cell>10,000</cell><cell>608.8</cell><cell></cell><cell>10,000</cell><cell cols="2">10,000</cell><cell>9.9 × 10 -32</cell></row><row><cell cols="6">(b) Cone Cloud P (V0|do(V14, V10, V4))</cell></row><row><cell cols="6">|V | = 15; |U | = 8; k = 10; hw = 2; tw = 14</cell></row><row><cell></cell><cell cols="4">largest factor P (V0|V1 . . . V14)</cell></row><row><cell>#Samples</cell><cell cols="2">time (s)</cell><cell cols="2">Max table size</cell><cell>t</cell><cell>density</cell></row><row><cell>100</cell><cell>2.2</cell><cell></cell><cell>9,900</cell><cell cols="2">100</cell><cell>1e-13</cell></row><row><cell>200</cell><cell>3.3</cell><cell></cell><cell>39,203</cell><cell cols="2">200</cell><cell>2e-13</cell></row><row><cell>400</cell><cell>7.3</cell><cell></cell><cell>152,877</cell><cell cols="2">400</cell><cell>4e-13</cell></row><row><cell>800</cell><cell>28.8</cell><cell></cell><cell>589,815</cell><cell cols="2">800</cell><cell>8e-13</cell></row><row><cell>1,000</cell><cell>39.1</cell><cell></cell><cell>882,604</cell><cell cols="2">1,000</cell><cell>1e-12</cell></row><row><cell>1,600</cell><cell>84.8</cell><cell></cell><cell>2,206,528</cell><cell cols="2">1,600</cell><cell>1.6e-12</cell></row><row><cell>3,200</cell><cell>280.3</cell><cell></cell><cell>7,553,700</cell><cell cols="2">3,200</cell><cell>3.2e-12</cell></row><row><cell>6,400</cell><cell>788.74</cell><cell></cell><cell>21,949,125</cell><cell cols="2">6,400</cell><cell>6.4e-12</cell></row><row><cell>10,000</cell><cell>1,594.2</cell><cell></cell><cell>40,404,630</cell><cell cols="2">10,000</cell><cell>1e-11</cell></row><row><cell cols="6">(c) Diamond Model, P (V16|do(V0, V4))</cell></row><row><cell></cell><cell cols="4">|V | = 17;k = 10; hw = 2, tw=16</cell></row><row><cell></cell><cell cols="4">P (V16|V0, . . . V15)-largest factor</cell></row><row><cell>#Samples</cell><cell>time (s)</cell><cell></cell><cell>Max table size</cell><cell>t</cell><cell>density</cell></row><row><cell>100</cell><cell>0.6</cell><cell></cell><cell>8,672</cell><cell>100</cell><cell>1 × 10 -15</cell></row><row><cell>200</cell><cell>1.9</cell><cell></cell><cell>35,605</cell><cell>200</cell><cell>2 × 10 -15</cell></row><row><cell>400</cell><cell>6.9</cell><cell></cell><cell>156,160</cell><cell>400</cell><cell>4 × 10 -15</cell></row><row><cell>800</cell><cell>26.4</cell><cell></cell><cell>603,790</cell><cell>800</cell><cell>8 × 10 -15</cell></row><row><cell>1,000</cell><cell>39</cell><cell></cell><cell>928,510</cell><cell cols="2">1,000</cell><cell>1 × 10 -14</cell></row><row><cell>1,600</cell><cell>87.4</cell><cell></cell><cell>2,184,880</cell><cell cols="2">1,600</cell><cell>1.6 × 10 -14</cell></row><row><cell>3,200</cell><cell>299.4</cell><cell></cell><cell>7,600,350</cell><cell cols="2">3,200</cell><cell>3.2 × 10 -14</cell></row><row><cell>6,400</cell><cell>988.8</cell><cell></cell><cell>22,208,750</cell><cell cols="2">6,400</cell><cell>6.4 × 10 -14</cell></row><row><cell>10,000</cell><cell>2,037.5</cell><cell></cell><cell>39,943,750</cell><cell cols="2">10,000</cell><cell>1 × 10 -13</cell></row><row><cell></cell><cell cols="5">(d) 3 Layer Model, P (V|do(Z, T ))</cell></row><row><cell></cell><cell cols="5">|V | = 17; 2 ≤ k ≤ 50; hw = 4, tw=15</cell></row><row><cell></cell><cell cols="5">P (V0|V1, V2, V3, X0)-largest factor</cell></row><row><cell>#Samples</cell><cell cols="2">time (s)</cell><cell cols="2">Max table size</cell><cell>t</cell><cell>density</cell></row><row><cell>25</cell><cell>2.8</cell><cell></cell><cell>3,219</cell><cell></cell><cell>25</cell><cell>0.00125</cell></row><row><cell>50</cell><cell>26.5</cell><cell></cell><cell>79,136</cell><cell></cell><cell>50</cell><cell>0.0025</cell></row><row><cell>100</cell><cell>640.8</cell><cell></cell><cell>1,623,559</cell><cell cols="2">100</cell><cell>0.005</cell></row><row><cell>200</cell><cell cols="2">30,511.5</cell><cell>34,018,439</cell><cell cols="2">200</cell><cell>0.01</cell></row><row><cell cols="4">4 Empirical validation</cell><cell></cell></row><row><cell cols="3">4.1 Benchmarks.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>table size during computation of the empirical plug-in on different sample sizes. The max table size reflects the space needed to evaluate the estimand. We also report the tightness t, and the density, which gives us a measure on the largest factor in the estimand, where density =</figDesc><table><row><cell># entries in table # of configurations in the joint table .</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Checklist 1. For all models and algorithms presented, check if you include: (a) A clear description of the mathematical setting, assumptions, algorithm, and/or model. yes (b) An analysis of the properties and complexity (time, space, sample size) of any algorithm. Yes in section 2 and section 3 (c) (Optional) Anonymized source code, with specification of all dependencies, including external libraries. [Yes/No/Not Applicable] 2. For any theoretical claim, check if you include: (a) Statements of the full set of assumptions of all theoretical results. yes, we explain the setting for causal effect estimation in section 2 (b) Complete proofs of all theoretical results. yes (c) Clear explanations of any assumptions. yes 3. For all figures and tables that present empirical results, check if you include:(a) The code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL). yes, can include in supplemental (b) All the training details (e.g., data splits, hyperparameters, how they were chosen). not applicable (c) A clear definition of the specific measure or statistics and error bars (e.g., with respect to the random seed after running experiments multiple times). not applicable (d) A description of the computing infrastructure used. (e.g., type of GPUs, internal cluster, or cloud provider). no, we are showing worst case results, and interested in only how the results for in O(t hw ) The estimated hourly wage paid to participants and the total amount spent on participant compensation. not applicable</figDesc><table><row><cell>(c) New assets either in the supplemental mate-</cell></row><row><cell>rial or as a URL, if applicable.</cell></row><row><cell>not applicable</cell></row><row><cell>(d) Information about consent from data</cell></row><row><cell>providers/curators.</cell></row><row><cell>not applicable</cell></row><row><cell>(e) Discussion of sensible content if applicable,</cell></row><row><cell>e.g., personally identifiable information or of-</cell></row><row><cell>fensive content.</cell></row><row><cell>not applicable</cell></row><row><cell>5. If you used crowdsourcing or conducted research</cell></row><row><cell>with human subjects, check if you include:</cell></row><row><cell>(a) The full text of instructions given to partici-</cell></row><row><cell>pants and screenshots.</cell></row><row><cell>not applicable</cell></row><row><cell>(b) Descriptions of potential participant risks,</cell></row><row><cell>with links to Institutional Review Board</cell></row><row><cell>(IRB) approvals if applicable.</cell></row><row><cell>not applicable</cell></row><row><cell>(c)</cell></row><row><cell>4. If you are using existing assets (e.g., code, data,</cell></row><row><cell>models) or curating/releasing new assets, check if</cell></row><row><cell>you include:</cell></row><row><cell>(a) Citations of the creator If your work uses ex-</cell></row><row><cell>isting assets.</cell></row><row><cell>not applicable</cell></row><row><cell>(b) The license information of the assets, if ap-</cell></row><row><cell>plicable.</cell></row><row><cell>not applicable</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Rina</forename><surname>Dechter</surname></persName>
		</author>
		<title level="m">Constraint Processing</title>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reasoning with Probabilistic and Deterministic Graphical Models: Exact Algorithms</title>
		<author>
			<persName><forename type="first">Rina</forename><surname>Dechter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Artificial Intelligence and Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">AND/OR search spaces for graphical models</title>
		<author>
			<persName><forename type="first">Rina</forename><surname>Dechter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Mateescu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2006.11.003</idno>
		<ptr target="https://doi.org/10.1016/j.artint.2006.11.003" />
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="73" to="106" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the practical significance of hypertree vs. treewidth</title>
		<author>
			<persName><forename type="first">Rina</forename><surname>Dechter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Otten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Marinescu</surname></persName>
		</author>
		<idno type="DOI">10.3233/978-1-58603-891-5-913</idno>
		<ptr target="https://doi.org/10.3233/978-1-58603-891-5-913" />
	</analytic>
	<monogr>
		<title level="m">ECAI 2008 -18th European Conference on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">Malik</forename><surname>Ghallab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Constantine</forename><forename type="middle">D</forename><surname>Spyropoulos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nikos</forename><surname>Fakotakis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nikolaos</forename><forename type="middle">M</forename><surname>Avouris</surname></persName>
		</editor>
		<meeting><address><addrLine>Patras, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2008">July 21-25, 2008. 2008</date>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="page" from="913" to="914" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A complete anytime algorithm for treewidth</title>
		<author>
			<persName><forename type="first">Vibhav</forename><surname>Gogate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rina</forename><surname>Dechter</surname></persName>
		</author>
		<idno>CoRR, abs/1207.4109</idno>
		<ptr target="http://arxiv.org/abs/1207.4109" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A backtrackingbased algorithm for hypertree decomposition</title>
		<author>
			<persName><forename type="first">Georg</forename><surname>Gottlob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marko</forename><surname>Samer</surname></persName>
		</author>
		<idno type="DOI">10.1145/1412228.1412229</idno>
		<ptr target="https://doi.org/10.1145/1412228.1412229" />
	</analytic>
	<monogr>
		<title level="j">ACM J. Exp. Algorithmics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A comparison of structural CSP decomposition methods</title>
		<author>
			<persName><forename type="first">Georg</forename><surname>Gottlob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Leone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Scarcello</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0004-3702(00)00078-3</idno>
		<ptr target="https://doi.org/10.1016/S0004-3702(00)00078-3" />
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="282" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Treewidth and hypertree width</title>
		<author>
			<persName><forename type="first">Georg</forename><surname>Gottlob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianluigi</forename><surname>Greco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Scarcello</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9781139177801.002</idno>
		<ptr target="https://doi.org/10.1017/CBO9781139177801.002" />
	</analytic>
	<monogr>
		<title level="m">Tractability: Practical Approaches to Hard Problems</title>
		<editor>
			<persName><forename type="first">Lucas</forename><surname>Bordeaux</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Youssef</forename><surname>Hamadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Estimating causal effects using weighting-based estimators</title>
		<author>
			<persName><forename type="first">Yonghan</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="10186" to="10193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning causal effects via weighted empirical risk minimization</title>
		<author>
			<persName><forename type="first">Yonghan</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marc'aurelio</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Maria-Florina</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hsuan-Tien</forename><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unifying tree decompositions for reasoning in graphical models</title>
		<author>
			<persName><forename type="first">Kalev</forename><surname>Kask</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rina</forename><surname>Dechter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Larrosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avi</forename><surname>Dechter</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2005.04.004</idno>
		<ptr target="https://doi.org/10.1016/j.artint.2005.04.004" />
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="165" to="193" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Pushing the power of stochastic greedy ordering schemes for inference in graphical models</title>
		<author>
			<persName><forename type="first">Kalev</forename><surname>Kask</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Gelfand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Otten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rina</forename><surname>Dechter</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v25i1.7828</idno>
		<ptr target="https://doi.org/10.1609/aaai" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2011</title>
		<editor>
			<persName><forename type="first">Wolfram</forename><surname>Burgard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</editor>
		<meeting>the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2011<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2011">August 7-11, 2011. 2011</date>
			<biblScope unit="page" from="1" to="7828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Bounding search space size via (hyper)tree decompositions</title>
		<author>
			<persName><forename type="first">Lars</forename><surname>Otten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rina</forename><surname>Dechter</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petri</forename><surname>Myllymäki</surname></persName>
		</author>
		<ptr target="https://dslpitt.org/uai/displayArticleDetails.jsp?" />
		<title level="m">UAI 2008, Proceedings of the 24th Conference in Uncertainty in Artificial Intelligence</title>
		<meeting><address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2008">July 9-12, 2008. 2008</date>
			<biblScope unit="page" from="452" to="459" />
		</imprint>
	</monogr>
	<note>mmnu=1&amp;smnu=2&amp; article_id=1964&amp;proceeding_id=24</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Causality: Models, Reasoning, and Inference</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Estimating causal effects from learned causal networks</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Raichev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Ihler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rina</forename><surname>Dechter</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2408.14101</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2408.14101" />
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Computing optimal hypertree decompositions with SAT</title>
		<author>
			<persName><forename type="first">André</forename><surname>Schidler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Szeider</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2023.104015</idno>
		<ptr target="https://doi.org/10.1016/j.artint.2023.104015" />
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">325</biblScope>
			<biblScope unit="page">104015</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Identification of joint interventional distributions in recursive semi-Markovian causal models</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Shpitser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st AAAI Conference on Artificial Intelligence</title>
		<meeting>the 21st AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">1219</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Studies in Causal reasoning and Learning</title>
		<author>
			<persName><forename type="first">Jin</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Los Angeles</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
