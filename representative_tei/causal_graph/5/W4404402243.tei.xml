<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs</title>
				<funder ref="#_bbGtxRu">
					<orgName type="full">BMBF</orgName>
				</funder>
				<funder ref="#_KA3bMcT #_2xjPCRJ">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-11-11">11 Nov 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Malte</forename><surname>Luttermann</surname></persName>
							<email>malte.luttermann@dfki.de</email>
							<affiliation key="aff0">
								<orgName type="department">German Research Center for Artificial Intelligence (DFKI)</orgName>
								<address>
									<settlement>Lübeck</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tanya</forename><surname>Braun</surname></persName>
							<email>tanya.braun@uni-muenster.de</email>
							<affiliation key="aff1">
								<orgName type="department">Data Science Group</orgName>
								<orgName type="institution">University of Münster</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ralf</forename><surname>Möller</surname></persName>
							<email>ralf.moeller@uni-hamburg.de</email>
							<affiliation key="aff2">
								<orgName type="department">Institute for Humanities-Centered Artificial Intelligence</orgName>
								<orgName type="institution">University of Hamburg</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marcel</forename><surname>Gehrke</surname></persName>
							<email>marcel.gehrke@uni-hamburg.de</email>
							<affiliation key="aff2">
								<orgName type="department">Institute for Humanities-Centered Artificial Intelligence</orgName>
								<orgName type="institution">University of Hamburg</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-11-11">11 Nov 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2411.07006v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>causal models</term>
					<term>probabilistic relational models</term>
					<term>lifted inference</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Lifting uses a representative of indistinguishable individuals to exploit symmetries in probabilistic relational models, denoted as parametric factor graphs, to speed up inference while maintaining exact answers. In this paper, we show how lifting can be applied to causal inference in partially directed graphs, i.e., graphs that contain both directed and undirected edges to represent causal relationships between random variables. We present partially directed parametric causal factor graphs (PPCFGs) as a generalisation of previously introduced parametric causal factor graphs, which require a fully directed graph. We further show how causal inference can be performed on a lifted level in PPCFGs, thereby extending the applicability of lifted causal inference to a broader range of models requiring less prior knowledge about causal relationships.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A fundamental problem for an intelligent agent performing reasoning under uncertainty is to compute the effect of an action on a certain random variable (randvar) on other randvars. When computing the effect of an action on a specific randvar, it is crucial to deploy the semantics of an intervention instead of performing a classical conditioning on that randvar <ref type="bibr" target="#b21">[22,</ref><ref type="bibr">Chapter 4</ref>]. An intervention acting on a randvar R can be thought of as setting R to a fixed value and removing all incoming influences on the value of R. In practice, generally not all causal relationships in a given model are known and thus, only a partially directed graphical model is available. In such a partially directed graph, directed edges represent cause-effect relationships and undirected edges represent causal relationships whose direction is unknown. In this paper, we solve the problem of efficiently estimating causal effects of actions in partially directed lifted probabilistic models, denoted as parametric factor graphs. Lifted representations are not only more expressive than propositional models such as factor graphs, but also allow for tractable probabilistic inference with respect to domain sizes of logical variables (logvars) by exploiting symmetries.</p><p>Previous Work. The estimation of causal effects using causal graphical models in form of directed acyclic graphs in combination with observational data has been extensively studied in the literature (see, e.g., <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27]</ref>). Some works incorporate causal knowledge into (propositional) factor graphs (which are originally undirected graphical models) to enable the estimation of causal effects in factor graphs <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b28">29]</ref>. In practice, the underlying causal graph is often not fully known and hence, identifying and estimating causal effects when provided with observational data and a partially directed graph has been investigated <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b23">24]</ref>. However, all of these works perform causal effect estimation on a propositional level and thus lack the expressivity of relational logic, for example to capture the relationships between individual objects. To represent individual objects and the relationships between them, Poole <ref type="bibr" target="#b24">[25]</ref> introduces parametric factor graphs as lifted representations, which combine relational logic and probabilistic models, thereby allowing to encode that certain properties hold for groups of indistinguishable objects. In probabilistic inference, lifting exploits symmetries to speed up inference while maintaining exact answers <ref type="bibr" target="#b19">[20]</ref>. Over the past years, both algorithms for symmetry detection <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref> allowing the construction of lifted representations such as parametric factor graphs as well as various lifted inference algorithms operating on parametric factor graphs have been developed and further refined <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28]</ref>. More recently, Luttermann et al. <ref type="bibr" target="#b11">[12]</ref> introduce parametric causal factor graphs (PCFGs) as an extension of parametric factor graphs allowing to incorporate causal knowledge into a lifted representation. Nevertheless, the authors assume that the causal relationships between the involved randvars are fully known, which is rarely the case in practical settings.</p><p>Our Contributions. We introduce partially directed parametric causal factor graphs (PPCFGs) as a generalisation of PCFGs to obtain a formalism that compactly encodes a full joint distribution over a set of randvars and at the same time incorporates causal knowledge in the model, if available. The major advantage of a PPCFG over an PCFG is that not all causal relationships between the involved randvars need to be known, thereby reducing the amount of prior knowledge required and thus making the model more suitable for many practical settings. We further define d-separation in PPCFGs to reason about conditional independence. In addition to that, we present an algorithm to efficiently estimate causal effects in PPCFGs on a lifted level, i.e., a representative of indistinguishable objects is used for computations to speed up inference. Our algorithm identifies whether a causal effect can be uniquely determined from the given PPCFG and if so, outputs the causal effect. If the undirected edges in the PPCFG lead to a causal effect being not uniquely identifiable, our algorithm efficiently enumerates all possible causal effects while operating on a lifted level.</p><p>Structure of this Paper. We begin by introducing necessary background information and notations. Afterwards, we present PPCFGs as a generalisation of PCFGs, allowing both for directed and undirected edges in the model and then define d-separation in PPCFGs. Thereafter, we provide an algorithm to efficiently estimate causal effects in PPCFGs before we conclude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>We begin to introduce parameterised randvars (PRVs), which use logvars as parameters to represent sets of indistinguishable randvars.</p><p>Definition 1 (Parameterised Random Variable). Let R be a set of randvar names, L a set of logvar names, and D a set of constants. All sets are finite. Each logvar L has a domain dom(L) ⊆ D. A constraint is a tuple (X , C X ) of a sequence of logvars X = (X 1 , . . . , X n ) and a set C X ⊆ × n i=1 dom(X i ). The symbol ⊤ for C marks that no restrictions apply, i.e., Example 2. Take a look at the parfactor g 1 = ϕ 1 (Comp(E), Rev) |⊤ . Assuming the same ranges of the PRVs and the same domains of the logvars as in Ex. 1,</p><formula xml:id="formula_0">C X = × n i=1 dom(X i ). A PRV R(L 1 , . . . , L n ), n ≥ 0, is a syntactical construct of a randvar R ∈ R</formula><formula xml:id="formula_1">g 1 specifies |range(Comp(E))| • |range(Rev)| = 9 input-output map- pings ϕ 1 (low, low) = φ 1 , ϕ 1 (low, medium) = φ 2 , ϕ 1 (low, high) = φ 3 ,</formula><p>and so on with φ i ∈ R + for all i = 1, . . . , 9. Further, lv(g 1 ) = {E} and gr(g</p><formula xml:id="formula_2">1 ⊤ ) = {ϕ 1 (Comp(alice), Rev), ϕ 1 (Comp(bob), Rev), ϕ 1 (Comp(charlie), Rev)}.</formula><p>A PCFG is then built from a set of parfactors {g 1 , . . . , g m } and the causal relationships between the PRVs, which are encoded by the direction of the edges in the graph structure of the PCFG <ref type="bibr" target="#b11">[12]</ref>. In its original form, a PCFG is a fully directed graph, but we extend this definition to allow for both directed and undirected edges in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rev Comp(E)</head><p>Sal(E) g1 g2 g3 Fig. <ref type="figure">1</ref>: A PPCFG modelling the interplay of a company's revenue and its employees' competences and salaries (without input-output mappings of parfactors).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Partially Directed Parametric Causal Factor Graphs</head><p>We now move on to define PPCFGs as lifted models that are able to incorporate partial causal knowledge, thereby allowing to exploit symmetries (in form of indistinguishable individuals) to speed up both probabilistic and causal inference by performing lifted inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 3 (Partially Directed Parametric Causal Factor Graph</head><formula xml:id="formula_3">). A PPCFG is a graph M = (A ∪ G, E) that consists of variable nodes A, factor nodes G (A∩G = ∅)</formula><p>, and a set of edges E. Each variable node A ∈ A represents a PRV A and every factor node g ∈ G represents a parfactor g = ϕ(A) |C , where</p><formula xml:id="formula_4">A = (A 1 , . . . , A k ) with A 1 ∈ A, . . . , A k ∈ A is a sequence of PRVs, ϕ : × k i=1 range(A i ) → R + is a function,</formula><p>and C is a constraint on the logvars of A. We again may omit |⊤ in ϕ(A) |⊤ . For a variable node A ∈ A and a factor node g ∈ G, there is an undirected edge g -A ∈ E if A appears in the argument list of g = ϕ(A) and no information about the causal relationships between the PRVs in A is available. If it is known that all A ′ ∈ A \ {A} are causes of A ∈ A (or if A \ {A} = ∅), the edge g -A can be replaced by a directed edge g → A.</p><p>The semantics of M is given by grounding and building a full joint distribution. With Z as the normalisation constant and A k denoting the PRVs appearing in the argument list of ϕ k (A k ), M represents the full joint distribution</p><formula xml:id="formula_5">P M = 1 Z g∈G ϕ k ∈gr(g) ϕ k (A k ).</formula><p>Example 3. Following Exs. 1 and 2, Fig. <ref type="figure">1</ref> depicts a PPCFG M modelling the interplay of a company's revenue and its employees' competences and salaries. Each parfactor represents a group of ground factors and thus, grounding M results in a partially directed factor graph (see Fig. <ref type="figure">2</ref>). In this particular example, the causal relationships encoded by M tell us that the revenue of the company influences the salary of each individual employee and the competence of a specific employee influences their salary. Moreover, there is a dependency between the competence of each individual employee and the revenue of the company, but the causal direction is not encoded in M . We humans expect that the competence of the employees influences the revenue of the company, but an autonomous agent might not have this information available, resulting in a partially directed graph. Fig. <ref type="figure">2:</ref> A visualisation of the resulting model when grounding the PPCFG M given in Fig. <ref type="figure">1</ref>, where dom(E) = {alice, bob, charlie}.</p><p>In accordance with the literature, in this paper we consider PPCFGs that do not contain directed cycles. Throughout this paper, we denote the parents of</p><formula xml:id="formula_6">a PRV A in a PPCFG M = (A ∪ G, E) by Pa(A, M ) = {A ′ ∈ A | ∃g ∈ G : (g-A ′ ) ∈ E∧(g → A) ∈ E}. Analogously, we define the children of A in M as Ch(A, M ) = {A ′ ∈ A | ∃g ∈ G : (g → A ′ ) ∈ E ∧(g-A) ∈ E} and the neighbours of A in M as Ne(A, M ) = {A ′ ∈ A | ∃g ∈ G : (g -A ′ ) ∈ E ∧ (g -A) ∈ E}.</formula><p>Note that the semantics of a PPCFG is defined with respect to the set of parfactors and thus is independent of the given causal relationships. A PPCFG hence simultaneously encodes a full joint probability distribution over a set of randvars (represented by PRVs) and a set of causal relationships between those randvars <ref type="foot" target="#foot_0">1</ref> . Another important remark is that grounding a PPCFG results in a partially directed factor graph as introduced by Frey <ref type="bibr" target="#b5">[6]</ref>. The important advantage is that the PPCFG combines relational logic with probabilistic models, thereby being more expressive than a factor graph and allowing us to exploit symmetries (in form of indistinguishable individuals) to speed up inference.</p><p>Example 4. Take a look at Fig. <ref type="figure">2</ref>, which presents the resulting model when grounding the PPCFG M given in Fig. <ref type="figure">1</ref>. The model gr(M ) now contains the randvars Comp(alice), Comp(bob), Comp(charlie), which are represented by a single PRV Comp(E) with a logvar E, dom(E) = {alice, bob, charlie}, in M (analogously for Sal(alice), Sal(bob), Sal(charlie) and Sal(E)). Moreover, each parfactor g i in M represents a set of three (identical) ground factors ϕ i in the grounded model gr(M ). In consequence, the lifted representation M is more compact than its grounded counterpart gr(M ), thereby reducing run times required to perform inference. The underlying assumption is that there are indistinguishable objects, here employees, which can be represented by a representative.</p><p>Since a PPCFG encodes a full joint probability distribution, a PPCFG can be used to compute marginal distributions of grounded PRVs given observations of specific events. A query asks for a probability distribution (or a specific probability) given a set of observed events or, in the case of an interventional query, given a set of interventions fixing the values of certain (grounded) PRVs.</p><p>Definition 4 (Query). A query P (Q | E 1 = e 1 , . . . , E k = e k ) consists of a query term Q and a set of events {E j = e j } k j=1 with Q and E j being grounded or parameterless PRVs. To query a specific probability instead of a probability distribution, the query term is an event Q = q. An interventional query P (Q | do(R 1 = r 1 , . . . , R k = r k )) asks for a probability distribution given that the grounded or parameterless PRVs R j are set to a fixed value r j . Before we consider interventions in detail, we first take a closer look at conditional independence in PPCFGs, which is needed to reason about interventions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conditional Independence in PPCFGs</head><p>The notion of d-separation <ref type="bibr" target="#b20">[21]</ref> provides a graphical criterion to test for conditional independence in directed acyclic graphs and is essential to compute the effect of an intervention in the sense that all non-causal paths, so-called backdoor paths, need to be blocked to remove spurious effects. Frey <ref type="bibr" target="#b5">[6]</ref> extends the notion of d-separation to partially directed factor graphs and we build on this definition to define d-separation in PPCFGs (analogously to d-separation in PCFGs <ref type="bibr" target="#b11">[12]</ref>). Note that the semantics of d-separation in PPCFGs is defined on a ground level.</p><p>Definition 5 (d-separation). Let M = (A ∪ G, E) be a PPCFG. Given three disjoint sets of randvars X, Y , and Z (subsets of gr(A)), we say that X and Y are conditionally independent given Z, written as X ⊥ ⊥ Y | Z, if the nodes in Z block all paths between the nodes in X and the nodes in Y in gr(M ). A path is a connected sequence of edges (independent of their directions) and it is therefore also possible for a path to pass from a parent of a factor to another parent of that factor. A path is blocked by the nodes in Z if 1. the path contains the pattern ϕ 1 → A ← ϕ 2 such that neither A nor any of its descendants are in Z, or 2. the path passes from ϕ 1 through A to ϕ 2 such that it does not contain the pattern ϕ 1 → A ← ϕ 2 and A is in Z, or 3. the path passes from a parent of a factor ϕ to another parent of ϕ, and neither the child of ϕ nor any of its descendants are in Z.</p><p>Example 6. Consider the grounded PPCFG M depicted in Fig. <ref type="figure">2</ref>. M encodes, for example, that the competence of alice is independent of bob's salary given the revenue of the company, written as {Comp(alice)} ⊥ ⊥ {Sal(bob)} | {Rev}, because all paths from Comp(alice) to Sal(bob) pass through Rev.</p><p>Remark 1. Definition 5 is slightly different from the definition of d-separation provided by Frey <ref type="bibr" target="#b5">[6]</ref> for partially directed factor graphs in the sense that Def. 5 is more flexible by allowing for variable nodes to have multiple parent factor nodes (e.g., in Fig. <ref type="figure">1</ref>, Sal(E) has two parent factor nodes g 2 and g 3 instead of a single parent factor node with two inputs from Comp(E) and Rev).</p><p>Remark 2. In case a PPCFG M is constructed by hand (instead of being learned from observational data), it is possible to construct a mismatch of the conditional independence statements encoded in the graph structure of M and the conditional independence statements implied by the full joint probability distribution encoded by M . We therefore assume that the graph structure of a given PPCFG M encodes exactly the same conditional independence statements as the underlying full joint probability distribution encoded by M .</p><p>As we have seen, the semantics of d-separation in PPCFGs is defined on a ground level. However, it is possible to check for d-separation on a lifted level without having to ground the entire PPCFG. For this purpose, the well-known Bayes-Ball algorithm <ref type="bibr" target="#b25">[26]</ref> that allows us to check for conditional independence can be applied on a lifted level, that is, it can be run on the PPCFG instead of on its grounded counterpart <ref type="bibr" target="#b16">[17]</ref>. The idea of the Bayes-Ball algorithm is that a bouncing ball is sent through the graph structure such that the ball can pass through a node, bounce back, or be blocked to determine blocked paths (more details can be found in <ref type="bibr" target="#b25">[26]</ref>). It is also possible to check whether PRVs (instead of ground randvars) are conditionally independent in a highly efficient manner on a lifted level. In a PPCFG, each PRV A is represented by a single variable node and thus, checking for conditional independence statements that involve A can be done by looking at this single variable node instead of taking into account all groundings gr(A) of A. In contrast, in a propositional setting (i.e., in a ground model), each ground randvar in gr(A) must be looked at individually (for example, to check whether {Comp(E)} ⊥ ⊥ {Sal(E)} | {Rev} holds, only three variable nodes are of relevance in the lifted representation while 2 • |dom(E)| + 1 nodes are of relevance in the ground model).</p><p>We next show how the estimation of causal effects, which rely on the notion of an intervention, can efficiently be realised in PPCFGs. The idea is again to avoid grounding the entire PPCFG, if possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Efficient Estimation of Causal Effects in PPCFGs</head><p>To compute the effect of actions carried out on randvars on other randvars, we have to answer interventional queries <ref type="bibr" target="#b21">[22]</ref>. An intervention on a grounded or parameterless PRV R, denoted as do(R = r) where r ∈ range(R), changes the structure of the underlying model by setting the value of R to r and removing all incoming influences on R. An intervention is defined on a fully directed graph. Definition 6 (Intervention). Let M = (A∪G, E) be a fully directed PPCFG and let gr(A) = {R 1 , . . . , R n } denote the set of randvars obtained by grounding the PRVs in A. Any probability distribution entailing the conditional independence statements encoded by M can be factorised as</p><formula xml:id="formula_7">P (R 1 , . . . , R n ) = n i=1 P (R i | Pa(R i , gr(M ))). An intervention do(R ′ 1 = r ′ 1 , . . . , R ′ k = r ′ k )</formula><p>changes the underlying probability distribution such that</p><formula xml:id="formula_8">P (R 1 = r 1 , . . . , R n = r n | do(R ′ 1 = r ′ 1 , . . . , R ′ k = r ′ k )) =    Ri∈{R1,...,Rn}\{R ′ 1 ,...,R ′ k } P (r i | pa(R i , gr(M ))) if ∀j ∈ {1, . . . , k} : r j = r ′ j 0 otherwise,</formula><p>where pa(R i , gr(M )) denotes the values of Pa(R i , gr(M )).</p><p>Observe that the definition of an intervention refers to a fully directed PPCFG. In general, we deal with PPCFGs that might contain undirected edges and thus represent a whole class of fully directed PPCFGs, namely all fully directed PPCFGs that entail the same conditional independence statements as the initial PPCFG<ref type="foot" target="#foot_1">foot_1</ref> .</p><p>To determine the semantics of an intervention, we thus need to know the parents of the PRVs on which we intervene. As we deal with PPCFGs that might contain undirected edges, however, we do not always know the real parents of a PRV.</p><p>Example 7. Given the PPCFG depicted in Fig. <ref type="figure">1</ref>, the company might wonder whether it is worth it to send its employee alice to an expensive training course to increase the revenue of the company due to the increased competence of alice. Hence, the company is interested in computing the quantity P (Rev | do(Comp(alice) = high)). Since an intervention can be thought of as setting the value of Comp(alice) to high and removing all incoming edges of Comp(alice) in the graph, there are two possible scenarios when computing P (Rev | do(Comp(alice) = high)): (i) Rev is a parent of Comp(alice) in the true model and thus, the underlying probability distribution is changed, or (ii) Comp(alice) is a parent of Rev in the true model and therefore, the underlying probability distribution remains unchanged as Comp(alice) has no parents. Without further background information, we do not know which of these two scenarios is actually correct and thus, we need to consider both possibilities.</p><p>Fortunately, we do not always have to consider all possible fully directed PPCFGs represented by a given PPCFG when computing the effect of an intervention because there are settings in which the represented fully directed PPCFGs all yield the same effect of the intervention. In particular, in case all parents of the randvars on which we intervene are known, we can uniquely determine the effect of the intervention even if there are still undirected edges in the PPCFG <ref type="foot" target="#foot_2">3</ref> .</p><formula xml:id="formula_9">Theorem 1. Let M = (A ∪ G, E) denote a PPCFG and let P (Q | do(R ′ 1 = r ′ 1 , . . . , R ′ k = r ′ k )) be an interventional query with Q ∈ gr(A), R ′ 1 ∈ gr(A), . . . , R ′ k ∈ gr(A), and {Q} ∩ {R ′ 1 , . . . , R ′ k } = ∅. If it holds that Ne(R ′ 1 , gr(M )) = ∅, . . . , Ne(R ′ k , gr(M )) = ∅, then the result of P (Q | do(R ′ 1 = r ′ 1 , . . . , R ′ k = r ′ k )) is identical for all fully directed PPCFGs represented by M . each R ′ i ∈ {R ′ 1 , . . . , R ′ k }.</formula><p>Splitting the parfactors results in a modified PPCFG M ′ entailing equivalent semantics as M and works as follows <ref type="bibr" target="#b3">[4]</ref>. Recall that R ′ i = A(L 1 = l 1 , . . . , L j = l j ), l 1 ∈ dom(L 1 ), . . . , l j ∈ dom(L j ), is a specific instance of a PRV A(L 1 , . . . , L j ). The idea behind the splitting procedure is that we would like to separate gr(A) into two sets gr(A) \ {R ′ i } and {R ′ i }, as R ′ i has to be treated differently than the remaining instances of A due to the intervention. Thus, every parfactor g for which there is an instance ϕ ∈ gr(g) such that R ′ i appears in the argument list of ϕ is split. Formally, splitting a parfactor g replaces g by two parfactors g ′ |C ′ and g ′′ |C ′′ and adapts the constraints of g ′ |C ′ and g ′′ |C ′′ such that the inputs of g ′ |C ′ are restricted to all sequences that contain R ′ i and the inputs of g ′′ |C ′′ are restricted to the remaining input sequences. After the splitting procedure, the semantics of the model remains unchanged as the groundings of M ′ are still the same as the groundings of the initial model M -they are just arranged differently across the sets of ground instances. Algorithm 1 then iterates over all possible parent sets (i.e., over all subsets of undirected neighbours) of R ′ 1 , . . . , R ′ k . When considering the subsets of undirected neighbours, it is necessary that all subsets are jointly valid, that is, they are not allowed to alter the conditional independence statements encoded by the model and they must not introduce any cycles when oriented towards R ′ 1 , . . . , R ′ k . To ensure the validity of these subsets, they are required to form a clique. A clique C is a subset of nodes such that all pairs of nodes in C are directly connected via a factor <ref type="foot" target="#foot_3">6</ref> . By ensuring that the subsets of undirected neighbours form cliques, the orientation of the undirected neighbours of R ′ 1 , . . . , R ′ k towards R ′ 1 , . . . , R ′ k does not introduce any pattern R 1 -ϕ 1 → R 2 ← ϕ 2 -R 3 such that R 1 and R 3 are not directly connected via a factor, as due to the clique property R 1 and R 3 are always guaranteed to be directly connected via a factor. Thus, the conditional independence statements encoded by M ′′ are equivalent to those encoded by M . Having obtained the parent sets of R ′ 1 , . . . , R ′ k , Alg. 1 next extends the modified model M ′′ to any fully directed PPCFG represented by M ′′ , if such a fully directed PPCFG exists. Afterwards, M ′′ is guaranteed to be a fully directed PPCFG represented by M and hence, the result of the provided query is given by Eq. ( <ref type="formula">1</ref>), which requires us to know the parents of all non-intervention randvars to compute a product over conditional probability distributions. Since M encodes the full joint probability distribution over gr(A), the conditional probability distributions are obtained by querying M , which allows us to compute the results for these queries using lifted probabilistic inference, thereby avoiding to ground the entire model if possible. The resulting post-intervention distribution is then added to the result set P and the algorithm continues the above steps for the next possible parent set until all possible parent sets have been taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rev</head><formula xml:id="formula_10">Comp(E) Sal(E) Comp(alice) g1 |C 1 g2 |⊤ g3 |C 3 g ′ 1 |C ′ 1 g ′ 3 |C ′<label>3</label></formula><p>Fig. <ref type="figure">3</ref>: The modified PPCFG obtained after splitting the parfactors in the PPCFG shown in Fig. <ref type="figure">1</ref>  </p><formula xml:id="formula_11">-g ′ 1 |C ′ 1 -Rev as Comp(alice) -g ′ 1 |C ′ 1 → Rev) and Pa 2 (Comp(alice), M ′′ ) = {Rev} (result- ing from orienting Comp(alice) -g ′ 1 |C ′ 1 -Rev as Comp(alice) ← g ′ 1 |C ′ 1 -Rev).</formula><p>Depending on whether Comp(alice) actually has a parent or not, the postintervention distribution is different and hence, Alg. 1 returns a set containing two possible results for the query P (Rev | do(Comp(alice) = high)).</p><p>Note that the model shown in Fig. <ref type="figure">3</ref> is more compact than the fully grounded model in Fig. <ref type="figure">2</ref> as Alg. 1 only grounds necessary parts of the model. Algorithm 1 can further benefit from interventions on multiple indistinguishable objects under the assumption that the graph structure is identical for all groundings. For example, when considering the effect of a training course given to multiple employees on the revenue of the company, even if there are hundreds of employees, after intervening on their competence there are still only two nodes representing their competences in the graph, namely one node for all employees that have received the training course and another node for the remaining employees. In this case, Alg. 1 has to consider only two possible parent sets regardless of the number of employees while there are 2 |dom(E)| possible parent sets in an equivalent propositional model to consider (where |dom(E)| is the number of employees).</p><p>Corollary 1. Let M = (A ∪ G, E) be a PPCFG. When intervening on a nongrounded PRV A(L 1 , . . . , L j ) ∈ A, under the assumption that the graph structure is identical for all groundings, it holds that 1. Alg. 1 considers O(2 |Ne(A,M )| ) possible parent sets in the worst case, and 2. in a propositional model, O(2 R∈gr(A) |Ne(R,gr(M ))| ) possible parent sets have to be considered in the worst case.</p><p>Finally, note that Alg. 1 can handle multiple query variables at once instead of a single query variable Q (the query variables are then not summed out in Line 9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We introduce PPCFGs as probabilistic relational models that allow to incorporate partial causal knowledge, thereby enabling lifted causal inference without the need for a fully specified causal model. A lifted representation such as a PPCFG is more expressive than a propositional model and allows for tractable inference with respect to domain sizes of logvars. We further present an algorithm to efficiently compute the effect of joint interventions in PPCFGs (i.e., on a lifted level). Our proposed algorithm is also able to efficiently deal with interventions on PRVs representing sets of indistinguishable randvars.</p><p>In future work, we aim to investigate the effect of interventions in a relational model with mutual interdependencies in form of bidirectional edges. We conjecture that randvars with mutual interdependencies can be collapsed into a single node in the graph such that our proposed algorithm can still be applied. Another interesting direction for future work is to allow for hidden confounders.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>possibly combined with logvars L 1 , . . . , L n ∈ L to represent a set of randvars. If n = 0, the PRV is parameterless and forms a propositional randvar. A PRV A (or logvar L) under constraint C is given by A |C (L |C ), respectively. We may omit |⊤ in A |⊤ or L |⊤ . The term range(A) denotes the possible values of a PRV A. An event A = a denotes the occurrence of PRV A with range value a ∈ range(A). Example 1. Consider R = {Comp, Sal, Rev} for competence, salary, and revenue, respectively, and L = {E} with dom(E) = {alice, bob, charlie} (employees), combined into PRVs Comp(E), Sal(E), and Rev with range(Comp(E)) = range(Sal(E)) = range(Rev) = {low, medium, high}. A parametric factor (parfactor) describes a function, mapping argument values to positive real numbers, of which at least one is non-zero. Definition 2 (Parfactor). Let Φ denote a set of factor names. We denote a parfactor g by ϕ(A) |C with A = (A 1 , . . . , A n ) being a sequence of PRVs, ϕ : × n i=1 range(A i ) → R + being a function with name ϕ ∈ Φ mapping argument values to a positive real number called potential, and C being a constraint on the logvars of A. We may omit |⊤ in ϕ(A) |⊤ . The term lv(Y ) refers to the logvars in some element Y , a PRV, a parfactor, or sets thereof. The term gr(Y |C ) denotes the set of all instances (groundings) of Y with respect to constraint C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Example 5 .</head><label>5</label><figDesc>The query P (Rev | Comp(alice) = high) asks for the probability distribution of Rev given that the event Comp(alice) = high is observed. Keep in mind that, in general, observing and intervening are two different things, e.g., generally P (Rev | Comp(alice) = high) ̸ = P (Rev | do(Comp(alice) = high)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>to separate Comp(alice) from Comp(E). Assume we want to compute P (Rev | do(Comp(alice) = high)) in the PPCFG M depicted in Fig.1. As the intervention operates on Comp(alice), first the parfactors in M are split on Comp(alice) to obtain the modified PPCFG M ′ shown in Fig.3. In M ′ , Comp(alice) is now a separate node in the graph, so its possible parents can be determined. Formally, g 1 has been replaced by two parfactors g 1 |C 1 and g ′ Analogously, g 3 has been replaced by g 3 |C 3 and g ′</figDesc><table><row><cell>Example 8. 1 |C ′</cell><cell></cell></row><row><cell>3 3 |C ′</cell><cell>. Next,</cell></row></table><note><p><p><p><p>1</p>with constraints C 1 = (E, {bob, charlie}) and</p>C ′ 1 = (E, {alice}).</p>Alg. 1 considers all possible parent sets of Comp(alice), which are given by Pa 1 (Comp(alice), M ′′ ) = ∅ (resulting from orienting Comp(alice)</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Thus, the setting of having an PPCFG is equivalent to having a causal graph and observational data for the randvars occurring in the causal graph<ref type="bibr" target="#b21">[22]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>For classical (propositional) directed acyclic graphs, the set of fully directed acyclic graphs representing identical conditional independence statements is known under the name of a Markov equivalence class.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>In fact, this has been shown for propositional models<ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b18">19]</ref> and we now transfer this result to relational models.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>Formally, a clique C in a PPCFG M = (A ∪ G, E) is a subset of nodes such that for each pair of nodes C1 ∈ C, C2 ∈ C with C1 ̸ = C2 it holds that there exists a factor ϕ such that there is an edge between C1 and ϕ as well as an edge between C2 and ϕ in E (either directed or undirected).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is funded by the <rs type="funder">BMBF</rs> project <rs type="projectName">AnoMed</rs> <rs type="grantNumber">16KISA057</rs>. This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this contribution is published in Lecture Notes in Computer Science, Volume <rs type="grantNumber">15350</rs>, and is available online at <ref type="url" target="https://link.springer.com/chapter/10.1007/978-3-031-76235-2_20">https: //link.springer.com/chapter/10.1007/978-3-031-76235-2_20</ref>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_bbGtxRu">
					<idno type="grant-number">16KISA057</idno>
					<orgName type="project" subtype="full">AnoMed</orgName>
				</org>
				<org type="funding" xml:id="_KA3bMcT">
					<idno type="grant-number">15350</idno>
				</org>
				<org type="funding" xml:id="_2xjPCRJ">
					<idno type="grant-number">1007/978-3-031-76235-2_20</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Proof. Let {R 1 , . . . , R ℓ } = gr(A)\{Q, R ′ 1 , . . . , R ′ k } denote the set of all grounded randvars that do not occur in the given query. From Def. 6 we know that</p><p>. . .</p><p>If it holds that Ne(R ′ 1 , gr(M )) = ∅, . . . , Ne(R ′ k , gr(M )) = ∅, then the parents of R ′ 1 , . . . , R ′ k are fully known and identical in all fully directed PPCFGs represented by M . Hence, it remains to be shown that the factorisation of all ground randvars that are not in {R ′ 1 , . . . , R ′ k } is equivalent for all fully directed PPCFGs represented by M . We know that all fully directed PPCFGs represented by M entail exactly the same conditional independence statements as M and thus, the factorisations induced by these fully directed PPCFGs entail equivalent semantics (just as all Bayesian network structures over a fixed set of randvars entailing the same conditional independence statements induce equivalent factorisations of the underlying probability distribution). Consequently, Eq. ( <ref type="formula">1</ref>) yields the same result for all fully directed PPCFGs represented by M .</p><p>Theorem 1 implies that we do not have to consider all possible edge directions of the undirected edges in a PPCFG when computing the effect of an intervention but just the possible directions of the undirected edges that are relevant for the intervention, that is, the directions of the undirected edges that are connected to the randvars on which we intervene. Note that all terms required to answer the interventional query can be computed by querying the PPCFG, as the PPCFG compactly encodes the full joint probability distribution over all ground randvars. The semantics of the PPCFG is well-defined even if there are undirected edges in the graph because the factors do not necessarily encode distributions conditioned on the parents but instead encode arbitrary local distributions that factorise the full joint probability distribution.</p><p>Intuitively, it becomes clear that the effect of an intervention cannot be uniquely determined if there are undirected edges connected to the randvars on which we intervene because there are different possible parent sets that might result in multiple disjoint effects of the intervention.</p><p>is not guaranteed to be uniquely determined. Proof. If there exists a randvar</p><p>there are undirected edges connected to R ′ i , implying that the parents of R ′ i are not guaranteed to be identical in all fully directed PPCFGs represented by M . Since we know that Eq. (1) gives us the result of the given query, the factors being removed from the product on the right hand side of the equation might differ depending on the actual parents of the ground randvars on which we intervene, thereby possibly yielding different results for the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Lifted Causal Inference in PPCFGs</head><p>Input : A PPCFG M = (A ∪ G, E) and an interventional query</p><p>The set of all possible post-intervention distributions</p><p>. . .</p><p>10 Add D to P ; 11 return P Remark 3. There are scenarios in which it is possible to uniquely determine the result of an interventional query even if there are undirected edges connected to the randvars on which we intervene as not all undirected edges can be oriented in both directions (because they are not allowed to introduce a cycle or to change the conditional independence statements encoded in the graph structure) 4 .</p><p>Combining the insights from Thms. 1 and 2 naturally leads to an algorithm to compute the effect of interventions in PPCFGs. The idea is that all possible parent sets of the intervention variables have to be considered. If there is just one possible set of parents, the effect of the intervention can be uniquely determined, otherwise there are multiple possible effects that are enumerated. This idea is incorporated in the IDA algorithm and its variants <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b15">16]</ref> for single interventions (i.e., interventions do(R ′ = r ′ )) in propositional models. Algorithm 1 displays our proposed algorithm, which extends the idea of just considering the possible parent sets of intervention variables to joint interventions (i.e., interventions</p><p>where k ≥ 1) in relational models 5 . Given a PPCFG M = (A∪G, E) and an interventional query</p><p>, Alg. 1 proceeds as follows to compute the set of all possible results for the given query. First, Alg. 1 splits the parfactors in M based on 4 An orientation of an undirected edge alters the conditional independence statements if the new orientation introduces the pattern R1 -ϕ1 → R2 ← ϕ2 -R3 such that R1 and R3 are not directly connected via a factor-see Item 1 in Def. 5. 5 Algorithm 1 transfers the results for joint interventions in propositional models with undirected edges <ref type="bibr" target="#b18">[19]</ref> to relational models.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Exploiting Symmetries for Scaling Loopy Belief Propagation and Relational Training</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mladenov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="91" to="132" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Lifted Junction Tree Algorithm</title>
		<author>
			<persName><forename type="first">T</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Möller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KI 2016: Advances in Artificial Intelligence (KI-16)</title>
		<meeting>KI 2016: Advances in Artificial Intelligence (KI-16)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="30" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Parameterised Queries and Lifted Query Answering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Möller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI-18)</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence (IJCAI-18)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4980" to="4986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Lifted First-Order Probabilistic Inference</title>
		<author>
			<persName><forename type="first">De</forename><surname>Salvo Braz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Joint Conference on Artificial Intelligence (IJCAI-05)</title>
		<meeting>the 19th International Joint Conference on Artificial Intelligence (IJCAI-05)</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1319" to="1325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MPE and Partial Inversion in Lifted Probabilistic Variable Elimination</title>
		<author>
			<persName><forename type="first">De</forename><surname>Salvo Braz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th National Conference on Artificial Intelligence (AAAI-06)</title>
		<meeting>the 21th National Conference on Artificial Intelligence (AAAI-06)</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1123" to="1130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Extending Factor Graphs so as to Unify Directed and Undirected Graphical Models</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th Conference on Uncertainty in Artificial Intelligence (UAI-03)</title>
		<meeting>the 19th Conference on Uncertainty in Artificial Intelligence (UAI-03)</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Minimal Enumeration of All Possible Total Effects in a Markov Equivalence Class</title>
		<author>
			<persName><forename type="first">R</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perkovic</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 24th International Conference on Artificial Intelligence and Statistics (AISTATS-21)</title>
		<meeting>The 24th International Conference on Artificial Intelligence and Statistics (AISTATS-21)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2395" to="2403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Counting Belief Propagation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI-09)</title>
		<meeting>the 25th Conference on Uncertainty in Artificial Intelligence (UAI-09)</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="277" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Constraint Processing in Lifted Probabilistic Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kisyński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI-09)</title>
		<meeting>the 25th Conference on Uncertainty in Artificial Intelligence (UAI-09)</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="293" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Collapsible IDA: Collapsing Parental Sets for Locally Estimating Possible Causal Effects</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Geng</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI-20)</title>
		<meeting>the 36th Conference on Uncertainty in Artificial Intelligence (UAI-20)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="290" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Colour Passing Revisited: Lifted Model Construction with Commutative Factors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luttermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gehrke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th AAAI Conference on Artificial Intelligence (AAAI-24)</title>
		<meeting>the 38th AAAI Conference on Artificial Intelligence (AAAI-24)</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="20500" to="20507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lifted Causal Inference in Relational Domains</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luttermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hartwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gehrke</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Conference on Causal Learning and Reasoning</title>
		<meeting>the 3rd Conference on Causal Learning and Reasoning</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="827" to="842" />
		</imprint>
	</monogr>
	<note>CLeaR-24</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient Detection of Commutative Factors in Factor Graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luttermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Machemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gehrke</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Conference on Probabilistic Graphical Models (PGM-2024)</title>
		<meeting>the Twelfth International Conference on Probabilistic Graphical Models (PGM-2024)</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="38" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient Detection of Exchangeable Factors in Factor Graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luttermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Machemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gehrke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International FLAIRS Conference (FLAIRS-24)</title>
		<meeting>the 37th International FLAIRS Conference (FLAIRS-24)</meeting>
		<imprint>
			<publisher>Florida Online Journals</publisher>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Lifting Factor Graphs with Some Unknown Factors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luttermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gehrke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU-23)</title>
		<meeting>the 17th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU-23)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="337" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Estimating High-Dimensional Intervention Effects from Observational Data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Maathuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kalisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="3133" to="3164" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">First-Order Bayes-Ball</title>
		<author>
			<persName><forename type="first">W</forename><surname>Meert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taghipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Blockeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD-10)</title>
		<meeting>the 14th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD-10)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="369" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Lifted Probabilistic Inference with Counting Formulas</title>
		<author>
			<persName><forename type="first">B</forename><surname>Milch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haimes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23th AAAI Conference on Artificial Intelligence (AAAI-08)</title>
		<meeting>the 23th AAAI Conference on Artificial Intelligence (AAAI-08)</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1062" to="1068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Estimating the Effect of Joint Interventions from Observational Data in Sparse High-Dimensional Settings</title>
		<author>
			<persName><forename type="first">P</forename><surname>Nandy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Maathuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="647" to="674" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tractability through Exchangeability: A New Perspective on Efficient Probabilistic Inference</title>
		<author>
			<persName><forename type="first">M</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Den Broeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI-14)</title>
		<meeting>the 28th AAAI Conference on Artificial Intelligence (AAAI-14)</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2467" to="2475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fusion, Propagation, and Structuring in Belief Networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="241" to="288" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Causality: Models, Reasoning and Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Causal Inference in Statistics: A Primer. Wiley, 1st edn</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jewell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Identifying Causal Effects in Maximally Oriented Partially Directed Acyclic Graphs</title>
		<author>
			<persName><forename type="first">E</forename><surname>Perkovic</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI-20)</title>
		<meeting>the 36th Conference on Uncertainty in Artificial Intelligence (UAI-20)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="530" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">First-Order Probabilistic Inference</title>
		<author>
			<persName><forename type="first">D</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI-03)</title>
		<meeting>the 18th International Joint Conference on Artificial Intelligence (IJCAI-03)</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="985" to="991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bayes-Ball: Rational Pastime (For Determining Irrelevance and Requisite Information in Belief Networks and Influence Diagrams)</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence (UAI-98)</title>
		<meeting>the 14th Conference on Uncertainty in Artificial Intelligence (UAI-98)</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="480" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<title level="m">Causation, Prediction, and Search</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Lifted Variable Elimination: Decoupling the Operators from the Constraint Language</title>
		<author>
			<persName><forename type="first">N</forename><surname>Taghipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fierens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Blockeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="393" to="439" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Causality with Gates</title>
		<author>
			<persName><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS-12)</title>
		<meeting>the 15th International Conference on Artificial Intelligence and Statistics (AISTATS-12)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1314" to="1322" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
