<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Leveraging Causal Inference for Explainable Automatic Program Repair</title>
				<funder>
					<orgName type="full">Ping An Technology (Shenzhen) Co</orgName>
				</funder>
				<funder ref="#_PnBT3Hg">
					<orgName type="full">Key Research and Development Program of Guangdong Province</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2022-06-06">6 Jun 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jianzong</forename><surname>Wang</surname></persName>
							<email>jzwang@188.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Technology (Shenzhen) Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shijing</forename><surname>Si</surname></persName>
							<email>shijing.si@outlook.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Technology (Shenzhen) Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Technology (Shenzhen) Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhitao</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Technology (Shenzhen) Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaoyang</forename><surname>Qu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Technology (Shenzhen) Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenhou</forename><surname>Hong</surname></persName>
							<email>hongzhenhou168@pingan.com.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Technology (Shenzhen) Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Xiao</surname></persName>
							<email>xiaojing661@pingan.com.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Technology (Shenzhen) Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Leveraging Causal Inference for Explainable Automatic Program Repair</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-06-06">6 Jun 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2205.13342v2[cs.SE]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Automated Program Repair</term>
					<term>Program Analysis</term>
					<term>Sequence-to-sequence Model</term>
					<term>Causal Inference</term>
					<term>Interpretability</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning models have made significant progress in automatic program repair. However, the black-box nature of these methods has restricted their practical applications. To address this challenge, this paper presents an interpretable approach for program repair based on sequence-to-sequence models with causal inference and our method is called CPR, short for causal program repair. Our CPR can generate explanations in the process of decision making, which consists of groups of causally related input-output tokens. Firstly, our method infers these relations by querying the model with inputs disturbed by data augmentation. Secondly, it generates a graph over tokens from the responses and solves a partitioning problem to select the most relevant components. The experiments on four programming languages (Java, C, Python, and JavaScript) show that CPR can generate causal graphs for reasonable interpretations and boost the performance of bug fixing in automatic program repair.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The goal of automatic program repair (APR) techniques is to automatically correct bug(s) in a piece of existing troublesome source code. Many researches have been devoted on applying machine learning techniques to APR <ref type="bibr" target="#b0">[1]</ref>. Given the similarity between a program repair task and generic natural language processing (NLP) tasks such as sequence-to-sequence (Seq2Seq) learning and machine translation <ref type="bibr" target="#b1">[2]</ref>, there has been a lot of work on applying machine learning for program repair <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b5">[6]</ref> in recent years. Similar techniques have been applied to code related tasks <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>.</p><p>Although deep learning based Seq2Seq models have achieved overwhelming success in APR tasks, there still remains a lot of potential for improvement <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>. One major concern is the interpretability of the deep Seq2Seq models, which is caused by the complicated nature of model architectures <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. The interpretability of deep models is often categorized into two types: 1.) model interpretability, which attempts to make the deep neural architecture itself interpretable and transparent, and 2.) prediction interpretability, which aims to explain particular predictions of the deep model <ref type="bibr" target="#b13">[14]</ref>. Once a deep APR model has achieved these two aspects of interpretability, it becomes trustworthy, transparent, and controllable, which surely makes deep models more useful for practical deployment.</p><p>To improve the interpretability of APR models, this paper introduces causal inference, which has shown great promise in discovering causal relations in deep learning <ref type="bibr" target="#b14">[15]</ref>. Simply combining APR with causal inference can lead to a few significant challenges. This paper aims to address three important unsolved issues about how to use causal inference in APR models. Because transparency in the deep APR models is often very restrictive and challenging to achieve <ref type="bibr" target="#b15">[16]</ref>, the first issue is how can we alleviate this difficult situation in real application. The second issue is how to define the causal graph in the APR task. The third issue is what kind of performance can be achieved by APR model combined with causal inference.</p><p>For the first issue, in this work we concentrate on prediction interpretability rather than model transparency. From the machine learning community, prediction interpretability can be sought more easily with existing mehtods, like Monte Carlo Dropout, Ensemble or Bayesian deep neural networks <ref type="bibr" target="#b16">[17]</ref>. In a typical APR problem, the inputs are the original code and comments, the output is the predicted repaired code. To tackle the second issue, we can define the causal graph since we are focusing on the interpretable relationship between input and output. In a causal graph, the context is the input of code and comments, the outcome is the predicted repaired code, and the confounder is the data disturbance, i.e., the data augmentation. For the third challenge, we alter the potential confounder, which is one kind of text data augmentation, and observe the effect of APR with causal inference.</p><p>Specifically, we propose to utilize data augmentation strategy to discover the causal relations between the input source (that is, the code and comments) and the corrected bugs, which can improve the prediction interpretability of APR models. Data augmentation methods are used to disturb the original inputs, which are then fed into the deep Seq2Seq model to infer the causal relation between the input and output tokens in the similar manner as <ref type="bibr" target="#b14">[15]</ref>. <ref type="bibr" target="#b14">[15]</ref> utilized a Variational auto-Encoder for data disturbation, which is computationally costly and hard to control. Our method is called CPR, short for Causal Program Repair, which leverages text data augmentation and easy to implement.</p><p>Our main contributions can be listed as follows:  • In the experiments, our framework can offer explanations on various Seq2Seq models in APR, which exhibits its ability to enhance the performance and provide insights into how the black-box models make predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>Our CPR is closely related to two lines of research: Seq2Seq model for automatic code repair and the causal inference. Therefore, we discuss the related research in the following two subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Sequence-to-Sequence Models in Automatic Code Repair</head><p>There are many existing works that attempt to use machine translation techniques to automatically fix bugs. Here are the most notable methods in this area. <ref type="bibr" target="#b17">[18]</ref> formulates the patches generation as a Seq2Seq translation problem and proposes to use a neural machine translation (NMT) model with attention-based Encoder-Decoder. To evaluate the performance of various APR methods, <ref type="bibr" target="#b18">[19]</ref> presents BEARS, a project for collecting and storing bugs into an extensible bug benchmark for automatic repair studies in Java. SequenceR <ref type="bibr" target="#b3">[4]</ref> leverages a Seq2Seq model by combining an encoder and a decoder architecture, where recurrent neural networks (RNNs) with LSTM gates are used for both the encoder and decoder. <ref type="bibr" target="#b9">[10]</ref> propose an APR framework using formal specification and expression templates.</p><p>Using a RNN encoder-decoder, <ref type="bibr" target="#b19">[20]</ref> investigates the application of NMT for candidate patches generation. Applying NMT techniques and ensemble learning, CoCoNuT <ref type="bibr" target="#b5">[6]</ref> can automatically repair programs of multiple languages in a end-to-end manner. <ref type="bibr" target="#b20">[21]</ref> proposes a new NMT-based APR technique, called CURE, which leverages pre-training, subword tokenization and an efficient code-aware search strategy. <ref type="bibr" target="#b21">[22]</ref> proposes a real-time code fix mechanism by semantic code suggestions, which is shown to improve the speed of repairing faulty programs. More details on APR can be found in <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Causal Inference</head><p>There is a very large body of work that attempts to address the issue of "explanation", but it is actually quite biased due to the different definitions of "explanation" that are of interest. In the field of machine learning, the area where interpretability is probably most valued is in medical applications, where the credibility of a predictive model depends heavily on its interpretability <ref type="bibr" target="#b23">[24]</ref>. With the advent of the deep learning trend, recent work has enhanced each of the two aspects of interpretability: model transparency <ref type="bibr" target="#b24">[25]</ref> and model functionality <ref type="bibr" target="#b25">[26]</ref>. For a broad survey of interpretability in deep learning, we refer the reader to the survey <ref type="bibr" target="#b26">[27]</ref>.</p><p>Model interpretability methods based on causal inference (counterfactual samples) have been increasingly applied to various scenarios. Among them, the sample-based explanation approach aims to explain the decision and judgment process of the model by finding sample examples. <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b27">[28]</ref> proposes a model that justifies the prediction results using fragments of the input. One of the most typical approaches is the counterfactual explanations that interpret the model's decisions by making minimal changes to the features on the existing samples and obtaining the expected counterfactual results, and collecting these samples with minor changes. <ref type="bibr" target="#b28">[29]</ref> relies on local perturbations of the instance to explain the predictions of the black-box classifiers. A generic counterfactual generator with sequential control of perturbation types and positions is further proposed by <ref type="bibr" target="#b29">[30]</ref>, which can generate diverse sets of realistic counterfactuals that can be useful in various distinct applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD</head><p>Comparing the Fig. <ref type="figure" target="#fig_0">1</ref>(a), (b) and (c), we can transition from NMT to APR with causal inference, which is Fig. <ref type="figure" target="#fig_0">1(c</ref>). Comparing Fig. <ref type="figure" target="#fig_0">1 (a</ref>) and (b), the process of APR is similar to NMT. Both input source text and target text, and the expected text is inferred through the Seq2Seq model. According to Fig. <ref type="figure" target="#fig_0">1(b)</ref>, we propose an APR framework with causal analysis, as illustrated by Fig. <ref type="figure" target="#fig_0">1(c)</ref>.</p><p>As demonstrated in Fig. <ref type="figure" target="#fig_2">2</ref>(a), we define a causal graph. In causal inference, capital X represents the treatment, capital A represents the potential confounder, and capital Y represents the outcome. In the APR problem, capital X is the input of code and comments, capital A indicates the data augmentation, and capital Y is the output of predicted repaired code. Based on the data augmentation, potential confounder A will influence X and Y, so we define the causal graph like the Fig. <ref type="figure" target="#fig_2">2(a)</ref>. To identify the input and output causality, we need to know the predict interpretability after we've defined the causal graph. Changing the input through data augmentation methods, we  Our approach formalizes this framework through a pipeline (sketched in Fig. <ref type="figure" target="#fig_0">1(c</ref>)) that consists of three main components, each of which is described in detail in the following section: a perturbation model for locally exercising F , a causal inference model for inferring associations between inputs and predictions, and a selection step for partitioning and selecting the most relevant sets of associations.</p><formula xml:id="formula_0">Causal Inference Explanation Selection Perturbation Input X → ( ∪ , ) APR model Y X Y Fig.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The framework of CPR.</head><p>The first step in the explainable APR approach is to obtain perturbed versions of the input: which involves changing the elements and their order in original input sentences. In <ref type="bibr" target="#b14">[15]</ref>, they propose a variational auto-encoder(VAE) model to perturb the text. However, training a VAE or bidirectional LSTM language model takes a lot of time and effort.</p><p>Based on <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, here we use the data augmentation to generate the perturbed comment texts. For word perturbation:</p><p>1) Synonym Replacement (SR): Select m words randomly from the original sentence that does not include stop words.</p><p>Then alter these words with one of closeness meaning chosen at random. 2) Random Insertion (RI): Find a most similar meaning for a random word in the original sentence (not include stop words). Insert that most similar word into a stochastic position in the sentence. Repeat m times. 3) Random Swap (RS): Casually select two words from the original sentence and switch their positions in m times. 4) Random Deletion (RD): With probability p. Delete words from the original sentence randomly. For sentence perturbation, we use Back-Translation (BT): Translating an existing example x in language A into another language B and then translating it back into A to obtain an augmented example x.</p><p>Long sentences will perform more word perturbation since they include more words than short ones. To fair comparison, we vary the number m for word perturbation based on the sentence length l with the formula m = αl , where α is a parameter that indicates the percent of the changed words in a sentence (we use p = α for RD). Furthermore, we generate m dist disturbed sentences for each original sentence.</p><p>To perturb the comment texts, the data augmentations operate the level of the words, and the symbols like {, : or == e.t.c. Symbols are also an essential part of a programming language.</p><p>This data augmentation strategy achieves similar outcomes but is considerably easier to employ because it does not involve the training of a language model and the usage of external datasets. We argue that it can be easily ported to other similar models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL SETUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>To train the ARP models in different programming languages, we collected corresponding training datasets for different programming languages based on the open-source datasets. For Java, we use Defects4J <ref type="bibr" target="#b32">[33]</ref> and QuixBugs <ref type="bibr" target="#b33">[34]</ref>. For Python, we use Python's version of QuixBugs. For C, we used the ManyBugs datasets from prior work <ref type="bibr" target="#b34">[35]</ref>. In order to compare with the Java, Python, and C program language, we select 12 JavaScript examples connected with ordinary bug problems in prior work (BugAID) <ref type="bibr" target="#b35">[36]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Settings</head><p>Training. In order to ensure the completeness of comparison, the details of training parameters are given here. Following Fig. <ref type="figure" target="#fig_0">1</ref>(c), we have two parts that need to train and inference, the APR model and the explainable graph. First, we use hyperband <ref type="bibr" target="#b36">[37]</ref> to tune hyper-parameters. We restrict the range of hyper-parameters to appropriate values. The size of embedding is 64 to 512, the dimensions of convolutional layer is 32 to 256, the number of convolutional layers is 1 to 10, the size of hidden units of LSTM is 128 to 512, the size of Transformer heads is 4 to 8, the size of hidden units of Transformer is 128 to 512. The learning rate is 0.1, 0.01, 0.001, and 0.0001. Then we train APR models for one epoch on the different training sets with various hyper-parameters for tuning. We are ranking the hyper-parameters sets based on their perplexity. Perplexity is a typical metric in NLP that quantifies how well a model generates a sequence. We make it stop at convergence or until 20 epochs and ranking the the top-k (default k=5) models. In inference mode, we employ beam search with a beamwidth of 784.</p><p>Explainable graph. We equally chose a data disturbance method to generate the disturbed input based on the proposed data augmentation strategy. For the explainable graph step, we use the robust clustering method of <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref> to generate the graph in the experiment. These bilateral clustering methods do not take uncertainty into account.</p><p>Infrastructure We use the LSTM, and Transformer is running on Pytorch <ref type="bibr" target="#b39">[40]</ref>. The implementations of FConv is provided by fairseq-py <ref type="bibr" target="#b40">[41]</ref>. We also use the implementation of Code-BERT <ref type="bibr" target="#b41">[42]</ref> running on Pytorch. Our models were trained and evaluated on an Intel Xeon E5-2695 with 4 NVIDIA V100 GPUs.</p><p>Performance The average time it takes to train the APR models for one epoch during tuning is 51 minutes. Sequentially for the SequenceR, FConv, and CodeBERT, it takes 93, 67, and 253 hours to train the model until convergence. In the inference stage, producing 1000 patches for a bug brings 9 seconds on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Evaluation and Results</head><p>The performance with causal inference Table <ref type="table" target="#tab_1">I</ref> displays the number of bugs fixed by the different approaches with or without causal inference. For all datasets, causal inference is used to improve the effect of debugging code. We test in four languages, and both models have been improved using causal inference. On the BugAID dataset, which is for JavaScript language, We observed an intriguing result. The debugs number for all three models is relatively less, and for FConv, the causal inference is not working. For SequenceR and CdoeBERT, the effect of improvement is not obvious. We believe that the main reason is that the amount of data is too small. Table <ref type="table" target="#tab_2">II</ref> depicts the different consequences of different data disturbance approaches in our framework. The RI, RS, and RD approaches would degrade the performance of APR with causal inference. In the FConv model with the RD method, its performance is almost the same as that of a model without causal inference. Likewise, the CodeBERT with the RS method, which reduces the number of fixed codes to 12, achieves the same performance without causal inference. When using the APR model with causal inference, the SR and BT methods are the best choices. It demonstrates that the SR and BT methods have the best effect in the APR model with causal inference. It helps when the APR model with the explainable graph because the SR and BT methods can maintain the original meaning of comments. Fig. <ref type="figure" target="#fig_5">5</ref> shows the input and output's interpretable relation with explanation graphs. The connected blue circle with more gray lines from green circles is more relevant. The density of gray lines might show whether or not the error code corresponds to the proper code. As shown in Fig. <ref type="figure" target="#fig_5">5</ref>, the incorrect part of the buggy code is most connected to the correct part in the repaired code.  The explanation graph in data perturbation. Fig. <ref type="figure" target="#fig_5">5</ref> shows the explanation graph when using data augmentation. In Fig. <ref type="figure" target="#fig_5">5</ref> (a), (b), and (c), the buggy code is all connected to the most relevant input. Especially in Fig. <ref type="figure" target="#fig_5">5</ref>(b), the incorrect symbol is connected to the correct symbol, where the second blue circle is the right answer. In Fig. <ref type="figure" target="#fig_5">5</ref> (d), the debugged code deletes the wrong parts compared to the buggy code. Since the solution is to delete the buggy code, the input is rarely connected to the output.</p><p>The bitwise AND operator is wrong.  and RS will cause some irrelevant connections to grow. The SR and BT methods can preserve the correct connections as seen in Fig. <ref type="figure" target="#fig_6">6</ref>.</p><p>Overall, Fig. <ref type="figure" target="#fig_6">6</ref> shows that our framework can demonstrate the interpretability of input and output. The data augmentation strategy and the explanation graph continuously provide improvements to model effects, but appropriate data augmentation approaches will make them more powerful.</p><p>V. CONCLUSION Our data augmentation approach combined with a modelagnostic framework for prediction interpretability can produce reasonable, related explanations. We formulate the explanation problem of APR model in causal inference. Our methods can be generalized to a variety of settings in which inputs and outputs can be expressed as sets of features. Also, we used data augmentation sampling for data disturbances. Experiments with various data augmentation methodologies suggest that the APR model can be utilized as a causal inference tool.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Comparison of three frameworks of NMT, APR and CPR. The boxes and arrows in blue in (c) mean the causal parts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>The input and output connections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The causal graph in APR task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.<ref type="bibr" target="#b3">4</ref>. We inferred dependency graphs before (left) and after (right) explanation selection for the prediction. Our framework generates dependency estimates and explanation graphs. The green circles mean the buggy code, the yellow circles mean the comments text, and the blue circles mean debugged code. (a) Raw Dependencies.(b) Explanation Graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Dependency estimates and explanation graph generated by our framework. The green circles means the buggy code, the yellow circles means the comments text, the blue circles means debugged code.(a) Explanation graph in Python.(b) Explanation graph in Python.(c) Explanation graph in Java.(d) Explanation graph in Java.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Dependency estimates and explanation graph generated with data disturbances. The green circles mean the buggy code, the yellow circles mean the comments text, and the blue circles mean debugged code. (a) Explanation graph in Python, without data disturbances. (b) Explanation graph in Python, with SR. (c) Explanation graph in Python, with RI. (d) Explanation graph in Python, with RD. (e) Explanation graph in Python, with RS. (f) Explanation graph in Python, with BT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 (</head><label>6</label><figDesc>Fig.6(b), (c), (d), (e), and (f) illustrate the circumstance when the data augmentation is implemented for the comment text. It shows that the comment text is still connected to the most relevant part but the irrelevant connections have increased. As in Fig.6 (c), (d), and (e), the second blue circle gets the connection, but the graph has deleted some unimportant connections to other circles. Data augmentation like RI, RD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I COMPARISON</head><label>I</label><figDesc>OF THE FIXED BUGS WITH CAUSAL INFERENCE AND WITHOUT CAUSAL INFERENCE. "CI" MEANS CAUSAL INFERENCE. THE EFFECTIVENESS OF MODELS IS MEASURED BY THE NUMBER OF FIXED BUGS</figDesc><table><row><cell>Dataset</cell><cell>Model</cell><cell cols="5">Paremeters Language Bugs number fixed w/o CI fixed with CI (CPR)</cell></row><row><cell>Defects4J</cell><cell>SequenceR</cell><cell>38M</cell><cell>Java</cell><cell>393</cell><cell>12</cell><cell>20</cell></row><row><cell>Defects4J</cell><cell>FConv</cell><cell>23M</cell><cell>Java</cell><cell>393</cell><cell>12</cell><cell>21</cell></row><row><cell>Defects4J</cell><cell>CodeBERT</cell><cell>675M</cell><cell>Java</cell><cell>393</cell><cell>14</cell><cell>23</cell></row><row><cell>QuixBugs</cell><cell>SequenceR</cell><cell>38M</cell><cell>Java</cell><cell>40</cell><cell>7</cell><cell>13</cell></row><row><cell>QuixBugs</cell><cell>FConv</cell><cell>23M</cell><cell>Java</cell><cell>40</cell><cell>8</cell><cell>11</cell></row><row><cell cols="2">QuixBugs CodeBERT</cell><cell>675M</cell><cell>Java</cell><cell>40</cell><cell>13</cell><cell>17</cell></row><row><cell>QuixBugs</cell><cell>SequenceR</cell><cell>38M</cell><cell>Python</cell><cell>40</cell><cell>6</cell><cell>13</cell></row><row><cell>QuixBugs</cell><cell>FConv</cell><cell>23M</cell><cell>Python</cell><cell>40</cell><cell>9</cell><cell>14</cell></row><row><cell cols="2">QuixBugs CodeBERT</cell><cell>675M</cell><cell>Python</cell><cell>40</cell><cell>12</cell><cell>19</cell></row><row><cell cols="2">ManyBugs SequenceR</cell><cell>38M</cell><cell>C</cell><cell>69</cell><cell>11</cell><cell>16</cell></row><row><cell>ManyBugs</cell><cell>FConv</cell><cell>23M</cell><cell>C</cell><cell>69</cell><cell>9</cell><cell>15</cell></row><row><cell cols="2">ManyBugs CodeBERT</cell><cell>675M</cell><cell>C</cell><cell>69</cell><cell>13</cell><cell>18</cell></row><row><cell>BugAID</cell><cell>SequenceR</cell><cell>38M</cell><cell>JavaScript</cell><cell>12</cell><cell>4</cell><cell>6</cell></row><row><cell>BugAID</cell><cell>FConv</cell><cell>23M</cell><cell>JavaScript</cell><cell>12</cell><cell>3</cell><cell>3</cell></row><row><cell>BugAID</cell><cell>CodeBERT</cell><cell>675M</cell><cell>JavaScript</cell><cell>12</cell><cell>6</cell><cell>7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II COMPARISON</head><label>II</label><figDesc>OF DIFFERENT DATA DISTURBANCES IN OUR FRAMEWORK. "CI" MEANS CAUSAL INFERENCE. THE EFFECTIVENESS OF MODELS IS MEASURED BY THE NUMBER OF FIXED BUGS.</figDesc><table><row><cell>Dataset</cell><cell>Model</cell><cell cols="6">Paremeters Language Bugs number Data augmentation fixed w/o CI fixed with CI (CPR)</cell></row><row><cell cols="2">QuixBugs SequenceR</cell><cell>38M</cell><cell>Python</cell><cell>40</cell><cell>SR</cell><cell>10</cell><cell>13</cell></row><row><cell cols="2">QuixBugs SequenceR</cell><cell>38M</cell><cell>Python</cell><cell>40</cell><cell>RI</cell><cell>8</cell><cell>10</cell></row><row><cell cols="2">QuixBugs SequenceR</cell><cell>38M</cell><cell>Python</cell><cell>40</cell><cell>RS</cell><cell>7</cell><cell>11</cell></row><row><cell cols="2">QuixBugs SequenceR</cell><cell>38M</cell><cell>Python</cell><cell>40</cell><cell>RD</cell><cell>8</cell><cell>11</cell></row><row><cell cols="2">QuixBugs SequenceR</cell><cell>38M</cell><cell>Python</cell><cell>40</cell><cell>BT</cell><cell>9</cell><cell>12</cell></row><row><cell>QuixBugs</cell><cell>FConv</cell><cell>23M</cell><cell>Python</cell><cell>40</cell><cell>SR</cell><cell>11</cell><cell>14</cell></row><row><cell>QuixBugs</cell><cell>FConv</cell><cell>23M</cell><cell>Python</cell><cell>40</cell><cell>RI</cell><cell>8</cell><cell>11</cell></row><row><cell>QuixBugs</cell><cell>FConv</cell><cell>23M</cell><cell>Python</cell><cell>40</cell><cell>RS</cell><cell>9</cell><cell>12</cell></row><row><cell>QuixBugs</cell><cell>FConv</cell><cell>23M</cell><cell>Python</cell><cell>40</cell><cell>RD</cell><cell>9</cell><cell>10</cell></row><row><cell>QuixBugs</cell><cell>FConv</cell><cell>23M</cell><cell>Python</cell><cell>40</cell><cell>BT</cell><cell>12</cell><cell>14</cell></row><row><cell cols="2">QuixBugs CodeBERT</cell><cell>675M</cell><cell>Python</cell><cell>40</cell><cell>SR</cell><cell>14</cell><cell>18</cell></row><row><cell cols="2">QuixBugs CodeBERT</cell><cell>675M</cell><cell>Python</cell><cell>40</cell><cell>RI</cell><cell>11</cell><cell>15</cell></row><row><cell cols="2">QuixBugs CodeBERT</cell><cell>675M</cell><cell>Python</cell><cell>40</cell><cell>RS</cell><cell>9</cell><cell>12</cell></row><row><cell cols="2">QuixBugs CodeBERT</cell><cell>675M</cell><cell>Python</cell><cell>40</cell><cell>RD</cell><cell>9</cell><cell>13</cell></row><row><cell cols="2">QuixBugs CodeBERT</cell><cell>675M</cell><cell>Python</cell><cell>40</cell><cell>BT</cell><cell>13</cell><cell>19</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENT</head><p>This paper is supported by the <rs type="funder">Key Research and Development Program of Guangdong Province</rs> under grant No.<rs type="grantNumber">2021B0101400003</rs>. Corresponding author is <rs type="person">Shijing Si</rs> from <rs type="funder">Ping An Technology (Shenzhen) Co</rs>., Ltd (sishi-jing204@pingan.com.cn).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_PnBT3Hg">
					<idno type="grant-number">2021B0101400003</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic software repair: a bibliography</title>
		<author>
			<persName><forename type="first">M</forename><surname>Monperrus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Syntactic knowledge-infused transformer and bert models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sundararaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CIKM 2021 Workshops</title>
		<meeting>the CIKM 2021 Workshops</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An empirical investigation into learning bug-fixing patches in the wild via neural machine translation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tufano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bavota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poshyvanyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ASE</title>
		<meeting>ASE</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="832" to="837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sequencer: Sequence-to-sequence learning for endto-end program repair</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Kommrusch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tufano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-N</forename><surname>Pouchet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poshyvanyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Monperrus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dlfix: Context-based code transformation learning for automated program repair</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICSE</title>
		<meeting>ICSE</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="602" to="614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Coconut: Combining context-aware neural translation models using ensemble for program repair</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lutellier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis</title>
		<meeting>the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="101" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Summarizing source code using a neural attention model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2073" to="2083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Latent predictor networks for code generation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kočiskỳ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="599" to="609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A syntactic neural model for general-purpose code generation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="440" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic program repair using formal verification and expression templates</title>
		<author>
			<persName><forename type="first">T.-T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-T</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-N</forename><surname>Chin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Verification, Model Checking, and Abstract Interpretation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="70" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A comprehensive study of automatic program repair on the quixbugs benchmark</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Durieux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Monperrus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="page">110825</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improving interpretability of deep neural networks with semantic information</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE CVPR</title>
		<meeting>the IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4306" to="4314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural translation and automated recognition of icd-10 medical entities from natural language: Model development and performance assessment</title>
		<author>
			<persName><forename type="first">L</forename><surname>Falissard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morgand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ghosn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Imbaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bounebache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMIR medical informatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">e26353</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Rationalizing neural predictions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A causal framework for explaining the predictions of black-box sequence-to-sequence models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Alvarez-Melis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="412" to="421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic programming: The open issue?</title>
		<author>
			<persName><forename type="first">M</forename><surname>O'neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Spector</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetic Programming and Evolvable Machines</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="251" to="262" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Simple and principled uncertainty estimation with deterministic deep learning via distance awareness</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Padhy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Bedrax</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7498" to="7512" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Learning to generate corrective patches using neural machine translation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shihab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.07170</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bears: An extensible java bug benchmark for automatic program repair studies</title>
		<author>
			<persName><forename type="first">F</forename><surname>Madeiral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Urli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Monperrus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="468" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An empirical study on learning bug-fixing patches in the wild via neural machine translation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tufano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bavota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poshyvanyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Software Engineering and Methodology (TOSEM)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cure: Code-aware neural machine translation for automatic program repair</title>
		<author>
			<persName><forename type="first">N</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lutellier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICSE</title>
		<meeting>ICSE</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1161" to="1173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic program repair as semantic suggestions: An empirical study</title>
		<author>
			<persName><forename type="first">D</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Restivo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICST</title>
		<meeting>ICST</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="217" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A literature review on automated code repair</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mamatha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Bindu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Recent Trends in Machine Learning, IoT, Smart Cities and Applications</title>
		<meeting>the 2nd International Conference on Recent Trends in Machine Learning, IoT, Smart Cities and Applications</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="249" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGKDD</title>
		<meeting>SIGKDD</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1721" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Understanding deep image representations by inverting them</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mahendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2015.7299155</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2015.7299155" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE CVPR</title>
		<meeting>the IEEE CVPR</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="5188" to="5196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generating natural counterfactual visual explanations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kurihara</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2020/742</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2020/742" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, C. Bessiere</title>
		<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, C. Bessiere</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5204" to="5205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A roadmap for a rigorous science of interpretability</title>
		<author>
			<persName><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08608</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ẅhy should i trust you?&quot; explaining the predictions of any classifier</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGKDD</title>
		<meeting>SIGKDD</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Fairfil: Contrastive neural debiasing method for pretrained text encoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Polyjuice: Generating counterfactuals for explaining, evaluating, and improving models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL/IJCNLP. ACL</title>
		<meeting>ACL/IJCNLP. ACL</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6707" to="6723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Eda: Easy data augmentation techniques for boosting performance on text classification tasks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-IJCNLP</title>
		<meeting>EMNLP-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6383" to="6389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Understanding backtranslation at scale</title>
		<author>
			<persName><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Defects4j: A database of existing faults to enable controlled testing studies for java programs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Just</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 International Symposium on Software Testing and Analysis</title>
		<meeting>the 2014 International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="437" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Quixbugs: A multilingual program repair benchmark set based on the quixey challenge</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Solar-Lezama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Companion of the 2017 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity</title>
		<meeting>Companion of the 2017 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="55" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The manybugs and introclass benchmarks for automated repair of c programs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Le Goues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Holtschulte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Brun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Devanbu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Forrest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1236" to="1256" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Discovering bug patterns in javascript</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Hanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S D M</forename><surname>Brito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mesbah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 24th ACM SIGSOFT international symposium on foundations of software engineering</title>
		<meeting>the 2016 24th ACM SIGSOFT international symposium on foundations of software engineering</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="144" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Hyperband: a novel bandit-based approach to hyperparameter optimization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Desalvo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="6765" to="6816" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Co-clustering documents and words using bipartite spectral graph partitioning</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGKDD</title>
		<meeting>SIGKDD</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="269" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Spectral biclustering of microarray data: coclustering genes and conditions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kluger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="703" to="716" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Convolutional sequence to sequence learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1243" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Codebert: A pre-trained model for programming and natural languages</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP: Findings</title>
		<meeting>EMNLP: Findings</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1536" to="1547" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
