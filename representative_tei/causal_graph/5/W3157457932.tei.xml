<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MicroDiag: Fine-grained Performance Diagnosis for Microservice Systems</title>
				<funder ref="#_rgNVg6s">
					<orgName type="full">European Union</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Li</forename><surname>Wu</surname></persName>
							<email>li.wu@elastisys.com</email>
							<affiliation key="aff0">
								<orgName type="department">Elastisys AB</orgName>
								<address>
									<settlement>Umeå</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Distributed and Operating Systems Group</orgName>
								<orgName type="institution">TU Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Johan</forename><surname>Tordsson</surname></persName>
							<email>johan.tordsson@elastisys.com</email>
							<affiliation key="aff0">
								<orgName type="department">Elastisys AB</orgName>
								<address>
									<settlement>Umeå</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">Umeå University</orgName>
								<address>
									<settlement>Umeå</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jasmin</forename><surname>Bogatinovski</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Distributed and Operating Systems Group</orgName>
								<orgName type="institution">TU Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Erik</forename><surname>Elmroth</surname></persName>
							<email>erik.elmroth@elastisys.com</email>
							<affiliation key="aff0">
								<orgName type="department">Elastisys AB</orgName>
								<address>
									<settlement>Umeå</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">Umeå University</orgName>
								<address>
									<settlement>Umeå</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Odej</forename><surname>Kao</surname></persName>
							<email>odej.kao@tu-berlin.de</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Distributed and Operating Systems Group</orgName>
								<orgName type="institution">TU Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MicroDiag: Fine-grained Performance Diagnosis for Microservice Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Performance diagnosis</term>
					<term>Microservice system</term>
					<term>Causal inference</term>
					<term>Data-driven</term>
					<term>Fine-grained root cause</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Microservice architecture has emerged as a popular pattern for developing large-scale applications for its benefits of flexibility, scalability, and agility. However, the large number of services and complex dependencies make it difficult and timeconsuming to diagnose performance issues. We propose Micro-Diag, an automated system to localize root causes of performance issues in microservice systems at a fine granularity, including not only locating the faulty component but also discovering detailed information for its abnormality. MicroDiag constructs a component dependency graph and performs causal inference on diverse anomaly symptoms to derive a metrics causality graph, which is used to infer root causes. Our experimental evaluation on a microservice benchmark running in a Kubernetes cluster shows that MicroDiag localizes root causes well, with 97% precision of the top 3 most likely root causes, outperforming state-of-the-art methods by at least 31.1%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Microservices architecture (MSA) has been adopted in many domains such as edge computing, internet of things (IoT), and cloud computing <ref type="bibr" target="#b0">[1]</ref>, to design large-scale applications because of its benefits of resilience, scalability, and acceleration of software delivery, etc <ref type="bibr" target="#b1">[2]</ref>. With MSA, an application is decomposed into autonomous units that can be deployed independently and intercommunicate with lightweight protocols. However, due to the highly distributed and dependent nature of microservice systems, performance issues are inevitable and it is infeasible for operators to diagnose them manually <ref type="bibr" target="#b2">[3]</ref>.</p><p>To resolve performance issues quickly, it is critical to automate the diagnosis process and pinpoint root causes at a fine granularity, i.e., identifying both the faulty component and details about why it is faulty (see Section III for a formal problem formulation). However, identifying fine-grained root causes in a microservice system is extremely difficult because of the following challenges. 1) A large number of anomalous metrics: A performance issue introduces anomalies to one or more metrics initially, but tends to propagate quickly to also create anomalies in other metrics, unrelated to root cause. It is a challenging task to pinpoint root causes from a large number of anomalous metrics; 2) Heterogeneous anomaly symptoms: Microservices can be polyglot and differ in other characteristics as well, which might lead to diverse anomaly symptoms for the same issue. 3) Frequently updates: Microservices are frequently updated to meet customers' needs (e.g., Netflix updates thousands of times per day <ref type="bibr" target="#b3">[4]</ref>), which might make the historical failure data obsolete. Hence, the performance diagnosis system must be able to adapt to changes. 4) A wide range of causes: Due to the complexity of microservice systems, the root cause for a performance issue can vary significantly, but issues can be broadly categorized as internal to a specific microservice (software bugs, configuration issues, etc) or external (third-party database, spike workload, etc). These causes have various symptoms, making it hard to localize them from observable metrics in microservice systems.</p><p>In the literature (Section II), various approaches based on deep learning <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, pattern recognition <ref type="bibr" target="#b6">[7]</ref>, and causal inference <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> have been proposed to identify fine-grained root causes for performance issues. However, deep learning based methods requires frequently retraining to follow up the updates in microservices and pattern recognition based methods have a high computation complexity and can only identify root causes for known issues. The third approach based on causal inference techniques constructs causality graph with metrics from multiple components and may fail to identify root causes that have diverse anomaly symptoms.</p><p>In this paper, we propose an application-agnostic system named MicroDiag (Section IV) for real-time performance diagnosis in microservice systems without requiring any historical anomaly data. MicroDiag continuously collects metrics from components and detects anomalies on SLO (Service Level Objective) metrics. Once an anomaly is detected, Micro-Diag infers fine-grained root causes by modeling the anomaly propagation with a metrics causality graph and ranking the culprit metrics by traversing along this graph. The metrics causality graph is derived from a component dependency graph with two causal inference methods, which are employed to detect anomaly propagation paths from diverse anomaly symptoms. As the metrics causality graph is based on causal inference between inter-dependent components, MicroDiag can easily scale to the number of components in the system.</p><p>We evaluate MicroDiag on a microservice system running on Google Cloud Engine 1 where the Sock-shop 2 microservice benchmark is deployed using Kubernetes and anomalies CPU hog and memory leaks are injected to different microservices (Section V). The evaluation show that our system can identify 97% of all root causes in one of the top 3 most likely causes, which outperforms the state-of-the-art methods by at least 31.1%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In the literature, different approaches have been proposed to diagnose performance issues in cloud computing <ref type="bibr" target="#b9">[10]</ref>, computer networks <ref type="bibr" target="#b10">[11]</ref>, and microservices <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. Overall, these approaches employ machine learning <ref type="bibr" target="#b4">[5]</ref>, pattern recognition <ref type="bibr" target="#b6">[7]</ref>, and causal inference <ref type="bibr" target="#b8">[9]</ref> to infer root causes. Some approaches aim to identify the faulty service or server node that initiates performance issues based on different observational data <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref>, such as tracing data, logs, and metrics. Here, we only discuss approaches for fine-grained performance diagnosis, which locates not only the faulty components but also hints for recovery.</p><p>Machine learning approaches <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> diagnose root causes by identifying features that significantly deviate from the predicted values estimated by machine learning algorithms. This kind of approach is based on the assumption that the anomalous causal feature has a significant deviation from its normal behavior. For example, reconstruction error from autoencoder is used to rank root causes in <ref type="bibr" target="#b5">[6]</ref>. Due to this assumption, machine learning approaches are limited to diagnose issues whose anomalous features can manifest significant deviations from their normal status. Besides, due to frequent updates of microservices, retraining might be frequently required, which is time-consuming and inefficient.</p><p>Álvaro Brandón, et al. <ref type="bibr" target="#b6">[7]</ref> define the performance diagnosis as a pattern recognition problem. They first label and store anomaly graphs from previous failures, then identify the root cause of a new anomaly by matching the anomalous pattern with previous knowledge. This method can identify the root cause at a fine-granularity if the anomaly graphs are labeled with fine-grained root causes. However, as the anomalous patterns are based only on previous anomalies, the method is limited to known issues. In addition, the computation complexity of graph matching is exponential to the size of the stored anomalous patterns.</p><p>Different causal inference methods has been applied to learn the causal relations among metrics. The Sieve <ref type="bibr" target="#b14">[15]</ref> and Loud <ref type="bibr" target="#b7">[8]</ref> systems construct anomaly propagation graph across all metrics using the Granger causality test. However, this test assumes time-lag between cause-effect metrics, which is quite restrictive for some observational metrics (e.g., resource metrics) in microservice systems. In MicroDiag, Granger causality tests are used only for accumulative effects and a structural equation model to infer the causal relations among contemporary metrics. Furthermore, MicroDiag limits the causal inference between inter-dependent components, which can eliminate a large number of spurious causal-effect relationships.</p><p>CauseInfer <ref type="bibr" target="#b8">[9]</ref> infers the root cause by constructing a metrics causality graph for each service with PC algorithm ((named after its authors, Peter and Clark <ref type="bibr" target="#b15">[16]</ref>), and each service is connected to other services by a service dependency graph. It gets the candidate culprit metrics by traversing the metrics causality graph of each service and ranks them with the significance of abnormality. However, with CauseInfer, it is difficult to know which service should be traversed first, and the method is sensitive to the root cause ranking results of individual service. In addition, instantaneous effects among resource metrics are also difficult to identify. MicroDiag constructs a metrics causality graph with metrics from all components, furthermore, the causality graph is constructed with the consideration of diverse anomaly propagation patterns in different components, which yields a higher accuracy in identifying causal-effect relationships and also root causes (see evaluation in Section V).</p><p>A variant of the PC algorithm that considers time-order of metrics is used in MicroCause <ref type="bibr" target="#b16">[17]</ref> to identify causality graph of metrics from multiple layers in microservice systems. However, as the time-series PC algorithm assumes time-lag between metrics, and conducts conditional independence test for data points of a metric, it would introduce high computation overhead and still cannot identify comtemporary effects well. MicroDiag differentiates the causal discovery of metrics from different layers, which is computationally efficient and scalable to the number of components. Additionally, Micro-Diag constructs a component dependency graph which can largely reduce spurious causal-effects, therefore improving the performance of root cause localization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROBLEM FORMULATION</head><p>In a typical microservice system, services run inside containers deployed in (virtual or physical) servers that are part of a cluster. We define services, containers, and servers as components C. In order to timely detect unexpected behaviors and assist the diagnosis, microservice systems are always equipped with a telemetry infrastructure, which provides extensive metrics time series M for components. We denote M c as metrics exposed by component c ∈ C, and m c i as an individual metric (e.g., response time, CPU utilization, read time of disk IO) of component c, where i is the type of metrics.</p><p>Based on above definition, the fine-grained performance diagnosis problem is formulated as follows: Given a set of components C and their exposed metrics M in a microservice system, assuming one or more anomalies are detected on response times m rt of microservices, how can we identify the culprit metric m crc rc that initiates the performance issue? A culprit metric m crc rc indicates not only the faulty component c rc but also the type of metrics m rc that causes the abnormality of c rc . For example, the culprit metric m s1 cpu utilization indicates that a high CPU utilization of service s 1 causes the performance degradation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SYSTEM DESIGN</head><p>In this section, we introduce details of the design of our system MicroDiag for fine-grained performance diagnosis in microservice systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. System Overview</head><p>To address the fine-grained performance diagnosis problem, we propose a system named MicroDiag, which can automatically localize root causes from observable metrics in real time without any application instrumentation.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> shows the overview of MicroDiag. Overall, there are five steps in MicroDiag to identify the fine-grained root cause. First of all, it continuously collects metrics data from microservice system and groups them by components as M c after preprocessing. Meanwhile, the response times of all microservices are monitored by the anomaly detection module. Once anomalies (unusually slow response times) are detected, the root cause localization process is triggered. In this process, MicroDiag firstconstructs a component dependency graph DG to model anomaly propagation across components, then infers causal relations among metrics of inter-dependent components using causal inference techniques and outputs a metrics causality graph M G. Finally, MicroDiag weighs the metrics causality graph and ranks culprit metrics m crc rc with a graph centrality algorithm, where the highest ranked metric has the highest probability to be the root cause. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Data Collection and Preprocessing</head><p>MicroDiag is designed to be application-agnostic. It collects metrics exposed by components from multiple layers, including microservices, containers and server nodes, without any instrumentation. It adopts a cloud-native monitoring stack, where Node-exporter 3 is used to monitor operating system of server nodes; Cadvisor 4 to monitor resources of containers and service mesh Istio 5 to monitor the network interactions between microservices, including response times. Once metrics are collected, the unvarying metrics will be removed and the rest of metrics will be grouped by components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Anomaly Detection</head><p>MicroDiag detects anomaly on the response times m rt of microservices using an unsupervised learning algorithm named Distance-Based online clustering BIRCH. For each response time which is a time series, MicroDiag applies the Birch clustering and detects it as an anomaly if multiple clusters are detected with a given threshold. Birch clustering is an efficient algorithm for anomaly detection which detects anomalies in real-time without relying on any historical failure data <ref type="bibr" target="#b17">[18]</ref>. 3 Node-exporter -<ref type="url" target="https://github.com/prometheus/node">https://github.com/prometheus/node</ref> exporter 4 Cadvisor -<ref type="url" target="https://github.com/google/cadvisor">https://github.com/google/cadvisor</ref>  5 Istio -<ref type="url" target="https://istio.io/">https://istio.io/</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Component Dependency Graph Construction</head><p>In order to infer the anomaly propagation across metrics, MicroDiag firstly constructs a component dependent graph to show the potential propagation across components, then detects the anomaly propagation across metrics of dependent components. By limiting the causal inference among metrics of inter-dependent components, the method can largely reduce spurious causal relations between unrelated metrics. In a microservice system (e.g., Figure <ref type="figure" target="#fig_2">2</ref> For each service, we add edges to all other services it communicates with and all containers it runs inside; For a container, we add edge to service it runs and server it runs on. For a server, we add edges to all containers it runs. Thus, we get a directed graph where some edges are bidirected. We discover the graph nodes and their dynamic relationships by enumerating and parsing the metrics exposed by the components, which is an extension of the attributed graph proposed in our previous work on root cause analysis for microservices <ref type="bibr" target="#b12">[13]</ref>. Specifically, we parse the servicelevel metrics collected by service mesh istio 5 to get the service dependencies and the system metrics collected by Cadvisor 4 to get the deployment information. Figure <ref type="figure" target="#fig_2">2(b)</ref> gives an example of the component dependency graph of the microservice system in Figure <ref type="figure" target="#fig_2">2</ref>(a), including service dependencies and deployment relationships among services, containers, and servers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Metrics Causality Graph Inference</head><p>After obtaining the component dependency graph, Micro-Diag use causal inference methods to construct a metrics causality graph across metrics of inter-dependent components.</p><p>In the metrics causality graph, each node represents an individual metric m c i of a component c and an edge represents a causal-effect relationship which is also an anomaly propagation path. For example, an edge from metric m p3 1 to metric m p3 2 in Figure <ref type="figure" target="#fig_2">2</ref>(c), means m p3 1 causes m p3 2 and the anomaly propagates from m p3 1 to m p3 2 . In order to identify the causal relations among metrics, Mi-croDiag divides the anomaly propagation properties into three types: i) propagation across resource metrics; ii) propagation across resource and service metrics; iii) propagation across services.</p><p>Regarding i) anomaly propagation across resource metrics, MicroDiag employs a structural causal model (SCM) <ref type="bibr" target="#b18">[19]</ref> to infer the causality. An anomaly from one resource simultaneously propagates to other resources, resulting in contemporary effects, which are hard to identify through conditional independence tests, like the PC algorithm, and time-lag based methods used in the existing methods <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> but can be handled by SCM methods. SCM methods assume that the value of each  variable is a deterministic function of its direct causes and some independent factors, like measurement errors. Notably, server resources are sums of the containers resources that it runs, i.e., a linear function. It is also assumed that anomalous resource metrics follows a non-gaussian distribution <ref type="bibr" target="#b19">[20]</ref>. Therefore, we employ a non-gaussian linear model to infer the anomaly propagation paths across resource metrics in dependent containers and servers. A metric m cx i , is defined as a linear function of causal metrics m cy j that the anomaly propagates from, and an independent factor e cx i , where the latter from the measurement errors or the fluctuations of metrics. Formally, m cx i can be defined as Equation <ref type="formula" target="#formula_0">1</ref>. MicroDiag employs a method named DirectLiNGAM <ref type="bibr" target="#b20">[21]</ref> to infer the causality from the non-gaussian linear model. It first identifies an exogenous variable based on its independence of the residuals of a number of pairwise regression, then removes the effect of the exogenous variable from the other variables using least squares regression. Based on these iterations of effect removal and causal ordering, it returns the causal relations of all metrics. The causality among resource metrics is shown as the container and server metrics in Figure <ref type="figure" target="#fig_2">2(c)</ref>.</p><formula xml:id="formula_0">m cx i = k(j)&lt;k(i) b ij m cy j + e cx i (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>For ii) anomaly propagation across resource and service metrics, MicroDiag leverages Granger causality tests to infer the causality as the anomaly propagates in an accumulative way, where a cause precedes an effect. Granger Causality tests are useful to determine whether a time series can be used to predict another time series and is defined as follows: A time series X is said to Granger-cause another time series Y if including information about the past of X significantly increases the prediction accuracy of the current value of Y in comparison to predicting future Y based on past values of Y.</p><p>For Granger causality tests, MicroDiag first gets the timelag between two metrics based on Akaike information criterion (AIC), then infers causal relation by applying Granger causality with χ 2 test. As Granger causality tests might introduce spurious causal relations among container resource metrics, we calibrate the causality with the results from above SCM model. The causality among resource and service metrics is shown as the container and service metrics in Figure <ref type="figure" target="#fig_2">2(c)</ref>.</p><p>Once MicroDiag identifies the causality of each service with above two steps, it further infers iii) the anomaly propagation across services, by reversing the edges between services in component dependent graph. In the end, MicroDiag gets a metrics causality graph of all metrics. Figure <ref type="figure" target="#fig_2">2(c)</ref> gives an example of the constructed metrics causality graph from component dependency graph Figure <ref type="figure" target="#fig_2">2(b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Culprit Metrics Localization</head><p>Once metrics causality graph is obtained, MicroDiag infers culprit metrics along the graph with a graph centrality algorithm which is commonly used in the state-of-the-art <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b12">[13]</ref>.</p><p>MicroDiag first weigh the graph with pearson correlation coefficient between two metrics to show the probability of anomaly propagation, then ranks the culprit metrics with PageRank. The transition probability matrix P in PageRank is computed as P ij = wij j wij if node i links to node j, and P ij = 0 otherwise, and the teleportation probability is set to c = 0.15 as recommended in <ref type="bibr" target="#b21">[22]</ref>. By ranking the nodes in the metrics causality graph, MicroDiags returns a ranked list of potential root causes. We note that the metrics causality graph needs to be reversed before conducting the localization procedure, as shown in Figure <ref type="figure" target="#fig_2">2(d</ref>). An example of the ranked list of culprit metrics is shown in Figure <ref type="figure" target="#fig_2">2(e)</ref>, where m p3</p><p>1 has the highest probability to be the root cause.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL EVALUATION</head><p>In this section, we set up a testbed to evaluate the effectiveness of MicroDiag on locating culprit metrics from anomaly cases, and also compare our method to two baseline methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Setup</head><p>Experimental Testbed: We develop a prototype of our system and evaluate it in a testbed created in Google Cloud Engine 1 using Kubernetes, where we deploy a microservice benchmark named Sock-shop 2 , which has 13 microservices, and a set of cloud-native monitoring tools, including Istio 5 , Cadvisor 4 , Node-exporter 3 and Prometheus<ref type="foot" target="#foot_2">foot_2</ref> . In our cluster, there are one master node and four worker nodes (4 vCPU and 15 GB) with container-Optimized OS, including three worker nodes dedicated for microservices and one for data collection. Besides, we developed a load generator based on Locust <ref type="foot" target="#foot_3">7</ref> and run it on a virtual machine (6 vCPU and 12 GB) outside of the cluster. Memory Leak PR@1 PR@3 PR@5 AP@5</p><p>Figure . 3. Performance of MicroDiag in terms of PR@1, PR@3, PR@5, and AP@5.</p><p>Fault Injection: We inject two types of performance issues: CPU hog and memory leak, by exhausting resource CPU and memory in a container, with stress-ng 8 . These two types of faults are commonly used in the state-of-the-art <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> , and can be manifested in the monitoring metrics. In order to simulate the performance issues in containers that microservices run inside, we customize the Docker images of each microservice by installing the fault injection tools. For each anomaly case, we run the system in normal status for 5 minutes, then we inject one anomaly to one of four microservices (catalogue, carts, orders, and users) for 1 minutes and wait for another 5 minutes for cold down in the system before the next fault injection. We repeat our experiments for 5 times and in total we have 40 cases.</p><p>Baseline Methods: We compare our system to two stateof-the-art methods as follows:</p><p>• Loud <ref type="bibr" target="#b7">[8]</ref>: Loud localizes the culprit metrics by constructing a propagation graph of anomalous metrics using the Granger causality test. To implement Loud, we use the anomalous metrics detected by our anomaly detection and construct the propagation graph using the Granger causality test, then rank the culprit metrics using PageRank after assigning weights to edges. • CauseInfer <ref type="bibr" target="#b8">[9]</ref>: CauseInfer identifies the culprit metrics by constructing a service dependency graph and metrics causality graphs for each service using the PC algorithm.</p><p>To implement CauseInfer, we use the dependency among services in our component dependency graph as the service dependency graph, then use PC algorithm with partial correlation to get the metrics causality graph, and rank the culprit metrics with our localization method. We note that the independent test and ranking method in CauseInfer have poor performance in our dataset.</p><p>Evaluation Metrics: To quantify the performance of each system, we use the following two performance metrics:</p><p>• Precision at top k denotes the probability that the top k results given by a system include the real root cause, denoted as P R@k. A higher P R@k score, especially for small values of k, represents the system correctly identifies the root cause, Let R[i] be the rank of each 8 stress-ng -<ref type="url" target="https://kernel.ubuntu.com/">https://kernel.ubuntu.com/</ref> cking/stress-ng/ cause and v rc be the set of root causes. More formally, P R@k is defined on a set of given anomalies A as:</p><formula xml:id="formula_2">P R@k = 1 |A| a∈A i&lt;k (R[i] ∈ v rc ) (min(k, |v rc |))<label>(2)</label></formula><p>• Average Precision at k (AP@k) quantifies the overall performance of a system with an average of PR@k:</p><formula xml:id="formula_3">AP @k = 1 k 1≤j≤k P R@j.<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Effectiveness Evaluation</head><p>Figure <ref type="figure">3</ref> shows the performance of MicroDiag in identifying root cause from two types of anomalies injected to four microservices. Overall, we can see that MicroDiag achieves a higher performance in CPU hog than memory leak in PR@1, with 80% in PR@1 of CPU hog and 33% of PR@1 for memory leak. This is because i) memory leak issue manifests in multiple resource metrics, which is more difficult to identify causal-effect relationships; ii) The monitoring interval is 5 seconds and it might fail to capture the changes in time, thus fails causal inference. Besides, we can see that MicroDiag pinpoints root cause well as one of top 3 mostly likely causes, with an average of 100% and 93% for CPU hog and memory leak respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison</head><p>Furthermore, we evaluate the performance of MicroDiag by comparing with two baseline methods (Loud and CauseInfer).</p><p>We apply MicroDiag and two baseline methods to all anomaly cases and get the average performance of each method in terms of PR@1, PR@3, PR@5 and AP@5, as shown in Table <ref type="table" target="#tab_1">I</ref>. We can see that all these methods cannot pinpoint the culprit metric in top 1 of the ranked list. However, comparing to the baseline methods, our MicroDiag achieves a large improvement with at least 76.5% in precision, and it achieves 97% in PR@3 and 100% in PR@5. Besides, we can see that CauseInfer has a poor performance in identifying root causes, particularly, with 9% in PR@1. This is because PC algorithm has a low performance of discovering contemporary effects resource metrics, thus failing to pinpoint root causes well. In opposite, Loud uses Granger causality tests which adds spurious causal relations among metrics. With the aids of PageRank, it has a high chance to identify the root cause, therefore, it achieves a higher performance in PR@5.</p><p>VI. CONCLUSIONS In this paper, we propose an automated performance diagnosis system named MicroDiag for microservice systems. MicroDiag infers fine-grained root causes from metrics, which indicates not only faulty component but also the clues for the abnormality of faulty component, by modeling the anomaly propagation across metrics with a causality graph. To achieve the metric causality graph, MicroDiag identifies the potential propagation across components firstly, then infers the causal relations among metrics of inter-dependent components with causal inference techniques. As the property of anomaly propagation across metrics are different, two types of causal inference methods are used. We evaluate our system on a testbed running on google cloud engine where a microservice benchmark is deployed on a Kubernetes cluster and two types of performance issues are injected. The experimental results show that MicroDiag can rank 97% of the culprit metrics in one of the top 3 most likely causes, and outperforms at least 31.1% of the state-of-the-art methods.</p><p>So far, we only evaluated our system on two types of faults. In the future, we will extend our evaluation on more types of faults and also a large microservice benchmark, like TrainTicket. Besides, we would like to improve our MicroDiag with feature selection to reduce the dimensionality of metrics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure. 1 .</head><label>1</label><figDesc>Figure. 1. Overview of MicroDiag.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a)), an anomaly can propagates across not only inter-dependent microservices along invocations but also containers and severs through resources sharing or contention (such as s 1 and s 3 in Figure 2(a)). To capture such dependencies, we construct a component dependent graph among microservices, containers, and servers to model the potential anomaly propagation paths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure. 2 .</head><label>2</label><figDesc>Figure. 2. Root cause localization procedures in MicroDiag.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I PERFORMANCE</head><label>I</label><figDesc>OF EACH SYSTEM.</figDesc><table><row><cell>Metric</cell><cell cols="3">Loud CauseInfer MicroDiag</cell><cell>Minimum improvement</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>to baseline methods (%)</cell></row><row><cell>PR@1</cell><cell>34</cell><cell>9</cell><cell>60</cell><cell>76.5</cell></row><row><cell>PR@3</cell><cell>74</cell><cell>49</cell><cell>97</cell><cell>31.1</cell></row><row><cell>PR@5</cell><cell>94</cell><cell>69</cell><cell>100</cell><cell>6.4</cell></row><row><cell>AP@5</cell><cell>70</cell><cell>42</cell><cell>89</cell><cell>27.1</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Google Cloud Engine -https://cloud.google.com/compute/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Sock-shop -https://microservices-demo.github.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>Prometheus -https://prometheus.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3"><p>Locust -https://locust.io/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENT</head><p>This work is part of the <rs type="projectName">FogGuru</rs> project which has received funding from the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 research and innovation programme</rs> under the <rs type="grantName">Marie Skłodowska-Curie</rs> grant agreement No <rs type="grantNumber">765452</rs>. The information and views set out in this publication are those of the author(s) and do not necessarily reflect the official opinion of the <rs type="funder">European Union</rs>. Neither the <rs type="funder">European Union</rs> institutions and bodies nor any person acting on their behalf may be held responsible for the use which may be made of the information contained therein.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_rgNVg6s">
					<idno type="grant-number">765452</idno>
					<orgName type="grant-name">Marie Skłodowska-Curie</orgName>
					<orgName type="project" subtype="full">FogGuru</orgName>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Research on architecting microservices: Trends, focus, and potential for industrial adoption</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Francesco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Malavolta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lago</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Software Architecture (ICSA)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Building</forename><surname>Microservices</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>O&apos;Reilly Media, Inc, USA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Microservices: The journey so far and challenges ahead</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jamshidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Software</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="24" to="35" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Why</forename><surname>Netflix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apple</forename><surname>Amazon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">About</forename><surname>Care</surname></persName>
		</author>
		<author>
			<persName><surname>Microservices</surname></persName>
		</author>
		<ptr target="https://blog.leanix.net/en/why-netflix-amazon-and-apple-care-about-microservices" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Seer: Leveraging big data to navigate the complexity of performance debugging in cloud microservices</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pancholi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delimitrou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS &apos;19</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="19" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Performance Diagnosis in Cloud Microservices using Deep Learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bogatinovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nedelkoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tordsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AIOPS 2020 -International Workshop on Artificial Intelligence for IT Operations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graph-based root cause analysis for service-oriented and microservice architectures</title>
		<author>
			<persName><forename type="first">Á</forename><surname>Brandón</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="110" to="432" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Localizing faults in cloud systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mariani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Monni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pezzé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Riganelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ICST</publisher>
			<biblScope unit="page" from="262" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Causeinfer: Automatic and distributed performance diagnosis with hierarchical causality graph in large distributed systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<publisher>IEEE INFO-COM</publisher>
			<biblScope unit="page" from="1887" to="1895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Performance anomaly detection and bottleneck identification</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ibidunmoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hernández-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Elmroth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A survey of fault localization techniques in computer networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Steinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Sethi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science of computer programming</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="165" to="194" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Latent error prediction and fault localization for microservice applications by learning from system trace logs</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESEC/FSE 2019</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="683" to="694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">MicroRCA: Root cause localization of performance issues in microservices</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tordsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Elmroth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NOMS 2020-2020 IEEE/IFIP Network Operations and Management Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Logsayer: Log pattern-driven cloud component anomaly diagnosis with machine learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/ACM 28th International Symposium on Quality of Service (IWQoS)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Sieve: Actionable insights from monitored metrics in distributed systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thalheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">E</forename><surname>Akkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bhatotia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Viswanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fetzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="14" to="27" />
		</imprint>
	</monogr>
	<note>in Middleware &apos;17</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<title level="m">Causation, prediction, and search</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Y</forename><surname>Meng</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Detecting anomalous behavior of black-box services modeled with distance-based online clustering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gulenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wallschläger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE 11th International Conference on Cloud Computing (CLOUD)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="912" to="915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Causal inference in statistics: An overview</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics surveys</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="96" to="146" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cloud resource usage-heavy tailed distributions invalidating traditional capacity planning models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Loboz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of grid computing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="108" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Directlingam: A direct method for learning a linear non-gaussian structural equation model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Inazumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sogawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Washio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1225" to="1248" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Scaling personalized web search</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
	<note>in WWW &apos;03</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
