<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Causality can systematically address the monsters under the bench(marks)</title>
				<funder>
					<orgName type="full">Future of Life Institute</orgName>
				</funder>
				<funder ref="#_M9BsFY5">
					<orgName type="full">Haslerstiftung</orgName>
				</funder>
				<funder ref="#_KNQq3UZ">
					<orgName type="full">Swiss National Science Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">International Max Planck Research School for Intelligent Systems</orgName>
					<orgName type="abbreviated">IS</orgName>
				</funder>
				<funder ref="#_DBphZ2m">
					<orgName type="full">ELISE</orgName>
				</funder>
				<funder ref="#_agQ4n3e">
					<orgName type="full">German Federal Ministry of Education and Research (BMBF)</orgName>
				</funder>
				<funder ref="#_6UcqCB2">
					<orgName type="full">John Templeton Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">Precision Health Initiative</orgName>
				</funder>
				<funder ref="#_sKQ9w4K">
					<orgName type="full">Machine Learning Cluster of Excellence</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-02-07">7 Feb 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Felix</forename><surname>Leeb</surname></persName>
							<email>fleeb@tue.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>Tübingen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhijing</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>Tübingen</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">ETH Zürich</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Training Verifiers to Solve Math Word Problems</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<addrLine>November 2021. Yupeng Chang, Xu Wang Jindong Wang Yuan Wu, Linyi Yang Kaijie Zhu Xiaoyuan Yi Cunxiang Wang Yidong Wang, Wei Ye Yue Zhang, Yi Chang Philip S. Yu Qiang Yang</addrLine>
									<settlement>Hao Chen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>Tübingen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tony</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dilara</forename><surname>Soylu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yian</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Deepak</forename><surname>Narayanan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ananya</forename><surname>Ku- Mar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Newman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Binhang</forename><surname>Yuan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bobby</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ce</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christian</forename><surname>Cosgrove</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Man- Ning</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Ré</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Diana</forename><surname>Acosta-Navas</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Drew</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Zelikman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Esin</forename><surname>Durmus</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Faisal</forename><surname>Ladhak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Frieda</forename><surname>Rong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jue</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Keshav</forename><surname>Santhanam</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Laurel</forename><surname>Orr</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lucia</forename><surname>Zheng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mert</forename><surname>Yuksekgonul</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mirac</forename><surname>Suzgun</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Neel</forename><surname>Guha</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Niladri</forename><surname>Chatterji</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Omar</forename><surname>Khattab</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Henderson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qian</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ryan</forename><surname>Chi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sang</forename><forename type="middle">Michael</forename><surname>Xie</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Icard</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
						</author>
						<author>
							<persName><forename type="first">William</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xuechen</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yifan</forename><surname>Mai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuhui</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuta</forename><surname>Koreeda</surname></persName>
						</author>
						<author>
							<persName><surname>Holistic</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Xing Xie. A Survey on Evaluation of Large Language Models</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Causality can systematically address the monsters under the bench(marks)</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-02-07">7 Feb 2025</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2502.05085v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Effective and reliable evaluation is essential for advancing empirical machine learning. However, the increasing accessibility of generalist models and the progress towards ever more complex, high-level tasks make systematic evaluation more challenging. Benchmarks are plagued by various biases, artifacts, or leakage, while models may behave unreliably due to poorly explored failure modes. Haphazard treatments and inconsistent formulations of such "monsters" can contribute to a duplication of efforts, a lack of trust in results, and unsupported inferences. In this position paper, we argue causality offers an ideal framework to systematically address these challenges. By making causal assumptions in an approach explicit, we can faithfully model phenomena, formulate testable hypotheses with explanatory power, and leverage principled tools for analysis. To make causal model design more accessible, we identify several useful Common Abstract Topologies (CATs) in causal graphs which help gain insight into the reasoning abilities in large language models. Through a series of case studies, we demonstrate how the precise yet pragmatic language of causality clarifies the strengths and limitations of a method and inspires new approaches for systematic progress.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine learning achievements continue to break records and grab headlines, drawing attention from both the public and the research community. However, the rapid proliferation of powerful models and the increasing complexity of tasks continue to amplify existing challenges in reliable evaluation of these models <ref type="bibr" target="#b0">[Mao et al., 2024]</ref>. Between inflated expectations <ref type="bibr" target="#b1">[Bubeck et al., 2023</ref><ref type="bibr" target="#b2">, Ullman, 2023</ref><ref type="bibr" target="#b3">, Grace et al., 2024]</ref>, opaque or misleading assessments <ref type="bibr" target="#b4">[Martínez, 2024]</ref>, and even the occasional mistake <ref type="bibr" target="#b5">[Chowdhuri et al., 2023]</ref>, the poor communication <ref type="bibr" target="#b6">[Bowman, 2022]</ref> and unreliable benchmarks <ref type="bibr">[Raji et al., 2021</ref><ref type="bibr">, Bowman and Dahl, 2021</ref><ref type="bibr">, Alzahrani et al., 2024]</ref> can significantly undermine our understanding of the capabilities and limitations of these models <ref type="bibr">[Nezhurina et al., 2024</ref><ref type="bibr">, Yan et al., 2024]</ref>. This risks a decline of public trust <ref type="bibr">[Bender et al., 2021</ref><ref type="bibr">, Green and Hu, 2018</ref><ref type="bibr">, Hu and Kohler-Hausmann, 2020a</ref>] and perhaps even an AI winter. A key issue is that many evaluations focus on Figure <ref type="figure">1</ref>: Growth of reasoning papers in ACL Anthology, among which the concept of "causality" is not growing at the same rate, suggesting that NLP is underutilizing causality.</p><p>performance alone <ref type="bibr" target="#b83">[Liang et al., 2023]</ref>, failing to account for the reasoning process behind a model's behavior. For instance, a model may arrive at the right answer for the wrong reasons, making the performance an incomplete indication of its capabilities beyond the test set.</p><p>To systematically address the challenges in evaluating, in particular, large models, this position paper argues for a shift toward causality-driven experimental design. By making causal assumptions explicit, we formulate precise hypotheses and underlying assumptions, diagnose model limitations, and leverage principled tools for analysis.</p><p>One subfield that is particularly well-fitted for more causal analyses is the evaluation of reasoning abilities in large language models (LLMs) <ref type="bibr">[Huang and</ref><ref type="bibr" target="#b15">Chang, 2023, Yu et al., 2023]</ref>. A cursory analysis of the recent NLP papers in the ACL anthology reveals a dramatic rise in the attention in reasoning capabilities of models, as seen in Figure <ref type="figure">1</ref>. However, curiously, the subset of these papers that mention "causality" or "causal" in the title or abstract is not growing in tandem (yet). In fact, the dendrogram in Figure <ref type="figure">2</ref> shows that among the reasoning papers, causality-related terms tend not to co-occur very much with many non-causal mimics (discussed in Section 2).</p><p>Despite many of the issues appearing to be quite disparate based on the distinct terminology that is used, we argue that causality can serve as the framework to</p><formula xml:id="formula_0">FR QIR XQ GLQ J LQ WH UY H Q WL R Q P H G LD W LR Q F D X V D O FRX QWH UIDF WXD O KH XU LVW LFV Y D U LD WL R Q S H U W X U E D W LR Q UH OL D E OH LQWHUS UHWDE LOLW\ DV VR FL DW HG LQ IO X H Q F H LP S D F W F R UU H OD WL R Q VHQVLWLYH EL DV HV V S X U LR X V U R E X V W VK R UW FX WV FKHDW Figure 2:</formula><p>This dendrogram shows the co-occurrences of causal and causality-adjacent terms of papers that contain "reasoning" in the abstracts (total 3181 papers) from the ACL anthology from the past 10 years. The numbers in parentheses indicate the number of papers that mention the term. Note, that the very first split separates all the causality-related terms from the rest of the terms, suggesting relatively poor co-occurrence with other invariably related concepts.</p><p>systematically study a wide array of issues thus bridging gaps between different subfields and approaches. The expertise required to understand and satisfactorily mitigate these issues is very diverse, and we do not mean to suggest that causality is all you need. Rather, we argue that causality already (often implicitly) underlies much of the design, analysis, and interpretation of machine learning experiments, despite the apparent gap in terminology as suggested by Figure <ref type="figure">2</ref>.</p><p>To make an explicit causal framing more accessible and attractive, we develop a guide to common causal structures and then use these abstract topologies to gain insights across case studies about reasoning abilities in LLMs. While we focus on research questions and issues concerning the evaluation of reasoning abilities in LLMs, all four of our main claims (particularly 2-4) largely apply to the whole of empirical machine learning research. Our contributions include:</p><p>• We survey a wide variety of common challenges, or monsters, that hinder reliable evaluation and discuss how these can faithfully be modeled using causality As LLMs become an increasingly integral component of decision-making systems, reasoning failures (including seemingly toy problems like in Example 1) may have dire real-world consequences <ref type="bibr">Nezhurina et al. [2024</ref><ref type="bibr">], Bender et al. [2021]</ref>. This necessitates more powerful tools to identify, catalog, and address the bestiary of issues that arise in the design as well as evaluation of large models.</p><p>Example 1 is indicative of several common reasoning failures in LLMs, and, by implication, our evaluation procedures for addressing such issues. The input prompt is structurally similar to the questions found in GSM8k Cobbe et al. <ref type="bibr">[2021]</ref>, a benchmark used for evaluating a model's multi-step arithmetic and commonsense understanding skills. However, we select the subject matter and word choice to evoke a mobster discussing plans to extort money from local businesses. Although the LLM's final answer is factually correct, there are several problems with the rationale: (1) it makes several arithmetic mistakes which happen to cancel out, (2) it fails to pick up on the unethical situation implied by the scenario, and (3) by implicitly condoning the criminal behavior, it does not consider the broader consequences of the response. Crucially, if we only check for correctness, as is standard practice Huang and Chang [2023], we would find no fault in the response.</p><p>The problem is that to demonstrate good reasoning abilities, a correct answer is insufficient. We need to show that the model answers the question correctly for the right reasons. In other words, our evaluation must verify that the model's processing of the input information leads to the correct answer consistently and reliably. This criterion makes a causal claim about the model's reasoning process, and thus must be supported by a causal analysis.</p><p>Claim 1: Evaluating reasoning involves causal inference A correct answer can be reached through very poor reasoning, but poor reasoning will not generalize beyond the lab bench. To generalize well, the model's reasoning must rely on robustly predictive (i.e. causal) features and relationships rather than spurious ones. Consequently, evaluating the reasoning abilities involves causal inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">"Here be dragons" 1</head><p>To get a qualitative sense of the myriad of issues, or monsters, that plague our benchmarks and experiments, we will briefly survey recent approaches, including broad overviews into the nature of reasoning tasks <ref type="bibr">[Huang and</ref><ref type="bibr" target="#b15">Chang, 2023, Yu et al., 2023]</ref> and the evaluation of LLMs <ref type="bibr" target="#b0">[Mao et al., 2024</ref><ref type="bibr" target="#b15">, Chang et al., 2023</ref><ref type="bibr" target="#b7">, Hajikhani and Cole, 2023]</ref>. For investigations of more specific issues, we separate efforts into three clusters depending on whether the problem originates with the (1) models, (2) datasets, or (3) evaluation procedures.</p><p>Models This line of work focuses on characterizing the reasoning failures and biases of language models, which is nontrivial given their opaque behavior <ref type="bibr" target="#b8">[Binz and Schulz, 2023]</ref>. These failures range from well-defined formal errors such as logical fallacies <ref type="bibr" target="#b9">[Jin et al., 2022]</ref>, red herrings <ref type="bibr" target="#b10">[Naeini et al., 2023]</ref>, or invalid inferences <ref type="bibr" target="#b11">[Saparov and He, 2023]</ref> to broader issues including sensitivity to superficial features <ref type="bibr" target="#b7">[Hajikhani and</ref><ref type="bibr">Cole, 2023, Ullman, 2023]</ref>, overconfidence <ref type="bibr">[Nezhurina et al., 2024]</ref>, hallucinations <ref type="bibr" target="#b12">[Dziri et al., 2022</ref><ref type="bibr" target="#b13">, Cui et al., 2023]</ref>, and lack of robustness <ref type="bibr" target="#b14">[Zheng et al., 2024</ref><ref type="bibr" target="#b15">, Wang et al., 2023</ref><ref type="bibr" target="#b16">, Jin et al., 2020]</ref>. Some studies explore how models exhibit "content effects" <ref type="bibr" target="#b17">[Poesia et al., 2023]</ref>, absorbing and amplifying human biases <ref type="bibr" target="#b18">[Dasgupta et al., 2022</ref><ref type="bibr" target="#b19">, Zečević et al., 2023]</ref> including social and cultural biases <ref type="bibr">[Bender et al., 2021</ref><ref type="bibr" target="#b20">, Messner et al., 2023</ref><ref type="bibr" target="#b21">, Hutchinson et al., 2020</ref><ref type="bibr" target="#b22">, Vig et al., 2020</ref><ref type="bibr" target="#b23">, Cao et al., 2023a</ref><ref type="bibr" target="#b24">, AlKhamissi et al., 2024</ref><ref type="bibr" target="#b25">, Motoki et al., 2024]</ref>, such as stereotyping <ref type="bibr" target="#b26">[Kotek et al., 2023]</ref>.</p><p>Datasets Meanwhile, subtle variations of popular benchmarks, such as premise order in reasoning tasks <ref type="bibr" target="#b27">[Chen et al., 2024]</ref> or minor changes in problem parameters <ref type="bibr" target="#b28">[Mirzadeh et al., 2024</ref><ref type="bibr" target="#b29">, Wu et al., 2024]</ref>, can cause large performance drops <ref type="bibr">[Nezhurina et al., 2024</ref><ref type="bibr">, Yan et al., 2024]</ref>, raising concerns not just about whether models genuinely reason <ref type="bibr" target="#b30">[Zhou et al., 2024]</ref>, but also about exploitable issues in the training data and benchmarks <ref type="bibr">[Rogers and</ref><ref type="bibr">Rumshisky, 2020, Bowman and</ref><ref type="bibr">Dahl, 2021]</ref>. These are can be described as enabling cheating <ref type="bibr" target="#b32">[Zhou et al., 2023]</ref>, heuristics <ref type="bibr">[Mc-Coy et al., 2019]</ref>, or shortcuts <ref type="bibr" target="#b34">[Branco et al., 2021</ref><ref type="bibr" target="#b35">, Li et al., 2022</ref><ref type="bibr" target="#b36">, Marconato et al., 2023]</ref>, possibly due to sampling biases <ref type="bibr" target="#b37">[Razeghi et al., 2022]</ref> or in certain cases even leakage between the training and testsets <ref type="bibr" target="#b32">[Zhou et al., 2023]</ref> which can result in memorization <ref type="bibr" target="#b38">[Feldman, 2021]</ref>. Poor dataset construction can lead to annotation artifacts <ref type="bibr" target="#b39">[Gururangan et al., 2018</ref><ref type="bibr" target="#b40">, Fleisig et al., 2024]</ref> such as priming effects <ref type="bibr" target="#b41">[Gardner et al., 2021]</ref>, which degrade the quality and reliability of results <ref type="bibr" target="#b42">[Byrd and Srivastava, 2022]</ref> while also unintentionally reinforcing social biases or cultural inequities <ref type="bibr">[Bender et al., 2021</ref><ref type="bibr">, Hu and Kohler-Hausmann, 2020b</ref><ref type="bibr" target="#b44">, Naous et al., 2024]</ref>.</p><p>Evaluation Even with well-constructed datasets, evaluation methodologies can introduce systematic errors <ref type="bibr" target="#b45">[Dominguez-Olmedo et al., 2024]</ref> or lead to misleading conclusions <ref type="bibr" target="#b6">[Bowman, 2022]</ref>. For example, automated scoring systems can obscure obvious failures <ref type="bibr" target="#b5">[Chowdhuri et al., 2023]</ref>, while static benchmarks can emphasize surface-level accuracy at the cost of other important factors, such as generalization <ref type="bibr" target="#b83">[Liang et al., 2023]</ref> or interpretability <ref type="bibr" target="#b46">[Loftus, 2024]</ref> or social costs <ref type="bibr">[Raji et al., 2021</ref><ref type="bibr">, Bender et al., 2021]</ref>. While standardized leaderboards <ref type="bibr" target="#b47">[Beeching et al., 2023]</ref> and evaluation procedures <ref type="bibr">[Srivastava and et al.]</ref> can enable more direct model comparisons, these benchmarks can gradually become less representative of real-world tasks <ref type="bibr" target="#b49">[Schlangen, 2019</ref><ref type="bibr">, Alzahrani et al., 2024</ref><ref type="bibr">, Shirali et al., Kiela et al., 2021]</ref>, introduce biases that favor certain model families <ref type="bibr" target="#b52">[Zhang et al., 2024a]</ref>, or inadvertently leak information from the test set <ref type="bibr" target="#b32">[Zhou et al., 2023]</ref> which can be difficult to detect due to closed-source models and proprietary datasets <ref type="bibr" target="#b0">[Mao et al., 2024]</ref>.</p><p>Despite the diverse, at times redundant, terminology, we observe certain structural similarities in the approaches of these contributions. Terms like "ablation", "perturbations", "edits", "flips", "masking" can often be interpreted as interventional or counterfactual analyses, while "sensitivity"/"robustness", "consistency", "shortcut", "leakage", "bias", etc. refer to how the model's behavior is impacted by, for example, (seen or unseen) confounders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Claim 2: The monsters are causal</head><p>The disparate and often vague formulations of the issues that lurk within our benchmarks and models such as biases or failure modes can often faithfully be described in terms of causality. Whether the factors are known or unknown, their influences can be captured by an appropriate causal model to guide the experimental design and analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Common Abstract Topologies</head><p>Coming up with a causal graph that faithfully represents the underlying structure of an experiment or data generating process can be very challenging. Especially, since usually when we design an experiment, we think in terms of more vague concepts like independent, dependent, and controlled variables, and consequently only implicitly make causal assumptions. However, explicit causal graphs:  <ref type="table">1</ref>: Some simple Common Abstract Topologies (CATs) which can be used to formalize a wide variety of monsters both known and unknown that may lurk in a benchmark or experiment analysis and some example issues that they may help represent. For the graphs, is the independent variable, is the dependent/outcome variable, and represents a third variable factor such as a confounder or mediator. Note that the examples are partially overlapping, reflecting that depending on the specific setting, a similar issue may be represented by different CATs or combinations thereof.</p><p>• precisely communicate the assumptions that go into an approach, experiment, or analysis</p><p>• leverage the machinery of causal inference for a more principled analysis</p><p>• understand the implications of our design choices including the particular strengths and limitations on both technical and conceptual levels</p><p>To help make the process of constructing a causal graph more accessible and systematic, we identify some Common Abstract Topologies (CATs) of causal graphs and discuss associated phenomena (see Table <ref type="table">1</ref>) in the context of evaluating reasoning abilities in large models where these structures may be useful.</p><p>However, there may be some hesitancy to commit to a specific causal graph that faithfully captures all the factors that may affect the analysis <ref type="bibr" target="#b53">Bareinboim et al. [2022]</ref>. Especially since, in practice, the graph is often severely underdetermined by available data, or depends on precise definitions or interpretations of relevant factors. As pointed out by <ref type="bibr" target="#b46">Loftus [2024]</ref>, researchers may even avoid causal language because it offers more assumptions for reviewers to challenge.</p><p>Claim 3: Instrumentalism is all you need A causal model does not need to be perfect to be useful. Plausible simplifying assumptions and abstractions can yield valuable insights and motivate practical experiments. As research advances, the model can be refined to mark our progress, while providing transparent falsifiable hypotheses at every step of the way.</p><p>Here we urge the community to be more pragmatic, much like <ref type="bibr" target="#b46">Loftus [2024]</ref>, <ref type="bibr" target="#b54">Janzing and Garrido [2022]</ref>. Due to subtle differences in the model design such as variable construction or selection, the same issue may be represented by various causal models, perhaps even ones that appear incompatible. For example, depending on the level of abstraction <ref type="bibr" target="#b55">Chalupka et al. [2016]</ref>, <ref type="bibr" target="#b56">Rubenstein et al. [2017]</ref>, <ref type="bibr" target="#b57">Beckers et al. [2020]</ref>, certain causal relationships may be omitted, and the graph may be simplified or augmented with additional variables. Nevertheless, as long as a proposed causal model does not directly conflict with the available data, it may be sufficient to improve performance or produce insights (such as more interpretable or explainable models).</p><p>Aside from the additional explanatory power, if a more formal treatment is necessary or desired, there is a whole world of tools and techniques to explore. The field of causal inference <ref type="bibr" target="#b58">Pearl [2009</ref><ref type="bibr">Pearl [ , 2020]]</ref>, <ref type="bibr" target="#b59">Imbens and Rubin [2015]</ref>, <ref type="bibr" target="#b60">Peters et al. [2017]</ref>, <ref type="bibr" target="#b53">Bareinboim et al. [2022]</ref> has developed a language for formalizing the effects of subtle design choices and their, potentially counterintuitive, consequences for the analysis. For example, Simpson's paradox can be elegantly explained, to "resolve" the apparent paradox based on the appropriate causal assumptions of the problem (for a deep dive into this topic see <ref type="bibr" target="#b61">Pearl [2022]</ref> and Chapter 6 of <ref type="bibr">Pearl [2020]</ref>).</p><p>Claim 4: Towards explicit causal assumptions An experimental design involves a variety of assumptions about what factors matter, how they interact, and how this relates to the proposed approach. Here the language of causality provides a powerful framework for motivating an approach, precisely formulating the hypothesis, and answering questions in a principled way.</p><p>Causal inference is valuable not only for formal analysis but also as a conceptual framework for understanding the structural assumption behind an approach or argument. By making the concepts and tools of causal inference more accessible, we aim to develop a practical guide to recognize familiar causal structures in common phenomena, as well as build an intuition for the implications of model design choices on analysis and interpretation. To this end, we present three simple CATs that correspond to the three causal interpretations of a statistical dependence between two variables according to the common cause principle <ref type="bibr" target="#b62">Reichenbach [1956]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Confounding</head><p>Confounding occurs when there is a common cause between the independent and dependent variables. For our purposes, we further restrict the "confounding" CAT to the case where the confounder is known and can, in principle, be controlled for. This is in contrast to the "spurious correlation" CAT, where the confounder is unknown or too complex to be modeled explicitly.</p><p>Confounding makes evaluation difficult or unreliable because the observed statistical relationship between the stimulus and response is not representative of the underlying causal relationship, thus unbiased causal effect estimation necessitates controlling for the confounder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Mediation</head><p>Another important type of causal topology is mediation, where there are multiple causal paths between the stimulus and response. For simplicity, we illustrate this general structure with one direct causal link and one that goes through a mediator variable. Mediation analysis is often used to quantify the impact of subcomponents or side-effects on the model's behavior. For example, a common setting may be to study the impact of a specific prompting strategy or representation on the model's response, which can be modeled as mediation as in Figure <ref type="figure" target="#fig_0">3</ref>. The impacts of the individual causal paths can be studied by estimating the natural direct effect (NDE), natural indirect effect (NIE), or controlled direct effect (CDE) <ref type="bibr" target="#b58">Pearl [2009]</ref>. However, notably controlling for the mediator is not always appropriate, for example, for estimating the total causal effect (TCE). This underscores one of the key benefits of causal inference: given the specific causal query, the appropriate analysis method is dictated by the graph structure, thereby prescribing specific and principled experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Spurious Correlations</head><p>The final common pattern we discuss here is spurious correlations, which are closely related to confounding but differ in the interpretation and implications for analysis. Spurious correlations (depicted as a dashed curved edge) are statistical associations between variables that are not causally related (neither is an ancestor of the other), but are correlated due to some external factor (a common cause), which is usually unknown.</p><p>If a model is only trained on observational data (as is almost always the case) as opposed to interventional or counterfactual data, then there is no way to differentiate a spurious correlation from a causal relationship. Consequently, a model can learn to rely on spurious correlations in the data to make predictions, effectively forming an undesirable causal link between the spurious feature and the model's output.</p><p>A common cause of spurious correlations, particularly in datasets, is due to selection bias in the data generative process, which may also be described as a collider bias <ref type="bibr" target="#b58">Pearl [2009]</ref>. Generally, it is not feasible to entirely eliminate spurious correlations, as seemingly innocent choices in variable construction and selection are invariably informed by the experimenter's biases <ref type="bibr">Hu and Kohler-Hausmann [2020b]</ref>, <ref type="bibr" target="#b63">Pietsch [2015]</ref>. Nevertheless, there is extensive causal inference machinery to address spurious correlations depending on the specific setting <ref type="bibr" target="#b64">[Plecko and Bareinboim, 2023]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Case Studies</head><p>In this section, we discuss a variety of specific research projects which either make use of one of the Common Abstract Topologies (CATs) or could benefit from a more explicitly causal framing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Confounding</head><p>One project that explicitly uses a causal framing to understand the biases in the text generation of large language models (LLMs) is <ref type="bibr" target="#b65">Xia et al. [2024]</ref>. To address confounding due to biases in the training data or prompt, they propose using a reward model as an instrumental variable. <ref type="bibr" target="#b66">Zhang et al. [2024b]</ref> formulate a human-LM collaborative writing setting as a causal inference problem where the past human commands and LLM responses are confounders for the current command and the overall interaction outcome. To identify strategies that improve the collaboration, they introduce a new causal estimand, the Incremental Stylistic Effect (ISE), which allows them to abstract away from specific interactions and focus on how actions incrementally contribute to the desired stylistic outcome of the text. Meanwhile, a good example of an active area of research that largely revolves around the confounding CAT, despite "confounding" rarely being mentioned explicitly, is the study of how the mathematical reasoning abilities of LLMs are affected by various undesirable factors <ref type="bibr" target="#b30">[Zhou et al., 2024</ref><ref type="bibr" target="#b67">, Patel et al., 2021]</ref>. In particular, a variety of projects have focused on using the dataset GSM8K <ref type="bibr">[Cobbe et al., 2021]</ref> to evaluate multistep arithmetic reasoning as well as common sense understanding <ref type="bibr" target="#b28">[Mirzadeh et al., 2024</ref><ref type="bibr">, Chen et al., 2024</ref><ref type="bibr" target="#b52">, Zhang et al., 2024a]</ref>.</p><p>Several of these projects probe the robustness of the LLM's reasoning ability by systematically vary-ing certain features such as the subjects or numbers involved <ref type="bibr" target="#b28">[Mirzadeh et al., 2024]</ref>, the order of the premises <ref type="bibr" target="#b27">[Chen et al., 2024]</ref>, or attempt to replicate the original data generative process <ref type="bibr" target="#b52">[Zhang et al., 2024a]</ref> to test whether LLMs have overfit to the original dataset.</p><p>While these projects generally suggest that LLMs are sensitive to these factors, a more causal treatment can provide more precise conclusions. Let's take a closer look at one of the projects with a relatively specific target: <ref type="bibr" target="#b37">Razeghi et al. [2022]</ref> investigate how much a language model's performance on quantitative reasoning tasks is affected by how often the numbers in the question occur in the model's training dataset. An intuitive causal framing for their approach using the "confounding" CAT is shown in Figure <ref type="figure" target="#fig_1">4a</ref>. Note, that here the model's response is abstracted away since we are only interested in the response in so far as it affects the resulting accuracy.</p><p>Alternative Approach Here it is instructive to consider a hypothetical project where we design a benchmark to evaluate the math skills of a language model. Much like in <ref type="bibr" target="#b37">Razeghi et al. [2022]</ref>, our questions take the form "What is n 1 times n 2 ?" where n 1 and n 2 are numbers selected by some sampling strategy. However, we do not consider the training dataset of the model at all, and instead of following <ref type="bibr" target="#b37">Razeghi et al. [2022]</ref>, we sample numbers uniformly, which effectively removes the causal link between the term frequency and the numbers used in the question. Based on the findings of <ref type="bibr" target="#b37">Razeghi et al. [2022]</ref>, we can expect to find a substantial correlation between the presence of certain numbers in the question and the model's accuracy, even though the rules of arithmetic are obviously entirely agnostic to which numbers are used.</p><p>To explain the results of our approach, we might phenomenologically define a new property of numbers called "difficulty" which, we conclude significantly affects the model's accuracy, leading to the causal graph in Figure <ref type="figure" target="#fig_1">4b</ref> using the "spurious correlation" CAT.</p><p>Verifying Causal Assumptions A notable consequence of committing to a causal graph as in Figure <ref type="figure" target="#fig_1">4a</ref> is that it may imply certain falsifiable causal relationships that are not actually verified by the experiments. Specifically, the experiments of <ref type="bibr" target="#b37">Razeghi et al. [2022]</ref> identify a significant correlation between the term frequency and the model's accuracy, rather than showing a causal relationship, as the authors helpfully state explicitly. Therefore, an alternative plausible causal graph as in Figure <ref type="figure" target="#fig_1">4c</ref> may be posited for their approach where the term frequency is merely correlated with the model's accuracy by sharing a hither-to unknown confounder. This process illustrates how structurally distinct causal interpretations can be proposed to motivate certain experiments or approaches, and then how the results can be used to incrementally refine the causal graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Mediation</head><p>Mediation analysis guides the approaches of mechanistic interpretability <ref type="bibr" target="#b68">[Stolfo et al., 2023</ref><ref type="bibr" target="#b69">, Gupta et al., 2023</ref><ref type="bibr" target="#b70">, Meng et al., 2023</ref><ref type="bibr" target="#b71">, Wang et al., 2022]</ref>, but it is also useful in augmentation of language models <ref type="bibr" target="#b72">Mialon et al. [2023]</ref>, embedding LLMs within larger programs <ref type="bibr" target="#b73">Schlag et al. [2023]</ref>. and the quantification of biases like, gender bias <ref type="bibr" target="#b22">Vig et al. [2020]</ref>.</p><p>A common setup for mechanistic interpretability is to study the impact of a specific component, such as an attention head or even a single parameter on the model behavior. <ref type="bibr" target="#b74">Olsson et al. [2022]</ref> propose that transformers can learn simple, interpretable algorithms called "induction heads," which they hypothesize significantly contribute to in-context learning abilities. While mediation analysis is not explicitly used in their work, we can frame their approach as studying a mediation graph, where the tendency for a given model architecture (stimulus) to exhibit in-context learning (response) is mediated by induction heads. Their six supporting arguments can be interpreted through this causal lens: arguments 1 and 2 establish links between stimulus, mediator, and response through co-occurrence and co-perturbation; argument 3, an ablation study, resembles controlled direct effect estimation; and arguments 4-6 examine the causal influence of the mediator on the response. This framing also highlights potential limitations, particularly regarding unmeasured confounders that could affect causal interpretations, as the authors' "pattern-preserving" ablation does not fully isolate the induction heads' effect. By considering mediation explicitly, we can better understand the underlying assumptions in their analysis and identify areas for further investigation, such as quantifying the natural indirect effect to understand the full impact of the induction heads on in-context learning abilities.</p><p>In contrast, <ref type="bibr" target="#b68">Stolfo et al. [2023]</ref> propose a method for mechanistic interpretability of arithmetic reasoning in LLMs by editing the model's parameters to characterize the information flow in the network. Note that the level of abstraction for this approach is quite different from the causal model we proposed for <ref type="bibr" target="#b74">Olsson et al. [2022]</ref>, as the focus is on how information flows between individual model subcomponents, rather than how specific subcomponents affect the overall model's behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Spurious Correlations</head><p>There several recent projects that use causal models to characterize spurious correlations in, for example, factual knowledge <ref type="bibr">[Cao et al., 2023b]</ref>, multi-modal models for fake news detection <ref type="bibr" target="#b76">Chen et al. [2023]</ref>, or to avoid spurious features by designing strategies for finding useful demonstrations in few-shot learning <ref type="bibr">Zhang and Yu [2023]</ref> or control NLP classifiers <ref type="bibr" target="#b77">Bansal and Sharma [2023]</ref>. <ref type="bibr" target="#b76">Chen et al. [2023]</ref> develop a causal model to systematically quantify and remove two specific kinds of bias: psycholinguistic (use of emotional language) and imageonly (ignoring text features). Note that the assumptions of the causal model address very specific types of bias using both interventional and counterfactual techniques. <ref type="bibr" target="#b77">Bansal and Sharma [2023]</ref> presents a particularly interesting case as it addresses the same issue as <ref type="bibr" target="#b41">Gardner et al. [2021]</ref>, but from a causal perspective. They both  <ref type="bibr" target="#b37">Razeghi et al. [2022]</ref>. (a) A simple interpretation of their approach using the confounding CAT. (b) A causal framing for an alternative approach where we do not consider the term frequency, and instead observe a spurious correlation. (c) A more cautious causal framing that combines CATs to avoid claiming that the term frequency causally affects the model's accuracy (as is consistent with the authors' approach). study the issue of label bias, specifically in "competency problems" <ref type="bibr" target="#b41">[Gardner et al., 2021]</ref>, where an individual token in the prompt is not indicative of the label, but the model learns to rely on it, usually due to selection bias in the data collection.</p><p>The authors of <ref type="bibr" target="#b41">Gardner et al. [2021]</ref> propose a mitigation strategy based on "local edits" to individual tokens in the prompt to debias the benchmark. Using their statistical framing, the authors prove that the most promising strategy must apply local edits such that the label is flipped precisely half of the time.</p><p>Translating this into a causal framing, we can recover the same result quite intuitively. Adopting the same terms as <ref type="bibr" target="#b41">Gardner et al. [2021]</ref>, we now treat the input (text) features X as the stimulus, the model's response Y as the response, and the individual token X i as the third variable, which our model has learned to rely on despite it being a spurious feature. To remove the label bias for our model, we need the effect of an edit on X i = x ′ i to be as likely to flip the label as not. This is equivalent to the average causal effect conditioned on X:</p><formula xml:id="formula_1">E(Y |X, do(X i = x ′ i )) -E(Y |X, do(X i = x i )) = 0 (1)</formula><p>However, due to the non-causal treatment <ref type="bibr" target="#b41">Gardner et al. [2021]</ref>, need to make a "strong independence assumption," which is equivalent to, for the purposes of the mitigation strategy, assuming that the individual token X i is completely independent of the prompt X. As the authors point out, this assumption is not very realistic, as changing a single token may well affect the semantic meaning of the prompt beyond just the label (e.g. replacing "very" with "not" in a movie review).</p><p>Meanwhile, <ref type="bibr" target="#b77">Bansal and Sharma [2023]</ref> uses a causal graph matching the spurious correlation CAT and a condition analogous to Equation 1 to derive a causal regularization term for the model's training objectivewithout the need for the strong independence assumption.</p><p>In summary, both approaches started with the same objective, but due to the purely statistical treatment, a cumbersome derivation still required an unrealistic assumption severely limiting the applicability of the method. The causal model not only provided a more intuitive motivation for the approach, but also offered a more powerful, principled method for achieving the same goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Alternative Views</head><p>We are hardly the first to point out systematic shortcomings of evaluation methodology, particularly in NLP. One existing perspective focuses on improving the external validity of benchmarks to ensure that high performance on a benchmark actually translates to improved capabilities in the real world, such as with common sense reasoning <ref type="bibr" target="#b78">[Elazar et al., 2021]</ref>, or more precisely defining LLMs <ref type="bibr" target="#b79">[Rogers and Luccioni, 2024]</ref> and how tasks relate to specific cognitive capabilities <ref type="bibr" target="#b49">[Schlangen, 2019]</ref>. <ref type="bibr">Raji et al. [2021]</ref> argue that the common practice for certain "standard" benchmarks to become proxies for testing complex, high-level abilities, such as natural language understanding (NLU) leads to vague or unreliable results, while <ref type="bibr" target="#b31">Rogers and Rumshisky [2020]</ref> connect this to a proliferation of low-quality datasets.</p><p>Precisely this issue, that "benchmarking for NLU is broken" Bowman and Dahl <ref type="bibr">[2021]</ref>, can be addressed using causality. Not only does a causal framing provide a versatile way to define the underlying assumptions and design choices of a benchmark, but it also offers principled methods for evaluating the benchmark's external validity <ref type="bibr">[Bareinboim and</ref><ref type="bibr" target="#b80">Pearl, 2012, Pearl and</ref><ref type="bibr">Bareinboim, 2022]</ref>.</p><p>In the context of evaluating the reasoning abilities of language models, a natural field to turn to is psychometrics, which has been studying the evaluation of human reasoning abilities for over a century <ref type="bibr" target="#b82">[Wilhelm, 2005]</ref>. This direction also coincides with an increasing practice in Natural Language Processing (NLP) to treat language models as agents <ref type="bibr" target="#b83">[Park et al., 2023</ref><ref type="bibr" target="#b84">, Liu et al., 2023]</ref> or subjects in the social sciences <ref type="bibr" target="#b85">[Horton, 2023</ref><ref type="bibr" target="#b86">, Leng and Yuan, 2023</ref><ref type="bibr" target="#b87">, Pellert et al., 2024]</ref>. Specifically, item response theory <ref type="bibr" target="#b88">[Lord and</ref><ref type="bibr">Novick, 2008, Baker, 2001]</ref> holds promise to develop tools to systematically quantify what information about the model's reasoning abilities can be extracted from a benchmark with respect to some population candidate models, and there are some projects applying this framework in the context of NLP <ref type="bibr" target="#b90">[Rodriguez et al., 2021]</ref>. Within the field of NLP there are also notable calls for more holistic evaluation schemes <ref type="bibr" target="#b83">[Liang et al., 2023</ref><ref type="bibr">, Bowman and Dahl, 2021</ref><ref type="bibr" target="#b52">, Zhang et al., 2024a]</ref> and practical tools for improving the evaluation of language models <ref type="bibr" target="#b91">[Ribeiro et al., 2020</ref><ref type="bibr">, Srivastava et al., Alzahrani et al., 2024]</ref> or even reintroducing principles from linguistic theory <ref type="bibr">[Lan, 2023]</ref>.</p><p>There is also a growing interest in studying the causal knowledge learned by language models <ref type="bibr" target="#b94">[Zhang et al., 2023</ref><ref type="bibr" target="#b95">, Kıcıman et al., 2023]</ref> and their causal reasoning abilities <ref type="bibr" target="#b96">[Jin et al., 2024</ref><ref type="bibr" target="#b19">, Zečević et al., 2023</ref><ref type="bibr">, Liu et al., 2024]</ref> to help with causal discovery <ref type="bibr">[Montagna et al., Jiralerspong et al., 2024]</ref> or even hypothesis generation in psychology <ref type="bibr" target="#b100">[Tong et al., 2024]</ref>. This effort largely coincides with our message: just as an LLM may benefit from more explicit causal models, so can the research community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The burgeoning research on large models, and, in particular, high-level reasoning tasks, faces a variety of challenges, or monsters, to reliably evaluate and improve models. Despite the wide variety of approaches and frameworks that have been developed to tackle these challenges, this variety obscures their shared structural features and recurring issues. By recognizing that monsters can often be effectively formulated in terms of causal assumptions underlying an experimental design or data generation process, we can unify our understanding using the language of causality.</p><p>A causal framing aids along several steps of the research process by guiding experimental design, formulating testable hypotheses, and interpreting results. Causal methods enable researchers to gain a clearer lens to understand how variables of interest interact, rather than merely optimizing for predictive performance on an artificial benchmark. We argue that causality offers a path toward deeper scientific insights, more transparent communication of assumptions, and stronger justifications for the conclusions drawn.</p><p>One stumbling block to adopting causal methods is that the restrictive assumptions and formalism may seem unapproachable at first. Additionally, researchers may hesitate to commit modeling assumptions to paper where they can be scrutinized. However, data-driven approaches which rely on implicit or vague assumptions along with results that may (inadvertently) be interpreted as causal contribute to confusion and unsupported claims, which hinder scientific progress. Causal methods, by contrast, encourage explicit modeling and critical thinking about the mechanisms that underlie empirical observations.</p><p>To make causality more accessible and practically applicable, we introduce Common Abstract Topologies (CATs) to faithfully describe the underlying structure of many issues that arise in designing and evaluating ML models. In the case studies in Section 4, we have shown how a causal framing can formalize a various common issues and help develop mitigate them. We envision CATs as a practical guide, helping researchers quickly identify relevant causal models and choose appropriate inference tools. Ultimately, causal models encourage more hypothesis-driven research which directly tackle key questions in a principled, transparent way, leading to more robust progress across empirical machine learning. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Sketch of a conceptual causal model treating the prompt (i.e. surface form) as a mediator between the underlying problem or task of interest and the model's response.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: Various causal framings based on the approach of<ref type="bibr" target="#b37">Razeghi et al. [2022]</ref>. (a) A simple interpretation of their approach using the confounding CAT. (b) A causal framing for an alternative approach where we do not consider the term frequency, and instead observe a spurious correlation. (c) A more cautious causal framing that combines CATs to avoid claiming that the term frequency causally affects the model's accuracy (as is consistent with the authors' approach).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Listen here, I'm starvin' and it's already half past four. Gotta rake in 10 grand in protection dough before I eat. I'm hittin' up every joint in the hood with my bat, collecting an average of 800 bucks a pop. Takes me 10 minutes to move from one mark to the next. Am I gonna get to chow down before 7?</figDesc><table><row><cell>LLM Chatbot: If you're aiming to collect 10 grand</cell></row><row><cell>by shaking down joints for an average of $800</cell></row><row><cell>each and it takes you 10 minutes to move from one</cell></row><row><cell>target to the next, it would take you approximately</cell></row><row><cell>3 hours and 20 minutes (200 minutes) to reach</cell></row><row><cell>your goal. Starting at half-past four, you should be</cell></row><row><cell>able to hit your target before 7 PM. So, yes, you</cell></row><row><cell>can have a meal before 7 if everything goes as</cell></row><row><cell>planned. Enjoy your dinner!</cell></row></table><note><p>• We propose intuitive templates for causal modeling, called Common Abstract Topologies (CATs), and show how these aid in effective model design • We motivate practical causal models to approaches in several case studies • We promote causality as a tool to encourage hypothesis-driven research with precise, transparent assumptions and more systematic evaluation 2 A Bestiary of Monsters Prompt: Example 1: The final answer is correct, and yet the reasoning is very wrong. Although this LLM's response is technically correct in a narrow sense, its answer for this GSM8k-like multi-step reasoning question Cobbe et al. [2021] is unsatisfactory both the purposes of evaluating the model's arithmetic reasoning, as well as commonsense or moral reasoning as the LLM appears not to pick up on the obvious unethical context implied by the scenario.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>the Everything in the Whole Wide World Benchmark, November 2021. Samuel R. Bowman and George E. Dahl. What Will it Take to Fix Benchmarking in Natural Language Understanding?, October 2021. Norah Alzahrani, Hisham Abdullah Alyahya, Yazeed Alnumay, Sultan Alrashed, Shaykhah Alsubaie, Yusef Almushaykeh, Faisal Mirza, Nouf Alotaibi, Nora Altwairesh, Areeb Alowisheq, M. Saiful Bari, and Haidar Khan. When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards, February 2024. Marianna Nezhurina, Lucia Cipolina-Kun, Mehdi Cherti, and Jenia Jitsev. Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Ofthe-Art Large Language Models, June 2024. Qianqi Yan, Xuehai He, Xiang Yue, and Xin Eric Wang. Worse than Random? An Embarrassingly Simple Probing Evaluation of Large Multimodal Models in Medical VQA, October 2024. Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT '21, pages 610-623, New York, NY, USA, March 2021. Association for Computing Machinery. ISBN 978-1-4503-8309-7. doi: 10.1145/3442188.3445922. Ben Green and Lily Hu. The myth in the methodology: Towards a recontextualization of fairness in machine learning. In Proceedings of the Machine Learning: The Debates Workshop, 2018. Lily Hu and Issa Kohler-Hausmann. What's Sex Got To Do With Fair Machine Learning? In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pages 513-513, January 2020a. doi: 10.1145/3351095.3375674.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The heir of vagueness and discomfort that researchers frequently use when mentioning potential undesirable biases or systematic limitations in their analysis is not unlike the way medieval cartographers would fill the mysterious edges of their maps with dragons.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>December 2023.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgment <rs type="person">Felix Leeb</rs> is supported by the <rs type="funder">International Max Planck Research School for Intelligent Systems (IMPRS-IS)</rs>. <rs type="person">Zhijing Jin</rs> is supported by PhD fellowships from the <rs type="funder">Future of Life Institute</rs> and <rs type="person">Open Philanthropy</rs>, as well as the travel support from <rs type="funder">ELISE</rs> (GA no <rs type="grantNumber">951847</rs>) for the <rs type="programName">ELLIS program</rs>. The material presented in this manuscript is partly based upon works supported by the <rs type="funder">German Federal Ministry of Education and Research (BMBF)</rs>: <rs type="person">Tübingen AI Center</rs>, FKZ: <rs type="grantNumber">01IS18039B</rs>; by the <rs type="funder">Machine Learning Cluster of Excellence</rs>, EXC number 2064/1 -Project number <rs type="grantNumber">390727645</rs>; the <rs type="funder">Swiss National Science Foundation</rs> (Project No. <rs type="grantNumber">197155</rs>); a <rs type="grantName">Responsible AI</rs> grant by the <rs type="funder">Haslerstiftung</rs>; an <rs type="grantName">ETH Grant</rs> (<rs type="grantNumber">ETH-19 21-1</rs>); the <rs type="funder">Precision Health Initiative</rs> at the <rs type="affiliation">University of Michigan</rs>; and by the <rs type="funder">John Templeton Foundation</rs> (grant #<rs type="grantNumber">61156</rs>).</p><p>Lastly, the authors thank <rs type="person">Luigi Gresele</rs> for the many fruitful conversations and feedback.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_DBphZ2m">
					<idno type="grant-number">951847</idno>
					<orgName type="program" subtype="full">ELLIS program</orgName>
				</org>
				<org type="funding" xml:id="_agQ4n3e">
					<idno type="grant-number">01IS18039B</idno>
				</org>
				<org type="funding" xml:id="_sKQ9w4K">
					<idno type="grant-number">390727645</idno>
				</org>
				<org type="funding" xml:id="_KNQq3UZ">
					<idno type="grant-number">197155</idno>
					<orgName type="grant-name">Responsible AI</orgName>
				</org>
				<org type="funding" xml:id="_M9BsFY5">
					<idno type="grant-number">ETH-19 21-1</idno>
					<orgName type="grant-name">ETH Grant</orgName>
				</org>
				<org type="funding" xml:id="_6UcqCB2">
					<idno type="grant-number">61156</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Rui</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xulang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Guerin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">GPTEval: A Survey on Assessments of ChatGPT and GPT</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2024-12">December 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronen</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ece</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Tat Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harsha</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sparks of Artificial General Intelligence: Early experiments with GPT-4</title>
		<imprint>
			<date type="published" when="2023-03">March 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks</title>
		<author>
			<persName><forename type="first">Tomer</forename><surname>Ullman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-03">March 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Katja</forename><surname>Grace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harlan</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><forename type="middle">Fabienne</forename><surname>Sandkühler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Weinstein-Raun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Brauner</surname></persName>
		</author>
		<title level="m">Thousands of AI Authors on the Future of AI</title>
		<imprint>
			<date type="published" when="2024-01">January 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Re-evaluating GPT-4&apos;s bar exam performance. Artificial Intelligence and Law</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Martínez</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10506-024-09396-9</idno>
		<imprint>
			<date type="published" when="2024-03">March 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Raunak</forename><surname>Chowdhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Deshmukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Koplow</surname></persName>
		</author>
		<ptr target="https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b" />
		<title level="m">GPT4 can&apos;t ace MIT</title>
		<imprint>
			<date type="published" when="2023-06">June 2023</date>
			<biblScope unit="page">76864</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The Dangers of Underclaiming: Reasons for Caution When Reporting How NLP Systems Fail</title>
		<author>
			<persName><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><surname>Bowman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-03">March 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Inioluwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Raji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amandalynne</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Paullada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arash</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolyn</forename><surname>Hajikhani</surname></persName>
		</author>
		<author>
			<persName><surname>Cole</surname></persName>
		</author>
		<title level="m">A Critical Review of Large Language Models: Sensitivity, Bias, and the Path Toward Specialized AI</title>
		<imprint>
			<date type="published" when="2023-07">July 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using cognitive psychology to understand GPT-3</title>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2218523120</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<idno type="ISSN">0027-8424, 1091-6490</idno>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">2218523120</biblScope>
			<date type="published" when="2023-02">February 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Zhijing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Lalwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tejas</forename><surname>Vaidhya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Lyu</surname></persName>
		</author>
		<title level="m">Mrinmaya Sachan, Rada Mihalcea, and Bernhard Schölkopf. Logical Fallacy Detection</title>
		<imprint>
			<date type="published" when="2022-12">December 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset</title>
		<author>
			<persName><forename type="first">Saeid</forename><surname>Naeini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raeid</forename><surname>Saqur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mozhgan</forename><surname>Saeidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Taati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-11">November 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought</title>
		<author>
			<persName><forename type="first">Abulhair</forename><surname>Saparov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-03">March 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On the Origin of Hallucinations in Conversational Models: Is it the Datasets or the Models?</title>
		<author>
			<persName><forename type="first">Nouha</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sivan</forename><surname>Milton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Osmar</forename><surname>Zaiane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-main.387</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<editor>
			<persName><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ivan</forename><surname>Vladimir</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Meza</forename><surname>Ruiz</surname></persName>
		</editor>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-07">July 2022</date>
			<biblScope unit="page" from="5271" to="5285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Chenhang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirley</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<title level="m">Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges</title>
		<imprint>
			<date type="published" when="2023-11">November 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Large Language Models Are Not Robust Multiple Choice Selectors</title>
		<author>
			<persName><forename type="first">Chujie</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-02">February 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Are Large Language Models Really Robust to Word-Level Perturbations?</title>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guozheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linrui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suwei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongzhe</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peilin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-09">September 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment</title>
		<author>
			<persName><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-04">April 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Certified Reasoning with Language Models</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Poesia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanishk</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Zelikman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-06">June 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Language models show human-like content effects on reasoning</title>
		<author>
			<persName><forename type="first">Ishita</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">K</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Stephanie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonia</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dharshan</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">L</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><surname>Hill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-07">July 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Parrots: Large Language Models May Talk Causality But Are Not Causal</title>
		<author>
			<persName><forename type="first">Matej</forename><surname>Zečević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Willig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Singh Dhami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-08">August 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">From Bytes to Biases: Investigating the Cultural Self-Perception of Large Language Models</title>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Messner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatum</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josephine</forename><surname>Matalone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-12">December 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Social Biases in NLP Models as Barriers for Persons with Disabilities</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinodkumar</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kellie</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Denuyl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-05">May 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias</title>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Vig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharon</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Nevo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simas</forename><surname>Sakenis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Shieber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-11">November 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study</title>
		<author>
			<persName><forename type="first">Yong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seolhwa</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Cabello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-03">March 2023a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Investigating Cultural Alignment of Large Language Models</title>
		<author>
			<persName><forename type="first">Badr</forename><surname>Alkhamissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Elnokrashy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mai</forename><surname>Alkhamissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-07">July 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">More human than human: Measuring Chat-GPT political bias</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Motoki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valdemar</forename><forename type="middle">Pinho</forename><surname>Neto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Rodrigues</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11127-023-01097-2</idno>
	</analytic>
	<monogr>
		<title level="j">Public Choice</title>
		<idno type="ISSN">0048-5829</idno>
		<imprint>
			<biblScope unit="volume">198</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1573" to="7101" />
			<date type="published" when="2024-01">January 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Gender bias and stereotypes in Large Language Models</title>
		<author>
			<persName><forename type="first">Hadas</forename><surname>Kotek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rikker</forename><surname>Dockum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1145/3582269.3615599</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The ACM Collective Intelligence Conference, CI &apos;23</title>
		<meeting>The ACM Collective Intelligence Conference, CI &apos;23<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023-11">November 2023</date>
			<biblScope unit="page" from="12" to="24" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Premise Order Matters in Reasoning with Large Language Models</title>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-05">May 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Iman</forename><surname>Mirzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keivan</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hooman</forename><surname>Shahrokhi</surname></persName>
		</author>
		<title level="m">Oncel Tuzel, Samy Bengio, and Mehrdad Farajtabar. GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models</title>
		<imprint>
			<date type="published" when="2024-10">October 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks</title>
		<author>
			<persName><forename type="first">Zhaofeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linlu</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekin</forename><surname>Akyürek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Najoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-03">March 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shudong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maizhen</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jindong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiufeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaizhu</forename><surname>Huang</surname></persName>
		</author>
		<title level="m">Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist</title>
		<imprint>
			<date type="published" when="2024-10">October 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A guide to the dataset explosion in QA, NLI, and commonsense reasoning</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-tutorials.5</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics: Tutorial Abstracts</title>
		<editor>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Daniel</forename><surname>Beck</surname></persName>
		</editor>
		<meeting>the 28th International Conference on Computational Linguistics: Tutorial Abstracts<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12">December 2020</date>
			<biblScope unit="page" from="27" to="32" />
		</imprint>
	</monogr>
	<note>ternational Committee for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Don&apos;t Make Your LLM an Evaluation Benchmark Cheater</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wentong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-11">November 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Linzen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1334</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="3428" to="3448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Shortcutted Commonsense: Data Spuriousness in Deep Learning of Commonsense Reasoning</title>
		<author>
			<persName><forename type="first">Ruben</forename><surname>Branco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">António</forename><surname>Branco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">João António</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">João Ricardo</forename><surname>Silva</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.113</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Scott</forename><surname>Wen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">-Tau</forename><surname>Yih</surname></persName>
		</editor>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">November 2021</date>
			<biblScope unit="page" from="1504" to="1521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">How Pre-trained Language Models Capture Factual Knowledge? A Causal-Inspired Analysis</title>
		<author>
			<persName><forename type="first">Shaobo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhua</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingquan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenzhou</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-03">March 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and Mitigation of Reasoning Shortcuts</title>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Marconato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Teso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Vergari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Passerini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-12">December 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Impact of Pretraining Term Frequencies on Few-Shot Reasoning</title>
		<author>
			<persName><forename type="first">Yasaman</forename><surname>Razeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-05">May 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Does Learning Require Memorization? A Short Tale about a Long Tail</title>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Feldman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-01">January 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Annotation Artifacts in Natural Language Inference Data</title>
		<author>
			<persName><forename type="first">Suchin</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2017</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06">June 2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="107" to="112" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The Perspectivist Paradigm Shift: Assumptions and Challenges of Capturing Human Labels</title>
		<author>
			<persName><forename type="first">Eve</forename><surname>Fleisig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Blodgett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><surname>Talat</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2024.naacl-long.126</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<editor>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Helena</forename><surname>Gomez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</editor>
		<meeting>the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Mexico City, Mexico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2024-06">June 2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2279" to="2292" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Competency Problems: On Finding and Removing Artifacts in Language Data</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Merrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-12">December 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Predicting Difficulty and Discrimination of Natural Language Questions</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashank</forename><surname>Srivastava</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-short.15</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-05">May 2022</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="119" to="130" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">What&apos;s Sex Got To Do With Fair Machine Learning?</title>
		<author>
			<persName><forename type="first">Lily</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Issa</forename><surname>Kohler-Hausmann</surname></persName>
		</author>
		<idno type="DOI">10.1145/3351095.3375674</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the 2020 Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<date type="published" when="2020-01">January 2020</date>
			<biblScope unit="page" from="513" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Having Beer after Prayer? Measuring Cultural Bias in Large Language Models</title>
		<author>
			<persName><forename type="first">Tarek</forename><surname>Naous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-03">March 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Questioning the Survey Responses of Large Language Models</title>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Dominguez-Olmedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Celestine</forename><surname>Mendler-Dünner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-02">February 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Position: The Causal Revolution Needs Scientific Pragmatism</title>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">R</forename><surname>Loftus</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st International Conference on Machine Learning</title>
		<meeting>the 41st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2024-07">July 2024</date>
			<biblScope unit="page" from="32671" to="32679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Open llm leaderboard</title>
		<author>
			<persName><forename type="first">Edward</forename><surname>Beeching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clémentine</forename><surname>Fourrier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Habib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nazneen</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Sanseviero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lewis</forename><surname>Tunstall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<ptr target="https://huggingface.co/spaces/open-llmleaderboard/open_llm_leaderboard" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models</title>
		<author>
			<persName><forename type="first">Aarohi</forename><surname>Srivastava</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2206.04615" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Language Tasks and Language Games: On Methodology in Current Natural Language Processing Research</title>
		<author>
			<persName><forename type="first">David</forename><surname>Schlangen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-08">August 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">Ali</forename><surname>Shirali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rediet</forename><surname>Abebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2210.03165" />
		<title level="m">A Theory of Dynamic Benchmarks</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divyansh</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atticus</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertie</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grusha</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratik</forename><surname>Ringshia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Thrush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dynabench: Rethinking Benchmarking in NLP</title>
		<imprint>
			<date type="published" when="2021-04">April 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">A Careful Examination of Large Language Model Performance on Grade School Arithmetic</title>
		<author>
			<persName><forename type="first">Hugh</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaughn</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiffany</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Slack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Hendryx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Lunati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Summer</forename><surname>Yue</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-05">May 2024a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">On Pearl&apos;s Hierarchy and the Foundations of Causal Inference</title>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">D</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duligur</forename><surname>Ibeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Icard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Probabilistic and Causal Inference: The Works of Judea Pearl</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022-03">March 2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="507" to="556" />
		</imprint>
	</monogr>
	<note>1 edition</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Phenomenological Causality</title>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergio</forename><surname>Hernan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garrido</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2022-11">November 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Multi-level cause-effect systems</title>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Chalupka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Eberhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v51/chalupka16.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Artificial Intelligence and Statistics</title>
		<editor>
			<persName><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Christian</forename><forename type="middle">C</forename><surname>Robert</surname></persName>
		</editor>
		<meeting>the 19th International Conference on Artificial Intelligence and Statistics<address><addrLine>Cadiz, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05-09">2016. May 9-11, 2016. 2016</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="361" to="369" />
		</imprint>
	</monogr>
	<note>JMLR Workshop and Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Causal consistency of structural equation models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Rubenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weichwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bongers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grosse-Wentrup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<ptr target="http://auai.org/uai2017/proceedings/papers/11.pdf.*equalcontribution" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Conference on Uncertainty in Artificial Intelligence (UAI), page ID 11</title>
		<meeting>the 33rd Conference on Uncertainty in Artificial Intelligence (UAI), page ID 11</meeting>
		<imprint>
			<date type="published" when="2017-08">August 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Approximate causal abstractions</title>
		<author>
			<persName><forename type="first">Sander</forename><surname>Beckers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Eberhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">Y</forename><surname>Halpern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in artificial intelligence</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="606" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Causal inference in statistics: An overview</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction</title>
		<author>
			<persName><forename type="first">Guido</forename><forename type="middle">W</forename><surname>Imbens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Elements of Causal Inference -Foundations and Learning Algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Comment: understanding simpson&apos;s paradox</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Probabilistic and causal inference: The works of judea Pearl</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="399" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">The direction of time</title>
		<author>
			<persName><forename type="first">Hans</forename><surname>Reichenbach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1956">1956</date>
			<publisher>Univ of California Press</publisher>
			<biblScope unit="volume">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Aspects of theory-ladenness in dataintensive science</title>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Pietsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy of Science</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="905" to="916" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">A Causal Framework for Decomposing Spurious Variations</title>
		<author>
			<persName><forename type="first">Drago</forename><surname>Plecko</surname></persName>
		</author>
		<author>
			<persName><surname>Bareinboim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-06">June 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhankui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Handong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2024.naacl-long.262</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<editor>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Helena</forename><surname>Gomez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</editor>
		<meeting>the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Mexico City, Mexico</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2024-06">June 2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4684" to="4695" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Causal Inference for Human-Language Model Collaboration</title>
		<author>
			<persName><forename type="first">Bohan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paramveer</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-03">March 2024b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Are NLP Models really able to Solve Simple Math Word Problems?</title>
		<author>
			<persName><forename type="first">Arkil</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satwik</forename><surname>Bhattamishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navin</forename><surname>Goyal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-04">April 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Stolfo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mrinmaya</forename><surname>Sachan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-10">October 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Editing Common Sense in Transformers</title>
		<author>
			<persName><forename type="first">Anshita</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debanjan</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><surname>Akshay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenlong</forename><surname>Sheshadri</surname></persName>
		</author>
		<author>
			<persName><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorraine</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niket</forename><surname>Wiegreffe</surname></persName>
		</author>
		<author>
			<persName><surname>Tandon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-10">October 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Locating and Editing Factual Associations in GPT</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Andonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-01">January 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Interpretability in the Wild: A Circuit for Indirect Object Identification in GPT-2 small</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Variengien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Conmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Buck</forename><surname>Shlegeris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-11">November 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Grégoire</forename><surname>Mialon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Dessì</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Lomeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoforos</forename><surname>Nalmpantis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ram</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberta</forename><surname>Raileanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Baptiste Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asli</forename><surname>Dwivedi-Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><surname>Scialom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-02">February 2023</date>
		</imprint>
	</monogr>
	<note>Augmented Language Models: A Survey</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Large Language Model Programs</title>
		<author>
			<persName><forename type="first">Imanol</forename><surname>Schlag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-05">May 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nelson</forename><surname>Elhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nova</forename><surname>Dassarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Conerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deep</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zac</forename><surname>Hatfield-Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackson</forename><surname>Kernion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liane</forename><surname>Lovitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamal</forename><surname>Ndousse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<ptr target="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html" />
		<title level="m">-context learning and induction heads. Transformer Circuits Thread</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Does the Correctness of Factual Knowledge Matter for Factual Knowledge-Enhanced Pre-trained Language Models?</title>
		<author>
			<persName><forename type="first">Boxi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaoyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.emnlp-main.143</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Houda</forename><surname>Bouamor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Juan</forename><surname>Pino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</editor>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023-12">December 2023</date>
			<biblScope unit="page" from="2327" to="2340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Causal Intervention and Counterfactual Reasoning for Multi-modal Fake News Detection</title>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linmei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weixin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingxia</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.acl-long.37</idno>
		<idno>doi: 10.18653/v1/2023. acl-short.125</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</editor>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada; Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023-07">July 2023. July 2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1465" to="1475" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<author>
			<persName><forename type="first">Parikshit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Sharma</surname></persName>
		</author>
		<title level="m">Controlling Learned Effects to Reduce Spurious Correlations in Text Classifiers</title>
		<imprint>
			<date type="published" when="2023-06">June 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Back to Square One: Artifact Detection, Training and Commonsense Disentanglement in the Winograd Schema</title>
		<author>
			<persName><forename type="first">Yanai</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-10">October 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Sasha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luccioni</forename></persName>
		</author>
		<title level="m">Position: Key Claims in LLM Research Have a Long Tail of Footnotes</title>
		<imprint>
			<date type="published" when="2024-06">June 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Transportability of Causal Effects: Completeness Results</title>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v26i1.8232</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="698" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">External Validity: From Do-Calculus to Transportability Across Populations. In Probabilistic and Causal Inference: The Works of Judea Pearl</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-03">March 2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="451" to="482" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>Association for Computing Machinery. 1 edition</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Measuring reasoning ability</title>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Wilhelm</surname></persName>
		</author>
		<idno type="DOI">10.4135/9781452233529.n21</idno>
	</analytic>
	<monogr>
		<title level="m">Handbook of Understanding and Measuring Intelligence</title>
		<imprint>
			<date type="published" when="2005-01">January 2005</date>
			<biblScope unit="page" from="373" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<author>
			<persName><forename type="first">Sung</forename><surname>Joon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><forename type="middle">J</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><surname>Bernstein</surname></persName>
		</author>
		<title level="m">Generative Agents: Interactive Simulacra of Human Behavior</title>
		<imprint>
			<date type="published" when="2023-04">April 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanchen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanyu</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanyu</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hangliang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiwen</forename><surname>Men</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kejuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shudan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aohan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenhui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianjun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-08">August 2023</date>
		</imprint>
	</monogr>
	<note>AgentBench: Evaluating LLMs as Agents</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">J</forename><surname>Horton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-01">January 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Do LLM Agents Exhibit Social Behavior?</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-12">December 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories</title>
		<author>
			<persName><forename type="first">Max</forename><surname>Pellert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><forename type="middle">M</forename><surname>Lechner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beatrice</forename><surname>Rammstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Strohmaier</surname></persName>
		</author>
		<idno type="DOI">10.1177/17456916231214460</idno>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<idno type="ISSN">1745- 6916</idno>
		<imprint>
			<biblScope unit="page">17456916231214460</biblScope>
			<date type="published" when="2024-01">January 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Statistical theories of mental test scores</title>
		<author>
			<persName><forename type="first">M</forename><surname>Frederic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melvin</forename><forename type="middle">R</forename><surname>Lord</surname></persName>
		</author>
		<author>
			<persName><surname>Novick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IAP</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">The basics of item response theory</title>
		<author>
			<persName><forename type="first">B</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><surname>Baker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>ERIC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Evaluation Examples are not Equally Informative: How should that change NLP Leaderboards?</title>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Barrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Miserlis Hoyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">P</forename><surname>Lalor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.346</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08">August 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4486" to="4503" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Beyond Accuracy: Behavioral Testing of NLP models with CheckList</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-05">May 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap</title>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annarose</forename><forename type="middle">M B</forename><surname>Anto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashank</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Sukumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adwaith</forename><surname>Samod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Philipose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stevin</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sooraj</forename><surname>Thomas</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2402.19450" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Language models and linguistic theories beyond words</title>
		<idno type="DOI">10.1038/s42256-023-00703-8</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<idno type="ISSN">2522-5839</idno>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="677" to="678" />
			<date type="published" when="2023-07">July 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbo</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agrin</forename><surname>Hilmkil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Jennings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Vaughan</surname></persName>
		</author>
		<title level="m">Understanding Causality with Large Language Models: Feasibility and Opportunities</title>
		<imprint>
			<date type="published" when="2023-04">April 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<author>
			<persName><forename type="first">Emre</forename><surname>Kıcıman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Ness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<title level="m">Causal Reasoning and Large Language Models: Opening a New Frontier for Causality</title>
		<imprint>
			<date type="published" when="2023-04">April 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<author>
			<persName><forename type="first">Zhijing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Leeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luigi</forename><surname>Gresele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ojasv</forename><surname>Kamal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Blin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Gonzalez Adauto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mrinmaya</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<title level="m">CLadder: Assessing Causal Reasoning in Language Models</title>
		<imprint>
			<date type="published" when="2024-01">January 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">CASA: Causality-driven Argument Sufficiency Assessment</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-04">April 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Demystifying amortized causal discovery with transformers</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Montagna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Cairney-Leeming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhanya</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2405.16924" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Yash More, Vedant Shah, and Yoshua Bengio. Efficient Causal Graph Discovery Using Large Language Models</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Jiralerspong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyin</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-02">February 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Automating psychological hypothesis generation with AI: When large language models meet causal graph</title>
		<author>
			<persName><forename type="first">Song</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiping</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.1057/s41599-024-03407-5</idno>
	</analytic>
	<monogr>
		<title level="j">Humanities and Social Sciences Communications</title>
		<idno type="ISSN">2662-9992</idno>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">896</biblScope>
			<date type="published" when="2024-07">July 2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
