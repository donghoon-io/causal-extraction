<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Debiased Contrastive Representation Learning for Mitigating Dual Biases in Recommender Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhirong</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education</orgName>
								<orgName type="laboratory">Key Lab of Education Blockchain and Intelligent Technology</orgName>
								<orgName type="institution">Guangxi Normal University</orgName>
								<address>
									<postCode>541004</postCode>
									<settlement>Guilin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Guangxi Key Lab of Multi-Source Information Mining and Security</orgName>
								<orgName type="institution">Guangxi Normal University</orgName>
								<address>
									<postCode>541004</postCode>
									<settlement>Guilin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Shichao</forename><surname>Zhang</surname></persName>
							<email>zhangsc@mailbox.gxnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education</orgName>
								<orgName type="laboratory">Key Lab of Education Blockchain and Intelligent Technology</orgName>
								<orgName type="institution">Guangxi Normal University</orgName>
								<address>
									<postCode>541004</postCode>
									<settlement>Guilin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Guangxi Key Lab of Multi-Source Information Mining and Security</orgName>
								<orgName type="institution">Guangxi Normal University</orgName>
								<address>
									<postCode>541004</postCode>
									<settlement>Guilin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Debo</forename><surname>Cheng</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">UniSA STEM</orgName>
								<orgName type="institution">University of South Australia</orgName>
								<address>
									<settlement>Mawson Lakes Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiuyong</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">UniSA STEM</orgName>
								<orgName type="institution">University of South Australia</orgName>
								<address>
									<settlement>Mawson Lakes Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lin</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">UniSA STEM</orgName>
								<orgName type="institution">University of South Australia</orgName>
								<address>
									<settlement>Mawson Lakes Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guixian</forename><surname>Zhang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">China University of Mining and Technology</orgName>
								<address>
									<postCode>221116</postCode>
									<settlement>Xuzhou Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Debiased Contrastive Representation Learning for Mitigating Dual Biases in Recommender Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recommender systems, popularity and conformity biases undermine recommender effectiveness by disproportionately favouring popular items, leading to their over-representation in recommendation lists and causing an unbalanced distribution of user-item historical data. We construct a causal graph to address both biases and describe the abstract data generation mechanism. Then, we use it as a guide to develop a novel Debiased Contrastive Learning framework for Mitigating Dual Biases, called DCLMDB. In DCLMDB, both popularity bias and conformity bias are handled in the model training process by contrastive learning to ensure that user choices and recommended items are not unduly influenced by conformity and popularity. Extensive experiments on two real-world datasets, Movielens-10M and Netflix, show that DCLMDB can effectively reduce the dual biases, as well as significantly enhance the accuracy and diversity of recommendations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Recommender systems are designed to predict user preferences and recommend items that might be of interest to users. They are widely used in e-commerce (e.g. by Amazon.com) <ref type="bibr" target="#b15">(Shoja and Tabrizi 2019)</ref>, streaming services (e.g. by Netflix) (Gomez-Uribe and Hunt 2015), social media platforms <ref type="bibr" target="#b12">(Liao et al. 2022)</ref>, and other online services where personalised content is crucial <ref type="bibr" target="#b4">(Covington, Adams, and Sargin 2016;</ref><ref type="bibr" target="#b18">Xie et al. 2021)</ref>. In an era of information, recommender systems are increasingly indispensable since they not only assist users in finding content that aligns with their preferences but also offer substantial commercial benefits <ref type="bibr" target="#b15">(Shoja and Tabrizi 2019)</ref>. For example, e-commerce platforms can significantly increase the transaction probability by recommending products of interest to users.</p><p>Traditional recommender system models operate under the assumption that observational data is generated when a user's preference aligns with the attributes of an item. Various models employing collaborative filtering algorithms have been developed based on this premise <ref type="bibr">(Liang et</ref>  2018; <ref type="bibr" target="#b25">Zou et al. 2020;</ref><ref type="bibr" target="#b9">Ji et al. 2020</ref>). These models predict the likelihood of a user choosing an item by calculating the inner product of their respective embedding. We illustrate these models using the causal graph in Fig. <ref type="figure" target="#fig_0">1</ref> (a), where U and I represent user preference and exposed item, respectively, and both are causes of C, the choice. However, the traditional modelling approach can be biased towards popular items. Popularity bias leads to over-recommendation of certain items to users despite users' lack of prior interaction with similar items, thereby missing the opportunity of recommending users truly interesting items by matching user preferences and item attributes. Balanced representation of items in a recommender system is a common approach to addressing popularity bias <ref type="bibr">(Zhao et al. 2023b;</ref><ref type="bibr" target="#b13">Schnabel et al. 2016)</ref>. For instance, Zhang et al. <ref type="bibr" target="#b19">(Zhang et al. 2021</ref>) proposed a novel training and inference paradigm called Popularity-bias Deconfounding and Adjusting (PDA). This method employs docalculus <ref type="bibr">(Pearl 2009;</ref><ref type="bibr" target="#b3">Cheng et al. 2024)</ref> to mitigate the negative effects of popularity bias during the training phase and adjusts predicted item popularity scores during inference for endowing recommendation policy with the desired level of popularity bias. PDA incorporates an item popularity node Z into the traditional recommender model, as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>  of an item influences its exposure rate, while Z → C indicates that item popularity impacts user choice because users tend to believe that a popular item has a high quality.</p><p>Conformity bias occurs when users align their choices with the group, even the item attributes conflict with their personal preferences <ref type="bibr" target="#b2">(Chen et al. 2023</ref>). Zheng et al. <ref type="bibr" target="#b22">(Zheng et al. 2021</ref>) presented an innovative causal graph that outlines user-item interactions influenced by conformity. They developed a framework called Disentangling Interest and Conformity with Causal Embedding (DICE), which utilises different embedded representations to independently capture user interest and conformity, thereby reducing the impact of user conformity bias.</p><p>Existing methods address either popularity bias or conformity bias, but no works deal with both biases. Popularity and conformity biases often coexist (as verified through experiments detailed in the Appendix) and should be addressed simultaneously. In this paper, we aim to tackle the complexity of user-item interactions to mitigate both biases. We model both biases using the causal graph as shown in Fig. <ref type="figure" target="#fig_1">2 (a)</ref>. Specifically, W → U demonstrates that conformity distorts user judgement, while W → C denote that conformity directly impacts user choice, e.g., word-of-mouth.</p><p>To tackle the issue of the dual biases, it is essential to sever connections that contribute to these biases. That is, we need to cut the edges Z → I and W → U as shown in the manipulated causal graph (Pearl 2009) in Fig. <ref type="figure" target="#fig_1">2 (b)</ref> when training a recommender model. In this way, user choices and recommended items are not influenced by conformity and popularity. To achieve this, we propose a novel framework, the Debiased Contrastive Learning framework for Mitigating Dual Biases (DCLMDB) to learn and disentangle the latent representations Z and W from user-item interactions, aiming to remove the connections contributing to the biases. Fine-tuning Z and W to address the dual biases by applying back-door adjustment (Pearl 2009) improves the implementation of the click prediction task and enhances recommendation accuracy. The main contributions of our work are summarised as follows:</p><p>• We study the problem regarding popularity and conformity biases in recommender systems and use a graphical causal modelling approach to address the problem. To the best of our knowledge, this is the first work which simultaneously addresses both the popularity bias associated with items and the conformity bias stemming from users. • We design and develop a novel debiased contrastive learning framework, DCLMDB, for mitigating both popularity and conformity biases by learning two embeddings derived from the latent space of items and users. • Extensive experiments conducted on two real-world datasets validate the effectiveness and robustness of our DCLMDB model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Recommender systems primarily aim to predict user choices. Collaborative filtering, which leverages user-item historical data to uncover user-item similarities, remains a dominant approach for personalised recommendations. In recent years, causal-based recommendation methods have emerged. This section reviews related work in two main areas: traditional and causal recommendation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Traditional Recommendation Methods</head><p>Traditional collaborative filtering methods focus on learning user and item embeddings to make predictions. Early methods, such as Matrix Factorisation (MF) <ref type="bibr" target="#b10">(Koren, Bell, and Volinsky 2009)</ref>, decompose the user-item rating matrix to predict user ratings and personalised rankings. However, MF is not inherently optimised for personalised ranking, leading to the development of the Bayesian Personalised Ranking (BPR) loss by Rendle et al. <ref type="bibr" target="#b13">(Rendle et al. 2012)</ref>, which has become a standard in personalised recommender methods.</p><p>With the advances of deep learning, He et al. <ref type="bibr" target="#b8">(He et al. 2017)</ref> proposed the Neural network-based Collaborative Filtering (NCF) framework, replacing the inner product with a multilayer perceptron to model user-item choices.</p><p>To enhance the capture of interaction information between users and items, researchers have incorporated graph structures into recommender systems <ref type="bibr" target="#b17">(Xia et al. 2022;</ref><ref type="bibr" target="#b23">Zhu, Sun, and Chen 2021;</ref><ref type="bibr" target="#b12">Liu et al. 2021)</ref>. <ref type="bibr" target="#b16">Wang et al. (Wang et al. 2019</ref>) introduced the Neural Graph Collaborative Filtering (NGCF) framework, grounded in Graph Convolutional Networks (GCN), which markedly enhances recommendation performance by more precisely embedding useritem interaction data. Nonetheless, He et al. <ref type="bibr" target="#b8">(He et al. 2020)</ref> noticed that the feature transformation and the nonlinear activation components in NGCF did not significantly improve the performance. Therefore, they retained only the neighbourhood aggregation component and then proposed the Light Graph Convolutional Network (LightGCN). However, these methods often overlook popularity bias and conformity bias, inadvertently amplifying the biases during training and skewing recommendations towards popular items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Causal Recommendation Methods</head><p>The impact of popularity bias and conformity bias has led to the emergence of causal inference-based solutions. A notable method is Inverse Propensity Scoring (IPS) <ref type="bibr" target="#b13">(Schnabel et al. 2016)</ref>, which reweights items based on their popularity, giving less popular items a greater weight to mitigate bias. Despite IPS's effectiveness, its high variance led to the development of variants for stability <ref type="bibr" target="#b1">(Bottou et al. 2013;</ref><ref type="bibr" target="#b6">Gruson et al. 2019;</ref><ref type="bibr" target="#b24">Zhu et al. 2020)</ref>. CausE, proposed by <ref type="bibr" target="#b0">Bonner et al. (Bonner and Vasile 2018)</ref>, uses both a biased and a small unbiased dataset to obtain two sets of embeddings, which are later regularised to reduce their disparity.</p><p>However, constructing unbiased datasets is costly and often ignores user conformity. <ref type="bibr" target="#b22">Zheng et al. (Zheng et al. 2021)</ref> tackled conformity bias at the embedding level with the framework that DICE, separating user and item embeddings into interest and conformity parts of the user by constructing specific training samples. <ref type="bibr">Zhao et al. (Zhao et al. 2023a)</ref> argued that the DICE approach to constructing specific training samples introduces noise, so they modified it to use contrast learning for data augmentation and then decoupled user interest and conformity based on DICE. On the other hand, Zhang et al. <ref type="bibr" target="#b19">(Zhang et al. 2021</ref>) proposed the PDA method, which uses the do-calculus to eliminate the popularity bias on the item side during the model training phase. These approaches, while innovative in addressing item-based popularity bias or conformity of user, have not considered mitigating both biases simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Proposed DCLMDB Framework</head><p>We first provide the problem definition and then analyse the effects of both popularity bias and conformity bias on the effectiveness of recommendations from a causal perspective. Subsequently, we propose DCLMDB, the debiasing framework based on disentangled contrastive learning designed to simultaneously mitigate the negative impacts of popularity bias and conformity bias in recommender systems. We provide definitions/concepts of causality related to our DCLMDB framework in the Appendix due to the page limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem Setting and A Causal Analysis</head><p>In a recommender system, there are two main sets: V , the set of users and J, the set of items. We denote a specific user in set V as v. Within set J, we identify two types of items, p and n, where p is an item that user q has chosen, while n are many items that the user q did not choose. Let D denote user behaviour data, which can be represented as a set of triples, i.e., D = {(v, p, n)|p, n ∈ J, v ∈ V }. We use C to indicate whether or not a user has chosen an item. Due to the complexity of user-item interplay, the historical data D often does not reflect real user preferences and exposed items. Thus, we need to reconstruct both user preference (denoted as U ) and exposed items (denoted as I) from D.</p><p>In this work, we simultaneously consider both item popularity and user conformity biases. To analyse the dual biases, we propose a new causal graph G, depicted in Fig. <ref type="figure" target="#fig_1">2 (a)</ref>, which explicates the factors contributing to popularity bias and conformity bias in recommender systems. In the causal graph G, we use Z to represent an item's popularity, which is considered as a latent factor. Traditional methods, such as matrix factorisation, do not explicitly model this aspect, yet it significantly impacts the effectiveness of the recommendation. W denotes conformity influence, a latent factor reflecting the behaviour of other users who choose the item. The relationships between nodes in the causal graph G are represented by edges, which are explained as follows:</p><p>• (U, I, Z, W ) → C denotes that the four edges pointing toward C from U , I, Z and W respectively, i.e., C is determined by the four factors: U , I, Z and W . Traditional recommendation methods operate under the assumption that a choice C occurs when user preference U matches with attributes of the exposed item I. In this work, we aim to learn the two latent causes of C, Z and W , to account for popularity and conformity biases. Specifically, the edge Z → C signifies that an item's popularity influences the choice. For example, a "popular movie" is more likely to be chosen by a user. Similarly, W → C refers to the effect of user word-of-mouth on choice, e.g., a movie with high positive ratings is more likely to be chosen by a user. • W → U represents the influence of conformity on a user.</p><p>This conformity effect can be detrimental to the recommender system as it may not accurately reflect the user's genuine preference. For instance, a user might conform to many other users on an online forum and choose the same movie, even though it is not their preferred type of movie. • Z → I indicates that the popularity of items affects their exposure. For example, on many online movie ticket websites, merchants can have their movies appear on the homepage recommendation list by purchasing certain traffic services from the website (i.e., increase item exposure). However, this does not reflect the attributes and quality of the items; it is merely a means to increase the sales of movies.</p><p>From the causal graph G, we know that Z and W are confounders between (I, C) and (U, C), respectively. Thus, W affects the observed choices through the causal paths W → C and W → U → C. The path W → U → C indicates that the conformity effect contributes to a higher prevalence of certain choices, leading to what is known as conformity bias amplification (Gomez-Uribe and Hunt 2015; <ref type="bibr" target="#b2">Chen et al. 2023</ref>). This effect is undesirable in a recommender system. Similarly, Z affects the observed choices through Z → C and Z → I → C. The path Z → I → C indicates that the popularity of an item increases its exposure, leading to a higher prevalence of popular items in observed choices. This phenomenon results in popularity bias amplification, which is undesirable in a recommender system <ref type="bibr" target="#b19">(Zhang et al. 2021</ref>). An effective recommender system should accurately estimate a user's preferences and recommend the appropriate quality items. However, popularity and conformity biases lead to a false reflection of item quality or the user's genuine preference. Hence, they need to be mitigated to enhance a recommender system's effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mitigating the Dual Biases with Causal Inference</head><p>Guided by the proposed causal graph G in Fig. <ref type="figure" target="#fig_1">2</ref> (a) and the causal analysis in the previous section, we aim to design a data-driven method to mitigate both the popularity  <ref type="table"></ref>and<ref type="table">W</ref> ). Both sets of embeddings encompass those of users and items. Subsequently, in the debiasing learning phase (i.e., the dotted box portion of the figure), we employ contrastive learning to steer the debiased embeddings away from biases inherent in the base embeddings. The specific realisations of L u , L i and L BP R are in Eq. ( <ref type="formula" target="#formula_3">4</ref>), Eq.</p><p>(5) and Eq. ( <ref type="formula" target="#formula_5">6</ref>) respectively. Finally, L u , L i and L BP R are summed as in Eq. ( <ref type="formula" target="#formula_6">7</ref>) to obtain the final loss function L DCLM DB .</p><p>and conformity biases in recommender systems. As indicated in Fig. <ref type="figure" target="#fig_1">2</ref> (b), to deal with the biases, we need to remove the influence of popularity (Z) and conformity (W ) on item exposure (I) and user preferences (U ), respectively.</p><p>To this end, we propose to perform do(I, U ), i.e., the dooperation on I and U (Pearl 2009). The "do" operator, denoted as do(X = x), or do(x) for short, represents an intervention where X is set to a specific value x intentionally, rather than by observing X naturally occurring at x. Applying the do operation on I and U removes all the edges pointing to I and U , i.e., the edges Z → I and W → U from G as shown in Fig. <ref type="figure" target="#fig_1">2</ref> (b) by the red crosses. We denote the manipulated graph as G U,I . Note that cutting off the edges Z → I and W → U from G to obtain G U,I is equivalent to obtaining P (C | do(U, I)) from data. Thus, as implied by the manipulated graph G Ū,I , we need to ensure that W and U are independent, as well as Z and I when we learn the four embeddings from D. In the following sections, we will introduce the details of our method for achieving debiased recommendation based on causal manipulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Debiased Contrastive Representation Learning</head><p>Based on the above theoretical analysis from the perspective of causal inference, we proposed the novel Debiased Contrastive Learning framework for Mitigating Dual Biases (DCLMDB) as outlined in Fig. <ref type="figure" target="#fig_2">3</ref>.</p><p>It is challenging to learn both latent embeddings Z and W at the same time because, as shown in the causal graph in Fig. <ref type="figure" target="#fig_1">2 (b)</ref>, both are latent factors encoded within the useritem historical data and are influenced by the interactive nature of user-item information. To tackle this challenge, we employ contrastive representation learning <ref type="bibr" target="#b14">(Schroff, Kalenichenko, and Philbin 2015)</ref> to learn the embeddings Z and W derived from the latent spaces of items and users, guided by the proposed causal graph in Fig. <ref type="figure" target="#fig_1">2</ref> (b) to effectively mitigate the dual biases in recommender systems. Contrastive learning reduces the correlation between positive and negative samples in the feature space by adjusting the model such that the distance between the anchor point and positive samples (which are drawn closer together) is smaller than the distance between the anchor point and negative samples (which are pushed further apart).</p><p>First, we utilise a normal distribution to initialise the four embeddings: Z, W , U , and I. Then, we impose constraints in our DCLMDB method by ensuring that the learned Z is independent of I and W is independent of U . To achieve these independencies, contrastive representation learning is employed to distance Z (or W ) from I (or U ), thereby keeping Z (or W ) away from the biases in I (or U ) during the training phase. In our DCLMDB, I and U are used as negative samples for training Z and W through contrastive learning. We define the following similarity functions to calculate the similarity between the pairs (W, Z), (U, Z), and (W, I):</p><formula xml:id="formula_0">S wz = ⟨w v , z p ⟩ ,<label>(1)</label></formula><formula xml:id="formula_1">S uz = ⟨u v , z p ⟩ ,<label>(2)</label></formula><formula xml:id="formula_2">S wi = ⟨w v , i p ⟩ ,</formula><p>(3) where ⟨•, •⟩ denotes the dot product operation and is used to measure matching scores among the sample pairs (w v , z p ), (u v , z p ), and (w v , i p ). u v and w v represent the embeddings of user v, while i p and z p are the embeddings of the positive sample of item p (i.e., the user v selected item). We use two triplet loss functions in contrastive learning to maximise S wz and minimise S wz and S wi , thereby reducing the distance between the anchor point and the positive samples while increasing the distance between the anchor point and the negative samples. Note that in the two loss functions, w v and z p serve as anchor points and positive samples, and u v and i p serve as negative samples. The two loss functions are defined as follows.</p><formula xml:id="formula_3">L u = max (S wz -S uz + m, 0) ,<label>(4)</label></formula><formula xml:id="formula_4">L i = max (S wz -S wi + m, 0) ,<label>(5)</label></formula><p>where m is a hyperparameter. By maximising these distances, we keep w v (or z p ) away from u v (or i p ), and thereby reducing biases in u v (or i p ). Consequently, DCLMDB yields two embeddings, Z and W , such that is as uncorrelated with I as possible, and W is as uncorrelated with U as possible. Our DCLMDB seeks to redirect W and Z away from the biases found in U and I. Both loss functions L u and L i are used as regularisation terms in the click prediction task of the recommender system to ensure that Z (or W ) and I (or U ) remain independent during the training phase.</p><p>However, merely distancing (W, Z) from (U, I) does not guarantee the elimination of the dual biases. Since we are distancing them in multiple dimensions, it is not certain whether the direction of their distancing is mitigating or exacerbating the bias. We use the Bayesian Personalised Ranking (BPR) loss function to guide the direction of the optimisation of the two embeddings W and Z, as well as to achieve the main task (click prediction) in the recommender system.</p><formula xml:id="formula_5">L BRP = - (v,p,n)∈D ln σ (⟨w v , z p ⟩ -⟨w v , z n ⟩) ,<label>(6)</label></formula><p>where σ(•) is the activation function, and n denotes the negative sample item (i.e., the user q unselected items). Each training instance within the BPR loss function is represented by a ternary (v, p, n). This BPR function acts as the primary loss function in the recommender system, aiding in the click prediction. We utilise the Popularity-based Negative Sampling with Margin (PNSM) strategy <ref type="bibr" target="#b22">(Zheng et al. 2021</ref>) for selecting negative sample items. Consequently, the overall loss function of DCLMDB can be articulated as follows:</p><formula xml:id="formula_6">L DCLM DB = α • L BP R + β • (L u + L i ) ,<label>(7)</label></formula><p>where α and β stand as hyperparameters. Note that L DCLM DB is a realistic implementation of the causal graph in Fig. <ref type="figure" target="#fig_1">2 (b</ref>) that takes into account the reality of the click prediction task. For example, to leverage similar user behaviour for recommendations, we use the inner product operation instead of the distance metric in the latent space.</p><p>To summarise, we use the embeddings Z and W to separate biased input data, combined with the corresponding user v (i.e., U ) and item p (or n) (i.e., I) for click prediction to conform to the causal graph assumptions as shown in Fig. <ref type="figure" target="#fig_1">2</ref> (b). Additionally, L u (or L i ) serves as a regular term to ensure that W (or Z) and U (or I) remain independent.</p><p>By combining the two contrastive learning loss functions with the BPR function, we obtain our ultimate loss function, L DCLM DB . This combination enables us to learn two embeddings, Z and W , such that Z, I, W and U are mutually independent, as shown in the causal graph in Fig. <ref type="figure" target="#fig_1">2 (b</ref>). These independences align with the core objective of estimating click probability. Such alignment strengthens the direction of debiasing representation, ensuring that our DCLMDB effectively reduces bias without inadvertently intensifying it. Furthermore, our DCLMDB, being independent of specific data and models, serves as a generalised framework that can be seamlessly incorporated into various mainstream recommendation models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In this section, we conduct experiments on two real-world datasets to evaluate the performance of DCLMDB against state-of-the-art recommendation methods. The details of the parameter settings for all methods and additional experiments are provided in the Appendix due to the page limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Settings</head><p>Datasets: We utilised two real-world datasets: the Movielens-10M dataset <ref type="bibr">(Harper and</ref>   <ref type="bibr" target="#b0">(Bennett and Lanning 2007)</ref>. Both datasets comprise movie ratings featuring user IDs, movie IDs, and the ratings assigned by users. We preprocess the two datasets according to the previous methods <ref type="bibr" target="#b22">(Zheng et al. 2021)</ref>. We binarised both datasets by keeping the rating of five stars as one and others as zero. We randomly selected 40% of the items (which can be seen as the outcome of a completely random recommendation strategy) and designated 10% and 20% of these as the validation and test sets, respectively. Finally, the remaining 10% of the random data and another 60% of the unselected samples form the training set. This approach to dataset handling aims for realism, ensuring that test data are not influenced by item popularity and that each item has an equal chance of being exposed to users. Table <ref type="table" target="#tab_0">1</ref> provides the details of the two processed datasets.</p><p>Baseline: We compare DCLMDB with existing causal debiasing methods. Causal methods are often used as supplementary techniques alongside backbone recommendation models. In the experiments, all baseline methods use two commonly used backbone recommendation models, namely MF and LightGCN. We will compare our approach against the following six causal methods:</p><p>• IPS (Schnabel et al. 2016): IPS addresses popularity bias in models by tackling the imbalance in the long-tail distribution within observational data. Specifically, it assigns the inverse of an item's popularity as its weight, elevating the significance of less popular items and reducing the weight of more popular ones. We evaluate the Top-K recommendation performance on implicit feedback, a commonly used setting in recommender systems. Top-K refers to the K items that the recommender system deems most relevant or attractive to the user, where K represents the number of items in the recommendation list. We utilize three frequently used evaluation metrics: Recall, Hit Rate (HR), and NDCG. In the experiments, the reported results represent the optimal performance achieved by each method under its parameter settings. Additionally, we counted the degree of improvement of Recall for each method compared to the backbone, denoted by "Imp.".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison of Experimental Results</head><p>We report the results of DCLMDB and all baseline approaches in Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table">3</ref> on the two real-world datasets.</p><p>From Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table">3</ref>, CausE does not demonstrate any performance improvement, likely, because it only coarsely aligns the biased embeddings with the unbiased ones and fails to eliminate the impact of confounders. DCCL, which applies contrastive learning to DICE, yields even poorer results. This is due to the fact that DCCL's starting point is to address the problem of data sparsity, so it directly employs the original training data. Although both DCCL and DCLMDB apply contrastive learning, DCLMDB performs debiasing on user-item pairs rather than using data augmentation on the user or item itself. In contrast, our DCLMDB framework outperforms all the baselines, demonstrating significant improvements across all metrics on both datasets. For example, when using MF as the backbone on the Movielens-10M dataset, DCLMDB shows an increase of over 35% in the Recall@20 metric and more than 26% improvement in Recall@50. Similarly, DCLMDB achieves notable enhancements across all three metrics on the Netflix dataset. It is worth noting that the comparison of DCLMDB with the second-best method, DICE, on the two datasets yields p-values of 0.004 and 0.007, respectively, indicating a statistically significant improvement.</p><p>DCLMDB is a versatile framework that can be seamlessly integrated into various recommendation models, regardless of the backbone. It consistently delivers optimal results across different datasets and excels in three metrics. According to the results presented in Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table">3</ref>, methods that do not involve the embedding layer, such as IPS, show inconsistent performance. While IPS improves upon the MF model in the Movielens-10M, it negatively impacts the performance of the MF model on the Netflix. This inconsistency is also observed in other non-embedding layer baselines, likely due to their overdependence on dataset distribution. In contrast, DCLMDB, which applies debiasing and disentangling at the embedding layer and leverages causal graph analysis, consistently enhances recommendation performance across various datasets and backbone models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Experiments</head><p>In the ablation experiments, we introduced two variants of DCLMDB: DCLMDB-user and DCLMDB-item. These variants only eliminate conformity bias and popularity bias during training, respectively. We performed ablation experiments on DCLMDB to determine the validity of the debiasing effect of each component. We evaluated all methods, including DCLMDB, its variant versions, as well as the baseline methods, using the Intersection Over Union (IOU) <ref type="bibr" target="#b22">(Zheng et al. 2021)</ref>, an evaluation metric that measures the degree of overlap between their recommended items and popular items. The results on the Movielens-10M dataset, as shown in Fig. <ref type="figure" target="#fig_3">4</ref>  <ref type="table">3</ref>: The performance of all methods on Netflix. DCLMDB's improvement on Netflix is highly significant, with a p-value of 0.0007 in pairwise comparison to the 12 results of the second-best method. user and DCLMDB-item exhibit lower overlap ratios between its recommended items and popular items compared to other baselines. This outcome highlights their effectiveness in removing both popularity bias and conformity bias, thereby affirming the efficacy of our approach. Further analysis of the curves in Fig. <ref type="figure" target="#fig_3">4</ref> reveals that the curve for our method remains relatively flat, whereas the curves for other baselines show a marked upward trend. This observation suggests a significant diminution in the debiasing effect of the baseline algorithms as the Top-K value increases. In contrast, our method maintains a consistent debiasing effect across various Top-K values, demonstrating its robustness.</p><p>In conclusion, DCLMDB not only excels in eradicating popularity bias and conformity bias but also maintains stable debiasing effects under varying Top-K conditions. Fig. <ref type="figure" target="#fig_4">5</ref> illustrates the IOU ratios of DCLMDB and its variant methods, showing more clearly the debiasing effect between them. In Fig. <ref type="figure" target="#fig_4">5</ref>, it is remarkable to notice that DCLMDB-user and DCLMDB-item show different degrees of weakening of their debiasing effects when the number of recommended items increases. However, the debiasing effect of the DCLMDB method remains stable without significant fluctuations. It shows that the DCLMDB method is robust. This further demonstrates that the strategy of simultaneous debiasing on both the user side and the item side is effective and can make the debiasing effect more stable. Ablation experiments for the Netflix dataset are provided in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we first presented an analysis of the impact of popularity and conformity on recommender systems from a causal perspective using the proposed causal graph. Guided by causal-based analysis and diverging from existing studies on eliminating popularity bias and conformity bias, we formulated the click prediction model using docalculus. To address both popularity bias and conformity bias simultaneously, we proposed DCLMDB, a novel de-biased contrastive learning method for recommender systems. DCLMDB utilises initial item and user embeddings as negative samples to derive two sets of embeddings specifically designed to eliminate popularity and conformity biases, and it accomplishes this by implementing targeted interventions in the model's training process, using contrastive learning. The experimental results conducted on two realworld datasets indicate that our proposed DCLMDB is more effective and consistent in eliminating popularity bias in both items and users compared to other benchmark models. This leads to superior recommendation performance, as evidenced by our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preliminaries</head><p>In this section, we will introduce the fundamental concepts of causal inference related to our main manuscript. Causal graphs use Directed Acyclic Graphs (DAGs) to present causal relationships between variables, where nodes represent variables and edges represent relationships between them. Specifically, there are three Do-calculus is a derivation system consisting of three derivation rules. Before introducing the rules, we illustrate two special subgraphs. In a causal DAG G with three arbitrarily disjoint sets of nodes X, Y , and Z, we denote by G X the graph obtained by deleting from G all arrows pointing to nodes in X. Likewise, we denote by G X the graph obtained by deleting from G all arrows emerging from nodes in X. Theorem 1 (Rules of do-calculus (Pearl 2009)). Let G be DGA associated with a causal model, and let P (•) stand for the probability distribution induced by that model. For any disjoint subsets of variables X, Y, Z, and W, we have the following rules.</p><p>1. Insertion/deletion of observations:</p><formula xml:id="formula_7">P (y | do(x), z, w) = P (y | do(x), w) if (Y ⊥ ⊥ Z | X, W ) G X .<label>(8)</label></formula><p>2. Action/observation exchange:</p><formula xml:id="formula_8">P (y | do(x), do(z), w) = P (y | do(x), z, w) if (Y ⊥ ⊥ Z | X, W ) G XZ . (9)</formula><p>3. Insertion/deletion of actions:</p><formula xml:id="formula_9">P (y | do(x), do(z), w) = P (y | do(x), w) if (Y ⊥ ⊥ Z | X, W ) G X,Z(W ) ,<label>(10)</label></formula><p>where Z(W) is the set of Z-nodes that are not ancestors of any W-node in G X .</p><p>For example, we perform do(A = a) on the causal DAG A ← B → C, which denotes the intervention of setting the variable A to be a and cutting off the path B → A on the causal DAG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Experimental Settings</head><p>Parameter Settings: To ensure fair comparisons, we standardised the parameter counts across all methods. For models utilising DICE <ref type="bibr" target="#b22">(Zheng et al. 2021)</ref> and DCCL <ref type="bibr">(Zhao et al. 2023a)</ref>, we set the embedding size to 64, since they comprise two concatenated sets of embeddings. For the other models, we maintained a consistent embedding size of 128. In the DCLMDB method, the hyperparameters α and β were set to 0.05 and 0.005, respectively, for the MF-based model, and to 0.5 and 0.005 for the GCN-based model. We employed the Adam optimiser for updating model weights, with an initial learning rate of 0.001 and a batch size of 128. All models use BPR <ref type="bibr" target="#b13">(Rendle et al. 2012</ref>) loss as the objective function for click prediction. All models were executed on an NVIDIA A100 (40GB RAM) GPU. To assess model performance and validate the effectiveness of our approach, we utilised three widely recognised metrics in the recommendation systems field: Recall, Hit Ratio (HR), and NDCG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correlation Analysis between Popularity and Conformity Biases</head><p>In this section, we conduct experiments to analyze and demonstrate the correlation between popularity and conformity biases, thereby validating the rationality of the causal graph proposed in our experiments. Let D represent the historical observational data between items and users, R denote the count of five-star ratings for each item, and I represent the set of all items. We divided the Movielens-10M dataset into T stages in timestamp order. For each stage t, we computed the local positive rating rate and local popularity, defined as follows:</p><formula xml:id="formula_10">r t i = R t i / j∈I R t j ,<label>(11)</label></formula><formula xml:id="formula_11">m t i = D t i / j∈I D t j ,<label>(12)</label></formula><p>where R t i denotes the count of five-star ratings received by item i at stage t, while D t i represents the total number of interactions with item i at the same stage. The terms r t i and m t i correspond to the conformity and popularity of item i at stage t, respectively. To illustrate these concepts, we randomly selected ten items with relatively high interaction counts and compared the trends of their local positive rating rates and local popularity, as shown in Fig. <ref type="figure" target="#fig_6">6</ref> (a) and (b). The trends in the local positive rating rates and popularity among these items displayed a notable similarity.  To scientifically demonstrate their correlation, we calculated the Pearson correlation coefficient for these ten items, as shown in Fig. <ref type="figure" target="#fig_8">7</ref>. This coefficient measures the strength of the relationship between two variables and ranges from -1 to 1, where values closer to 1 indicate a stronger positive correlation. The Pearson correlation coefficients, as displayed in Fig. <ref type="figure" target="#fig_8">7</ref> for the trends of local positive rating rates and local popularity among these ten items, all exceed 0.98. These results suggest an exceptionally strong correlation between popularity bias and conformity bias. They imply that these biases often coexist and should be addressed simultaneously rather than focusing on only one aspect of the bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance under Intervened Training Data</head><p>In this section, we assess the performance of DCLMDB across various proportions of intervention data. In the prior experiment, due to CausE's stringent requirements, we were compelled to merge biased data (60%) with intervention data (10%) to form a training set. As the training data includes intervention data, DCLMDB's effectiveness might be enhanced by it. Additionally, in actual recommendation systems, acquiring intervention data often involves randomly We will perform ablation experiments on the Netflix dataset. As with the experimental results on the Movielens-10M dataset, the overlap between recommended and popular entries is lower for DCLMDB-user and DCLMDB-item compared to other baselines. This result illustrates their effectiveness in eliminating prevalence bias and conformity bias, further validating the effectiveness of our method. Meanwhile, as can be seen in Fig <ref type="figure">9</ref>, the IOU curves of DCLMDB and its variant methods are relatively flat, which illustrates the robustness of the debiasing ability of our method. Fig. <ref type="figure" target="#fig_10">10</ref> shows the IOU ratios of DICE, DCLMDB, and its variants to more clearly demonstrate the debiasing effect between them. In Fig. <ref type="figure" target="#fig_10">10</ref>, DCLMDB-user, DCLMDBitem, and DICE all show different decreases in their debiasing power compared to DCLMDB as the number of recommended items increases. However, the debiasing effect of the DCLMDB method remains stable without significant fluctuations. This phenomenon is consistent with the results of our ablation experiments on the Movielens-10M dataset, which further verifies the strong robustness of the DCLMDB method. It also demonstrates again that the strategy of simultaneous debiasing on the user side and the item side is effective, which can make the debiasing effect more stable.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Two causal graphs are used to show the recommendation process. U : user preference, I: exposed item, C: choice, Z: item popularity. (a) Traditional recommender methods; (b) Popularity bias caused by item popularity Z.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Causal graphs showing both popularity bias and conformity bias and an illustration of our solution. U : user preference, I: exposed item, C: choice, Z: item popularity, W : conformity influence. (a) The causal graph considers the effects of popularity items and conformity influence; (b) we cut off the edges Z → I and W → U in the training model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Overall structure of the proposed DCLMDB. First, we use the backbone to represent the input data as base embeddings (U and I) and debiased embeddings (Z and W ). Both sets of embeddings encompass those of users and items. Subsequently, in the debiasing learning phase (i.e., the dotted box portion of the figure), we employ contrastive learning to steer the debiased embeddings away from biases inherent in the base embeddings. The specific realisations of L u , L i and L BP R are in Eq. (4), Eq. (5) and Eq. (6) respectively. Finally, L u , L i and L BP R are summed as in Eq. (7) to obtain the final loss function L DCLM DB .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: Overlapped items with popular items. A higher IOU indicates that the recommendation result is more similar to the recommended top popular items.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The IOU ratios of DCLMDB and its variants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>classical DAGs to describe causal relationships between variables: chain A → B → C, fork A ← B → C, and collider A → B ← C. In the causal DAG A → B → C, A influencing C through intermediary B. In the causal DAG A ← B → C, B is referred to as the confounder or common cause of A and C, i.e., B influences both A and C, resulting in an correlation A and C. Note that there is not imply a direct causal relationship between A and C. A → B ← C is a collider structure, where A and C are independent of each other but jointly influence the collision node B. A and C exhibit correlation when conditioned on B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Correlation analysis between popularity bias and conformity bias. (a) Local praise rate change curve at each stage; (b) Local popularity change curve at each stage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The Pearson correlation coefficient between the local praise rate and popularity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Figure 8: Performance comparison between different algorithms under different proportions of intervened training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: The IOU ratios of DICE, DCLMDB and its variants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Details of two real-world datasets and the Netflix dataset</figDesc><table><row><cell>Konstan 2015)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>The performance of all methods on Movielens-10M. The "Original" indicates that only the backbone is used, with no additional causal debiasing methods. The best results are highlighted in bold, and the second-best result is underlined. The DCLMDB's enhancement on the Movielens-10M is highly significant, exhibiting a p-value of 0.004 when pairwise compared to the 12 results of the second-best method.</figDesc><table><row><cell>• IPS-C (Bottou et al. 2013): This method imposes a cap</cell></row><row><cell>on the maximum value of IPS weights to reduce the vari-</cell></row><row><cell>ance in the overall weight distribution.</cell></row><row><cell>• IPS-CN (Gruson et al. 2019): IPS-CN applies normali-</cell></row><row><cell>sation to reduce variance in weight distribution.</cell></row><row><cell>• CauseE (Bonner and Vasile 2018): CauseE constructs</cell></row><row><cell>a small unbiased dataset, and employs matrix factorisa-</cell></row><row><cell>tion on both datasets to derive two sets of embeddings,</cell></row><row><cell>then applies L 1 or L 2 regularisation to align these em-</cell></row><row><cell>beddings, enforcing their similarity.</cell></row><row><cell>• DICE (Zheng et al. 2021): DICE utilises Structural</cell></row><row><cell>Causal Modeling (SCM) (Pearl 2009) to model user-item</cell></row><row><cell>interactions as an interplay between "interest" and "con-</cell></row><row><cell>formity". It constructs specific training samples based on</cell></row><row><cell>collision effects, thereby disentangling the embedding of</cell></row><row><cell>each user and item into separate "interest" and "confor-</cell></row><row><cell>mity" components to eliminate conformity bias.</cell></row><row><cell>• DCCL (Zhao et al. 2023a): This study critiques DICE's</cell></row><row><cell>use of specific data to disentangle "interest" and "confor-</cell></row><row><cell>mity", suggesting it may introduce noise. DCCL adopts</cell></row><row><cell>contrastive learning to address data sparsity and disen-</cell></row><row><cell>tangle "interest" and "conformity".</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>, indicate that both DCLMDB-</figDesc><table><row><cell cols="2">Dataset</cell><cell></cell><cell cols="2">Top-K=20</cell><cell cols="2">Netflix</cell><cell cols="2">Top-K=50</cell><cell></cell></row><row><cell>Backbone</cell><cell>Method</cell><cell>Recall↑</cell><cell>HR↑</cell><cell>NDCG↑</cell><cell>Imp.↑</cell><cell>Recall↑</cell><cell>HR↑</cell><cell>NDCG↑</cell><cell>Imp.↑</cell></row><row><cell></cell><cell>Original</cell><cell cols="3">0.1154 0.5262 0.0959</cell><cell>-</cell><cell cols="3">0.1947 0.6804 0.1200</cell><cell>-</cell></row><row><cell></cell><cell>IPS</cell><cell cols="3">0.1043 0.4816 0.0831</cell><cell>-9.61%</cell><cell cols="3">0.1843 0.6541 0.1081</cell><cell>-5.34%</cell></row><row><cell></cell><cell>IPS-C</cell><cell cols="3">0.1109 0.5012 0.0885</cell><cell>-3.89%</cell><cell cols="3">0.1901 0.6649 0.1133</cell><cell>-2.36%</cell></row><row><cell>MF</cell><cell>IPS-CN CausE</cell><cell cols="3">0.1179 0.5298 0.1032 0.0996 0.4832 0.0838</cell><cell>+2.17% -13.69%</cell><cell cols="3">0.2040 0.6817 0.1290 0.1751 0.6460 0.1057</cell><cell>+4.78% -10.07%</cell></row><row><cell></cell><cell>DICE</cell><cell cols="3">0.1265 0.5535 0.1069</cell><cell>+9.62%</cell><cell cols="4">0.2166 0.7065 0.1341 +11.24%</cell></row><row><cell></cell><cell>DCCL</cell><cell cols="3">0.1231 0.5433 0.1023</cell><cell>+6.67%</cell><cell cols="3">0.2091 0.6955 0.1283</cell><cell>+7.40%</cell></row><row><cell></cell><cell cols="9">DCLMDB 0.1313 0.1313 0.1313 0.5731 0.5731 0.5731 0.1126 0.1126 0.1126 +13.78% +13.78% +13.78% 0.2204 0.2204 0.2204 0.7152 0.7152 0.7152 0.1391 0.1391 0.1391 +13.20% +13.20% +13.20%</cell></row><row><cell></cell><cell>Original</cell><cell cols="3">0.1149 0.5272 0.0962</cell><cell>-</cell><cell cols="3">0.2009 0.6718 0.1219</cell><cell>-</cell></row><row><cell></cell><cell>IPS</cell><cell cols="3">0.1139 0.5211 0.0970</cell><cell>-0.87%</cell><cell cols="3">0.1953 0.6718 0.1219</cell><cell>-2.79%</cell></row><row><cell></cell><cell>IPS-C</cell><cell cols="3">0.1164 0.5256 0.0997</cell><cell>+1.31%</cell><cell cols="3">0.1985 0.6777 0.1249</cell><cell>-1.19%</cell></row><row><cell>LightGCN</cell><cell>IPS-CN CausE</cell><cell cols="3">0.0776 0.4160 0.0691 0.0919 0.4594 0.0751</cell><cell>-32.46% -20.02%</cell><cell cols="3">0.1549 0.6009 0.0922 0.1690 0.6336 0.0987</cell><cell>-22.90% -15.88%</cell></row><row><cell></cell><cell>DICE</cell><cell cols="8">0.1410 0.5848 0.1212 +22.72% 0.2343 0.7290 0.1490 +16.63%</cell></row><row><cell></cell><cell>DCCL</cell><cell cols="3">0.1200 0.5389 0.1012</cell><cell>+4.44%</cell><cell cols="3">0.2027 0.6902 0.1261</cell><cell>+0.90%</cell></row><row><cell></cell><cell cols="9">DCLMDB 0.1442 0.1442 0.1442 0.5948 0.5948 0.5948 0.1250 0.1250 0.1250 +25.50% +25.50% +25.50% 0.2383 0.2383 0.2383 0.7325 0.7325 0.7325 0.1526 0.1526 0.1526 +18.62% +18.62% +18.62%</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Causal embeddings for recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lanning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bonner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vasile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM Conference on Recommender Systems</title>
		<meeting>the 12th ACM Conference on Recommender Systems<address><addrLine>New York; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2007">2007. 2007. 2018</date>
			<biblScope unit="page" from="104" to="112" />
		</imprint>
	</monogr>
	<note>Proceedings of the KDD Cup Workshop</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Quiñonero-Candela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">X</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Portugaly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Snelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="3207" to="3260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bias and debias in recommender system: A survey and future directions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Datadriven causal effect estimation based on graphical causal modelling: A survey</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep Neural Networks for YouTube Recommendations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Conference on Recommender Systems, 191-198</title>
		<meeting>the 10th ACM Conference on Recommender Systems, 191-198<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The netflix recommender system: Algorithms, business value, and innovation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Gomez-Uribe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Management Information Systems (TMIS)</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Offline Evaluation to Make Decisions About PlaylistRecommendation Algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gruson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Charbuillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcinerney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tardieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Twelfth ACM International Conference on Web Search and Data Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="420" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<title level="m">The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2020. 2017</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
	<note>Proceedings of the 26th International Conference on World Wide Web. Republic and Canton of Geneva, CHE: International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dual Channel Hypergraph Collaborative Filtering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2020" to="2029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Variational Autoencoders for Collaborative Filtering</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jebara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International World Wide Web Conferences Steering Committee</title>
		<meeting><address><addrLine>Geneva, CHE</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="689" to="698" />
		</imprint>
	</monogr>
	<note>Proceedings of the 2018 World Wide Web Conference</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SocialLGN: Light graph convolution network for social recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021, 1296-1305</title>
		<meeting>the Web Conference 2021, 1296-1305<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2021">2022. 2021</date>
			<biblScope unit="volume">589</biblScope>
			<biblScope unit="page" from="595" to="607" />
		</imprint>
	</monogr>
	<note>Interest-aware Message-Passing GCN for Recommendation. Pearl, J. 2009. Causality.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recommendations as Treatments: Debiasing Learning and Evaluation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1205.2618</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<meeting>The 33rd International Conference on Machine Learning<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2012">2012. 2016</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1670" to="1679" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Bayesian personalized ranking from implicit feedback</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Customer reviews analysis with deep neural networks for e-commerce recommender systems</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Shoja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tabrizi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="119121" to="119130" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural Graph Collaborative Filtering</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hypergraph Contrastive Collaborative Filtering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="70" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Explore User Neighborhood for Real-time E-commerce Recommendation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 37th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2464" to="2475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Causal Intervention for Leveraging Popularity Bias in Recommendation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Disentangled Causal Embedding With Contrastive Learning For Recommender System</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the ACM Web Conference 2023</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="406" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Popularity Bias is not Always Evil: Disentangling Benign and Harmful Bias for Recommendation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="9920" to="9931" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Disentangling User Interest and Conformity for Recommendation with Causal Embedding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2980" to="2991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Graph-based embedding smoothing for sequential recommendation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="496" to="508" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unbiased Implicit Recommendation and Propensity Estimation via Combinational Joint Learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Caverlee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM Conference on Recommender Systems</title>
		<meeting>the 14th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="551" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural Interactive Collaborative Filtering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="749" to="758" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
