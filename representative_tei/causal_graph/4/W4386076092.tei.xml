<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Histopathology Whole Slide Image Analysis with Heterogeneous Graph Representation Learning</title>
				<funder ref="#_FCruAFa">
					<orgName type="full">National Natural Science Fund</orgName>
				</funder>
				<funder ref="#_bsENDyu">
					<orgName type="full">Research Grants Council of Hong Kong</orgName>
				</funder>
				<funder ref="#_ayqayQn">
					<orgName type="full">Theme-based Research Scheme</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-07-09">9 Jul 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tsai</forename><forename type="middle">Hor</forename><surname>Chan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics and Actuarial Science</orgName>
								<orgName type="institution">The University of Hong</orgName>
								<address>
									<country>Kong</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fernando</forename><forename type="middle">Julio</forename><surname>Cendra</surname></persName>
							<email>fcendra@connect.hku.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics and Actuarial Science</orgName>
								<orgName type="institution">The University of Hong</orgName>
								<address>
									<country>Kong</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">TCL Corporate Research Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lan</forename><surname>Ma</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">TCL Corporate Research Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guosheng</forename><surname>Yin</surname></persName>
							<email>guosheng.yin@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics and Actuarial Science</orgName>
								<orgName type="institution">The University of Hong</orgName>
								<address>
									<country>Kong</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="laboratory">at https://github.com/HKU-MedAI/WSI-HGNN</orgName>
								<orgName type="institution">Imperial College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lequan</forename><surname>Yu</surname></persName>
							<email>lqyu@hku.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics and Actuarial Science</orgName>
								<orgName type="institution">The University of Hong</orgName>
								<address>
									<country>Kong</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Histopathology Whole Slide Image Analysis with Heterogeneous Graph Representation Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-07-09">9 Jul 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2307.04189v1[cs.CV]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph-based methods have been extensively applied to whole slide histopathology image (WSI) analysis due to the advantage of modeling the spatial relationships among different entities. However, most of the existing methods focus on modeling WSIs with homogeneous graphs (e.g., with homogeneous node type). Despite their successes, these works are incapable of mining the complex structural relations between biological entities (e.g., the diverse interaction among different cell types) in the WSI. We propose a novel heterogeneous graph-based framework to leverage the inter-relationships among different types of nuclei for WSI analysis. Specifically, we formulate the WSI as a heterogeneous graph with "nucleus-type" attribute to each node and a semantic similarity attribute to each edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>We then present a new heterogeneous-graph edge attribute transformer (HEAT) to take advantage of the edge and node heterogeneity during massage aggregating. Further, we design a new pseudo-label-based semantic-consistent pooling mechanism to obtain graph-level features, which can mitigate the over-parameterization issue of conventional cluster-based pooling. Additionally, observing the limitations of existing association-based localization methods, we propose a causal-driven approach attributing the contribution of each node to improve the interpretability of our framework. Extensive experiments on three public TCGA benchmark datasets demonstrate that our framework outperforms the state-of-the-art methods with considerable margins on various tasks. Our codes are available</head></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Histopathology slides provide rich information on diagnosis and treatment planning for many cancer diseases. The * The first two authors contributed equally to this work. recent technological advancements in tissue digital scanners facilitate the development of whole slide histopathology image (WSI) analysis. However, traversing through the WSI with diverse magnifications is time-consuming and tedious for pathologists due to the large-scale nature of the WSI (e.g., its typical size is 60,000 × 60,000 pixels). Hence deep learning techniques play an important role as they introduce accurate and automated analysis of WSIs, which can significantly relieve the workload of pathologists.</p><p>Since it is difficult to fit the complete WSI into the memory, most of the works adopt multiple instance learning (MIL) to divide the WSI into instances and then aggregate them for WSI analysis. However, these methods operate on bags of instances that do not emphasize the interrelationships between these instances. Recently, the emergence of graph neural networks (GNNs) has made large progress in representing the spatial relationships between instances. As a result, there are many attempts to represent the WSIs as graphs of instances. Figure <ref type="figure" target="#fig_0">1</ref> presents an example of a graph constructed from WSI. Unlike convolutional neural networks (CNNs) that aggregate features based on locality in the Euclidean space, GNNs focus on locality on graph topology, which offers more flexibility in analyzing the deep connections between features in the image data beyond the spatial locality <ref type="bibr" target="#b0">[1]</ref>. For example, GNNs are able to learn relational information and distinguish cells based on their apposition to tumor cells, or normal stroma (i.e., cells which are tumor-infiltrating lymphocytes or from an adjacency inflammatory response), which are important for prognosis <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>However, existing paradigms on graph-based WSI analysis focus on representing the WSI with a homogeneous graph structure and then predicting the response via vanilla GNNs with cluster-based pooling (i.e., based on similarities of node embeddings). Despite their successes, these methods suffer from several drawbacks: (i) GNNs on homogeneous graphs focus on aggregating direct relational information from neighboring nodes, where the complex relational information of the graphs is often neglected. (ii) For different graphs, the clusters defined by similarities between node embeddings have inconsistent meanings. This introduces a large degree of freedom in parameters and leads to over-parameterization issue <ref type="bibr" target="#b1">[2]</ref>. Therefore, GNNs tend to easily overfit due to a lack of identifiability <ref type="bibr" target="#b13">[14]</ref>.</p><p>In view of these limitations, we propose a novel framework for WSI analysis, which leverages a heterogeneous graph to learn the inter-relationships among different types of nodes and edges. The heterogeneous graph introduces a "nucleus-type" attribute to each node, which can serve as an effective data structure for modeling the structural interactions among the nuclei in the WSI. To tackle the aggregation process in the heterogeneous graph, we propose a novel heterogeneous-graph edge attribute transformer (HEAT) architecture which can take advantage of the edge and node heterogeneity. Thus, the diverse structural relations among different biological entities in the WSI can be incorporated to guide the GNN for more accurate prediction. Further, to obtain the graph-level representations for slide-level prediction, we propose a semantic-consistent pooling mechanism -pseudo-label (PL) pooling, which pools node features to graph level based on clusters with a fixed definition (i.e., nucleus type). The proposed PL pooling can regularize the graph pooling process by distilling the context knowledge (i.e., pathological knowledge) from a pretrained model to alleviate the over-parameterization issue <ref type="bibr" target="#b1">[2]</ref>. Additionally, we propose a Granger causality <ref type="bibr" target="#b12">[13]</ref> based localization method to identify the potential regions of interest with clinical relevance to provide more insights to pathologists and promote the clinical usability of our approach.</p><p>We extensively evaluate our method on three TCGA public benchmark datasets, including colon adenocarcinoma cancer (COAD) and breast invasive carcinoma (BRCA) datasets from the TCGA project <ref type="bibr" target="#b34">[35]</ref> and the Camelyon 16 dataset <ref type="bibr" target="#b2">[3]</ref>, and compare to various latest state-of-the-art (SOTA) methods. Our method outperforms the competitors on cancer staging, cancer classification, cancer typing, and localization tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Multiple Instance Learning on WSIs. Existing WSI analysis approaches generally adopt MIL <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b40">41]</ref>, which first divide the WSI into fixed-size patches and then compress the information of these patches into lowdimensional vectors. Conventional methods aggregate bags of instances to learn WSI-level features for final predictions. Tellez et al. <ref type="bibr" target="#b29">[30]</ref> compress the WSI-level image into embedding vectors and use a standard CNN to perform patchlevel and WSI-level cancer classification. These CNNbased methods analyze local areas in the Euclidean space on fixed connectivity (i.e., fixed-size kernels), limiting the performance beyond the spatial locality. Graph-based methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b40">41]</ref> have recently been proposed, which model the interactions between instances via graphs. Their capability of modeling instances based on graph topology provides more flexibility to analyze complex structures of WSIs. Chen et al. <ref type="bibr" target="#b4">[5]</ref> propose patch-GCN, a method of modeling WSI with homogeneous graphs, and regress survival data with a graph convolutional neural network (GCN) <ref type="bibr" target="#b35">[36]</ref>. Zheng et al. <ref type="bibr" target="#b40">[41]</ref> propose a graph-based MIL method using graph transformer networks <ref type="bibr" target="#b39">[40]</ref>. In spite of their power, most of these WSI methods use homogeneous graphs, which limits the information mined from WSIs. A recent method <ref type="bibr" target="#b14">[15]</ref> is proposed to model WSIs with heterogeneous graphs, where the heterogeneity in each patch is introduced by different resolution levels. However, it only considers the resolution level heterogeneity of patches, with insufficient ability to model the complex contextual interaction between patches in the same resolution level.</p><p>Graph Neural Networks. Although the SOTA GNNs have shown great successes in many problem domains <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref>, they are mostly focused on homogeneous graphs <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b41">42]</ref>. These architectures extract the locality information on the graph topology and learn the graph representations by performing aggregation on neighboring nodes. However, the potential heterogeneity in nodes and edges is not incorporated by these homogeneous GNN algorithms, and therefore their capability in mining the structural information is limited. Several works attempt to address the heterogeneity in their architectural designs <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34]</ref> and assume that the relation type is finite and discrete. However, when modeling images with graphs, the heterogeneity in relations is typically continuous (e.g., the similarity between nodes) or high-dimensional. Although there are several attempts <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref> to extend SOTA GNNs <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b35">36]</ref> to incorporate edge attributes, their works are limited to homogeneous graphs.</p><p>Graph Pooling. Graph pooling aims to aggregate nodelevel features to obtain graph-level features. Conventional methods <ref type="bibr" target="#b35">[36]</ref> directly take the average of node-level features to extract graph-level features, which tends to oversmooth the signals of the nodes and cannot generate representative graph-level features. Recently, there is extensive development of graph pooling algorithms based on the clusters of the embeddings <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b24">25]</ref>. However, the clusters constructed based on similarity are inconsistent across graphs. This leads to a large degree of freedom in parameters which easily causes overfitting. A semantic-consistent pooling method is therefore needed.</p><p>Explaining GNNs. Despite the success of graph neural networks, their poor interpretability of the parameters makes them notoriously recognized as "blackboxes". With the advances in network attribution methods <ref type="bibr" target="#b28">[29]</ref>, extensive attempts have been made to open such "blackboxes" <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b38">39]</ref>. Generating network explanation is an important qualitative step in the WSI analysis since it can highlight the abnormal regions for further investigation. Conventional explainers try to find the associations between the parameters in deep neural networks (or the nodes in GNNs) and the predictions. GNNExplainer <ref type="bibr" target="#b38">[39]</ref> is the SOTA method explaining the contributions of node features to the GNN predictions. It trains feature masks on each node and edge feature to minimize the prediction loss of a trained GNN. PGExplainer <ref type="bibr" target="#b23">[24]</ref> shares the same objective as GNNExplainer and trains a generative model to generate explana-tions. Recently, there has been emerging attention in generating causal explanations for GNNs <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b28">29]</ref>, and most of the methods focus on the Granger causality as the explanation objective. Gem <ref type="bibr" target="#b22">[23]</ref> trains explanation generators from the causal perspective. Causal explainers attempt to provide explanations of features that are causal rather than associated with the neural network prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries</head><p>Heterogeneous Graph: A heterogeneous graph is defined by a graph G = (V, E, A, R), where V, E, A represent the set of entities (vertices or nodes), relations (edges), and entity types, respectively. And R represents the space of edge attributes. For v ∈ V, v is mapped to an entity type by a function τ (v) ∈ A. An edge e = (s, r, t) ∈ E links the source node s and the target node t, and r is mapped to an edge attribute by a function φ(e) = r ∈ R. Every node v has a d-dimensional node feature x ∈ X , where X is the embedding space of node features. Granger Causality <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b22">23]</ref>: Let I be all the available information and I -X be the information excluding variable X. If we can make a better prediction of Y using I than using I -X , we conclude that X Granger-causes Y . WSI Classification: Given a WSI X and a heterogeneous graph G constructed from X, we wish to predict the label y with a GNN model M. We also aim to assign an importance score f (v) to each node v ∈ V in G as the causal </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology 4.1. Heterogeneous Graph Construction</head><p>We introduce our methodology of modeling the WSI with a heterogeneous graph. Figure <ref type="figure" target="#fig_1">2</ref> presents the overall workflow of our proposed framework. We adopt the commonly used OTSU thresholding algorithm <ref type="bibr" target="#b4">[5]</ref> and sliding window strategy to crop each WSI into non-overlapping patches. Uninformative patches with backgrounds are removed. These patches define the nodes of the graph constructed. To define the corresponding node type, we use HoverNet <ref type="bibr" target="#b11">[12]</ref> pretrained on the PanNuke dataset <ref type="bibr" target="#b7">[8]</ref> to classify the patches into predefined types. HoverNet detects nuclei in each patch and assigns types to these nuclei. By majority votes, we take the most frequently predicted nucleus type to be the type of the patch. Figure <ref type="figure" target="#fig_0">1</ref> presents an example of a WSI with patches selected from the OTSU and node types generated by HoverNet <ref type="bibr" target="#b11">[12]</ref>. We use a pretrained feature encoder (i.e., KimiaNet <ref type="bibr" target="#b25">[26]</ref>) to obtain the embeddings of each patch, which serves as the features of each node in the heterogeneous graph.</p><p>Based on the nodes and node features, we define the edges and edge attributes between the patches. For each node v ∈ V, we use the k-nearest neighbor algorithm to find k nodes that have the most similar features to that node, and connect edges between node v and these neighboring nodes. For each edge, we compute the Pearson R correlation between the head and tail node features as the edge attributes. The edge attributes introduce heterogeneity in edges and highlight meta-relations in the WSI. We adopt data augmentations (e.g., randomly removing some edges) during training to alleviate the potential noises introduced by the edge attributes. As a result, we obtain a heterogeneous graph G with heterogeneity introduced by different node types and edge attributes. As shown in Figure <ref type="figure" target="#fig_2">3</ref>, a heterogeneous graph outlines the meta-relations between the nuclei in a WSI. Mining these meta-relations can reveal the structural interactions between the cells, leading to im-proved performances on different tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Heterogeneous Edge Attribute Transformer</head><p>The conventional graph attention mechanism is incapable of tackling the heterogeneity of the graph. Inspired by the transformer architecture <ref type="bibr" target="#b30">[31]</ref> and its extension on graphs <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b39">40]</ref>, we propose a new graph aggregation layer, named the Heterogeneous Edge Attribute Transformer (HEAT) layer, to aggregate the structural relations between biological entities in the built heterogeneous graph. We explicitly incorporate the node types and continuous edge features into the aggregation process, which guides the learning of edge similarities. Our proposed architecture also generalizes the existing architecture to incorporate continuous or high-dimensional edge attributes and simplifies the use of linear layers to avoid overfitting led by model over-parameterizations.</p><p>For each edge e = (s, r, t) and each attention head i, we project the target node t into a query vector with a linear projection layer W i τ (s) , and the source node into a key vector with W i τ (t) . We also compute the value vector h i value of each source node by the same projection layer W i τ (s)</p><formula xml:id="formula_0">h i key = W i τ (s) H (l-1) s , h i query = W i τ (t) H (l-1) t , h i value = W i τ (s) H (l-1) s ,</formula><p>where</p><formula xml:id="formula_1">H (l-1) v</formula><p>is the input node feature for node v ∈ V from the (l-1)-th layer. These projection layers can project node features of various node types into a node-type-invariant embedding space. The edge attributes from the (l -1)-th layer h (l-1) e are also projected to h ′ e = W edge h (l-1) e by a linear projection layer W edge . After projecting the node embeddings, we compute the dot-product similarity between the query and key vectors and further multiply the linear transformed edge attribute to the similarity score to incorporate the edge attributes in G. We then concatenate the scores from each head and take the softmax of the score (i.e., overweights of incoming edges for all neighboring nodes) to obtain the final attention scores to the value vector h i value ,</p><p>Attention(e) = softmax</p><formula xml:id="formula_2">∀s∈N (t) i∈[1,h]</formula><p>ATT(e, i) ,</p><formula xml:id="formula_3">ATT(e, i) = h i key h ′ e h i query / √ d,</formula><p>where N (t) is the set of all the source nodes pointing to target node t, d is the dimension of node embeddings, ATT(e, i) represents the i-head attention score of edge e, i∈ <ref type="bibr">[1,h]</ref> is the concatenation operator concatenating the attention scores from all heads and Attention(e) represents the final attention score of the edges aggregating all the heads. We multiply the attention score obtained by the value </p><formula xml:id="formula_4">h i key = W i τ (s) H (l-1) s</formula><p>⊲ Project the source node 4:</p><formula xml:id="formula_5">h i value = W i τ (s) H (l-1) s</formula><p>⊲ Compute value vector 5:</p><formula xml:id="formula_6">h i query = W i τ (t) H (l-1) t ⊲ Project the target node 6: h ′ e ← W edge • h (l-1) e</formula><p>⊲ Project the edge attribute 7:</p><p>ATT(e, i)</p><formula xml:id="formula_7">= h i key h ′ e h i query / √ d 8:</formula><p>Attention(e) = softmax ∀s∈N (t)</p><p>( i∈ <ref type="bibr">[1,h]</ref> ATT(e, i)) </p><formula xml:id="formula_8">H (l) t = ⊕ ∀s∈N (t) ( i∈[1,h] h i value •</formula><p>Attention(e)) 13: end for 14: return G l vector to obtain the output features. By doing so, the output features contain both the node-type and edge-attributespecific information. Hence the HEAT layer can capture the structural information in G by transforming the node features from different node types. It can also model different semantic relations since edge attributes are included in the aggregation.</p><p>Finally, we perform target-specific aggregation to update the feature of each target node by averaging its neighboring node features. We concatenate all h attention heads to obtain the attention vector for each pair of source and target nodes. For each target node t, we conduct a softmax operation on all the attention vectors from its neighboring nodes and then aggregate the information of all neighboring source nodes of t together. The updated node features H (l) t for G l can be represented as</p><formula xml:id="formula_9">H (l) t = ∀s∈N (t) i∈[1,h] h i value • Attention(e) ,</formula><p>where ⊕ is an aggregation operator (e.g., mean aggregation). The updated graph G l is returned as the output of the l-th HEAT layer. Algorithm 1 demonstrates the overall process of our proposed HEAT layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Pseudo-label Graph Pooling</head><p>We introduce a novel pooling method -pseudo-label (PL) pooling, to aggregate information with respect to the S a = h a ⊲ Assign pooled feature to the a-th row of S 7: end for 8: return S pseudo-labels (i.e., node types) predicted from a pretrained teacher network (e.g., HoverNet <ref type="bibr" target="#b11">[12]</ref>). Unlike conventional methods of pooling features based on clusters, we define clusters using a pretrained node classifier. Pooling from pseudo-labels ensures the semantic consistency in cluster definitions and distills the context knowledge (e.g., nuclei features) from the teacher network. Specifically, for each node type a, we pool all node features belonging to type a into a single vector h a with a readout layer. The pooled features from each node type are then aggregated into a feature matrix S ∈ R |A|×d . The graph level feature is then determined by another readout layer (e.g., mean readout).</p><p>Algorithm 2 presents the workflow of the proposed PL Pooling. By pooling with the pseudo-labels, we are able to cluster patch representation according to nuclei types, such that the graph-level features are enhanced with the prior knowledge on nuclei type distributions. The detailed mechanism of the PL Pool is presented in the supplementary materials. We also perform an ablation study in Table <ref type="table" target="#tab_5">4</ref> and show that PL Pooling outperforms existing pooling methods in cancer classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Prior Knowledge Regularization</head><p>Here we discuss the motivation for introducing prior knowledge in our proposed HEAT and PL pooling algorithms. In the context of WSI analysis when the data are scarce, while data distributions are sparse and highdimensional. The curse of high dimensionality makes the sampling distributions difficult to approximate the properties of true distributions of the WSIs. This leads to a significant gap between training and testing distributions. Hence regularization techniques are needed to reduce the model variance and mitigate performance deterioration when transferring the model from training to testing environments. Since WSI data contain enriched prior knowledge (e.g., the interaction among different cell types), integrating such knowledge into the framework regularizes the model, such that the testing performance improves. Therefore, we design the above two designs by integrating prior knowledge into the feature aggregation procedure. Specifically, for the HEAT layer, we integrate the prior knowledge of node type and node attributes when extracting node-level features. For PL Pooling, we pool node-level features using prior definitions on node clusters. Moreover, we perform data augmentations (e.g., random pruning on edges and nodes) to regularize the learning from training distributions. Besides that, other regularization such as imposing a Gaussian prior on the model weights (i.e., using a Bayesian neural network) would also achieve the goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Causal-driven Localization</head><p>We make use of the Granger causality to outline causal regions in the WSI with the causal graph explainer <ref type="bibr" target="#b22">[23]</ref>. Given a trained GNN model M, the causal contribution of each node v is given by</p><formula xml:id="formula_10">∆ δ,v = L(y, ỹG ) -L(y, ỹG\{v} ), (<label>1</label></formula><formula xml:id="formula_11">)</formula><p>where y is the true label and ỹG = M(G) and ỹG\{v} = M(G\{v}) are the predicted labels from M with input graphs G and G\{v}, respectively. The causality heatmap of the patches can then be visualized with the causal contribution computed for each patch (i.e., node). Addressing causality in instance interpretation can adjust for observational and selection biases, which would improve the explanation accuracy. Moreover, the causal property of the explainer could facilitate pathologists to find out potential biomarkers for diagnosis and prognosis by highlighting the patches with clinical relevance in the WSI.</p><p>Model AUC Accuracy Macro-F1 ABMIL <ref type="bibr" target="#b17">[18]</ref> 79.5 (7.5) 80.3 (8.4) 81.3 (7.4) DSMIL <ref type="bibr" target="#b20">[21]</ref> 92.5 (1.7) 87.3 (2.0) 86.3 (2.0) ReMix <ref type="bibr" target="#b37">[38]</ref> 92.5 (7.2) 90.0 (8.1) 90.3 (7.7) PatchGCN <ref type="bibr" target="#b4">[5]</ref> 88.6 (3.5) 92.1 (2.3) 92.3 (2.4) GTNMIL <ref type="bibr" target="#b39">[40]</ref> 89.7 (4.7) 81.2 (4.8) 89.2 (4.9) H 2 -MIL <ref type="bibr" target="#b14">[15]</ref> 92.1 (3.9) 88.2 (5.8) 88.0 (5.8) HEAT (ours) 92.8 (2.5) 92.7 (2.2) 93.3 (1.9) Table <ref type="table">2</ref>. Cancer typing results [%] of our method compared to various methods on the TCGA-ESCA dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Datasets</head><p>We use WSIs from the public TCGA-COAD (cancer staging task: 1304 cases, classification task: 1434 cases), TCGA-BRCA (cancer staging task: 1328 cases, classification task: 1712 cases), and TCGA-ESCA (typing task: 213 cases) from the TCGA project <ref type="bibr" target="#b34">[35]</ref> and Camelyon 16 <ref type="bibr" target="#b2">[3]</ref> as the benchmark datasets. On average, around 300 patches are sampled from each WSI in the TCGA datasets (around 5,000 for Camelyon 16), where each patch corresponds to a node in the final heterogeneous graph. For the TCGA-COAD and the TCGA-BRCA datasets, we conduct two tasks for the benchmark methods -cancer staging and cancer classification. For the cancer staging task, all the cases are divided into the "Stage I", "Stage II", "Stage III", and "Stage IV" classes. For the cancer classification task, all the cases are divided into the "Normal" and "Tumor" classes. For the cancer typing task, we use TCGA-ESCA dataset where all the cases are divided into two classes i.e., "Type I: adenocarcinoma" and "Type II: squamous cell carcinoma". We also evaluate the localization ability of our framework on the Camelyon 16 dataset, as this dataset provides the tumor mask annotations. A detailed summary of datasets is GNN Architecture AUC Accuracy Macro-F1 GCN <ref type="bibr" target="#b35">[36]</ref> 90.8 90.9 90.0 GAT <ref type="bibr" target="#b31">[32]</ref> 85.8 86.4 88.9 GIN <ref type="bibr" target="#b36">[37]</ref> 91.6 90.9 83.3 HetRGCN <ref type="bibr" target="#b27">[28]</ref> 82.5 83.3 88.9 HGT <ref type="bibr" target="#b15">[16]</ref> 87 provided in supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Implementation Details</head><p>The proposed framework is implemented in Python with the Pytorch library on a server equipped with four NVIDIA TESLA V100 GPUs. We use openslide <ref type="bibr" target="#b10">[11]</ref> as the tool to process the WSIs. The dropout ratio of each dropout layer is selected as 0.2. All models are trained with 150 epochs with early stopping. The batch size is selected as 2. We adopt the cross-entropy loss to train the network for classification tasks. We use the Adam optimizer to optimize the model with a learning rate of 5 × 10 -5 and a weight decay of 1 × 10 -5 . We perform data augmentations on the training graphs by randomly dropping the edges and nodes, and adding Gaussian noises to the node and edge features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experiment Settings and Evaluation Metrics</head><p>We compare our method with an array of SOTA methods, including MIL or graph-based methods. We use fivefold cross-validation to evaluate the overall performance of our framework and other methods. We used the pretrained KimiaNet as the feature extraction for all methods for a fair comparison. The details of compared methods are listed below.</p><p>• ABMIL <ref type="bibr" target="#b17">[18]</ref>: a MIL framework aggregating bag-level instance information by the attention mechanism. • DSMIL <ref type="bibr" target="#b20">[21]</ref>: a dual-stream multiple instance learning method using max pooling and attention to aggregate the signals from the individual patches. rich features. • PatchGCN <ref type="bibr" target="#b4">[5]</ref>: a hierarchical graph-based model on survival data with patient-level and WSI-level aggregations. We adapt this method as a GCN model with global attention pooling <ref type="bibr" target="#b21">[22]</ref>. • GTNMIL <ref type="bibr" target="#b40">[41]</ref>: a graph-based MIL method based on the graph transformer network <ref type="bibr" target="#b39">[40]</ref>. • H 2 -MIL <ref type="bibr" target="#b14">[15]</ref>: a tree-graph-based multiple instance learning method that utilizes different magnification levels to represent hierarchical features. For the cancer staging, classification and typing tasks, we use AUC, classification accuracy, and macro F-1 score as the evaluation metrics. Percentage [%] values are reported for each of the metrics. Standard errors are reported in brackets. For all metrics, a higher value indicates a better performance. Detailed definitions of the evaluation metrics can be found in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Comparison with Other Methods</head><p>Quantitative Results. Table <ref type="table" target="#tab_3">1</ref> shows the cancer staging and classification results on the TCGA-COAD and the TCGA-BRCA datasets, and Table <ref type="table">2</ref> presents cancer typing results on the TCGA-ESCA dataset. Compared to graph-based WSI analysis methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b40">41]</ref>, our method demonstrates improved performance, which indicates our graph modeling method potentially better represents the interaction of patches in a WSI than existing graph-based methods. We also observe that aggregation on a graph of instances is more effective than aggregation on bags of instances in the staging tasks, which implies graph-based methods are more capable of capturing the global information of WSI for staging tasks than conventional MIL methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b37">38]</ref>. We further compare HEAT on the BRCA subtyping task with a recent SOTA method on WSI -hierarchical image pyramid transformer (HIPT) <ref type="bibr" target="#b3">[4]</ref>. Our method achieves an AUC of 89.69 (SD: 3.63), which outperforms the AUC of 87.4 (SD: 6.0) by HIPT.</p><p>Additionally, we perform a t-test on the AUCs to demonstrate the statistical significance of our improvements over the SOTA methods, for which the results are presented in Table <ref type="table">6</ref>. We observe that the improvements are statistically significant over most of the baseline methods under the 0.05 significance level.</p><p>Qualitative Results. We compute the causal contribution of each patch using Equ. <ref type="bibr" target="#b0">(1)</ref>. We visualize the patch image associated with that node to outline the causal regions related to the predictions. We also compare our causal explanation method to numerous baseline graph interpretation methods based on associations <ref type="bibr" target="#b38">[39]</ref>. Figures in the supplementary materials present the explanation results with different graph explainers on the Camelyon 16 dataset. It is observed that using an association-based explainer provides a smooth heatmap where many regions are highlighted as important. A such heatmap is less accurate in localizing the tumor regions and pathologists still need to traverse a large number of abnormal regions suggested by the explainer to identify tumor regions. On the contrary, we observe that using a causal explainer can outline the tumor regions in the WSIs more accurately, with the heatmap more concentrated on the ground-truth tumor regions compared to associationbased explainers (e.g., GNNExplainer <ref type="bibr" target="#b38">[39]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Analysis of Our Framework</head><p>Effectiveness of Heterogeneous Graph Construction. We compare our method with other SOTA GNNs <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref> to evaluate the effectiveness of our heterogeneous graph construction. For heterogeneous graph transformer (HGT) <ref type="bibr" target="#b15">[16]</ref> and HetRGCN <ref type="bibr" target="#b27">[28]</ref>, we define the discrete edge types -each relation either has the "positive" type representing positive correlations between the nodes of the edge, or the "negative" type representing negative correlations. Table <ref type="table" target="#tab_4">3</ref> presents cancer typing results of our method compared to various SOTA GNN aggregation methods on the TCGA-ESCA dataset. Not only our method outperforms SOTA homogeneous GNN architectures <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref>, but it is also superior to some recently heterogeneous GNN architectures <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">28]</ref>. This implies the advantage of our proposed architecture for graph-based WSI analysis.</p><p>Analysis of Different Pooling Strategies. We compare our proposed pooling strategy to a variety of comparable pooling methods, including basic pooling methods, such as sum/max/mean poolings and advanced pooling strategies <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b24">25]</ref>. Table <ref type="table" target="#tab_5">4</ref> presents the comparison results of cancer classification on TCGA-COAD dataset. We fix the model architecture to be GCN <ref type="bibr" target="#b35">[36]</ref> and the feature encoder as KimiaNet <ref type="bibr" target="#b25">[26]</ref>. It is observed that our pooling strategy outperforms the competitors, which validates the advantage of using semantic-consistently defined clusters in pooling.</p><p>Performance on Different Class Distributions. We ob-serve the WSI datasets for cancer classification is imbalanced (i.e., approximately ten cancer WSIs to one normal WSI). We thus compose a balanced dataset (i.e., normal:cancer = 1:1) with the undersampling strategy to study how the difference in class distributions affect the performance of our model. Table <ref type="table" target="#tab_6">5</ref> presents the comparison. It is observed that our method achieves similar performance with the unbalanced setting (See Table <ref type="table" target="#tab_3">1</ref>).</p><p>Generalizability. The pretrained features are a key component of our proposed framework. As the pretrained embedding models are from a diverse WSI context, they can extract good features from most of the WSI datasets. Because the PanNuke dataset <ref type="bibr" target="#b8">[9]</ref> (used to pretrain the HoverNet node type classifier) contains WSIs of most of the common cancer types, this leads to a broad generalization of HoverNet. Furthermore, one may adopt contrastive learning to finetune the pretrained models to improve their generalizability to new datasets in potential deployment scenarios.</p><p>Accuracy of HoverNet. The performance of the Hover-Net classifier would influence the sensitivity of our framework. Since the PanNuke dataset contains WSIs of most of the common cancer types and cohorts of the TCGA dataset (e.g., COAD), there are domain overlaps between them. Hence the HoverNet trained on the PanNuke dataset can be transferred to the TCGA dataset for patch types classification with good performance. Furthermore, we perform cancer classification on COAD using node types generated by unsupervised K-means clustering. The performance (AUC: 98.5) is lower than that using HoverNet predicted node types (AUC: 99.9). This demonstrates that incorporating the pretrained HoverNet outperforms unsupervised methods and improves WSI analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We present a novel heterogeneous graph-based framework for WSI analysis. By modeling WSI as a heterogeneous graph with various node types and edge attributes, our method not only leverages the locality information, but also mines the complex relational information of WSI. We further design a novel heterogeneous edge attribute transformer architecture to aggregate the structural information in the graph and a semantic consistent pooling method to address the potential over-parameterization problems in conventional pooling. We provide a causal explanation mechanism to highlight the causal contributions of the instances to improve the clinical usability of our work. Extensive experiments on public datasets validate the effectiveness of our proposed framework and our framework could be adapted to other graph-based computer vision tasks, such as 3D point cloud analysis and anomaly detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Left: Input WSI. Middle: A WSI with selected patches and associated node types. (Black -no label; cyan -neoplastic; red -inflammatory; blue -connective; yellow -dead; green -nonneoplastic epithelial). Right: Constructed heterogeneous graph with different types of nodes and edge attributes (Illustrative).</figDesc><graphic coords="1,308.88,259.64,247.52,102.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The paradigm of our proposed heterogeneous graph-based WSI analysis framework, which includes heterogeneous graph construction, heterogeneous-graph edge attribute transformer (HEAT) for structural information aggregation, pseudo-label-based (PL) graph pooling for slide-level prediction and casual-driven localization.</figDesc><graphic coords="3,50.05,73.46,495.21,278.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Examples of introduced meta-relations in a heterogeneous graph constructed from a WSI. contribution of each patch to the prediction for localization.</figDesc><graphic coords="4,50.11,71.98,247.60,139.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Algorithm 1 The HEAT algorithm. Node-type specific projection layers {W i a , ∀a ∈ A} Edge attribute transformation layer W edge . Output: The updated graph G l with node features {H</figDesc><table><row><cell>Input:</cell></row><row><cell>Heterogeneous graph G l-1 with node features {H (l-1) i , ∀i ∈ V} and edge attribute {h (l-1) e , ∀e ∈ E};</cell></row><row><cell>(l) i , ∀i ∈ V}, and the edge features {h 1: Initialize projection layers for each node type (l) e , ∀e ∈ E}</cell></row><row><cell>2: for e = (s, t) ∈ E do 3:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Algorithm 2 The PL-Pool Algorithm Input: Heterogeneous graph G with node features {H i , ∀i ∈ V} and node type set A. Output: The pooled graph-level feature S ∈ R |A|×d . 1: Initialize readout layers for each node type a ∈ A.</figDesc><table><row><cell>2: Initialize aggregate feature matrix S.</cell></row><row><cell>3: for a ∈ A do 4: X a ← feature matrix of nodes of type a 5: h a ← readout a (X a ) ⊲ Pool feature with readout layer</cell></row><row><cell>6:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Cancer staging and classification results [%] of various methods on TCGA-COAD and TCGA-BRCA datasets.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Cancer Staging (Four Stages)</cell><cell cols="2">Cancer Classification</cell></row><row><cell></cell><cell>Model</cell><cell>AUC</cell><cell>Accuracy</cell><cell>Macro-F1</cell><cell>AUC</cell><cell>Accuracy Macro-F1</cell></row><row><cell>TCGA-COAD</cell><cell cols="3">ABMIL [18] DSMIL [21] ReMix [38] PatchGCN [5] 62.5 (4.9) 38.2 (3.1) 53.8 (3.7) 19.2 (7.8) 59.3 (1.4) 35.7 (5.7) 58.3 (1.5) 33.9 (7.8) GTNMIL [41] 54.2 (2.6) 29.3 (1.4) H 2 -MIL [15] 58.6 (2.7) 38.5 (5.4)</cell><cell>35.8 (4.4) 37.9 (2.8) 24.8 (7.5) 38.5 (5.7) 24.3 (3.9) 33.0 (5.0)</cell><cell cols="2">97.7 (2.3) 98.3 (0.9) 95.8 (2.2) 99.7 (0.2) 98.6 (0.5) 96.9 (0.9) 94.3 (3.4) 96.0 (4.6) 92.8 (5.9) 91.1 (5.3) 97.1 (2.0) 98.8 (1.0) 97.3 (2.6) 98.1 (1.3) 95.9 (2.4) 99.7 (0.4) 99.2 (0.5) 97.4 (1.7)</cell></row><row><cell></cell><cell cols="3">HEAT (Ours) 63.4 (2.5) 40.0 (2.1)</cell><cell>41.3 (2.7)</cell><cell cols="2">99.9 (0.2) 99.9 (0.3) 99.2 (0.4)</cell></row><row><cell>TCGA-BRCA</cell><cell cols="4">ABMIL [18] DSMIL [21] ReMix [38] PatchGCN [5] 50.3 (0.2) 41.6 (0.5) 54.7 (4.6) 19.0 (10.0) 23.9 (3.2) 51.4 (4.7) 18.3 (14.9) 23.2 (2.3) 58.8 (2.2) 35.6 (16.2) 27.6 (5.8) 25.1 (0.3) GTNMIL [41] 53.0 (3.7) 41.3 (4.4) 25.1 (2.3) H 2 -MIL [15] 52.1 (7.2) 53.7 (2.6) 21.2 (2.5)</cell><cell cols="2">97.3 (1.7) 98.3 (1.1) 97.3 (1.6) 98.7 (0.5) 95.6 (1.4) 93.3 (2.0) 96.1 (0.7) 95.8 (2.6) 93.0 (3.4) 96.2 (1.7) 98.2 (0.8) 98.4 (0.8) 94.7 (1.0) 94.5 (0.2) 93.7 (1.7) 97.9 (2.7) 98.0 (1.5) 97.6 (2.2)</cell></row><row><cell></cell><cell cols="6">HEAT (ours) 61.9 (3.8) 55.8 (6.4) 27.7 (16.3) 98.8 (0.7) 98.3 (0.5) 99.5 (0.7)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Cancer typing results [%] of our method compared to various GNN architectures on the TCGA-ESCA dataset.</figDesc><table><row><cell></cell><cell>.8</cell><cell>87.5</cell><cell>83.3</cell></row><row><cell>HEAT (ours)</cell><cell>92.8</cell><cell>92.7</cell><cell>93.2</cell></row><row><cell>Pooling Method</cell><cell cols="3">AUC Accuracy Macro-F1</cell></row><row><cell>Sum pooling</cell><cell>95.5</cell><cell>99.3</cell><cell>99.2</cell></row><row><cell>Max pooling</cell><cell>95.1</cell><cell>98.6</cell><cell>99.2</cell></row><row><cell>Mean pooling</cell><cell>97.7</cell><cell>95.8</cell><cell>99.8</cell></row><row><cell cols="2">Global attention pooling [22] 94.7</cell><cell>97.9</cell><cell>99.2</cell></row><row><cell>IH-Pool [15]</cell><cell>99.3</cell><cell>97.2</cell><cell>88.1</cell></row><row><cell>ASAP [25]</cell><cell>99.2</cell><cell>98.6</cell><cell>95.1</cell></row><row><cell>PL-Pool (ours)</cell><cell>99.6</cell><cell>99.3</cell><cell>99.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Cancer classification results [%] on TCGA-COAD of our pooling method to various comparable pooling methods using GCN and KimiaNet feature encoder.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>• ReMix<ref type="bibr" target="#b37">[38]</ref>: a general and efficient MIL's based framework for WSI analysis that takes the advantage of data augmentation and reduces method to produce Cancer classification results [%] of our method on TCGA-COAD and TCGA-BRCA balanced datasets.</figDesc><table><row><cell>Balanced dataset</cell><cell>AUC</cell><cell>Accuracy Macro-F1</cell></row><row><cell>TCGA-COAD</cell><cell cols="2">99.1 (1.8) 99.1 (1.8) 99.2 (1.7)</cell></row><row><cell>TGCA-BRCA</cell><cell cols="2">98.7 (2.5) 98.7 (2.5) 98.7 (2.6)</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. We thank the anonymous reviewers and the area chair for their insightful comments on our manuscript. This work was partially supported by the <rs type="funder">Research Grants Council of Hong Kong</rs> (<rs type="grantNumber">17308321</rs>), the <rs type="funder">Theme-based Research Scheme</rs> (<rs type="grantNumber">T45-401/22-N</rs>), the <rs type="funder">National Natural Science Fund</rs> (<rs type="grantNumber">62201483</rs>), and the <rs type="institution">HKU-TCL Joint Research Center for Artificial Intelligence</rs> sponsored by <rs type="affiliation">TCL Corporate Research (Hong Kong</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_bsENDyu">
					<idno type="grant-number">17308321</idno>
				</org>
				<org type="funding" xml:id="_ayqayQn">
					<idno type="grant-number">T45-401/22-N</idno>
				</org>
				<org type="funding" xml:id="_FCruAFa">
					<idno type="grant-number">62201483</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey on graph-based deep learning for computational histopathology</title>
		<author>
			<persName><forename type="first">David</forename><surname>Ahmedt-Aristizabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Ali Armin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Denman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clinton</forename><surname>Fookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Petersson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">102027</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Understanding overparameterization in generative adversarial networks</title>
		<author>
			<persName><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammadmahdi</forename><surname>Sajedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mukund</forename><surname>Neha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mucong</forename><surname>Kalibhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahdi</forename><surname>Stöger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soheil</forename><surname>Soltanolkotabi</surname></persName>
		</author>
		<author>
			<persName><surname>Feizi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer</title>
		<author>
			<persName><forename type="first">Ehteshami</forename><surname>Babak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitko</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">Johannes</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bram</forename><surname>Van Diest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nico</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geert</forename><surname>Karssemeijer</surname></persName>
		</author>
		<author>
			<persName><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Awm</forename><surname>Jeroen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meyke</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName><surname>Hermsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maschenka</forename><surname>Quirine F Manson</surname></persName>
		</author>
		<author>
			<persName><surname>Balkenhol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jama</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scaling vision transformers to gigapixel images via hierarchical self-supervised learning</title>
		<author>
			<persName><forename type="first">Chengkuan</forename><surname>Richard J Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yicong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiffany</forename><forename type="middle">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Trister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Rahul G Krishnan</surname></persName>
		</author>
		<author>
			<persName><surname>Mahmood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="16144" to="16155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Whole slide images are 2d point clouds: Context-aware survival prediction using patch-based graph convolutional networks</title>
		<author>
			<persName><forename type="first">Ming</forename><forename type="middle">Y</forename><surname>Richard J Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengkuan</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiffany</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drew Fk</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><surname>Mahmood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2021. 2, 4, 6, 7</date>
			<biblScope unit="page" from="339" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Diffgcn: Graph convolutional networks via differential operators and algebraic multigrid pooling</title>
		<author>
			<persName><forename type="first">Moshe</forename><surname>Eliasof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Treister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="18016" to="18027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Artificial intelligence and algorithmic computational pathology: an introduction with renal allograft examples</title>
		<author>
			<persName><forename type="first">Alton</forename><forename type="middle">B</forename><surname>Farris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Vizcarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Amgad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Gutman</surname></persName>
		</author>
		<author>
			<persName><surname>Hogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Histopathology</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="791" to="804" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pannuke: an open pancancer histology dataset for nuclei instance segmentation and classification</title>
		<author>
			<persName><forename type="first">Jevgenij</forename><surname>Gamper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alemi</forename><surname>Navid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ksenija</forename><surname>Koohbanani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Benet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasir</forename><surname>Khuram</surname></persName>
		</author>
		<author>
			<persName><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European congress on digital pathology</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Jevgenij</forename><surname>Gamper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alemi</forename><surname>Navid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ksenija</forename><surname>Koohbanani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Benes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><surname>Jahanifar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayesha</forename><surname>Khurram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Azam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasir</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><surname>Rajpoot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10778</idno>
		<title level="m">Pan-nuke dataset extension, insights and baselines</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exploiting edge features for graph neural networks</title>
		<author>
			<persName><forename type="first">Liyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9211" to="9219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Openslide: A vendor-neutral software foundation for digital pathology</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Goode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Harkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drazen</forename><surname>Jukic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahadev</forename><surname>Satyanarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of pathology informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hover-net: Simultaneous segmentation and classification of nuclei in multi-tissue histology images</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">Dang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shan</forename><forename type="middle">E</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Raza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayesha</forename><surname>Azam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Wah</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Tae</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasir</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">101563</biblScope>
			<date type="published" when="2005">2019. 2, 4, 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Investigating causal relations by econometric models and cross-spectral methods</title>
		<author>
			<persName><forename type="first">Clive Wj</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica: journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bayesian pyramids: Identifiable multilayer discrete latent structure models for discrete data</title>
		<author>
			<persName><forename type="first">Yuqi</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">B</forename><surname>Dunson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B: Statistical Methodology</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">H2-mil: Exploring hierarchical representation with heterogeneous multiple instance learning for whole slide image analysis</title>
		<author>
			<persName><forename type="first">Wentai</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lequan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongshan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liansheng</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2022. 2, 3, 6, 7, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Heterogeneous graph transformer</title>
		<author>
			<persName><forename type="first">Ziniu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference 2020</title>
		<meeting>The Web Conference 2020</meeting>
		<imprint>
			<date type="published" when="2008">2020. 2, 4, 7, 8</date>
			<biblScope unit="page" from="2704" to="2710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donglin</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.05688</idno>
		<title level="m">Da-hgt: Domain adaptive heterogeneous graph transformer</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Attention-based deep multiple instance learning</title>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Ilse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">kgcn: a graphbased deep learning framework for chemical structures</title>
		<author>
			<persName><forename type="first">Ryosuke</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shoichi</forename><surname>Ishida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masateru</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Iwata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teruki</forename><surname>Honma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasushi</forename><surname>Okuno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cheminformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pytorch-biggraph: A large-scale graph embedding system</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothee</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Wehrstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhijit</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Peysakhovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd SysML Conference</title>
		<meeting>the 2nd SysML Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dual-stream multiple instance learning network for whole slide image classification with self-supervised contrastive learning</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">W</forename><surname>Eliceiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR&apos;16</title>
		<meeting>ICLR&apos;16</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generative causal explanations for graph neural networks</title>
		<author>
			<persName><forename type="first">Wanyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baochun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Dongsheng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongkuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenchao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">19620-19631, 2020. 3</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
	<note>Parameterized explainer for graph neural network</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Asap: Adaptive structure aware pooling for learning hierarchical graph representations</title>
		<author>
			<persName><forename type="first">Ekagra</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2008">2020. 3, 7, 8</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="5470" to="5477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Abtin</forename><surname>Riasatian</surname></persName>
		</author>
		<author>
			<persName><surname>Kimianet</surname></persName>
		</author>
		<title level="m">Training a deep network for histopathology using high-cellularity. Master&apos;s thesis</title>
		<imprint>
			<publisher>University of Waterloo</publisher>
			<date type="published" when="2008">2020. 2, 4, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Spatial organization and molecular correlation of tumor-infiltrating lymphocytes using deep learning on pathology images</title>
		<author>
			<persName><forename type="first">Joel</forename><surname>Saltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajarsi</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tahsin</forename><surname>Kurc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pankaj</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vu</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianhao</forename><surname>Kenneth R Shroyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><surname>Batiste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell reports</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="181" to="193" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European semantic web conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cxplain: Causal explanations for model interpretation under uncertainty</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Schwab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Karlen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Neural image compression for gigapixel histopathology image analysis</title>
		<author>
			<persName><forename type="first">David</forename><surname>Tellez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geert</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeroen</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Ciompi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="567" to="578" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Rmdl: Recalibrated multi-instance deep learning for whole slide gastric image classification</title>
		<author>
			<persName><forename type="first">Shujun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaxi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lequan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huangjing</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangbo</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinjuan</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">101549</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Heterogeneous graph attention network</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houye</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2022" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The cancer genome atlas pan-cancer analysis project</title>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">A</forename><surname>John N Weinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><forename type="middle">B</forename><surname>Collisson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenna</forename><forename type="middle">R</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Ozenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Ellrott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Shmulevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">M</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName><surname>Stuart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature genetics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">J. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2008">2017. 2016. 2, 3, 7, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Remix: A general and efficient framework for multiple instance learning based whole slide image classification</title>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanbo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhua</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention-MICCAI 2022: 25th International Conference</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">September 18-22, 2022. 2022</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Gnnexplainer: Generating explanations for graph neural networks</title>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Bourgeois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008">2019. 3, 8</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Graph transformer networks</title>
		<author>
			<persName><forename type="first">Seongjun</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minbyul</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raehyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunwoo J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007">2019. 2, 4, 6, 7</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A graph-transformer for whole slide image classification</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rushin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">J</forename><surname>Gindra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">J</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margrit</forename><surname>Burks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">E</forename><surname>Betke</surname></persName>
		</author>
		<author>
			<persName><surname>Beane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vijaya</surname></persName>
		</author>
		<author>
			<persName><surname>Kolachalama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dual graph convolutional networks for graph-based semi-supervised classification</title>
		<author>
			<persName><forename type="first">Chenyi</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference</title>
		<meeting>the 2018 World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="499" to="508" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
