<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data-Driven Confounder Selection via Markov and Bayesian Networks</title>
				<funder ref="#_g3MpCYe #_Nwf5AkF">
					<orgName type="full">Swedish Research Council</orgName>
				</funder>
				<funder>
					<orgName type="full">Umeå University</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2017-03-17">17 Mar 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Jenny</forename><surname>Häggström</surname></persName>
							<email>jenny.haggstrom@umu.se</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution" key="instit1">USBE</orgName>
								<orgName type="institution" key="instit2">Umeå University</orgName>
								<address>
									<postCode>SE-901 87</postCode>
									<settlement>Umeå</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data-Driven Confounder Selection via Markov and Bayesian Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-03-17">17 Mar 2017</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1604.07212v2[stat.ME]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian networks</term>
					<term>Causal inference</term>
					<term>Confounding</term>
					<term>Covariate selection</term>
					<term>Markov networks</term>
					<term>Matching</term>
					<term>TMLE</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To unbiasedly estimate a causal effect on an outcome unconfoundedness is often assumed. If there is sufficient knowledge on the underlying causal structure then existing confounder selection criteria can be used to select subsets of the observed pretreatment covariates, X, sufficient for unconfoundedness, if such subsets exist. Here, estimation of these target subsets is considered when the underlying causal structure is unknown. The proposed method is to model the causal structure by a probabilistic graphical model, e.g., a Markov or Bayesian network, estimate this graph from observed data and select the target subsets given the estimated graph. The approach is evaluated by simulation both in a high-dimensional setting where unconfoundedness holds given X and in a setting where unconfoundedness only holds given subsets of X. Several common target subsets are investigated and the selected subsets are compared with respect to accuracy in estimating the average causal effect. The proposed method is implemented with existing software that can easily handle high-dimensional data, in terms of large samples and large number of covariates. The results from the simulation study show that, if unconfoundedness holds given X, this approach is very successful in selecting the target subsets, outperforming alternative approaches based on random forests and LASSO, and that the subset estimating the target subset containing all causes of outcome yields smallest MSE in the average causal effect estimation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>To get an unbiased estimate of a causal effect, of a treatment on some outcome, the treatment assignment is often assumed to be unconfounded, which is the case, e.g., when assignment to treatment is randomized. In an observational study treatment assignment is not randomized, and to get unbiased causal effect estimates we need to make sure that the assumption of unconfoundedness is plausible when conditioning on some set of covariates. Two important questions are: 1) Which set of covariates should we aim to condition on? and 2) How should we in practice go about to select the latter set of covariates? Often the answer to the first question has been "the set of covariates that are common causes of treatment and outcome" or "all observed pretreatment covariates", hereinafter referred to as 'the common cause criterion' and 'the pretreatment criterion', respectively. However, in response to <ref type="bibr" target="#b30">Rubin (2007)</ref>, in a series of letters to the editor and author's replies <ref type="bibr" target="#b38">(Shrier, 2008;</ref><ref type="bibr">Rubin, 2008a;</ref><ref type="bibr" target="#b25">Pearl, 2009b;</ref><ref type="bibr" target="#b39">Sjölander, 2009;</ref><ref type="bibr" target="#b33">Rubin, 2009)</ref> and later on in <ref type="bibr" target="#b44">VanderWeele and Shpitser (2011)</ref> it was discussed under what circumstances conditioning on the covariate set defined by the common cause criterion or the pretreatment criterion will in fact induce bias in the causal effect estimate instead of reducing it.</p><p>In an attempt to mediate between the standpoints of <ref type="bibr">Pearl, Shrier, Sjölander and Rubin VanderWeele and Shpitser (2011)</ref> proposed an alternative covariate selection criterion, 'the disjunctive cause criterion'. The disjunctive cause criterion entails selecting all covariates that are causes of treatment and/or causes of outcome, and will, under certain assumptions, result in unconfoundedness. Specifically, the disjunctive cause criterion is similar to 'the backdoor path criterion' <ref type="bibr" target="#b23">(Pearl, 1995)</ref> in the sense that the covariate set selected by the disjunctive cause criterion will suffice to block all backdoor paths from treatment to outcome if such a set exists. The main practical difference between these two criteria is that to use the backdoor path criterion, knowledge of the full causal structure of the data is needed but to use the disjunctive cause criterion it is sufficient to know which covariates are causes of the treatment and which covariates are causes of the outcome. <ref type="bibr" target="#b44">VanderWeele and Shpitser (2011)</ref> dismiss the practical usefulness of the backdoor path criterion and point out that "In a number of analyses in the biomedical and social sciences, such complete knowledge of causal structures is unlikely" (Section 1, p.1406). Regarding the knowledge of the causal structure that is required for use of the disjunctive cause criterion, they are however optimistic, stating that "In many epidemiological and biomedical applications, subject matter experts have intuitive knowledge of whether each covariate is a cause of the treatment or the outcome" (Section 6, p.1411). If it is indeed the case, that we have the knowledge required to use the disjunctive cause criterion (or the backdoor path criterion), then the problem of covariate selection, with respect to unconfoundedness, is solved and the question in 2) is redundant.</p><p>However, when knowledge of the causal structure is not sufficient for use of the disjunctive cause criterion the process of covariate selection can be aided by data-driven procedures. Moreover, even in cases where the disjunctive cause criterion can be used, mean squared error of nonparametric estimators of causal effects may be improved by further reducing the dimensionality of the covariate set <ref type="bibr" target="#b6">(de Luna, Waernbaum, and Richardson, 2011)</ref>. Given a set of covariates such that conditioning on this set unconfoundedness is upheld the latter authors propose general algorithms, in line with the common cause criterion, for selecting minimal sets of covariates such that unconfoundedness still holds when conditioning on the selected sets. These algorithms are implemented using marginal coordinate hypothesis testing (continuous covariates) and kernel smoothing (continuous and/or discrete covariates) in the R package CovSel <ref type="bibr" target="#b14">(Häggström, Persson, Waernbaum, and de Luna, 2015)</ref>. These implementations have in simulation studies <ref type="bibr" target="#b26">(Persson, Häggström, Waernbaum, and de Luna, 2017)</ref> been shown to perform well in reducing the dimensionality of the covariate set while still upholding unconfoundedness, thereby resulting in improved mean squared error. For other recently proposed covariate selection procedures see, e.g., <ref type="bibr" target="#b26">Persson et al. (2017)</ref>, <ref type="bibr" target="#b34">Schnitzer et al. (2016)</ref> and references therein. Existing proposals have in common that they are computer intensive, yielding prohibitive running times in high dimensional applications (in terms of number of covariates and number of units).</p><p>In this paper we propose and study the use of Markov and Bayesian network algorithms, more precisely Max-Min Parents and Children (MMPC) and Max-Min Hill-Climbing (MMHC) <ref type="bibr" target="#b42">(Tsamardinos, Brown, and Aliferis, 2006)</ref>, in conjunction with the covariate selection algorithms in de <ref type="bibr" target="#b6">Luna et al. (2011)</ref>. MMHC has in empirical evaluations been shown to outperform the PC algorithm <ref type="bibr" target="#b40">(Spirtes et al., 2000)</ref>, previously studied by <ref type="bibr" target="#b20">Maathuis, Kalisch, and Bühlmann (2009)</ref> in a similar causal inference setting (although not for explicitly selecting covariates), both with regard to computation time and in ability to accurately estimate the true causal structure <ref type="bibr" target="#b42">(Tsamardinos et al., 2006)</ref>. To the author's knowledge, using estimated graphs to explicitly select covariates to control for, as a step completely separated from the nonparametric estimation of causal effects, has not been proposed and studied elsewhere.</p><p>The performance of the proposed data-driven covariate selection procedures is investigated, using simulations, in two general high-dimensional scenarios: 1) Unconfoundedness holds given the full covariate set, 2) Unconfoundedness does not hold given the full covariate set, but it does hold given a subset of the full covariate set. In scenario 1), the results show that this approach is very successful in selecting the target covariate subsets. Furthermore, targeting the subset containing all causes of outcome often yields smallest MSE in the average causal effect (ACE) estimation, but the magnitude of the reduction in MSE (relative to conditioning on the full covariate set) depends on the ACE estimator. The proposed covariate selection algorithms are implemented in the R package CovSelHigh <ref type="bibr" target="#b13">(Häggström, 2016)</ref>.</p><p>The remainder of this paper is organized as follows. In Section 2 relevant notation and concepts from causal inference are reviewed. Section 3 focuses on covariate selection when the causal structure is known and Section 4 on covariate selection using Markov and Bayesian network algorithms when the causal structure is unknown. In Section 5 the simulation study is presented. In Section 6 the proposed approach is illustrated using a large register data set with which the ACE of C-section delivery on asthma medication early in life is estimated. The paper is concluded with a discussion in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Context and Terminology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Potential Outcomes and Unconfoundedness</head><p>Let T denote a binary treatment, Y denote outcome and X denote the set of observed pretreatment covariates, i.e., the full covariate set. Within the potential outcome framework <ref type="bibr" target="#b22">(Neyman, 1923;</ref><ref type="bibr" target="#b28">Rubin, 1974)</ref> we let Y (1) and Y (0) denote the potential outcomes for Y under the two treatments T = 1 and T = 0, respectively. Since only one treatment assignment is possible for each unit only one of the two potential outcomes is observed, Y = Y (0)(1 -T ) + Y (1)T . In this paper, the ACE, β = E{Y (1) -Y (0)}, is the parameter of interest.</p><p>If treatment assignment is not randomized, β is identified if a unit's potential outcomes does not depend on the treatments received by other units (stable unit treatment assumption, SUTVA) <ref type="bibr" target="#b29">(Rubin, 1990)</ref> and we have available a set of pretreatment covariates S such that the probability of receiving either treatment conditional on S is bounded away from 0 (overlap assumption) and such that the treatment assignment is unconfounded conditional on S. Letting ⊥ ⊥ mean "is independent of" <ref type="bibr" target="#b5">(Dawid, 1979)</ref> the assumption of unconfoundedness is upheld if Y (1), Y (0) ⊥ ⊥ T | S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graphical Models</head><p>A graph G = (V, E) consists of a set of vertices V = {V i : i ∈ 1, . . . , p} and a set of edges E. The vertices represent random variables, and the edges describe pairwise relationships among the variables. Here, the two types of graphs considered are undirected graphs and directed acyclic graphs <ref type="bibr">(DAGs)</ref>. In an undirected graph all edges are undirected (-) and in a directed graph all edges are directed (→). A directed graph with no cycles is a DAG. Two vertices are adjacent if they are connected by an edge and the neighbors of a vertex V i consists of all vertices adjacent to V i . Furthermore, we define a path in a graph as a sequence of edges connecting vertices such that each vertex on the path is visited only once. In a DAG a vertex is a collider on a path if the path enters and leaves the vertex via arrowheads. In this paper we interpret directed edges as causal, i.e., <ref type="bibr">(Pearl, 2009a)</ref>. In an undirected graph the Markov blanket of a vertex consists of the vertex's neighbors and in a DAG the Markov blanket of a vertex consists of the vertex's parents, children and children's other parents. The local Markov property holds with respect to an undirected graph G if there exists a joint probability distribution for V such that, for each V i ∈ V , V i is conditionally independent of its non-neighbors given its neighbors. For a DAG the local Markov property holds if there exists a joint probability distribution for V such that, for each V i ∈ V , V i is conditionally independent of its non-descendants given its parents.</p><formula xml:id="formula_0">V 1 → V 2 means that V 1 is a cause of V 2 , also V 1 is said to be a parent of V 2 and V 2 the child V 1</formula><p>A Markov network is a model consisting of an undirected graph, G = (V, E), and a joint probability distribution P defined over V such that the local Markov property holds with respect to G. Similarly, a Bayesian network is a model consisting of a DAG, G = (V, E), and a joint probability distribution P defined over V such that the local Markov property holds with respect to G. A probability distribution is faithful to the graph if it obeys no further conditional independence relations than what are entailed by the local Markov property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Target Covariate Subsets</head><p>In this section, target covariate subsets are defined using the languages of potential outcomes and graphical models. Let G t = (V t , E t ) with V t = {X, T, Y (t)} for t = 0, 1. The subset of X that includes all causes of treatment is defined as</p><formula xml:id="formula_1">X →T = {X i ∈ X : X i → T ∈ E 0 ∪ E 1 }. Similarly, let X →Y = X 0 →Y ∪ X 1 →Y = {X i ∈ X : X i → Y (0) ∈ E 0 } ∪ {X i ∈ X : X i → Y (1) ∈ E 1 } be</formula><p>the subset of X that includes all causes of outcome. Furthermore, let the subset of X →T consisting of elements dependent with outcome be defined as</p><formula xml:id="formula_2">Q →T = Q 0 →T ∪ Q 1 →T where Q t →T ⊆ X →T such that Y (t) ⊥ ⊥ X →T \ Q t →T | Q t</formula><p>→T , for t = 0, 1, and let the subset of X →Y consisting of elements dependent with treatment be defined as</p><formula xml:id="formula_3">Z →Y = Z 0 →Y ∪Z 1 →Y where Z t →Y ⊆ X t →Y such that T ⊥ ⊥ X t →Y \ Z t →Y | Z t</formula><p>→Y , for t = 0, 1. Defined in line with the common cause criterion, Q →T is a subset of the covariates that cause treatment, and Z →Y a subset of the covariates that cause outcome.</p><p>The following, similar but not identical to the above, sets are defined in de Luna et al. ( <ref type="formula">2011</ref>):</p><formula xml:id="formula_4">X T ⊆ X such that T ⊥ ⊥ X \ X T | X T , X Y = X 0 ∪ X 1 where X t ⊆ X such that Y (t) ⊥ ⊥ X \ X t | X t for t = 0, 1, Q t ⊆ X T such that Y (t) ⊥ ⊥ X T \ Q t | Q t for t = 0, 1 and Z t ⊆ X Y such that T ⊥ ⊥ X Y \ Z t | Z t for t = 0, 1.</formula><p>As long as we have unconfoundedness given X the following equalities hold:</p><formula xml:id="formula_5">X →T = X T , X →Y = X Y , Q →T = Q and Z →Y = Z.</formula><p>The latter authors also state assumptions under which these sets are unique <ref type="bibr" target="#b6">(de Luna et al., 2011</ref>, Lemmas A2-A5) and Z and Q are minimal sets that cannot be reduced without violating unconfoundedness <ref type="bibr">(de Luna et al., 2011, Proposition 8)</ref>. The above equalities do not hold in general since X →T and X →Y are defined in terms of edges present in a DAG while <ref type="bibr" target="#b6">de Luna et al. (2011)</ref> define all sets in terms of conditional independencies.</p><p>The subset of X that includes all causes of treatment and/or outcome, i.e., the disjunctive cause criterion subset, is defined as X →T,Y = X →T ∪ X →Y . VanderWeele and Shpitser (2011) suggest a criterion where covariates unassociated with the outcome are iteratively discarded from X →T,Y , henceforth 'the disjunctive cause criterion with backward selection', and the subset of X →T,Y consisting of elements that are associated with outcome is defined as</p><formula xml:id="formula_6">W →Y = W 0 →Y ∪W 1 →Y where W t →Y ⊆ X →T,Y such that Y (t) ⊥ ⊥ X →T,Y \W t →Y | W t →Y , for t = 0, 1. If X →T</formula><p>and X →Y are uniquely defined then it follows that X →T,Y is unique and under assumptions similar to Lemma A3 in de Luna et al. ( <ref type="formula">2011</ref>) so is W →Y .</p><p>For illustrative purposes consider the causal diagram in Figure <ref type="figure">1</ref>. Here, the observed pretreatment covariates X = {X i : i ∈ 1, . . . , 10} are the only variables affecting T and Y and thus all of the covariate selection criteria mentioned in Section 1 would result in unconfoundedness. The target sets are</p><formula xml:id="formula_7">X →T = X T = {X 1 , X 2 , X 3 , X 4 , X 7 }, X →Y = X Y = {X 1 , X 2 , X 5 , X 6 , X 8 }, Q →T = Q = {X 1 , X 2 , X 7 }, Z →Y = Z = {X 1 , X 2 , X 8 }, X →T,Y = {X 1 , X 2 , X 3 , X 4 , X 5 , X 6 , X 7 , X 8 } and W →Y = {X 1 , X 2 , X 5 , X 6 , X 7 , X 8 }.</formula><p>The common cause criterion would select S = {X 1 , X 2 , X 7 } = Q →T , the pretreatment criterion would select S = X, the backdoor path criterion would select S = {X 1 , X 2 , X 3 , X 4 , X 7 }, the disjunctive cause criterion would select S = X →T,Y and the disjunctive cause criterion with backward selection would select S = W →Y . Now consider the causal diagram in Figure <ref type="figure">2</ref>. Here, in addition to T , Y and X = {X i : i ∈ 1, . . . , 10} we have a set of unobserved variables U = {U 1 , U 2 , U 3 } affecting T and/or Y . The target sets X →T , X →Y , Z →Y , and X →T,Y remain as for Figure <ref type="figure">1</ref> </p><formula xml:id="formula_8">but now Q →T = {X 1 , X 2 , X 4 , X 7 }, and W →Y = {X 1 , X 2 , X 4 , X 5 , X 6 , X 7 , X 8 }.</formula><p>As pointed out by <ref type="bibr" target="#b44">VanderWeele and Shpitser (2011)</ref>, in this setting not all of the above covariate selection criteria would result in unconfoundedness. Except for the disjunctive cause criterion with backward selection,</p><formula xml:id="formula_9">X1 X2 T X3 Y (t) X5 X6 X8 X7 X9 X10 X4 Figure 1 A causal DAG without unobservables. X1 X2 T X3 Y (t) X5 X6 X8 X7 X9 U1 U2 X10 X4 U3 Figure 2 A causal DAG with unobservables.</formula><p>all of the criteria would in this setting select the same sets as in the previous setting. However, the set selected by the common cause criterion, {X 1 , X 2 , X 7 } = Q →T , would not result in unconfoundedness since it does not include the covariate X 4 , which is now related to both T and Y , the latter through the unobserved variable U 3 . The set selected by the pretreatment criterion would fail to achieve unconfoundedness due to the inclusion of the covariate X 9 , which is now a collider on the path between T and Y due to the unobserved variables U 1 and U 2 . Conditioning on X 9 will thus open up this path between T and Y and introduce the so called M -bias <ref type="bibr" target="#b10">(Greenland, 2003)</ref>. The sets selected by the backdoor path criterion and the disjunctive cause criterion would however achieve unconfoundedness since both sets would include X 4 but not X 9 . The disjunctive cause criterion with backward selection would select S = {X 1 , X 2 , X 4 , X 5 , X 6 , X 7 , X 8 } = W →Y which includes X 4 since it is now associated with the outcome and conditioning on this set upholds unconfoundedness. Conditioning on Q →T would also, in this case, result in unconfoundedness.</p><p>Note that here the sets defined in de Luna et al. ( <ref type="formula">2011</ref>) are</p><formula xml:id="formula_10">X T = X →T ∪ {X 9 }, X Y = X →Y ∪ {X 4 , X 9 }, Q = Q →T ∪ {X 9 } and Z = Z →Y ∪ {X 4 , X 9 }, all including X 9 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Covariate Selection When the Causal Structure is Unknown</head><p>Given the setup stated in Section 2, and no further knowledge on the causal structure, only the pretreatment criterion can be readily used without aid of data-driven procedures. If we, in some way, from data estimate the dependence structure in the form of an undirected or directed graph then we can use the estimated graph to select covariates by reading off which covariates are related to T and/or Y | T = t for t = 0, 1.</p><p>There are many different methods available for estimating Markov and Bayesian networks (see, e.g., <ref type="bibr" target="#b9">Friedman et al., 1999;</ref><ref type="bibr" target="#b40">Spirtes et al., 2000;</ref><ref type="bibr" target="#b3">Chickering, 2002;</ref><ref type="bibr">Tsamardinos et al., 2006, and references therein)</ref>. In this paper, the Max-Min Parents and Children Algorithm (MMPC) and the Max-Min Hill-Climbing Algorithm (MMHC) are used to estimate the underlying structure of the data. Algorithms used for estimating such networks can be classified as either constraint-based or score-based. MMHC is a hybrid algorithm which as a first step uses the constraint-based MMPC algorithm to estimate a Markov network, i.e., an undirected graph, and as a second step uses the score-based local optimization technique hill-climbing (similar to steepest ascent) to find the Bayesian network, i.e., the DAG, that best fits the data. For the purpose of estimating the graphs we assume that we have a copy of the data {X, T, Y } where any continuous variables have been discretized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Max-Min Parents and Children Algorithm</head><p>MMPC estimates the underlying graph structure by testing if the conditional independencies between the variables implied by a Markov network hold. One commonly used conditional independence test is based on the information-theoretic measure mutual information. Using the observed frequencies for variables V i , V j and all the configurations of the variables in the conditioning set MI is estimated by MI</p><formula xml:id="formula_11">(V i , V j | V k = {V \ {V i , V j }}) = n -1 abc n abc ijk ln{n abc ijk n c k (n ac ik n bc jk ) -1 },</formula><p>where n abc ijk is the size of the subsample where</p><formula xml:id="formula_12">V i = a, V j = b and V k = c. n c</formula><p>k , n ac ik and n bc jk are defined analogously. MI is proportional to the likelihood-ratio test (by a factor of 2n) and is asymptotically χ 2 -distributed with (A -1)(B -1)C degrees of freedom, where A, B and C are the number of distinct configurations of V i , V j and V k .</p><p>The goal of MMPC is, for each variable V i , i = 1, . . . , p, to return the set containing the variable's neighbors, i.e., the variable's Markov blanket, M B i . For the variable V i and supposing that the rest of the variables in the graph are ordered as (V 1 , . . . , V J ) MMPC starts in phase 1 with the empty set as the candidate M B i , CM B i 0 = ∅, and updates the candidate M B i as follows, j = 1, . . . , J,</p><formula xml:id="formula_13">CM B i j = CM B i j-1 if V j ⊥ ⊥ V i | CM B i j-1 , CM B i j-1 ∪ {V j } otherwise.</formula><p>In phase 2 MMPC starts with the set CM B i J from phase 1 as the candidate M B i , i.e., CM B i 0 = CM B i J . Suppose that the variables in the set CM B i J are ordered as (V 1 , . . . , V K ) then the set is updated as follows, k = 1, . . . , K,</p><formula xml:id="formula_14">CM B i k =    CM B i k-1 \ {V k } if ∃A ⊆ CM B i k-1 \ {V k } s.t. V i ⊥ ⊥ V k | A, CM B i k-1 otherwise.</formula><p>After running phase 1 and phase 2 for all V i , i = 1, . . . , p, an attempt to remove any variables included in the final CMBs that are not a neighbor (false positives) is made in phase 3. Start with the set CM B i 0 = CM B i K and suppose that the variables in the set CM B i K are ordered as (V 1 , . . . , V L ) then the set is updated as follows, l = 1, . . . , L,</p><formula xml:id="formula_15">CM B i l = CM B i l-1 if V i ∈ CM B l K CM B i l-1 \ {V l } otherwise. The final set for variable V i is M B i = CM B i L .</formula><p>With the knowledge of all neighbors of all the variables in the graph the undirected graph can be constructed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Max-Min Hill-Climbing Algorithm</head><p>In the first step MMPC is performed. In the second step MMHC attempts to identify the Bayesian network that maximizes a score function indicating how well the graph fits the data, e.g., AIC, BIC or similar criteria. An empty graph is the starting point and a new candidate graph is generated by performing one of the following alterations to the current candidate graph: single-edge addition, single-edge deletion, or single-edge direction reversal. The alteration that leads to the largest increase in score is performed. The procedure is iterated until there is no alteration that increases the score. The optimization is constrained to only consider adding an edge if it is present in the undirected graph returned by MMPC in the first step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Estimation of Target Covariate Subsets</head><p>The target covariate sets defined earlier are estimated by fitting a number of discrete Markov or Bayesian networks in a stepwise manner adhering to the covariate selection algorithms in de <ref type="bibr" target="#b6">Luna et al. (2011)</ref>. To be clear, we only estimate certain graphs and the sets of covariates in the Markov blankets of these estimated graphs are what is meant by "estimated target covariate sets". Given the assumed temporal order between X, T and Y we always incorporate the constraints that T and Y | T = t for t = 0, 1 have no children in X. Consider estimating the subgraph including only vertices V = {X, T } then X →T is defined as the estimated Markov blanket of T . Given X →T we estimate the subgraphs including only vertices V = { X →T , Y | T = t} for t = 0, 1 and define</p><formula xml:id="formula_16">Q →T = Q 0 →T ∪ Q 1</formula><p>→T as the union of the estimated Markov blankets for Y | T = t for t = 0, 1. Similarly, we estimate X →Y by estimating the subgraphs including only vertices V = {X, Y | T = t} for t = 0, 1 and define X →Y = X 0 →Y ∪ X 1 →Y as the union of the estimated Markov blankets for Y | T = t for t = 0, 1. Given X →Y we estimate the subgraphs including only vertices V = { X t →Y , T } for t = 0, 1 and define Z → = Z 0 →Y ∪ Z 1 →Y as the union of the estimated Markov blankets for T . Furthermore, X →T,Y = X →T ∪ X →Y and given X →T,Y we estimate the subgraphs including only vertices V = { X →T,Y , Y | T = t} for t = 0, 1 and define W →Y = W 0 →Y ∪ W 1 →Y as the estimated Markov blankets for Y | T = t for t = 0, 1. Although MMHC results in a DAG, for our purposes, the directionality of the edges give no added information since we assume that T and Y | T = t, for t = 0, 1, have no children in X and we are not interested in the relations between the covariates. MMHC can however result in a graph with fewer edges than those present in the undirected graph produced by MMPC.</p><p>Note that technically this estimation strategy violates Rubin's "no outcome data"-policy <ref type="bibr" target="#b30">(Rubin, 2007;</ref><ref type="bibr" target="#b32">Rubin, 2008b)</ref> which entails that study design, e.g., confounder selection, should be performed without any use of outcome data. However, the ACE is never estimated in the confounder selection process and outcome data are only considered separately for each treatment group, thus avoiding any difference in outcome between the treatment groups to influence the confounder selection and subsequent ACE estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Theoretical Results</head><p>C1. X, T and Y (t), t = 0, 1 are all discrete random variables.</p><p>C2. Y (t) and T have no children in X and Y (t), t = 0, 1 is not a parent of T . All confounders are observed.</p><p>C3. The underlying true causal structures are DAGs, denoted G X,T,Y (t) for t = 0, 1, involving the set of vertices V X,T,Y (t) = {X, T, Y (t)}.</p><p>C4. There exist joint probability functions, denoted p X,T,Y (0) and p X,T,Y (1) , such that the local Markov property holds with respect to G X,T,Y (t) , for t = 0, 1.</p><p>C5. p X,T,Y (0) and p X,T,Y (1) are faithful to G X,T,Y (t) , for t = 0, 1, respectively.</p><p>C6. A perfect conditional independence oracle is available.</p><p>Theorem 1: When conditions C1 -C6 are satisfied, the estimated target covariate sets resulting from using MMPC will equal the true target covariate sets. That is,</p><formula xml:id="formula_17">X →T = X →T , Q →T = Q →T , X →Y = X →Y , Z → = Z →Y , X →T,Y = X →T,Y and W →Y = W →Y .</formula><p>A proof of Theorem 1 appear in Appendix A.</p><p>Remark 1: Conditions C2-C5 are fairly reasonable and common assumptions in settings like these. If the outcome and/or some of the covariates are continuous variables (C1 violated) and there is a need for discretizing prior to performing confounder selection via MMPC, information will be lost and this can affect the performance of the confounder selection procedure in practice. Most notably, we do not have access to a perfect conditional independence oracle (C6 violated) and hence the quality of the confounder selection procedure will depend on the properties of the method used for determining conditional independencies.</p><p>As far as the author knows, there is no theoretical results regarding the final output of MMHC. However, since MMHC performs MMPC in the first step, when conditions C1-C6 are satisfied the estimated target covariate sets resulting from using MMHC will be equal to, or subsets of, the estimated target covariate sets resulting from MMPC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Simulation Study</head><p>A simulation study is performed to evaluate 1) the ability of MMPC and MMHC, respectively, to retrieve the target covariate subsets X →T , Q →T , X →Y , Z →Y , X →T,Y and W →Y and 2) to what extent the retrieved covariate sets result in unconfoundedness and 3) the impact of the selected sets on the estimation of the ACE. Comparisons are made with two other methods sometimes used for variable selection, namely random forests (RF; <ref type="bibr" target="#b2">Breiman, 2001)</ref> and LASSO <ref type="bibr" target="#b41">(Tibshirani, 1996)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Simulation design</head><p>All simulations are repeated with 1000 iterations each, with sample sizes n = 500, 1000, 2000, 10000 and 100 covariates included in X. Data generation and all computations are performed with the software R (R Core Team, 2016) using the R package CovSelHigh <ref type="bibr" target="#b13">(Häggström, 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Setting 1: Unconfoundedness holds given X</head><p>In this setting the core causal structure corresponds to Figure <ref type="figure">1</ref>. In addition to the ten covariates visible in Figure <ref type="figure">1</ref> 90 additional covariates are generated, related to each other but not to the first ten covariates. Hence, the complete covariate set consists of 100 covariates , X = {X i : i ∈ 1, ..., 100}. A mixture of continuous and discrete covariates are simulated and the ten covariates in the core causal structure are generated according to the following specification: (R 1 , X 2 ) T , (X 5 , R 2 ) T ∼ N (0, 0) T , ((1, 0.5) T (1, 0.5) T ) , X 1 = I(R 1 &gt; 0), X 6 = I(R 2 &gt; 0), (X 7 , X 8 ) T ∼ Bernoulli (0.5, 0.5) T , ((1, 0.7) T (1, 0.7) T ) , X 3 , X 10 ∼ Bernoulli(0.5), X 4 , X 9 ∼ N(0, 1).</p><p>We have that Corr(X 1 , X 2 ) = Corr(X 5 , X 6 ) = 0.4 and Corr(X 7 , X 8 ) = 0.7. For a full specification of how the rest of the covariates are generated see the function cov.sel.high.sim in the R package CovSelHigh. Let f T (X) = 3-2X 1 -2X 2 -2X 3 -X 4 -2X 7 and f Y (X) = 4X 1 +2X 2 +2X 5 +4X 6 +4X 8 , then the treatment variable, T , is generated from n Bernoulli trials with the treatment probability P(T = 1 | X) = [1 + exp{f T (X)}] -1 . The coefficients are chosen such that E(T ) = 0.5. Three outcome models are generated: one linear, one binary and one nonlinear. The linear outcome model, for</p><formula xml:id="formula_18">t = 0, 1, is Y (t) = 2 + 2t + f Y (X) + ε t , where ε t ∼ N(0, 1).</formula><p>The binary outcome model, for t = 0, 1, is generated as Bernoulli trials with probabilities P{Y (t</p><formula xml:id="formula_19">) = 1|X} = [1 + exp{-2 -2t + f Y (X)}] -1 . The more complex nonlinear outcome model, for t = 0, 1, is specified as Y (t) = 2 + 4.4t + f t (X) + ε t , where f t (X) = (7 -4t)X 1 -{(6 + 3t)X 6 }{0.5 + (X 2 + 1.4) (2+2t) } -1 + 2X 2</formula><p>5 + 4X 8 , and ε t ∼ N(0, 1). In order to uphold the assumption of unconfoundedness, a selected subset has to include one of the subsets, {X 1 , X 2 , X 7 } or {X 1 , X 2 , X 8 }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Setting 2: M -bias given X</head><p>In this setting the causal structure corresponds to Figure <ref type="figure">2</ref>. Here X 4 , X 9 , T , Y (0) and Y (1) all depend on the unobservable variables U 1 , U 2 and U 3 . Everything else is analogous to the data generating process described in Section 5.</p><formula xml:id="formula_20">1.1. Now, let U 1 , U 2 , U 3 ∼ N(0, 1), ν 1 , ν 2 ∼ N(0, 0.5), X 4 = 0.2 + 0.8U 3 + ν 1 , and X 9 = 1 + 2U 1 + 3U 2 + ν 2 . Here the outcome model functions are f T (X) = 3 -2X 1 -2X 2 -2X 3 -X 4 -2X 7 -U 1 , f Y (X) = 4X 1 + 2X 2 + 2X 5 + 4X 6 + 4X 8 + 7U 2 + 2U 3 , and, for t = 0, 1, f t (X) = (7 -3t)X 1 -{(6 + 3t)X 6 }{0.5 + (X 2 + 1.4) (2+2t) } -1 + 2X 2 5 + 4X 8 + 7U 2 + 2U 3 .</formula><p>With these alterations the treatment variable T and outcomes for the linear, binary and nonlinear models are generated following the specification in Section 5.1.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Estimation of the ACE</head><p>To illustrate the impact of the estimated target subsets on the estimation of the ACE we consider two different strategies: propensity score matching (PSM; <ref type="bibr" target="#b0">Abadie and Imbens, 2006)</ref> and targeted maximum likelihood estimation (TMLE; van der Laan and <ref type="bibr" target="#b43">Rubin, 2006)</ref>. PSM has several downsides (see, e.g., <ref type="bibr" target="#b16">King and Nielsen, 2016)</ref> but is possibly the most popular strategy in practice. TMLE is a doubly robust estimator, i.e., consistent if either propensity score or outcome model is correct, and consistent and efficient if both models are correct. For PSM the propensity score is estimated by main effects logistic regression. One-to-one matching with replacement, and Euclidean distance as matching criterion, is used. For TMLE both the propensity score and outcome model is estimated by Bayesian additive regression trees (BART; <ref type="bibr" target="#b4">Chipman et al., 2010)</ref>. BART is a nonparametric regression method that have been shown to perform well in finite samples <ref type="bibr" target="#b12">(Hill, 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Implementation details</head><p>MMPC and MMHC are computed using the functions mmpc and mmhc in the package bnlearn <ref type="bibr" target="#b35">(Scutari, 2010)</ref>. The argument optimized is set to FALSE and for MMHC score="aic". RF is computed using the function randomForest in the package randomForest <ref type="bibr" target="#b17">(Liaw and Wiener, 2002)</ref>. Variables with importance larger than 25% of the largest importance are included in the estimated set. LASSO is computed using the function cv.glmnet in the package glmnet <ref type="bibr" target="#b8">(Friedman, Hastie, and Tibshirani, 2010)</ref> and variables with nonzero coefficients at lambda.1se are included in the estimated set. The LASSO model is specified to always include main effects, quadratic terms for the continuous covariates and all two-way interactions. T and the discrete covariates are treated as factors for all four methods. For MMPC and MMHC continuous covariates and Y are first discretized (using discretize with method="quantile" in bnlearn) and subsequently treated as factors. For RF, LASSO and when estimating the propensity score, continuous variables are not discretized. If S = ∅, where S is an estimate of the target covariate subset S, the propensity score is estimated as the proportion of treated units. The ACE estimators are evaluated with S equal to each of the following covariate sets: X, X →T , Q →T , X →Y , Z →Y , X →T,Y and W →Y . PSM is performed using the function Match in the package Matching <ref type="bibr" target="#b36">(Sekhon, 2011)</ref>. TMLE estimates are computed using the functions bartMachine in package bartMachine <ref type="bibr" target="#b15">(Kapelner and Bleich, 2016)</ref> and tmle in package tmle <ref type="bibr" target="#b11">(Gruber and van der Laan, 2012)</ref>, default argument values are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Simulation Results</head><p>The results from the covariate selection algorithms are summarized in Tables 1-24 in Appendix B, where selection success rates and median cardinality of the selected sets are presented. Three definitions of success are used for the selected subset, S; i) unconfoundedness holds, i.e., Y (1), Y (0) ⊥ ⊥ T | S, ii) the target subset is included in the selected subset (S ⊆ S), and iii) equal subsets (S = S). The tables also include empirical bias, standard deviation and MSE for the ACE estimation as well as confidence interval coverage, mean width and mean lower and upper confidence interval limits. Results for Setting 1, n = 2000, are illustrated in Figures <ref type="figure">3</ref><ref type="figure">4</ref><ref type="figure" target="#fig_1">5</ref>. Results for W →Y are omitted throughout due to the fact that when the causal structure is estimated W →Y and X →Y turn out to be virtually identical.</p><p>In Setting 1, when the sample size is relatively small (n = 500, n = 1000) neither of the network algorithms succeed in selecting only sets that uphold unconfoundedness. MMPC has in these cases higher rates of success than MMHC. For the linear outcome model, when n = 500 the success rates for MMPC and MMHC are in the range <ref type="bibr">[63.6, 99.2] and [31.6, 88.2]</ref>, respectively, and for n = 1000 the ranges are [94.9, 100.0] and <ref type="bibr">[66.1, 98.8</ref>]. However, when the sample size is relatively large (n = 2000, n = 10000) virtually all selected sets have 100% success rate in upholding unconfoundedness (the exception is the Q →T sets with success rates 99.8 when n = 2000), and this is the case for both network algorithms. For the larger sample sizes MMPC and MMHC not only select sets that uphold unconfoundedness, they frequently manage to exactly select the target subsets.</p><p>For the binary outcome model, when n = 500 the success rates for MMPC and MMHC are in the range <ref type="bibr">[57.3, 97.7] and [29.0, 85.4]</ref>, respectively, and for n = 1000 the ranges are <ref type="bibr">[92.8, 100.0] and [70.7, 99.2]</ref>. For the larger sample sizes the results are similar to the linear outcome case. For the nonlinear outcome model, when n = 500 the success rates for MMPC and MMHC are in the range [83.2, 99.9] and <ref type="bibr">[43.6, 99.7]</ref>, respectively, and for n = 1000 the success rates are 100.0 for all sets selected by MMPC and in the range [96.9, 100.0] for MMHC. For the larger sample sizes all sets have 100% success rate and both methods frequently manage to exactly select the target subsets.</p><p>RF performs similar to MMPC and MMHC with the important exception that it is, regardless of outcome model, unable to select the minimal target subsets Q →T and Z →Y with any desirable accuracy. Also, for the nonlinear outcome model case, RF fails when estimating the set X →Y .</p><p>Due to the fact that implementing the LASSO in a high-dimensional covariate space was much more time consuming than the other three methods, the investigation of LASSO is limited to n = 500, 1000, 2000. LASSO is the only method that is able, regardless of sample size, to select sets that virtually always uphold unconfoundedness. However, sets selected by LASSO have much higher cardinality than the sets selected by the other three methods. Thus the dimension reduction is not as pronounced as with the other methods and the exact target sets are rarely selected. When n = 500, 1000, LASSO performs better than the other methods, while for the larger sample sizes sets selected by any of the network methods often result in smaller MSE than sets selected by LASSO.</p><p>The simulation settings for the linear and binary outcome cases in this paper are similar to the linear and binary outcome cases in <ref type="bibr" target="#b26">Persson et al. (2017)</ref> which allow us to make some comparisons of the methods used here and the kernel smoothing method used in the latter paper. Note that the kernel smoothing procedure is very computer intensive and is not feasible for the relatively high dimensions studied in this paper. For n = 1000 (the largest sample size studied in <ref type="bibr" target="#b26">Persson et al. (2017)</ref>) and only 10 covariates in X kernel smoothing performs marginally better than MMPC does (when n = 1000 and 100 covariates), in terms of success rates in upholding unconfoundedness, but MMPC manages to exactly retrieve the target subsets much more frequently. MMHC on the other hand is outperformed by kernel smoothing for such a relatively small sample size.</p><p>When PSM is used, conditioning on one of the sets X, X →T or X →T,Y results in a considerable larger bias and variance than conditioning on any of the other sets (where success rates of upholding unconfoundedness are 100%). These results corroborates the results for PSM in <ref type="bibr" target="#b26">Persson et al. (2017)</ref> in so far that, with very few exceptions, conditioning on Q →T results in lower MSE than conditioning on X →T but that conditioning on X →Y or Z →Y in turn results in lower MSE than conditioning on Q →T . However, as pointed out by an anonymous referee, these results are probably, at least partly, driven by the fact that PSM with main effects logistic regression is a poor estimation strategy, and not by the selected sets per se. Consequently, when TMLE together with BART is used, first of all we see that MSEs generally are much lower than when using PSM with logistic regression. Secondly, we see that in many cases reducing the covariate set prior to estimating ACE results in higher MSE compared to using X. Still, for large sample sizes, conditioning on X →Y results in a reduction in MSE compared to conditioning on X and conditioning on X →T,Y results in reduced or equal MSE compared to X.</p><p>In Setting 2, when unconfoundedness does not hold given X the success rates are, as expected, very low. In Setting 2 there are two ways in which a set can fail to uphold unconfoundedness: 1) if it does not include X 4 and/or 2) if it includes X 9 . For the larger sample sizes all methods select sets that include both X 4 and X 9 or include too few covariates, thus failing the unconfoundedness assumption. However, for PSM, except for X →T,Y , the sets selected by MMPC or MMHC often result in smaller bias and MSE compared to bias and MSE </p><formula xml:id="formula_21">Y t ⊥ T |S ^S ⊆ S ^S = S X ^→T Q ^→T X ^→Y Z ^→Y X ^→TY X ^→T Q ^→T X ^→Y Z ^→Y X ^→TY X ^→T Q ^→T X ^→Y Z ^→Y X ^→TY X ^→T Q ^→T X ^→Y Z ^→Y X ^→TY</formula><formula xml:id="formula_22">; i) unconfoundedness holds (Y t ⊥ T | Ŝ), ii</formula><p>) the target subset is included in the selected subset (S ⊆ Ŝ) and iii) equal subsets (S = Ŝ). The selected covariates sets are: covariates predicting treatment X →T , covariates predicting outcome X →Y , covariates predicting both treatment and outcome  when conditioning on X. For TMLE it is only Q →T , X →Y and Z →Y that results in reduced MSE compared to X for n = 10000. Thus, in a situation where we are not perfectly sure that unconfoundedness is upheld when conditioning on X, at least for PSM, it does not seem to be harmful to use this confounder selection procedure for reducing the covariate set.</p><formula xml:id="formula_23">Q →T ⊆ X →T , Z →Y ⊆ X →Y and X →T,Y = X →T ∪ X →Y . X X ^→T Q ^→T X ^→Y Z ^→Y X ^→TY X X ^→T Q ^→T X ^→Y Z ^→Y X ^→TY 0.025 0.050 0.075 0.0 0.1 0.2 MSE |Bias| PSM TMLE Linear X X ^→T Q ^→T X ^→Y Z ^→Y X ^→TY X X ^→T Q ^→T X ^→Y Z ^→Y X ^→TY 0.</formula><formula xml:id="formula_24">Q →T ⊆ X →T , Z →Y ⊆ X →Y and X →T,Y = X →T ∪ X →Y .</formula><p>As mentioned in Section 5.3 implementing LASSO was more computer intensive than any of the methods MMPC, MMHC or RF. In Table <ref type="table" target="#tab_1">1</ref> the computational times (measured by system.time) for n = 10000 when only running the step where X →T is estimated from X, i.e., mmpc, mmhc, cv.glmnet and randomForest are each run only once. Timings differ slightly between runs but the example in Table <ref type="table" target="#tab_1">1</ref> give an accurate description of the difference between methods. The computations were run on a MacBook Pro (Early 2015) with 3,1 GHz Intel Core i7 Processor and 16 GB 1867 MHz DDR3 Memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Data Analysis</head><p>Previous studies have indicated that children delivered by C-section are at an increased risk of developing wheezing and asthma (see, e.g., <ref type="bibr" target="#b21">Magnus et al., 2011;</ref><ref type="bibr" target="#b1">Bråbäck et al., 2013)</ref>. Here, we select covariates for estimating the ACE of being delivered by C-section on, before the age of four, being prescribed medication commonly used to treat asthma. Using record linkage register data from the Umeå SIMSAM Lab <ref type="bibr" target="#b18">(Lindgren, Nilsson, de Luna, and Ivarsson, 2016)</ref> all children being the result of first-time mothers giving birth to full term (37 or more full weeks of gestation) singleton live offspring in the year 2006 in Sweden were identified (n = 41857). From this population the subset of children being delivered by C-section or non-instrumental vaginal delivery, who were residents in Sweden during the whole study period, were offspring of two native Swedish parents and had no major malformations reported at birth were selected (n = 23817). Using data from the Swedish Prescribed Drug Registry all children being prescribed drugs with one of the ATC-codes (WHO Collaborating Centre for Drug Statistics Methodology, 2014) R03AC, R03AK, R03BA, R03BC, R03CC, R03DC (hereinafter "asthma drugs") at least once before the age of four were identified.</p><p>As potential confounders we included 24 variables, listed in Table <ref type="table" target="#tab_22">25</ref> in Appendix C. All observations with missing data on any of the covariates were excluded (n = 2950), resulting in a complete cases sample containing n = 20867 children. The proportion of children delivered by C-section was 20.9% and 39.7% of the children had been prescribed asthma drugs at least once before the age of four. MMPC and MMHC resulted in equal sets, namely: X →T ={Maternal BMI at first antenatal visit, Gestational age}, Q →T ={Maternal BMI at first antenatal visit}, X →Y ={Maternal asthma, Paternal asthma drugs prescription within 6 months before delivery, Offspring sex, Birth place}, Z →Y ={Offspring sex, Birth place}, X →T,Y = X →T ∪ X →Y . The DAGs estimated by MMHC are given in Figures <ref type="figure">1</ref><ref type="figure">2</ref><ref type="figure">3</ref><ref type="figure">4</ref><ref type="figure" target="#fig_1">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>in Appendix C (Cytoscape was used to visualize the graphs <ref type="bibr" target="#b37">(Shannon et al., 2003)</ref>). PSM and TMLE were implemented as described in Section 5.2 and estimates of the ACE, i.e., risk difference, are presented in Table <ref type="table" target="#tab_2">2</ref>. For PSM the distributions of the estimated propensity scores for the different treatment groups were similar and exact matches were found when controlling for all sets except X (where a caliper of 0.1 standard deviations of the estimated propensity score was used). The estimate based on raw data, not controlling for any confounders, suggest on average an 3.5% risk increase in being prescribed asthma drugs before the age of four if you are delivered by C-section compared to what would be the risk in case of non-instrumental vaginal delivery. For both PSM and TMLE, controlling for any of the selected covariate sets results in slightly lower point estimates, although all still statistically significant. Assuming that we have unconfoundedness given the 24 potential confounders we started with, and taking into consideration the results from the simulation study where controlling for X →Y often was the best choice, the results in Table <ref type="table" target="#tab_2">2</ref> suggest that the ACE lies in the range [0.012, 0.047]. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>In this paper, we have introduced the network algorithms MMPC and MMHC in conjunction with the covariate selection algorithms in de Luna et al. ( <ref type="formula">2011</ref>) as methods for confounder selection in causal inference when the true causal structure is not known. Given that unconfoundedness holds when conditioning on X, the approach was shown, for sufficiently large sample sizes, to accurately estimate certain target covariate subsets. Compared to RF and LASSO, the network algorithms were preferable both with regard to estimation of the ACE and with regard to computational efficiency. However, it is very likely that the performance of RF and LASSO could be improved upon by carefully selecting their respective tuning parameter (variable importance cut-off and regularization parameter). Also, as expected, none of the four methods investigated were able to select covariate sets that uphold unconfoundedness when the true causal structure included a collider of unmeasured causes of the outcome and treatment. This is due to the fact that the methods cannot distinguish association from causation and thus a collider will frequently be included in the selected covariate set. How much one in practice should worry about the M -bias scenario exemplified in Setting 5.1.2 is debatable. <ref type="bibr" target="#b33">Rubin (2009)</ref>, <ref type="bibr" target="#b19">Liu et al. (2012)</ref> and <ref type="bibr" target="#b7">Ding and Miratrix (2015)</ref> suggest that it is rather uncommon and might be more of mathematical than practical interest. Moreover, the simulation results show that even if M -bias is present reducing the the dimension of the covariate set might still be beneficial.</p><p>The real data analysis consisted of 20867 observations and 24 covariates and this relatively high dimensional data proved to be more than feasible for MMPC and MMHC. 0.0 0.0 1.5 -1.575 -0.065 0.0 0.6 -1.186 -0.600</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 23</head><p>Setting 2, binary outcome model, n = 500, 1000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 3Simulation results for Setting 1, n = 2000. Selection success rates (%) for the covariate sets ( Ŝ) selected by MMPC, MMHC, RF or LASSO. Definitions of success are; i) unconfoundedness holds (Y t ⊥ T | Ŝ), ii) the target subset is included in the selected subset (S ⊆ Ŝ) and iii) equal subsets (S = Ŝ). The selected covariates sets are: covariates predicting treatment X →T , covariates predicting outcome X →Y , covariates predicting both treatment and outcome Q →T ⊆ X →T , Z →Y ⊆ X →Y and X →T,Y = X →T ∪ X →Y .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. DAG resulting from MMHC, X →T .</figDesc><graphic coords="43,154.73,56.69,289.14,490.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 .→YFigure 7 .→YFigure 8 .→TFigure 9 .</head><label>6789</label><figDesc>Figure 6. DAG resulting from MMHC, X 1 →Y</figDesc><graphic coords="44,154.73,56.69,289.14,495.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="45,154.73,56.69,289.14,492.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Simulation results for Setting 1, n = 2000. Absolute bias and MSE are for the ACE estimated using different sets of covariates as selected by MMPC and either propensity score matching (PSM) or targeted maximum likelihood estimation (TMLE). The different covariates sets are: X, covariates predicting treatment X →T , covariates predicting outcome X →Y , covariates predicting both treatment and outcome</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Binary</cell><cell></cell><cell></cell><cell cols="2">Nonlinear</cell></row><row><cell></cell><cell>0.100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>X</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.06</cell><cell></cell><cell></cell><cell>X ^→T</cell></row><row><cell></cell><cell>0.075</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.05</cell><cell></cell><cell></cell></row><row><cell>|Bias|</cell><cell>0.050</cell><cell></cell><cell></cell><cell></cell><cell>|Bias|</cell><cell>0.04</cell><cell></cell><cell></cell><cell>X ^→TY</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>X</cell><cell>Q ^→T Z ^→Y</cell><cell></cell></row><row><cell></cell><cell>0.025</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.03</cell><cell>X ^→Y Z ^→Y Q ^→T</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">X ^→Y X ^→TY</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.02</cell><cell></cell><cell></cell></row><row><cell></cell><cell>000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>X ^→T</cell><cell></cell></row><row><cell></cell><cell>0.00</cell><cell>0.01</cell><cell>0.02</cell><cell>0.03</cell><cell>0.04</cell><cell>0.0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">MSE</cell><cell></cell><cell></cell><cell cols="2">MSE</cell></row><row><cell></cell><cell></cell><cell></cell><cell>PSM</cell><cell>TMLE</cell><cell></cell><cell></cell><cell>PSM</cell><cell>TMLE</cell></row><row><cell></cell><cell></cell><cell cols="2">Figure 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Computation time in seconds (and relative to MMPC) for n = 10000 when only running the step were X T is estimated from {X, T }, i.e., mmpc, mmhc, cv.glmnet and randomForest are each run only once.</figDesc><table><row><cell cols="2">Method Seconds</cell><cell>Rel</cell></row><row><cell>MMPC</cell><cell>1.1</cell><cell>1.0</cell></row><row><cell>MMHC</cell><cell>2.2</cell><cell>2.0</cell></row><row><cell>RF</cell><cell>78.2</cell><cell>71.1</cell></row><row><cell>LASSO</cell><cell cols="2">2114.3 1922.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Estimates of the ACE. The cardinalities of the covariate sets (#), ACE estimates ( β), standard errors (SE; Abadie-Imbens for PSM and influence-curved based for TMLE), lower (CIL) and upper (CIU) limits of 95% confidence intervals.</figDesc><table><row><cell>Ŝ</cell><cell>#</cell><cell>β</cell><cell>SE</cell><cell>CIL</cell><cell>CIU</cell></row><row><cell>∅</cell><cell cols="5">0 0.035 0.008 0.019 0.052</cell></row><row><cell></cell><cell></cell><cell></cell><cell>PSM</cell><cell></cell><cell></cell></row><row><cell>X</cell><cell cols="5">24 0.023 0.010 0.004 0.042</cell></row><row><cell>X →T</cell><cell cols="5">2 0.026 0.009 0.009 0.043</cell></row><row><cell>Q →T</cell><cell cols="5">1 0.031 0.008 0.015 0.048</cell></row><row><cell>X →Y</cell><cell cols="5">4 0.029 0.008 0.013 0.045</cell></row><row><cell>Z →Y</cell><cell cols="5">2 0.031 0.008 0.015 0.048</cell></row><row><cell>X →T,Y</cell><cell cols="5">6 0.021 0.009 0.004 0.038</cell></row><row><cell></cell><cell></cell><cell></cell><cell>TMLE</cell><cell></cell><cell></cell></row><row><cell>X</cell><cell cols="5">24 0.024 0.011 0.003 0.044</cell></row><row><cell>X →T</cell><cell cols="5">2 0.027 0.009 0.009 0.045</cell></row><row><cell>Q →T</cell><cell cols="5">1 0.032 0.009 0.014 0.049</cell></row><row><cell>X →Y</cell><cell cols="5">4 0.029 0.009 0.012 0.047</cell></row><row><cell>Z →Y</cell><cell cols="5">2 0.031 0.009 0.014 0.048</cell></row><row><cell>X →T,Y</cell><cell cols="5">6 0.025 0.010 0.006 0.044</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc>Setting 1, linear outcome model, n = 500, 1000. The proportion (%) of times the selected subset, S, satisfies three conditions of unconfoundedness and the median cardinality of S (#). Average bias (Bias), standard deviation (SD) and mean square error (MSE) from estimating ACE with PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc>Setting 1, linear outcome model, n = 2000, 10000. The proportion (%) of times the selected subset, S, satisfies three conditions of unconfoundedness and the median cardinality of S (#). Average bias (Bias), standard deviation (SD) and mean square error (MSE) from estimating ACE with PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc>Setting 1, binary outcome model, n = 500, 1000. The proportion (%) of times the selected subset, S, satisfies three conditions of unconfoundedness and the median cardinality of S (#). Average bias (Bias), standard deviation (SD) and mean square error (MSE) from estimating ACE with PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6</head><label>6</label><figDesc>Setting 1, binary outcome model, n = 2000, 10000. The proportion (%) of times the selected subset, S, satisfies three conditions of unconfoundedness and the median cardinality of S (#). Average bias (Bias), standard deviation (SD) and mean square error (MSE) from estimating ACE with PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7</head><label>7</label><figDesc>Setting 1, nonlinear outcome model, n = 500, 1000. The proportion (%) of times the selected subset, S, satisfies three conditions of unconfoundedness and the median cardinality of S (#). Average bias (Bias), standard deviation (SD) and mean square error (MSE) from estimating ACE with PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8</head><label>8</label><figDesc>Setting 1, nonlinear outcome model, n = 2000, 10000. The proportion (%) of times the selected subset, S, satisfies three conditions of unconfoundedness and the median cardinality of S (#). Average bias (Bias), standard deviation (SD) and mean square error (MSE) from estimating ACE with PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9</head><label>9</label><figDesc>Setting 2, linear outcome model, n = 500, 1000. The proportion (%) of times the selected subset, S, satisfies three conditions of unconfoundedness and the median cardinality of S (#). Average bias (Bias), standard deviation (SD) and mean square error (MSE) from estimating ACE with PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10</head><label>10</label><figDesc>Setting 2, linear outcome model, n = 2000, 10000. The proportion (%) of times the selected subset, S, satisfies three conditions of unconfoundedness and the median cardinality of S (#). Average bias (Bias), standard deviation (SD) and mean square error (MSE) from estimating ACE with PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11</head><label>11</label><figDesc>Setting 2, binary outcome model, n = 500, 1000. The proportion (%) of times the selected subset, S, satisfies three conditions of unconfoundedness and the median cardinality of S (#). Average bias (Bias), standard deviation (SD) and mean square error (MSE) from estimating ACE with PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12</head><label>12</label><figDesc>Setting 2, binary outcome model, n = 2000, 10000. The proportion (%) of times the selected subset, S, satisfies three conditions of unconfoundedness and the median cardinality of S (#). Average bias (Bias), standard deviation (SD) and mean square error (MSE) from estimating ACE with PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 15</head><label>15</label><figDesc>Setting 1, linear outcome model, n = 500, 1000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 16</head><label>16</label><figDesc>Setting 1, linear outcome model, n = 2000, 10000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 17</head><label>17</label><figDesc>Setting 1, binary outcome model, n = 500, 1000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 18</head><label>18</label><figDesc>Setting 1, binary outcome model, n = 2000, 10000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 19</head><label>19</label><figDesc>Setting 1, nonlinear outcome model, n = 500, 1000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 20</head><label>20</label><figDesc>Setting 1, nonlinear outcome model, n = 2000, 10000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 21</head><label>21</label><figDesc>Setting 2, linear outcome model, n = 500, 1000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 22</head><label>22</label><figDesc>Setting 2, linear outcome model, n = 2000, 10000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 24</head><label>24</label><figDesc>Setting 2, binary outcome model, n = 2000, 10000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 25</head><label>25</label><figDesc>Setting 2, nonlinear outcome model, n = 500, 1000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 26</head><label>26</label><figDesc>Setting 2, nonlinear outcome model, n = 2000, 10000. The proportion (%) of times the selected subset, S, upholds unconfoundedness and coverage probability (CP), width of confidence interval (CIW) as well as average lower and upper limits (CIL, CIU) of confidence intervals when estimating ACE by PSM and TMLE.</figDesc><table><row><cell>PSM</cell><cell>TMLE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 27</head><label>27</label><figDesc>Distribution of demographic and perinatal factors by mode of delivery. The first antenatal visit takes place around pregnancy week 12. Median disposable income in the total Swedish population was 184700SEK in the year 2005.</figDesc><table><row><cell>Covariate</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by the <rs type="funder">Swedish Research Council</rs> (Dnr: <rs type="grantNumber">2013-672</rs>). The simulations were performed on resources provided by the <rs type="institution" subtype="infrastructure">Swedish National Infrastructure for Computing (SNIC) at High Performance Computing Centre North</rs> (<rs type="grantNumber">HPC2N</rs>). The <rs type="institution">Umeå SIMSAM Lab data infrastructure</rs> used in this study was developed with support from the <rs type="funder">Swedish Research Council</rs> and by strategic funds from <rs type="funder">Umeå University</rs>. The author is grateful to the <rs type="institution">Co-Editor</rs>, the Associate Editor, and the referee for their helpful and constructive comments.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_g3MpCYe">
					<idno type="grant-number">2013-672</idno>
				</org>
				<org type="funding" xml:id="_Nwf5AkF">
					<idno type="grant-number">HPC2N</idno>
				</org>
			</listOrg>

			<listOrg type="infrastructure">
				<org type="infrastructure">					<orgName type="extracted">Swedish National Infrastructure for Computing (SNIC) at High Performance Computing Centre North</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Appendix A: Proof of Theorem 1 in Section 4.4</p><p>Proof. Let G A,B denote a graph involving only the variables in the sets A and B. Consider the graphs G X,T , G X →T ,Y (t) , G X,Y (t) , G X →Y ,T and G X →T ,Y ,Y (t) , t = 0, 1.</p><p>It follows from C3 that the above graphs are all DAGs since each of them is a subgraph of a DAG. It follows from C4-C5 that there exist joint probability distributions p X,T , p X →T ,Y (t) , p X,Y (t) , p X →Y ,T and p X →T ,Y ,Y (t) , t = 0, 1, such that the local Markov property holds and which are faithful to the respective subgraph.</p><p>Then, together with conditions C1-C2 and C6, it follows from Theorem 3 in <ref type="bibr" target="#b42">Tsamardinos et al. (2006)</ref> that if in the estimated skeleton of G X,T , produced by MMPC with input variables {X, T }, there is an edge connecting T to X j ∈ X then X j is a parent of T . Hence, X →T = X →T . Similarly, if in the estimated skeleton of G X →T ,Y (t) , t = 0, 1, produced by MMPC with input variables {X →T , Y |T = t}, there is an edge connecting</p><p>Finally, according to the same reasoning as above using MMPC with input variables (X →T,Y , Y |T = t) results in W →Y = W →Y Appendix B: Simulation results from Section 5.3 </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Large sample properties of matching estimators for average treatment effects</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Imbens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="235" to="267" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Confounding with familial determinants affects the association between mode of delivery and childhood asthma medication-a national cohort study</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bråbäck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ekéus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hjern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Allergy, Asthma &amp; Clinical Immunology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Optimal structure identification with greedy search</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="507" to="554" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BART: Bayesian additive regression trees</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Chipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mcculloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="266" to="298" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Conditional independence in statistical theory</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dawid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Covariate selection for the nonparametric estimation of an average treatment effect</title>
		<author>
			<persName><forename type="first">X</forename><surname>De Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Waernbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="861" to="875" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<author>
			<persName><forename type="first">P</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Miratrix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">To adjust or not to adjust? Sensitivity analysis of M-bias and Butterflybias</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="41" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Regularization paths for generalized linear models via coordinate descent</title>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning Bayesian network structure from massive datasets: the &quot;sparse candidate&quot; algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Peér</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence</title>
		<meeting>the Fifteenth conference on Uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="206" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Quantifying biases in causal models: Classical confounding vs collider-stratification bias</title>
		<author>
			<persName><forename type="first">S</forename><surname>Greenland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Epidemiology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="300" to="306" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">tmle: An R package for targeted maximum likelihood estimation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Van Der Laan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bayesian nonparametric modeling for causal inference</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="217" to="240" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">CovSelHigh: Model-Free Covariate Selection in High Dimensions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Häggström</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>R package version 1.0.0</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">CovSel: An R package for covariate selection when estimating average causal effects</title>
		<author>
			<persName><forename type="first">J</forename><surname>Häggström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Persson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Waernbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>De Luna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">bartMachine: Machine learning with Bayesian additive regression trees</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kapelner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bleich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Why propensity scores should not be used for matching</title>
		<author>
			<persName><forename type="first">G</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nielsen</surname></persName>
		</author>
		<ptr target="http://j.mp/1sexgVw" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Classification and regression by randomForest</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wiener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">R News</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="18" to="22" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Data resource profile: Swedish microdata research from childhood into lifelong health and welfare (Umeå SIMSAM Lab)</title>
		<author>
			<persName><forename type="first">U</forename><surname>Lindgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>De Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ivarsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Epidemiology</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1075" to="1075" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Implications of M bias in epidemiologic studies: A simulation study</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Brookhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schneeweiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Setoguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Epidemiology</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page" from="938" to="948" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Estimating high-dimensional intervention effects from observational data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Maathuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kalisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="3133" to="3164" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Delivery by Cesarean section and early childhood respiratory symptoms and disorders: the Norwegian mother and child cohort study</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Magnus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Håberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stigum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nafstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vangen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nystad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Epidemiology</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="page" from="1275" to="1285" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the application of probability theory to agricultural experiments, essay on principles. Roczniki nauk Rolczych X, 1-51</title>
		<author>
			<persName><forename type="first">J</forename><surname>Neyman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Polish. English translation by D.M. Dabrowska and T</title>
		<imprint>
			<date type="published" when="1923">1923</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="465" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Causal diagrams for empirical research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Causality</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
	<note>Second edition</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Letter to the editor</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1415" to="1416" />
			<date type="published" when="2009">2009b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Data-driven algorithms for dimension reduction in causal inference</title>
		<author>
			<persName><forename type="first">E</forename><surname>Persson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Häggström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Waernbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>De Luna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="280" to="292" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">R: A Language and Environment for Statistical Computing</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Estimating causal effects of treatments in randomized and nonrandomized studies</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="688" to="701" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Formal modes of statistical inference for causal effects</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Planning and Inference</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="279" to="292" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The design versus the analysis of observational studies for causal effects: Parallels with the design of randomized trials</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="20" to="36" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Author&apos;s reply (to Ian Shrier&apos;s letter to the editor)</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2741" to="2742" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">For objective causal inference, design trumps analysis</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="808" to="840" />
			<date type="published" when="2008">2008b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Author&apos;s reply (to Judea Pearl&apos;s and Arvid Sjölander&apos;s letters to the editor)</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1420" to="1423" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Variable selection for confounder control, flexible modeling and collaborative targeted minimum loss-based estimation in causal inference</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Schnitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Lok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gruber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Biostatistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="97" to="115" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning Bayesian networks with the bnlearn R package</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scutari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multivariate and propensity score matching software with automated balance optimization: the Matching package for R</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Sekhon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1" to="52" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Cytoscape: A software environment for integrated models of biomolecular interaction networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Shannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Markiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ozier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Baliga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schwikowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ideker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2498" to="2504" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Letter to the editor</title>
		<author>
			<persName><forename type="first">I</forename><surname>Shrier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2740" to="2741" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Letter to the editor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sjölander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1416" to="1420" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<title level="m">Causation, Prediction, and Search</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The max-min hill-climbing Bayesian network structure learning algorithm</title>
		<author>
			<persName><forename type="first">I</forename><surname>Tsamardinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Aliferis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="31" to="78" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Targeted maximum likelihood learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Van Der Laan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Biostatistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A new criterion for confounder selection</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Vanderweele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shpitser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="1406" to="1413" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">ATC Classification Index With DDDs</title>
	</analytic>
	<monogr>
		<title level="m">Collaborating Centre for Drug Statistics Methodology</title>
		<meeting><address><addrLine>Oslo, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>WHO Collaborating Centre for Drug Statistics Methodology</publisher>
			<date type="published" when="2014">2014. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
