<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IDENTIFIABILITY IN CAUSAL BAYESIAN NETWORKS: A GENTLE INTRODUCTION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2001-06-11">Jun 11 2001</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Marco</forename><surname>Valtorta</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of South Carolina</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yimin</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of South Carolina</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">IDENTIFIABILITY IN CAUSAL BAYESIAN NETWORKS: A GENTLE INTRODUCTION</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0196-9722 print=1087-6553</idno>
						<imprint>
							<date type="published" when="2001-06-11">Jun 11 2001</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1080/01969720802039594</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this article we describe an important structure used to model causal theories and a related problem of great interest to semi-empirical scientists. A causal Bayesian network is a pair consisting of a directed acyclic graph (called a causal graph) that represents causal relationships and a set of probability tables, that together with the graph specify the joint probability of the variables represented as nodes in the graph. We briefly describe the probabilistic semantics of causality proposed by Pearl for this graphical probabilistic model, and how unobservable variables greatly complicate models and their application. A common question about causal Bayesian networks is the problem of identifying casual effects from nonexperimental data, which is called the identifability problem. In the basic version of this problem, a semi-empirical scientist postulates a set of causal mechanisms and uses them, together with a probability distribution on the observable set of variables in a domain of interest, to predict the effect of a manipulation on some variable of interest. We explain this problem, provide several examples, and direct the readers to recent work that provides a solution to the problem and some of its extensions. We assume that the Bayesian network structure is given to us and do not address the problem of learning it from data and the related statistical inference and testing issues.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MOTIVATION</head><p>Flash back to the late 1950s. Evidence was mounting that smoking was bad for one's health. In particular, some researchers postulated a causal link between smoking and lung cancer. Such a model could be represented by the graph of Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>The intuitive meaning of the model in Fig. <ref type="figure" target="#fig_0">1</ref> is that there is a mechanism that relates cigarette smoking (node X) and lung cancer (node Y ), in the sense that the probability of a person getting lung cancer is affected by that person smoking cigarettes. All that could be observed was a strong correlation between smoking and lung cancer, but the public health community of the 1950s suspected that the correlation was a manifestation of a causal link, and that therefore a manipulation of the smoking variable, namely by making smoking less pervasive, would lead to a reduction of the incidence of lung cancer in the population.</p><p>The model of Fig. <ref type="figure" target="#fig_0">1</ref>, however, was not universally accepted, and in a way that has a profound impact on the expected value of public health policy efforts directed at reducing smoking in the general population. The distinguished British statistician R. A. Fisher suggested that this model was a manifestation of ''an error . . . of an old kind, in arguing from correlation to causation,'' and proposed that the correlation between smoking and lung cancer could be explained by a genetic predisposition to smoking and lung cancer, as described in Fig. <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q1</head><p>Since the genotype (represented by node U in the figure) was not observable at the time of Fisher's work, it appeared impossible to conclude that reducing smoking would have a positive effect on the prevalence of lung cancer. (The links from U to X and Y are drawn dashed to emphasize that U is unobservable.) By accepting Fisher's model, we would have to conclude that the effect of smoking on lung cancer is unidentifiable; i.e., it cannot be determined from statistics derived solely from variables that are in the model and that can be observed (such as X and Y ). Incidentally, studies involving identical twins (who presumably would have the same genetic predisposition to both smoking and lung cancer) were carried out in attempt to identify the causal effect of smoking on lung cancer, but at least Fisher was unconvinced that they settled the matter <ref type="bibr" target="#b1">(Fisher 1958)</ref>. Even in these very simple models, we can observe two important features of the causal graphs that we will formalize as causal Bayesian networks in the remainder of this article. First, the models relate variables (genotype, smoking, lung cancer) represented as nodes in a directed acyclic graph through directed edges or links (such as the edge from smoking to lung cancer) indicating a causal influence. The links from U to X and Y are drawn dashed to emphasize that U is unobservable. Second, in the first model, the joint probability of the variables can be represented by the product of the prior probability of smoking times the conditional probability of lung cancer given smoking. In the second model, the joint probability of genotype, smoking, and lung cancer can be represented by the product of the prior probability of the genotype, times the conditional probability of smoking given the genotype, times the conditional probability of the genotype and smoking. This decomposition is allowed by the fundamental rule of probability in the case of a joint distribution of two and three variables.</p><p>In the next section we define formally the key notion of causal Bayesian network. Following that, we discuss the concept of intervention and define an identifiability problem. We then present a proof of unidentifiability for a particular causal Bayesian network and use different versions of smoking-lung cancer causal models to show why the identifiability problem is interesting and how it can be solved mathematically. Our conclusions consist mainly of a survey of the recent literature on the topic.</p><p>Disclaimers are in order. We do not claim that any of our specific examples are reflective of good domain knowledge. We are not interested in validating or repudiating causal assumptions specific to a domain. We assume that the domain knowledge is obtained somehow before our analysis. The framework described in this article is limited to answering the question of whether a given set of assumptions is sufficient for quantifying causal effects from non-experimental data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CAUSAL BAYESIAN NETWORKS</head><p>A Bayesian network (BN) is a graphical representation of the joint probability distribution of a set of discrete variables. The representation consists of a directed acyclic graph (DAG), prior probability tables for the nodes in the DAG that have no parents and conditional probabilities tables (CPTs) for the nodes in the DAG given their parents. As an example, consider the network in Fig. <ref type="figure" target="#fig_2">3</ref>.</p><p>More formally, a Bayesian network is a pair composed of: (1) a multivariate probability distribution over n random variables in the set <ref type="figure"></ref>and<ref type="figure"></ref> (2) a directed acyclic graph (DAG) whose nodes are in one-to-one correspondence with V 1 , . . . ,V n . (Therefore, for the sake of convenience, we do not distinguish the nodes of a graph from variables of the distribution.)</p><formula xml:id="formula_0">V ¼ V 1 , . . . ,V n ,</formula><p>Bayesian networks allow specification of the joint probability of a set of variables of interest in a way that emphasizes the qualitative aspects of the domain. The defining property of a Bayesian network is that the conditional probability of any node, given any subset of non-descendants, is equal to the conditional probability of that same node given the parents alone. The Chain rule for Bayesian networks <ref type="bibr" target="#b12">(Neapolitan 1990</ref>) follows from the preceding definition: Let PðV i jpðV i ÞÞ be the conditional probability of V i given its parents. (If there are no parents for V i , let this be P(V i )). If all the probabilities involved are nonzero, then PðV Þ ¼ Q v2V PðvjpðvÞÞ.</p><p>Three features of Bayesian networks are worth mentioning. First, the directed graph constrains the possible joint probability distributions represented by a Bayesian network. For example, in any distribution consistent with the graph of Fig. <ref type="figure" target="#fig_2">3</ref>, D is conditionally independent of A given B and C. Also, E is conditionally independent of any subset of the other variables given C.</p><p>Second, the explicit representation of constraints about conditional independence allows a substantial reduction in the number of parameters to be estimated. In the example, assume that the possible values of the five variables are as shown in Fig. <ref type="figure" target="#fig_2">3(b)</ref>. Then, the joint probability table</p><formula xml:id="formula_1">P(A, B, C, D, E ) has 2 Â 3 Â 2 Â 4 Â 4 ¼ 192 entries.</formula><p>It would be very difficult to assess 191 independent parameters. However, the independence constraints encoded in the graph permit the factorization P(A, B, C, D, E ) ¼ P(A) Â P(BjA) Â P(CjA) Â P(DjB, C) Â P(EjC), which reduces the number of parameters to be estimated to</p><formula xml:id="formula_2">1 þ 4 þ 2 þ 18 þ 6 ¼ 31.</formula><p>The second term in the sum is the table for the conditional probability of B given A. This probability is shown in Fig. <ref type="figure" target="#fig_2">3(c)</ref>; note that there are only four independent parameters to be estimated since the sum of values by column is one.</p><p>Thirdly, the Bayesian network representation allows a substantial (usually, dramatic) reduction in the time needed to compute marginals for each variable in the domain. The explicit representation of constraints on independence relations is exploited to avoid the computation of the full joint probability table in the computation of marginals both prior and conditioned on observations. Limitation of space prevents the description of the relevant algorithms; see <ref type="bibr" target="#b7">Jensen (2001)</ref> for a discussion of the justly famous junction tree algorithm.</p><p>The most common operation on a Bayesian network is the computation of marginal probabilities, both unconditional and conditioned upon evidence. Marginal probabilities are also referred as beliefs in the literature <ref type="bibr" target="#b15">(Pearl 1988</ref>). This operation is called probability updating, belief updating, or belief assignment.</p><p>A link between two nodes in a Bayesian network is often interpreted as a causal link. However, this is not necessarily the case. When each link in a Bayesian network is causal, then the Bayesian network is called a causal Bayesian network or Markovian model. Markovian models are popular graphical models for encoding distributional and causal relationships. To summarize, a Markovian model consists of a DAG G over a set of variables V ¼ fV 1 ; . . . ; V n g, called a causal graph and a probability distribution over V, which has some constraints on it that will be specified precisely below. We use V(G ) to indicate that V is the variable set of graph G. If it is clear in the context, we also use V directly. The interpretation of such kind of model consists of two parts. The probability distribution must satisfy two constraints. The first one is that each variable in the graph is independent of all its non-descendants given its direct parents. The second one is that the directed edges in G represent causal influences between the corresponding variables. A Markovian model for which only the first constraint holds is called a Bayesian network, and its DAG is called a Bayesian network structure. This explains why Markovian models are also called causal Bayesian networks. As far as the second condition is concerned, some authors prefer to consider Eq. (3) (below) as definitional; others take Eq. ( <ref type="formula" target="#formula_7">3</ref>) as following from more general considerations about causal links, and in particular the account of causality that requires that, when a variable is set, the parents of that variable be disconnected from it. A full discussion of this is beyond the scope of this article, but see <ref type="bibr" target="#b10">Lauritzen (2001)</ref> and <ref type="bibr" target="#b16">Pearl (2000)</ref>.</p><p>In this article, capital letters, like V, are used for variable sets; lowercase letters, like v, stand for the instances of variable set V. Capital letters like X, Y, and V i are also used for single variables, and their values can be x, y, and v i . Normally, we use F(V ) to denote a function on variable set V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>An instance of this function is denoted as</head><formula xml:id="formula_3">F(V )(V ¼ v), or F(V )(v), or just F(v).</formula><p>Each variable is in one-to-one correspondence to one node in the causal graph.</p><p>We use Pa(V i ) to denote parent node set of variable V i in graph G and pa(V i ) as an instance of Pa(</p><formula xml:id="formula_4">V i ). Ch(V i ) is V i 's children node set; ch(V i ) is an instance of Ch(V i ).</formula><p>Based on the probabilistic interpretation, we get that the joint probability function PðvÞ ¼ Pðv 1 ; . . . ; v n Þ can be factorized as</p><formula xml:id="formula_5">PðvÞ ¼ Y V i 2V Pðv i jpaðV i ÞÞ<label>ð1Þ</label></formula><p>From the joint probability, all marginal prior and posterior probabilities can be obtained, by marginalizing and conditioning. The notion of conditional probability is a well-defined and accepted one. The conditional probability of an event S given an event D is defined as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PðSjDÞ ¼ PðS; DÞ PðDÞ</head><p>This definition is actually an axiom of probability, which can be shown to hold in all useful interpretation of probability, including the subjective Bayesian one <ref type="bibr" target="#b12">(Neapolitan 1990)</ref>. It is a tenet of applied Bayesian reasoning that beliefs are updated by conditioning when new knowledge is gained. There are, however, two kinds of updating in causal Bayesian networks, viz. updating by conditioning (also known as updating by observation) and updating by intervention.</p><p>Updating by conditioning is well-defined and understood, both in principle and algorithmically <ref type="bibr" target="#b0">(Cooper 1990;</ref><ref type="bibr" target="#b11">Lauritzen 1996)</ref>. There are free and commercial software packages, like Hugin,<ref type="foot" target="#foot_1">foot_1</ref> that perform update by conditioning on Bayesian networks in a very efficient manner in most practical cases. In the next section, we explain updating by intervention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTERVENTIONS AND THE IDENTIFIABILITY PROBLEM</head><p>The causal interpretation of a Markovian model enables us to predict intervention effects. Here, intervention means some kind of modification of factors in product <ref type="bibr" target="#b1">(Fisher 1958)</ref>. The simplest kind of intervention is fixing a subset, T V, of variables to some constants, t, denoted by do(T ¼ t) or just do(t). Then, the post-intervention distribution</p><formula xml:id="formula_6">P T ðV ÞðT ¼ t; V ¼ vÞ ¼ P t ðvÞ ð<label>2Þ</label></formula><p>is given by:</p><formula xml:id="formula_7">P t ðvÞ ¼ PðvjdoðtÞÞ ¼ Q V i 2V nT Pðv i jpaðV i ÞÞ v consistant with t 0 v inconsistant with t<label>ð3Þ</label></formula><p>To stress the distinction between observation and intervention, we present a simple example based on the sneezing model of Fig. <ref type="figure" target="#fig_4">4</ref>, originally presented in <ref type="bibr" target="#b18">Pearl and Verma (1991)</ref>, in which wiping one's nose (W) is caused by sneezing (S), which in turn is caused by either a cold (C) or hay fever (F), or both. To complete this causal Bayesian network, we give the probabilities in Table <ref type="table" target="#tab_0">1</ref> and PðColdÞ ¼ ð:2; :8Þ, PðHayFeverÞ ¼ ð:1; :9Þ, and PðWipingOne 0 sNosejSneezing ¼ yÞ ¼ :9.</p><p>We use this causal graph to compare the notions of observation and intervention. The initial probabilities for the four variables are shown in Fig. <ref type="figure" target="#fig_7">5</ref>. Suppose that it is observed that sneezing occurs. The probabilities of each variable in the network are updated as shown in Fig. <ref type="figure" target="#fig_5">6</ref>.</p><p>Suppose now that we intervene and force sneezing. The connections between node Sneezing and its parents are cut, as indicated in the model of Fig. <ref type="figure" target="#fig_6">7</ref>. Unlike the situation in which sneezing is observed, the posterior probabilities of Cold and Hay Fever are unchanged.</p><p>We call interventions of the simple kind described so far in this section, which consist in fixing a subset of variables to some constants, crisp interventions. Referring to the sneezing causal graph, a simple example is setting the variable Sneezing to the value true (i.e., forcing sneezing to occur), by the administration of a perfectly effective sneezing powder. More complicated interventions can be described using the intervention graph or augmented model <ref type="bibr" target="#b8">(Korb and Nicholson 2003)</ref>, in the way originally described in <ref type="bibr" target="#b13">Pearl (1993)</ref> and <ref type="bibr" target="#b16">Pearl (2000)</ref>. The intervention graph is formed by adding a parent to each node representing a variable where intervention is contemplated. The brief discussion here follows the excellent presentation of <ref type="bibr" target="#b21">Spirtes et al. (1993)</ref>      intervention. The new parent set of X i in the augmented network is Pa 0 ðX i Þ ¼ PaðX i Þ [ fF i g, and it is related to X i by the conditional probability.</p><p>Pðx i jpa 0 ðX i ÞÞ ¼</p><formula xml:id="formula_8">Pðx i jpaðX i Þ if F i ¼ idle 0 if F i ¼ doðx 0 i Þ and x i 6 ¼ x 0 i 1 if F i ¼ doðx 0 i Þ and x i ¼ x 0 i 8 &lt; :<label>ð4Þ</label></formula><p>The effect of the intervention doðx 0 i Þ is to transform the original probability function PðX 1 ; . . . ; X n Þ into a new probability function</p><formula xml:id="formula_9">P X i ¼X 0 i ðX i ; . . . ; X n Þ, given by P X i ¼X 0 i ðX i ; . . . ; X n Þ ¼ P 0 ðX 1 ; . . . ; X n jF i ¼ doðx 0 i ÞÞ<label>ð5Þ</label></formula><p>where P 0 is the distribution specified by the augmented network G 0 ¼ G [ fF i ! X i g and ( <ref type="formula" target="#formula_8">4</ref>), with an arbitrary prior distribution on F i . In general, by adding a hypothetical intervention link F i ! X i to multiple nodes in G, we can construct an augmented probability function P 0 ðX 1 ; . . . ; x n ; F i ; . . . ; F n Þ, which allows for interventions beyond the setting of a subset of variable to constants. For a simple example related to the causal graph of Fig. <ref type="figure" target="#fig_4">4</ref>, imagine administering an imperfectly effective sneezing power, which causes sneezing with probability p. This would be modeled by setting the prior probability of the value true for the forcing variable F Sneezing in the model of Fig. <ref type="figure" target="#fig_10">9</ref> to p.</p><p>In many cases, an empirical scientist faces the following question: Can we estimate the post-intervention distribution under crisp intervention from non-experimental data? When all the variables in the model are observable, the answer for the question above is positive. But when some variables in V are unobservable, things are much more complex, and the answer may be either positive or negative, depending on the structure of the causal Bayesian network and the relative location of observable and unobservable variables. We give a detailed proof of unindentifiability for the key example of Fig. <ref type="figure" target="#fig_9">10</ref> in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AN UNIDENTIFIABLE MODEL</head><p>A simple example of unidentifiable model is R. A. Fisher's genotype model of the relation between smoking and lung cancer <ref type="bibr" target="#b21">(Spirtes et al. 1993</ref>), which we briefly discussed in the first section of this article. R. A. Fisher suggested that the observed correlation between smoking(X)</p><p>and lung cancer(Y ) can be explained by some sort of carcinogenic genotype(U ) that involves inborn craving for nicotine.</p><p>The carcinogenic genotype is presented by Fisher as a concept that has not been observed in nature, and it is therefore modeled as an unobservable variable. Intuitively, the effect of smoking on lung cancer is unidentifiable because we are not sure whether the observed response (lung cancer) is due to our action (smoking) or to the confounder event (genotype) that triggers the action and simultaneously causes the response.  Formally, we show that the effect of smoking on lung cancer is unidentifiable in the following way. We show that, with a given observational distribution P(x, y), it is possible to find two different causal Bayesian networks M 1 and M 2 that share the graph of Fig. <ref type="figure" target="#fig_9">10</ref>, and such that P M 1 ðx; yÞ ¼ P M 2 ðx; yÞ. As an extreme example, we can construct two drastically different models following the explanation that smoking is the cause of lung cancer (the part a in Fig. <ref type="figure" target="#fig_11">11</ref>) or carcinogenic genotype is the only cause of this fatal disease (the part b in Fig. <ref type="figure" target="#fig_11">11</ref>). Both of them satisfy the graph in Fig. <ref type="figure" target="#fig_9">10</ref>. That is, Fig. <ref type="figure" target="#fig_9">10</ref> generalizes both graphs in Fig. <ref type="figure" target="#fig_11">11</ref>, or, equivalently, the graphs in Fig. <ref type="figure" target="#fig_11">11</ref> are special cases of the graph in Fig. <ref type="figure" target="#fig_9">10</ref>.</p><p>Our question about the smoking and lung cancer model of Fig. <ref type="figure" target="#fig_9">10</ref> is: If we intervene on variable X, which means we control the smoking behavior, is unexperimental observational knowledge about smoking and lung-cancer (i.e., P(x, y)) sufficient to determine the probability of lung cancer? Mathematically, this problem can be explained as a question on the Markovian model of Fig. <ref type="figure" target="#fig_9">10</ref>: If we know P(x, y), which is the joint probability on observable variables X, Y, can we calculate P x ðyÞ for all (x, y)? Unfortunately, the answer to this question is negative.</p><p>The fact is that it is possible to create a model compatible with Fig. <ref type="figure" target="#fig_11">11</ref> part a and another model compatible with Fig. <ref type="figure" target="#fig_11">11</ref> part b, both of them satisfying P(x, y), but with different P x ðyÞ. We cannot get the same P x ðyÞ from these two models because for the first model, the intervention will change the probability of lung cancer but if the second model is correct, the behavior of smoking has no effect on lung cancer at all. We now carry out the calculations in detail to show that the effect of smoking on lung cancer is unidentifiable for the causal Bayesian network of Fig. <ref type="figure" target="#fig_9">10</ref>. All variables are binary, and their states are denoted as 0 and 1. For variable U, we assume PðU ¼ 0Þ ¼ PðU ¼ 1Þ ¼ 1=2. In that spirit, we conclude the section by describing two more models that may match some researchers' understanding of the relation between smoking and lung cancer.</p><p>It is observed that smoking causes tar deposit on lung. So, with the evidence that genotype may cause lung cancer and smoking behavior, a researcher may establish a causal model about smoking (X ) and lung cancer (Y ) with tar (Z ). See Fig. <ref type="figure" target="#fig_13">12</ref>. Incidentally, R. A. Fisher himself seems to hint at such a model <ref type="bibr" target="#b1">(Fisher 1958)</ref>. This causal graph assumes that smoking cigarettes has no effect on the production of lung cancer except as mediated through tar deposits and that genotype has no effect on the amount of tar in the lungs except indirectly through cigarette smoking.</p><p>Finally, the causal graph of Fig. <ref type="figure" target="#fig_12">13</ref> adds to the causal graph of Fig. <ref type="figure" target="#fig_13">12</ref> the assumption that the production of tar deposits in the lung (Z) is affected by pollution (U 1 ), which also affects the propensity towards smoking (X ).</p><p>The causal effect of smoking on lung cancer (P X ðY Þ) is identifiable in the causal graph of Fig. <ref type="figure" target="#fig_13">12</ref>, but unidentifiable in the causal graph of Fig. <ref type="figure" target="#fig_12">13</ref>. We do not attempt to prove this claim in this article, and refer the reader to the references given in the next section for the algorithms needed to establish this claim and, in the case of Fig. <ref type="figure" target="#fig_13">12</ref>, compute the value of the causal effect.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>This article provides an introduction to the problem of inferring the strength of cause-and-effect relationships from a causal Bayesian network, emphasizing conceptual foundations and examples. In this concluding section, we provide a roadmap to the literature where proofs and algorithms are provided.</p><p>A causal Bayesian network consists of a causal graph, an acyclic directed graph expressing causal relationships, and a probability distribution respecting the independence relation encoded by the graph.</p><p>Because of the existence of unmeasured variables, the following identifiability questions arise: ''Can we assess the strength of causal effects from nonexperimental data and casual relationships? And if we can, what is the total causal effect in terms of estimable quantities?'' The questions just given could partially be answered using graphical approaches due to Pearl and his collaborators. More precisely, graphical conditions have been devised to show whether a causal effect, that is, the joint response of any set S of variables to interventions on a set T of action variables, denoted P T ðSÞ<ref type="foot" target="#foot_3">foot_3</ref> is identifiable or not. Those results are summarized in <ref type="bibr" target="#b16">Pearl (2000)</ref>. For example, ''back-door'' and ''front-door'' criteria and do-calculus <ref type="bibr" target="#b14">Pearl (1995)</ref>; graphical criteria to identify P T ðSÞ when T is a singleton <ref type="bibr" target="#b2">(Galles and Pearl 1995)</ref>; graphical conditions under which it is possible to identify P T ðSÞ where T and S are, possibly non-singleton, sets, subject to a special condition called Q-identifiability <ref type="bibr" target="#b17">(Pearl and Robins 1995)</ref>. Further study can be also found in <ref type="bibr" target="#b9">Kuroki and Miyakawa (1999)</ref> and <ref type="bibr" target="#b19">Robins (1997)</ref>.</p><p>More recently, Tian and Pearl published a series of papers related to this topic <ref type="bibr">(Tian and Pearl 2002;</ref><ref type="bibr">Tian and Pearl 2002;</ref><ref type="bibr" target="#b22">Tian and Pearl 2003)</ref>. Their new methods combined the graphical character of causal graph and the algebraic definition of causal effect. They used both algebraic and graphical methods to identify causal effects. The basic idea is, first, to transfer causal graphs to semi-Markovian graphs <ref type="bibr">Tian and Pearl (2002)</ref>, then to use Algorithm 2 in <ref type="bibr" target="#b22">Tian and Pearl (2003)</ref> (the Identify algorithm) to calculate the causal effects we want to know.</p><p>Tian and Pearl's method was a great contribution to this study area. But there were still some problems left. First, even though we believe, as Tian and Pearl do, that the semi-Markovian models obtained from the transforming Projection algorithm in Tian and Pearl</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q9</head><p>(2002) are equal to the original causal graphs, and therefore the causal effects should be the same in both models, still, to the best of our knowledge, there was no formal proof for this equivalence. Second, the completeness question of the Identify algorithm in <ref type="bibr" target="#b22">Tian and Pearl (2003)</ref> was still open, so that it was unknown whether a causal effect was identifiable if that Identify algorithm failed.</p><p>In a series of papers, <ref type="bibr" target="#b3">Huang and Valtorta Q7 (2006;</ref><ref type="bibr" target="#b19">2006)</ref> and, independently, Q8 <ref type="bibr" target="#b20">Shpitser and Pearl (2006)</ref> solved the open questions and several related ones. In particular, following Tian and Pearl's work, <ref type="bibr">Huang and Valtorta (2006)</ref> solved the second question. They showed that the Identify algorithm Tian and Pearl used on semi-Markovian models is sound and complete. In <ref type="bibr">Huang and Valtorta (2006)</ref>, they followed the ideas Tian and Pearl presented in <ref type="bibr" target="#b22">Tian and Pearl (2003)</ref>, but instead of working on semi-Markovian models, they focused on general causal graphs directly, and their proofs showed, that Algorithm 2 in <ref type="bibr" target="#b22">Tian and Pearl (2003)</ref> can also be used in general causal models, and that the algorithm is sound and complete, which means a causal effect is identifiable if and only if the given algorithm runs successfully and returns an expression that is the target causal effect in terms of observable quantities.</p><p>It is our hope that the reader will be motivated to study, implement, refine, and apply the algorithmic framework to causal modeling that Pearl pioneered and that, the authors believe, is ready to be put to the test of deployment in actual applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. A simple causal model relating cigarette smoking and lung cancer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. R. A. Fisher's genotype model explaining the correlation between smoking and lung cancer.</figDesc><graphic coords="4,166.79,79.43,85.21,56.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. (a) Example Bayesian network, (b) variable states, and (c) conditional probability table for B given A.</figDesc><graphic coords="5,83.34,412.89,278.48,136.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. A causal graph for sneezing.</figDesc><graphic coords="9,165.54,79.43,114.01,115.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Marginal probabilities for the sneezing causal Bayesian network, after updating by conditioning on the evidence of sneezing.</figDesc><graphic coords="10,137.37,267.87,144.06,105.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. The sneezing causal graph, after a crisp intervention that Forces sneezing to occur.</figDesc><graphic coords="10,151.54,442.83,115.71,117.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Initial marginal probabilities for the sneezing model.</figDesc><graphic coords="10,116.96,79.43,184.82,134.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Q10Figure 8 .</head><label>8</label><figDesc>Intervention graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. R. A. Fisher's genotype model explaining the correlation between smoking and lung cancer (Fig. 2, repeated here for the reader's convenience).</figDesc><graphic coords="12,166.79,493.12,85.21,56.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. An intervention graph for the sneezing model of Fig. 4.</figDesc><graphic coords="12,134.65,79.43,149.56,112.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Different models compatible with the model of Fig. 10.</figDesc><graphic coords="13,138.56,493.74,168.04,66.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 13 .</head><label>13</label><figDesc>Figure13. Air pollution (U 1 ) affects tar deposits (Z) and the propensity to smoke (X).</figDesc><graphic coords="15,179.60,493.46,85.95,66.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Smoking (X) affects lung cancer (Y) through tar deposits (X).</figDesc><graphic coords="15,168.55,79.43,108.00,78.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>very closely. The interested reader should consult that reference for more detail.The effect of a crisp interventiondoðX i ¼ x i Þ can be encoded by adding to G a link F i ! X i ,where F i is a new variable taking values in fdoðx i Þ; idleg; x i ranges over the domain of X i , and idle represents no Table for P(Sneezing ¼ y j Cold, Hay Fever)</figDesc><table><row><cell></cell><cell>H</cell><cell></cell></row><row><cell>C</cell><cell>y</cell><cell>n</cell></row><row><cell>Y</cell><cell>. 9</cell><cell>. 8</cell></row><row><cell>n</cell><cell>. 7</cell><cell>. 1</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>M. VALTORTA AND Y. HUANG</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>http://www.hugin.com/ IDENTIFIABILITY IN CAUSAL BAYESIAN NETWORKS</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>M. VALTORTA AND Y. HUANG</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>Pearl and Tian used notation PðsjdoðtÞÞ and Pðsj t tÞ in [6] and P t ðSÞ in [13], [14]</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The conditional probability tables of variable X and Y in model M1 are defined as below:</p><p>x u P M 1 ðxjuÞ 0 0 0:6 0 1 0:4</p><p>The conditional probability tables of variable X and Y in model M 2 defined as: </p><p>We also have P X ðY Þ ¼ R U PðY jX ; U ÞPðU Þ for both two models, and for M 1 , P M 1 X ¼0 ðY ¼ 0Þ ¼ 0:45, but for M 2 , we have P M 2 X ¼0 ðY ¼ 0Þ ¼ 0:40. We conclude that P X ðY Þ is unidentifiable in this causal graph. We emphasize, again, that the models we use are not intended to be correct representations of domain knowledge: We use them simply to illustrate how they can be used in representing causal modeling assumptions, which have different bearing on the identifiability of causal effects. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The computational complexity of probabilistic inference using Bayesian networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="393" to="405" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cancer and smoking</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="page" from="596" to="597" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Testing identifiability of causal effects</title>
		<author>
			<persName><forename type="first">D</forename><surname>Galles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh annual conference on uncertainty in artificial intelligence (UAI-95)</title>
		<meeting>the eleventh annual conference on uncertainty in artificial intelligence (UAI-95)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="185" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Identifiability on causal bayesian networks: A sound and complete algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valtorta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-first national conference on artificial intelligence (AAAI-06)</title>
		<meeting>the twenty-first national conference on artificial intelligence (AAAI-06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">On the completeness of an identifiability algorithm for semi-Markovian models. tech. rep., University of South Carolina Department of Computer Science, 1</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valtorta</surname></persName>
		</author>
		<ptr target="http://www.cse.sc.edu/mgv/reports/tr2006-001.pdf" />
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>journal version to appear</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Valtorta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pearl&apos;s calculus of intervention is complete</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valtorta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-second conference on uncertainty in artificial intelligence (UAI-06 )</title>
		<meeting>the twenty-second conference on uncertainty in artificial intelligence (UAI-06 )</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="217" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bayesian networks and decision graphs</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer Verlag</publisher>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Korb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Nicholson</surname></persName>
		</author>
		<title level="m">Bayesian artificial intelligence</title>
		<meeting><address><addrLine>Boca Raton, FL</addrLine></address></meeting>
		<imprint>
			<publisher>Chapman Hall=CRC Press</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identifiability criteria for causal effects of joint interventions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kuroki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Miyakawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Japan Statistical Society</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="117" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Causal inference from graphical models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lauritzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Complex Stochastic Systems</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Barndorff-Nielsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Klueppelberg</surname></persName>
		</editor>
		<editor>
			<persName><surname>London=baton Rouge</surname></persName>
		</editor>
		<imprint>
			<publisher>Chapman and Hall=CRC</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="63" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Graphical models</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Lauritzen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Clarendon Press</publisher>
			<pubPlace>Oxford, United Kingdom</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Probabilistic reasoning in expert systems: theory and algorithms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Neapolitan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>John Wiley and Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Graphical models, causality, and intervention. Comments on: Linear dependencies represented by chain graphs by D. Cox and N. Wermuth, and Bayesian analysis in expert systems by</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dawid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Lauritzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Cowell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Statistical Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="266" to="269" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Causal diagrams for empirical research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="669" to="710" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Probabilistic reasoning in intelligent systems: Networks of plausible inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Morgan-Kaufmann Publishers</publisher>
			<pubPlace>San Mateo, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Causality: models, reasoning, and inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Probabilistic evaluation of sequential plans from causal models with hidden variables</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Robins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh annual conference on uncertainty in artificial intelligence (UAI-95)</title>
		<meeting>the eleventh annual conference on uncertainty in artificial intelligence (UAI-95)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="444" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A theory of inferred causation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Principles of knowledge representation and reasoning: Proceedings of the second international conference</title>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufman</publisher>
			<date type="published" when="1991-04">April 1991</date>
			<biblScope unit="page" from="441" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Identification of conditional interventional distributions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Robins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-second conference on uncertainty in artificial intelligence (UAI-06 )</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Berkane</surname></persName>
		</editor>
		<editor>
			<persName><surname>Newyork</surname></persName>
		</editor>
		<editor>
			<persName><surname>Springerverlag</surname></persName>
		</editor>
		<meeting>the twenty-second conference on uncertainty in artificial intelligence (UAI-06 )<address><addrLine>Shpitser, Q8 I. and Pearl, J</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997. 2006</date>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="437" to="444" />
		</imprint>
	</monogr>
	<note>Latent variable modeling with applications to causality</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Identification of conditional interventional distributions</title>
		<author>
			<persName><forename type="first">I</forename><surname>Shpitser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-first national conference on artificial intelligence (AAAI-06 )</title>
		<meeting>the twenty-first national conference on artificial intelligence (AAAI-06 )</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1217" to="1226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Causation, prediction and search</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the identification of causal effects</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<ptr target="http://www.cs.iastate.edu/jtian/r290-L.pdf" />
	</analytic>
	<monogr>
		<title level="m">290-L, tech. rep</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Cognitive Systems Laboratory, University of California at Los Angeles</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
