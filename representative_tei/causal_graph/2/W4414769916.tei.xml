<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Characterization and Learning of Causal Graphs from Hard Interventions</title>
				<funder ref="#_tF4tuAZ">
					<orgName type="full">Amazon Research Award and Adobe Research</orgName>
				</funder>
				<funder ref="#_SGtferR">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-05-05">May 5, 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zihan</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Purdue University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Equal Contribution</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Muhammad</forename><surname>Qasim Elahi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Purdue University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Equal Contribution</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Murat</forename><surname>Kocaoglu</surname></persName>
							<email>mkocaoglu@purdue.edu</email>
						</author>
						<title level="a" type="main">Characterization and Learning of Causal Graphs from Hard Interventions</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-05-05">May 5, 2025</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2505.01037v1[stat.ML]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A fundamental challenge in the empirical sciences involves uncovering causal structure through observation and experimentation. Causal discovery entails linking the conditional independence (CI) invariances in observational data to their corresponding graphical constraints via d-separation. In this paper, we consider a general setting where we have access to data from multiple experimental distributions resulting from hard interventions, as well as potentially from an observational distribution. By comparing different interventional distributions, we propose a set of graphical constraints that are fundamentally linked to Pearl's do-calculus within the framework of hard interventions. These graphical constraints associate each graphical structure with a set of interventional distributions that are consistent with the rules of do-calculus. We characterize the interventional equivalence class of causal graphs with latent variables and introduce a graphical representation that can be used to determine whether two causal graphs are interventionally equivalent, i.e., whether they are associated with the same family of hard interventional distributions, where the elements of the family are indistinguishable using the invariances from do-calculus. We also propose a learning algorithm to integrate multiple datasets from hard interventions, introducing new orientation rules. The learning objective is a tuple of augmented graphs which entails a set of causal graphs. We also prove the soundness of the proposed algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Understanding the behavior of complex systems through their causal relationships is a fundamental problem in science. Researchers collect data and perform experiments to analyze how specific phenomena arise or to investigate the structure and function of underlying systems, whether social, biological, or economic <ref type="bibr" target="#b16">Hünermund &amp; Bareinboim (2023)</ref>; <ref type="bibr" target="#b36">Petersen et al. (2024)</ref>; <ref type="bibr" target="#b38">Sanchez et al. (2022)</ref>. Causal discovery focuses on identifying causal relationships from both observational and interventional data <ref type="bibr" target="#b31">Pearl (1995)</ref>; <ref type="bibr" target="#b41">Spirtes et al. (2001)</ref>; <ref type="bibr" target="#b35">Peters et al. (2017)</ref>. A widely used approach for causal discovery models the underlying system as a causal graph, represented by a directed acyclic graph (DAG), where nodes denote random variables and directed edges between nodes (A → B) signify causal relations <ref type="bibr" target="#b32">Pearl (2009)</ref>; <ref type="bibr" target="#b41">Spirtes et al. (2001)</ref>.</p><p>Causal discovery involves deriving constraints from data to infer the underlying causal graph. However, in practice, these constraints are rarely enough to identify the exact causal graph. Instead, they typically define a set of graphs consistent with the data, collectively referred to as an equivalence class (EC) <ref type="bibr" target="#b2">Ali et al. (2012)</ref>; <ref type="bibr">Meek (2013a)</ref>. Conditional independence (CI) relations are the primary markers of the underlying causal structure and are used to define an equivalence class. These fundamental probabilistic invariances have been widely explored within the framework of graphical models <ref type="bibr" target="#b31">Pearl (1995)</ref>; <ref type="bibr" target="#b35">Peters et al. (2017)</ref>. Conditional independencies (CIs) are a powerful tool and serve as the foundation for many causal discovery algorithms, e.g., PC and FCI <ref type="bibr" target="#b41">Spirtes et al. (2001)</ref>.</p><p>When only observational data is available, the Markov equivalence class (MEC) comprises all causal graphs that exhibit the same set of conditional independences (CIs) among the measured variables, as defined by the d-separation criterion <ref type="bibr" target="#b45">Verma &amp; Pearl (1992)</ref>. The availability of interventional (i.e., experimental) data allows us to reduce the size of the equivalence class, potentially facilitating the recovery of the true causal graph <ref type="bibr" target="#b12">Hauser &amp; Bühlmann (2012)</ref>; <ref type="bibr" target="#b21">Kocaoglu et al. (2017)</ref>. Hard and soft interventions are two methods for manipulating variables in causal systems. A hard intervention directly sets a variable to a fixed value, removing natural dependencies, while a soft intervention alters the mechanism through which the parents of a variable influence the target variable. While soft interventions are more common in biology as, e.g., in gene knockout experiments <ref type="bibr" target="#b28">Meinshausen et al. (2016)</ref> since we do not have precise control of mechanisms, in computer systems hard interventions are feasible and have been used for learning causal relations, e.g., in microsystem architectures <ref type="bibr" target="#b46">Wang et al. (2023)</ref>.</p><p>Although a hard intervention can be seen as a special case of a soft one, it can be more informative in the presence of latent variables in many cases. For instance, consider the causal graph D 1 = {X → Z → Y, Z ↔ Y }. A hard intervention on Z breaks the inducing path<ref type="foot" target="#foot_0">foot_0</ref> X, Z, Y , which implies that after a hard intervention on Z, the variables X and Y are no longer dependent. In contrast, in the case of a soft intervention, the incoming edges to Z are not removed, so a soft intervention will not break the inducing path. It is also worth noting that hard interventions may change d-separation statements non-locally, as seen here between X, Y after do(z), which the existing representations of interventional Markov equivalence classes cannot encode. Now consider another graph D 2 = {X → Z → Y, Z ↔ Y, X → Y }, which is the same as D 1 with the additional edge X → Y . With access to a hard intervention on Z, we can distinguish these graphs; however, with a soft intervention, one cannot differentiate between them. This example demonstrates that hard interventions can be more informative in the presence of latent variables and narrow down the search space more effectively compared to soft interventions. A fundamental question is how can we extract as much causal knowledge as possible from a collection of hard interventional datasets. To the best of our knowledge, this problem has been open before this work.</p><p>Motivated by this, our paper considers a general setting where multiple experimental distributions resulting from hard interventions are available alongside (optionally) observational distributions. Prior work has focused on characterizing the I-Markov equivalence class through distributional invariances both within and across a set of observational and interventional distributions <ref type="bibr" target="#b12">Hauser &amp; Bühlmann (2012)</ref>; <ref type="bibr" target="#b48">Yang et al. (2018)</ref>. The closest work to ours is <ref type="bibr" target="#b22">Kocaoglu et al. (2019)</ref>. However, they deal with soft interventions, whereas we consider a setting where experimental data comes from hard interventions. This can lead to more invariances that can be inferred from the experimental data compared to the soft intervention case, which can potentially further reduce the size of I-Markov equivalence class. However, the existing work cannot utilize these additional invariances.</p><p>We propose using do-constraints with hard interventions, a concept that emerges from comparing observational and experimental distributions, extending Pearl's do-calculus to uncover new structural insights in causal graphs <ref type="bibr" target="#b22">Kocaoglu et al. (2019)</ref>; <ref type="bibr" target="#b18">Jaber et al. (2020)</ref>. They emerge as the converse of the causal calculus developed by <ref type="bibr" target="#b31">Pearl (1995)</ref>. These constraints, distinct from traditional conditional independence (CI) relations, are derived by contrasting distributions such as P (y|x) and P (y|do(x)) through a do-see test. When differences are detected, they reveal open backdoor paths in the graph, aiding structure learning. We leverage F-nodes, introduced by Pearl, to explicitly encode intervention effects in augmented graphs <ref type="bibr" target="#b30">Pearl (1993)</ref>. These nodes make the effects of interventions visible within the graph, enabling the application of do-calculus tests and capturing key structural knowledge such as the existence of a backdoor path from X to Y when F X is not d-separated from Y given X. Such augmented representations, widely used in inference and identification, highlight the utility of do-constraints alongside CI relations for learning causal structures <ref type="bibr" target="#b48">Yang et al. (2018)</ref>; <ref type="bibr" target="#b22">Kocaoglu et al. (2019)</ref>; <ref type="bibr" target="#b29">Mooij et al. (2020)</ref>.</p><p>We say that a set of interventional distributions satisfies the I-Markov property with respect to a graph if these distributions adhere to the invariance constraints imposed by the causal calculus rules of that graph. We first extend the causal calculus rules to operate between arbitrary sets of hard interventions. We say that two causal graphs, D 1 and D 2 , are I-Markov equivalent if the set of distributions that are I-Markov to both D 1 and D 2 is the same. Using the augmented graph, we identify a graphical condition that is both necessary and sufficient for two Causal Bayesian Networks (CBNs) with latents to be I-Markov equivalent under the framework of hard interventions. Finally, we propose a sound algorithm for causal discovery from hard-interventional datasets. Our main contributions can be summarized as follows:</p><p>• We propose a characterization of I-Markov equivalence between two causal graphs with latent variables for a given intervention set I, based on a generalization of do-calculus under hard interventions.</p><p>• We provide a graphical characterization of I-Markov equivalence for causal graphs with latent variables under the framework of hard interventions.</p><p>• We introduce a learning algorithm for inferring the graphical structure using a combination of different interventional data, while utilizing the corresponding new constraints. This procedure includes a new set of orientation rules, and we formally prove its soundness.</p><p>Outline of the paper: In Section 2, we briefly cover the necessary background knowledge and summarize the related works. In Section 3, we derive a set of do-constraints to combine the observational and interventional distributions. In Section 4, we characterize the graph conditions for I-Markov equivalence class. In Section 5, we construct a more compact graphical structure to capture the characterization. In Section 6, we propose a learning algorithm that recovers the causal graph from given interventional distributions. In Section 7, we show some experimental results to compare the size of interventional Markov equivalence classes under hard interventions and soft interventions. In Section 8, we conclude with a discussion of limitations and future extensions. Finally, we discuss the potential broader impact of our work. The related proofs and extra information are included in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Works</head><p>In this section, we briefly describe related background knowledge and notations in this paper. Throughout this paper, we use upper case letters to denote variables, lower case letters to denote realizations, and bold letters for sets.</p><p>Causal Bayesian Network (CBN): Given a set of variables V, P (v) represents the joint distribution for V = v. A hard intervention do(X = x) refers to setting a subset X ⊆ V to constants x. It breaks the causal relationship between the intervened variables and their parents. The interventional distribution is P x (v). Let P denote the tuple of all interventional distributions for all X ⊆ V. Then, a directed acyclic graph (DAG) D = (V, E) is said to be a causal Bayesian network compatible with P if and only if, for all X ⊆ V, P x (v) = {i|Vi / ∈X} P (v i |pa i ), for all v consistent with x, and where pa i is the set of parents of V i in D. D is said to be causal if it satisfies this condition. V [D] and E[D] denote the set of all nodes and all edges of graph D respectively. Causal graphs entail specific conditional independence (CI) relationships among observable variables via d-separation statements. The d-separation serves as a criterion to determine whether a set of variables X is independent of another set Y, given Z.</p><p>If a causal graph has latent variables, it is denoted as D = (V ∪ L, E) where V represents observable variables, L represents latent variables, and E denotes the edges. If a latent variable L ∈ L is a common cause of two observable variables, we use a curved bidirected edge between the two children variables. Such a causal graph is called Acyclic Directed Mixed Graph (ADMG). However, unlike causal graphs with sufficiency, the observed distribution is obtained by marginalizing L out as the Markovian condition does not hold in this case.</p><formula xml:id="formula_0">P (v) = L {i|Ti∈L∪V} P (t i |pa i )<label>(1)</label></formula><p>Two causal graphs are called Markov equivalent if they encode the same set of CI statements over V. Ancestral graphs: Ancestral graph is a graphical representation widely used for a class of Markov equivalent causal graphs with latent variables. In an ADMG, X is an ancestor of Y if there is a directed path from X to Y . X is a spouse of Y if X ↔ Y is present. An inducing path relative to Z is a path on which every non-endpoint vertex T / ∈ Z is a collider on the path (the two adjacent nodes are into it) and every collider is an ancestor of one of the endpoints. An ADMG is ancestral if it does not contain any almost directed cycle. It is maximal if there is no inducing path (relative to the empty set) between any pair of non-adjacent vertices. It is called a Maximal Ancestral Graph (MAG) if it is both maximal and ancestral <ref type="bibr" target="#b37">Richardson &amp; Spirtes (2002)</ref>. In <ref type="bibr">Zhang (2008a)</ref>, the authors show how to uniquely construct a MAG M D for a causal graph with latents D = (V ∪ L, E), such that all the (conditional) independence statements and ancestral relationships over V are preserved. Such CI statements are called m-separation statements in ADMGs.</p><p>In a graph D, a triple X, Y, Z is unshielded if X, Y are adjacent and Y, Z are adjacent while X, Z are not adjacent. If both edges are into Y , then it is an unshielded collider. A path between X and Y , p = X, ..., W, Z, Y , is a discriminating path for Z if (1) p includes at least three edges; (2) Z is a nonendpoint node on p, and is adjacent to Y on p; and (3) X is not adjacent to Y , and every node between X and Z is a collider on p and is a parent of Y . Two MAGs are Markov equivalent if and only if (1) they have the same skeleton; (2) they have the same unshielded colliders; and (3) if a path p is a discriminating path for Z in both MAGs, then Z is a collider on the path in one graph if and only if it is a collider on the path in the other. A partial ancestral graph (PAG) represents a Markov equivalence class of MAGs. It can be learned from CI statements over the observable variables under faithfulness. When observational data is provided, FCI algorithm is a commonly used algorithm used to recover the PAG and is proved to be sound and complete in <ref type="bibr">Zhang (2008b)</ref>.</p><p>Related works: There are many works in the literature <ref type="bibr" target="#b4">(Chickering, 2002;</ref><ref type="bibr" target="#b17">Hyttinen et al., 2013;</ref><ref type="bibr" target="#b8">Eberhardt, 2007;</ref><ref type="bibr" target="#b39">Shanmugam et al., 2015;</ref><ref type="bibr" target="#b21">Kocaoglu et al., 2017)</ref> related to learning the causal structure from a combination of observational and interventional data. Under the assumption of sufficiency, <ref type="bibr" target="#b12">Hauser &amp; Bühlmann (2012</ref><ref type="bibr">, 2014)</ref> introduced the Markov equivalence characterization. <ref type="bibr" target="#b48">Yang et al. (2018)</ref> further showed that the same characterization can be used for both hard and soft interventions. More works aimed at the cases where latents are present in the graph. If only observational data is available, <ref type="bibr">Zhang (2008b)</ref> showed the property and proposed the sound and complete FCI algorithm to learn a PAG. <ref type="bibr" target="#b41">Spirtes et al. (2001)</ref>; <ref type="bibr" target="#b5">Colombo et al. (2012)</ref>; <ref type="bibr" target="#b40">Spirtes et al. (1991)</ref>; <ref type="bibr" target="#b6">Colombo et al. (2014)</ref>; <ref type="bibr" target="#b11">Ghassami et al. (2018)</ref>; <ref type="bibr" target="#b21">Kocaoglu et al. (2017)</ref> proposed FCI-variant algorithms under different settings. <ref type="bibr" target="#b22">Kocaoglu et al. (2019)</ref> introduced a characterization for I-Markov equivalence class for soft interventions using augmented graphs with F node and proposed an FCI-variant algorithm to learn it. Following this, Jaber et al. ( <ref type="formula">2020</ref>) characterized the Ψ-MEC for unknown soft interventions and proposed a learning algorithm. <ref type="bibr" target="#b23">Li et al. (2023)</ref> introduced the S-Markov property and learning algorithm when data from multiple domains are provided.</p><p>Notations: For disjoint sets of variables X, Y, Z, a CI statement 'X is independent of Y conditioning on Z' is represented by X ⊥ ⊥ Y|Z. Similarly, in a causal graph D, the d-separation statement 'X is independent of Y conditioning on Z in graph D' is denoted as (X ⊥ ⊥ Y|Z) D . A set of interventions is I ⊆ 2 V , where 2 V is the power set of V. For two interventions I, J ∈ I, the symmetric difference is I∆J := (I \ J) ∪ (J \ I). D X /D X is the graph obtained by removing all the edges into/out of X from D. For D X,Y(Z) , Y(Z) is the subset of Y that are not ancestors of Z in the graph D X . In a PAG, a circle mark in an edge Xo→ Y can be either an arrowtail or an arrowhead which is not determined. A star mark in an edge X * → Y is used as a wildcard which can be a circle, arrowhead, or arrowtail. We assume that there is no selection bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Combining Observational and Experimental Distributions under Do-Calculus</head><p>One of the most renowned contributions to causal inference is the development of do-calculus (also known as causal calculus) <ref type="bibr" target="#b31">Pearl (1995</ref><ref type="bibr" target="#b32">Pearl ( , 2009))</ref>. Do-calculus is a set of three inference rules that enable the transformation of distributions associated with a causal graph. It leverages the graphical structure to determine when and how interventions can be adjusted or "removed" from expressions. In the context of hard interventions, the theorem is stated as follows:</p><p>Theorem 3.1. (Theorem 3 in <ref type="bibr" target="#b31">Pearl (1995)</ref>). Let D = (V ∪ L, E) be a causal graph. Then the following statements hold for any distribution that is consistent with D Rule 1 (see-see): For any</p><formula xml:id="formula_1">X ⊆ V and disjoint Y, Z, W ⊆ V P x (y|w, z) = P x (y|w), if Y ⊥ ⊥ Z|W, X in D X Rule 2 (do-see): For any disjoint X, Y, Z ⊆ V and W ⊆ V \ (Z ∪ Y) P x,z (y|w, z) = P x (y|w, z), if Y ⊥ ⊥ Z|W, X in D X,Z Rule 3 (do-do): For any disjoint X, Y, Z ⊆ V and W ⊆ V \ (Z ∪ Y) P x,z (y|w) = P x (y|w), if Y ⊥ ⊥ Z|W, X in D XZ(W ) where Z(W) ⊆ Z are non-ancestors of W in D X .</formula><p>Similar to the observations in <ref type="bibr" target="#b22">Kocaoglu et al. (2019)</ref> that the converse of the rules can be utilized to derive insights of the graph structures, here we also need a set of statements for hard interventions. With soft intervention, the interventional graph remains the same as no causal relationship is broken by soft interventions. However, hard interventions induce changes to the causal graph, making it potentially more informative in learning the graph structure. The intuition is that with hard interventions, the causal graph becomes more sparse and thus more do-invariance statements can be found to constrain the graph. Accordingly, we show the following Proposition that characterizes the graph conditions from the invariance of two arbitrary intervention sets.</p><p>Proposition 3.2. (Generalized do-calculus for hard interventions). Let D = (V ∪ L, E) be a causal graph with latents. Then, the following holds for any tuple of hard-interventional distributions (P I ) I∈I consistent with D, where I ⊆ 2 V .</p><p>Rule 1 (conditional independence): For any I ⊆ V and disjoint Y, Z, W ⊆ (V \ I)</p><formula xml:id="formula_2">P I (y|w, z) = P I (y|w), if Y ⊥ ⊥ Z|W, I in D I Rule 2 (do-see): For any I, J ⊆ V and disjoint Y, W ⊆ V \ K, where K := I∆J P I (y|w, k) = P J (y|w, k), if (Y ⊥ ⊥ K J |W, I) D I,K J ∧ (Y ⊥ ⊥ K I |W, J) D J,K I Rule 3 (do-do): For any I, J ⊆ V and disjoint Y, W ⊆ V \ K, where K := I∆J P I (y|w) = P J (y|w), if (Y ⊥ ⊥ K J |W, I) D I,K J (W) ∧ (Y ⊥ ⊥ K I |W, J) D J,K I (W)</formula><p>Rule 4 (mixed do-see/do-do): For any I, J ⊆ V and disjoint Y, W ⊆ V, where K := I∆J P I (y|w</p><formula xml:id="formula_3">) = P J (y|w), if (Y ⊥ ⊥ R J |W, I) D I,R J (W) ∧(Y ⊥ ⊥ W J |W, I) D I,W J ∧(Y ⊥ ⊥ R I |W, J) D J,R I (W) ∧ (Y ⊥ ⊥ W I |W, J) D J,W I</formula><p>where</p><formula xml:id="formula_4">K I = K \ J, K J = K \ I, W I = K I ∩ W, W J = K J ∩ W, R = K \ W, R I = R ∩ K I , R J = R ∩ K J .</formula><p>Note that Rule 2 and Rule 3 are special cases of Rule 4. We present all three to make the connection to standard causal calculus rules more explicit. In the following sections, we will show how the generalized rules can be crucial in characterizing and learning the I-Markov Equivalence Class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">I-Markov Equivalence Class</head><p>In this section, we will characterize the graphical conditions for interventional Markov equivalence class. First of all, we start by introducing the definition of interventional Markov equivalence based on the new do-constraint rules.</p><p>Definition 4.1. Consider the tuples of absolutely continuous probability distributions (P I ) I∈I over a set of variables V. A tuple (P I ) I∈I satisfies the I-Markov property with respect to a causal graph D = (V ∪ L, E) if the following holds for disjoint Y, Z, W ⊆ V:</p><p>1. For I ∈ I:</p><formula xml:id="formula_5">P I (y|w, z) = P I (y|w) if Y ⊥ ⊥ Z|W, I in D I 2. For I, J ∈ I: P I (y|w) = P J (y|w) if (Y ⊥ ⊥ R J |W, I) D I,R J (W) ∧ (Y ⊥ ⊥ W J |W, I) D I,W J ∧ (Y ⊥ ⊥ R I |W, J) D J,R I (W) ∧ (Y ⊥ ⊥ W I |W, J) D J,W I</formula><p>where</p><formula xml:id="formula_6">K I = K \ J, K J = K \ I, W I = K I ∩ W, W J = K J ∩ W, R = K \ W, R I = R ∩ K I , R J = R ∩ K J .</formula><p>The set of all tuples that satisfy the I-Markov property with respect to D are denoted by P I (D, V).</p><p>The two conditions of I-Markov property correspond to the first Rule in Theorem 3.1 and Rule 4 in Proposition 3.2 respectively. When I = ∅, i.e. we only have access to observational distribution, this definition aligns with the well-known definition of Markov equivalence. It only implies the first condition on the observational distribution P (V). Accordingly, two causal graphs are said to be I-Markov equivalent if they induce the same constraints to the interventional distribution tuple which we formalize as follows: Definition 4.2. Given two causal graphs D 1 = (V∪L 1 , E 1 ) and D 2 = (V∪L 2 , E 2 ), and a set of intervention targets I ⊆ 2 V , D 1 and D 2 are I-Markov equivalent if</p><formula xml:id="formula_7">P I (D 1 , V) = P I (D 2 , V).</formula><p>The challenge of checking the I-Markov property in Definition 4.1 involves checking multiple graph conditions in different graph mutilations of D. In order to construct a more compact representation of D that captures all the graph conditions, we introduce the augmented pair graph defined as follows.</p><p>Definition 4.3 (Augmented Pair Graph). Given a causal graph D = (V ∪ L, E) and a set of intervention targets I ⊆ 2 V , for a pair of interventions I, J ∈ I, K = I∆J, the augmented pair graph of D, denoted as Aug (I,J) (D), is constructed as follows: Aug (I,J) (D) = (V (I) ∪ V (J) ∪ {F (I,J) }, E (I) ∪ E (J) ∪ E), where F (I,J) is an auxiliary node, J) , S)} S∈K (I) ∪K (J) , with S as a singleton.</p><formula xml:id="formula_8">E (I) = E[D I ], E (J) = E[D J ], E = {(F (I,</formula><p>In words, for each pair of interventions I, J, we create the augmented pair graph by creating two copies of vertices V (I) , V (J) and adding the edges between the vertices with those in the corresponding interventional graphs D I , D J , and then connecting the auxiliary node F to all the nodes in the symmetric difference of I, J. We will omit the subscript for the graph and superscript for F node when the pair of interventions is clear from the context. This kind of construction has been proposed and used in the causality literature before <ref type="bibr" target="#b9">(Eberhardt &amp; Scheines, 2007;</ref><ref type="bibr" target="#b12">Hauser &amp; Bühlmann, 2012;</ref><ref type="bibr" target="#b32">Pearl, 2009;</ref><ref type="bibr" target="#b7">Dawid, 2002)</ref>. The constructed augmented pairs allow us to test the m-separation statements as listed in Definition 4.1 without looking into mutilations of the original graph D. This is illustrated by the following Proposition.</p><p>Proposition 4.4. Given a causal graph D = (V ∪ L, E) and a set of intervention targets I ⊆ 2 V , for each pair of interventions I, J ∈ I, K = I∆J, and the corresponding augmented pair graph Aug (I,J) (D) = (V (I) ∪ V (J) ∪ {F (I,J) }, E (I) ∪ E (J) ∪ E), E = {(F (I,J) , S)} S∈K (I) ∪K (J) , we have the following equivalence statements:</p><p>For disjoint Y, Z, W ⊆ V:</p><formula xml:id="formula_9">(Y ⊥ ⊥ Z|W, I) D I ⇐⇒ (Y ⊥ ⊥ Z|W, I, F (I,J) ) Aug (I,J) (D)<label>(2)</label></formula><p>For disjoint Y, Z, W ⊆ V, where</p><formula xml:id="formula_10">K I = K \ J, K J = K \ I, W I = K I ∩ W, W J = K J ∩ W, R = K \ W, R I = R ∩ K I , R J = R ∩ K J :          (Y ⊥ ⊥ R J |W, I) D I,R J (W) (Y ⊥ ⊥ W J |W \ W J , I) D I,W J (Y ⊥ ⊥ R I |W, J) D J,R I (W) (Y ⊥ ⊥ W I |W \ W I , J) D J,W I ⇐⇒ (F (I,J) ⊥ ⊥ Y (I) |I (I) , W (I) ) Aug (I,J) (D) (F (I,J) ⊥ ⊥ Y (J) |J (J) , W (J) ) Aug (I,J) (D)<label>(3)</label></formula><p>While the augmented pair graphs encode the same CI statements as the original graph, we know that different graphs may entail the same CI statements. To characterize the I-Markov equivalence, we utilize the structure of Maximal Ancestral Graphs (MAGs). MAGs represent the Markov equivalence class of the original graph, making it possible to compare and analyze equivalence classes without needing the full graph with latent variables. We introduce the following definition to construct a graph structure that captures the I-Markov equivalence.</p><p>Definition 4.5. (Twin Augmented MAG). Given a causal graph D = (V ∪ L, E) and a set of interventions I ⊆ 2 V , for each pair of intervention targets I, J ∈ I, K = I∆J, and the corresponding augmented pair graph Aug (I,J) (D) = (V (I) ∪V (J) ∪{F (I,J) }, E (I) ∪E (J) ∪E), E = {(F (I,J) , S)} S∈K (I) ∪K (J) , construct the MAG of the augmented pair graph and denote it as M AG(Aug (I,J) (D)). The twin augmented MAG, denoted as T win (I,J) (D), is constructed by adding edges (F, S (I) ) and (F, S (J) ) to M AG(Aug (I,J) (D)) if the singleton S (I) or S (J) is adjacent to F in M AG(Aug (I,J) (D)). Proof. The extra cycles contain F , while F has only outgoing edges. Thus, the twin augmented MAGs are ancestral. Suppose there is an inducing path F, X 1 , X 2 , ..., X k , F and X k are not adjacent. Then X k-1 has a directed edge to X k in M AG(Aug(D)) while M AG(Aug(D)) is a MAG by definition. Thus, a contradiction arises, and the supposition does not hold. The twin augmented MAGs are maximal  1) , Y (1) in both augmented pair graphs. In the twin augmented graphs, we further add F → Y (2) to make the adjacencies around the F node symmetric.</p><formula xml:id="formula_11">X Z Y (a) Graph D1 X (1) Z (1) Y (1) F Z (2) X (2) Y (2) (b) Aug (∅,{Z}) (D1) X (1) Z (1) Y (1) F Z (2) X (2) Y (2) (c) M AG(Aug (∅,{Z}) (D1)) X (1) Z (1) Y (1) F Z (2) X (2) Y (2) (d) T win (∅,{Z}) (D1) X Z Y (e) Graph D2 X (1) Z (1) Y (1) F Z (2) X (2) Y (2) (f) Aug (∅,{Z}) (D2) X (1) Z (1) Y (1) F Z (2) X (2) Y (2) (g) M AG(Aug (∅,{Z}) (D2)) X (1) Z (1) Y (1) F Z (2) X (2) Y (2) (h) T win (∅,{Z}) (D2)</formula><formula xml:id="formula_12">F → Y (1) in M AG(Aug (∅,{Z}) (D 1 )) and M AG(Aug (∅,{Z}) (D 2 )) because there is an inducing path F, Z<label>(</label></formula><p>The motivation of adding extra edges to F nodes comes from the fact that F ⊥ ⊥ Y (I) itself is not testable by comparing the invariances using P I , P J . It requires access to P I,J which is not necessarily given. Therefore, when the invariance does not hold, we cannot distinguish if F is non-separable to Y in only one domain or in both domains. Next, we give a graphical characterization of I-Markov equivalence between causal graphs using Definition 4.5.</p><p>Theorem 4.7. Given two causal graphs 1. M 1 and M 2 have the same skeleton; 2. M 1 and M 2 have the same unshielded colliders;</p><formula xml:id="formula_13">D 1 = (V ∪ L 1 , E 1 ) and D 2 = (V ∪ L 2 , E 2 ),</formula><p>3. If a path p is a discriminating path for a node Y in both M 1 and M 2 , then Y is a collider on the path if and only if it is a collider on the path in the other.</p><p>To illustrate the concepts, we construct the examples in Figure <ref type="figure" target="#fig_1">1</ref>. Graph D 1 in Figure <ref type="figure" target="#fig_1">1a</ref> is the original graph with a confounder between Z, Y . Assume that the intervention set is I = {I 1 = ∅, I 2 = {Z}}. Here we use the index of the targets in the superscripts of the variables for simplicity. Figure <ref type="figure" target="#fig_1">1b</ref> shows how we build the augmented pair graph by adding the F node and pointing it to both Zs in the two interventional subgraphs. In Figure <ref type="figure" target="#fig_1">1c</ref>, we show the MAG of Aug (∅,{Z}) (D 1 ). The edge of (F, Y (1) ) is added because there is an inducing path F, Z (1) , Y (1) in Aug (∅,{Z}) (D 1 ), which means that F is not m-separable from Y (1)  and F is an ancestor of Y (1) . Now that (F, Y (1) ) is presented in M AG(Aug (∅,{Z}) (D 1 )) but not (F, Y (2) ), according to Definition 4.5, we also add the edge of (F, Y (2) ) to finally construct the twin augmented MAG of D 1 , which is T win (∅,{Z}) (D 1 ).</p><p>Next, we repeat the same process for D 2 as illustrated in Figure <ref type="figure" target="#fig_1">1e</ref>. Comparing T win (∅,{Z}) (D 1 ) and T win (∅,{Z}) (D 2 ), we see that they do not satisfy the three conditions from Theorem 4.7 since they have different skeletons. Therefore, we conclude that D 1 and D 2 are not I-Markov equivalent with respect to the given intervention set I. This example also highlights that hard interventions can be more informative than soft interventions because, under a soft intervention on Z, one cannot distinguish the two graphs, and they will be I-Markov equivalent using the results from <ref type="bibr" target="#b22">Kocaoglu et al. (2019)</ref>. However, with a hard intervention, we can distinguish the two graphs D 1 and D 2 from one another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">I-Augmented MAG</head><p>We have demonstrated that the characterization of I-Markov equivalence between two causal graphs can be effectively captured using the proposed twin augmented MAGs. However, for an intervention target set of size k, we will have to inspect all k 2 such structures. This is undesirable, as there exists only one underlying causal graph, and a more compact graph representation is preferred. Additionally, each twin augmented MAG encodes information for only a single pair of distributions, whereas we aim for an objective that encapsulates as much information as possible. To address these challenges, we propose a new graphical structure defined as follows:</p><p>Definition 5.1 (I-augmented MAG). Given a causal graph D = (V, E) and a set of intervention targets I, construct all twin augmented MAGs T win (I,J) (D) for all J ∈ I \ {I}. For each I ∈ I, the Iaugmented MAG related to I is defined as</p><formula xml:id="formula_14">Aug I (D, I) = (V ∪ F , E(D I ) ∪ E) where F = {F (I,J) } J∈I\{I} , E = {(F (I,J) , X (I) )} (F (I,J) ,X (I) )∈E(T win (I,J) (D)),J∈I\{I} .</formula><p>In other words, it is the graph union of each twin augmented MAG's induced subgraph on</p><formula xml:id="formula_15">V (I) ∪ {F (I,J) }. The I-augmented MAG tuple N I (D) is a tuple of all I-augmented MAGs N I (D) = (Aug I (D, I)) I∈I .</formula><p>Remark: The I-augmented MAG Aug I (D, I) preserves all the m-separation statements in the domain of do(I) from the twin augmented MAGs with I in the intervention pair, T win (I,J) (D), J ∈ I \ {I}. The structure of V (I) ∪ F within each twin augmented MAG is preserved in the I-augmented MAG and is not affected by the other domains.</p><p>The constructed I-augmented MAG tuple consists of only k graphs, each of which encapsulates more information on the domain than a twin augmented MAG. Specifically, the set of ADMGs consistent with a twin augmented MAG in one domain is a superset of those consistent with an I-augmented MAG, as the I-augmented MAG imposes stricter constraints of separations across other domains on the causal graph. Furthermore, the graphical conditions for two causal graphs to be I-Markov equivalent, as stated in Theorem 4.7, remain valid when using the I-augmented MAG. Hence, the I-augmented MAG serves as the unified and compact graphical representation.</p><p>In Figure <ref type="figure" target="#fig_4">2</ref>, we demonstrate the construction of I-augmented MAGs with respect to three datasets, including observational data and interventions on X and Z, i.e., I = {I 1 = ∅, I 2 = {X}, I 3 = {Z}}, for the graph D 1 from Figure <ref type="figure" target="#fig_1">1a</ref>. For simplicity, we relabel the observational domain and the interventional domains for targets X and Z as 1, 2, and 3, respectively, in the I-augmented MAGs shown in Figure <ref type="figure" target="#fig_4">2</ref>. Figure <ref type="figure" target="#fig_4">2a</ref>, Figure <ref type="figure" target="#fig_4">2b</ref>, and Figure <ref type="figure" target="#fig_4">2c</ref> are the twin augmented MAGs given (∅, {X}), (∅, {Z}), and ({X}, {Z}) respectively. Based on the twin augmented MAGs, we construct the I-augmented MAGs as shown in Figure <ref type="figure" target="#fig_4">2d</ref>, Figure <ref type="figure" target="#fig_4">2e</ref>, and Figure <ref type="figure" target="#fig_4">2f</ref> for the domains ∅, {X} and {Z} respectively. Each I-augmented MAG has the domain-specific skeleton in the center with the F nodes around it indicating the invariances from other domains. The Iaugmented MAGs entail the same information about the causal graph as the twin augmented MAGs, but they have a much more compact representation. We show the equivalence between twin augmented MAGs and I-augmented MAGs with the following proposition.</p><p>Proposition 5.2. Given two causal graphs </p><formula xml:id="formula_16">D 1 = (V ∪ L 1 , E 1 ), D 2 = (V ∪ L 2 , E 2 )</formula><formula xml:id="formula_17">X (1) Z (1) Y (1) F (1,2) Z (2) X (2) Y (2) (a) T win (∅,{X}) (D1) X (1) Z (1) Y (1) F (1,3) Z (3) X (3) Y (3) (b) T win (∅,{Z}) (D1) X (2) Z (2) Y (2) F (2,3) Z (3) X (3) Y (3) (c) T win ({X},{Z}) (D1) F (1,2) Z (1) X (1)</formula><p>Y ( <ref type="formula" target="#formula_0">1</ref>) </p><formula xml:id="formula_18">F (1,3) (d) Aug ∅ (D1, I) F (1,2) Z (2) X (2) Y (2) F (2,3) (e) Aug {X} (D1, I) F (1,3) Z (3) X (3) Y (3) F (2,3) (f) Aug {Z} (D1, I)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Learning by Combining Experiments</head><p>In this section, we develop an algorithm to learn the causal structure from given datasets. Here we do not assume that the given datasets contain the observational data. Like any learning algorithm, a faithfulness assumption is necessary to infer graphical properties from the corresponding distributional constraints. Therefore, we assume that the provided interventional distributions are h-faithful to the causal graph D, defined below.</p><p>Definition 6.1 (h-faithful). Consider a causal graph D = (V ∪ L, E). A tuple of distributions (P I ) I∈I ∈ P(D, V) is called h-faithful to graph D if the converse for each of the conditions given in Definition 4.1 holds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Learning Objective</head><p>Similar to the case when only observational data is available, it is hard to recover the whole graph in general. Therefore, the objective of the algorithm is to learn a graphical representation that demonstrates a set of I-Markov equivalent graphs. However, although the MAG of the augmented pair graphs proposed in Definition 4.5 denotes the ground truth, it is not always a fundamentally learnable structure from the distributions.</p><p>To witness, let us consider the example in Figure <ref type="figure" target="#fig_1">1c</ref>. The edge (F,</p><formula xml:id="formula_19">Y (2) ) is not in M AG(Aug (∅,{Z}) (D 1 )).</formula><p>While we can only learn from the distributions that P obs (y|w) = P Z (y|w), W ⊆ {X, Z}. The inequality tells us that there is an inducing path from F to Y (1) or Y (2) which we cannot distinguish. Therefore, we proposed the twin augmented MAG to be able to capture the characterization for I-Markov equivalent graphs. Based on that, we construct the I-augmented MAG which is a more compact graphical structure and we utilize as the learning objective. Accordingly, we define the I-augmented graph as follows. </p><formula xml:id="formula_20">SepSet ← ∅; for I in I do E(G I ) ← ∅; for J in I do Run Algorithm 3 on I, J, (P I ) I∈I , V, F I to get E J , SepSet J ; E(G I ) ← E(G I ) ∪ E J ; SepSet ← SepSet ∪ SepSet J ; V (G I ) ← V (I) ∪ F I ; Add G I to L I ; Phase III: Apply Orientation Rules to each G I , I ∈ I; Rule 0: For every unshielded triple X, Y, Z in G I , I ∈ I, orient it as X * → Y ← * Z if Y /</formula><p>∈ SepSet(X, Z). First apply Rule 0, then apply 7 FCI rules in <ref type="bibr">Zhang (2008b)</ref> together with the following 4 additional rules to each G I until none applies. Rule 8: For any edge adjacent to an F node, orient the edge out of the F node. Rule 9: For any I ∈ I, if X ∈ I, X (I) , Y (I) are adjacent in G I , then orient X (I) o- * Y (I) as X (I) → Y (I) . Rule 10: If X (I) → Y (I) in G I for some I ∈ I, replace the circle mark at Y (J) between X (J) and Y (J) in G J with an arrowhead for any J ∈ I \ {I}. Rule 11: In G I , I, J ∈ I, if J = I ∪ {X}, F (I,J) is adjacent to Y (I) , Y / ∈ J, then orient X (I) * - * Y (I) as X (I) → Y (I) . Output: I-augmented graph tuple L I The I-augmented graph tuple L I (D) is a tuple of all I-augmented graphs L I (D) = (G I (D, I)) I∈I . We will omit the graph D or the intervention targets I in the brackets when it is clear from the context for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">The Learning Algorithm</head><p>We propose Algorithm 1 to learn the I-augmented graph tuple from the given experiments. The algorithm is inspired by the FCI algorithm. To explain the algorithm, we first outline the FCI procedure, which operates in three phases given an independence model over the measured variables <ref type="bibr" target="#b49">Zhang (2006)</ref>. In phase I, it initializes a complete graph with only circle edges (o-o ), then removes edges between pairs of nodes if a separating set between them exists, and records all the separating sets. In Phase II, it identifies unshielded triples A, B, C and orients the edges into B if B is not in the separating set of A and C. In phase III, it applies a set of orientation rules to refine the graph. The orientation rules serve for the MAG properties, found separating sets, and the soundness and completeness of the previous phases, i.e., all correct edges and unshielded colliders have been directed. Notice that if two nodes X, Y are separated given Z in the I-augmented MAG, they are also separated given Z ∪ F since F nodes are introduced as source nodes and Algorithm 2 Algorithm for Creating F Nodes</p><formula xml:id="formula_21">Input: Intervention set I, intervention I Initialize F ← ∅; for J in I \ {I} do F ← F ∪ {F (I,J) } Output:</formula><p>The set of F nodes F thus conditioning on them will not activate any extra path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Algorithm for Finding Separating Set</head><p>Input: Target I and J, intervetional distributions It puts a circle edge between each pair of nodes X, Y ∈ V. This constructs the domain specific skeleton G (I) under target I. After that, we attach the F nodes to the I-augmented graph using Algorithm 2 and then put a circle edge between any F node and any X ∈ V. In Phase II, we learn the skeleton for each I-augmented graph. G I . For each I ∈ I, we retrieve the I-augmented graph G | with all circle edges. Algorithm 3 tests if there is a separating set between any pair of nodes X, Y in G I . If both nodes are non-F nodes, this can be tested through checking if P I (y|w, x) and P I (y|w). If one of them is an F node, the can be tested by checking the equality between P I (y|w) and P J (y|w) for Y ∈ V, W ⊆ V. Two F nodes are separated by default. If there is no such set W, we preserve the circle edge between X and Y . Otherwise, we remove the circle edge from G I . In Phase III, we apply orientation rules to learn more edges in the constructed I-augmented graphs. Notice that the skeleton G (I) in G I is a PAG; thus, the FCI rules are still applicable here. We first use Rule 0 to to orient all the unshielded triples by checking if the node in the center of the triple is in the separating set of the two end nodes. After that, Algorithm 1 will repeatedly apply the FCI rules (Rules 5 to 7 are not included here as they are related to selection bias nodes) together with 4 new rules until none apply.</p><formula xml:id="formula_22">(P I ) I∈I , observable variables V, F nodes F Initialize E ← ∅; if I = J then for X, Y in V do SepF alg ← F alse; for W ⊂ V do if P I (y|w, x) = P I (y|w) then SepF lag ← T rue SepSet(X (I) , Y (I) ) = W (I) ∪ F ∪ I (I) ; if SetpF lag = F alse then E ← E ∪ (X (I) , Y (I) ); else for Y in V do SepF lag ← F alse; if Y in I∆J then Pass; else for W ⊆ V do if P I (y|w) = P J (y|w) then SepF lag ← T rue; SepSet(F, Y (I) ) ← I (I) ∪ W (I) ; SepSet(F, Y (J) ) ← J (J) ∪ W (J) ; if SetF lag = F alse then E ← E ∪ (F (I,J) , Y<label>(</label></formula><p>Rule 8 (F-node edges): For any edge adjacent to an F node, orient the edge out of the F node.</p><p>Rule 9 (Intervened nodes): For any I ∈ I, if X ∈ I, X (I) , Y (I) are adjacent in G I , then orient X (I) o- * Y (I) as X (I) → Y (I) . The intuition of this rule is that since X is intervened, all the non-descendants of X become separable from X in D I . Thus, Y has to be a descendant of X in D I .</p><p>Rule 10 (Consistency of Skeletons): If X (I) → Y (I) in G I for some I ∈ I, replace the circle mark at Y (J) between X (J) and Y (J) in G J with an arrowhead for any J ∈ I \ {I}. The intuition of this rule stems from the fact that each skeleton is obtained from the same causal graph D. The ancestral relationship between any pair of nodes cannot be reversed by hard interventions.</p><p>Rule 11 (Inducing Path): ) , Y / ∈ J, then orient X (I) * - * Y (I) as X (I) → Y (I) . The intuition is that the F nodes cannot be separated from Y / ∈ K, meaning there is an inducing path to Y (I) or Y (J) through X (I) or X (J) . If X is intervened, the inducing path cannot go through X (J) .</p><formula xml:id="formula_23">In G I , I, J ∈ I, if J = I ∪ {X}, F (I,J) is adjacent to Y (I</formula><p>To illustrate how each step in Algorithm 1 works, we show an example in Appendix A.7. We establish the soundness of the proposed algorithm. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Enumerate All ADMGs</head><p>In this experiment, we aim to demonstrate that the I-MEC size under hard interventions is smaller than that under soft interventions in general. Here is how we set up the experiments. Given the number of observable variables n, we iterate through all possible ADMGs structures with n nodes. The number of such ADMGs can be found as follows. We first generate all possible DAGs (not necessarily connected) with n nodes. Then, for each pair of nodes in a DAG, there can be a bidirected edge or not. Thus, the number of ADMGs under consideration is 2 ( n 2 ) multiplied by the number of all DAGs. Each time, we randomly pick an ADMG G as the ground truth graph. Assuming that the size of the intervention targets is 2, we construct the twin augmented MAG M 1 of G following Definition 4.5 and the Augmented MAG M 2 of G following Definition 4 in <ref type="bibr" target="#b22">Kocaoglu et al. (2019)</ref>. We then enumerate all possible ADMGs, and for each candidate ADMG G ′ , we construct its corresponding M ′ 1 and M ′ 2 , and compare M 1 , M ′ 1 following Theorem 4.7, M 2 , M ′ 2 following Theorem 2 in <ref type="bibr" target="#b22">Kocaoglu et al. (2019)</ref>. For each n, we repeat the experiment 30 times and calculate the average size of I-MEC size together with standard errors. We consider two types of sampling ADMGs, random and complete. 'Random' means the ADMG is constructed by randomly adding directed and bidirected edges with a probability of 0.5 between each pair of nodes while not creating any cycle. 'Complete' means we first construct a random complete DAG and then randomly add bidirected edges with a probability of 0.5 between each pair. For intervention targets, we assume they are either atomic or an empty set. We only show the results for small n, as the number of ADMGs grows super-exponentially with n. The numerical results are shown in Table <ref type="table" target="#tab_0">1</ref>. We notice that the number of ADMGs grows very fast with n. The results have a high standard error. This is due to the differences between the sampled graphs. Nevertheless, under hard interventions, the I-MEC size tends to shrink the I-MEC size more efficiently than with soft interventions on average, showing the power of hard interventions. Furthermore, as n grows, the ratio of hard I-MEC divided by the soft I-MEC decreases, meaning that hard interventions extract more information on the causal graphs.</p><p>n </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Sample ADMGs</head><p>When n = 5, the total number of valid ADMGs is 29,983,744, which is intractable to enumerate. Instead, we can sample ADMGs to estimate the expectation of the probability of a randomly sampled ADMG to be I-Markov equivalent to a given ADMG using Hoeffding's Inequality. To do this, given n, we randomly sample a DAG that is a complete graph using the uniform CPDAG sampler by <ref type="bibr" target="#b47">Wienöbst et al. (2021)</ref>. Then, for each sampled complete DAG, we add bidirected edges uniformly to each pair of nodes to construct a ground truth ADMG. To compare with the ADMG, we randomly pick two intervention targets that are either an empty set or atomic, and then randomly sample ADMGs following the same process and construct the augmented graphs. Suppose for each ground truth ADMG, we draw M such random samples. For the i-th sample, S i = 1, if it is I-Markov equivalent to the true graph and S i = 0 otherwise. We define S = M i=1 S i which shows the number of I-Markov equivalent ADMGs. We denote E S as the expectation we are approximating. Thus, according to Hoeffding's Inequality, we have:</p><formula xml:id="formula_24">P ( S M -E S ≥ ǫ) ≤ exp(-2M ǫ 2 )<label>(4)</label></formula><p>We choose ǫ = 0.01 and exp(-2M ǫ 2 ) = 0.01 for M with M = 23025. For each setting, we randomly sample 50 ground truth ADMGs and then take the average. The results are shown in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We address the challenge of learning the causal structure underlying a phenomenon of interest using a combination of several experimental data. Specifically, different from <ref type="bibr" target="#b22">Kocaoglu et al. (2019)</ref>, we study the problem under hard interventions. The motivation comes from the observation that hard interventions are more informative than soft ones, and thus we can learn more about the original causal graph. Our approach builds on a generalization of the converse of Pearl's do-calculus (Theorem 3.1), which introduces new tests that can be applied to data. These tests translate into structural constraints. We define an interventional equivalence class based on these criteria (Definition 4.1) and provide a graphical characterization for the equivalence of two causal graphs (Theorem 4.7) using the proposed twin augmented MAG structure (Definition 4.5).</p><p>To construct a unified graphical representation that is closer to the ground truth ADMG, we combine the twin augmented MAGs into a I-augmented MAG (Definition 5.1) and show the equivalence of the two representations (Proposition 5.2. Finally, we propose an algorithm (Algorithm 1) to learn the interventional equivalence class represented by the I-augmented graphs (Definition 6.2) from data, incorporating novel orientation rules. We also prove the soundness of the proposed algorithm (Theorem 6.3). The empirical results in Section 7 show that hard interventions efficiently decrease the size of I-Markov Equivalence Class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Detailed Related Works</head><p>Equivalence Class: The learning process uses data constraints to infer the causal diagram. However, these constraints often cannot uniquely identify the complete diagram. As a result, the analysis typically focuses on an equivalence class (EC) of causal diagrams that captures the constraints implied by the underlying causal system. When only observational data is available, such EC is called MEC. It characterizes causal graphs with the same set of d-separation statements over observable variables <ref type="bibr" target="#b41">(Spirtes et al., 2001;</ref><ref type="bibr" target="#b45">Verma &amp; Pearl, 1992;</ref><ref type="bibr" target="#b42">Spirtes et al., 2013;</ref><ref type="bibr">Meek, 2013a)</ref>  <ref type="formula">2020</ref>) often assume Markovianity or specific functional models (e.g., linearity), or combinations of observational and interventional data with both known and unknown targets. In contrast, JCI combines all data into a single dataset and performs learning on the pooled data <ref type="bibr" target="#b29">(Mooij et al., 2020)</ref>. <ref type="bibr" target="#b20">(Ke et al., 2019)</ref> introduces a neural-network-based framework that leverages observational and interventional data to identify causal structures, even when intervention targets are unknown, demonstrating superior performance in structure recovery tasks. <ref type="bibr" target="#b0">(Acharya et al., 2018)</ref> demonstrates that with O(log n) interventions and O(n/ǫ 2 ) samples per intervention, one can effectively distinguish whether an unknown CBN matches a given model or differs by more than ǫ in total variation distance. <ref type="bibr" target="#b19">(Jiang &amp; Aragam, 2023)</ref> offers the first results to characterize conditions under which causal representations are identifiable without parametric assumptions, even in settings with unknown interventions and without assuming faithfulness. <ref type="bibr" target="#b1">(Addanki et al., 2021)</ref> aims to determine the directions of all causal or ancestral relations in G using a minimum-cost set of interventions. <ref type="bibr" target="#b3">(Brouillard et al., 2020)</ref> proposes a neural network-based optimization framework for learning causal DAGs from both observational and interventional data, including unknown targets. <ref type="bibr" target="#b24">Lopez et al. (2022)</ref> developed a differentiable causal discovery for large and high-dimensional data. <ref type="bibr" target="#b44">Tigas et al. (2022)</ref> proposed an experiment design algorithm to adaptively choose the intervention targets. <ref type="bibr" target="#b25">(Mascaro &amp; Castelletti, 2023)</ref> proposes a Bayesian causal discovery algorithm that learns the causal graph from unknown general intervention under causal sufficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Proof for Proposition 3.2</head><p>In this section, we extend the do-calculus rules to enable their application across two arbitrary interventions. This extension is crucial for characterizing our equivalence class when arbitrary sets of interventional distributions are provided.</p><p>Proof. Rule 1: The results follow from rule 1 of Theorem 3.1. Rule 2: From (Y ⊥ ⊥ K J |W, I) D I,K J , we can derive from rule 2 of Theorem 3.1 that P I (y|w, z) = P I,J (y|w, z). Similarly, given (Y ⊥ ⊥ K I |W, J) D J,K I , we have P J (y|w, z) = P I,J (y|w, z). Together, we have</p><formula xml:id="formula_25">P I (y|w, z) = P J (y|w, z).</formula><p>Here, we use P I,J as the intermediate distribution to show the equality and use rule 2 in Theorem 3.1 twice. This is necessary, as for any S ⊂ I ∪ J, D S would be a denser graph that contains fewer m-separation statements than D I,J . Next, we show that it is also sufficient.</p><formula xml:id="formula_26">Lemma A.1. If ∃S ⊂ W \ (I ∪ J), s.t. (Y ⊥ ⊥ K J , S|W, I) D I,K J ,S ∧ (Y ⊥ ⊥ K I , S|W, J) D J,K I ,S , then (Y ⊥ ⊥ K J |W, I) D I,K J ∧ (Y ⊥ ⊥ K I |W, J) D J,K I . Proof. Suppose otherwise (Y ⊥ ⊥ K J |W, I) D I,K J , then there is an m-connecting path p from Y ∈ Y to U ∈ K J in D I,KJ . Given (Y ⊥ ⊥ K J , S|W, I) D I,K J ,S , we have (Y ⊥ ⊥ K J |W, I) D I,K J ,S . Comparing (Y ⊥ ⊥ K J |W, I) D I,K J and (Y ⊥ ⊥ K J |W, I) D I,K J ,S</formula><p>, the only difference between the two statements is the edges outgoing from S. Removing the edges creates p. Consider the case that S ∈ S is in p. For p to be m-connecting, S can only be a collider. However, such a m-connecting path indicates that there is also a m-connecting path from Y to S which contradicts the given conditions. Thus, S cannot be in p. Then, there has to be a collider in p activated by some S ∈ S in D I,KJ . Consider a collider C that is closest to Y in p. C is an ancestor of S. Then the path created by concatenating the subpath from Y to C and C to S is an m-connecting path which is also in D I,KJ,S . This is a contradiction. Following the same process we can also show that (Y ⊥ ⊥ K I |W, J) D J,K I .</p><p>Lemma A.1 shows that the graphical conditions for P I (y|w, z) = P I,J (y|w, z) = P J (y|w, z) are sufficient to use another interventional distribution P I,J,S as the intermediate distribution to show the equality.</p><p>Rule 3: From (Y ⊥ ⊥ K J |W, I) D I,K J (W) , we can tell using rule 3 of Theorem 3.1 that P I (y|w) = P I,J (y|w). From (Y ⊥ ⊥ K I |W, J) D J,K I (W) , we have P I,J (y|w) = P J (y|w). Together, we have P I (y|w) = P J (y|w). Similarly, we apply the do-do rule twice and use P I,J as an intermediate distribution to show the equality. Likewise, any distribution that corresponds to a denser graph indicates the conditions. Next, we show the sufficiency of the conditions. ) , the only difference in the graph is the edges into S(W). Consider the case that there is some S ∈ S(W) in p. Consider S that is closest to Y . S cannot be a collider on p since it is not an ancestor of any W ∈ W, and thus p will be blocked. Let us consider the 2 cases:</p><formula xml:id="formula_27">Lemma A.2. If ∃S ⊂ V\(I∪J∪W), such that (Y ⊥ ⊥ K J , S|W, I) D I,K J (W),S(W) ∧(Y ⊥ ⊥ K I , S|W, J) D J,K I (W),S(W) , then (Y ⊥ ⊥ K J |W, I) D I,K J (W) ∧ (Y ⊥ ⊥ K I |W, J) D J,K I (W) . Proof. Suppose otherwise (Y ⊥ ⊥ K J |W, I) D I,K J (W) , then there is an m-connecting path p from Y ∈ Y to U ∈ K J (W) in D I,KJ(W) . Given (Y ⊥ ⊥ K J , S|W, I) D I,K J (W),S(W) , we have (Y ⊥ ⊥ K J |W, I) D I,K J (W),S(W) . Comparing (Y ⊥ ⊥ K J |W, I) D I,K J (W),S(W) and (Y ⊥ ⊥ K J |W, I) D I,K J (W</formula><p>If S has an outgoing edge towards Y on p, then there is a directed path from S to Y because otherwise there has to be a collider C ∈ W in between Y and S, and S will be an ancestor of C. However, the subpath from Y to S in p would then be m-connecting in D I,KJ(W),S(W) , which is a contradiction.</p><p>If S has an incoming edge from Y on p, then there is a directed path S to U on p. Otherwise, there has to be a collider C in the subpath between S and U on p. Such C that is closest to S makes S an ancestor of C ∈ W, a contradiction. Nevertheless, if there is a directed path from S to U , S is an ancestor of U . If U is an ancestor of any W ∈ W, S will also be an ancestor of W , a contradiction. Thus U cannot be an ancestor of any W ∈ W, and the edges into U will be removed in D I,KJ(W) which contradicts the assumption that p is an m-connecting path.</p><p>Therefore, S cannot be on p. While S has to be an ancestor of some W ∈ W to activate p if it is not on p, this contradicts the assumption that S ∈ S(W). To conclude, we show that (Y ⊥ ⊥ K J |W, I) D I,K J (W) . Following the same process, we can also show that (Y ⊥ ⊥ K I |W, J) D J,K I (W) .</p><p>Lemma A.2 shows that the graphical conditions for P I (y|w) = P I,J (y|w) = P J (y|w) are sufficient to use another interventional distribution P I,J,S as the intermediate distribution to show the equality by using rule 3 of Theorem 3.1 twice.</p><p>Rule 4: We begin by introducing a useful lemma.</p><formula xml:id="formula_28">Lemma A.3. For disjoint X, Y, W ⊆ V, S ⊆ V \ (X ∪ Y), S ∩ W = ∅, S = W, then P x (y|w) = P x,s (y|w) if: (S R ⊥ ⊥ Y|W, X) D X,S R (W) ∧ (S W ⊥ ⊥ Y|W \ S W , X) D X,S W where S W = S ∩ W, S R = S \ W. Proof. Denote the statement (S R ⊥ ⊥ Y|W, X) D X,S R (W) ∧ (S W ⊥ ⊥ Y|W \ S W , X) D X,S W</formula><p>as C 1 . We first show that, by applying rule 3 and rule 2 in Theorem 3.1 sequentially, we can transform from P x to P x,s . Specifically, P x (y|w) = P x,sR (y|w) if (S R ⊥ ⊥ Y|W, X) D X,S R (W) , and P x,sR (y|w</p><formula xml:id="formula_29">) = P x,sR,sW (y|w) if (S W ⊥ ⊥ Y|W \ S W , X, S R ) D X,S R ,S W</formula><p>. By definition, P x,sR,sW (y|w) = P x,s (y|w).</p><p>Denote the statement</p><formula xml:id="formula_30">(S R ⊥ ⊥ Y|W, X) D X,S R (W) ∧ (S W ⊥ ⊥ Y|W \ S W , X, S R ) D X,S R ,S W as C 2 .</formula><p>Next, we show that C 1 and C 2 are equivalent. Notice that they share the same statement, and we just need to show that the other one holds true.</p><p>(</p><formula xml:id="formula_31">C 1 ⇒ C 2 ): Suppose otherwise, (S W ⊥ ⊥ Y|W \ S W , X, S R ) D X,S R ,S W , then there is an m-connecting path p from Y ∈ Y to U ∈ S W in D X,SR,SW . Comparing (S W ⊥ ⊥ Y|W \ S W , X, S R ) D X,S R ,S W<label>and</label></formula><formula xml:id="formula_32">(S W ⊥ ⊥ Y|W \ S W , X) D X,S W</formula><p>, the difference is the S R in the conditioning set and the edges into S R .</p><p>Consider the case that there is some S ∈ S R in p. Since the edges into S are removed, S can only have outgoing edges, but conditioning on S will then block p. Thus, S cannot be in p. If S is not in p, since the edges into S are removed, conditioning on S will not activate any path. Thus the supposition cannot hold.</p><p>(C 2 ⇒ C 1 ): Suppose otherwise, (S W ⊥ ⊥ Y|W \ S W , X) D X,S W . Then there is an m-connecting path</p><formula xml:id="formula_33">p from Y ∈ Y to U ∈ S W in D X,SW . Comparing (S W ⊥ ⊥ Y|W \ S W , X, S R ) D X,S R ,S W and (S W ⊥ ⊥ Y|W \ S W , X) D X,S W</formula><p>, the difference is the S R in the conditioning set and the edges into S R . Consider the case that there is some S ∈ S R that is closest to Y in p.</p><p>If S is a colliser on p, then S is an ancestor of some W ∈ W. There is a m-connecting path from S to Y in D X,SR(W) . A contradiction.</p><p>If S has an outgoing edge towards Y in p, there has to be a collider C / ∈ W between S and Y in p. Otherwise, the subpath between S and Y will be m-connecting in D X,SR(W) which contradicts the supposition. Since p is m-connecting, C has to be an ancestor of some W ∈ W in D X,SW . To block p in D X,SR,SW , there has to be some S ′ ∈ S that is in between C and W . This will create an m-connecting path from S ′ to Y in D X,SR(W) , which is a contradiction.</p><p>If S has an outgoing edge towards S W in p, then S has to be an ancestor of some W ∈ W in D X,SR(W) , which is a contradiction. Therefore, S is not in p. There has to be a collider C / ∈ W in p. Consider such C closest to Y . There is a directed path from C to S and a directed path from S to some W ∈ W in D X,SW for p to be m-connecting. However, this makes S an ancestor of W in D X,SR(W) , and the path created by concatenating the directed path from C to S and the subpath from C to Y in p would be d-connecting in D X,SR(W) . A contradiction. The supposition does not hold.</p><p>This concludes the proof of this lemma. By applying Lemma A.3 twice, we can derive the graphical condition for P I (y|w) = P I,J (y|w) = P J (y|w) for two arbitrary interventions I, J. The following lemma shows that this is a sufficient condition.</p><formula xml:id="formula_34">Lemma A.4. If ∃S ⊂ V \ (I ∪ J), S R = S \ W, S W = S ∩ W, such that (Y ⊥ ⊥ R J , S R |W, I) D I,K J (W),S R (W) ∧ (Y ⊥ ⊥ W J , S W |W \ (S W ∪ W J ), I) D IW J ,S W , then (Y ⊥ ⊥ R J |W, I) D I,R J (W) ∧ (Y ⊥ ⊥ W J |W \ W J , I) D I,W J .</formula><p>Proof. We first consider (Y ⊥ ⊥ R J |W, I) D I,R J (W) . Suppose otherwise (Y ⊥ ⊥ R J |W, I) D I,R J (W) , then there is an m-connecting path p from Y ∈ Y to U ∈ R J in D I,RJ(W) . From the given condition, we know that (Y ⊥ ⊥ R J |W, I) D I,K J (W),S R (W) . The only difference is the edges into S R (W) in D I . If there is any S ∈ S R in p, then it has only outgoing edges. Since p is m-connecting, the subpath from S to Y on p is also m-connecting in D I,RJ(W),SR(W) , which is a contradiction. Thus S R cannot be on p. To block p in D I,RJ(W),SR(W) , there is a collider C in p that is an ancestor of some W ∈ W. C is activated in p in D I,RJ(W) but not activated in D I,RJ(W),SR(W) . This requires some S ∈ S R (W) to be an ancestor of W , which is impossible. Therefore, the supposition does not hold.</p><p>Next, we consider</p><formula xml:id="formula_35">(Y ⊥ ⊥ W J |W \ W J , I) D I,W J . Suppose otherwise, (Y ⊥ ⊥ W J |W \ W J , I) D I,W J , then there is an m-connecting path p from Y ∈ Y to U ∈ W J in D I,WJ . p is blocked in D I,WJ,SW . Comparing (Y ⊥ ⊥ W J |W \ W J , I) D I,W J and (Y ⊥ ⊥ W J |W \ (S W ∪ W J ), I) D IW J ,S W</formula><p>, the only difference is the edges outgoing from S W . If there is some S ∈ S W in p, then S has to be a collider. Consider such S closest to Y . Since p is m-connecting, then the subpath from S to Y is also m-connecting in D IWJ ,SW , which is a contradiction. Thus, S cannot be in p. For S to block p in D IWJ,SW while not in p, it has to be an ancestor of some W ∈ W and a descendant of some collider in p. However, since S ∈ W, it can still activate the collider in p in D IWJ,SW . Therefore, the supposition does not hold.</p><p>By applying Lemma A.4 twice, we can show that it is sufficient to transfer through P I,J . This concludes the proof of this theorem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Proof for Proposition 4.4</head><p>We show the graphical conditions on the augmented pair graphs are equivalent to those given in the generalized causal calculus rules.</p><p>(⇒) Suppose otherwise (F ⊥ ⊥ Y (I) |I (I) , W (I) ) Aug (I,J) (D) , then there is an m-connecting path p from F to Y (I) ∈ Y (I) , in Aug (I,J) (D). If p is a frontdoor path through S (I) , since I (I) , W (I) are conditioned on, only R (I) J could be in p. However, the path from R J to Y would be m-connecting in D I,RJ(W) which is a contradiction. If p is a backdoor path from F to U ∈ S (I) to Y (I) ∈ Y (I) , since the edges into I (I) are removed, U can only be from R (I)</p><formula xml:id="formula_36">J or W (I) J . If U ∈ W (I) J , then it contradicts (Y ⊥ ⊥ W J |W \ W J , I) D I,W J . If U ∈ R (I)</formula><p>J , U could be either an ancestor of some W (I) ∈ W (I) or a non-ancestor of any W (I) ∈ W (I) . For the case that U is not an ancestor of any W (I) ∈ W (I) , p is blocked by U as an inactivated collider. If U is an ancestor of some W (I) ∈ W (I) , then the subpath from U to Y (I) would indicate an m-connecting path from R J to Y in D I,WJ which contradicts (Y ⊥ ⊥ R J |W, I) D I,R J (W) . Thus, the supposition does not hold.</p><p>(⇐) Suppose otherwise, there are two cases to consider, either</p><formula xml:id="formula_37">(Y ⊥ ⊥ R J |W, I) D I,R J (W) or (Y ⊥ ⊥ W J |W \ W J , I) D I,W J . If (Y ⊥ ⊥ W J |W \ W J , I) D I,W J</formula><p>, there is an m-connecting path p from Y ∈ Y to U ∈ W J in D I,WJ . p cannot be a frontdoor path at U , since all edges outgoing from W J are removed. While a valid backdoor path at U indicates that there is also a valid path from F to Y (I) through U (I) in Aug (I,J) (D). Thus, this case is impossible.</p><p>If</p><formula xml:id="formula_38">(Y ⊥ ⊥ W J |W \ W J , I) D I,W J , there is an m-connecting path p from Y ∈ Y to U ∈ R J in D I,RJ(W) .</formula><p>p cannot be a frontdoor path at U , because otherwise the path constructed by adding F → U (I) to p in Aug (I,J) (D) will be m-connecting. Thus, p can only be a backdoor path at U . If U is not an ancestor of any W ∈ W in D I , the edges into U are removed and such p do not exist. Else if U is an ancestor of some W ∈ W in D I , W (I) will activate the path constructed by adding F → U (I) to p in Aug (I,J) (D), which contradicts (F ⊥ ⊥ Y (I) |I (I) , W (I) ) Aug (I,J) (D) . Therefore, the supposition does not hold.</p><p>For the same reason, we can show that</p><formula xml:id="formula_39">(Y ⊥ ⊥ R I |W, J) D J,R I (W) ∧ (Y ⊥ ⊥ W I |W \ W I , J) D J,W I ⇔ (F ⊥ ⊥ Y (J) |J (J) , W (J) ) Aug (I,J) (D) .</formula><p>Proof of Proposition 4.4: The follows from Proposition A.5.</p><p>A.4 Proof for Theorem 4.7</p><p>Proof. (If ) Suppose that the twin augmented MAGs T win (I,J) (D 1 ), T win (I,J) (D 2 ) for all I, J ∈ I satisfy the 3 conditions. Then they induce the same m-separations and vice versa. Then by Proposition 4.4 that D 1 and D 2 impose the same constraints over the distribution tuples. Thus P I (D 1 , V) = P I (D 2 , V).</p><p>(Only if ) Suppose for a pair of interventions I, J ∈ I, M 1 = T win (I,J) (D 1 ), M 2 = T win (I,J) (D 2 ) do not fully satisfy the 3 conditions. Then they must induce at least one different m-separation statement. We need to show that all the differences in m-separation statements induced by different M structures can be captured by some m-separation statements that are testable by the distribution tuples, and therefore, the difference in m-separation would be inducing different constraints on P I (D 1 , V) and P I (D 2 , V). Thus the condition that P I (D 1 , V) = P I (D 2 , V) will no longer hold, which is a contradiction.</p><p>We start by showing all testable m-separation statements. For an arbitrary twin augmented MAG M = (V (I) ∪ V (J) ∪ {F }, E (I) ∪ E (J) ∪ E), the testable m-separation statements are as follows:</p><formula xml:id="formula_40">T ={(X (I) ⊥ ⊥ Y (I) |Z (I) , I (I) , F ) M : X, Y ⊆ V, Z ⊆ V \ (X ∪ Y)}∪ {(X (J) ⊥ ⊥ Y (J) |Z (J) , J (J) , F ) M : X, Y ⊆ V, Z ⊆ V \ (X ∪ Y)}∪ {(F ⊥ ⊥ Y (I) |I (I) , Z (I) ) M ∧ (F ⊥ ⊥ Y (J) |J (J) , Z (J) ) M : Y ⊆ V, Z ⊆ V \ Y}</formula><p>Next, we show that M 1 and M 2 should have the same skeleton.</p><p>First, we show that they have the same skeleton on V (I) . Suppose otherwise, in M 1 , X (I) and Y (I) are adjacent but they are non-adjacent in M 2 . Then it implies that (X (I) ⊥ ⊥ Y (I) |Z (I) , F ) M1 ∧ (X (I) ⊥ ⊥ Y (I) |Z (I) , F ) M2 for some Z ⊆ V. Then we can further condition on I (I) while preserving the m-separations since edges into I (I) are removed and thus conditioning on it will not activate any extra path. Therefore, we have (X (I) ⊥ ⊥ Y (I) |Z (I) , I (I) , F ) M1 ∧ (X (I) ⊥ ⊥ Y (I) |Z (I) , I (I) , F ) M2 which is a pair of different testable statements in T . Similarly, M 1 and M 2 also have the same skeleton in V (J) . What remains to be demonstrated is that the F nodes share the same adjacencies in both graphs.</p><p>By the construction of twin augmented MAGs, F is adjacent to K (I) , K (J) in both M 1 and M 2 . We need to show that F has the same adjacencies to X / ∈ K in both graphs. Suppose otherwise, F is adjacent to X (I) in M 1 , but non-adjacent to X (I) in M 2 . According to our construction of M 1 , M 2 , F is adjacent to X (I) , X (J) in M 1 but non-adjacent to them in M 2 . We introduce the following lemma which shows that in this case, we can still find a pair of different testable m-separation statements which reflect this structural difference.</p><p>Lemma A.6. Consider a causal graph D = (V ∪ L, E) given a set of intervention targets I ⊆ 2 V . Construct its twin augmented MAG M = (V (I) ∪ V (J) ∪ {F }, E (I) ∪ E (J) ∪ E), for I, J ∈ I. If there exists minimal</p><formula xml:id="formula_41">W 1 , W 2 ⊆ V, such that (F ⊥ ⊥ X (I) |I (I) , W (I) 1 ) M ∧(F ⊥ ⊥ X (J) |J (J) , W (J) 2 ) M , then (F ⊥ ⊥ X (I) |I (I) , W (I) ) M ∧ (F ⊥ ⊥ X (J) |J (J) , W (J) ) M , where W = W 1 ∪ W 2 .</formula><p>Proof. Suppose otherwise (F ⊥ ⊥ X (I) |I (I) , W (I) ) M , meaning that conditioning on W (I) activates extra paths from F to X (I) in M. Obviously, I (I) can neither be on the paths nor activate a collider on the paths. Consider a m-connecting path p (I) from F to X (I) given W (I) in M. Then there is a collider</p><formula xml:id="formula_42">C (I) 1 on p (I)</formula><p>which is activated by some</p><formula xml:id="formula_43">W (I) 2 ∈ W (I)</formula><p>2 . Let the subgraph of M induced by V (J) ∪ F be G J . F and X (J)  are blocked by W 2 meaning that the corresponding path p (J) in G J is either blocked by inactivated colliders or does not exist due to removed edges into J. In both cases, p (J) is blocked by ∅. However, due to the minimality of W 2 , it has to block some path other than p (J) . Consider W x ∈ W 2 which is closest to X and is a descendant of a collider C (J) 1 on p (J) . Denote the path created by concatenating direct paths from</p><formula xml:id="formula_44">C (J) 1 to W J)</formula><p>x and C (J) 1 to X (J) as p (J)</p><p>x . Suppose there is a path p</p><formula xml:id="formula_45">(J) 1 from F to X (J) that is blocked by W (J) x . Since p (J) 1 is blocked by W (J) x , W (J) x cannot be a collider on p (J)</formula><p>1 . If there is an edge into W (J) x from F 's side, then the subpath of p (J) x will be m-connecting. The subpath from F to W (J) x has to be blocked by inactivated colliders or conditioning on a non-collider. In either case, W x is not necessary for blocking p (J) 1 . Conversely, there has to be an outgoing edge from W (J) x towards F . Consequently, on p</p><formula xml:id="formula_46">(J)</formula><p>1 , F has an outgoing edge towards W (J)</p><p>x , while W (J) x has an outgoing edge towards F . Thus there has to be a collider in between F and W (J)</p><p>x . Consider such a collider</p><formula xml:id="formula_47">C (J) 2 ∈ W (J) 2</formula><p>that is closest to F . Nevertheless, according to the minimality of W 2 , C (J) 2 has to block another path. If we repeat this process for n = |V| times, we show that |W 2 | &gt; n, which is impossible. Thus the supposition that (F ⊥ ⊥ X (I) |I (I) , W (I) ) M does not hold. Similarly, we can show that (F ⊥ ⊥ X (J) |J (J) , W (J) ) M which concludes the proof.</p><p>Therefore, according to Lemma A.6, the structural difference implies that we can find some W ∈ W\{X} such that (F ⊥ ⊥ X (I) |I (I) ,</p><formula xml:id="formula_48">W (I) ) M1 ∨ (F ⊥ ⊥ X (J) |J (J) , W (J) ) M1 while (F ⊥ ⊥ X (I) |I (I) , W (I) ) M2 ∧ (F ⊥ ⊥ X (J) |J (J) , W (J) ) M2</formula><p>, which is a pair of different testable m-separation statements. To conclude, M 1 , M 2 have the same skeleton.</p><p>Next, we show that M 1 and M 2 have the same unshielded colliders. We start by showing that they have the same unshielded colliders in the vertex induced subgraph on V (I) and V (J) . Suppose otherwise, X (I) , Y (I) , Z (I) is an unshielded collider in M 1 but not in M 2 . Since Y (I) is not a collider in M 2 , it has to be conditioned on to make X (I) and Z (I) m-separable. Then we have (X</p><formula xml:id="formula_49">(I) ⊥ ⊥ Z (I) |I (I) , W (I) ) M1 ∧ (X (I) ⊥ ⊥ Z (I) |I (I) , W (I) , Y (I) ) M1 and (X (I) ⊥ ⊥ Z (I) |I (I) , W (I) ) M2 ∧ (X (I) ⊥ ⊥ Z (I) |I (I) , W (I) , Y (I) ) M2 for some W ⊆ V \ {Y }, which contains a pair of different testable statements.</formula><p>Then we need to show that unshielded colliders which include F nodes are also the same in both graphs. Due to the construction, F can only have outgoing edges, thus it can only be an end node in the collider. Suppose F, Y (I) , Z (I) is an unshielded collider in</p><formula xml:id="formula_50">M ! but not in M 2 . More specifically, F → Y (I) ← * Z (I) in M 1 and F → Y (I) → Z (I) in M 2 . There are 2 cases: Y ∈ K or Y / ∈ K. First, consider Y ∈ K. Y has to be in J \ I, then in the induced subgraph of V (J) , we cannot have Y (J) ← * Z (J) in M 1 or M 2 . Thus we can find some W ⊆ V\{Y }, such that (F ⊥ ⊥ Z (I) |I (I) , W (I) , Y (I) ) M1 ∨(F ⊥ ⊥ Z (J) |J (J) , W (J) , Y (J) ) M1 , while (F ⊥ ⊥ Z (I) |I (I) , W (I) , Y (I) ) M2 ∧ (F ⊥ ⊥ Z (J) |J (J) , W (J) , Y (J) ) M2 , which is a pair of different testable m-separation statements.</formula><p>Second, consider the case that Y / ∈ K, but is adjacent to F in both M 1 and M 2 . Then there is an inducing path from F to Y (I) or Y (J) in the augmented pair graphs. According to our construction of twin augmented MAGs, F is adjacent to both Y (I) and Y (J) in both M 1 and M 2 . Since F is not adjacent to Z (I) , Z (J) in M 2 , we know according to Lemma A.6 that there exists</p><formula xml:id="formula_51">W ⊆ V such that (F ⊥ ⊥ Z (I) |I (I) , W (I) ) M2 ∧ (F ⊥ ⊥ Z (J) |J (J) , W (J) ) M2 . W has to contain Y , otherwise F is m-connecting to Z (I)</formula><p>and let F I follow a uniform distribution. We need to show that the invariances implied by the graph separation in the generalized causal calculus rules fail for P I and P J . This is equivalent to demonstrating that F I is dependent on Y given Z in the distribution P * . To construct the interventional distributions, we use a SCM that implies the given CBN. Let x represent the vector of all variables in the graph, including latent ones. Consider the SCM given as follows:</p><formula xml:id="formula_52">x = Ax + e,</formula><p>where A is a lower triangular matrix describing the graph structure and parent-child relationships in D path , and e is the vector of exogenous Gaussian noise terms, |x| = n.</p><p>Let P I represent the distribution obtained by introducing the noise vector e I into the system. The vector e I is non-zero only in the rows i where x i ∈ I. Furthermore, the matrix A is modified to a new matrix A 1 , which is identical to A except that all entries in the rows corresponding to i (∀x i ∈ I) are set to zero. This modification effectively removes the influence of the parents of the variables in the intervention set I, as required by the definition of a hard intervention. Consequently, P I qualifies as a valid hard interventional distribution. Similarly, let e J denote the noise vector introduced for an intervention on J. The matrix A is similarly replaced with A 2 , where all entries in the rows corresponding to j (∀x j ∈ J) are set to zero, achieving the same effect for the variables in J. We show that in the combined distribution p * using these P I , P J every adjacent variable is dependent. Clearly, when e I and e J are different, F variable is dependent with the variables in K := I∆J, since P * (K | F = 0) = P * (K | F = 1 ), which implies ( K ⊥ ⊥ F | ∅) P * . Therefore, we focus on establishing that every pair of variables that are adjacent are correlated except for the F variable. The correlation of the variables in D path is calculated as follows:</p><formula xml:id="formula_53">x = A 1 x + e + e I ⇒ (I n -A 1 )x = e + e I ⇒ x = (I n -A 1 ) -1 (e + e I ) x = A 2 x + e + e J ⇒ (I n -A 2 )x = e + e J ⇒ x = (I n -A 2 ) -1 (e + e J )</formula><p>Where I n is the identity matrix of size n by n. Let e 1 = e + e I and e 2 = e + e J . The correlation matrix between the observed variables, with respect to the distribution P * after marginalizing out the binary regime variable, is computed as follows:</p><formula xml:id="formula_54">E xx T = 0.5(I n -A 1 ) -1 E e 1 e T 1 (I n -A 1 ) -1 T + 0.5(I n -A 2 ) -1 E e 2 e T 2 (I n -A 2 ) -1 T Let D 1 = E e 1 e T</formula><p>1 and D 2 = E e 2 e T 2 represent the diagonal covariance matrices for the noise introduced by the hard interventions. Additionally, assume that all the noise variables, including e, e I , and e J , follow zero-mean Gaussian distributions. Consider two adjacent variables, x i and x j , within D path . We observe that the matrices I n -A 1 and I n -A 2 are full-rank, as A is a strictly lower triangular matrix, and the same holds for A 1 and A 2 . As a result, the matrix inverses in these equations exist and are unique.</p><p>We now treat D 1 and D 2 as variables in this system. When performing a hard intervention, we can freely select the variance of each added noise term. Our objective is to demonstrate that there always exist hard interventions, represented by D 1 and D 2 , such that x i and x j become dependent. Since both x i and x j are jointly Gaussian, they are dependent if and only if they are correlated. Therefore, we need to show that E [x i x j ] = 0 for any adjacent pair x i , x j . If we set D 1 = D 2 = 0, we return to the observational system. By the assumption that the original distribution is faithful to the graph D path , any adjacent variables are dependent. This implies that the corresponding system of linear equations is not trivially zero. Hence, by randomly choosing the variances of the noise terms, we can ensure that, with probability 1, any adjacent pair of variables will be dependent (by applying a union bound).</p><p>Thus, we have shown that, in the graph D path along with the F variable, every pair of adjacent variables is dependent. Next, we can extend this distribution to include the variables outside D path . To do this, we select the remaining variables to be jointly independent and independent from those in D path . The interventional distributions can then be constructed by applying a similar hard intervention, where extra noise terms are added to the variables being intervened upon and replacing the matrix A. The resulting set of interventional distributions will belong to P I (D 2 , V), but not to P I (D 1 , V). This is because m-separation should imply invariance across the interventional distributions, but we have constructed them in such a way that this condition does not hold. This concludes the proof.</p><p>A.5 Proof for Proposition 5.2</p><p>Proof. We have shown in Theorem 4.7 that two causal graphs are I-Markov equivalent if and only if their twin augmented MAGs satisfy the 3 conditions. Here we just need to show that the twin augmented MAGs follow the 3 conditions if and only if the I-augmented MAGs follow the 3 conditions.</p><p>(If:) Notice that each twin augmented MAG T win I,J (D) can be constructed by taking the graph union of Aug I (D, I) and Aug J (D, I) and removing irrelevant F nodes. Therefore, if Aug I (D 1 , I) and Aug J (D 2 , I) have the same skeleton for any I ∈ I, T win I,J (D 1 ) and T win I,J (D 2 ) will also have the same skeleton. Furthermore, T win I,J (D) and Aug I (D, I) have the same unshielded colliders within V (I) ∪ {F (I,J) } because they have the same subgraph on V (I) ∪ {F (I,J) }. Since twin augmented MAGs do not have other F nodes, T win I,J (D 1 ) and T win I,J (D 2 ) have the same unshielded colliders. Similarly, any discriminating path in Aug I (D, I) will also be preserved in T win I,J (D) while there cannot be discriminating paths that pass through the F node in T win I,J (D). Therefore, T win I,J (D 1 ) and T win I,J (D 2 ) have the same collider status on discriminating paths.</p><p>(Only if:) Now we show that if T win I,J (D 1 ) and T win I,J (D 2 ) satisfy the 3 conditions for any I, J ∈ I, then Aug I (D 1 , I) and Aug I (D 2 , I) also satisfy the 3 conditions for any I ∈ I. Since Aug I (D 1 , I) is the graph union of T win I,J (D 1 ) on V (I) ∪ {F (I,J) }, all the adjacencies are kept and the same for Aug I (D 2 , I). Thus, they have the same adjacencies. For unshielded triples, if both ends are F nodes, then they have to be unshielded colliders in both Aug I (D 1 , I) and Aug I (D 2 , I) given F nodes have only outgoing edges by construction. If at most one endpoint of the unshielded triple is an F node, then the same structure can be retrieved from the relevant twin augmented MAG. Therefore, Aug I (D 1 , I) and Aug I (D 2 , I) have the same unshielded colliders. Finally, we need to show that if p = U, W 1 , W 2 , ..., W k , Y, Z is a discriminating path in both Aug I (D 1 , I) and Aug I (D 2 , I), then p has the same collider status. If p is in V (I) , then p is also in T win I,J (D 1 ) and T win I,J (D 2 ) for any J ∈ I and thus it shows the same collider status in both I-augmented MAGs. If F (I,J) is an endpoint of p, then the path is also in T win I,J (D 1 ) and T win I,J (D 2 ) with the same collider status. By the construction of I-augmented MAGs, an F node can only be Y in p if it is not the starting node. Since F nodes only have outgoing edges, p will have the same collider status in both Aug I (D 1 , I) and Aug I (D 2 , I), A.6 Proof for Theorem 6.3</p><p>The algorithm is learning the causal graph through finding the separating sets between each pair of nodes using the distributional invariance tests. The invariance tests are tied to the m-separation statements in the causal graph according to the h-faithfulness assumption, and the properties in Definition 4.1 are mapped to the m-separation statements in the twin augmented MAGs by Proposition 4.4. We show that twin augmented MAGs are combined to construct I-augmented MAGs which preserve the m-separation statements in Proposition 5.2. Ideally, our algorithm would learn a structure that is close to the I-augmented MAGs. Therefore, to show the soundness of Algorithm 1, we need to first define the I-essential graph as follows: </p><formula xml:id="formula_55">G i = (V i , E i )</formula><p>The union graph of k ADMGs, denoted as G ∪ = (V ∪ , E ∪ ), where V ∪ = k i=1 V i , for each pair of vertices (X, Y ), the edge set of G ∪ is determined by:</p><formula xml:id="formula_56">E ∪ =        X → Y, if (X → Y ) appears in all G i , X, Y ∈ V i . X ↔ Y, if (X ↔ Y ) appears in all G i , X, Y ∈ V i . Xo→ Y, if (X → Y ) appears in some G i , (X ↔ Y ) appears in some G j , X, Y ∈ V i , V j . Xo-oY, if (X ← Y ) appears in some G i , (X → Y )appears in some G j , X, Y ∈ V i , V j .</formula><p>The I-essential graphs denote the structure that is ultimately learnable by any causal discovery algorithm. Based on this definition, to demonstrate the soundness of our algorithm, it suffices to address the following two questions:</p><p>(a) Do all the I-augmented graphs returned by Algorithm 1 have the same adjacencies as the I-essential graphs?</p><p>(b) Are the orientation rules sound, i.e. any arrowhead/arrowtail learned by the algorithm is also present in the I-essential graph?</p><p>We first address (a). Consider an I-augmented graph G I , the edges either contain a F node or not. There are no edges between any two F nodes by our construction of G I and Aug I (D, I). Consider the edge (F (I,J) , Y (I) ) in G I . It is recovered because there does not exist W ⊆ V, such that P I (y|w) = P J (y|w) under h-faithfulness. According to Definition 4.1 and Proposition 4.4, it implies that F (I,J) and Y (I) , Y (J)  are also adjacent in T win (I,J) (D ′ ) for any D ′ that is I-Markov equivalent to D. Thus F (I,J) and Y (I) are also adjacent in Aug I (D ′ , I). Consequently, they are also adjacent in the I-essential graph. For the same reason, if F (I,J) and Y (I) are not adjacent in G I , we can derive that they are also not adjacent in E I (D, I).</p><p>Next, consider the edges that do not contain F nodes. There are no edges between two nodes in different domains in both G I and Aug I (D, I) by our construction. We call the vertex induced subgraph on V (J) , J ∈ I a domain. We just need to show that they have the same adjacencies within each domain. According to our algorithm, within each domain, all the edges are connected by applying the FCI algorithm, which is proved to be sound by <ref type="bibr">Zhang (2008b)</ref>. Thus, G I [V (I) ] will have the same adjacencies as Aug I (D ′ , I)[V (I) ], I ∈ I for all D ′ that are I-Markov equivalent to D.</p><p>Finally, we address the soundness of orientation rules. In phase I of the learning algorithm, we use FCI rules within each domain to learn the skeletons. <ref type="bibr">Zhang (2008b)</ref> showed that FCI is sound and complete. Thus, the orientations in the skeleton learned in this phase are shared across all Aug I (D ′ ), for all D ′ that is I-Markov equivalent to D. In phase II, F nodes are introduced and adjacent to the symmetric difference of the targets, and the nodes that are not separable from F . All the edges induced to F nodes are oriented outgoing from F nodes by Rule 8. This is also true in Aug I (D ′ , I) for all D ′ that is I-Markov equivalent to D. Thus, so far, all the orientations learned are sound. What remains to be shown is the soundness of the extra orientation rules.</p><p>Soundness of Rule 0: If both end nodes are in V, then the soundness is guaranteed by the soundness of FCI. Suppose F, X (I) , Y (I) is an unshielded collider identified by the learning algorithm, i.e., there is some W ⊆ V \ I, such that, F ⊥ ⊥ Y (I) |I (I) , W (I) , while X / ∈ W ∪ I. Suppose otherwise, F, X (I) , Y (I) is not an unshielded collider, then it can only be F → X (I) → Y (I) . Since F, Y (I) are non-adjacent, the soundness of the skeleton indicates that there is a set of nodes that separates F from Y (I) . However, in this case, to separate F from Y (I) , X (I) has to be in the condition set; otherwise, the path F → X (I) → Y (I) would be d-connecting.</p><p>Soundness of Rule 9: To address the soundness of Rule 9, we need to show that if X (I) , Y (I) are adjacent, and X ∈ I, then Y can only be a descendant of X in the interventional causal graph D I . Suppose otherwise, then Y is an ancestor of X or they have at least one common ancestor in D I . However, since X is intervened, there will be no ancestor of X in D I , which is a contradiction.</p><p>Soundness of Rule 10: We need to show that if we recover X → Y in the domain G (I) , there cannot be X (J) ← Y (J) in another domain of J. Suppose otherwise, it indicates that there is a directed path from Y to X in D J . However, there is also a directed path from X to Y in D I . D J and D I are subgraphs of D, thus there is at least 1 cycle in D which is a contradiction.</p><p>Soundness of Rule 11: F (I,J) is adjacent to Y (I) , Y (J) while Y / ∈ I shows that there does not exist any W ⊆ V such that P I (y|w) = P J (y|w). This means that there is no separating set that separates both F (I,J) , Y (I) and F (I,J) , Y (J) . This indicates that there is an inducing path from F (I,J) to Y (I) or from F (I,J) to Y (J) relative to the latent variables in the augmented pair graph. Due to the definition of the inducing path, it has to go through X (I) or X (J) as K = {X}. However, in G (I) , since X (I) is intervened, X (I) cannot serve as a collider in the path. Consequently, we can infer that the inducing path has to go through X (J)  to Y (J) . Furthermore, X (J) has to be a parent of one of the end nodes of the path. Given that F nodes are source nodes, we can orient X (J) → Y (J) . Here we show an example of the learning process of Algorithm 1 in Figure <ref type="figure" target="#fig_10">3</ref>. Consider the two causal graphs D 1 , D 2 as shown in Figure <ref type="figure" target="#fig_1">1a</ref> and Figure <ref type="figure" target="#fig_1">1e</ref> respectively. Assume that we have access to (P obs , P Z ), i.e. I = {I 1 = ∅, I 2 = {Z}}. In Phase I, we initialize the I-augmented graphs under each interventional target for both graphs by constructing complete graphs with only circle edges within the observable nodes. After that, we create the F nodes between each pair of interventional target using Algorithm 2 and connect each F node to all observable nodes. The initialized I-augmented graphs are shown in Figure <ref type="figure" target="#fig_10">3a</ref>, Figure <ref type="figure" target="#fig_10">3b</ref> Figure <ref type="figure" target="#fig_10">3c</ref>, and Figure <ref type="figure" target="#fig_10">3d</ref>. Here we omit the superscript for F nodes since there are only two domains. Then in Phase II, we learn skeletons by using Algorithm 3 to check the invariance statements. Specifically, for each pair of X, Y ∈ V, if there exists some W ⊆ V that separates X, Y in any domain, we remove the circle edge between X, Y accordingly. Similarly, if F is separable from a vertex in V given a condition set W ⊆ V, i.e. P ∅ (y|w) = P {Z} (y|w), then we remove the circle edge between F, Y in both domains. Thus we construct the skeletons of I-augmented graphs for D 1 and D 2 as shown in Figure <ref type="figure" target="#fig_10">3e</ref> and Figure <ref type="figure" target="#fig_10">3f</ref> respectively. The upper graphs are for the observational domain while the lower graphs are for the domain of P Z . Next, in Phase III, we apply the orientation rules. We start by finding all the unshielded colliders using Rule 0. In G ∅ (D 1 ), we notice that conditioning on Z (1) , F is dependent on X (1) . Similarly, conditioning on Y (1) , F is dependent on X (1) . We can then orient X (1) o-oZ (1) , X (1) o-oY (1) , F o-oZ (1) , and F o-oY (1) as X (1) o→ Y (1) , X (1) o→ Z (1) , F o→ Z (1) , and F o→ Y (1) respectively. The same structure appears in G ∅ (D 2 ). However, in G ∅ (D 2 ), we can identify the unshielded triplets X (2) , Y (2) , Z (2) and X (2) , Y (2) , F which help us orient the colliders accordingly. The resulting graphs are plotted in Figure <ref type="figure" target="#fig_10">3g</ref> and Figure <ref type="figure" target="#fig_10">3h</ref>. Using Rule 8, we orient all edges induced to F out of F . The I-augmented graphs after Rule 8 are presented in Figure <ref type="figure" target="#fig_10">3i</ref> and Figure <ref type="figure" target="#fig_10">3j</ref>. Since only Z is intervened but not Y , we can orient the edge Z (2) → Y (2) in both G {Z} (D 1 ) and G {Z} (D 2 ) using Rule 9. While Rule 10 helps us to orient Z (1) o→ Y (1) , Rule 11 implies that we can orient Z (1) → Y (1) since F points to Y (1) , Y (2) in both G ∅ (D 1 ) and G ∅ (D 2 ) as Y is not intervened. Thus, there has to be an inducing path from F to Y (1) , Y (2) that goes through Z (1) or Z (2) in both augmented pair graphs for D 1 and D 2 . Notice that these edges cannot be oriented by the FCI rules. At this stage, none of the rules apply anymore; therefore, G ∅ (D 1 ), G {Z} (D 1 ) and G ∅ (D 2 ), G {Z} (D 2 ) are returned as the learned I-augmented graphs of Algorithm 1. The final results are shown in Figure <ref type="figure" target="#fig_10">3k</ref> and Figure <ref type="figure" target="#fig_10">3l</ref>. Notice that the learned I-augmented graphs of the two causal graphs have different adjacencies and unshielded colliders. Therefore, they can be distinguished by the conditions listed in Theorem 4.7.  Y (1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.7 An Example of the Learning Process</head><formula xml:id="formula_57">X (1) Z (1) Y (1) F • • • • • • • • • •• • (a) Initialize G ∅ (D1) X (1) Z (1) Y (1) F • • • • • • • • • •• • (b) Initialize G ∅ (D2) X (2) Z (2) Y (2) F • • • • • • • • • •• • (c) Initialize G {Z} (D1) X (2) Z (2) Y (2) F • • • • • • • • • •• • (d) Initialize G {Z} (D2) X (1) Z (1) Y (1) F F Z (2) X (2) Y (2) • • • • • • • • • • • • • • • • (e) G ∅ (D1) and G {Z} (D1) After Phase II X (1) Z (1) Y (1) F F Z (2) X (2) Y (2) • • • • • • • • • • • • • • • • • • (f) G ∅ (D2) and G {Z} (D2) After Phase II X (1) Z (1) Y (1) F F Z (2) X (2) Y (2) • • • • • • • • • • • • (g) G ∅ (D1) and G {Z} (D1) After Rule 0 X (1) Z (1) Y (1) F F Z (2) X (2) Y (2) • • • • • • • • • • • (h) G ∅ (D2) and G {Z} (D2) After Rule 0 X (1) Z (1) Y (1) F F Z (2) X (2) Y • • • • • • (i) G ∅ (D1) and G {Z} (D1) After Rule 8 X (1) Z (1) Y (1) F F Z (2) X (2) Y (2) • • • • • • (j) G ∅ (D2) and G {Z} (D2) After Rule 8 X (1) Z (1) Y (1) F F Z (2) X (2) Y (2) • • (k) G ∅ (D1) and G {Z} (D1) X (1) Z (1) Y (1) F F Z (2) X (2) Y (2) • • • (l) G ∅ (D2) and G {Z} (D2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.8 Further Discussion</head><formula xml:id="formula_58">X (2) 1 Y (2) 1 X (2) 2 Y (2) 2 F (c) AugI 2 (D, I) X 1 Y 1 X 2 Y 2 F (d) Augmented MAG of D under soft interventions X 1 Y 1 X 2 Y 2 (e) Example graph D1 X 1 Y 1 X 2 Y 2 (f) Example graph D2</formula><p>F (1,2) F (1,3) (e) AugI 1 (D1, I)</p><formula xml:id="formula_59">X (1)</formula><p>Y (1)</p><formula xml:id="formula_60">F (1,2) F (2,3) (f) AugI 2 (D1, I) X (1)</formula><p>Y (1) F (2,3) F (1,3) (g) AugI 3 (D1, I)</p><formula xml:id="formula_61">X (1) Y (1)</formula><p>F (1,2) F (1,3) (h) AugI 1 (D2, I)</p><formula xml:id="formula_62">X (1)</formula><p>Y (1)</p><p>F (1,2) F (2,3) (i) AugI 2 (D2, I)</p><formula xml:id="formula_63">X (1)</formula><p>Y (1) F (2,3) F (1,3) (j) AugI 3 (D2, I) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.8.2 Imcompleteness of the Learning Algorithm</head><p>In this section, we will present an example in Figure <ref type="figure" target="#fig_0">6</ref> to show that Algorithm 1 is not complete, i.e., for some causal graphs and intervention targets I, there exist circles marks in the I-augmented graph returned by Algorithm 1 that can be an arrowhead in the I-augmented MAG of a causal graph that is I-Markov </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Lemma 4. 6 .</head><label>6</label><figDesc>Twin augmented MAGs are valid MAGs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of the construction of twin augmented MAGs where D 1 and D 2 are not I-Markov equivalent. (a) and (e) are two causal graphs, D 1 and D 2 respectively, given intervention targets I = {I 1 = ∅, I 2 = {Z}}. (b) and (f) are the augmented pair graphs for D 1 and D 2 respectively. (c) and (g) are the MAG of the augmented pair graphs for D 1 and D 2 respectively. (d) and (h) are the twin augmented MAGs for D 1 and D 2 respectively. F → Y(1) in M AG(Aug (∅,{Z}) (D 1 )) and M AG(Aug (∅,{Z}) (D 2 )) because there is an inducing path F, Z(1) , Y(1) in both augmented pair graphs. In the twin augmented graphs, we further add F → Y (2) to make the adjacencies around the F node symmetric.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>and a set of intervention targets I ⊆ 2 V , D 1 and D 2 are I-Markov equivalent with respect to I if and only if for each pair of interventions I, J ∈ I, M 1 = T win (I,J) (D 1 ), M 2 = T win (I,J) (D 2 ):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>and a set of intervention targets I ⊆ 2 V , construct the I-augmented MAGs following the steps in Definition 5.1 of D 1 , D 2 . D 1 and D 2 are I-Markov equivalent with respect to I if and only if for each I ∈ I, Aug I (D 1 , I) and Aug I (D 2 , I) satisfy the 3 conditions in Theorem 4.7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of the construction of I-augmented MAGs from twin augmented MAGs. Figure 1a is the ground truth graph. The intervention targets are I = {I 1 = ∅, I 2 = {X}, I 3 = {Z}}. (a), (b), and (c) are the twin augmented MAGs. (d), (e), and (f) are the I-augmented MAGs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Definition 6.2 (I-augmented Graph). Given a causal graph D and a set of intervention targets I, for each I ∈ I, let M = Aug I (D, I) and let [M] be the set of I-augmented MAGs corresponding to all the causal graphs that are I-Markov equivalent to D given I. For any I ∈ I, the I-augmented graph, denoted as G I (D, I), is a graph such that: 1. G I (D, I) has the same adjacencies as M, and any member of [M] does; and 2. every non-circle mark in G I (D, I) is an invariant mark in [M]. Algorithm 1 Main Causal Discovery Algorithm Input: Intervention targets I, interventional distributions (P I ) I∈I , observable variables V Initialize L I as an empty tuple; Phase I: Initialize with Complete Graphs; for I in I do Duplicate V to create V (I) ; Put a circle edge (o-o) between every pair of nodes in V (I) ; Run Algorithm 2 on I, I to get F I as F nodes; for J in I \ {I} do Put a circle edge (o-o) between every V ∈ V (I) and F (I,J) ∈ F I ; Phase II: Learning the Skeleton and Separating Sets;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>I) ); Output: Circle edges E, separating sets SepSet Algorithm 1 follows a similar framework to that of FCI. It learns the I-augmented graph tuple L I by iteratively recovering G I for each I ∈ I. In Phase I, it initializes the I-augmented graph G I for each I ∈ I.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Theorem 6.3. Consider a set of interventional distributions (P I ) I∈I that are h-faithful to a causal graph D = (V ∪ L, E), where I is a set of intervention targets. Algorithm 1 is sound, i.e., every adjacency and arrowhead/tail orientation in the returned I-augmented graph G I (D, I) for each I ∈ I is common for all I-augmented MAGs of D ′ , G I (D ′ , I) for any D ′ which is I-Markov equivalent to D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>. Under causal sufficiency,<ref type="bibr" target="#b12">Hauser &amp; Bühlmann (2012)</ref>;<ref type="bibr" target="#b48">Yang et al. (2018)</ref> characterizes the I-MEC.<ref type="bibr" target="#b43">Tian &amp; Pearl (2001)</ref> first considers the equivalence class under local changes. When there are latents under soft intervention with known targets,<ref type="bibr" target="#b22">Kocaoglu et al. (2019)</ref> characterize the I-MEC while with unknown targets, it is called ψ-MEC<ref type="bibr" target="#b18">(Jaber et al., 2020)</ref>. When there is access to multiple domains,<ref type="bibr" target="#b23">Li et al. (2023)</ref> propose S-MEC.Learning from Combined Datasets: There are plenty of works in the literature on learning the causal structure from experiments (or across domains). Approaches like Perry et al. (2022); Peters et al. (2016); Ghassami et al. (2017); Heinze-Deml et al. (2018); Huang et al. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Definition A.8 (I-essential graph). Given a causal graph D = (V ∪ L, E) and a set of intervention targets I ⊆ 2 V , the I-essential graph of D related to I, denoted as E I (D, I) is the union graph of the I-augmented MAGs of D ′ for all D ′ that are ADMGs I-Markov equivalent to D. Definition A.9 (Union Graph of k ADMGs). Let G 1 , G 2 , . . . , G k be k ADMGs, where each graph</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An example of the learning process of Algorithm 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>A.8.1 Comparison between Hard Interventions and Soft InterventionsOne may expect that hard interventions can always extract more information about the causal graph than soft interventions when there are latents. Here, we show an example in Figure4where this is not true. Consider the ground truth ADMG D in Figure4awith intervention targetsI = {I 1 = {X 1 , X 2 }, I 2 = {Y 1 , Y 2 }}.The I-augmented MAGs under hard interventions are shown in Figure4band Figure4crespectively. The augmented MAG under soft interventions is shown in Figure4d. We suppress the superscript of F nodes since they are the same. We notice that under hard interventions, the skeletons in both domains are empty graphs because the hard interventions remove all the bidirected edges in D. However, under soft interventions, the skeleton of D is preserved since soft interventions do not modify the graphical structures. As a result, any graph that has only bidirected edges between X i and Y j , i, j ∈ {1, 2} is I-Markov to D given I 1 , I 2 as hard interventions while this is not true for soft interventions with the same targets. For example, consider the two graphs D 1 , D 2 plotted in Figure4eand Figure4f. Given I, their domain-specific skeletons will all be empty graphs as D when I is hard, thus they are I-Markov equivalent to D. However, with soft interventions, their skeletons can be preserved and thus not I-Markov equivalent to D when I is soft. Therefore, for this kind of graphs and intervention targets, soft interventions may end up with a smaller I-Markov equivalence class than hard interventions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An example that soft interventions lead to a smaller I-Markov equivalence class than hard interventions. (a) is the ground truth causal graph D with intervention targets I = {{X 1 , X 2 }, {, Y 1 , Y 2 }}; (b) and (c) are the two I-augmented MAGs under hard interventions; (d) shows the augmented MAG under soft interventions; (e) and (f) are two examples graphs that are I-Markov equivalent to D when I is hard but not I-Markov equivalent to D when I is soft.If the observational distribution is provided, the skeleton is preserved for both hard and soft interventions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: An example that given the observational distribution, soft interventions can distinguish the given two causal graphs while hard interventions cannot. (a), (b) are the ground truth causal graph D 1 , D 2 respectively with intervention targets I = {∅, {Y }, {X, Y }}; (c), (d) are the augmented MAGs under soft interventions for D 1 and D 2 respectively; (e), (f), (g) are the I-augmented MAGs under hard interventions for D 1 ; (h), (i), (j) are the I-augmented MAGs under hard interventions for D 2 . Notice that D 1 and D 2 are not I-Markov equivalent when I is soft because F, X, Y have different unshielded collider status in the corresponding augmented MAGs. However, they are I-Markov equivalent when I is hard because their I-augmented MAGs corresponding to the same domains all satisfy the 3 conditions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>equivalent, and an arrowtail in another I-augmented MAG. Let us consider the causal graph D as shown in Figure 6a with intervention targets I = {I 1 = {X 2 }, I 2 = {X 4 }}. Here we use the domain index as the superscripts for simplicity. The I-augmented MAGs Aug I1 (D, I) and Aug I2 (D, I) are shown in Figure 6b and Figure 6c respectively. The I-augmented graphs G I1 (D, I) and G I2 (D, I) learned by Algorithm 1 are shown in Figure 6d and Figure 6e respectively. X</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Estimation of I-MEC size by enumerating all ADMGs of the same size. We consider random ADMGs and ADMGs by adding bidirected edges to random complete DAGs. For each setting we sample 30 ground truth ADMGs and calculate the mean and standard error of I-MEC size and the ratio.</figDesc><table><row><cell></cell><cell cols="2">Mean under Hard Mean under Soft</cell><cell>Graph</cell><cell>Ratio</cell><cell>Total Number of ADMGs</cell></row><row><cell>2</cell><cell>2.03 ± 0.15</cell><cell>2.93 ± 0.29</cell><cell cols="2">Random 0.69 ± 0.05</cell><cell>6</cell></row><row><cell>2</cell><cell>2.37 ± 0.12</cell><cell>3.67 ± 0.22</cell><cell cols="2">Complete 0.65 ± 0.05</cell><cell>6</cell></row><row><cell>3</cell><cell>19.50 ± 3.41</cell><cell>30.57 ± 4.36</cell><cell cols="2">Random 0.64 ± 0.11</cell><cell>200</cell></row><row><cell>3</cell><cell>14.03 ± 2.69</cell><cell>24.70 ± 4.12</cell><cell cols="2">Complete 0.57 ± 0.05</cell><cell>200</cell></row><row><cell>4</cell><cell>677.13 ± 227.72</cell><cell cols="3">1218.83 ± 361.83 Random 0.56 ± 0.18</cell><cell>34,752</cell></row><row><cell>4</cell><cell>721.37 ± 276.36</cell><cell cols="3">1529.57 ± 368.68 Complete 0.47 ± 0.07</cell><cell>34,752</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 ,</head><label>2</label><figDesc>Table 3, and Table 4. We can see that the estimated E hard S is significantly lower than E sof t S meaning hard interventions can more efficiently learn the causal structure. Notice that as n becomes larger, the number of ADMGs grows fast and thus the expectations get close to 0. Consequently, a much smaller ǫ would be necessary to approximate the expectations, leading to a much larger number of samples M .</figDesc><table><row><cell cols="2">n Estimated E hard S</cell><cell>Estimated E sof t S</cell><cell>Ratio</cell></row><row><cell>2</cell><cell>0.417 ± 0.010</cell><cell>0.584 ± 0.010</cell><cell>0.715 ± 0.011</cell></row><row><cell>3</cell><cell>0.143 ± 0.012</cell><cell>0.235 ± 0.016</cell><cell>0.607 ± 0.022</cell></row><row><cell>4</cell><cell>0.058 ± 0.011</cell><cell>0.112 ± 0.015</cell><cell>0.514 ± 0.024</cell></row><row><cell>5</cell><cell>0.028 ± 0.011</cell><cell>0.061 ± 0.013</cell><cell>0.459 ± 0.028</cell></row><row><cell>6</cell><cell>0.015 ± 0.010</cell><cell>0.036 ± 0.012</cell><cell>0.420 ± 0.030</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Estimation of I-MEC size on complete DAGs with different sizes and 0.5 density of bidirected edges.</figDesc><table><row><cell cols="2">n Estimated E hard S</cell><cell>Estimated E sof t S</cell><cell>Ratio</cell></row><row><cell>3</cell><cell>0.151 ± 0.011</cell><cell>0.264 ± 0.015</cell><cell>0.571 ± 0.017</cell></row><row><cell>4</cell><cell>0.067 ± 0.010</cell><cell>0.149 ± 0.013</cell><cell>0.451 ± 0.017</cell></row><row><cell>5</cell><cell>0.034 ± 0.010</cell><cell>0.091 ± 0.013</cell><cell>0.373 ± 0.017</cell></row><row><cell>6</cell><cell>0.019 ± 0.010</cell><cell>0.059 ± 0.012</cell><cell>0.317 ± 0.017</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell>ρ 0.1</cell><cell>Estimated E hard S 0.020 ± 0.011</cell><cell>Estimated E sof t S 0.024 ± 0.011</cell><cell>Ratio 0.804 ± 0.018</cell></row><row><cell>0.3</cell><cell>0.022 ± 0.011</cell><cell>0.040 ± 0.012</cell><cell>0.566 ± 0.030</cell></row><row><cell>0.5</cell><cell>0.028 ± 0.011</cell><cell>0.061 ± 0.013</cell><cell>0.459 ± 0.028</cell></row><row><cell>0.7</cell><cell>0.031 ± 0.011</cell><cell>0.081 ± 0.013</cell><cell>0.395 ± 0.021</cell></row><row><cell>0.9</cell><cell>0.034 ± 0.010</cell><cell>0.093 ± 0.011</cell><cell>0.365 ± 0.015</cell></row></table><note><p>Estimation of I-MEC size with different n and fixed 0.45n(n -1) bidirected edges (approximately 0.9 in density).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Estimation of I-MEC size on completed DAGs with 5 nodes and different densities of bidirected edges. It shows that when the density of bidirected edges goes up, hard interventions shrink the I-MEC size more efficiently than soft interventions.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Inducing paths are paths between non-adjacent variables that cannot be blocked by conditioning on any subset of observed variables. They only exist in the presence of unobserved confounders.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This research has been supported in part by <rs type="funder">NSF</rs> <rs type="grantNumber">IIS 2348717</rs>, <rs type="grantNumber">CAREER 2239375</rs>, <rs type="funder">Amazon Research Award and Adobe Research</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_SGtferR">
					<idno type="grant-number">IIS 2348717</idno>
				</org>
				<org type="funding" xml:id="_tF4tuAZ">
					<idno type="grant-number">CAREER 2239375</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Proposition A.5. Consider a CBN (D = (V ∪ L, E), P ) with latent variables L and its augmented pair graph Aug (I,J) (D) = (V (I) ∪ V (J) ∪ {F }, E (I) ∪ E (J) ∪ E) with respect to a pair of interventions I, J ∈ I. Let S = I∆J be a set of nodes, F is adjacent to S (I) , S (J) . We have the following equivalence relations:</p><p>Suppose disjoint Y, Z, W ⊆ V. We have (Y ⊥ ⊥ Z|W, I) D I ⇐⇒ (Y (I) ⊥ ⊥ Z (I) |W (I) , I (I) , F ) Aug (I,J) (D)</p><p>(5)</p><p>Suppose Y, W are disjoint subsets of V \ S. We have I) , I (I) ) Aug (I,J) (D) (F ⊥ ⊥ Y (J) |W (J) , J (J) ) Aug (I,J) (D) (6)</p><p>For disjoint Y, Z, W ⊆ V, where</p><p>Proof. Consider Equation <ref type="formula">5</ref>. For the right statement, conditioning on F is equivalent to removing it and the subgraph induced by V (J) from Aug(D). Then the statements on the two sides are equivalent.</p><p>Consider Equation <ref type="formula">6</ref>. We need to show that</p><p>(⇒) Suppose otherwise (F ⊥ ⊥ Y (I) |W (I) , I (I) ) Aug (I,J) (D) , then there is an m-connecting path p from F to Y (I) ∈ Y (I) in Aug (I,J) (D). Since W (I) is conditioned on, p cannot be a frontdoor path. Also, edges into I (I) are removed, thus p cannot be a backdoor path through W I . However, given (Y ⊥ ⊥ W J |W \ W J , I) D I,W J , there is no backdoor path through W J . The supposition does not hold.</p><p>(⇐) Suppose otherwise (Y ⊥ ⊥ W J |W \ W J , I) D I,W J , then there is an m-connecting path p from Y (I) ∈ Y (I) to U ∈ W J . It has to be a backdoor path from U . However, (F ⊥ ⊥ Y (I) |W (I) , I (I) ) Aug (I,J) (D) will not hold, if there is a backdoor path from U to Y . Thus the supposition does not hold.</p><p>For the same reason, we can show that</p><p>Consider Equation <ref type="formula">7</ref>. We need to show that</p><p>, then there is an m-connecting path p from F to Y (I) ∈ Y (I) in Aug (I,J) (D). Since I (I) is conditioned on and the edges into I (I) are removed, p cannot be through I (I) . If F has a frontdoor path to Y (I) through R (I) J , then Y to R J will also be m-connecting in D I,RJ(W) . Else if it is a backdoor path, it can only go through some W) . Thus the supposition does not hold.</p><p>(⇐) Suppose otherwise</p><p>. If p has an outgoing from U , then F would have a frontdoor path through U (I) to</p><p>. Thus p can only be a backdoor path from U . If U is not an ancestor of any W ∈ W in D I , the edges into U are removed and p do not exist in this case. Else if U is an ancestor of some W ∈ W, the same backdoor path would also be activated in Aug(D). Therefore, the supposition does not hold.</p><p>For the same reason, we can show that</p><p>Consider Equation <ref type="formula">8</ref>. We need to show that</p><p>or Z (J) in M 2 through Y (I) or Y (J) . We need to further show that there cannot be Y J) in M 2 , then there is a latent common ancestor of Y, Z in D 2 . This will create an inducing path F, Y (I) , Z (I) in M 2 which contradicts the condition that F and Z (I) are non-adjacent. In M 1 , since there is F → Y ← * Z, we have</p><p>, which contains a pair of different testable statements in T . Therefore, M 1 and M 2 have the same unshielded colliders. Suppose U, W 1 , W 2 , ..., W k , Y, Z is a discriminating path in both M 1 and M 2 , Y is a collider in M 1 but a non-collider in M 2 . By our construction, F can only be U or Y in the path. There are 3 cases.</p><p>First, if F is not in the path. Then all the nodes in the path are in V (I) or V (J) . Suppose the path is in V (I) . Then in M 2 , there exists some W ⊆ V, such that (U (I) ⊥ ⊥ Z (I) |I (I) , F,</p><p>While in M 1 , we have (U (I) ⊥ ⊥ Z (I) |I (I) , F, W (I) ) M1 , since conditioning on Y (I) would activate the path. Thus there is a pair of testable m-separation statements.</p><p>Next, if F is Y in the path, this case is not valid, since F can only have outgoing edges. Therefore, if F is Y in the path, it should have the same collider status in M 1 and M 2 .</p><p>Lastly, F is U in the path. All of the other nodes in the path have to be all in either V (I) or V (J) . Suppose that all other nodes are in V (I) . Since F is non-adjacent to Z (I) in M 1 and M 2 , we know that F is also non-adjacent to Z (J) according to Lemma A.6. Thus in M 2 , there exists W ⊆ V, such that</p><p>i , Y (I) will activate every collider in the path from F to Z (I) . Therefore, there is a pair of different testable statements in T . To conclude, for each discriminating path in M 1 and M 2 , F is a collider in M 1 if and only if it is a collider in M 2 . Up to now, we showed that if M 1 and M 2 do not satisfy the three graphical conditions in the theorem, then there exists a testable m-separation statement that holds in one graph but not the other.</p><p>When there exists a pair of intervention targets I, J ∈ I such that M 1 = Twin (I,J) (D 1 ) and M 2 = Twin (I,J) (D 2 ) do not satisfy either of the three conditions mentioned in the theorem statement, this implies that D 1 and D 2 are not I-Markov equivalent. This is because there is a m-separation statement that appears as a condition in the definition of I-Markov equivalence that is different in the two graphs M 1 and M 2 . There is a m-separating path in M 1 that is m-connecting in M 2 . We now show that P I (D 2 , V) contains tuples of distributions that are not in P I (D 1 , V). We leverage a key result from Meek, demonstrating that the set of unfaithful distributions has Lebesgue measure zero. Building on this, we construct a jointly Gaussian structural causal model that incorporates latent variables.</p><p>be the subgraph that contains all the nodes in the m-connecting path that induces (A ⊥ ⊥ B | C) D . Then any distribution P over V s where every adjacent pair of variables is dependent satisfies</p><p>The proof of Lemma A.7 uses weak transitivity and an inductive argument and can be found in <ref type="bibr">Meek (2013b)</ref></p><p>Suppose that both X, Y are observed variables. In this case, any tuple of interventional distribution obtained from an observational distribution that is faithful to the causal graph with latent variables constitutes a valid example. Suppose X = F for some and Y ∈ V. Therefore, an F -node is m-connected to an observed node in Aug (I,J) (D 2 ) but not in Aug (I,J) (D 1 ).</p><p>Consider the causal graph D 2 = (V ∪ L, E) with latent variables. Focus on the subgraph of D 2 that includes all variables contributing to the m-connecting path of (X ⊥ ⊥ Y | Z, F ) Aug (I,J) (D2) . An example can be found in <ref type="bibr">Meek (2013b)</ref>. Let us call this subgraph D path = (V path , E path ). Consider a jointly Gaussian distribution on V path that is faithful to D path . Such a distribution exists by construction in <ref type="bibr">Meek (Theorem 7, Meek (2013b)</ref>). Denote this distribution by P path . We will focus on P path and later expand it by adding the remaining variables in D suff as jointly independent and independent of the variables in D path . Now, consider two intervention targets I and J on the CBN (D path , P path ), where I∆J = K. This implies that the distributions P I and P J account for the graphical separation of F I . For this proof, we treat F I as a regime variable indicating when we switch between P I and P J . This treatment is valid because we add only this single F node, without introducing others. Define the distribution P * as follows: in G I1 (D). Suppose that there exists a graph D ′ such that there is X</p><p>in G I2 (D ′ , I), this indicates that there is an inducing path and a directed path from X 4 to X 3 in D ′ X4 and thus in D ′ as D ′ X4 is a subgraph of D ′ . The bidirected edge between X</p><p>(1) 4 and X</p><p>(1) 3 in G I1 (D ′ , I) indicates that the directed path from X 4 to X 3 is broken in D ′ X2 . This can only happen when X 2 is in the directed path between X 4 and X 3 in D ′ and thus D ′ X4 as removing the edges into X 4 does not affect its descendants. Therefore, X 4 has a child other than X 3 and is an ancestor of X 2 . Nevertheless, X</p><p>(2) 4 has only one possible child X</p><p>(2) 3 in G I2 (D, I). Thus, the supposition does not hold. For the same reason, we can orient the circle mark in X</p><p>(2) 2 o→ X</p><p>(2) 3 in G I2 (D, I). These circle marks can only be oriented by comparing the graphical structures across domains. We need extra orientation rules to catch them.  The proposed Algorithm 1 cannot recover the circle marks at X 2 and X 4 , but there does not exist a causal graph that has an arrowhead at the same places in their I-augmented MAGs.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning and testing causal models with interventions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Daskalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kandasamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Intervention efficient algorithms for approximate learning of causal graphs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Addanki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcgregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Musco</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Algorithmic Learning Theory</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="151" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Towards characterizing markov equivalence classes for directed acyclic graphs with latent variables</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.1365</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Differentiable causal discovery from interventional data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Brouillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Drouin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="21865" to="21877" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimal structure identification with greedy search</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="507" to="554" />
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning high-dimensional directed acyclic graphs with latent and selection variables</title>
		<author>
			<persName><forename type="first">D</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Maathuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kalisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="page" from="294" to="321" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Order-independent constraint-based causal structure learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Maathuis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3741" to="3782" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Influence diagrams for causal modelling and inference</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dawid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Statistical Review</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="189" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Causation and intervention</title>
		<author>
			<persName><forename type="first">F</forename><surname>Eberhardt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">93</biblScope>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note>Unpublished doctoral dissertation</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Interventions and causal inference</title>
		<author>
			<persName><forename type="first">F</forename><surname>Eberhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy of science</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="981" to="995" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning causal structures using regression invariance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghassami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salehkaleybar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kiyavash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Budgeted experiment design for causal structure learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghassami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salehkaleybar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kiyavash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1724" to="1733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Characterization and greedy learning of interventional markov equivalence classes of directed acyclic graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2409" to="2464" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Two optimal strategies for active learning of causal models from interventional data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="926" to="939" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Invariant causal prediction for nonlinear models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Heinze-Deml</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Causal Inference</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">20170016</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Causal discovery from heterogeneous/nonstationary data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sanchez-Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">89</biblScope>
			<biblScope unit="page" from="1" to="53" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Causal inference and data fusion in econometrics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hünermund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Econometrics Journal</title>
		<imprint>
			<biblScope unit="volume">008</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Experiment selection for causal discovery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyttinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Eberhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3041" to="3071" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Causal discovery from soft interventions with unknown targets: Characterization and learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kocaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9551" to="9561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning nonparametric latent causal graphs with unknown interventions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Aragam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="60468" to="60513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bilaniuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01075</idno>
		<title level="m">Learning neural causal models from unknown interventions</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Experimental design for learning causal graphs with latent variables</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kocaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Characterization and learning of causal graphs with latent variables from soft interventions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kocaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Causal discovery from observational and interventional data across multiple environments</title>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="16942" to="16956" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Large-scale differentiable causal discovery of factor graphs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Hütter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pritchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Regev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<date type="published" when="2022">19290-19303, 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Bayesian causal discovery from unknown general interventions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mascaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Castelletti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.00509</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Causal inference and causal explanation with background knowledge</title>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1302.4972</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Strong completeness and faithfulness in bayesian networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1302.4973</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Methods for causal inference from gene perturbation experiments and validation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Meinshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Versteeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">27</biblScope>
			<biblScope unit="page" from="7361" to="7368" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Joint causal inference from multiple contexts</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Magliacane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Claassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="108" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Aspects of graphical models connected with causality</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Sessiorn of the international Statistical</title>
		<meeting>the 49th Sessiorn of the international Statistical<address><addrLine>Institute, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="399" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Causal diagrams for empirical research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><surname>Causality</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Causal discovery in heterogeneous environments under the sparse mechanism shift hypothesis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Von Kügelgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="10904" to="10917" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Causal inference by using invariant prediction: identification and confidence intervals</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bühlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B: Statistical Methodology</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="947" to="1012" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Elements of causal inference: foundations and learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Causal discovery and epidemiology: A potential for synergy</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Ekstrøm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Osler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Epidemiology</title>
		<imprint>
			<biblScope unit="page">e101</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ancestral graph markov models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="962" to="1030" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Causal machine learning for healthcare and precision medicine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Voisey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Q</forename><surname>O'neil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Tsaftaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Royal Society Open Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">220638</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning causal graphs with small interventions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kocaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vishwanath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">From probability to causality</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Studies: An International Journal for Philosophy in the Analytic Tradition</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Causation, prediction, and search</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Causal inference in the presence of latent variables and selection bias</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1302.4983</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Causal discovery from changes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence</title>
		<meeting>the Seventeenth conference on Uncertainty in artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="512" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Interventions, where and how? experimental design for causal models at scale. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tigas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Annadani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jesson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24130" to="24143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An algorithm for deciding if a set of observed independencies has a causal explanation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in artificial intelligence</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="323" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Fault injection based interventional causal learning for distributed applications</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bagehorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Filepp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Abe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="15738" to="15744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Polynomial-time algorithms for counting and sampling markov equivalent dags</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wienöbst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bannach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liskiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="12198" to="12206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Characterizing and learning equivalence classes of causal dags under interventions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Katcoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Uhler</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5541" to="5550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Causal inference and reasoning in causally insufficient systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Causal reasoning with ancestral graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>a</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">On the completeness of orientation rules for causal discovery in the presence of latent confounders and selection bias</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">16-17</biblScope>
			<biblScope unit="page" from="1873" to="1896" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
