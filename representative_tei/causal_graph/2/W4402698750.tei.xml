<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fairness-Aware Streaming Feature Selection with Causal Graphs</title>
				<funder ref="#_mnjNNyk #_nrba6rz #_qJM43BR">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">Commonwealth Cyber Initiative</orgName>
					<orgName type="abbreviated">CCI</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-08-17">17 Aug 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Leizhen</forename><surname>Zhang</surname></persName>
							<email>leizhen.zhang1@louisiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Advance Computer Studies</orgName>
								<orgName type="institution">University of Louisiana</orgName>
								<address>
									<settlement>Lafayette</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lusi</forename><surname>Li</surname></persName>
							<email>l3li@odu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Old Dominion University</orgName>
								<address>
									<region>Virginia</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Di</forename><surname>Wu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">College of Computer and Information Science</orgName>
								<orgName type="institution">Southwest University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sheng</forename><surname>Chen</surname></persName>
							<email>sheng.chen@louisiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Advance Computer Studies</orgName>
								<orgName type="institution">University of Louisiana</orgName>
								<address>
									<settlement>Lafayette</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">School of Data Science</orgName>
								<orgName type="institution">William &amp; Mary</orgName>
								<address>
									<settlement>Williamsburg</settlement>
									<region>Virginia</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yi</forename><surname>He</surname></persName>
							<email>yihe@wm.edu</email>
						</author>
						<title level="a" type="main">Fairness-Aware Streaming Feature Selection with Causal Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-08-17">17 Aug 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2408.12665v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes a new online feature selection approach with an awareness of group fairness. Its crux lies in the optimization of a tradeoff between accuracy and fairness of resultant models on the selected feature subset. The technical challenge of our setting is twofold: 1) streaming feature inputs, such that an informative feature may become obsolete or redundant for prediction if its information has been covered by other similar features that arrived prior to it, and 2) non-associational feature correlation, such that bias may be leaked from those seemingly admissible, non-protected features. To overcome this, we propose Streaming Feature Selection with Causal Fairness (SFCF) that builds two causal graphs egocentric to prediction label and protected feature, respectively, striving to model the complex correlation structure among streaming features, labels, and protected information. As such, bias can be eradicated from predictive modeling by removing those features being causally correlated with the protected feature yet independent to the labels. We theorize that the originally redundant features for prediction can later become admissible, when the learning accuracy is compromised by the large number of removed features (non-protected but can be used to reconstruct bias information). We benchmark SFCF on five datasets widely used in streaming feature research, and the results substantiate its performance superiority over six rival models in terms of efficiency and sparsity of feature selection and equalized odds of the resultant predictive models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION Streaming data deluges in online applications</head> <ref type="bibr" target="#b0">[1]</ref><p>- <ref type="bibr" target="#b2">[3]</ref>, of which the huge volume tends to prohibit real-time decisionmaking that merely leverages manpower. Decisions aided by computing models are hence increasingly becoming a norm, which are about job or loan allocation <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref>, criminal recidivism <ref type="bibr" target="#b6">[7]</ref>, fraud detection <ref type="bibr" target="#b7">[8]</ref>, online advertising and recommendation <ref type="bibr" target="#b8">[9]</ref>, to name a few. However, such algorithmic decisions may unfairly discriminate against certain social groups that are constructed upon protected user characteristics, such as gender, age, and ethnicity <ref type="bibr" target="#b9">[10]</ref>.</p><p>The pursuit of mitigating algorithmic biases originates from the research conducted by Friedman and Nissenbaum in 1996 <ref type="bibr" target="#b10">[11]</ref> and has thrived within a decade <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b20">[21]</ref>, mainly due to the recent popularity of data-driven prediction and classification models <ref type="bibr" target="#b5">[6]</ref>. In those models, bias exists in the form of spurious (or superficial) statistical correlation between feature vectors and target labels, which represent users and decisions, respectively. Thus, the key idea shared by existing studies lies in the prevention of spurious correlations in training data from influencing the resultant model. Three main research thrusts stem from this idea <ref type="bibr" target="#b19">[20]</ref>: 1) pre-processing methods that directly modify statistical distributions of training data <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b21">[22]</ref>, 2) in-processing methods that impose fairness-based constraints on the objective function to regularize the training procedure <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, and 3) post-processing methods that scrutinize predictions and finetune the predicted label distributions to enforce outcome fairness with respect to prediction accuracy <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>.</p><p>Despite progresses, these thrusts mostly overlook one prominent stage in the lifecycle of data-driven applications, i.e., data generation. Too often in data-driven businesses, practitioners can source and inquiry hundreds even thousands of features for better user understanding and more precise user profiling <ref type="bibr" target="#b26">[27]</ref>. To wit, to detect fraudulent activities in online transactions, various features describing user behaviors are procured, such as the max/min/mean/top-k transactions over the last 10 seconds, 3/24/48 hours, or 1/2/4 weeks, etc. Consider the substantial loss of financial frauds <ref type="bibr" target="#b27">[28]</ref> and the fact that fraudsters can evolve their strategies to bypass the known indicative features <ref type="bibr" target="#b28">[29]</ref>, the banking industry urges to engineer more features and feature combinations to spotlight them. We refer to this data generation continuum as streaming features <ref type="bibr" target="#b29">[30]</ref>, where the feature set is nonexhaustive with new features constantly emerging.</p><p>How can algorithmic bias be eliminated from streaming features? This question remains open within the data mining community, and this study pioneers its first exploration. Its main technical challenge is twofold. On the one hand, the bias structure between features and label may not be associational <ref type="bibr" target="#b30">[31]</ref>, thereby complicating the strategy of predefining a subset of protected features and then removing all new features entailing them in the streaming features. On the other hand, new features may appear in high throughput, questioning the scalability of traditional feature selection methods being aware of fairness <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>. These methods operate and model the bias structure within a fixed feature space and thus must be reiterated each time a new feature is introduced. They falter, if the processing time for each feature exceeds the timespan of feature generation.</p><p>To overcome the challenge, we propose a new algorithm, named Streaming Feature Selection with Causal Fairness (SFCF). The key idea of SFCF is to leverage a causal structure that enables non-associational modeling among pro-tected features, admissible features (not protected, but carry sensitive demographic information), and the target labels. Unlike previous causal fairness studies <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b30">[31]</ref> that mostly postulate a known causal structure (which is next to impossible without domain knowledge), our SFCF excels by learning causal structure from streaming features in an online manner. Specifically, SFCF dynamically constructs two causal graphs being egocentric regarding the protected feature and label; once a new feature arrives, its topological positions on the two graphs are determined by its contribution to the algorithmic bias and prediction accuracy, respectively. In particular, if this feature is irrelevant or redundant to the label, it has no contribution to prediction and thus can be discarded. On the contrary, if the feature is relevant as well as non-redundant to the protected feature, it is inadmissible by possibly leaking the bias of the protected user information through the causal structure, thus is also pruned. In this study, we leverage d-separation <ref type="bibr" target="#b33">[34]</ref> to determine the feature positioning on causal graphs, allowing for the gauging of feature relevancy and redundancy in terms of conditional independence, regarding the target variable, i.e., label or protected feature, in their respective causal graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specific contributions of this paper are as follows:</head><p>1) Our work is the first study of online feature selection in streaming features with respect to the algorithmic performance regarding both accuracy and fairness. 2) We propose a new SFCF algorithm to solve the problem, with its key idea lying in a dynamic modeling of causal structure among protected features, inadmissible and admissible features, and labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Extensive experiments on five benchmark datasets</head><p>show the superiority of SFCF outperforming its six state-of-the-art competitors on average in the aspects of equalized odds, sparsity, and runtime by 52%, 98%, and 99%, respectively, while maintaining an average accuracy that remains virtually unchanged. 4) To champion reproducible research, our code and datasets are openly accessible at <ref type="url" target="https://github.com/zlzhan011/FSFS.git">https://github.com/zlzhan011/FSFS.git</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Fairness-Aware Machine Learning</head><p>We can divide fairness-aware machine learning algorithms into three primary categories. 1) For pre-processing approaches <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>, they aim to directly modify statistical distributions of training data by assigning weights to features or labels to achieve a fair representation of protected and reference groups with respect to their label assignments. For example, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b34">[35]</ref> propose massaging and reweighing techniques to adjust training data, ensuring predictions are independent of protected attributes. <ref type="bibr" target="#b18">[19]</ref> proposes a CGF framework that integrates causal graph structure learning with fairness regularization to minimize unfair edge weights, ensuring fair predictions by eliminating unfair causal effects. <ref type="bibr" target="#b16">[17]</ref> enforces statistical independence between model outputs and protected attributes, using Wasserstein-1 distances to align distributions across different groups. <ref type="bibr" target="#b30">[31]</ref> resamples training data to reduce bias, ensuring predictions independent of sensitive attributes for causally fair prediction, which could be time-consuming due to the sampling process. <ref type="bibr" target="#b11">[12]</ref> firstly introduces the inadmissible features, which are non-protected but could leak biased information from feature reconstruction. To mitigate their impact, <ref type="bibr" target="#b11">[12]</ref> proposes Capuchin which repairs training data by implementing interventional fairness, where both protected and inadmissible features are d-separated in the causal structure. <ref type="bibr" target="#b19">[20]</ref> introduces a HypeR framework, which uses a conditional probabilistic causal model to handle whatif and how-to queries, reducing discrimination for fair causal predictions in databases.</p><p>2) For in-processing, the methods <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref> modify learning objectives or model structures to achieve fairness. For example, <ref type="bibr" target="#b36">[37]</ref> introduces a method integrating discrimination and information gain as a new splitting criterion when constructing a Hoeffding Tree. <ref type="bibr" target="#b37">[38]</ref> proposes techniques incorporating regularization terms motivated by Mixed-integer programming to encourage low discrimination score. 3) For post-processing, the methods <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref> adjust algorithm predictions to achieve fairness. They involve altering the confidence of classification rules or re-labeling predicted classes in decision trees to prevent biased decisions against protected groups. However, all these methods cannot be directly adapted to streaming feature selection, mainly for two reasons. First, they are offline and presume all features are accessible prior to the learning process, which cannot be satisfied in our context wherein features emerge one at a time. Second, they mostly postulate prior knowledge of domain data (e.g., a known causal structure) or model architecture (e.g., trees or tree ensembles), thereby suffering from a generalization crisis when such assumptions do not hold in practice. Our proposed approach excels in the sense that we allow a sequential feature input and we do not rely on any domain knowledge nor assuming the structure of classifiers, thus is more general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Online Streaming Feature Selection</head><p>The main task of the methods in this category <ref type="bibr" target="#b40">[41]</ref>- <ref type="bibr" target="#b44">[45]</ref> is to generate a feature stream and select the optimal feature subset, aiming to maximize prediction performance while keeping selected features as few as possible. For example, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref> introduce an Alpha-investing method, which incorporates a new feature into the framework hinges on the p-value, with the impact of this addition evaluated through linear regression. To guide the selection of potential features, their technique relies on a heuristic understanding of the feature space's structure. However, this strategy may struggle with processing unmodified streaming features directly due to the practical challenge of acquiring comprehensive prior insights into such a structure. To relax this requirement, OSFS <ref type="bibr" target="#b42">[43]</ref> builds a Markov blanket for the target labels based on statistical independence, approximating the causal relationship between streaming features and labels. OCFSSF <ref type="bibr" target="#b43">[44]</ref> extends OSFS to consider spouse features of the Markov blanket by analyzing both conditional and unconditional independence relationships. However, these models mainly focus on the accuracy of prediction models and do not consider algorithmic fairness. Thus, once the protected and inadmissible features are wrongly incorporated into the selected feature subset, the resulting model will likely cause discrimination against protected groups, leading to algorithmic bias. To fill this gap, our proposed approach joins two objectives for optimizing both accuracy and fairness performance in the feature selection process. In particular, our approach allows for new features originally being redundant to the label into the selected feature subset, so as to remedy the information loss incurred by singling out the protected and inadmissible features for classification, thereby balancing the tradeoff between accuracy and fairness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PRELIMINARIES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Statement</head><p>Let a sequence of features be X = {X i | i = 1, . . . , D} ∈ R D×N , where X i denotes the feature that emerges at the round i, and D signifies the length of the feature stream. The column vector Y := {0, 1} N denotes the ground-truth labels. There are N instances in total. We have S / ∈ X the protected feature (e.g., gender, age, or ethnicity). The feature subset selected at round i is denoted by</p><formula xml:id="formula_0">F * i , |F * i | ≤ i.</formula><p>Let C denote the classifier trained on the selected features, our feature selection problem is constrained by empirical risk (ER) and group fairness measurement (GFM):</p><formula xml:id="formula_1">min i=1,...,T E[Y = C(F * i )]+λ F * i 0 , s.t. GF M (F * i ) ≤ ǫ,<label>(1)</label></formula><p>where the first term amounts for classification errors and the ℓ 0 -norm enforces the number of features in F * i to be minimized. The second GFM constraint can be implemented with demographic parity (DP) <ref type="bibr" target="#b45">[46]</ref>, equalized odds (EO) <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b46">[47]</ref>, or other fairness metrics based on the domain requirements. In this paper, we employ EO, defined:</p><formula xml:id="formula_2">GF M (F * i ) = max y={0,1} | P(C(F * i ) = 1 | S = 0, Y = y) -P(C(F * i ) = 1 | S = 1, Y = y)| .<label>(2)</label></formula><p>The intuition behind ( <ref type="formula" target="#formula_2">2</ref>) is to encourage the data points from the protected (S = 1) and reference (S = 0) groups to be predicted into the same class, with their maximum difference in opportunity controlled within a threshold ǫ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Causal Graph</head><p>Causal graphs are directed and acyclic (i.e., DAGs). Let G = (V, E) denote a causal DAG, where V is the set of nodes, and V i ∈ V represents the i-th node with the feature X i . A causal DAG is egocentric if it maps all connections from the perspective of a target node <ref type="bibr" target="#b47">[48]</ref>. In this study, we deem protect feature S or label Y as the target node, generally denoted as T . Given two features X i and X j , an edge E ij indicates the causal relationship between them, where X j → X i means that X i is the immediate descendant of X j . All features must be the descendants of T in our causal DAGs due to egocentricity. We propose to construct the edges from a Bayesian perspective, which entails a set of variable independence definitions, as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Bayesian Causal Relationship</head><p>To reason the causal relationship among features, we first define their independence and conditional independence.</p><p>Definition 1 (Null-Conditional Independence): For any i = j, X i , X j ∈ X are null-conditional independence, iif P(X i X j ) = P(X i )P(X j ), denoted as X i ⊥X j |∅.</p><p>Definition 2 (Conditional Independence <ref type="bibr" target="#b48">[49]</ref>):</p><formula xml:id="formula_3">For any i = n = m, X n , X m ∈ X are conditional independence iif P(X n |X m ,X i ) = P(X n |X i ), denoted as X n ⊥X m |X i .</formula><p>The topological position of a feature X i on G can be located by its relevancy and redundancy w.r.t. other features:</p><p>Definition 3 (Strong Relevance <ref type="bibr" target="#b49">[50]</ref>): A feature X i is deemed strongly relevant to T , iif ∀X j ⊆ Pow(G), it holds that T ⊥ X i |X j , where Pow(•) denotes powerset.</p><p>Definition 4 (Redundance <ref type="bibr" target="#b50">[51]</ref>): A feature X m is redundant to T , if there exists X j from the powerset of strongly relevant features, such that P(X m , X j ) = 0 and T ⊥X m |X j .</p><p>Definition 5 (Irrelevance <ref type="bibr" target="#b42">[43]</ref>): A feature X i is irrelevant, if it is not strongly relevant nor redundant to T .</p><p>Definition 6 (D-Separated): : If Z blocks all paths between X and Y, then X and Y are D-Separated and thus independent given Z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Technical Challenges and Our Thoughts</head><p>The main challenge arises from the existence of inadmissible features (a.k.a. proxy features <ref type="bibr" target="#b51">[52]</ref>) that are not protected, but can leak or be used to reconstruct the bias information conveyed by the protected features. Examples of such inadmissible features abound, such as zipcode, which is commonly included in user profiling and model training but has been evidenced to reveal the user's ethnicity, resulting in predictions discriminating against certain races <ref type="bibr" target="#b52">[53]</ref>. On the causal graphs generally, we can define:</p><formula xml:id="formula_4">Definition 7 (Inadmissible Feature): A feature X i is in- admissible, denoted as IA, if X i is not irrelevant to S.</formula><p>This general definition would result in a performance tradeoff between accuracy and fairness, because almost all features are null-conditional independent from others from the linear algebraic perspective when N is large. Thus, it is most likely that many features in F * i are relevant to label Y but are inadmissible. Pruning all such features would incur information loss, degrading classification performance of the trained model. In addition, computing the relevancy and redundancy of each incoming feature X i would require to compute the power set of the feature subset selected up to i, which entails combinatorial complexity depending on the size of F * i . The process is time and computationally intensive.</p><p>To overcome the challenge, we propose to establish causal graphs for a sensitive feature S and label Y independently. To ease notation, we denote them as the sensitive causal graph G S and the label causal graph G Y . We cast the problem of searching for inadmissible features into finding the overlapped features between the two graphs and replace them with a set of admissible features, denoted by A. The features in A reside outside of G S and G Y , which were originally deemed as redundant to Y . An inspiring observation is that they are also conditional independent or null-conditionally independent with the protected feature S, indicating their d-separation from S. Hence, it is possible that a feature subset in A may become redundant to S (thus do not leak bias) and relevant to Y (thus can provide classification information), after the removal of inadmissible features. As a result, locating this subset in A and replacing it with inadmissible features can be a viable solution to optimize the tradeoff between accuracy and algorithmic fairness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. THE SFCF APPROACH</head><p>Our proposed SFCF proceeds in two steps. First, two causal graphs egocentric to S and Y are built independently using Markov blanket, to model the non-associational contribution of an arriving feature to prediction and algorithm bias. Second, we search for an admissible feature set to replace those inadmissible features causally related to classification and protected information, so as to remedy the predictive power loss incurred by removing them. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Causal Graph Construction with Markov Blanket</head><p>To realize our idea, we use Markov blanket (MB) to build two causal graphs for sensitive feature S and label Y independently. The motivation for using MB is twofold. 1) MB allows for an incremental modeling of feature correlation. In our context, where new features emerge in sequence, and therefore, most existing methods that require a complete feature space input falter. 2) MB causally dseparates an incoming feature from the target variable by retaining the strongly relevant features only, which lifts the computational overhead required by powerset search for redundant features.</p><p>To do that, we leverage the conditional independence tests including Fisher's z test and the G 2 test <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b54">[55]</ref> (The details are explained in the supplementary materials). Specifically, given a target T ∈ {Y, S}, for the ith incoming feature X i , we use conditional independence tests to identify three feature subsets and one corresponding relationship based on the MB for the i-th feature moment: StrongRelevant i (T ), Redundant i (T ), Irrelevant i (T ), and COR RE MB (i)(T ). These are derived from the (i -1)-th feature moment, incorporating any changes that occur at the i-th feature moment.</p><p>The first step is to see whether X i and target T satisfy the definition of null-conditional independence (Definition 1). If X i satisfies, we will add X i into Irrelevant i (T ); otherwise, we will add X i into the candidate features set, denoted as CF S(T ).</p><p>The second step involves the redundancy analysis phase, which is triggered by the addition of a new feature to CF S(T ). This phase filters the redundant features from CF S(T ). Once a new feature is added into CF S(T ), we will do a loop for each feature X m in CF S(T ), to see whether there exist ∃X j ⊆ Pow(CF S(T ) \ X m ) that satisfies P(X m , X j ) = 0 and T ⊥X m |X j (Definition 4). If it exists, X m will be added to Redundant i (T ). Simultaneously, we record the corresponding relationship in COR RE MB (i)(T ), a dictionary where the keys are X j and the values are redundant feature X m . If it does not exist, we keep X m remaining in the CF S(Y ). After the loop, the features in CF S(T ) excluding feature in Redundant i (T ) are StrongRelevant i (T ). Here, we observe that StrongRelevant i (T ) and MB i (T ) are equivalent based on Definition 3, as both are the minimal feature subset for which T ⊥ X i |X j holds for any other previously arrived features or feature combinations, i.e., X j ⊆ P ow(X 1 , . . . , X i-1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Optimizing the Accuracy-Fairness Tradeoff</head><p>Based on the constructed causal graphs, at round i, the inadmissible feature set IA i , admissible feature set A i are: <ref type="figure" target="#fig_0">1</ref>, the inadmissible features set is the red area, and the admissible features set is the yellow area excluding the overlap area between red and yellow.</p><formula xml:id="formula_5">IA i = MB i (S) ∪ Redundant i (S)<label>(3)</label></formula><formula xml:id="formula_6">A i = MB i (Y ) ∪ Redundant i (Y ) \ IA i (4) In figure</formula><p>The intersection MI i between IA i from MB i (Y ) is:</p><formula xml:id="formula_7">MI i = MB i (Y ) ∪ IA i (5)</formula><p>Considering both accuracy and fairness, the initially selected feature set is MB i (Y ) removed intersection MI i :</p><formula xml:id="formula_8">RI i = MB i (Y ) \ MI i (6)</formula><p>The motivation behind equation 6 is that we can remove all inadmissible features from MB i (Y ), so that the selected features do not contain any sensitive information at all, but only contain accurate information.</p><p>If MI i is ∅, it is an ideal situation. However, according to our observation, for most situations, the MI i is not ∅. If MI i is not ∅, although removing it from MB i (Y ) can remove the sensitive information from selected features, it causes the accuracy information loss. In the figure <ref type="figure" target="#fig_0">1</ref>, the MI i contains feature X 11 .</p><p>To compensate for the accuracy information loss caused by removing the MI i from MB i (Y ), we can select partial features from Redundant i (Y ) to replace MI i . Since some Because Redundant i (Y ) includes both admissible and inadmissible features, for the features AD1 i of ICRF i (Y ) belonging to the admissible set, incorporating AD1 i into ISF i will enhance accuracy without compromising fairness. For example, in figure <ref type="figure" target="#fig_0">1</ref>, AD1 i includes feature X 10 .</p><formula xml:id="formula_9">AD1 i = ICRF i (Y ) ∩ A i<label>(7)</label></formula><p>Finally, for AD1 i , the final selected feature set is F * i :</p><formula xml:id="formula_10">F * i = RI i ∪ AD2 i = MB i (Y ) \ MI i ∪ AD1 i (8)</formula><p>However, for the other features AD2 i of ICRF i (Y ) in inadmissible features, considering MI i belongs to either MB i (S) or Redundant i (S), AD2 i , being a corresponding redundant feature linked to MI i , must be situated within Redundant i (S). For example, in figure <ref type="figure" target="#fig_0">1</ref>, AD2 i includes feature X 7 . Our experiments indicate that AD2 i can increase the accuracy of information while the induced adverse impact on fairness can be accepted.</p><formula xml:id="formula_11">AD2 i = ICRF i (Y ) ∩ Redundant i (S)<label>(9)</label></formula><p>Finally, for AD2 i , the final selected feature set is F * i :</p><formula xml:id="formula_12">F * i = RI i ∪ AD2 i = MB i (Y ) \ MI i ∪ AD2 i<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Time Complexity Analysis</head><p>Our algorithms' main time consumption can be attributed to two key steps. Due to page limits, a detailed analysis of these steps is provided in the 'C. Time complexity Analysis' section under 'II. ALGORITHM' in the Supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiment Setup</head><p>In this work, we use five benchmark datasets, frequently employed in fairness literature, to robustly assess SFCF's effectiveness across diverse applications including income, credit card, and crime domains. For the competitors, we have selected six distinct methods as competitors, including Baseline(use all features, without features selection), Remove Sensitive, Kamiran-massaging/Kamiran-reweighting, Capuchin, OSFS <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b30">[31]</ref>. from various perspectives. For the evaluation protocol, we leverage the Accuracy (ACC) and Equalized Odds (EO) to benchmark the experiments. The detailed introduction of datasets, competitors, and evaluation protocol was deferred into Section 'A. Datasets', 'B. Competitors', and 'C. Evaluation Protocol' under 'III. EXPERIMENTS' in the Supplementary due to the page limits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Results</head><p>Q1: Do our algorithms outperform other methods?</p><p>Three key observations can be drawn from Tables I, III, and II to answer this question.</p><p>First, our SFCF-AD1 algorithm does very well in the online streaming features scenario, giving the highest average EO score of 0.103, while keeping a competitive average accuracy of 0.748. Our algorithms, SFCF-RI, SFCF-AD1, and SFCF-AD2, are better than the Baseline algorithm by ratios of 39.82%, 53.45%, and 47.16% in EO score, respectively, while only having a small decrease in accuracy ratios of 5.80%, 5.55%, and 4.92%.</p><p>Second, compared with the competitors like Kamiranmassaging, Kamiran-reweighting, Capuchin, and FairExp, which use different mechanisms to address fairness via features or label processing, Our SFCF-AD1 beats all of them. Our SFCF-AD1 is better than them in the EO score by average ratios of 59.0%, 8.8%, 58.32%, and 21.39%, respectively. This confirms that conventional offline methods do sub-optimally in the online streaming feature scenario. Compared to OSFS, which has the same scenario with our algorithms, our algorithms show a significant decrease in EO score, dropping by ratios of 29.83%, 46.21%, and 37.17%, while keeping a near-steady accuracy, which only dropped by ratios of 4.72%, 4.44%, and 3.75%, respectively.</p><p>Last, as illustrated in Tables III and II, our algorithms select the minimal average proportion of features (14.17%). Compared to the Baseline, Kamiran-massaging, Kamiranreweighting, Capuchin, and FairExp, our algorithms signif-   icantly reduce the proportion of the selected features by an average ratio of 85.83%. It's worth noting that this selective use of features may result in some information loss, explaining the slight decrease in our algorithms' accuracy. However, this trade-off is acceptable given the significant reductions in EO score. Considering the aforementioned observations, we can state that our algorithm outperforms other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q2: How efficient do our algorithms excel in the context of streaming features?</head><p>We can address this question through two observations. First, we compare OSFS, an online streaming feature selection method, to our proposed algorithmss: SFCF-AD1, SFCF-AD2, and SFCF-RI. In terms of EO score, our algorithms demonstrate an average decrease in the ratios of 29.38%, 46.20%, and 37.17% respectively, while the accuracy maintain stable, decreasing on average by the ratios of 4.72%, 4.44%, and 3.97%. These results emphasize our algorithm's versatility in the online streaming feature scenario, striking a balance between accuracy and EO score.</p><p>Second, our algorithms show minimum time consumption, average 2.394 seconds. The average times reducing the time by ratios of 53.21%, 46.17%, and 43.90% compared to the Baseline's average time. For offline methods, in terms of time consumption, our algorithms beat all of them. The time for SFCF-RI is only 5.01%, 3.65%, 2.09%, and 0.01% of Kamiran-massaging, Kamiran-reweighting, Capuchin, and FairExp respectively. Our algorithms are online and use incremental computation, meaning that when a new feature arrives, calculations are only done with the previously selected features, avoiding unnecessary computations. In contrast, offline methods need to compute each new feature with all the previously arrived features, involving lots of redundant calculations and wasting resources.</p><p>Q3: How to optimize the tradeoff between accuracycentric and fair-centric online feature selection?</p><p>If we remove only the sensitive feature, it means that we want to retain more accurate information, and the selected features are accuracy-centric. If we remove all the features in G S , it means that we aim to achieve greater fairness, and the selected features are fair-centric.</p><p>First, for the accuracy-centric, we can answer the question by comparing 'Remove S' with Baseline and our algorithms. When compared to the Baseline, the accuracy of 'Remove S' remains almost unchanged, with an average difference of just 0.88%. However, the EO score shows an average decrease of 32.16% across all five datasets. Notably, the decrease in EO score on the Credit Card dataset is a mere 4.06%, whereas, on the other four datasets, the reductions are more considerable at 17.39%, 26.12%, 40.90%, and 69.68%, respectively. Now, comparing 'Remove S' with our algorithms, SFCF-RI, SFCF-AD1, and SFCF-AD2, our algorithms perform better, with EO score reductions by the ratios of 9.93%, 31.39%, and 19.86%, respectively. These findings align with our expectations that removing only sensitive features can not tackle the fairness problem thoroughly, since other features carry or contain sensitive information.</p><p>Second, for the fair-centric, we can answer it by comparing SFCF-RI with the 7 competitors. SFCF-RI is a method that eliminates all features in G S . Here, SFCF-RI achieved a winning ratio of 57.14% and a losing ratio of 2.86% on the EO score when evaluated in a win/tie/loss format. In contrast, its performance on accuracy was less impressive, with a win ratio of only 14.28% and a higher loss ratio of 28.56%. This suggests that while removing all features in G S can considerably improve the EO score, it doesn't fare as well in maintaining accuracy. This is due to the fact that SFCF-RI eliminates all features in G S , some of which may contain label information beneficial for accuracy.</p><p>Q4: How well can the admissible features remedy the information loss incurred by the removal of features in G S ?</p><p>First, comparing SFCF-AD1 and SFCF-AD2 with online and offline methods provide insight to answer this question. When comparing with online methods SFCF-RI, we observe that across all five datasets, SFCF-AD1 and SFCF-AD2 display a substantial decrease in EO score, reducing it by ratios of 23.82% and 11.03% respectively, while maintaining a stable average accuracy with a relative fluctuation of within 1%. This suggests that AD1 and AD2 contain some information of intersection, can remedy the information loss caused by removing the intersection.</p><p>Second, compared to the offline method Baseline, our algorithms decrease the accuracy by an average of 5.50% and 4.82% but significantly reduced the EO score by an average of 53.45% and 45.64%. Against offline methods Capuchin and FairExp, our methods outperform in both EO and accuracy, improving them by 2.57%, 11.07%, and 58.32%, 21.39%, respectively. In comparison to offline methods of Kamiran-massaging and Kamiran-reweighting, SFCF-AD1 shows superior performance in terms of EO score, averaging a decrease by ratios of 59.05% and 8.80%, respectively. In terms of accuracy, Kamiran-massaging and Kamiranreweighting outperform SFCF-AD1, with higher ratios of 3.35% and 2.29%, respectively. Among these competitors, Kamiran-reweighting is closest to our performance, but it utilizes 100% of the features, our algorithms, SFCF-RI, SFCF-AD1, and SFCF-AD2, use only 14.17%, 25.56%, and 45.97% of the features respectively. This indicates that our algorithms achieve comparable effectiveness while using fewer features. Hence, the information loss incurred by the removal of features in graph G S can be remedied by the admissible features set.</p><p>VI. CONCLUSION Our research presents SFCF, an innovative method addressing the challenges of online feature selection in streaming data while ensuring fairness and maintaining predictive accuracy. By dynamically exploring the causal structure from incoming features in real-time, SFCF effectively captures the complex relationships among protected features, admissible features, and labels using the Markov blanket model, thereby mitigating algorithmic bias. Leveraging d-separation, we accurately gauge feature relevance and redundancy, enhancing fairness and accuracy. Our experiments show that SFCF outperforms state-of-the-art baselines across various metrics on benchmark datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Causal graphs G S and G Y . 1) Each small circle represents a feature or label with its name. 2) Varying shades of red areas represent S, M B(S), Redundant(S); different shades of yellow areas represent Y , M B(Y ), Redundant(Y ); white area represents Irrelevant(S) and Irrelevant(Y ). 3) The dashed line represents the potential relationship.</figDesc><graphic coords="4,54.00,329.22,248.52,106.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Experimental results, including ACC and EO, across 5 datasets using LR classifier. 1) The higher the ACC indicator, the better the model performs. Conversely, the smaller the EO indicator, the fairer the model is considered. Taking these two aspects into account, a model that is closer to the bottom right corner demonstrates better overall performance. 2) Our model, represented in blue, includes SFCF-RI, SFCF-AD1, and SFCF-AD2. 3) The numerical text surrounding the legend the average proportion of selected features.</figDesc><graphic coords="6,54.00,207.08,510.00,238.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Results of experiments ACC±standard deviation and EO±standard deviation on 5 datasets using the LR classifier running 5 times. 1) The larger the ACC indicator, the better the model. The smaller the EO indicator, the more fair the model. 2) • denotes that our approach significantly outperforms competitors according to paired t-tests at the 95% significance level. are redundant given MI i with target Y , if we remove MI i , they will be strong relevant with target Y . For each feature in MI i , we can use the corresponding relationship COR RE MB (i)(Y ) to get the corresponding redundant features ICRF i (Y ) from Redundant i (Y ) and put them into ISF i .</figDesc><table><row><cell cols="2">Dataset Met</cell><cell>Baseline</cell><cell>Kamiran-</cell><cell>Kamiran-</cell><cell>Capuchin</cell><cell>FairExp</cell><cell>OSFS</cell><cell>Remove S</cell><cell>SFCF-RI</cell><cell>SFCF-</cell><cell>SFCF-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>massaging</cell><cell>reweighting</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>AD1</cell><cell>AD2</cell></row><row><cell>D1</cell><cell>ACC EO</cell><cell>.849±.002 .115±.017•</cell><cell>.845±.001 .227±.038•</cell><cell>.841±.005 .079±.011•</cell><cell>.762±.020• .142±.013•</cell><cell>.755±.010• .025±.004</cell><cell>.846±.003 .101±.018•</cell><cell>.848±.002 .095±.020•</cell><cell>.805±.004 .035±.021</cell><cell>.805±.004 .035±.021</cell><cell>.806±.004 .036±.022</cell></row><row><cell>D2</cell><cell>ACC EO</cell><cell>.679±.006 .246±.017•</cell><cell>.665±.015 .342±.041•</cell><cell>.658±.014 .089±.032</cell><cell>.624±.044 .313±.075</cell><cell>.551±.016 .101±.025</cell><cell>.682±.009 .233±.022•</cell><cell>.680±.006 .236±.019•</cell><cell>.550±.022 .087±.026</cell><cell>.550±.022 .087±.026</cell><cell>.576±.011 .178±.036</cell></row><row><cell>D3</cell><cell>ACC EO</cell><cell>.770±.025 .287±.063•</cell><cell>.711±.019 .229±.124</cell><cell>.711±.019 .229±.124•</cell><cell>.696±.041 .287±.102•</cell><cell>.699±.031 .065±.049</cell><cell>.736±.032 .087±.032</cell><cell>.736±.032 .087±.032</cell><cell>.739±.021 .077±.039</cell><cell>.725±.012 .061±.033</cell><cell>.720±.012 .070±.044</cell></row><row><cell>D4</cell><cell>ACC EO</cell><cell>.806±.003 .044±.031</cell><cell>.794±.010 .040±.022</cell><cell>.793±.011 .041±.019</cell><cell>.796±.015 .065±.049</cell><cell>.651±.046• .188±.137•</cell><cell>.804±.004 .042±.023</cell><cell>.806±.002 .026±.019</cell><cell>.805±.002 .026±.019</cell><cell>.804±.003 .028±.015</cell><cell>.806±.002 .029±.028</cell></row><row><cell>D5</cell><cell>ACC EO</cell><cell>.856±.014 .421±.103•</cell><cell>.857±.012 .427±.112</cell><cell>.827±.023 .130±.059</cell><cell>.770±.024• .436±.107•</cell><cell>.713±.000• .280±.000</cell><cell>.848±.008 .500±.086•</cell><cell>.855±.012 .311±.074</cell><cell>.832±.020 .455±.134</cell><cell>.858±.017 .307±.083</cell><cell>.861±.012 .292±.069</cell></row><row><cell>W/T/L</cell><cell>ACC</cell><cell>0/3/2</cell><cell>0/3/2</cell><cell>0/3/2</cell><cell>2/3/0</cell><cell>3/2/0</cell><cell>0/3/2</cell><cell>0/3/2</cell><cell>-</cell><cell>0/4/1</cell><cell>0/3/2</cell></row><row><cell>-RI</cell><cell>EO</cell><cell>3/2/0</cell><cell>2/3/0</cell><cell>2/2/1</cell><cell>3/2/0</cell><cell>0/5/0</cell><cell>2/3/0</cell><cell>2/3/0</cell><cell>-</cell><cell>0/4/1</cell><cell>1/2/2</cell></row><row><cell>W/T/L</cell><cell>ACC</cell><cell>0/1/4</cell><cell>0/3/2</cell><cell>0/3/2</cell><cell>2/3/0</cell><cell>3/2/0</cell><cell>0/3/2</cell><cell>0/2/3</cell><cell>1/4/0</cell><cell>-</cell><cell>1/3/1</cell></row><row><cell>-AD1</cell><cell>EO</cell><cell>4/1/0</cell><cell>2/3/0</cell><cell>1/3/1</cell><cell>3/2/0</cell><cell>0/5/0</cell><cell>3/2/0</cell><cell>2/3/0</cell><cell>1/4/0</cell><cell>-</cell><cell>1/4/0</cell></row><row><cell>W/T/L</cell><cell>ACC</cell><cell>0/2/3</cell><cell>0/3/2</cell><cell>0/3/2</cell><cell>2/3/0</cell><cell>3/2/0</cell><cell>0/3/2</cell><cell>0/3/2</cell><cell>2/3/0</cell><cell>1/3/1</cell><cell>-</cell></row><row><cell>-AD2</cell><cell>EO</cell><cell>4/1/0</cell><cell>2/3/0</cell><cell>1/2/2</cell><cell>3/2/0</cell><cell>0/4/1</cell><cell>3/2/0</cell><cell>2/3/0</cell><cell>1/3/1</cell><cell>0/4/1</cell><cell>-</cell></row></table><note><p>features</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>The average proportion of features selected, based on 5 runs across 5 datasets. 1) D: Dataset; 2) #: the number of features; 3) Met: Metrics name. 4) RSF: The ratio between selected features and the total number of features.. 5) NSF: the number of selected features;</figDesc><table><row><cell>D</cell><cell>#</cell><cell cols="3">Met Baseline Kamiran-</cell><cell>Kamiran-</cell><cell cols="4">Capuchin FairExp OSFS Remove</cell><cell>SFCF-</cell><cell>SFCF-</cell><cell>SFCF-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>massaging</cell><cell>reweighting</cell><cell></cell><cell></cell><cell></cell><cell>S</cell><cell>RI</cell><cell>AD1</cell><cell>AD2</cell></row><row><cell>D1</cell><cell>14</cell><cell>NSF RSF</cell><cell>14 1.0</cell><cell>14 1.0</cell><cell>14 1.0</cell><cell>14 1.0</cell><cell>&gt;1.0</cell><cell>9 .642</cell><cell>13 .928</cell><cell>4 .285</cell><cell>5 .357</cell><cell>5 .357</cell></row><row><cell>D2</cell><cell>12</cell><cell>NSF RSF</cell><cell>12 1.0</cell><cell>12 1.0</cell><cell>12 1.0</cell><cell>12 1.0</cell><cell>&gt;1.0</cell><cell>5 .416</cell><cell>11 .916</cell><cell>1 .083</cell><cell>1 .083</cell><cell>2 .166</cell></row><row><cell>D3</cell><cell>25</cell><cell>NSF RSF</cell><cell>25 1.0</cell><cell>25 1.0</cell><cell>25 1.0</cell><cell>25 1.0</cell><cell>&gt;1.0</cell><cell>4 .160</cell><cell>24 .960</cell><cell>3 .120</cell><cell>8 .320</cell><cell>9 .360</cell></row><row><cell>D4</cell><cell>24</cell><cell>NSF RSF</cell><cell>24 1.0</cell><cell>24 1.0</cell><cell>24 1.0</cell><cell>24 1.0</cell><cell>&gt;1.0</cell><cell>8 .333</cell><cell>23 .958</cell><cell>5 .208</cell><cell>10 .416</cell><cell>14 .583</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>122</cell><cell>2</cell><cell>14</cell><cell>104</cell></row><row><cell></cell><cell></cell><cell>RSF</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>&gt;1.0</cell><cell>.032</cell><cell>.991</cell><cell>.016</cell><cell>.113</cell><cell>.845</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>SFCF</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>SFCF</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>SFCF</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>The average running time (in seconds) taken by different algorithms across five datasets over five runs.</figDesc><table><row><cell cols="3">Dataset Baseline Kamiran-</cell><cell>Kamiran-</cell><cell>Capuchin</cell><cell>FairExp</cell><cell>OSFS</cell><cell>Remove</cell><cell>SFCF-RI</cell><cell>SFCF-</cell><cell>SFCF-</cell></row><row><cell></cell><cell></cell><cell>massaging</cell><cell>reweighting</cell><cell></cell><cell></cell><cell></cell><cell>S</cell><cell></cell><cell>AD1</cell><cell>AD2</cell></row><row><cell>D1</cell><cell>4.925</cell><cell>59.163</cell><cell>59.782</cell><cell>154.207</cell><cell>32882.201</cell><cell>3.813</cell><cell>4.831</cell><cell>3.471</cell><cell>3.456</cell><cell>3.779</cell></row><row><cell>D2</cell><cell>3.326</cell><cell>69.354</cell><cell>207.403</cell><cell>207.462</cell><cell>3590.497</cell><cell>2.273</cell><cell>3.637</cell><cell>1.681</cell><cell>1.583</cell><cell>1.685</cell></row><row><cell>D3</cell><cell>5.417</cell><cell>28.342</cell><cell>28.593</cell><cell>66.220</cell><cell>3095.371</cell><cell>1.062</cell><cell>2.780</cell><cell>1.147</cell><cell>1.068</cell><cell>1.130</cell></row><row><cell>D4</cell><cell>8.492</cell><cell>39.908</cell><cell>41.176</cell><cell>83.061</cell><cell>29326.990</cell><cell>5.339</cell><cell>8.849</cell><cell>4.341</cell><cell>4.957</cell><cell>4.291</cell></row><row><cell>D5</cell><cell>3.441</cell><cell>42.447</cell><cell>40.409</cell><cell>175.345</cell><cell>658818.357</cell><cell>1.405</cell><cell>3.545</cell><cell>1.337</cell><cell>2.716</cell><cell>3.477</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>*This work was supported in part by the <rs type="funder">National Science Foundation (NSF)</rs> under Grants <rs type="grantNumber">CNS-2245918</rs>, <rs type="grantNumber">IIS-2245946</rs>, and <rs type="grantNumber">IIS-2236578</rs>, and by the <rs type="funder">Commonwealth Cyber Initiative (CCI)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_mnjNNyk">
					<idno type="grant-number">CNS-2245918</idno>
				</org>
				<org type="funding" xml:id="_nrba6rz">
					<idno type="grant-number">IIS-2245946</idno>
				</org>
				<org type="funding" xml:id="_qJM43BR">
					<idno type="grant-number">IIS-2236578</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The data deluge: An e-science perspective</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trefethen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Grid computing: Making the global infrastructure a reality</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="809" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Modeling and optimization for big data analytics:(statistical) learning tools for our era of data deluge</title>
		<author>
			<persName><forename type="first">K</forename><surname>Slavakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mateos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="18" to="31" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Forecast: The business value of artificial intelligence, worldwide, 2017-2025</title>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Lovelock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Woodward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Priestley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Gartner.(ID G00348137</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Amazon scraps secret ai recruiting tool thatshowed bias against women</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dastin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ethics of Data and Analyt-ics</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="296" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Help wanted: An examination of hiring algorithms, equity, and bias</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bogen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rieke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">&apos;it&apos;s reducing a human being to a percentage&apos; perceptions of justice in algorithmic decisions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Binns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Kleek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Veale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Lyngs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shadbolt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Chi conference on human factors in computing systems</title>
		<meeting>the 2018 Chi conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fair prediction with disparate impact: A study of bias in recidivism prediction instruments</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chouldechova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="163" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistical fraud detection: A review</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical science</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="235" to="255" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The online advertising industry: Economics, evolution, and privacy</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of economic perspectives</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="37" to="60" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Equality law and the protected characteristics</title>
		<author>
			<persName><forename type="first">K</forename><surname>Malleson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Modern Law Review</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="598" to="621" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bias in computer systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nissenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on information systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="330" to="347" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Interventional fairness: Causal database repair for algorithmic fairness</title>
		<author>
			<persName><forename type="first">B</forename><surname>Salimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data</title>
		<meeting>the 2019 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="793" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Algorithmic fairness: Choices, assumptions, and definitions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Potash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>D'amour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Statistics and Its Application</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="141" to="163" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Equality of opportunity in supervised learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fairness-aware classifier with prejudice remover regularizer</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kamishima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Akaho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Asoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sakuma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2012</title>
		<meeting><address><addrLine>Bristol, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">September 24-28, 2012. 2012</date>
			<biblScope unit="page" from="35" to="50" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II 23</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fairness constraints: Mechanisms for fair classification</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Zafar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Rogriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="962" to="970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Wasserstein fair classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pacchiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stepleton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="s">Uncertainty in artificial intelligence</title>
		<imprint>
			<biblScope unit="page" from="862" to="872" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Certifying and removing disparate impact</title>
		<author>
			<persName><forename type="first">S</forename><surname>Friedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatasubramanian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3756</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Path-specific counterfactual fairness</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7801" to="7808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Causal feature selection for algorithmic fairness</title>
		<author>
			<persName><forename type="first">S</forename><surname>Galhotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sattigeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Varshney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="276" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mitigating bias in algorithmic systems --a fish-eye view</title>
		<author>
			<persName><forename type="first">K</forename><surname>Orphanou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kleanthous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Batsuren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giunchiglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bogina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hartman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kuflik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Optimized pre-processing for discrimination prevention</title>
		<author>
			<persName><forename type="first">F</forename><surname>Calmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vinzamuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Natesan</forename><surname>Ramamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Varshney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Three naive bayes approaches for discrimination-free classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Calders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Verwer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data mining and knowledge discovery</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="277" to="292" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Classification with fairness constraints: A meta-algorithm with provable guarantees</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Celis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Keswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Vishnoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on fairness, accountability, and transparency</title>
		<meeting>the conference on fairness, accountability, and transparency</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="319" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Data preprocessing techniques for classification without discrimination</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kamiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Calders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and information systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Achieving outcome fairness in machine learning models for social decision problems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>-Y. Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="444" to="450" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Febench: A benchmark for real-time relational data feature extraction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="3597" to="3609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Intelligent financial fraud detection: a comprehensive review</title>
		<author>
			<persName><forename type="first">J</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bhattacharya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; security</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="47" to="66" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Financial cybercrime: A comprehensive survey of deep learning approaches to tackle the evolving financial crime landscape</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nicholls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kuppa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N.-A</forename><surname>Le-Khac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="163" to="965" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Online feature selection with streaming features</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1178" to="1192" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automated feature engineering for algorithmic fairness</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Neutatz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Abedjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1694" to="1702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Lessons from archives: Strategies for collecting sociocultural data in machine learning</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 conference on fairness, accountability, and transparency</title>
		<meeting>the 2020 conference on fairness, accountability, and transparency</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="306" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Fairprep: Promoting data to a first-class citizen in studies on fairness-enhancing interventions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schelter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Khilnani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stoyanovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.12587</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Finding minimal d-separators in linear time and applications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Van Der Zander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liśkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="637" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Building classifiers with independency constraints</title>
		<author>
			<persName><forename type="first">T</forename><surname>Calders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kamiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pechenizkiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE international conference on data mining workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Certifying and removing disparate impact</title>
		<author>
			<persName><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Friedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 21th ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="259" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Faht: an adaptive fairness-aware decision tree classifier</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ntoutsi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.07237</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning optimal and fair decision trees for non-discriminative decision-making</title>
		<author>
			<persName><forename type="first">S</forename><surname>Aghaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Azizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vayanos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1418" to="1426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Discrimination aware decision tree learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kamiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Calders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pechenizkiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE international conference on data mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="869" to="874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Discrimination-and privacy-aware patterns</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hajian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Domingo-Ferrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Monreale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pedreschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giannotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1733" to="1782" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Streaming feature selection using alpha-investing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining</title>
		<meeting>the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="384" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Streamwise feature selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Stine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Online streaming feature selection</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th international conference on machine learning (ICML-10)</title>
		<meeting>the 27th international conference on machine learning (ICML-10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1159" to="1166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Online causal feature selection for streaming features</title>
		<author>
			<persName><forename type="first">D</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Online streaming feature selection using adapted neighborhood rough set</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">481</biblScope>
			<biblScope unit="page" from="258" to="279" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Fairness definitions explained</title>
		<author>
			<persName><forename type="first">S</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international workshop on software fairness</title>
		<meeting>the international workshop on software fairness</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Beyond adult and COMPAS: Fair multi-class prediction via information projection</title>
		<author>
			<persName><forename type="first">W</forename><surname>Alghamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Michalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Asoodeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Calmon</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=0e0es11XAIM" />
		<editor>NeurIPS, A. H. Oh, A. Agarwal, D. Belgrave, and K. Cho</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning causal bayesian network structures from experimental data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">482</biblScope>
			<biblScope unit="page" from="778" to="789" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Toward optimal feature selection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sahami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page">292</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Wrappers for feature subset selection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="273" to="324" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Efficient feature selection via analysis of relevance and redundancy</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1205" to="1224" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A review on fairness in machine learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pessach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shmueli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="44" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Assessing algorithmic fairness with unobserved protected class using data combination</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kallus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1959" to="1981" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<title level="m">Causation, prediction, and search</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Learning bayesian networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Neapolitan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Pearson Prentice Hall Upper Saddle River</publisher>
			<biblScope unit="volume">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
