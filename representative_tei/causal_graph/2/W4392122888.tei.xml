<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-11-27">27 Nov 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yifan</forename><surname>Duan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei China</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guibin</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Tongji University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shilong</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei China</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaojiang</forename><surname>Peng</surname></persName>
							<email>pengxiaojiang@sztu.edu.cn</email>
							<affiliation key="aff3">
								<orgName type="department">{Yifan Duan</orgName>
								<orgName type="institution">Shenzhen Technology University</orgName>
								<address>
									<addrLine>Shilong Wang Wang Ziqi Hao Wu, wk520529</addrLine>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wang</forename><surname>Ziqi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei China</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junyuan</forename><surname>Mao</surname></persName>
							<email>maojunyuan@mail.ustc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei China</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei China</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinke</forename><surname>Jiang</surname></persName>
							<email>thinkerjiang@foxmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kun</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei China</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-11-27">27 Nov 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2402.14708v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Credit card fraud poses a significant threat to the economy. While Graph Neural Network (GNN)based fraud detection methods perform well, they often overlook the causal effect of a node's local structure on predictions. This paper introduces a novel method for credit card fraud detection, the Causal Temporal Graph Neural Network (CaT-GNN), which leverages causal invariant learning to reveal inherent correlations within transaction data. By decomposing the problem into discovery and intervention phases, CaT-GNN identifies causal nodes within the transaction graph and applies a causal mixup strategy to enhance the model's robustness and interpretability. CaT-GNN consists of two key components: Causal-Inspector and Causal-Intervener. The Causal-Inspector utilizes attention weights in the temporal attention mechanism to identify causal and environment nodes without introducing additional parameters. Subsequently, the Causal-Intervener performs a causal mixup enhancement on environment nodes based on the set of nodes. Evaluated on three datasets, including a private financial dataset and two public datasets, CaT-GNN demonstrates superior performance over existing state-of-the-art methods. Our findings highlight the potential of integrating causal reasoning with graph neural networks to improve fraud detection capabilities in financial transactions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The substantial damages wrought by financial fraud continue to garner ongoing focus from academic circles, the business sector, and regulatory bodies <ref type="bibr" target="#b10">[Jiang et al., 2016;</ref><ref type="bibr">Aleksiejuk and HoÅ‚yst, 2001]</ref>. Fraudsters masquerade as ordinary users and attack transactions made with credit cards <ref type="bibr" target="#b10">[Ileberi et al., 2022]</ref>, which may inflict substantial economic losses and pose a severe threat to sustainable economic growth <ref type="bibr">[AlFalahi and Nobanee, 2019]</ref>. Consequently, effective detection of financial fraud is imperative for safeguarding the economy and consumer security. In the financial deception realm, identifying credit card fraud has garnered considerable attention among both industry and academia <ref type="bibr" target="#b1">[Bhattacharyya et al., 2011]</ref>. Traditional approaches to detecting fraudulent activities typically entail meticulous examination of each transaction for irregularities, employing predefined criteria such as verification against lists of compromised cards or adherence to established transaction thresholds <ref type="bibr" target="#b17">[Maes et al., 2002;</ref><ref type="bibr" target="#b7">Fu et al., 2016]</ref>. However, the aforementioned anti-fraud systems, based on expert prior and rules, are often susceptible to exploitation by fraudsters, who can circumvent detection by crafting ingenious transaction methods that elude the system's scrutiny of illicit activities. Toward this end, predictive modeling has been introduced, aiming to autonomously identify patterns that suggest fraudulent activity and calculate a corresponding risk score.</p><p>Currently, state-of-the-art predictive models are focused on using deep learning methods, capturing potential illegal patterns in a data-driven manner <ref type="bibr" target="#b7">[Fu et al., 2016;</ref><ref type="bibr">Dou et al., 2020]</ref>. For instance, <ref type="bibr" target="#b15">[Liu et al., 2021]</ref> introduces PC-GNN, a Graph Neural Network approach that effectively handles class imbalance in graph-based fraud detection by selectively sampling nodes and edges, particularly focusing on the minority class. Moreover, <ref type="bibr" target="#b25">[Xiang et al., 2023]</ref> leverages transaction records to construct a temporal transaction graph, apply-ing a Gated Temporal Attention Network to effectively learn transaction representations and model fraud patterns. Unfortunately, i) these methods often overlook the intrinsic patterns and connections within the data due to a lack of consideration for local structure consistency; ii) they lack the ability to uncover the causal nature of each specific case, which leads to inadequate differentiation between the attributes of causal nodes and environment nodes, thereby impairing the model's generalization capabilities; iii) they lack interpretability in making specific predictions.</p><p>In this paper, we introduce a novel Causal Temporal Graph Neural Network, termed CaT-GNN, aiming at providing an interpretable paradigm for credit card fraud detection. Guided by the currently popular causal invariant learning techniques <ref type="bibr" target="#b2">[Chang et al., 2020;</ref><ref type="bibr" target="#b16">Liu et al., 2022]</ref>, CaT-GNN's primary objective is to unveil the inherent correlations in the transaction attribute data of nodes within available temporal transaction graphs, thereby offering interpretability for complex transaction fraud problems.</p><p>To unravel causal correlations, specifically, we decompose the algorithmic process of CAT-GNN into two stages discovery and intervention. The goal of the discovery stage is to identify potential causal components within observed temporal graph data, where we introduce a causal temporal graph neural network for modeling. Utilizing the popular node-attention metrics <ref type="bibr">[VeliÄkoviÄ‡ et al., 2017;</ref><ref type="bibr" target="#b25">Xiang et al., 2023]</ref>, we employ attention score to locate key nodes, designated as causal and environment nodes. In the intervention process, we aim to reasonably enhance potential environment nodes. This approach is designed to align with and perceive the underlying distribution characteristics in explicit fraud networks, thereby boosting our temporal GNN's ability to identify and understand problematic nodes. Furthermore, drawing inspiration from <ref type="bibr" target="#b22">[Wang et al., 2020]</ref>, to ensure that causal interventions between nodes do not interfere with each other, we create parallel universes for each node. Consequently, the model is exposed to a wider potential data distribution, providing insights for fraud prediction with a causal perspective. This process can further be understood as a back-door adjustment in causal theory <ref type="bibr" target="#b18">[Pearl, 2009;</ref><ref type="bibr">Pearl and Mackenzie, 2018]</ref>. The contributions of this paper are summarized as follows:</p><p>â€¢ We propose a novel method, CaT-GNN, that embodies both causality and resilience for the modeling of credit card fraud detection. By harnessing causal theory, known for its interpretability, CaT-GNN enables the model to encompass a wider potential data distribution, thereby ensuring its exceptional performance in this task.</p><p>â€¢ CaT-GNN, characterized by its refined simplicity, initially identifies causal nodes and subsequently refines the model into a causally coherent structure. It aims to achieve invariance in attribute information and temporal features through semi-supervised learning, thereby providing a bespoke and robust foundation for targeted tasks.</p><p>â€¢ We evaluate CaT-GNN on three representative datasets, including a private financial benchmark, and the other two are public settings. Extensive experiments show that our proposed method outperforms the compared state-of-the-art baselines in credit card fraud detection, thanks to the casual intervention of the node causal augment.</p><p>2 Preliminaries </p><formula xml:id="formula_0">Definition 1. (Multi-Relation Graph) The Multi-Relation Financial Graph G is defined as G = (V, E, X , Y), where V = {v 1 , v 2 , â€¢ â€¢ â€¢ , v N }</formula><formula xml:id="formula_1">Î˜ L = -1 B B u=1 y âŠ¤ i log (Å· i ) + (1 -y i ) âŠ¤ log (1 -Å·i ) +Î·||Î˜|| 2 ,</formula><p>where B is the batch size, Å·i âˆˆ [0, 1] is the predicted probability, and y i âˆˆ {0, 1} is the ground truth. Î˜ is the parameter of the GNN predictor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>In Section 3.1, we explore the motivation behind our approach, emphasizing the crucial role of understanding the local structure and causal relationships within transaction data to improve detection accuracy. Section 3.2 introduces our two-phase method: discovery and intervention. Section Section 3.2 provides the causal theory support. Taking the arXiv <ref type="bibr" target="#b9">[Hu et al., 2020]</ref> dataset as an example, real-world graphs often exhibit locally variable structures,  that is, the distribution of node attributes differs from the distribution of local structural properties <ref type="bibr" target="#b6">[Feng et al., 2021]</ref>. We observe that this phenomenon is also prevalent in the financial sector, where cunning fraudsters may disguise themselves through various means (such as feature camouflage and relationship disguise) to connect with users who have a good credit transaction history <ref type="bibr">[Dou et al., 2020]</ref>. In such scenarios, if we simply aggregate node information and neighbor information together, it is likely to obscure the suspiciousness of the fraudsters, which contradicts our objective. This situation tends to yield poorer training outcomes, especially in a semi-supervised learning environment with limited labeled data. Existing methods do not incorporate causal factors into credit card fraud modeling, resulting in models that fail to learn the intrinsic connections of node attributes. This oversight further leads to the neglect of causal attribute structure differences on test nodes, thereby reducing the model's generalizability. By comprehensively examining the confounding variables, we are able to significantly alleviate the aforementioned issue, as illustrated in Figure <ref type="figure" target="#fig_1">2</ref>. This strategy is the cornerstone of our framework and is also known as the "backdoor adjustment" technique <ref type="bibr" target="#b18">[Pearl, 2009;</ref><ref type="bibr">Pearl and Mackenzie, 2018]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Motivation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Discovering &amp; Intervention</head><p>Based on the motivation, we adopt a causal perspective to analyze the attribute aggregation process and formalize principles for distinguishing between causal and non-causal elements within local structures. We first introduce the discovery process to effectively examine the causal and environment nodes within the current node's local structure. In response, we refine the temporal attention graph network mechanism <ref type="bibr" target="#b25">[Xiang et al., 2022]</ref> into a causal temporal GAT mechanism as shown in the upper half of Figure <ref type="figure" target="#fig_2">3</ref>. This refinement introduces two key components designed to accurately identify both environmental and causal nodes, which enhances our ability to understand and manipulate the local structural dynamics more effectively.</p><p>In the context of temporal transaction graphs, we main-tain a set of transaction records, denoted as</p><formula xml:id="formula_2">R = [r t1 , r t2 , â€¢ â€¢ â€¢ , r ti ], alongside their embeddings X = [x t1 , x t2 , â€¢ â€¢ â€¢ , x ti ]</formula><p>obtained via a projection layer. As demonstrated in <ref type="bibr" target="#b20">[Shi et al., 2020]</ref>, GNNs are capable of concurrently propagating attributes and labels. Consequently, we integrate fraud labels as an embedded feature within the attribute embedding x ti , employing masking techniques to prevent label leakage <ref type="bibr" target="#b25">[Xiang et al., 2023]</ref>. However, this aspect does not constitute the primary focus of our research.</p><p>Causal-Inspector: We design a Causal-Inspector to identify causal and environment nodes as shown in the bottom left corner of Figure <ref type="figure" target="#fig_2">3</ref>. To aggregate information efficiently, we employ the aforementioned causal temporal graph attention mechanism, which allows for dynamic information flow based on the temporal relationships among transactions. Leveraging a multi-head attention mechanism, we compute temporal attention scores that serve as weights for each neighboring node, facilitating the assessment of each neighbor's causal importance, which can be formulated as follows:</p><formula xml:id="formula_3">Î± h xi,xj = exp LeakyReLU(W T a [x i âŠ• x j ]) jâˆˆN (xi) exp(LeakyReLU W T a [x i âŠ• x j ]) ,<label>(1)</label></formula><p>where W a is a learnable weight matrix, Î± xi,xj represents the attention weight of node x i with respect to node x j in one head, which determines the importance of node x i relative to node x j . The âŠ• symbol represents the concatenation operation. N (x i ) is the set of temporal neighboring nodes of node x i . In order to quantify the importance of each node x j we aggregate the attention weights Î± h xi,xj from each attention head and compute the average to determine the final weight of the node. Then, based on its final weight, we calculate its normalized importance:</p><formula xml:id="formula_4">á¾±xi,xj = 1 H H h=1 Î± h xi,xj â†’ I j = á¾±xi,xj / N (xi) j=1 á¾±xi,xj (2)</formula><p>where H is the total number of attention heads and</p><formula xml:id="formula_5">I i = [I j1 , â€¢ â€¢ â€¢ , I jN (xi)</formula><p>] represents the set of importance of each node with respect to x i . This formula calculates the normalized importance weight I j , representing the importance of node x j by compiling the contributions from all attention heads, thus providing a comprehensive measure of node significance. To segregate the nodes into environmental and causal categories, we introduce a proportion parameter r e , ranging between 0 and 1, which denotes the fraction of nodes to be earmarked as environment nodes. This approach affords us the flexibility to select environment nodes tailored to the specific exigencies of the graph. We use the argmin(â€¢) function to select the âŒˆr e N âŒ‰ nodes with the lowest importance scores as environment nodes. Therefore, a ranking function R is defined to map I j to its rank among all node importance scores. Then, we determine the environment set S e as:</p><formula xml:id="formula_6">S e = x j | argmin j=1,â€¢â€¢â€¢ ,âŒŠreN âŒ‹ R(I j ) .<label>(3)</label></formula><p>The remaining nodes, those not in S e , naturally form the set of causal nodes S c .This method ensures that nodes with the lowest importance scores are precisely selected as environmenta nodes according to the proportion r e , while the rest serve as causal nodes. Due to the differences between test and training distributions <ref type="bibr" target="#b6">[Feng et al., 2021]</ref>, CaT-GNN is dedicated to perceiving the essence of temporal graph data, thereby enhancing generalization capabilities and robustness.</p><p>Causal-Intervener: We design a Causal Intervener as shown in the bottom right corner of Figure <ref type="figure" target="#fig_2">3</ref>, which employs a transformative mixup strategy known as a causal mixup, that blends environment nodes with a series of causally significant nodes. Given an environmental node x j âˆˆ S e , We select the causal nodes {x c1 , x c2 , â€¢ â€¢ â€¢ , x ck } with the highest importance scores, which are computed as outlined in the Causal-Inspector, from the causal set S c at a proportion of r c . The causal mixup is then executed by linearly combining the environmental node with the selected causal nodes, weighted by their respective coefficients {a j , a 1 , a 2 , â€¢ â€¢ â€¢ , a k }, which are learned through a dedicated linear layer:</p><formula xml:id="formula_7">x â€² j = a j x j + k i=1 a i x ci ,<label>(4)</label></formula><p>where x â€² j is the causally mixed environmental node, k is the number of selected causal nodes, a j is the self-weight of the environmental node reflecting its inherent causal significance, and a i is the causal node weight. These weights are normalized such that a j + k i=1 a i = 1. The incorporation of the causal mixup enhances the robustness of the model against distributional shifts by embedding a richer causal structure within the environmental node. By adapting the causal structure to the environmental context, the Causal-Intervener aims to mitigate the disparity between training and test distributions, thus bolstering the model's generalizability. Finally, we aggregate the information, and the outputs of multiple attention heads are concatenated to form a more comprehensive representation:</p><formula xml:id="formula_8">H = x i âˆˆX Ïƒ x j âˆˆN (x i ) Î±x i ,x j x â€² j , M = H1 âŠ• â€¢ â€¢ â€¢ âŠ• Hh Wc,<label>(5)</label></formula><p>where W c is a learnable weight matrix, H is a attention head, M denotes the aggregated embeddings. It is important to highlight that the causal intervention result x â€² j on an environmental node x j with respect to x i is essentially a duplicate of x j and does not modify x j itself. This distinction is crucial as it guarantees that the process of augmenting central nodes within individual local structures remains mutually non-disruptive. By preserving the original state of x j , we ensure that enhancements applied to central nodes in one local structure do not adversely affect or interfere with those in another, maintaining the integrity and independence of local structural enhancements <ref type="bibr" target="#b22">[Wang et al., 2020]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Causal Support of CaT-GNN</head><p>In elucidating the causal backbone of CaT-GNN, we invoke causal theory to formulate a Structural Causal Model (SCM) as propounded by <ref type="bibr" target="#b18">[Pearl, 2009]</ref>. This framework scrutinizes four distinct elements: the inputs node attribute X, the truth label Y decided by both the attribute of causal nodes of X symbolized as C, and the confounder E, emblematic of the attribute of environment nodes. The causal interplay among these variables can be articulated as follows:</p><p>â€¢ C â† -X-â†’ E. The local structure of node attribute X is composed of causal nodes attributes C and environment nodes attributes E.</p><p>â€¢ C -â†’ Y â† -E. The causal attributes C actually determine the true value Y , however, the environmental attributes E also affect the prediction results, causing spurious associations. Do-calculus <ref type="bibr" target="#b18">[Pearl, 2009]</ref> is a trio of rules within the causal inference framework that facilitates the mathematical deduction of causal effects from observed data. These rules enable manipulation of do(â€¢) operator expressions, essential for implementing interventions in causal models:</p><formula xml:id="formula_9">P Y |do( Äˆ), E = P (Y | Äˆ), P Y |do( Äˆ), do(E) = P Y |do( Äˆ), E , P Äˆ|do(Y ) = P Äˆ|Y . (6)</formula><p>Typically, a model M Î¸ that is trained using Empirical Risk Minimization (ERM) may not perform adequately when generalizing to test data distribution P test . These shifts in distribution are often a result of changes within environment nodes, necessitating the need to tackle the confounding effects. As illustrated in Figure <ref type="figure" target="#fig_2">3</ref>, we apply causal intervention to enhance the model's generalizability and robustness. To this end, our approach utilizes do-calculus <ref type="bibr" target="#b18">[Pearl, 2009]</ref>   where N e signifies the count of environment nodes, with E i indicating the i-th environmental variable. The environmental enhancement of Cat-GNN is in alignment with the theory of backdoor adjustment, thereby allowing for an effective exploration of possible test environment distributions.</p><formula xml:id="formula_10">P Y |do( Äˆ) = Ne i P Y |do( Äˆ), E = Ei P E = Ei|do( Äˆ) = Ne i P Y |do( Äˆ), E = Ei P (E = Ei) = Ne i P Y | Äˆ, E = Ei)P (E = Ei),</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we critically assess the CaT-GNN model on a series of research questions (RQs) to establish its efficacy in graph-based fraud detection tasks. The research questions are formulated as follows:</p><p>â€¢ RQ1: Does CaT-GNN outperform the current state-of-theart models for graph-based anomaly detection?</p><p>â€¢ RQ2: What is the effectiveness of causal intervention in the aggregation of neighboring information?</p><p>â€¢ RQ3: What is the performance with respect to different environmental ratios r e ?</p><p>â€¢ RQ4: Is CaT-GNN equally effective in semi-supervised settings, and how does it perform with limited labeled data?</p><p>â€¢ RQ5: Does the causal intervention component lead to a significant decrease in efficiency?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>Datasets.</p><p>we adopt one open-source f inacial f raud semisupervised dataset <ref type="bibr" target="#b25">[Xiang et al., 2023]</ref>, termed S-FFSD 1 , with the partially labeled transaction records. Same with the definition in section 2, if a transaction is reported by a cardholder or identified by financial experts as fraudulent, the label y v will be 1; otherwise, y v will be 0. In addition, we also validate on two other public fraud detection datasets Yelpchi and Amazon. Yelpchi <ref type="bibr" target="#b19">[Rayana and Akoglu, 2015]</ref>  </p><formula xml:id="formula_11">a i = I i / k i=1 I i . â¿: CaT-GNN (FL).</formula><p>This variant uses a fixed number of environment nodes. Mixup weights are determined by a learnable linear layer. â¿:CaT-GNN (FI). Combining fixed environmental node selection with importancebased weighting for mixup. Reproducibility In our experiment, the learning rate l r is set to 0.003, and the batch size batch N batch is established at 256. Moreover, the input dropout ratio r dropout is determined to be 0.2, with the number of attention heads N head set to 4, and the hidden dimension d to 256. We employed the Adam optimizer to train the model over N epoch = 100 epochs, incorporating an early stopping mechanism to prevent overfitting. In GraphConsis, CARE-GNN, PC-GNN and GTAN, we used the default parameters suggested by the original paper. In Semi-GNN and Player2Vec, We set the learning rate to 0.01. In YelpChi and Amazon datasets, the train, validation, and test ratio are set to be 40%, 20%, and 40% respectively. In the S-FFSD dataset, we use the first 7 months' transactions as training data, and the rest as test data. Similar to previous work <ref type="bibr" target="#b15">[Liu et al., 2021]</ref>, we repeat experiments with different random seeds 5 times and we report the average and standard error. Experimental results are statistically significant with p &lt; 0.05. Cat-GNN and other baselines are all implemented in Pytorch 1.9.0 with Python 3.8. All the experiments are conducted on Ubuntu 18.04.5 LTS server with 1 NVIDIA Tesla V100 GPU, 440 GB RAM. Metrics. We selected three representative and extensively utilized metrics: AUC (Area Under the ROC Curve), F1macro and AP (averaged precision). The first metric AUC is the area under the ROC Curve and as a single numerical value, AUC succinctly summarizes the classifier's overall performance across all thresholds. The second metric F1macro is the macro average of F1 score which can be formulated as</p><formula xml:id="formula_12">F 1 macro = 1/(l l i=1<label>2Ã—PiÃ—Ri</label></formula><p>Pi+Ri ), and the third metric AP is averaged precision that can be formulated as AP = l i=1 (R i -R i-1 )P i , where P i stands for the Precision and R i stands for recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Comparison (RQ1)</head><p>In the experiment of credit card fraud detection across three distinct datasets, Cat-GNN showcases superior performance metrics compared to its counterparts. First of all, Cat-GNN achieves the highest AUC in all three datasets, .0207 GraphSAGE 0.5414Â±0.0029 0.4516Â±0.0954 0.1806Â±0.0866 0.7590Â±0.0053 0.5926Â±0.0087 0.6597Â±0.0079 0.6534Â±0.0095 0.5396Â±0.0101 0.3881Â±0.0089 GraphConsis 0.7046Â±0.0287 0.6023Â±0.0195 0.3269Â±0.0186 0.8761Â±0.0317 0.7725Â±0.0319 0.7296Â±0.0301 0.6554Â±0.0412 0.5436Â±0.0376 0.3816Â±0.0341 CARE-GNN 0.7745Â±0.0281 0.6252Â±0.0091 0.4238Â±0.0151 0.8998Â±0.0925 0.8468Â±0.0085 0.8117Â±0.0114 0.6589Â±0.1078 0.5725Â±0.0096 0.4004Â±0.0090 PC-GNN 0.7997Â±0.0021 0.6429Â±0.0205 0.4782Â±0.0194 0.9472Â±0.0019 0.8798Â±0.0084 0.8442Â±0.0096 0.6707Â±0.0031 0.6051Â±0.0230 0.4479Â±0.0210 GTAN 0.8675Â±0.0036 0.7254Â±0.0197 0.6425Â±0.0154 0.9580Â±0.0014 0.8954Â±0.0095 0.8718Â±0.0083 0.7496Â±0.0041 0.6714Â±0.0089 0.5709Â±0.0097</p><p>Cat-GNN(FI) 0.8721Â±0.0044 0.7336Â±0.0295 0.6528Â±0.0209 0.9643Â±0.0026 0.9011Â±0.0129 0.8794Â±0.0102 0.7643Â±0.0078 0.6907Â±0.0198 0.5925Â±0.0174 Cat-GNN(FL) 0.8910Â±0.0026 0.7692Â±0.0182 0.6687Â±0.0135 0.9705Â±0.0016 0.9125Â±0.0099 0.8942Â±0.0081 0.8023Â±0.0067 0.7031Â±0.0154 0.6145Â±0.0169 Cat-GNN(PI) 0.8895Â±0.0041 0.7706Â±0.0223 0.6701Â±0.0181 0.9669Â±0.0021 0.9077Â±0.0113 0.8896Â±0.0095 0.8145Â±0.0061 0.7096Â±0.0149 0.6294Â±0.0166 Cat-GNN(PL) 0.9035Â±0.0035 0.7783Â±0.0209 0.6863Â±0.0127 0.9706Â±0.0015 0.9163Â±0.0104 0.8975Â±0.0089 0.8281Â±0.0054 0.7211Â±0.0115 0.6457Â±0.0156</p><p>with values of 0.9035, 0.9706, and 0.8281 for YelpChi, Amazon, and S-FFSD, respectively. This indicates that Cat-GNN consistently outperforms other methods in distinguishing between classes across diverse datasets.</p><p>Focusing on the F1 Score, which balances the precision P i and recall R i , Cat-GNN again tops the charts with scores of 0.7783, 0.9163, and 0.7211 for YelpChi, Amazon, and S-FFSD. This reflects the model's robustness in achieving high precision while not compromising on recall, which is essential where both false positives and false negatives carry significant consequences. Finally, Cat-GNN's superiority extends to the AP metric, with the improvement of at least 6.82%, 2.86%, and 13.10% for YelpChi, Amazon and S-FFSD respectively.</p><p>The comparative performance of Cat-GNN is particularly significant when contrasted with previous methods such as Player2Vec, Semi-GNN, and GraphSAGE. For the Amazon dataset, existing state-of-the-art models, like CARE-GNN, PC-GNN, and GTAN, have already proven effective at capturing the inherent correlations within the data. In this context, the benefits of causal intervention may not be as pronounced, possibly due to the dataset's simpler local structures and more uniform distribution. However, for the S-FFSD dataset, our methodology exhibits significant performance improvements. This enhancement is attributed to the complex local structures and the prevalence of unlabeled nodes within the dataset. In such scenarios, causal intervention adeptly learns the inherent attribute connections, thereby boosting the model's generalization. Additionally, learning mixup weights with a linear layer is more reasonable than weighting with importance scores. Similarly, selecting environment nodes based on proportions is more sensible than choosing a fixed number of environment nodes, and the effect is also slightly better. All in all, This superior performance can be ascribed to the integration of causal theory within the Cat-GNN, enhancing its capacity to comprehend the inherent principles of graph attributes, allowing it to discern complex patterns and interactions that other models are unable to effectively capture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation Study (RQ2)</head><p>In this section, we evaluate the effectiveness of causal interventions in the aggregation within graph structures. Initially, we explore a variant without any causal intervention, termed N-CaT, which aggregates all neighboring information indiscriminately. Secondly, we introduce D-CaT, a method that omits environment nodes entirely during the aggregation phase, and directly aggregates all neighboring information in the learning process. Finally, our proposed method, CaT, integrates a causal intervention approach, simultaneously considering both causal nodes and environment nodes during aggregation to refine the learning representations.</p><p>The results shown in Figure <ref type="figure">4</ref> highlight the importance of causal intervention in information aggregation. N-CaT, which lacks causal discernment, performs worse across all datasets compared to CaT because it does not account for causal relationships. D-CaT, which simply deletes environmental factors, shows a significant drop in performance, as the mere deletion of environment nodes prevents the model from fully learning valuable information. Our CaT method consistently outperforms the other variants across all datasets, achieving the highest AUC scores. This superior performance underscores the value of our causal intervention technique, which effectively balances the influence of causal and environment nodes, resulting in a more generalizable model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Parameter Sensitivity Analysis (RQ3, RQ4)</head><p>In this section, we study the model parameter sensitivity with respect to the environment nodes ratio and the training ratio. The corresponding results are reported in Figure <ref type="figure">5</ref>.</p><p>As demonstrated in the left of Figure <ref type="figure">5</ref>, using the YelpChi dataset as an example, the performance of Cat-GNN (measured by AUC as the performance metric) significantly surpasses other competitive models, including PC-GNN and CARE-GNN, across all training ratios, from 10% to 70%. Particularly at lower training ratios (such as 10%), Cat-GNN remains effective for semi-supervised learning and exhibits more robust performance compared to other models.</p><p>In our sensitivity analysis of the environmental ratio as demonstrated in the right of Figure <ref type="figure">5</ref>, we observed that Cat-GNN's performance on the Amazon dataset is less affected by variations in the training ratio, with AUC fluctuations not exceeding 2%. Conversely, on the S-FFSD dataset, as the training ratio increases from 5% to 40%, there is a larger fluctuation in Cat-GNN's performance. This can be attributed to the characteristics of the dataset or the differences in the distribution of labeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Model Efficiency (RQ5)</head><p>In this section, we present a comprehensive analysis of the efficiency of CaT-GNN. Our causal intervention aims to boost performance while maintaining computational efficiency. Table <ref type="table" target="#tab_6">3</ref> shows that the performance enhancements are achieved without imposing significant additional computational costs.</p><p>The results indicate that the execution time with causal intervention experienced only a marginal increase. This negligible rise in time is a testament to the algorithm's ability to retain its computational efficiency while incorporating our advancements. Thus, our algorithm stands as a robust solution that can cater to the needs of high-performance computing while facilitating enhancements that do not compromise on efficiency. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Works</head><p>Graph Neural Network and its Variants. Graph neural networks have been widely used in structured data prediction <ref type="bibr" target="#b0">[Abadal et al., 2021;</ref><ref type="bibr" target="#b24">Wu et al., 2020;</ref><ref type="bibr" target="#b12">Jiang et al., 2024]</ref> by integrating graph structure and attribute. With the development of GNNs, there are several types of GNNs nowadays. 1): Recurrent Graph Neural Networks (RecGNNs) aim to learn node representations with recurrent neural architectures: <ref type="bibr" target="#b20">[Scarselli et al., 2008;</ref><ref type="bibr">Gallicchio and Micheli, 2010;</ref><ref type="bibr">Li et al., 2015;</ref><ref type="bibr" target="#b5">Dai et al., 2018]</ref>. 2): Convolutional Graph Neural Networks (ConvGNNs) generalize the operation of convolution from grid data to graph data: <ref type="bibr" target="#b13">[Li et al., 2018;</ref><ref type="bibr">Zhuang and Ma, 2018;</ref><ref type="bibr" target="#b26">Xu et al., 2018;</ref><ref type="bibr" target="#b4">Chiang et al., 2019]</ref>.</p><p>3): Spatial-Temporal Graph Neural Networks (STGNNs) aim to learn complex hidden patterns from spatial-temporal graphs: <ref type="bibr" target="#b26">[Yan et al., 2018;</ref><ref type="bibr" target="#b23">Wu et al., 2019;</ref><ref type="bibr" target="#b8">Guo et al., 2019;</ref><ref type="bibr" target="#b11">Jiang et al., 2023;</ref><ref type="bibr" target="#b13">Li et al., 2022]</ref>. Machine-learning based credit card fraud detection. Recently, numerous efforts have been dedicated to integrating machine learning methodologies into the research of credit card fraud detection. For instance, <ref type="bibr" target="#b17">[Maes et al., 2002]</ref> successfully applied Bayesian Belief Networks and MLP to the Europay International dataset. <ref type="bibr" target="#b20">[S Â¸ahin and Duman, 2011]</ref> utilized decision trees and support vector machines on data from a major national bank. <ref type="bibr" target="#b7">[Fu et al., 2016]</ref> demonstrates that convolutional neural networks outperform traditional approaches in pattern recognition for higher accuracy. However, their models were limited as they only considered individual transactions or cardholders, missing out on the potential of unlabeled data in real-world transactions <ref type="bibr" target="#b25">[Xiang et al., 2023]</ref>. GNN-based credit card fraud detection. More recently, the focus has shifted towards graph-based approaches as the use of graph convolutional networks on datasets with partial labels has been effective for predicting node attributes within citation networks so that many GNN-based fraud detectors have been proposed to detect fraud <ref type="bibr" target="#b21">[Wang et al., 2019;</ref><ref type="bibr">Liu et al., 2018]</ref>. Concretely, <ref type="bibr">[Dou et al., 2020]</ref> introduces CARE-GNN for fraud detection on relational graphs, while <ref type="bibr" target="#b15">[Liu et al., 2021]</ref> develops PC-GNN for managing imbalanced learning on graphs. Additionally, <ref type="bibr" target="#b6">[Fiore et al., 2019]</ref> presents a generative adversarial network to enhance classification capabilities. <ref type="bibr" target="#b3">[Cheng et al., 2020]</ref> suggested a joint feature learning model, concentrating on spatial and temporal patterns. However, these methods often lack the capability to uncover the causal nature of each specific case and are easily influenced by the surrounding neighbors due to the aggregation mechanism inherent in GNNs. Towards this end, we take the first step to propose a structural causal GNN model, which introduces causal intervention and data augmentation mechanism into the aggregation process of GNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion &amp; Future Work</head><p>In this work, we introduce the Causal Temporal Graph Neural Network (CaT-GNN), a causal approach in the domain of credit card fraud detection. Our model innovates by integrating causal learning principles to discern and leverage the intricate relationships within transaction data. We validate the effectiveness of CaT-GNN through comprehensive experiments on diverse datasets, where it consistently outperforms existing techniques. Notably, CaT-GNN not only enhances detection accuracy but also maintains computational efficiency, making it viable for large-scale deployment. Future directions will explore extending this methodology to a broader range of fraudulent activities, with the aim of fortifying the integrity of financial systems globally.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The model overview. First Stage (discovery): we utilize an attention map in the attention temporal network to identify causal nodes and environment nodes. Second Stage: Intervention, we apply causal mix-up enhancement to the environment nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Motivation. The original prediction incorrectly identifies a fraudster (central node labeled xi) as benign, as does the state-ofthe-art GTAN model. Following our causal intervention, the prediction is correctly adjusted to identify xi as a fraudster. Green: benign users, red: fraudsters, gray: unlabeled nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The depiction of the proposed model's architecture, featuring a causal temporal graph attention mechanism, alongside the theoretical support for backdoor adjustment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>on the variable C to negate the influence of the backdoor path E â†’ Y by estimating P Y |do( Äˆ) = P m (Y | Äˆ):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: The ablation study results on three datasets. Gray bars represent the D-CaT variant, blue bars represent the N-CaT variant, and orange bars represent the CaT-GNN model.</figDesc><graphic coords="7,74.90,42.06,139.56,104.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>represents the set of nodes, with N = |V| indicates the total number of nodes. X âˆˆ R N Ã—d denotes the node features with x i âˆˆ R d as its entry for node v i , d is the feature dimension. Each node v i is assigned a label y i âˆˆ Y, which is a binary variable with the value in {0, 1}.E = {E 1 , â€¢ â€¢ â€¢ , E R }signifies the set of edges, partitioned into R distinct types of relations.</figDesc><table><row><cell>Definition 2. (Graph-based Fraud Detection) The graph-</cell></row><row><cell>based fraud detection problem is defined on the multi-</cell></row><row><cell>relation graph G = (V, E, X , Y). For such a problem,</cell></row><row><cell>each node v i represents the target entity such as a trans-</cell></row><row><cell>action record, and has a label y i âˆˆ Y , where y i = 0</cell></row><row><cell>represents benign and y i = 1 represents fraud. The ob-</cell></row><row><cell>jective of graph-based fraud detection is to identify fraud</cell></row><row><cell>nodes that stand out distinctly from the non-fraudulent, or</cell></row><row><cell>benign, nodes within a multi-relational graph G. This task</cell></row><row><cell>is effectively approached as a binary classification prob-</cell></row><row><cell>lem focused on nodes within the graph G. And the sur-</cell></row><row><cell>prised Binary Cross-Entropy Loss function is: min</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>CT-GAT CT-GAT CT-GAT MLP + + + CT-GAT: Causal Temporal GAT Block Input Graph ğ‘®</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Embedding</cell><cell></cell><cell></cell></row><row><cell>Attention Score</cell><cell>ğ›¼ ğ‘¥ ğ‘– , ğ‘¥ ğ‘—</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğ‘¥ ğ‘–</cell><cell></cell><cell></cell><cell>ğ‘ ğ‘¥ ğ‘–</cell><cell>ğ‘¥ ğ‘—</cell><cell>ğ‘¥ ğ‘–</cell><cell>ğ‘¥ ğ‘—</cell></row><row><cell></cell><cell>ğ¼ ğ‘— =</cell><cell>ğ›¼ ğ‘¥ğ‘–,ğ‘¥ ğ‘—</cell><cell>àµ—</cell><cell>ğ›¼ ğ‘¥ ğ‘– ,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>ğ‘—=1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>ğ‘¥ ğ‘— Causal Inspector Skip-connection Causal Intervener</head><label></label><figDesc></figDesc><table><row><cell>Iterative</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Stacking</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Theoretical support</cell></row><row><cell>ğ‘¥ ğ‘—</cell><cell>ğ‘¥ ğ‘– ğ‘¥ ğ‘—</cell><cell>ğ‘˜</cell><cell>ğ‘¥ ğ‘— â€²</cell><cell>ğ‘¥ ğ‘— â€²</cell><cell>ğ‘¥ ğ‘–</cell></row><row><cell></cell><cell>ğ‘¥ ğ‘— â€² = ğ‘ ğ‘— ğ‘¥ ğ‘— +</cell><cell></cell><cell>ğ‘ ğ‘– ğ‘¥ ğ‘ğ‘–</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>ğ‘–=1</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the three datasets.</figDesc><table><row><cell>Dataset</cell><cell>#Node</cell><cell>#Edge</cell><cell cols="2">#Fraud #benigh</cell></row><row><cell>YelpChi</cell><cell>45,954</cell><cell>7,739,912</cell><cell>6,677</cell><cell>39,277</cell></row><row><cell>Amazon</cell><cell>11,948</cell><cell>8,808,728</cell><cell>821</cell><cell>11,127</cell></row><row><cell cols="3">S-FFSD 130,840 3,492,226</cell><cell>2,950</cell><cell>17,553</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>The inductive graph learning model is based on a fixed sample number of the neighbor nodes<ref type="bibr" target="#b8">[Hamilton et al., 2017]</ref>. âº CARE-GNN The camouflage-resistant GNN-based model tackling fraud detection[Dou et al., 2020]. â» PC-GNN. A GNN-based model to address the issue of class imbalance in graph-based fraud detection<ref type="bibr" target="#b15">[Liu et al., 2021]</ref>. â¼ GTAN. A semi-supervised GNN-based model that utilizes a gated temporal attention mechanism to analyze credit card transaction data<ref type="bibr" target="#b25">[Xiang et al., 2023]</ref>. â½: CaT-GNN (PL). This variant of the CaT-GNN framework selects environment nodes based on a proportion r e and determines mixup weights a i via a learnable linear layer. â¾: CaT-GNN (PI). This version employs a proportional selection of environment nodes and leverages the nodes' importance scores to inform mixup weights</figDesc><table><row><cell>com-</cell></row><row><cell>piles a collection of hotel and restaurant reviews from Yelp,</cell></row><row><cell>in which nodes represent reviews. And there are three kinds</cell></row><row><cell>of relationship edges among these reviews. Amazon: The</cell></row><row><cell>Amazon graph [McAuley and Leskovec, 2013] comprises re-</cell></row><row><cell>views of products in the musical instruments category, in</cell></row><row><cell>which nodes represent users, and the edges are the corre-</cell></row><row><cell>sponding three kinds of relationships among reviews. The</cell></row><row><cell>statistics of the above three datasets are shown in Table 1.</cell></row><row><cell>Baselines. To verify the effectiveness of our proposed CaT-</cell></row><row><cell>GNN, we compare it with the following state-of-the-art meth-</cell></row><row><cell>ods. â¶ Player2Vec. Attributed Heterogeneous Information</cell></row><row><cell>Network Embedding Framework [Zhang et al., 2019]. â·</cell></row><row><cell>Semi-GNN. A semi-supervised graph attentive network for fi-</cell></row><row><cell>nancial fraud detection that adopts the attention mechanism</cell></row></table><note><p><p><p><p><p>to aggregate node embed dings across graphs</p><ref type="bibr" target="#b21">[Wang et al., 2019]</ref></p>. â¸ GraphConsis. The GNN-based fraud detectors aim 1 https://github.com/AI4Risk/antifraud at the inconsistency problem</p><ref type="bibr" target="#b14">[Liu et al., 2020]</ref></p>. â¹ Graph-SAGE.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Performance Comparison (in percent Â± standard deviation) on YelpChi, Amazon and S-FFSD datasets across five runs. The best performances are marked with bold font, and the second-to-best are shown underlined.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>YelpChi</cell><cell></cell><cell></cell><cell>Amazon</cell><cell></cell><cell></cell><cell>S-FFSD</cell><cell></cell></row><row><cell>Metric</cell><cell>AUC</cell><cell>F1</cell><cell>AP</cell><cell>AUC</cell><cell>F1</cell><cell>AP</cell><cell>AUC</cell><cell>F1</cell><cell>AP</cell></row><row><cell>Player2Vec</cell><cell cols="9">0.7012Â±0.0089 0.4120Â±0.0142 0.2477Â±0.0161 0.6187Â±0.0152 0.2455Â±0.0091 0.1301Â±0.0117 0.5284Â±0.0101 0.2149Â±0.0136 0.2067Â±0.0155</cell></row><row><cell>Semi-GNN</cell><cell cols="9">0.5160Â±0.0154 0.1023Â±0.0216 0.1809Â±0.0205 0.7059Â±0.0211 0.5486Â±0.0105 0.2248Â±0.0142 0.5460Â±0.0125 0.4393Â±0.0152 0.2732Â±0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Experimental run times with and without causal intervention on three datasets. The experiments were conducted on a Tesla V100 40GB GPU, with the execution times measured in seconds.</figDesc><table><row><cell>Dataset</cell><cell>YelpChi</cell><cell>Amazon</cell><cell>S-FFSD</cell></row><row><cell>No-intervention</cell><cell>126.676</cell><cell>110.518</cell><cell>208.085</cell></row><row><cell cols="4">Causal-intervention 129.481 (+2.21%) 113.660 (+2.84%) 213.341 (+2.52%)</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Aleksiejuk and HoÅ‚yst, 2001] Agata Aleksiejuk and Janusz A HoÅ‚yst. A simple model of bank bankruptcies</title>
		<author>
			<persName><surname>Abadal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSRN 3472409</title>
		<imprint>
			<date type="published" when="2001">2021. 2021. 2001. 2019</date>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="198" to="204" />
		</imprint>
	</monogr>
	<note>AlFalahi and Nobanee, 2019] Latifa AlFalahi and Haitham Nobanee</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Data mining for credit card fraud: A comparative study</title>
		<author>
			<persName><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision support systems</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="602" to="613" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Invariant rationalization</title>
		<author>
			<persName><forename type="first">Chang</forename></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1448" to="1458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Graph neural network for fraud detection via spatial-temporal attention</title>
		<author>
			<persName><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3800" to="3813" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks</title>
		<author>
			<persName><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining</title>
		<meeting>the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="257" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enhancing graph neural network-based fraud detectors against camouflaged fraudsters</title>
		<author>
			<persName><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM international conference on information &amp; knowledge management</title>
		<meeting>the 29th ACM international conference on information &amp; knowledge management</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018. 2020</date>
			<biblScope unit="page" from="315" to="324" />
		</imprint>
	</monogr>
	<note>International conference on machine learning</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using generative adversarial networks for improving classification effectiveness in credit card fraud detection</title>
		<author>
			<persName><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">Alfredo</forename><forename type="middle">De</forename><surname>Fiore</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Francesca</forename><surname>Santis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paolo</forename><surname>Perla</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Francesco</forename><surname>Zanetti</surname></persName>
		</editor>
		<editor>
			<persName><surname>Palmieri</surname></persName>
		</editor>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2021. 2021. 2019. 2019</date>
			<biblScope unit="volume">479</biblScope>
			<biblScope unit="page" from="448" to="455" />
		</imprint>
	</monogr>
	<note>Qifan Wang, and Tat-Seng Chua. Should graph convolution trust neighbors? a simple causal inference method</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Gallicchio and Micheli, 2010] Claudio Gallicchio and Alessio Micheli. Graph echo state networks</title>
		<author>
			<persName><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2010 international joint conference on neural networks (IJCNN)</title>
		<meeting><address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2016. 2016. October 16-21, 2016. 2016. 2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>Neural Information Processing: 23rd International Conference</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Attention based spatialtemporal graph convolutional networks for traffic flow forecasting</title>
		<author>
			<persName><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2019. 2019. 2017. 2017</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="922" to="929" />
		</imprint>
	</monogr>
	<note>Inductive representation learning on large graphs. Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Open graph benchmark: Datasets for machine learning on graphs. Advances in neural information processing systems</title>
		<author>
			<persName><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="22118" to="22133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Meng Jiang, Peng Cui, and Christos Faloutsos. Suspicious behavior detection: Current trends and future directions</title>
		<author>
			<persName><surname>Ileberi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE intelligent systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="39" />
			<date type="published" when="2016">2022. 2022. 2016. 2016</date>
		</imprint>
	</monogr>
	<note>Journal of Big Data</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Uncertainty quantification via spatial-temporal tweedie model for zero-inflated and long-tail travel demand prediction</title>
		<author>
			<persName><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Incomplete graph learning via attributestructure decoupled variational auto-encoder</title>
		<author>
			<persName><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05493</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<editor>
			<persName><surname>Li</surname></persName>
		</editor>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2015">2024. 2024. 2015. 2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Gated graph sequence neural networks</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mining spatio-temporal relations via self-paced graph contrastive learning</title>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM international conference on information and knowledge management</title>
		<meeting>the 27th ACM international conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2018">2022. 2022. 2018. 2018</date>
			<biblScope unit="page" from="2077" to="2085" />
		</imprint>
	</monogr>
	<note>SIGKDD</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Alleviating the inconsistency problem of applying graph neural network to fraud detection</title>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval</title>
		<meeting>the 43rd international ACM SIGIR conference on research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1569" to="1572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pick and choose: a gnn-based imbalanced learning approach for fraud detection</title>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the web conference 2021</title>
		<meeting>the web conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="3168" to="3177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards robust and adaptive motion forecasting: A causal representation perspective</title>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern</meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="page" from="17081" to="17092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews</title>
		<author>
			<persName><surname>Maes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on World Wide Web</title>
		<meeting>the 22nd international conference on World Wide Web<address><addrLine>Mackenzie</addrLine></address></meeting>
		<imprint>
			<publisher>Judea Pearl and Dana Mackenzie</publisher>
			<date type="published" when="2002">2002. 2002. 2013. 2013. 2018. 2018</date>
			<biblScope unit="volume">261</biblScope>
			<biblScope unit="page" from="897" to="908" />
		</imprint>
		<respStmt>
			<orgName>McAuley and Leskovec</orgName>
		</respStmt>
	</monogr>
	<note>In Proceedings of the 1st international naiso congress on neuro fuzzy technologies. The book of why: the new science of cause and effect. Basic books</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
			<publisher>Judea Pearl. Causality. Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Collective opinion spam detection: Bridging review networks and metadata</title>
		<author>
			<persName><forename type="first">Akoglu</forename><surname>Rayana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th acm sigkdd international conference on knowledge discovery and data mining</title>
		<meeting>the 21th acm sigkdd international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="985" to="994" />
		</imprint>
	</monogr>
	<note>Shebuti Rayana and Leman Akoglu</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Masked label prediction: Unified message passing model for semi-supervised classification</title>
		<author>
			<persName><forename type="first">Ekrem</forename><surname>Duman ; Yusuf G S Â¸ahin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Duman</surname></persName>
		</author>
		<author>
			<persName><surname>Scarselli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03509</idno>
		<idno>arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2008">2011. 2011. 2008. 2008. 2020. 2017. 2017</date>
			<publisher>Adriana Romero, Pietro Lio, and Yoshua Bengio</publisher>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="61" to="80" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Detecting credit card fraud by decision trees and support vector machines. Graph attention networks</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A semi-supervised graph attentive network for financial fraud detection</title>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="598" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nodeaug: Semi-supervised node classification with data augmentation</title>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="207" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Graph wavenet for deep spatial-temporal graph modeling</title>
		<author>
			<persName><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.00121</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semi-supervised credit card fraud detection via attribute-driven graph representation</title>
		<author>
			<persName><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 31st ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022. 2023</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="14557" to="14565" />
		</imprint>
	</monogr>
	<note>Proceedings of the AAAI Conference on Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Key player identification in underground forums over attributed heterogeneous information network embedding framework</title>
		<author>
			<persName><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00826</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM international conference on information and knowledge management</title>
		<meeting>the 28th ACM international conference on information and knowledge management<address><addrLine>Ma</addrLine></address></meeting>
		<imprint>
			<publisher>Chenyi Zhuang and Qiang Ma</publisher>
			<date type="published" when="2018">2018. 2018. 2018. 2018. 2019. 2019. 2018. 2018</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="499" to="508" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Proceedings of the 2018 world wide web conference</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
