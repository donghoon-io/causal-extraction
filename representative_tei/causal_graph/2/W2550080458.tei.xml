<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Achieving Non-Discrimination in Data Release</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2016-11-22">22 Nov 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Computer Engineering</orgName>
								<orgName type="institution">University of Arkansas</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongkai</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Computer Engineering</orgName>
								<orgName type="institution">University of Arkansas</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xintao</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Computer Engineering</orgName>
								<orgName type="institution">University of Arkansas</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Achieving Non-Discrimination in Data Release</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-11-22">22 Nov 2016</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1611.07438v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Discrimination discovery and prevention/removal are increasingly important tasks in data mining. Discrimination discovery aims to unveil discriminatory practices on the protected attribute (e.g., gender) by analyzing the dataset of historical decision records, and discrimination prevention aims to remove discrimination by modifying the biased data before conducting predictive analysis. In this paper, we show that the key to discrimination discovery and prevention is to find the meaningful partitions that can be used to provide quantitative evidences for the judgment of discrimination. With the support of the causal graph, we present a graphical condition for identifying a meaningful partition. Based on that, we develop a simple criterion for the claim of non-discrimination, and propose discrimination removal algorithms which accurately remove discrimination while retaining good data utility. Experiments using real datasets show the effectiveness of our approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Discrimination discovery and prevention/removal has been an active research area recently <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b7">8]</ref>. Discrimination discovery is the data mining problem of unveiling evidence of discriminatory practices by analyzing the dataset of historical decision records, and discrimination prevention aims to ensure non-discrimination by modifying the biased data before conducting predictive analysis (e.g., building classifiers). Discrimination refers to unjustified distinctions of individuals based on their membership in a certain group. Federal Laws and regulations (e.g., Fair Credit Reporting Act or Equal Credit Opportunity Act) prohibit discrimination on several grounds, such as gender, age, marital status, sexual orientation, race, religion or belief, and disability or illness, which are referred to as the protected attributes. Different types of discrimination have been introduced, which can be generally categorized as direct and indirect discrimination <ref type="bibr" target="#b7">[8]</ref>. Direct discrimination occurs when individuals are treated less favorably in comparable situations explicitly due to their membership in a protected group; indirect discrimination refers to an apparently neutral practice which results in an unfair treatment of a protected group <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b23">24]</ref>. In this paper, we focus on the problem of discrimination discovery and prevention on direct discrimination. In the following, we simply say discrimination for direct discrimination.  For a quantitative measurement of discrimination, a general legal principle is to measure the difference in the proportion of positive decisions between the protected group and non-protected group <ref type="bibr" target="#b23">[24]</ref>. Discovering and preventing discrimination is not trivial. As shown by Žliobaitė et al. <ref type="bibr" target="#b27">[28]</ref>, simply considering the difference measured in the whole population fails to take into account the part of differences that are explainable by other attributes, and removing all the differences will result in reverse discrimination. They proposed to partition the data by conditioning on a certain attribute, and remove the difference within each produced subpopulation. Their method, although in the right direction, has two significant limitations: 1) it does not distinguish whether a partition is meaningful for measuring and removing discrimination; 2) it does not consider the situation where there exist multiple meaningful partitions.</p><p>Typically, given a population, a partition is determined by a subset of non-protected attributes and a subpopulation is specified by a value assignment to the attributes. In our study we find that, the key to answering whether a population contains discrimination is to finding the meaningful partitions that can be used to provide quantitative evidences for the judgment of discrimination. We have two observations. First, not all partitions are meaningful and using inappropriate partitions will result in misleading conclusions. For example, consider a toy model for a university admission system that contains four attributes: gender, major, test score, and admission, where gender is the pro-tected attribute, and admission is the decision. We assume there is no correlation between gender and test score. The summary statistics of the admission rate is shown in Table 1. It can be observed that the average admission rate is 37% for females and 46% for males. It is already known that the judgment of discrimination cannot be made simply based on the average admission rates in the whole population and further partitioning is needed. If we partition the data conditioning on test score as shown in the table, there exist significant differences (from either 35% -25% for L or from 65% -55% for H) between the admission rates of females and males in the two subpopulations. However, intuitively test score should not be used for partitioning the data alone as it is uncorrelated with the protected attribute. In fact, this result is indeed misleading, since if we carefully examine the admission rates for each major or each combination {major, test score}, it shows no bias in any of the subpopulations. Therefore, it would be groundless if if a plaintiff tries to file a lawsuit of discrimination against the university by demonstrating admission rate difference either in the whole population or based on the partitioning on test score.</p><p>Second, when there are multiple meaningful partitions, examining one partition showing no bias does not guarantee no bias based on other partitions. Consider a different example on the same toy model shown in Table <ref type="table" target="#tab_1">2</ref>. The average admission rate now becomes 43% equally for both females and males. Further conditioning on major still shows that females and males have the same chance to be admitted in the two subpopulations. However, when partitioning the data based on the combination {major, test score}, significant differences (≥ 5%) between the admission rates of females and males present. The difference among applicants applied to either a major with test scores of L is clear evidence of discrimination against females. The difference among applicants applied to either a major with test scores of H can be treated as reverse discrimination against males, or tokenism where some strong male applicants are purposefully rejected to refute a claim of discrimination against females. So, the data publisher cannot make a non-discrimination claim.</p><p>The above two examples show that, any quantitative evidence of discrimination must be measured under a meaningful partition. In addition, to ensure non-discrimination, we must show no bias for all meaningful partitions. In this paper, we make use of the causal graphs to identify meaningful partitions and develop discrimination discovery and removal algorithms. A causal graph is a probabilistic graph model widely used for causation representation, reasoning and inference <ref type="bibr" target="#b25">[26]</ref>. Our main results are: 1) a graphical condition for identifying a meaningful partition, which is defined by a subset of attributes referred to as the block set; 2) a simple criterion for the claim of non-discrimination; and 3) discrimination removal algorithms which achieve non-discrimination while maximizing the data utility. Our approaches can be used to find quantitative evidences of discrimination for plaintiffs, or to achieve a non-discrimination guarantee for data owners. The experiments using real datasets show that our proposed approaches are effective in discovering and removing discrimination.</p><p>The rest of the paper is organized as follows. Section 2 models discrimination and presents the graphical condition using the causal graph. Section 3 establishes the nondiscrimination criterion, develops the discrimination discovery mechanism, and proposes discrimination removal algorithms. Section 4 discusses a relaxed non-discrimination criterion. The experimental setup and results are discussed in Section 5. Section 6 summarizes the related work, and Section 7 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Modeling Discrimination Using Causal Graph</head><p>Consider a dataset D which may contain discrimination against a certain protected group. Each individual in D is specified by a set of attributes V, which includes the protected attribute (e.g., gender), the decision attribute (e.g., admission), and the non-protected attributes (e.g., major). Throughout this paper, we use an uppercase alphabet, e.g., X, to represent an attribute; a bold uppercase alphabet, e.g., X, to represent a subset of attributes, e.g., {gender, major}. We use a lowercase alphabet, e.g., x, to represent a domain value of attribute X; a bold lowercase alphabet, e.g., x, to represent a value assignment to X. We denote the decision attribute by E, associated with domain values of positive decision e + and negative decision e -; denote the protected attribute by C, associated with two domain values c -(e.g., female) and c + (e.g., male).</p><p>For the measurement of discrimination, we use risk difference <ref type="bibr" target="#b23">[24]</ref> to measure the difference in the the proportion of positive decisions between the protected group and nonprotected group. Formally, by assuming c -is the protected group, risk difference is defined as ∆P| s = Pr(e + |c + , s) -Pr(e + |c -, s), where s denotes a specified subpopulation produced by a partition S. We say that the protected group is treated less favorably within subpopulation s if ∆P| s ≥ τ, where τ &gt; 0 is a threshold for discrimination depending on law. For instance, the 1975 British legislation for sex discrimination sets τ = 0.05, namely a 5% difference. To avoid reverse discrimination, we do not specify which group is the protected group. Thus, we use |∆P| s | to deal with both scenarios where either c -or c + is designated as the protected group.</p><p>A DAG G is represented by a set of nodes and a set of arcs. Each node represents an attribute in D. Each arc, denoted by an arrow → in the graph, connects a pair of nodes where the node emanating the arrow is called the parent of the other node. The DAG is assumed to satisfy the Markov condition, i.e., each node X is independent of all its non-descendants conditioning on its parents Par(X). Each node is associated with a conditional probability table (CPT) specified by Pr(X|Par(X)). The joint probability distribution can be computed using the factorization formula <ref type="bibr" target="#b15">[16]</ref>:</p><formula xml:id="formula_0">(2.1) Pr(v) = X∈V Pr(x|Par(X)).</formula><p>Spirtes et al. <ref type="bibr" target="#b25">[26]</ref> have shown that, when causal interpretations are given to the DAG, i.e., each node's parents are this node's direct causes, the DAG represents a correct causal structure of the underlying data. In particular, the causation among the attributes are encoded in the missing arcs in the DAG: if there is no arc between two nodes in G, then it guarantees no direct causal effect between the two attributes in D.</p><p>The DAG with the causal interpretation is called the causal graph.</p><p>In this paper, we assume that we have a causal graph G that correctly represents the causal structure of the dataset. We also assume that the arc C → E is present in G, since the absence of the arc represents a zero direct effect of C on E. A causal DAG can be learned from data and domain knowledge. In the past decades, many algorithms have been proposed to learn causal DAGs, and they are proved to be quite successful <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b11">12]</ref>. In our implementation, we use the original PC algorithm <ref type="bibr" target="#b25">[26]</ref> to build the causal graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Identifying Meaningful Partition</head><p>Discrimination occurs due to difference decisions made explicitly based on the membership in the protected group. As stated in <ref type="bibr" target="#b8">[9]</ref>, all discrimination claims require plaintiffs to demonstrate the existence of a causal connection between the decision and the protected attribute. Given a partition S, for ∆P| s to capture the discriminatory effect and be considered as a quantitative evidence of discrimination, one needs to prove that this difference is directly caused by the protected attribute. In causal graphs, causal effects are carried by the paths that trace arrows pointing from the cause to the effect. Specially, the direct causal effect of C on E, if exists, is carried by the direct arc from C to E, i.e., C → E in the causal graph. In the following, we show that ∆P| s captures the direct causal effect of C on E if S satisfies certain requirements, which we refer to as the block set.</p><p>We use the graphical criterion d-separation. Consider a dataset D and its represented causal graph G. Nodes X and Y are said to be d-separated by a set of attributes Z in G, denoted by (X Y | Z) G , if following requirement is met: Definition 2.1. (d-Separation <ref type="bibr" target="#b25">[26]</ref>) Nodes X and Y are dseparated by Z if and only if Z blocks all paths from X to Y. A path p is said to be blocked by a set of nodes Z if and only if 1. p contains a chain i → m → j or a fork i ← m → j such that the middle node m is in Z, or 2. p contains an collider i → m ← j such that the middle node m is not in Z and no descendant of m is in Z.</p><p>Attributes X and Y are said to be conditionally independent given a set of attributes Z, denoted by (X Y | Z) D , if Pr(x|y, z) = Pr(x|z) holds for all values x, y, z. With the Markov condition, the d-separation criterion in G and the conditional independence relations in D are connected such that, if we have (X</p><formula xml:id="formula_1">Y | Z) G , then we must have (X Y | Z) D .</formula><p>We make use of the above connection to identify the direct causal effect of C on E. We construct a new DAG G by deleting the arc C → E from G and keeping everything else unchanged. Thus, the possible difference between the causal relationships represented by G and G lies merely in the presence of the direct causal effect of C on E. We consider a node set B such that (E C | S) G , then this conditional dependence between C and E given S that is not caused by the direct causal effect will also exist in ∆P| s . As a result, ∆P| s cannot accurately measure the direct causal effect.</p><formula xml:id="formula_2">C | B) G ,</formula><p>It must be noted that, for ∆P| b to correctly measure the direct causal effect, set B cannot contain any descendant of E even when it satisfies the requirement (E C | B) G . This is because when conditioning on E's descendants, part of the knowledge of E is already given since the consequences caused by E is known.</p><p>Based on the above analysis, we measure the direct causal effect of C on E using ∆P| b where the node set B satisfies the following requirements: <ref type="bibr" target="#b0">(1)</ref> </p><formula xml:id="formula_3">(C E | B) G holds;</formula><p>(2) B contains none of E's decedents. We call such set B a block set. By treating the direct causal effect of C one E as the effect of direct discrimination, ∆P| b is considered as a correct measure for direct discrimination if and only if B is a block set. Thus, if |∆P| b | ≥ τ, it is a quantitative evidence of discrimination against either c -or c + for subpopulation b. As can be seen, each block set B forms a meaningful partition on the dataset where the direct causal effect of C on E within each subpopulation b can be correctly measured by ∆P| b . On the other hand, for any partition that is not defined by a block set, the measured differences, which either contain spurious influences or have been explained by the consequences of the decisions, cannot accurately measure the direct causal effect and hence cannot be used to prove discrimination or non-discrimination. Therefore, we give the following theorem. The proof follows the above analysis. We use the illustrative examples in Section 1 to show how the criterion works. The causal graph of the examples is shown in Figure <ref type="figure" target="#fig_1">1</ref>. There are two block sets in this graph: {major}, and {major,test score}. Note that test score alone is not a block set. That is why conditioning on it will produce misleading results. For the example shown in Table <ref type="table" target="#tab_0">1</ref>, examining both block sets shows no discriminatory effect. Thus, non-discrimination can be claimed. For the example shown in Table <ref type="table" target="#tab_1">2</ref>, although examining {major} shows no discriminatory effect, when examining {major,test score} we observe |∆P| {math,B} | = 0.06, |∆P| {math,A} | = 0.10, |∆P| {biology,B} | = 0.05, and |∆P| {biology,A} | = 0.10. Thus, the evidences of discrimination for four subpopulations are identified.</p><p>Although Theorem 3.1 provides a clear criterion for non-discrimination, it requires examining each subpopulation of each block set. A brute force algorithm may have an exponential complexity. Instead of examining all block sets, the following theorem shows that we only need to examine one node set Q, which is the set of all E's parents except C, i.e., Q = Par(E)\{C}. Theorem 3.2. Non-discrimination is claimed if and only if inequality |∆P| q | &lt; τ holds for each value assignment q of set Q where Q = Par(E)\{C}.</p><p>Proof. We first give two lemmas and their proofs are given Appendices A and B. </p><formula xml:id="formula_4">∆P| b = Q Pr(q |b) • ∆P| q ,</formula><p>where q goes through all the possible combinations of the values of non-overlapping attributes Q = Q\B. For overlapping attributes Q ∩ B, q and b have the same values. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Discrimination Discovery</head><p>We present the nondiscrimination certifying algorithm based on Theorem 3.2. The algorithm first finds set Q in the graph. Then, the algorithm computes |∆P| q | = | Pr(e + |c + , q) -Pr(e + |c -, q)| for each subpopulation q, and makes the judgment of nondiscrimination based on the criterion. The procedure of the algorithm is shown in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Certifying of Non-Discrimination (Certify)</head><formula xml:id="formula_5">Input: dataset D, protected attribute C, decision E, user-defined parameter τ Output: judgment of non-discrimination judge, parents of E ex- cept C Q 1: Q = f indParent(E)\{C} 2:</formula><p>for all value assignment q of Q do 3:</p><formula xml:id="formula_6">|∆P| q | = | Pr(e + |c + , q) -Pr(e + |c -, q)| 4: if |∆P| q | ≥ τ then 5: return [ f alse, Q] 6: end if 7: end for 8: return [true, Q]</formula><p>The complexity from Line 2 to 8 is O(|Q|), where |Q| is the number of value assignments of Q. The function f indParent(E) (Line 1) finds the parents of E in a causal graph. A straightforward way is to first build a causal graph from the dataset using a structure learning algorithm (e.g., the classic PC algorithm), then find the parents of E in the graph. The complexity of the PC algorithm is bounded by the largest degree in the undirected graph. In the worst case, the number of conditional independence tests required by the algorithm is bounded by n 2 (n-1) k-1</p><formula xml:id="formula_7">(k-1)!</formula><p>where k is the maximal degree of any vertex and n is the number of vertices. However, in our algorithm we only need to identify the parents of E without the need of building the complete network. Thus, we can use local causal discovery algorithms such as the Markov blanket <ref type="bibr" target="#b26">[27]</ref> to determine the local structure for the decision attribute E. We leave this part as our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Discrimination Removal</head><p>When non-discrimination is not claimed, the discriminatory effects need to be removed by modifying the data before it is used for predictive analysis (e.g., building a discrimination-free classifier). Since the modification makes the data distorted, it may cause losses in data utility when compared with the original data. Thus, a general requirement in discrimination removal is to maximize the utility of the modified data while achieving nondiscrimination. A naive approach such as used in <ref type="bibr" target="#b7">[8]</ref> would be totally removing the protected attribute from the dataset to eliminates discrimination. However, as we shall show in the experiments, in this way the data utility would be greatly suffered. In this section, we propose two strategies that exactly remove discrimination while retaining good data utility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Discrimination Removal by Modifying Causal</head><p>Graph The first strategy modifies the constructed causal graph and uses it to generate a new dataset. Specifically, it modifies the CPT of E, i.e., Pr(e|c, q), to obtain a new CPT Pr (e|c, q), to meet the non-discrimination criterion given by Theorem 3.2, i.e., |Pr (e + |c + , q) -Pr (e + |c -, q)| &lt; τ for all subpopulations q. The CPTs of all the other nodes are kept unchanged. The joint distribution of the causal graph after the modification can be calculated using the factorization formula (2.1). After that, the algorithm generates a new dataset based on the modified joint distribution. Since the structure of the causal graph is not changed after the modification, Q is still the parent set of E excluding C. Thus, according to Theorem 3.2, the newly generated dataset satisfies the nondiscrimination criterion.</p><p>To achieve a good data utility, we minimize the difference between the original distribution (denoted by P) and the modified distribution (denoted by P ). We use the Euclidean distance, i.e., d(P , P) = V (Pr (v) -Pr(v)) 2 , to measure the distance between the two distributions. We sort the nodes according to the topological ordering of the graph, and represent the sorted nodes as {C, X, E, Y}. Note that we must have Q ⊆ X. Then, using the factorization formula (2.1), d(P , P) can be formulated as</p><formula xml:id="formula_8">d(P , P) = C,Q,E β c,e</formula><p>q • Pr (e|c, q) -Pr(e|c, q) 2 , where β c,e q =</p><p>x ,y Pr(c) Pr(x|c) Pr(y|c, x, e) 2 and X = X\Q. Thus, the optimal solution (denoted by Pr * (e|c, q)) that minimizes d(P , P) can be obtained by solving the following quadratic programming problem. minimize</p><formula xml:id="formula_9">C,Q,E β c,e</formula><p>q • Pr (e|c, q) -Pr(e|c, q) 2 subject to ∀q, |Pr (e + |c + , q) -Pr (e + |c -, q)| &lt; τ, ∀c, q, Pr (e -|c, q) + Pr (e + |c, q) = 1, ∀c, q, e, Pr (e|c, q) &gt; 0.</p><p>The procedure of the algorithm is shown in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Removal by Modifying Graph (MGraph)</head><p>Input: dataset D, protected attribute C, decision E, user-defined parameter τ Output:</p><formula xml:id="formula_10">modeified dataset D * 1: [ judge, Q] = Certi f y(D, C, E, τ) 2: if judge == true then 3: D * = D 4: else 5:</formula><p>Calculate the modified CPT of E: Pr * (e|c, q) 6:</p><p>for all X ∈ V\{E} do The complexity of Algorithm 2 depends on the complexity of building the causal graph and solving the quadratic programming. The complexity of building a causal graph has been discussed in Section 3.2. Note that since deriving the objective function needs information of the whole network, local causal discovery cannot be used to improve the algorithm. For the quadratic programming, it can be easily shown that, the coefficients of the quadratic terms in the objective function form a positive definite matrix. According to <ref type="bibr" target="#b16">[17]</ref>, the quadratic programming can be solved in polynomial time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Discrimination Removal by Modifying Dataset</head><p>The second strategy directly modifies the decisions of selected tuples from the dataset to meet the non-discrimination criterion. For each value assignment q, if ∆P| q ≥ τ, we randomly select a number of tuples with C = c -and E = e -, and change their E values from e -to e + . If ∆P| q ≤ -τ, we select tuples similarly and change their E values from e + to e -. As result, we ensure that for each q we have |∆P| q | ≤ τ.</p><p>For any E's non-decedent X, according to the Markov condition, X is independent of E in each subpopulation specified by E's parents, i.e., C and Q. Since the modified tuples are randomly selected in the subpopulation specified by C and Q, X would still be independent of E after the modification. Thus, all E's non-decedents would be conditionally independent of E given C and Q, implying that Q is still the parent set of E excluding C after the modification. According to Theorem 3.2, the modified dataset satisfies the non-discrimination criterion. positive decision (e + ) negative decision (e -) total protected group (c -)</p><formula xml:id="formula_11">n c -e + q n c -e - q n c - q non-protected group (c + ) n c + e + q n c + e - q n c + q total n e + q n e - q n q</formula><p>To calculate the number of tuples to be modified within each subpopulation q, we express ∆P| q as n c + e + q /n c + qn c -e + q /n c - q . Please refer to Table <ref type="table" target="#tab_2">3</ref> for the meaning of the notations. For subpopulations with ∆P| q ≥ τ, by selecting n c - q • (|∆P| q | -τ) tuples with C = c -and E = e -, and changing their E values from e -to e + , the value of ∆P| q would decrease by n c - q • (|∆P| q | -τ) /n c - q ≥ ∆P| q -τ. Therefore, we have ∆P| q &lt; τ after the modification. The result is similar when ∆P| q ≤ -τ. The pseudo-code of the algorithm is shown in Algorithm 3. for all value assignment q of Q do</p><formula xml:id="formula_12">6: if ∆P| q &gt; τ then 7:</formula><p>randomly select a set T of n c - q •(|∆P| q |-τ) tuples with C = c -and E = e -in subpopulation q, and change the values of Es from e -to e + to get the set T * of the modified tuples 8:</p><p>else if ∆P| q &lt; -τ then The complexity of Algorithm 3 includes the complexity of finding Q. Similar to Algorithm 1, we can identify E's parents without building the whole network. Therefore, local discovery algorithms can be employed to improve the efficiency of algorithm. The complexity from Line 5 to 14 is bounded by the size of the original dataset, i.e., O(|D|). In this section, we propose a relaxed α-nondiscrimination criterion which may perform better under the context of randomness and small samples by finding statistical evidences. Formally, for a given block set B, we treat ∆P| B as a variable and treat the values of ∆P| b s observed across all subpopulations as samples. We introduce a userdefined parameter, α (0 &lt; α &lt; 1), to indicate a threshold for the probability of One challenge here is that we do not know the exact distribution of ∆P| B for estimating Pr(|∆P| B | &lt; τ) accurately. We propose to employ the Chebyshev's inequality <ref type="bibr" target="#b0">[1]</ref>, which provides a lower bound of the probability for the value of a random variable lying within a given region, using its mean and variance. Note that the Chebyshev's inequality holds for any random variable irrespective of its distribution. The general form of the Chebyshev's inequality is given as follows.</p><formula xml:id="formula_13">|∆P| B | &lt; τ. If | Pr(∆P| B | &lt; τ) ≥ α,</formula><p>Theorem 4.1. (Chebyshev's inequality) Let X be a random variable with finite expected value µ and finite non-zero variance σ 2 . Then for any real numbers a &lt; b,</p><formula xml:id="formula_14">Pr(a &lt; X &lt; b) ≥ 1 - σ 2 + (µ -b+a 2 ) 2 ( b-a 2 ) 2</formula><p>.</p><p>The following theorem shows a sufficient condition to satisfy Definition 4.1 using the Chebyshev's inequality. Theorem 4.2. Given α, α-non-discrimination is claimed if the following inequality holds for each block set B:</p><formula xml:id="formula_15">1 - σ 2 B + µ 2 B τ 2 ≥ α,</formula><p>where µ B and σ 2 B are mean and variance of ∆P| B .</p><p>The proof is straightforward by replacing X with ∆P| B , a with -τ, and b with τ in the Chebyshev's inequality. We show Theorem 4.2 can be achieved by examining Q only.</p><p>Theorem 4.3. Given α, α-non-discrimination is claimed if the following inequalities holds for set Q:</p><formula xml:id="formula_16">1 - σ2 Q + μ2 Q τ 2 ≥ α,</formula><formula xml:id="formula_17">where μB = B Pr(b) • ∆P| b and σ2 B = B Pr(b)(∆P| b -μB ) 2 .</formula><p>Proof. The proof is straightforward by giving two lemmas: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we conduct experiments for discrimination discovery and removal algorithms by using two real data sets: the Adult dataset <ref type="bibr" target="#b17">[18]</ref> and the Dutch Census of 2001 <ref type="bibr" target="#b21">[22]</ref>, and compare our algorithms with the conditional discrimination removal methods proposed in <ref type="bibr" target="#b27">[28]</ref>.</p><p>The causal graphs are constructed by utilizing an opensource software TETRAD <ref type="bibr" target="#b9">[10]</ref>, which is a widely used platform for causal modeling. We employ the original PC algorithm and set the significance threshold 0.01 used for conditional independence testing in causal graph construction. The quadratic programming is solved using CVXOPT <ref type="bibr" target="#b1">[2]</ref>. All experiments were conducted with a PC workstation with 16GB RAM and Intel Core i7-4770 CPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Discrimination Discovery</head><p>The Adult dataset consists of 65123 tuples with 11 attributes such as age, eduation, sex, occupation, income, etc.. Since the computational complexity of the PC algorithm is an exponential function of the number of attributes and their domain sizes, for computational feasibility we binarize each attribute's domain values into two classes to reduce the domain sizes. We use three tiers in the partial order for temporal priority: sex, age, native country, race are defined in the first tier, education is defined in the second tier, and all other attributes are defined in the third tier. The constructed causal graph is shown in Figure <ref type="figure" target="#fig_11">2</ref>. We treat sex (female and male) as the protected attribute and income (low income and high income) as the decision. An arc pointing from sex to income is observed. We first find set Q of income, which contains all the non-protected attributes. There are 512 subpopulations specified by Q, and 376 subpopulations with non-zero number of tuples. Then, we compute ∆P| q for the 376 subpopulations. The value of ∆P| q ranges from -0.85 to 0.67 across all subpopulations. Among them, 90 subpopulations have ∆P| q &gt; 0.05 and 49 subpopulations have ∆P| q &lt; -0.05, indicating the existence of discrimination in the Adult dataset. Moreover, the mean and the standard variance of ∆P| q are 0.004 and 0.129, which has small Pr(|∆P| q | &lt; τ) based on the Chebyshev's inequality, e.g., Pr(|∆P| q | &lt; 0.15) ≥ 25.97%. It indicates that the nondiscrimination cannot be claimed for the Adult dataset even under the relaxed α-non-discrimination model with large τ and small α.</p><p>Another dataset Dutch census consists of 60421 tuples with 12 attributes. Similarly, we binarize the domain values of attribute age due to its large domain size. Three tiers are used in the partial order for temporal priority: sex, age, country birth are defined in the first tire, education level is defined in the second tire, and all other attributes are defined in the third tire. The constructed causal graph is shown in Figure <ref type="figure" target="#fig_6">3</ref>. We treat sex (female and male) as the protected attribute and occupation (occupation w low income, occupation w high income) as the decision. An arc from sex to occupation is observed in the causal graph. Set Q of occupation is Q = {edu level, age}. The value of ∆P| q ranges from 0.062 to 0.435 across all the 12 subpopulations specified by Q. Thus, discrimination against females is detected in the Dutch dataset based on the non-discrimination criterion. Moreover, the mean and the standard variance of ∆P| q are 0.222 and 0.125, which has small Pr(|∆P| q | &lt; τ) based on the Chebyshev's inequality, e.g., Pr(|∆P| q | &lt; 0.30) ≥ 27.94%. Hence, the Dutch census dataset still contains discrimination based on the relaxed α-non-discrimination criterion.</p><p>Our current implementation uses the PC algorithm to construct the complete causal graph. In our experiment, the PC algorithm with the default significance threshold 0.01 takes 51.59 seconds to build the graph for the binarized Adult dataset and 139.96 seconds for the binarized Dutch census dataset. We also run the PC algorithm on the original Adult dataset, which incurs 4492.36 seconds. In our future work, we will explore the use of the local causal discovery algorithms to improve the efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Discrimination Removal</head><p>The performance of our two proposed discrimination removal algorithms, MGraph  and MData, in terms of the utility of the modified data is shown in Table <ref type="table" target="#tab_3">4</ref>. We also report the results from the Naive method used in <ref type="bibr" target="#b7">[8]</ref> in which we completely reshuffle the gender information. We measure the utility by three metrics: the Euclidean distance (d ), the number of modified tuples (n T ), and the utility loss (χ 2 ). We can observe from Table <ref type="table" target="#tab_3">4</ref> that the MGraph algorithm retains the highest utility. Both MGraph and MData algorithms significantly outperform the Naive method. We also examine how utility in terms of three metrics vary with different τ values for our MGraph and MData algorithms. We can see from Table <ref type="table" target="#tab_4">5</ref> that both discrimination removal algorithms incur less utility loss with larger τ values. This observation validates our analysis of non-discrimination model. We measure the execution times of our removal algo-  the unexplainable (bad) discrimination when one of the attributes is considered to be explanatory for the discrimination. However, their methods do not distinguish whether a partition is meaningful or not. Therefore, they cannot find the correct partitions to measure the direct discriminatory effects. Our experiments show that, their methods cannot completely remove discrimination conditioning on any single attribute. The results are skipped due to space limitation. In addition, even if we remove "bad" discrimination using their methods by conditioning on each attribute one by one, a significant amount of discriminatory effects still exist. After running the local massaging (LM) method, there are still 97 subpopultions (out of 376) with discrimination for Adult and 4 subpopulations (out of 12) with discrimination for Dutch census. The local preferential sampling (LPS) method performs even worse -there are 108 subpopultions with discrimination for Adult and 8 subpopulations with discrimination for Dutch census. This is because for both datasets, any single attribute is not a block set and hence does not form a meaningful partition. Even assuming each attribute forms a meaningful partition, removing discrimination for each partition one by one does not guarantee to remove discrimination since the modification under one partition may change the distributions under other partitions. Differently, our approaches remove discrimination based on block set Q and ensure that the causal structure is not changed after the modification. Thus, Theorem 3.2 can prove non-discrimination for our approaches. Furthermore, their methods incur much larger utility loss than our algorithms, as shown in the last two columns of Table <ref type="table" target="#tab_3">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>A number of data mining techniques have been proposed to discover discrimination in the literature. Classification rule-based methods such as elift <ref type="bibr" target="#b22">[23]</ref> and belift <ref type="bibr" target="#b19">[20]</ref> were proposed to represent certain discrimination patterns. In <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b28">29]</ref>, the authors dealt with the individual discrimination by finding a group of similar individuals. Žliobaitė et al. <ref type="bibr" target="#b27">[28]</ref> proposed conditional discrimination. However, their approaches cannot determine whether a partition is meaningful and hence cannot achieve non-discrimination guarantee. Our work showed that the causal discriminatory effect through C → E can only be correctly measured under the partition specified by the block set. Recently, the authors in <ref type="bibr" target="#b2">[3]</ref> proposed a framework based on the Suppes-Bayes causal network and developed several random-walk-based methods to detect different types of discrimination. However, the construction of the Suppes-Bayes causal network is impractical with the large number of attribute-value pairs. In addition, it is unclear how the number of random walks is related to practical discrimination metrics, e.g., the difference in positive decision rates. Proposed methods for discrimination removal are either based on data preprocessing <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b27">28]</ref> or algorithm tweaking <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b14">15]</ref>. The authors <ref type="bibr" target="#b6">[7]</ref> addressed the problem of fair classification that achieves both group fairness, i.e., the proportion of members in a protected group receiving positive classification is identical to the proportion in the population as a whole, and individual fairness, i.e., similar individuals should be treated similarly. A recent work <ref type="bibr" target="#b7">[8]</ref> studies how to remove disparate impact, i.e., indirect discrimination, from the data. The authors first ensures no direct discrimination by completely removing the protected attribute C from the data. Then, they proposed to test disparate impact based on how well C can be predicted with the non-protected attributes, and remove disparate impact by modifying the non-protected attributes. As shown by our experiments, removing C from the data would significantly damage the data utility. Still, their work is based on correlations rather than the causation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>In this paper, we have investigated the problems of discovery and removal direct discrimination from historical decision data. With the support of the causal graph, we have shown that the discriminatory effect can only be identified under the partition defined by the block set. We have provided the graph condition for the block set. Based on that, we have developed a simple non-discrimination criterion and two strategies for removing discrimination. We also proposed a relaxed non-discrimination criterion to deal with sampling randomness in the data. The experiment results using real datasets show that our proposed approaches are effective in discovering and completely removing discrimination. Our work in this paper focuses on direct discrimination. We will investigate how to extend our work to modeling indirect discrimination using the causal graph and compare with the correlation-based indirect discrimination removal approach proposed in <ref type="bibr" target="#b7">[8]</ref> in the future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>and use B to examine the conditional independence relations in D. If there is no direct causal effect of C on E in G, we should also obtain (E C | B) G , which entails (E C | B) D , i.e., Pr(e + |c + , b) = Pr(e + |c -, b) = Pr(e + |b) for each value assignment b of B. However, if we observe Pr(e + |c + , b) Pr(e + |c -, b), the difference must be due to the existence of the direct causal effect of C on E. Therefore, ∆P| b = Pr(e + |c + , b) -Pr(e + |c -, b) can be used to measure the direct causal effect of C on E. On the other hand, if a node set S does not satisfy (E</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Causal graph of an example university admission system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 2 . 1 .</head><label>21</label><figDesc>A node set B forms a meaningful partition for measuring discrimination if and only if B is a block set, i.e., B satisfies: (1) (C E | B) G holds; (2) B contains none of E's decedents, where G is the graph constructed by deleting arc C → E from G. Discriminatory effect is considered to present for subpopulation b if |∆P| b | ≥ τ, where ∆P| b = Pr(e + |c + , b) -Pr(e + |c -, b). 3 Discrimination Discovery and Prevention 3.1 Non-Discrimination Criterion Now we develop the criterion that ensures non-discrimination for a dataset. Based on Theorem 2.1, if each block set B is examined and ensures that |∆P| b | &lt; τ holds for each subpopulation b, we can guarantee that the dataset contains no discriminatory effect and is not liable for any claim of direct discrimination. Otherwise, there exists a subpopulation b of a block set such that |∆P| b | ≥ τ, which implies that subpopulation b suffers the risk of being accused of discrimination. Therefore, we give the following theorem. Theorem 3.1. Non-discrimination is claimed for D if and only if inequality |∆P| b | &lt; τ holds for each value assignment b of each block set B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Lemma 3 . 1 .</head><label>31</label><figDesc>Given a value assignment b of a block set B, Q = Par(E)\{C}, we have</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Lemma 3 . 2 .</head><label>32</label><figDesc>Node set Q of all E's parents except C, i.e., Q = Par(E)\{C}, must be a block set. Lemma 3.1 indicates that, for each value assignment b of each block set, ∆P| b can be expressed by a weighted average of ∆P| q . If |∆P| q | &lt; τ for each subpopulation of Q, then it is guaranteed that |∆P| b | &lt; τ holds for each subpopulation of each block set. According to Theorem 3.1, non-discrimination is claimed. Otherwise, Lemma 3.2 means that |∆P| b | ≥ τ for at least one block set Q, which provides the evidence of discrimination.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>based on P * 11: end if 12: return D *</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Algorithm 3</head><label>3</label><figDesc>Removal by Modifying Data (MData) Input: dataset D, protected attribute C, decision E, user-defined parameter τ Output: modeified dataset D * 1: [ judge, Q] = Certi f y(D, C, E, τ) 2: if judge == true then</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>9 :</head><label>9</label><figDesc>randomly select a set T of n c - q •(|∆P| q |-τ) tuples with C = c -and E = e + in subpopulation q, and change the values of Es from e + to e -to get the set T * of the modified tuples 10: end if 11: D * = D * \T ∪ T * 12:end for 13: end if 14: return D *</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>4</head><label></label><figDesc>Relaxed Non-Discrimination Criterion So far, we treat dataset D as the whole population. In real situations, D may be a sample of the whole population, and ∆P| b s under a block set B may vary from one subpopulation to another due to randomness in sampling, especially when the sample size is small. The |∆P| b | values of a few b could be larger than τ due to the small sample size although the majority of |∆P| b | values are smaller than τ. In this situation, the dataset is claimed as containing discrimination based on the above criterion where all |∆P| b |s should be smaller than τ no matter of the majority of ∆P| b values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Definition 4 . 1 .</head><label>41</label><figDesc>then we say no significant bias is observed under partition B. If Pr(|∆P| B | &lt; τ) ≥ α holds for each block set, then α-nondiscrimination can be claimed for D. Given α, α-non-discrimination is claimed if Pr(|∆P| B | &lt; τ) ≥ α holds for each block set B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Lemma 4 . 1 .Lemma 4 . 2 .</head><label>4142</label><figDesc>For each block set B, μB = μQ , where Q = Par(E)\{C}. For each block set B, σ2 B ≤ σ2 Q , where Q = Par(E)\{C}. Refer to the Appendices C and D for proof details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Causal graph for Adult dataset: the red node represents the protected attribute, the blue node represents the decision, the green nodes represent set Q.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Causal graph for Dutch Census dataset: the red node represents the protected attribute, the blue node represents the decision, the green nodes represent set Q, and the black nodes represent the others.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Summary statistics of Example 1.</figDesc><table><row><cell>test score</cell><cell>L</cell><cell></cell><cell>H</cell><cell></cell></row><row><cell>gender</cell><cell>female</cell><cell>male</cell><cell>female</cell><cell>male</cell></row><row><cell>major</cell><cell cols="4">CS EE CS EE CS EE CS EE</cell></row><row><cell cols="5">No. applicants 450 150 150 450 300 100 100 300</cell></row><row><cell cols="5">admission rate 20% 40% 20% 40% 50% 70% 50% 70%</cell></row><row><cell></cell><cell>25%</cell><cell>35%</cell><cell>55%</cell><cell>65%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Summary statistics of Example 2.</figDesc><table><row><cell>major</cell><cell></cell><cell>CS</cell><cell></cell><cell></cell><cell></cell><cell>EE</cell><cell></cell><cell></cell></row><row><cell>gender</cell><cell cols="2">female</cell><cell cols="2">male</cell><cell cols="2">female</cell><cell cols="2">male</cell></row><row><cell>test score</cell><cell>L</cell><cell>H</cell><cell>L</cell><cell>H</cell><cell>L</cell><cell>H</cell><cell>L</cell><cell>H</cell></row><row><cell cols="9">No. applicants 450 300 150 100 600 300 200 100</cell></row><row><cell cols="9">admission rate 30% 50% 36% 40% 40% 60% 45% 50%</cell></row><row><cell></cell><cell>38%</cell><cell></cell><cell>38%</cell><cell></cell><cell>47%</cell><cell></cell><cell>47%</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Contingency table within subpopulation q.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Comparison of MGraph, MData, Naive, and two conditional discrimination removal algorithms (LM and LPS) on Adult and Dutch Census.</figDesc><table><row><cell cols="3">Adult MGraph MData Naive</cell><cell>LM</cell><cell>LPS</cell></row><row><cell>d(×10 -3 )</cell><cell>1.089</cell><cell cols="2">1.28 39.40 50.99 35.22</cell></row><row><cell>n T</cell><cell>676</cell><cell cols="2">790 29836 31506 14962</cell></row><row><cell>χ 2</cell><cell>210</cell><cell cols="2">422 19612 28943 11937</cell></row><row><cell cols="3">Dutch MGraph MData Naive</cell><cell>LM</cell><cell>LPS</cell></row><row><cell>d(×10 -3 )</cell><cell>5.09</cell><cell cols="2">6.66 13.64 18.38 14.87</cell></row><row><cell>n T</cell><cell>8776</cell><cell cols="2">8838 31908 30032 19998</cell></row><row><cell>χ 2</cell><cell>3478</cell><cell cols="2">8771 30990 30114 17209</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Comparison of utility with varied τ values for MGraph and MData.</figDesc><table><row><cell>Adult</cell><cell>MGraph</cell><cell>MData</cell></row><row><cell>τ</cell><cell cols="2">0.025 0.050 0.075 0.100 0.025 0.050 0.075 0.100</cell></row><row><cell cols="3">d(×10 -3 ) 1.46 1.08 0.79 0.56 1.73 1.28 0.93 0.68</cell></row><row><cell>n T</cell><cell cols="2">1046 676 476 326 1136 790 584 420</cell></row><row><cell>χ 2</cell><cell>327 218 155 113</cell><cell>604 422 332 261</cell></row><row><cell>Dutch</cell><cell>MGraph</cell><cell>MData</cell></row><row><cell>τ</cell><cell cols="2">0.025 0.050 0.075 0.100 0.025 0.050 0.075 0.100</cell></row><row><cell cols="3">d(×10 -3 ) 5.58 5.09 4.60 4.14 7.29 6.66 5.92 5.28</cell></row><row><cell>n T</cell><cell cols="2">10315 8776 7523 6595 10114 8838 7702 6800</cell></row><row><cell>χ 2</cell><cell cols="2">4418 3478 2716 2132 11460 8771 6964 5658</cell></row><row><cell cols="3">rithms. As expected, MGraph takes longer time than MData</cell></row><row><cell cols="3">since the former requires quadratic programming and data</cell></row><row><cell cols="3">generation based on the whole modified graph while the lat-</cell></row><row><cell cols="3">ter only requires the information of Q. For the Adult dataset</cell></row><row><cell cols="3">with τ = 0.05, MGraph takes 20.86s while MData takes</cell></row><row><cell cols="3">11.43s. For the Dutch dataset the difference is even larger,</cell></row><row><cell cols="3">i.e., 735.83s for MGraph and 0.20s for MData, since the size</cell></row><row><cell cols="3">of Q of Dutch census is much smaller.</cell></row><row><cell cols="3">5.3 Comparison with conditional discrimination meth-</cell></row></table><note><p><p><p>ods In</p><ref type="bibr" target="#b27">[28]</ref></p>, the authors measured the "bad" discrimination i.e., the effect that can be explained by conditioning on one attribute. They developed two methods, local massaging (LM) and local preferential sampling (LPS), to remove</p></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices</head><p>A Proof of Lemma 3.1</p><p>Proof. We first sort the nodes in the causal graph according to the topological ordering of the DAG, so that for each sorted pair of nodes X and Y that X is ahead of Y, X must be Y's non-descendent and Y must be X's non-ancestor. The topological ordering is guaranteed to be found in a DAG <ref type="bibr" target="#b5">[6]</ref>. We represent the sorted nodes by an ordered list</p><p>According to the Markov condition, we have</p><p>where Prior(V) represents all the nodes prior to V in the ordering. Now we consider a topological ordering such that, (i) node E and all nodes in Q are consecutive in ordering, (ii) all nodes posterior to E are E's descendents.</p><p>It is easy to prove that such a topological ordering can always be constructed. </p><p>Pr(x, c + , y, q, e + , z).</p><p>According to the chain rule of probability calculus, we have</p><p>1 For (i), if any node lies between E and some of its parents, we can move the node to the front of all E's parents and the resultant list is still a topological ordering. Similarly we can prove (ii).</p><p>From Equation (A.1), it follows that</p><p>From Equation (A.2), we have</p><p>We can obtain similar result for Pr(e + |c -, b). Therefore, we have</p><p>Hence, the lemma is proven.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Proof of Lemma 3.2</head><p>Proof. We classify the paths from C to E other than arc C → E into two cases based on the last node X ahead of E on the path. For the first case, X is a parent of E. Thus, X is a noncollider and belongs to Q. Based on the definition, each path in the first case is blocked by Q. For the second case, X is a child of E. Then, there must be at least one collider Y on each path in the second case. Otherwise, the path is monodirectional with all the arcs pointing from E to C, forming a circle with the arc C → E. This contradicts to that a CBN is a directed acyclic graph. Let Y be the last collider ahead of E on a path. Then, neither Y nor its descendant Z can be E's parent. Otherwise, mono-directional path</p><p>, which again contradicts to that a CBN is a directed acyclic graph. Thus, according to the definition, each path in the second case is blocked by Q. Finally, Q contains none of E's descendents. Therefore, Q is a block set. Hence, the lemma is proven. According to Equation (A.3), we have</p><p>where B = B\Q. Then, it follows that</p><p>Hence, the lemma is proven. According to Equation (A.3), we have</p><p>According to Cauchy's Inequality, it follows that</p><p>Similar to the proof of Lemma 4.1, it follows that</p><p>Pr(b , q) • (∆P| q ) 2 = Q Pr(q) • (∆P| q ) 2 .</p><p>Hence, we have Besides, we have</p><p>Thus, it follows that</p><p>Hence, the lemma is proven.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Probabilistic inequalities</title>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">A</forename><surname>Anastassiou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>World Scientific</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Martin</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joachim</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lieven</forename><surname>Vandenberghe</surname></persName>
		</author>
		<ptr target="http://cvxopt.org/" />
	</analytic>
	<monogr>
		<title level="j">CVXOPT</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Exposing the probabilistic causal structure of discrimination</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Bonchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Hajian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bud</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniele</forename><surname>Ramazzotti</surname></persName>
		</author>
		<idno>CoRR, abs/1510.00552</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Three naive bayes approaches for discrimination-free classification</title>
		<author>
			<persName><forename type="first">Toon</forename><surname>Calders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sicco</forename><surname>Verwer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="277" to="292" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Orderindependent constraint-based causal structure learning</title>
		<author>
			<persName><forename type="first">Diego</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Marloes</surname></persName>
		</author>
		<author>
			<persName><surname>Maathuis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3741" to="3782" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><surname>Thomas H Cormen</surname></persName>
		</author>
		<title level="m">Introduction to algorithms</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Omer Reingold, and Richard Zemel. Fairness through awareness</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toniann</forename><surname>Pitassi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ITCS</title>
		<meeting>ITCS</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="214" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Certifying and removing disparate impact</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sorelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Friedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Moeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName><surname>Venkatasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="259" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Causation in antidiscrimination law: Beyond intent versus impact</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sheila</surname></persName>
		</author>
		<author>
			<persName><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hous. L. Rev</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">1469</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
		<ptr target="http://www.phil.cmu.edu/tetrad" />
		<title level="m">The TETRAD project</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A methodology for direct and indirect discrimination prevention in data mining</title>
		<author>
			<persName><forename type="first">Sara</forename><surname>Hajian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Domingo-Ferrer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JKDE</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1445" to="1459" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Estimating highdimensional directed acyclic graphs with the pc-algorithm</title>
		<author>
			<persName><forename type="first">Markus</forename><surname>Kalisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="613" to="636" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Data preprocessing techniques for classification without discrimination</title>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Kamiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toon</forename><surname>Calders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KAIS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discrimination aware decision tree learning</title>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Kamiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toon</forename><surname>Calders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mykola</forename><surname>Pechenizkiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="869" to="874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fairness-aware classifier with prejudice remover regularizer</title>
		<author>
			<persName><forename type="first">Toshihiro</forename><surname>Kamishima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shotaro</forename><surname>Akaho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hideki</forename><surname>Asoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Sakuma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML-PKDD</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="35" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Probabilistic graphical models: principles and techniques</title>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nir</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The polynomial solvability of convex quadratic programming</title>
		<author>
			<persName><forename type="first">Sergei</forename><forename type="middle">P</forename><surname>Mikhail K Kozlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonid</forename><forename type="middle">G</forename><surname>Tarasov</surname></persName>
		</author>
		<author>
			<persName><surname>Khachiyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">USSR Computational Mathematics and Mathematical Physics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="223" to="228" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lichman</surname></persName>
		</author>
		<ptr target="http://archive.ics.uci.edu/ml" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">knn as an implementation of situation testing for discrimination discovery and prevention</title>
		<author>
			<persName><forename type="first">Thanh</forename><surname>Binh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franco</forename><surname>Ruggieri</surname></persName>
		</author>
		<author>
			<persName><surname>Turini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="502" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Combating discrimination using bayesian networks</title>
		<author>
			<persName><forename type="first">Koray</forename><surname>Mancuhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Clifton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence and law</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="238" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning bayesian networks</title>
		<author>
			<persName><surname>Richard E Neapolitan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Prentice Hall Upper Saddle River</publisher>
			<biblScope unit="volume">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<ptr target="https://sites.google.com/site/faisalkamiran/" />
	</analytic>
	<monogr>
		<title level="j">Statistics Netherlands. Volkstelling</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Discrimination-aware data mining</title>
		<author>
			<persName><forename type="first">Dino</forename><surname>Pedreshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Ruggieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franco</forename><surname>Turini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="560" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A multidisciplinary survey on discrimination analysis</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Romei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Ruggieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Knowledge Engineering Review</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">05</biblScope>
			<biblScope unit="page" from="582" to="638" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Data mining for discrimination discovery</title>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Ruggieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dino</forename><surname>Pedreschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franco</forename><surname>Turini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDD</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Causation, prediction, and search</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clark</forename><forename type="middle">N</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Scheines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>MIT press</publisher>
			<biblScope unit="volume">81</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Algorithms for discovery of multiple markov boundaries</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Statnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Lemeir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Constantin</forename><forename type="middle">F</forename><surname>Aliferis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="499" to="566" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Handling conditional discrimination</title>
		<author>
			<persName><forename type="first">Indre</forename><surname>Žliobaitė</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Kamiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toon</forename><surname>Calders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="992" to="1001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Situation testingbased discrimination discovery: a causal inference approach</title>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongkai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xintao</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI 2016</title>
		<meeting>IJCAI 2016</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
