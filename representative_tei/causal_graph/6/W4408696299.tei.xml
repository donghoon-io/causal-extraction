<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Causal Adjacency Learning for Spatiotemporal Prediction Over Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhaobin</forename><surname>Mo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qingyuan</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Baohua</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Longxiang</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xuan</forename><surname>Di</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Civil Engineer- ing and Engineering Mechanics</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<addrLine>500 West 120th Street</addrLine>
									<postCode>10025</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<addrLine>500 West 120th Street</addrLine>
									<postCode>10025</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Applied Physics and Applied Mathematics</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<addrLine>500 West 120th Street</addrLine>
									<postCode>10025</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Columbia University</orgName>
								<address>
									<addrLine>550 W 120th St</addrLine>
									<postCode>10027</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Causal Adjacency Learning for Spatiotemporal Prediction Over Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Spatiotemporal prediction over graphs (STPG) is crucial for transportation systems. In existing STPG models, an adjacency matrix is an important component that captures the relations among nodes over graphs. However, most studies calculate the adjacency matrix by directly memorizing the data, such as distance-and correlation-based matrices. These adjacency matrices do not consider potential pattern shift for the test data, and may result in suboptimal performance if the test data has a different distribution from the training one. This issue is known as the Out-of-Distribution generalization problem. To address this issue, in this paper we propose a Causal Adjacency Learning (CAL) method to discover causal relations over graphs. The learned causal adjacency matrix is evaluated on a downstream spatiotemporal prediction task using real-world graph data. Results demonstrate that our proposed adjacency matrix can capture the causal relations, and using our learned adjacency matrix can enhance prediction performance on the OOD test data, even though causal learning is not conducted in the downstream task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Spatiotemporal (ST) prediction over graphs (STPG) aims to uncover the dynamics of graph-structured data along its temporal evolution. This method has been widely studied in several transportation-related areas, including predictions of traffic flow and vehicle speeds <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. Understanding these spatiotemporal patterns is crucial for making better decision, improving the allocation of resources, and strengthening risk management efforts <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b4">[5]</ref>.</p><p>In the STPG problem, an important question is how to calculate an adjacency matrix that captures the inter-nodal relations. Existing studies mainly employ three methods for calculating adjacency matrices: heuristic, correlation, and attention mechanisms. Heuristic methods <ref type="bibr" target="#b5">[6]</ref> use predefined human knowledge, such as the geospatial distance among nodes, assuming that neighboring nodes have a higher impact if they are closer to the current node. Similarly, correlation <ref type="bibr" target="#b6">[7]</ref> and attention-based <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b10">[11]</ref> methods assume that a neighboring node with a high impact will have a high correlation or attention score, respectively. Additionally, some studies propose a multi-graph method that combines different graphs. However, these methods often fail to consider potential shifts in the data, such as those caused by events like the COVID-19 outbreak. This issue is known as the outof-distribution (OOD) generalization problem. Consequently, applying the learned adjacency matrix to OOD data may result in suboptimal performance.</p><p>To address the OOD issue, some studies have incorporated causal inference into STPG <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref>. Causal inference aims to identify causality, as opposed to merely correlation, among different variables. The underlying idea is that causal relations remain constant for OOD data, while correlation relations may not. However, most existing causal inference approaches for STPG underemphasize the temporal dimension. Additionally, most of these studies conduct causal inference in the latent space, where the causal effects of the nodes are represented as latent variables. This representation, however, lacks interpretability and is not transferable after learning.</p><p>To fill in this research gap, we propose a Causal Adjacency Learning (CAL) framework in this study to learn causal relationships and encode them into the adjacency matrix. Unlike existing causal inference methods, our proposed method considers the temporal dimension to calculate causal relations in the spatiotemporal prediction setting and provides a transferable upstream task of learning a causal adjacency matrix. Compared to other matrices, our learned adjacency matrix successfully encodes causal relations and can be transferred to a downstream task without the need to conduct causal inference again. This method is inspired by the temporal causal feature selection, which concerns about deciding if one time-series variable can decide another one. We extend this idea from the temporal domain to the spatiotemporal domain, and first apply it to propose a transferrable CAL framework for addressing the OOD issue. Our contributions are:</p><p>• We are the first to consider temporal dimensions in the problem of spatiotemporal prediction over graphs; • We provide the transferrable upstream causal adjacency learning framework; • Our proposed method is evaluated using real-world graph data with OOD patterns.</p><p>The rest of the paper is organized as follows: Section II review the related work. Section III introduces the preliminaries and problem statement. Section IV introduces the methodology of our proposed framework. Section V introduces the experiment and results using real-wi experiments and results. Section VI concludes and projects future research arXiv:2411.16142v1 [cs.LG] 25 Nov 2024 directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we introduce two important relevant topics in STPG, the adjacency matrix and causal inference in the setting of STPG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Adjacency Matrix</head><p>An adjacency matrix is a crucial tool for leveraging the non-Euclidean nature of graph data. There are various types of adjacency matrices designed for different analytical purposes. Heuristic methods calculate adjacency matrices using human prior knowledge. For example, distance-based matrices emphasize geospatial relations among nodes. <ref type="bibr" target="#b5">[6]</ref> first calculate the inter-node distance by geographical coordinates, and set a threshold to determine the connectivity between each two nodes. Apart from the geographic distance, <ref type="bibr" target="#b14">[15]</ref> uses road-network distance, which considers the actual path distance between each node. Additionally, some studies utilize road connections and contextual similarity in their matrices. Although these matrices have strong semantic significance, however, their main limitation is that they do not consider temporal dynamics. In contrast, correlation <ref type="bibr" target="#b15">[16]</ref> and attention-based <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> methods are more adaptive to the evolving feature and account for the temporal dimension by incorporating time series data to calculate the matrix. Nonetheless, these adjacency matrices mostly just memorize the pattern of the training data. Both the correlation and attention-based methods consider the temporal dimensions in a way that the temporal patterns are aggregated in the form of a correlation matrix or attention score. This aggregation will hide the potential pattern shift, which is the OOD issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Causality-based Methods in STPG</head><p>Causal methods can effectively address the OOD issue <ref type="bibr" target="#b18">[19]</ref>. The fundamental assumption behind causality-based methods is that the effect of some variables on others will remain constant for out-of-distribution data. Thus, these variables that hold constant relations are also known as causal factors. Causal-based methods are not new for graph applications. For example, <ref type="bibr" target="#b19">[20]</ref> aims to identify the key protein subgraph as the causal factor to determine the functionality of the protein, while <ref type="bibr" target="#b20">[21]</ref> identifies key pixels in images. However, most relevant studies do not consider the temporal dimension of a graph, and there are two relevant studies on causality-based methods for STPG. <ref type="bibr" target="#b11">[12]</ref> applied an attention mechanism to learn a feature mask that can identify the causal feature. An invariance loss function is designed to guide the model to generate the correct causal feature. While it considers the temporal dimension, the time-series data is used as a chunk to predict the causal chunk, and the patterns within the temporal dimension are understudied. In <ref type="bibr" target="#b12">[13]</ref>, the causal factor is learned as a latent variable that inputs the spatiotemporal data chunk. This approach also treats the temporal dimension as a chunk without studying the patterns within it. Furthermore, learning a latent code as a causal factor lacks interpretability. Our paper differs from these studies in that we consider the within-temporal features, and we learn the causal factor as an adjacency matrix that can be easily transferred to downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PRILIMINARIES AND PROBLEM STATEMENT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Graph and Adjacency Matrix</head><p>In an undirected graph G = (V, E, A), V = {v i } N i=1 represents the nodes, with N = |V | being the total number of nodes. The edges are represented by the set E, and the adjacency matrix A ∈ R N ×N denotes node connectivity. An entry A ij in the matrix is set to 1 if an edge (v i , v j ) exists in E, and 0 otherwise. Node features are encapsulated in X. For example, the distance-based adjacency matrix is calculated as</p><formula xml:id="formula_0">(A DIS ) ij = exp - d 2 ij σ 2 , i ̸ = j and exp - d 2 ij σ 2 ≥ ϵ 0, otherwise ,<label>(1)</label></formula><p>where d i,j is the distance between nodes i and j, σ is a normalization parameter, and ϵ is a threshold that determines the connectivity among nodes based on their distance. Also, the correlation-based adjacency matrix is calculated as:</p><formula xml:id="formula_1">(A COR ) ij = T t=1 (x i t -xi )(x j t -xj ) T t=1 (x i t -xi ) 2 T t=1 (x j t -xj ) 2 ,<label>(2)</label></formula><p>, where x i t is the feature of node i at time step t and xi is its averaged value across time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Problem Statement</head><p>With all the preliminaries introduced above, we are ready to define the problem of predicting human mobility, i.e., the future regional number of visits. Given the historical nodal feature of previous τ time window,</p><formula xml:id="formula_2">X (t-τ +1):t = [X t-τ +1 , • • • , X t ],</formula><p>we aim to learn a function f to predict the future τ ′ -length mobility sequence Y (t+1):</p><formula xml:id="formula_3">(t+τ ′ ) = [Y t+1 , • • • , Y (t+1):(t+τ ′ ) ]. [X (t-τ +1):t ; A] f → Y (t+1):(t+τ ′ ) ,<label>(3)</label></formula><p>where X t = (x 1 t , ..., x N t ) represents all the nodal feature at time t; A is the adjacency matrix;</p><formula xml:id="formula_4">Y t = (y 1 t , • • • y N t</formula><p>) stands for all the prediction targets, with y i t ∈ R being the prediction target of node i at time t, where i ∈ {1, • • • , N }. Specifically, our goal will focus on the prediction performance of test data that has an apparent OOD pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. METHODOLOGY</head><p>We will introduce the framework of our proposed framework for STPG which is illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. The proposed method consists of two modules, an upstream CAL and a downstream spatiotemporal graph neural network (GNN). We make such a design so that the adjacency matrix A CAU that is learned from the upstream can be interpretable and transferrable for the downstream tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Causal Adjacency Learning</head><p>The core of our proposed framework is to learn the causal adjacency matrix that captures the causal relations among nodes. In the framework of CAL, we use the temporal conditional independence test (CIT) <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b23">[24]</ref> to identify the causal relations. We further incorporate spatial correlations into the temporal CIT framework to decrease the computational burden and also to encode the spatial relations.</p><p>1) Conditional Independence Test (CIT): An important tool for deciding the causal factor is the conditional independence test which has been applied to causal discovery. We define the concept of condition independence in the context of STPG as follows:</p><p>Definition IV.1. (Conditional Independence) Let x i 1:t , x j 1:t and x k 1:t denote time-series features of three nodes. The conditional independence is denoted as x i 1:t</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>|=</head><p>x j 1:t | x k 1:t . This conditional independence indicates that given the timeseries feature of node k, knowing the time-series feature of node i (or j) does not provide additional information about node j (or i).</p><p>Conditional independence provides guidance for selecting causal features, given the fact that knowing the information of the causal feature can get rid of other features that may have a variant relation across data distribution (also known as environment features). As our problem is on continuous space, we adopt a kernel-based CIT to identify the causal features. The kernel-based method is used to approximate the distribution of a continuous variable. The algorithm of kernel-based CIT is illustrated in Algorithm 1. Note that we omit some technical detail like normalization for notation simplicity for STPG. Readers can refer to <ref type="bibr" target="#b24">[25]</ref> for the complete derivation of the kernel-based CIT.</p><p>2) SyPI: However, directly applying the above-mentioned kernel-based CIT will contribute to plenty of false positives and false negative causal dependencies, which will cause perturbation for the training of the downstream model. To reduce false positive and false negative rates, we apply the SyPI algorithm <ref type="bibr" target="#b25">[26]</ref> to further filter the fake relationships generated from kernel-based CIT.</p><p>The algorithm of SyPI is illustrated well in Algorithm 2. Note that the input is a 2D array X (candidate time series) and a vector Y (target), and the output A CAU is a set with indices of the time series that were identified as causes, we treat it as our causal adjacency matrix here. min lags represent the minimum lag between time series of the candidate node and target node. τ means the times window.</p><p>3) Spatial Pre-selection: The method above is still O(n 2 ) computational complexity. To reduce the computation burden and also incorporate the spatial information. We propose to use the correlation matrix in Eq. 2 for the pre-selection of potential causal candidates. For each node i, we define the potential causal factor candidates as the neighbouring nodes with the M highest correlations, where M is a hyperparameter to be tuned. Using this pre-selection approach, the computational complexity can be reduced to O(M n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Spatiotemporal Prediction</head><p>For the learned adjacency matrix of a A CAU , we define the normalized Laplacian matrix as L = I-D -1/2 A CAU D -1/2 , where I is the identity matrix, and D is a diagonal degree matrix with each D ii being the sum of the elements in the i th row of A CAU . To approximate the graph convolution operator * G , we employ K-order Chebyshev polynomials, expressed as:</p><formula xml:id="formula_5">g θ * G x = g θ (L)x = K-1 k=0 θ k T k ( L) x,<label>(4)</label></formula><p>Here, θ in R K represents the vector of polynomial coefficients. The scaled Laplacian L is calculated as L = 2 λmax L -I, with λ max being the maximum eigenvalue of L.</p><p>Algorithm 2 SyPI Algorithm 1: Input: X, Y 2: Output: A CAU 3: n vars = shape(X, 1), A CAU = [ ] 4: w = min lags(X t-w-τ +1:t-w , Y ) 5: for i = 1 to n vars do 6:</p><formula xml:id="formula_6">S i = nvars j=1,j̸ =i {X j t-τ -1:t-1 } 7: pvalue1 = KCIT(X i t-w-τ +1:t-w , Y t-τ +1:t , [S i , Y t-τ :t-1 ]) 8:</formula><p>if pvalue1 &lt; threshold1 then</p><formula xml:id="formula_7">9: pvalue2 = KCIT(X i t-w-τ :t-w-1 , Y t-τ +1:t , [S i , X i t-w-τ +1:t-w , Y t-τ -1:t-1 ]) 10:</formula><p>if pvalue2 &gt; threshold2 then 11:</p><formula xml:id="formula_8">A CAU = append(A CAU , X i t-w-τ +1:t-w ) 12:</formula><p>end if</p><formula xml:id="formula_9">13:</formula><p>end if 14: end for Chebyshev polynomials are recursively defined by T k (x) = 2xT k-1 (x) -T k-2 (x), starting with T 0 (x) = 1 and T 1 (x) = x. Using this K-order Chebyshev polynomial approximation allows each node to be updated based on the information from its K neighboring nodes.</p><p>After graph convolution effectively captures neighboring node data in the spatial dimension, we further refine the node signals by adding a standard convolution layer in the temporal dimension. This layer integrates data from neighboring time slices, updating the node signals accordingly. A final 1×D convolution with a nonlinear neural network layer is used to generate the final prediction X(t-τ+1):t . We employ the mean squared error (MSE) as our loss function:</p><formula xml:id="formula_10">L = ||Y (t-τ +1):t -Ŷ(t-τ+1):t || 2 N τ ,<label>(5)</label></formula><p>where || • || 2 is the L 2 norm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENT</head><p>In this section, we use a real-world dataset to evaluate the performance of our proposed method. Specifically, we demonstrate our proposed method as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset</head><p>To model human mobility patterns during the COVID-19 pandemic, we employ the SafeGraph dataset (Table <ref type="table" target="#tab_0">I</ref>), which aggregates location information from mobile applications on individuals' smartphones. This dataset furnishes comprehensive insights into the migration of populations across various districts such as residential, commercial, and recreational sectors, spanning a broad geographical expanse with precise spatial and temporal resolutions.</p><p>We aggregate the SafeGraph data into a weekly time frame since it provides a good balance between granularity and data availability. This temporal aggregation is meticulously aligned with the periodicity of COVID-19 case reporting. In our preprocessing efforts, we extract critical attributes from the SafeGraph dataset, including visitor counts, duration of stays, and the distances traversed among various locations.</p><p>Our dataset encapsulates the aggregated data on weekly visits and additional pertinent attributes for 172 areas in New York, recorded from August 10, 2020, to April 18, 2022. We utilize the z-score normalization method to standardize the visitor metrics, preparing the data for downstream modeling inputs.</p><p>In addition to the SafeGraph data, we enhance our analysis by incorporating COVID-19 epidemiological data from the Centers for Disease Control and Prevention (CDC), which includes weekly statistics on cases, hospitalizations, and mortality rates across the United States. This integration is crucial for examining the interplay between human mobility and the dynamics of COVID-19 outbreaks. Complementing our dataset, we also include contextual variables such as income levels, population density, and points of interest from open data sources in New York City, thereby enriching our analytical framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiment Setting</head><p>In our study, the experimental framework revolves around a basic graph convolutional neural network (GCN) model. The model is designed to predict the mobility of future weeks of a certain node given the last four weeks' data: images from the dataset and vehicle speed data. The choice of a GCN model was intentional, as it allows for easier training and a clearer explanation of how the quality of the adjacency affects model performance.</p><p>1) Setting for SyPI: In our experiment, we set the time series length as 50 weeks and the fixed min lag as 1 since our time granularity is on a weekly basis, which is quite coarse. We used threshold1 = 0.1 and threshold2 = 0.08 for SyPI. For the configuration in KCIT, we set kernel size σ as 10 and kernel width σ x as 0.8 while other hyperparameters remain the default values.</p><p>2) Baseline Method: In our study, we evaluate the effectiveness of the SyPI adjacency matrix in predicting future mobility and compare it to three well-established relationship measurement methods on our dataset. Our baseline adjacency matrix is:</p><p>• Distance matrix: We calculated the distance between   <ref type="table" target="#tab_1">II</ref>, our CAL method could achieve 14.23%, 15.49%, and 50.27% Root Mean Square Error (RMSE) improvement in predicting the next week's mobility in New York, compared with the results based on distance, correlation, and attention matrix separately. The average RMSE improvement of predicting the mobility after 4 weeks is 24.71%, 10.98%, and 27.26%, compared with the results using distance, correlation, and attention adjacency matrix separately.</p><p>Meanwhile, the number of edges in the CAL adjacent matrix is reduced by 9.67% and 15.98%, compared with the correlation and attention adjacent matrix separately, which verifies the success of filtering the false positive relationships in the distance and correlation adjacency matrix. Furthermore, it increases the sparsity of the adjacent matrix, optimizing the computation time and space complexity during the training and testing progress. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Visualization</head><p>The prediction of the CAL is illustrated in Fig 2 . The CAL model demonstrates superior performance in fitting the ground truth compared to other models, for both one-week and four-week predictions. Note that there was a COVID-19 outbreak around the sixth week (February 2022) in our test dataset, which provides a strong OOD property and difficulty for data forecasting. However, our method delivers more accurate predictions in that week, even for long-time forecasting, which implies that the CAL model can catch more potential and sustainable causal relationships than other methods.</p><p>We aggregate the adjacency matrix in the row and column directions and plot these aggregations on the map, as shown in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSIONS</head><p>In this paper, we propose a causal adjacency learning framework that identifies causal factors for each node in a graph. By encoding the results into the adjacency matrix, this causal information can be utilized in other downstream tasks. We demonstrate with real-world datasets that our learned causal adjacency matrix enables models to capture out-ofdistribution (OOD) patterns, even if causal learning is not explicitly performed in the downstream task. Additionally, by visualizing the causal adjacency matrix on a geospatial map, we provide a practical interpretation of our method's performance.</p><p>This method could be enhanced in two key ways. First, we are considering incorporating information from spatial dimensions beyond using a correlation matrix for pre-selection. Second, we plan to explore the application of our proposed method in various cities that exhibit different patterns.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Framework of the upstream CAL and the downstream spatiotemporal GCN for the problem of STPG.</figDesc><graphic coords="3,104.40,50.08,403.19,78.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 2 X 1 n</head><label>121</label><figDesc>Kernel-based CIT 1: Input: i: A permutation of nodes time-series feature combination (x i 1:t , x j 1:t , x k 1:t ) where i ̸ = j ̸ = k ∈ {1, ..., N }; the significance level α; the Gaussian Kernel K = exp -∥x1-x2∥ 2 2σ with σ X being the kernel width. 2: Calculate centralized kernel matrice for the nodes feature permutation Ki , Kj and K(i,k) by K := HKH, where H is the normalizing matrix. 3: Conduction eigenvalue decomposition for each normalized kernel by K = VΛV T , where Λ is the diagonal matrix containing the non-negative eigenvalues. 4: Calculate the conditional kernel function by K(i,k)|k = R k K(i,k) R k and Kj|k = R Kj R k , where R k = ϵ( Kk + ϵI) -1 with ϵ and I being a small positive regularization parameter and identity matrix, respectively. 5: Calculate p-value based on the statistic T CI := T r( K(i,k)|k Kj|k ), where T r is the trace of a matrix. 6: Output: The p-value and whether the conditional independence x i 1:t |= x j 1:t | x k 1:t ) holds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>each node through the Google Map API and set the average distance as a threshold to compute the final adjacency matrix.• Correlation matrix: We employed the Pearson Correlation algorithm to calculate the correlation between each node and computed the adjacency matrix by setting the correlation threshold to 0.75 and the p-value threshold to 0.05. • Attention matrix: The attention matrix is obtained from a well-trained GAT model and extracting its attention parameters. For this matrix, we did not set any threshold but kept the same edges as the SyPI adjacency matrix according to the attention value. 3) Dataset Splitting: In preparation for training the GCN model, we split the first 74 weeks of the whole 90 weeks data as our in-distribution train/validation dataset and treated the last 16 weeks of data of our dataset which represents the peak of the COVID-19 outbreak as our out-of-distribution test dataset. 4) GCN Structure: Our Spatiotemporal GCN model uses two spatial convolution layers as the encoder and one temporal convolution layer as the decoder. During the training process, the GCN model receives 4 consecutive weeks' data and returns the following 4 weeks' data as the forecasting results. C. Results 1) Performance Comparison: Given different random seeds, as shown in Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: GCN prediction of future mobility based on different adjacency matrices for two ZIP codes.</figDesc><graphic coords="5,337.68,345.88,195.83,83.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig 3 ,</head><label>3</label><figDesc>The row and column aggregations represent the total impact received from and sent to other regions, respectively. The figure clearly illustrates that Manhattan exerts the most significant influence on other regions, while Staten Island has the minimal impact, reflecting their respective levels of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Row (left) and column (right) aggregation of A CAU .</figDesc><graphic coords="6,55.74,50.08,244.79,112.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Summary of SafeGraph datasets</figDesc><table><row><cell></cell><cell>SafeGraph</cell></row><row><cell># of ZIP codes</cell><cell>172</cell></row><row><cell># of Weeks</cell><cell>90</cell></row><row><cell>Time Span</cell><cell>2020/08/03 -2022/04/25</cell></row><row><cell></cell><cell>Point of Interest (POI)</cell></row><row><cell># of POIs</cell><cell>18,912</cell></row><row><cell cols="2">Types of POIs residential(16%), education(20%), etc.</cell></row><row><cell cols="2">Median Household Annual Income</cell></row><row><cell>Range</cell><cell>$31,536 -$243,571</cell></row><row><cell></cell><cell>ZIP Code Population</cell></row><row><cell>Range</cell><cell>1,783 -111,344</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Performance metrics of GCN prediction on future 1-4 weeks based on different adjacency matrices. Bolded represents the best result and underlined means second best. Distance .221/.049 .284/.081 .339/.115 .414/.171 .322/.104 Correlation .224/.050 .258/.066 .259/.067 .337/.114 .273/.074 Attention .381/.145 .276/.076 .233/.054 .412/.170 .334/.111 CAL(Ours) .189/.036 .239/.057 .239/.057 .292/.085 .243/.059</figDesc><table><row><cell>#Adjacency</cell><cell></cell><cell>RMSE/MAE</cell><cell></cell><cell></cell></row><row><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>Avg.</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Stgin: An uncertainty quantification approach in traffic data imputation with spatio-temporal graph attention and bidirectional recurrent united neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1454" to="1459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">St-mlp: A cascaded spatio-temporal linear framework with channel-independence strategy for traffic forecasting</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mulvey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.07496</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust node classification on graphs: Jointly from bayesian label transition and topology-based label propagation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Al</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Mana gement</title>
		<meeting>the 31st ACM International Conference on Information &amp; Knowledge Mana gement</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2795" to="2805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">How does bayesian noisy selfsupervision defend graph convolutional networks?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Processing Letters</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2997" to="3018" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Defending graph convolutional networks against dynamic graph perturbations via bayesian self-supervision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Al</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="4405" to="4413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04875</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Invariant graph neural network for out-of-distribution nodes</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 15th International Conference on Machine Learning and Computing</title>
		<meeting>the 2023 15th International Conference on Machine Learning and Computing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="192" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive graph convolutional recurrent network for traffic forecasting</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="17" to="804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Attention based spatial-temporal graph convolutional networks for traffic flow forecasting</title>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="922" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Event-aware multimodal mobility nowcasting</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shibasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="4228" to="4236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Spatiotemporal adaptive gated graph convolution network for urban traffic flow forecasting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International conference on information &amp; knowledge management</title>
		<meeting>the 29th ACM International conference on information &amp; knowledge management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1025" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Dynamic graph neural networks under spatio-temporal distribution shift</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="6074" to="6089" />
		</imprint>
	</monogr>
	<note>Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deciphering spatio-temporal graph forecasting: A causal lens and treatment</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zimmermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Infostgcan: An information-maximizing spatialtemporal graph convolutional attention network for heterogeneous human trajectory prediction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Di</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">151</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Spatial-temporal fusion graph neural networks for traffic flow forecasting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4189" to="4196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Trafficgan: Network-scale deep traffic prediction with generative adversarial nets</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="219" to="230" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cross-and context-aware attention based spatial-temporal graph convolutional networks for human mobility prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Di</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Spatial Algorithms and Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pi-neugode: Physics-informed graph neural ordinary differential equations for spatiotemporal trajectory prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Di</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems</title>
		<meeting>the 23rd International Conference on Autonomous Agents and Multiagent Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1418" to="1426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Causal imitation learning via inverse reinforcement learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning causally invariant representations for out-ofdistribution generalization on graphs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22" to="131" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Debiasing graph neural networks via learning disentangled causal substructure</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24" to="934" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Model-powered conditional independence test</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shakkottai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Conditional independence test for weights-of-evidence modeling</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Agterberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Resources Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="249" to="255" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A permutationbased kernel conditional independence test</title>
		<author>
			<persName><forename type="first">G</forename><surname>Doran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="132" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Kernel-based conditional independence test and application in causal discovery</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1202.3775</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Necessary and sufficient conditions for causal feature selection in time series with latent common causes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Mastakouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7502" to="7511" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
