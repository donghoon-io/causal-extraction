<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Real-Time Anomaly Detection Using Distributed Tracing in Microservice Cloud Applications</title>
				<funder ref="#_A5Scyae">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mahsa</forename><surname>Raeiszadeh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CIISE</orgName>
								<orgName type="institution">Concordia University</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amin</forename><surname>Ebrahimzadeh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CIISE</orgName>
								<orgName type="institution">Concordia University</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ahsan</forename><surname>Saleem</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CIISE</orgName>
								<orgName type="institution">Concordia University</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Ericsson Research</orgName>
								<address>
									<settlement>Lund</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roch</forename><forename type="middle">H</forename><surname>Glitho</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CIISE</orgName>
								<orgName type="institution">Concordia University</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Ericsson Research</orgName>
								<address>
									<settlement>Lund</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Johan</forename><surname>Eker</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Ericsson Research</orgName>
								<address>
									<settlement>Lund</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Raquel</forename><forename type="middle">A F</forename><surname>Mini</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Ericsson Research</orgName>
								<address>
									<settlement>Lund</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Computer Science Programme</orgName>
								<orgName type="institution">University of Western Cape</orgName>
								<address>
									<settlement>Capetown</settlement>
									<country key="ZA">South Africa</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Real-Time Anomaly Detection Using Distributed Tracing in Microservice Cloud Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Anomaly Detection</term>
					<term>Distributed Tracing</term>
					<term>Microservice</term>
					<term>Positive and Unlabeled Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Distributed tracing plays a vital role in microservice infrastructure, and learning-based trace analysis has been utilized to detect anomalies within such systems. However, existing approaches for learning-based trace-based anomaly detection face certain limitations. Some assume that trace patterns can be learned solely from normal executions, while others depend on anomaly injection to generate labeled traces categorized as normal or anomalous. However, in practical scenarios, anomalies may also happen during the normal execution. Moreover, a wide variety of anomalies may occur in practice, which cannot be captured solely through anomaly injection. To address these issues, we propose a Trace-Driven Anomaly Detection (TDAD) approach based on a Span Causal Graph (SCG) representation, which trains a model using a Graph Neural Network (GNN) and Positive and Unlabeled (PU) learning. This technique allows the model parameters to be optimized by estimating the underlying data distribution. As a result, TDAD can be effectively trained using a small number of labeled anomalous traces along with a relatively large number of unlabeled traces. Our evaluation reveals that TDAD outperforms not only the existing unsupervised trace-based anomaly detection methods by 11.9% in terms of F1-score but also a supervised learning-based benchmark by 12x in terms of detection time.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Industrial microservice systems typically encompass largescale distributed architectures, housing hundreds to thousands of services within complex cloud infrastructures. These systems experience dynamic creation and destruction of service instances, necessitating prompt and efficient analytics capabilities within a bounded time. To attain the required observability in highly intricate and dynamic microservice environments, it is crucial to trace the flow of requests among services. To this end, distributed tracing has started to play a vital role in industrial microservice systems <ref type="bibr" target="#b0">[1]</ref>. Typically, it is implemented as a pipeline that facilitates the collection, preprocessing, and storage of traces <ref type="bibr" target="#b1">[2]</ref>. These traces serve as the foundation for a range of trace analysis techniques that aim to comprehend system behaviors <ref type="bibr" target="#b2">[3]</ref>, detect anomalies <ref type="bibr" target="#b3">[4]</ref>, and diagnose faults <ref type="bibr" target="#b4">[5]</ref> within microservice architectures.</p><p>Detection of application anomalies in a microservice system is complicated due to the following challenges. First, microservice systems are highly dynamic with rapid updates and continuous integration and deployment of new features.</p><p>These systems often run in a containerized environment, where container states frequently change from busy to idle, adding to the difficulty of performance diagnosis. Debugging in microservice systems is exceptionally challenging due to their intricate and dynamic nature. Developers face the task of analyzing concurrent behaviors across multiple microservices and comprehending the overall system interaction topology. Second, microservice architecture involves multiple intricately interconnected fine-grained services that are distributed loosely across the system, resulting in complex tracing paths. Additionally, each microservice may have multiple instances to handle requests, thus further increasing the complexity of trace paths. Therefore, tracing and visualizing system executions are fundamental and efficient methods for understanding and debugging distributed systems <ref type="bibr" target="#b5">[6]</ref>. Traces generated from system executions provide valuable insights into runtime service dependencies and facilitate the analysis of request execution across various services <ref type="bibr" target="#b1">[2]</ref>. These traces also capture important details on service invocations such as status codes and duration times. As a result, traces are widely used to identify potential anomalies by examining their structural aspects, such as the presence of missing service invocations and performance metrics (e.g., latency).</p><p>Recently, a few works have focused on learning-based trace analysis for anomaly detection in microservice systems <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b10">[11]</ref>. Unsupervised learning approaches rely on the assumption that patterns within traces can be learned only from normal system executions, while supervised learning approaches depend on injecting anomalies into the system to generate labeled traces. We note, however, that unsupervised methods struggle to ensure that normal traces are truly anomaly-free, while supervised methods require a large number of labeled traces, and rely on time-consuming anomaly injection processes.</p><p>To tackle the aforementioned issues, we propose our Trace-Driven Anomaly Detection (TDAD), which uses a Graph Neural Network (GNN) to enable learning vector representations for traces and Positive and Unlabeled (PU) learning that allows for training a trace-based anomaly detection model with a partially labeled dataset. Our proposed TDAD represents a trace as a Span Causal Graph (SCG) that encompasses a complex hierarchy structure. In order to detect anomalies in microservice system traces, we employ a graph-based approach, where each node in the graph is associated with three distinct information types, including the semantics of the operation name, time-related attributes, and status code. To develop distinct representations for each graph, we use a combination of a graph attention network and a PU learningbased model for trace-based anomaly detection. Model parameters are optimized by estimating the empirical risk on the historical data, which serves as a measure of the expected loss on the training data using PU learning. Leveraging historical anomalous traces, TDAD trains the anomaly detection model using a small number of labeled anomalous traces along with a relatively large number of unlabeled traces, thus being able to detect anomalies in a timely manner. The main contributions of this paper are summarized as follows.</p><p>• We define a trace representation using an SCG, incorporating the hierarchical structure and contextual information of spans which can be obtained via a parallel processing approach. • We present a trace-based anomaly detection method that utilizes a combination of GNN and PU learning. This approach leverages historical anomalous traces and only relies on a small number of labeled anomalous traces. • We have carried out a comprehensive experimental evaluation on a real-world microservice benchmark to evaluate the performance of our proposed TDAD in terms of detection accuracy and detection time. The remainder of this paper is structured as follows. Section II reviews related work. Section III describes the system model, problem statement, and the proposed method. Evaluation results are presented in Section IV. Section V concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Distributed trace-based anomaly detection methods can be classified into two categories (a) Machine Learning-Based and (b) Trace Comparison methods. There are several factors that determine the classifications, including the availability of data, system requirements, and desired capabilities. In the following, we review each category in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Machine Learning-Based Methods</head><p>Machine learning-based anomaly detection methods are classified into two groups of supervised and unsupervised learning methods.</p><p>1) Supervised Learning: The authors of <ref type="bibr" target="#b7">[8]</ref> proposed the so-called Seer, which is a deep neural network that uses convolutional and LSTM layers to detect performance anomalies in application services. Seer receives key performance indicators (KPIs) such as latency, outstanding requests, and resource consumption from distributed traces and node interactions. The output neurons identify the affected services. Seer continuously processes traces to detect anomalies, communicates with the node runtime to identify saturated resources, and notifies the system manager to mitigate performance degradation by allocating additional computing resources. In <ref type="bibr" target="#b8">[9]</ref>, dual neural networks for service anomaly detection were proposed. The first network was a variational autoencoder trained on normal traces to identify anomalies through reconstruction errors. The second network was a convolutional neural network trained on failure-injected traces to recognize the specific failurecausing anomalies. False positives were filtered out during the post-processing of the autoencoder's output. The convolutional network determines the type of anomaly when a service is considered anomalous. Bogatinovski et al. <ref type="bibr" target="#b9">[10]</ref> proposed an anomaly detection approach based on event dependencies. A self-supervised encoder-decoder network was trained to identify events in hidden positions by considering nearby events. During anomaly detection, the network generated expected event lists for each position in a new trace. The post-processing stage flagged genuinely logged events as anomalies if they were absent from their expected positions. Anomaly scores were calculated based on the ratio of anomalous events to trace length, and if the score exceeded a user-defined threshold, a functional anomaly in the application was indicated.</p><p>2) Unsupervised Learning: In TraceAnomaly <ref type="bibr" target="#b6">[7]</ref>, a deep Bayesian neural network with the posterior flow was presented for anomaly detection. The network determines the likelihood of a trace being normal. It stores observed service call paths and sequences of service interactions in traces. During online anomaly detection, TraceAnomaly checks for previously unseen call paths. If found, it evaluates them for functional anomalies using a whitelist. If no functional anomalies are detected, the trace is forwarded to a Bayesian neural network, which determines the probability that the trace is normal. If the probability is below a threshold, the trace is considered a performance anomaly. Microscope <ref type="bibr" target="#b10">[11]</ref> is an application-level performance anomaly detection model. It monitors KPIs at the front-end of a microservice application and compares them against specified Service Level Objectives (SLOs). Deviations from the specified SLOs are detected by Microscope as performance anomalies affecting the application. Jin et al. <ref type="bibr" target="#b3">[4]</ref> introduced RPCA, which is an offline anomaly detection solution for microservice applications. They analyzed distributed tracing traces to detect performance anomalies, considering various metrics such as CPU and memory consumption. Principal component analysis was employed to identify services involved in anomalous interactions. Performance metrics were collected using unsupervised learning algorithms, and anomaly values were detected by applying a linear function to the principal components of anomalous traces. Anomaly scores were assigned to services connected to anomalous traces, and a list of impacted services was generated based on a predefined threshold. Services were ranked according to their anomaly scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Trace Comparison Methods</head><p>Wang et al. <ref type="bibr" target="#b4">[5]</ref>, Meng et al. <ref type="bibr" target="#b11">[12]</ref>, and Chen et al. <ref type="bibr" target="#b12">[13]</ref> utilized trace comparison as a technique for online anomaly detection in microservice applications with distributed tracing instrumentation. The techniques involved collecting possible traces in a microservice application and then comparing newly collected traces with the existing ones. This work is based on the assumption that the application maintains a consistent behavior compared to the past runs. Thus, previously collected traces serve as a reference for comparison. However, anomaly detection may be less accurate if the runtime conditions of the application differ from those under which the reference traces were acquired. Wang et al. <ref type="bibr" target="#b4">[5]</ref> and Meng et al. <ref type="bibr" target="#b11">[12]</ref> proposed trace-based anomaly detection methods for microservice applications. They collect traces in a pre-production environment, build representative call trees, and detect anomalies by computing tree-edit distances and analyzing response times. These approaches are computationally expensive and thus suitable only for offline detection scenarios. In contrast, Chen et al. <ref type="bibr" target="#b12">[13]</ref> introduced a trace comparison-based method using a fast matrix sketching algorithm. By comparing response times with sketch vectors, anomalies are detected efficiently with reduced false positives/negatives. The sketch vectors were updated to adapt to changing runtime conditions, enabling online anomaly detection.</p><p>The literature on anomaly detection in microservice applications commonly employs machine learning algorithms, which are either supervised or unsupervised <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b10">[11]</ref>. Both unsupervised and supervised learning-based approaches in anomaly detection have limitations. Unsupervised methods assume that most training traces are normal, but this assumption may not be valid in practice, and incorporating historical anomalous traces is challenging. Supervised methods rely on a large number of labeled traces, which necessitates the need for a laborious and time-consuming anomaly injection process and may struggle to cover diverse types of normal and anomalous traces. Some works are based on trace comparison methods, which compare newly generated traces with stored traces to identify similarities. However, these methods can be timeconsuming, limiting their suitability to promptly detect and respond to anomalies in real-time, e.g., <ref type="bibr" target="#b4">[5]</ref>  <ref type="bibr" target="#b11">[12]</ref>. The research gap lies in the need to train the anomaly detection model with a small number of labeled anomalous traces. Also, there is a need for efficient real-time anomaly detection methods that can effectively detect anomalies in microservice applications while the system is running, thus allowing for a timely response to failures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SYSTEM MODEL, PROBLEM STATEMENT, AND PROPOSED SOLUTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. System Model and Problem Statement</head><p>Distributed tracing systems commonly adhere to the OpenTracing specification, which establishes a languageindependent data structure and a collection of principles for distributed tracing <ref type="foot" target="#foot_0">1</ref> . OpenTracing, a project under the Cloud Native Computing Foundation (CNCF), provides an API specification and a range of frameworks and libraries that have implemented this specification <ref type="bibr" target="#b1">[2]</ref>. Fig. <ref type="figure" target="#fig_0">1</ref> presents an illustrative example, depicting an instance of a trace that conforms to the OpenTracing specification. Based on the OpenTracing specification, a trace refers to a sequential representation of the steps involved in processing a request across multiple service instances. Each step in this workflow is called a span and captures the context of a service operation. Each trace in the system is assigned a unique trace ID, and spans within a trace are identified by their own unique span ID, along with the ID of their parent span indicating the preceding span in the sequence. Moreover, a span contains information about both the caller operation and the callee operation involved in the current invocation. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, the caller operation of Span 004 is Span 003, its callee operation is Span 004, and its parent span is Span 003. The span captures the initiation and completion times of the server-side invocation, while the parent span records the corresponding initiation and completion times on the client-side for the same invocation. For instance, Span 002 captures the server-side initiation and completion times between Span 001 and Span 002, whereas its parent span (Span 001) captures the client-side initiation and completion times for the identical invocation. Trace i is denoted by T i = s i 1 , . . . , s i L , i ∈ {1, . . . , Z}, from Z time instant, where s i j is span j of trace i and L is the length of T i , i.e., the number of spans in trace i . With these considerations in mind, we aim to solve the problem of determining whether trace T i is an anomaly or not in real time with the main objective of maximizing detection accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proposed Solution</head><p>Fig. <ref type="figure" target="#fig_1">2</ref> illustrates an overview of our proposed TDAD method, which comprises four main components: (i) Span Embedding, (ii) Graph Building, (iii) Model Training, and (iv) Anomaly Detection. First, a vector representation, including semantic information, is generated for each individual span through the process of Span Embedding. Second, Graph Building constructs an SCG for each trace, capturing the relationship among the spans. Third, the Model Training of trace-based anomaly detection uses GNN and PU learning, which enables the learning of a vector representation for each trace derived from its SCG representation. By using PU learning, the model can be trained using a small number of labeled anomalous traces, estimating the empirical risk based on the available data. Next, the trained model is fed with the SCG, employing a signum function in the output layer to generate the final outcome. Finally, TDAD produces a prediction indicating the presence of anomalies. In the following, we describe each component in more detail.</p><p>1) Span Embedding: A trace comprises multiple spans that depict the causal connections between various service invocations. These spans are associated with each service invocation, recording details such as service and operation names, start time, duration, and status code. The process of span embedding involves capturing and encoding these invocation contexts to form the trace graph representation. Specifically, it encodes service and operation names, start and duration times, and status codes separately. These components are then combined into a vector representation for each span, which serves as a basis for further analysis and processing of the trace data. Span embedding comprises three main steps: (i) Semantic Embedding, (ii) Time Embedding, and (iii) Status Code Embedding, which are explained in greater detail next.</p><p>a) Semantic Embedding: The semantics embedding part is responsible for generating a vector representation for each span of a trace including the concatenated service name and operation name. Firstly, we split the names into words using common separators in microservices (e.g., "/", "-", ":"). Next, all words are transformed to lowercase, removing non-verbal symbols such as punctuation marks and numbers. For instance, the name "ts-travelservice/POST:/api/v1/travelservice/travelPlan/cheapest" becomes "ts", "travel", "service", "post", "api", "v1", "travelservice", "travelplan", "cheapest". To handle the dynamic nature of service and operation names in microservices systems, we employ the WordPiece algorithm <ref type="bibr" target="#b13">[14]</ref> for tokenization, which splits words into tokens based on character combinations. This helps address the presence of out-of-vocabulary (OOV) words. For example, "traveldate" and "trainnumber" can be split into tokens like "travel", "date", "train", and "number". Based on the obtained sequence of tokens, we employ a pre-trained BERT model <ref type="bibr" target="#b14">[15]</ref>, which is a transformer-based language representation model, to generate a vector representation. Specifically, we use the BERT-Base model <ref type="bibr" target="#b15">[16]</ref>, which uses 12 transformer encoder layers and a hidden layer with 768 dimensions. This model generates a 768-dimensional vector representation for each span, effectively capturing the semantics of its service and operation name. Employing the BERT-Base model <ref type="bibr" target="#b15">[16]</ref>, which is equipped with 12 transformer encoder layers to capture intricate patterns and dependencies in trace data alongside its 768-dimensional hidden layer for representing nuanced features, has proven beneficial for tasks demanding a deeper comprehension of language semantics and potential performance improvement.</p><p>b) Time Embedding: Every span within the system captures essential information about a service invocation, including the start time and duration of the interaction between the caller and callee. In order to enhance the detection of anomalies related to time, we extract four distinct timerelated attributes from these recorded timestamps, namely, (1) duration time, which refers to the span duration, (2) waiting time, which indicates how long the callee waits for a response from other services, (3) local execution time, which represents the time taken by the callee to perform the current invocation, excluding the waiting time, and (4) relative start time, which is the time difference between the start time of the current span and the start time of its root span.</p><p>Given the use of the BERT-Base model, each span is represented by a 768-dimensional vector. This vector represents the span and includes the embedding of service and operation names. However, if each time feature occupies only a single dimension within this 768-dimensional vector, there is a possibility of overlooking the time-related attributes in the span representation. Moreover, the considerable variation in time across different traces (which may range from a few dozen to several thousand milliseconds) poses challenges in achieving weight convergence and training efficiency of the model. To address these issues, we project a single-dimensional time feature t into a d-dimensional vector space denoted by E time . Subsequently, we use the softmax function to create a soft one-hot encoding, where each element lies between 0 and 1 and the sum of all elements is equal to 1. The soft one-hot encoding vector s is obtained as follows:</p><formula xml:id="formula_0">s = τ (tW + b),<label>(1)</label></formula><p>where τ (•) is the softmax function, W ∈ R p is the weight matrix, and b ∈ R p is the bias. Next, we project the vector s into a vector space specifically designed for time embeddings. The soft one-hot encoding s is multiplied by the time embedding vector E s ∈ R p×d , which results in p-dimensional vector E time as follows:</p><formula xml:id="formula_1">E time = s ⊙ E s ,<label>(2)</label></formula><p>where ⊙ denotes the element-wise multiplication of two vectors of the same length. Finally, to create a comprehensive representation of the time-related attributes within a span, we concatenate the four time embedding vectors, i.e., duration time, waiting time, local execution time, and relative start time (which are defined above). This combined representation effectively captures and encodes the temporal information associated with the span. c) Status Code Embedding: The HTTP/1.1 standard [17] outlines a comprehensive list of 63 status codes categorized into five distinct groups. We utilize one-hot encoding to embed status codes, wherein each status code is represented by a 63-dimensional vector. This means that each dimension corresponds to a specific status code. For instance, a status code 200 can be represented as a vector with a value of 1 on the 5 th dimension and 0 on all other dimensions. Similarly, a status code 404 can be encoded as a vector with a value of 1 on the 28 th dimension and 0 on all other dimensions. This method of encoding status codes enables an efficient analysis of HTTP traffic.</p><p>2) Graph Building: Traces exhibit a hierarchical structure that includes service invocations or spans. In our proposed TDAD method, this hierarchical structure can be effectively represented by SCG, which is a directed acyclic graph (see Fig. <ref type="figure" target="#fig_1">2</ref>). In this graph, each node represents a span within the trace, while the edges indicate the parent-child relationship between spans. To capture the characteristics of each span, its vector representation is used as an attribute of the corresponding graph node.</p><p>3) Model Training: In our proposed approach, trace-based anomaly detection is formulated as a PU learning problem, leveraging historical knowledge of anomalous traces while minimizing the number of labeled traces used for training. PU learning involves training a binary classifier using a small number of positive samples (i.e., anomalous traces) and a relatively large number of unlabeled samples. Essentially, traces are represented as SCGs with span embeddings as node attributes. To obtain meaningful representations of the traces, we employ a graph neural network called Graph Attention Network (GAT), which leverages the multi-head self-attention mechanism <ref type="bibr" target="#b17">[18]</ref>. We employ GAT mainly because it aligns well with the characteristics of the trace data (graph structure), learning trace vector representations, and the need for capturing complex relationships and dependencies within the graph. These graph neural networks learn vector representations of the traces, as depicted in Fig. <ref type="figure" target="#fig_1">2</ref>. In order to train the binary classifier for trace-based anomaly detection, we employ the non-negative risk estimator (nnPU) algorithm <ref type="bibr" target="#b18">[19]</ref>, which exhibits robustness against overfitting.</p><p>Let g = {V, A, X} represent an SCG, where V is the set of nodes, A is the adjacency matrix indicating the edges and X is the node attribute set with each attribute x i representing the node's vector representation. In the context of an SCG, the GAT layer calculates attention scores for adjacent nodes, indicating their relative importance. We obtain the attention score e ij from node j to node i as follows:</p><formula xml:id="formula_2">e ij = ψ a T • (Wh i ∥Wh j ) ,<label>(3)</label></formula><p>where ψ(•) is the LeakyReLU activation function, ∥ represents concatenation, h i and h j denote the vector representations of node i and node j, respectively. The weight matrix W ∈ R F ′ ×F corresponds to a shared linear transformation, where F is the dimensionality of the input node features and F ′ is the dimensionality of the transformed features. a is a learnable attention vector. To obtain the attention coefficients α ij from node j to node note i, the softmax operation is applied to normalize the importance among all neighboring nodes of i:</p><formula xml:id="formula_3">α ij = exp (e ij ) k∈Ni exp (e ik ) ,<label>(4)</label></formula><p>where N i represents the neighborhood of node i. The GAT utilizes multi-head attention to enhance the stability of the attention mechanism's learning process. The attention coefficients are used to compute the output node representation h ′ i as follows:</p><formula xml:id="formula_4">h ′ i = ∥ K k=1 σ   j∈Ni α k ij W k h j   ,<label>(5)</label></formula><p>where K represents the number of involved attention heads. Each attention head α k ij possesses its own attention score. The weight matrix W k corresponds to the linear transformation associated with attention head k. Additionally, σ(•) denotes the activation function.</p><p>After performing the calculations through m GAT layers, TDAD acquires vector representations for all nodes. The overall graph representation v g is obtained as the average of the vectors over all nodes:</p><formula xml:id="formula_5">v g = 1 N g Ng n=1 h m n ,<label>(6)</label></formula><p>where N g denotes the number of nodes in graph g. The vector representation h m n represents the output of node n from the embeddings of GAT layer m.</p><p>During the training phase, our proposed TDAD employs the non-negative risk estimation derived from nnPU <ref type="bibr" target="#b18">[19]</ref>, which is a large-scale PU learning approach to iteratively optimize the GAT parameters. In each epoch, the training set is divided into N mini-batches, and TDAD adjusts the GAT parameters based on the risk estimation for each mini-batch. Suppose we have a two-layer perceptron (MLP) function f with an output dimension of 1. Let L represent the sigmoid loss function. In each mini-batch, there are n p labeled anomalous traces. We use the symbol p to denote the positive data, while u represents the unlabeled data. The estimated risk R + p associated with labeled anomalous traces is obtained as follows:</p><formula xml:id="formula_6">R + p = 1 n p np i=1 L (f (v p i ) , +1) .<label>(7)</label></formula><p>Similarly, the estimated risk R - p associated with unlabeled anomalous traces is obtained as follows:</p><formula xml:id="formula_7">R - p = 1 n p np i=1 L (f (v p i ) , -1) . (<label>8</label></formula><formula xml:id="formula_8">)</formula><p>We calculate the estimated risk R - u for unlabeled traces by treating them as normal as follows:</p><formula xml:id="formula_9">R - u = 1 n u nu i=1 L (f (v u i ) , -1) ,<label>(9)</label></formula><p>where n u is the number of unlabeled traces. Finally, the empirical risk estimation R pu is given by:</p><formula xml:id="formula_10">R pu = π p R + p + R - u -π p R - p ,<label>(10)</label></formula><p>where the hyperparameter π p denotes the class prior probability of anomalous traces. Let β be the hyperparameter which ensures the risk is non-negative. If R - u -π p R - p ≥ -β, TDAD uses Adam <ref type="bibr" target="#b19">[20]</ref> optimization to minimize R pu and optimize GAT parameters; otherwise, Adam is used to minimize π p R - p -R - u and optimize the GAT parameters. It is worthwhile to mention that we employ PU learning, which is a well-known semi-supervised approach, for the purpose of learning representations for each graph and optimizing model parameters by estimating the empirical risk based on the data.</p><p>4) Anomaly Detection: The anomaly detection component is responsible for generating the final outcome. After being fed to the trained model, the trace is considered normal when the outcome is equal to or greater than 0; otherwise, it is considered as anomalous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS</head><p>In this section, we first describe our implementation details and then present our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation Details</head><p>We provide an overview of our experimental testbed, the benchmark application in use, load generation and trace collection procedures, anomaly injection specifications, and the parameter settings and coding environment utilized for implementing the solution under study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Experimental Testbed:</head><p>We have set up a lab testbed environment within Ericsson Research's private cloud, also known as Xerces. The Xerces private cloud operates a vast infrastructure of around 300 servers managed by an Infrastructure-as-a-Service (IaaS) OpenStack platform. Our testbed comprises a Kubernetes cluster composed of four Virtual Machines (VMs) running Ubuntu 20.04. In the central site cluster, one VM takes on the role of the master node, while three VMs serve as worker nodes. The monitoring of VMs within the Kubernetes clusters and data collection were performed using Jaeger<ref type="foot" target="#foot_1">foot_1</ref> .</p><p>2) Benchmark Application: In our evaluations, we considered TrainTicket <ref type="bibr" target="#b5">[6]</ref>, which is a dynamic real-world microservice benchmark. This benchmark encompasses the essential functionalities of train ticket booking, including ticket inquiries, reservations, payments, changes, and user notifications. TrainTicket follows microservice design principles and incorporates various modes of interaction such as synchronous and asynchronous invocations as well as message queues. The system comprises 41 business logic microservices (excluding database and infrastructure microservices) with the explicit purpose of facilitating the examination and experimentation of existing microservice and cloud-native technologies.</p><p>3) Load Generation and Trace Collection: We simulate various user behaviors to create realistic workloads. These behaviors include users who only visit the homepage and search for trains, while others log in and book tickets. Also, we dynamically adjust the number of simulated users per behavior over time. This approach generates a mixture of different request types that change dynamically, closely resembling real-world scenarios. We utilize Production and Performance Testing-based Application Monitoring (PPTAM) <ref type="bibr" target="#b20">[21]</ref> as our load generator, which incorporates 5 distinct user types. We made slight modifications to PPTAM to ensure that the number of users for each request type changes continuously during runtime. Workloads were uniformly generated for each request type, covering all microservice benchmarks (see Fig. <ref type="figure" target="#fig_1">2</ref>). We employ OpenTracing to track the sequential traces of request processing across multiple microservices. In order to ensure uniformity in the data format for collecting execution trace information, we used Jaeger, which is a distributed tool specifically designed to support OpenTracing. We collect 189,486 execution traces from the microservice application.</p><p>4) Anomaly Injection: We implemented an anomaly injector, providing configurability for the injection targets, anomaly types, injection time, duration, and intensity. The injector is specifically developed to be packaged within microservice containers as a file-system layer, allowing for remote activation during the training phase. It includes different types of anomalies that have the potential to violate the SLOs, as shown in Table <ref type="table" target="#tab_0">I</ref>. Anomalies of different types are randomly injected into containers, with adjustable injection timing and intensity. The time interval for anomaly injection follows an exponential distribution with a rate parameter of δ = 0.33s -1 , while the anomaly type and intensity are chosen randomly. 28.7% of the entire trace data consists of anomalous traces. 5) Parameter Setting and Coding Environment: We implemented our TDAD solution using PyTorch 1.10 and Python 3.10.9. The GAT was implemented using PyTorch Geometric 2.2, while the large-scale PU learning algorithm was adapted from nnPU <ref type="bibr" target="#b18">[19]</ref>, an open-source implementation. Semantic embedding utilized the pre-trained BERT-Base model <ref type="bibr" target="#b15">[16]</ref> and WordPiece tokenizer <ref type="bibr" target="#b13">[14]</ref>. Time features were projected to 100 dimensions for time embedding. In TDAD, the model parameters are set as follows. The GAT consists of three layers. The first two layers use three attention heads, while the last layer employs one attention head. Batch normalization was applied after each GAT layer. During training, a batch size of 128 was used, and the prior probability π p of positive data was set to 0.15. The hyperparameter β was set to 0 throughout the training process. The training involved 50 epochs using the Adam <ref type="bibr" target="#b19">[20]</ref> optimization algorithm with a learning rate of 0.001. We randomly partitioned traces into training, validation, and testing sets with a ratio of 3:1:6. Within the training set, ∼ 10% of the anomalous traces were designated as positive samples, accounting for roughly 2% of the entire training set. For the Self-Supervised approach <ref type="bibr" target="#b9">[10]</ref>, we utilized the same training, validation, and testing sets, but labeled all traces in the training set. To ensure a fair comparison with RPCA <ref type="bibr" target="#b3">[4]</ref>, TraceAnomaly <ref type="bibr" target="#b6">[7]</ref>, and Microscope <ref type="bibr" target="#b10">[11]</ref>, which assume that the training set predominantly consists of normal traces, we adopt a different division strategy. The traces were randomly distributed into three subsets, following a ratio of 3:1:6. The first subset exclusively contained normal traces and served as the training set. The third subset was designated as the testing set. To balance the increase in anomalous traces within the testing set, all the normal traces from the second subset were incorporated into the testing set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Results</head><p>1) Evaluation Metrics: We consider precision, recall, and F 1 -score to evaluate the performance of different trace- based anomaly detection methods under study. Moreover, time efficiency is measured using the detection time, which is the time required for processing a single trace data including the time needed for anomaly detection.</p><p>2) Anomaly Detection Results: As described in Section IV-A5, in TDAD, we adopt a randomized approach to select a subset of 10% anomalous traces from the training set. The selected traces are subsequently labeled as positive samples for the training process. This procedure is repeated in 10 iterations, with each iteration involving training a model using the modified training set and evaluating its performance on the testing set. Each shown result is the average over 10 iterations. Table II depicts the obtained recall, precision, and F 1 -score for different anomaly detection solutions. The proposed TDAD achieves a precision of 87.1%, recall of 93%, and an F 1 -score of 89.8%. Although TDAD underperforms Self-Supervised <ref type="bibr" target="#b9">[10]</ref> in precision and F 1 -score, it outperforms RPCA <ref type="bibr" target="#b3">[4]</ref>, TraceAnomaly <ref type="bibr" target="#b6">[7]</ref>, and Microscope <ref type="bibr" target="#b10">[11]</ref> significantly in terms of precision, recall, and F 1 -score. The inferior performance of the unsupervised approaches, RPCA <ref type="bibr" target="#b3">[4]</ref>, TraceAnomaly <ref type="bibr" target="#b6">[7]</ref>, and Microscope <ref type="bibr" target="#b10">[11]</ref>, is evident in their low F 1 -score 80.2% and 61.5%, and 55.7%, respectively. These approaches rely on sequence-based trace representation, which lacks the ability to capture the causal relationships between spans. Additionally, they do not account for status codes. In contrast, Self-Supervised <ref type="bibr" target="#b9">[10]</ref> achieves high precision and F 1 -score mainly because it uses fully labeled training data.</p><p>Next, we evaluate the detection time performance of our proposed TDAD method. We observe from Table II that the proposed TDAD outperforms RPCA <ref type="bibr" target="#b3">[4]</ref>, TraceAnomaly <ref type="bibr" target="#b6">[7]</ref>, Microscope <ref type="bibr" target="#b10">[11]</ref>, and Self-Supervised <ref type="bibr" target="#b9">[10]</ref>, with significantly shorter detection times of only 0.131 ms. In comparison, RPCA <ref type="bibr" target="#b3">[4]</ref>, TraceAnomaly <ref type="bibr" target="#b6">[7]</ref>, Microscope <ref type="bibr" target="#b10">[11]</ref>, and Self-Supervised <ref type="bibr" target="#b9">[10]</ref> had higher detection times of 2.695, 1.860, 4.791, and 0.349 ms. This is mainly due to the fact that the process of network units, represented by the nodes in an SCG in our proposed approach, benefits from parallel processing. Even though the Self-Supervised method <ref type="bibr" target="#b9">[10]</ref> achieved a higher F 1 -score, it is outperformed by our proposed TDAD in terms of detection time (see Table <ref type="table" target="#tab_0">II</ref>). This is because the Self-Supervised method employs a softmax function for generating the final prediction, whereas TDAD uses a signum function.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Impact of Configuration Parameters on the Output:</head><p>We evaluate the impact of the number of labeled anomalous traces on the performance of our proposed TDAD method. Specifically, we employ TDAD to train a model using 5%, 10%, 15%, 20%, and 25% of labeled anomalous traces from the training set. Fig. <ref type="figure" target="#fig_3">3</ref> illustrates the performance metric of the proposed TDAD method for different percentages of labeled anomalous traces. It is apparent that TDAD's performance can be enhanced by increasing the number of labeled anomalous traces. With only 10% anomalous traces labeled in the training data, TDAD significantly outperforms the RPCA <ref type="bibr" target="#b3">[4]</ref>, TraceAnomaly <ref type="bibr" target="#b6">[7]</ref>, and Microscope <ref type="bibr" target="#b10">[11]</ref>, and only slightly underperforms the Self-Supervised <ref type="bibr" target="#b9">[10]</ref> which uses fully labeled training data. When 20% of the anomalous traces are labeled, TDAD achieves an F 1 -score of 97%, which is comparable to that of Self-Supervised with an F 1 -score of 98.5%. However, a further increase in the number of labeled anomalous traces results in a decline in model performance. We attribute this decline to the fixed value of hyperparameter β during model training. As the number of labeled anomalous traces increases, the proportion of normal traces within the unlabeled data also grows. This leads to a more precise estimation of the risk associated with the unlabeled data, denoted as R - u in Eq. <ref type="bibr" target="#b9">(10)</ref>, without subtracting a substantial portion of π p R - p as previously done. However, π p R - p remains unchanged, leading to reduced learning from the unlabeled data and eventually causing underfitting. In order to address this issue, we suggest adjusting the value of β appropriately when the number of labeled anomalous traces increases. This adjustment ensures that the model parameters are optimally tuned, even in cases where R pu is slightly below 0. Fig. <ref type="figure" target="#fig_4">4</ref> illustrates the impact of varying the number of GAT layers on TDAD's performance. Notably, the performance of TDAD initially improves and subsequently declines as the number of layers increases. The highest F 1 -score can be obtained when the number of GAT layers is 3. This is due to the dynamics of interaction within the SCG. When the number of GAT layers is small, the flow of information between nodes in the graph might be inadequate, which can result in incomplete learning of the graph's features. Conversely, an excessive number of GAT layers can lead to over-smoothing <ref type="bibr" target="#b21">[22]</ref>, where the model becomes excessively generalized and therefore incapable of distinguishing the learned representations among diverse graphs.</p><p>V. CONCLUSIONS AND FUTURE DIRECTIONS In this paper, we proposed TDAD, a novel approach that combines GNN and PU learning for the accurate detection of anomalous traces. Our approach demonstrates high performance even with a small number of labeled anomalous traces and a relatively large number of unlabeled traces. TDAD employs an SCG to capture the intricate hierarchical structure of traces effectively. The graph ensures the preservation of span relationships and embeds three types of information into the corresponding node representation vectors, including the semantics of the invoked service name and operation name, time-related attributes, and the status code. By utilizing the SCG, TDAD employs a graph attention network and a trace-based anomaly detection model based on PU learning. The training process involves the utilization of both a small number of labeled anomalous traces and a relatively large number of unlabeled traces. Our trace-driven evaluation on a microservice benchmark demonstrates that the proposed method outperforms not only the existing unsupervised tracebased anomaly detection methods by 11.9% in terms of F 1score but also an existing supervised learning-based approach by 12x in terms of detection time. An interesting future work is to evaluate TDAD across diverse microservice systems as well as develop new techniques that can consider microservice application logs, resource metrics, and trace data to address the challenges associated with anomaly detection in large-scale complex microservice systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example of trace and spans in TrianTicket microservice application.</figDesc><graphic coords="4,48.96,50.54,257.05,180.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Overview of TDAD.</figDesc><graphic coords="5,48.96,50.54,514.05,127.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Precision, recall, and F 1 -score of our proposed TDAD method vs. ratio (%) of labeled anomalous traces.</figDesc><graphic coords="9,76.46,50.54,200.49,167.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Precision, recall, and F 1 -score of our proposed TDAD method vs. the number of GAT layers (ratio of labeled anomalous traces=10%).</figDesc><graphic coords="9,74.25,261.39,200.49,167.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I CATEGORY</head><label>I</label><figDesc>OF INJECTED ANOMALIES INTO TRAINTICKET.</figDesc><table><row><cell>Anomaly</cell><cell>Anomaly Type</cell><cell>Example</cell></row><row><cell>Category</cell><cell></cell><cell></cell></row><row><cell>Network</cell><cell>Network loss</cell><cell>A network congestion incident</cell></row><row><cell>Anomaly</cell><cell>Network delay</cell><cell>arises, resulting in a notable surge</cell></row><row><cell></cell><cell></cell><cell>in network latency.</cell></row><row><cell>Pod</cell><cell>Pod failure</cell><cell>The container experiences memory</cell></row><row><cell>Anomaly</cell><cell>CPU stress</cell><cell>depletion, resulting in a notable rise</cell></row><row><cell></cell><cell>Memory stress</cell><cell>in the response time of service</cell></row><row><cell></cell><cell></cell><cell>invocations.</cell></row><row><cell>Application</cell><cell>service invocation</cell><cell>An error in the implementation of a</cell></row><row><cell>Anomaly</cell><cell>failure,</cell><cell>service introduces a flaw that leads</cell></row><row><cell></cell><cell>Incorrect return</cell><cell>to inaccurate responses during ser-</cell></row><row><cell></cell><cell>results</cell><cell>vice invocations. For example, mod-</cell></row><row><cell></cell><cell></cell><cell>ifying the pricing algorithm in the</cell></row><row><cell></cell><cell></cell><cell>pricing service results in incorrect</cell></row><row><cell></cell><cell></cell><cell>ticket prices being calculated and</cell></row><row><cell></cell><cell></cell><cell>returned.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>See https://opentracing.io/ for further information.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.jaegertracing.io/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>ACKNOWLEDGMENT This work is funded by the <rs type="grantName">Ericsson/ENCQOR-5G Senior Industrial Research Chair on Cloud</rs> and <rs type="person">Edge Computing</rs> for 5G and Beyond.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_A5Scyae">
					<orgName type="grant-name">Ericsson/ENCQOR-5G Senior Industrial Research Chair on Cloud</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A qualitative interview study of distributed tracing visualisation: A characterisation of challenges and opportunities</title>
		<author>
			<persName><forename type="first">T</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>IEEE Xplore Early Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Enjoy your observability: an industrial survey of microservice tracing and analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Causeinfer: Automated end-to-end performance diagnosis with hierarchical causality graph in cloud environment</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Services Computing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="214" to="230" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An anomaly detection algorithm for microservice architecture based on robust principal component analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="226397" to="226408" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Workflow-aware automatic fault diagnosis for microservice-based applications with statistics</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Network and Service Management</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2350" to="2363" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fault analysis and debugging of microservice systems: Industrial survey, benchmark system, and empirical study</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="260" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised detection of microservice trace anomalies through service-level deep bayesian networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Symposium on Software Reliability Engineering (ISSRE)</title>
		<meeting>IEEE International Symposium on Software Reliability Engineering (ISSRE)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="48" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Seer: Leveraging big data to navigate the complexity of performance debugging in cloud microservices</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pancholi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delimitrou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>ACM International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="19" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Anomaly detection and classification using distributed tracing and deep learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nedelkoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CC-GRID)</title>
		<meeting>IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CC-GRID)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="241" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Self-supervised anomaly detection from distributed traces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bogatinovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nedelkoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/ACM International Conference on Utility and Cloud Computing (UCC)</title>
		<meeting>IEEE/ACM International Conference on Utility and Cloud Computing (UCC)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="342" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Microscope: Pinpoint performance issues with causal graphs in micro-service environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Springer International Conference on Service-Oriented Computing (ICSOC)</title>
		<meeting>Springer International Conference on Service-Oriented Computing (ICSOC)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Detecting anomalies in microservices with execution trace comparison</title>
		<author>
			<persName><forename type="first">L</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="291" to="301" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A framework of virtual war room and matrix sketch-based streaming anomaly detection for microservice systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="43413" to="43426" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Japanese and korean voice search</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nakajima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>IEEE International Conference on Acoustics, Speech and Signal essing</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="5149" to="5152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>abs/1810.04805</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>International Conference on Empirical Methods in Natural Language essing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hypertext Transfer Protocol (HTTP/1.1): Semantics and content</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fielding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reschke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RFC</title>
		<imprint>
			<biblScope unit="volume">7231</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="10" to="48550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Positiveunlabeled learning with non-negative risk estimator</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kiryo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Du Plessis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR) Engineering</title>
		<meeting>International Conference on Learning Representations (ICLR) Engineering</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">PPTAM: production and performance testing based application monitoring</title>
		<author>
			<persName><forename type="first">A</forename><surname>Avritzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Menasché</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rufino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Janes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ferme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Hoorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM/SPEC International Conference on Performance Engineering</title>
		<meeting>ACM/SPEC International Conference on Performance Engineering</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="39" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deeper insights into graph convolutional networks for semi-supervised learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conference on Artificial Intelligence</title>
		<meeting>AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
