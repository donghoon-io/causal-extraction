<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CausalLP: Learning causal relations with weighted knowledge graph link prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Utkarshani</forename><surname>Jaimini</surname></persName>
							<email>ujaimini@email.sc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Articial Intelligence Institute</orgName>
								<orgName type="institution">University of South Carolina Columbia</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cory</forename><surname>Henson</surname></persName>
							<email>cory.henson@us.bosch.com</email>
							<affiliation key="aff1">
								<orgName type="department">Bosch Center for Articial Intelligence Pittsburgh</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amit</forename><surname>Sheth</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Articial Intelligence Institute</orgName>
								<orgName type="institution">University of South Carolina Columbia</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CausalLP: Learning causal relations with weighted knowledge graph link prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Causal knowledge graph</term>
					<term>Causal explanation</term>
					<term>Causal prediction</term>
					<term>Link prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Causal networks are useful in a wide variety of applications, from medical diagnosis to root-cause analysis in manufacturing. In practice, however, causal networks are often incomplete with missing causal relations. This paper presents a novel approach, called CausalLP, that formulates the issue of incomplete causal networks as a knowledge graph completion problem. More specically, the task of nding new causal relations in an incomplete causal network is mapped to the task of knowledge graph link prediction. The use of knowledge graphs to represent causal relations enables the integration of external domain knowledge; and as an added complexity, the causal relations have weights representing the strength of the causal association between entities in the knowledge graph. Two primary tasks are supported by CausalLP: causal explanation and causal prediction. An evaluation of this approach uses a benchmark dataset of simulated videos for causal reasoning, CLEVRER-Humans, and compares the performance of multiple knowledge graph embedding algorithms. Two distinct dataset splitting approaches are used for evaluation: (1) random-based split, which is the method typically employed to evaluate link prediction algorithms, and (2) Markovbased split, a novel data split technique that utilizes the Markovian property of causal relations. Results show that using weighted causal relations improves causal link prediction over the baseline without weighted relations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Causal networks are structured as a directed, acyclic graph with edges representing the causal links between entities. Each causal link may be annotated with weights representing the strength of the causal association. Traditional techniques for generating causal networks rely solely on the use of observation data with datasets that are often incomplete and lack important information about the underlying causal structures, leading to an incomplete causal network. If the incomplete causal network is encoded as a knowledge graph (KG), then the task of nding missing causal relations can be formulated as a knowledge graph completion problem, i.e. nding missing links in the knowledge graph.</p><p>Figure <ref type="figure" target="#fig_1">1</ref>: A snapshot of collision events in a video at time t-1, t, and t+1. There are four consecutive collision events that occur: 1) the red cube enters from the left, 2) the red cube collides with the yellow ball, 3) the yellow ball hits the blue cylinder, and 4) the blue cylinder moves.</p><p>In this paper, we present an approach to nding new causal relations using KG link prediction methods. This approach is composed of four primary phases: (1) encoding known causal relations into a causal network, (2) translating the causal network into a knowledge graph, (3) learning knowledge graph embedding for the causal relations, and (4) predicting new causal links in the knowledge graph.</p><p>In a knowledge graph, causal links may be encoded as follows: &lt;cause-entity, causes, eect-entity, w&gt; with the causes relation linking the cause and eect entities. Each causal link is associated with a causal weight, w, that represents the causal inuence of the cause-entity on the eect-entity. This causal inuence is measured by performing an intervention on the cause-entity and observing its outcome on the eect-entity <ref type="bibr" target="#b11">[12]</ref>. In the next phase, a KG embedding (KGE) model is learned. Any KGE algorithm may be used for this task. However, current algorithms do not incorporate relation weights into the learned embedding model. To overcome this issue, FocusE is used to assimilate the causal weights into the KGE model <ref type="bibr" target="#b9">[10]</ref>. In the nal phase, KG link prediction is used to nd new causal links. More specically, two tasks are performed: causal explanation and causal prediction. When implemented with link prediction, causal explanation is mapped to the task of nding the type of the head (i.e. cause-entity) of a causal link, and causal prediction is mapped to the task of nding the type of the tail (i.e. eect-entity) of a causal link.</p><p>Consider an example shown in Figure <ref type="figure" target="#fig_1">1</ref>. The events occurring in the video frames can be encoded in a causal KG. At t-1 &lt;the red cube enters from the left, causes, the red cube collides with the yellow ball&gt;. This subsequently leads to t where &lt;the red cube collides with the yellow ball, causes, the yellow ball hit with the blue cylinder&gt;. Eventually this leads to t+1 where &lt;the yellow ball hits the blue cylinder, causes, the blue cylinder to move&gt;. Now consider the following causal explanation query: Explain the cause of the event the red cube colliding with the yellow ball which occurs at t. The answer would be the prior event the red cube enters from the left which occurs at t-1. Similarly, consider the causal prediction query: Predict the eect of the event the red cube colliding with the yellow ball which occurs at t. The answer would be the subsequent event the blue cylinder moves which occurs at t+1. From these examples, we can see that the answer to causal explanation queries requires predicting a causal link to prior events, and the answer to a causal prediction queries requires predicting a causal link to subsequent events.</p><p>With the traditional approach to evaluating KG embedding algorithms, links are randomly split into a train and test set. In the case of a causal KG, such an approach could lead to model bias. This is due to the fact that there may be multiple causal relations connecting a cause and eect entity in the KG. To resolve this issue we propose a novel approach to splitting the data, called Markov-based split, that is based on the local Markov property of the causal links.</p><p>Due to this split, it may be the case for causal explanation, at t, that some of the causal links from prior frames (i.e. t-1 ) could be in train set. Similarly, for causal prediction at t , some of the latter links (i.e. t+1 ) could be in train set. During the evaluation this could lead to model bias. To resolve this issue we propose to split the data based on the local Markov property of the causal links (i.e. Markovbased splitting). The causal links in t are independent of causal links in t+1 given the causal links in t-1. For causal explanation in frame t, the causal links with events spanning from t-1 to t are in the test set. Similarly for causal prediction in frame t, the causal links with events spanning from t following t+1 are in the test set.</p><p>For the causal prediction task, given a cause-entity we want to predict the type of the eect-entity. There are several causal links that may provide relevant information: causes, causedBy, and caus-esType. To make a causal prediction in this case, the causesType link which links the cause-entity to the type of eect-entity would need to be assigned to the test set (see Figure <ref type="figure" target="#fig_2">3</ref>). But with a random split, the other causal relations (causes and causedBy) connecting these entities may be assigned to the training set. In a real-world scenario, we would not know any of this additional causal information when inferring the eect of an event. Thus, by providing this information during training would lead to bias in the prediction model and articially inate the prediction performance results.</p><p>The proposed approach is evaluated using a benchmark dataset for causal reasoning, CLEVRER-Humans <ref type="bibr" target="#b8">[9]</ref>. The dataset contains a collection of videos showing objects colliding in a simulated environment. Each video in the dataset is annotated with causal relations between events, along with the associated causal weights. Both causal link prediction tasks are evaluated with multiple common KGE algorithms, including DistMult, HolE, TransE, and Com-plEx. Results of the evaluation show that the addition of causal weights leads to improved performance for all algorithms, and also when using either the random-split and Markov-based split.</p><p>The main contributions of this paper include:</p><p>(1) A novel formulation of the task of nding missing causal relations in an incomplete causal network as a KG completion problem.</p><p>(2) Demonstration of the approach for causal link prediction using a benchmark dataset of video simulation data. (3) Evaluation of the approach using multiple KG embedding algorithms, which shows that incorporating causal weights leads to improved performance. (4) Denition and use of a novel method, Markov-based data split, for evaluating the causal link prediction tasks.</p><p>The rest of the paper proceeds as follows: Section 2 describes the related work. The problem formulation is dened in Section 3 followed by the methodology in Section 4. Section 5 details the evaluation with the results and discussion outlined in Section 6. Section 7 provides a conclusion with future direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Causal discovery: Causal discovery algorithms fall under two major categories: constraint based and score based <ref type="bibr" target="#b1">[2]</ref>. The constraint based methods use conditional independence relations in the observational data to nd Markov equivalence classes of directed causal structures. The score based methods use structural equation models to nd unique causal structures under certain assumptions. Another approach to causal discovery, knowledge guided greedy score based approach, uses prior knowledge about the causal structure (knowledge about the edges, i.e. presence or absence of a directed or an un-directed edge) between entities and observational data to learn causal graphs <ref type="bibr" target="#b2">[3]</ref>. The research demonstrates that the prior structural knowledge improves causal graph discovery. The focus of the above research, however, is on causal graphs and not knowledge graphs.</p><p>Causal knowledge graphs: CauseNet is a knowledge graph of causal concepts and relations extracted from semi and unstructured web sources <ref type="bibr" target="#b4">[5]</ref>. The CauseNet links are of the form &lt;subject may-Cause object&gt;. Linguistic patterns are used to extract the causal statements. Statements with words such as "cause(d)", "result(ed)", "lead(s)/led", and "associated with" are termed as causal statements. The causal concepts, i.e. cause and eect, in the statements are presumed to be nouns similar to ConceptNet and WordNet. The linguistic patterns extract explicit causal relations from statements, but does not capture implicit mentions of causal relation and causal concepts spanning across sentences. Since the causal relations are extracted from web, they suer from societal bias in the data. Some of the extracted biased causal relations include "Autism is caused by vaccination" and "HIV is caused by homosexuality" <ref type="bibr" target="#b4">[5]</ref>.</p><p>Causal link prediction: The existing techniques for KG link prediction are used to predict general links and are not tailored for predicting causal links specically. However, <ref type="bibr" target="#b3">[4]</ref> generates an event-related causal knowledge graph from Wikipedia articles and Wikidata with causal predicates, hasCause and hasEect, associated with a given event. The nodes in the graph are events and the edges represent cause-eect relations. It aims to predict future events by analyzing the underlying causes and eects of similar past events. Existing KG link prediction techniques are used to evaluate the causal relation prediction task.</p><p>This paper focuses on nding missing causal relations using knowledge graph completion. The CausalLP approach proposed in this paper predicts new causal links in a knowledge graph utilizing Figure <ref type="figure">2</ref>: CausalLP has four primary phases: 1) encoding the causal associations in data as a causal network, 2) translating the causal network into a causal knowledge graph, 3) learning knowledge graph embeddings from the causal knowledge graph, and 4) using the knowledge graph embeddings for causal link prediction tasks.</p><p>four causal relations i.e. causes, causedBy, causesType, and caused-ByType. The approach uses the prior causal structure knowledge encoded in a causal network which in turn is represented in the causal knowledge graph <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM FORMULATION</head><p>This section formulates the problem of nding missing causal relations as a KG link prediction task and denes the primary concepts, including causal relation, causal link, causal entity, causal weight, and causal knowledge graph.</p><p>Causal knowledge graph: A causal knowledge graph ⇠0DB0; ⌧ is a KG that includes causal knowledge in the form of causal entities, causal relations, and causal weights. ⇠0DB0; ⌧ = (# , ', ⇢, ⇢ 2 , , 2 ):</p><p>• # : a set of nodes representing entities • ': a set of labels representing relations • ⇢ ✓ # ⇥ ' ⇥ # : a set of edges representing links between pairs of entities. Each link has the form &lt;⌘, A , C&gt;, where ⌘ is the head entity, A is the relation, C is the tail entity. Causal entity: A causal entity = 2 2 # 2 is an entity that is the head or tail of a causal link. There are two types of causal entities: cause-entity (= 20DB4 ) and eect-entity (= 4 5 5 42C ) such that the cause-entity causes the eect-entity. Causal weight: A causal weight F 2 , 2 ✓ R is a real number associated with a causal link. It quanties the responsibility or contribution of the cause-entity in causing the eect-entity.</p><formula xml:id="formula_0">• # 2 ✓ # : a set of nodes representing causal entities • ' 2 ✓ ': a set of labels representing causal relations • , 2 ✓ R: a set of real numbers representing causal weights • ⇢ 2 ✓ # 2 ⇥ ' 2 ⇥ # 2 ⇥</formula><p>Causal link: A causal link 4 2 2 ⇢ 2 is an edge in the causal KG connecting a pair of causal entities with a causal relation and an associated causal weight. Causal link is a quad &lt;⌘ 2 , A 2 , C 2 , F 2 &gt;, where ⌘ 2 is the head causal entity, A 2 is the causal relation, C 2 is the tail causal entity, and F 2 is the causal weight.</p><p>Causal link prediction: Causal link prediction is the task of nding new causal links in a CausalKG. Given a CausalKG G, this task can be implemented using knowledge graph link prediction. There are two distinct methods for nding causal links: causal prediction and causal explanation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODOLOGY</head><p>The proposed approach is structured into four primary phases (see gure 2): (1) nding and encoding the known causal relations into a causal network, (2) translating the causal network into a CausalKG, conformant to the causal ontology <ref type="bibr" target="#b5">[6]</ref>, (3) learning KG embeddings for the CausalKG, and (4) predicting new causal links in the KG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Causal Network</head><p>A causal network is a graphical model that describes the causeand-eect relationships between the nodes and is represented as a causal Bayesian network. It is a directed acyclic graph where the nodes of the network denote events and the edges represent the causal association between them. ⇠# = (# 2= , ⇢ 2= ,, 2= ), such that # 2= is the set of nodes in the causal network, ⇢ 2= is the set of edges between nodes, and , 2= is the set of causal weights associated with the edges. The direction of the edge denotes the direction of the causal association. Each edge has a causal weight, F 2 , , which measure the strength of the edge between the nodes. The causal weight represents the total causal eect estimated using do-calculus. The total causal eect is the measure of the strength of the change of a given node on its direct linked node <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. Given an edge, 4 2 ⇢ 2= , between two nodes (= 1 2 # 2= , = 2 2 # 2= ), the total causal eect can be estimated as an expected value (⇢+ ) of intervention on = 1 using do-calculus, ⇢+ [= 2 |3&gt; (= 1 )]. The causal network satises the local Markov property where given the direct causes of a node, it is independent of its non-eects <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Causal Knowledge Graph</head><p>The task of translating information from a causal network into a causal KG is fairly straightforward:</p><p>• # 2= ! # 2 : nodes in the causal network become causal entities in the CausalKG • , 2= ! , 2 : weights in the causal network become causal weights in the CausalKG • ⇢ 2= ! ⇢ 2 : edges in the causal network become causal links in the CausalKG, of the form &lt;= 20DB4 , A 20DB4B , = 4 5 5 42C , F 2 &gt; Additional causal links are added to the KG as appropriate, including those utilizing the other causal relations: 20DB43⌫~, 20DB4B)~?4, and 20DB43⌫~)~?4. The resulting CausalKG contains all the information from the causal network and is conformant to the causal ontology <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>The causal ontology used for this task denes the structure and semantics of causal relations using the concepts grounded in causal AI, i.e causal Bayesian network and do-calculus <ref type="bibr" target="#b5">[6]</ref>. More specically, the ontology denes the primary concepts used to structure a CausalKG, including causal entities, causal relations, and causal weights.</p><p>The CausalKG is used for nding missing causal links using KG link prediction. For the task of causal explanation, the goal is to predict the type of a cause-entity that's linked to an eectentity and not to predict the specic cause-entity instance. However, the eect-entity does not link directly with the cause-entity type. Rather it is connected through a two-hop path: &lt;= 4 5 5 42C , A 20DB43⌫~, = 20DB4 &gt;, &lt;= 20DB4 , A3 5 : C~?4, C~?4&gt;. KG link prediction models can only make predictions about directly linked entities. To overcome this issue, CausalKG uses a reied relation 20DB43⌫~)~?4 (A 20DB43⌫~) ~?4 2 ' 2 ) to add links connecting an eect-entity with the type of a cause-entity (see Figure <ref type="figure" target="#fig_2">3</ref>). The same issue arises for the task of causal prediction where the goal is to predict the type of an eect-entity that's linked to a cause-entity. To overcome this issue, CausalKG uses a reied relation 20DB4B)~?4 (A 20DB4B) ~?4 2 ' 2 ) to add links connecting a cause-entity with the type of an eect-entity.</p><p>The CausalKG can also integrate additional domain knowledge associated with the causal entities which are not explicitly mentioned in the causal network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">CausalKG Embedding and Link Prediction</head><p>CausalKG can be converted into a low-dimensional continuous latent vector space representation, called KG embeddings (KGE). The KG embeddings can then be used for downstream tasks such as link prediction, triple classication, entity classication, relation extraction, etc. <ref type="bibr" target="#b13">[14]</ref>. CausalLP uses KG embedding algorithms to generate embeddings that will be used for nding causal links. The proposed approach learns two types of KGEs for a CausalKG: 1) CausalKGE-Base, embeddings without causal weights, and 2) CausalKGE-W, embeddings with causal weights.</p><p>The CausalKG-W uses causal weight to generate weighted KGEs <ref type="bibr" target="#b9">[10]</ref>. The CausalKG embeddings for both CausalKGE-Base and CausalKGE-W are generated using KG embedding algorithms available in the Ampligraph library <ref type="foot" target="#foot_0">1</ref> . The CausalKGE-Base embedding is trained using the causal links, but ignoring the causal weights associated with each link. The CausalKGE-W embedding, on the other hand, is trained using the causal links with the causal weights. The links with high causal weight will have a high probability of being true. A link with low causal weight signies an unlikely link, and links with causal weight zero are considered as negative samples. During the training, causal weights are used to update the output of the scoring layer of a KGE algorithm before feeding the scores to the loss layer <ref type="bibr" target="#b9">[10]</ref>. The scores from the scoring layer are modulated based on the causal weight values associated with the links to obtain "weighted" scores. The CausalKGE-Base and CausalKGE-W embeddings are evaluated on the task of causal link prediction using KG link prediction techniques. The proposed approach, CausalLP, formalizes the problem of nding missing causal links as a KG link prediction task. The trained CausalKG embedding models, i.e. CausalKGE-Base and CausalKGE-W, are used to predict missing causal links between causal entities in the KG. More specically, CausalLP is used for the task of causal explanation and causal prediction. Causal explanation aims to predict the cause of an eect and causal prediction aims to predict the eect of a cause. For a given causal link, causal explanation predicts links of form &lt; = 4 5 5 42C , A 20DB43⌫~) ~?4 , ?, F &gt;, and causal prediction predicts links of form &lt; = 20DB4 , A 20DB4B) ~?4 , ?, F &gt;.</p><p>Given any dataset, with causal relations, causal entities, and weights associated with the causal links between the entities, CausalDisco can be used to generate a CausalKG and KG embeddings. The generated KG embeddings can then be used for causal relation discovery in the form of causal explanation and causal prediction. In the next section, we demonstrate and evaluate our approach using CLEVRER-Humans, a causal reasoning benchmark dataset <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>The proposed approach is evaluated using KG link prediction task for 1) causal explanation, given an eect-entity predict the type of the cause-entity of the causal link of form &lt;= 4 5 5 42C , A 20DB43⌫~) ~?4 , ?, F &gt; and 2) causal prediction, given a cause-entity predict the type of eect-entity of the causal triple of form &lt;= 20DB4 , A 20DB4B) ~?4 , ?, F &gt; (see Figure <ref type="figure" target="#fig_2">3</ref>). The above experiment is demonstrated using a benchmark dataset for causal reasoning, CLEVRER-Humans <ref type="bibr" target="#b8">[9]</ref>. This section describes the CLEVRER-Humans dataset, data pre-processing steps, creation of a CausalKG from the dataset, experimental set up, evaluation metrics, and description of the evaluation for dierent CausalKG variations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data</head><p>CLEVRER-Humans is a causal reasoning benchmark dataset with human annotated causal judgement regarding physical events occurring in videos <ref type="bibr" target="#b8">[9]</ref>. The dataset is based on the videos from CLEVRER, a simulated dataset of collision events for video representation and reasoning <ref type="bibr" target="#b15">[16]</ref>. The videos consist of moving objects that are distinct in their shape (sphere, cube, and cylinder), color (blue, red, yellow, green, purple, gray, cyan and brown) and material (metal and rubber). Each object can participate in 27 distinct events such as enter, exit, collide, move, hit, bump, roll etc. Figure <ref type="figure" target="#fig_1">1</ref> shows an example snapshot of events occurring in a CLEVRER video. CLEVRER-Humans encodes the causal information from these events in the form of Causal Event Graph (CEG), where the nodes of the graph are descriptions of events in the videos and the directed edges between the nodes represent the causal links (Figure <ref type="figure" target="#fig_3">4</ref>). The edges of the CEGs are scored by human annotators to determine the the strength of causal links between the nodes. The edges are scored between 1-5, such that 1 = not responsible at all, 2 = a bit responsible, 3 = moderately responsible, 4 = quite responsible, and 5 = extremely responsible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Pre-processing the Data</head><p>The rst step towards generation of a CLEVRER-Humans CausalKG involves pre-processing the CEGs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Structure of CEG.</head><p>The CEGs are considered as a proxy for a causal network. The pre-processing of the CEGs are done to ensure that they are consistent with the denition of causal network. The edges in the causal network represents causal links between the nodes. As the rst step, we remove the edges with score 1, as it is determined that there is no causal responsibility between the two given nodes. Next, since a causal network is a directed acyclic graph, the edges responsible for cycles in the CEGs are removed. Finally, we remove the CEGs which 1) do not have any remaining causal links between the nodes, or 2) have depth &lt; 2 from the root node to the leaf node, in order to satisfy the requirement for our Markov-based split. After pre-processing we are left with 764 CEGs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Event extraction.</head><p>The CLEVRER-Humans dataset contains 27 distinct events such as collide, enter, exit, halt, go, etc. We subdivided the events into two categories: binary and singular event. A binary event involves two participating objects, including events such as collide, bump, hit, bounce, sideswipe, etc. A singular event involves only a single participating object, including events such as enter, exit, stop, etc. Information about the event type and participating objects are extracted from the node descriptions in the CEG. This is accomplished by parsing the CEG JSON les provided by the dataset. We use the Berkeley neural semantic parser<ref type="foot" target="#foot_1">foot_1</ref> and NLTK<ref type="foot" target="#foot_2">foot_2</ref> stem lemmatizer to capture the root form of the event label, such as collide, hit, push, etc. instead of collided, hits, pushed, etc. The nodes that include a composition of multiple events, such as The red ball collides with the blue sphere and hits the yellow cylinder which consists of two events (i.e. collide and hit), are removed from the CEG. We are only interested in nodes that describe a single event.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Object and object property extraction.</head><p>Along with the event type, we also extract the participating objects and their characteristics, such as color, shape, and material. There are some object characteristics that are mislabelled in the dataset, such as labeling an object color as gold rather than yellow. These mislabelling issues are identied and the terms are normalized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">CausalKG from CLEVRER-Humans</head><p>A CausalKG is generated from CLEVRER-Humans by encoding the causal information within the CEGs in RDF <ref type="foot" target="#foot_3">4</ref> format, conformant with the causal ontology. In addition to causal relations, the KG contains information about events (such as hit, collide, push, etc.) along with the participating objects and their characteristics. The CEGs are graphical representations of events in the videos. We use three ontologies to represent information from the CEGs: causal ontology, scene ontology (prex so:), and semantic sensor network ontology (prex ssn:). The causal ontology is used to represent the events (as causal entities), causal relations, and their associated causal weights (i.e. edge score). The scene ontology and sensor ontology are used to represent the additional information about the video, including scenes, objects, and object characteristics <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15]</ref>. Each video is represented as a scene (so:Scene) using concepts from the scene ontology. This includes representing and linking the events included in the scene (with the so:includes relation), the participating objects (with the so:hasParticipant relation), and the object characteristics (with the ssn:hasProperty relation) <ref type="bibr" target="#b14">[15]</ref>. In total, the CausalKG from CLEVRER-Humans contains &gt;48K links, 5664 entities, 31 entity types, and 10 relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Splitting the Data</head><p>We introduce a novel dataset splitting approach, Markov-based split, grounded in the local Markov property of causal relations. For the evaluation, we utilise two dierent techniques for splitting the data into train and test sets: 1) random data split and 2) Markov-based data split. In the random data split, the links in the CausalKG are randomly split into train, test, and validation sets following the 80:10:10 split ratio. Depending on which causal links are selected for training and testing, this approach could lead to model bias. For example, given the CEG shown in Figure <ref type="figure" target="#fig_3">4</ref>, and considering the causal prediction query for event G (i.e. predict the type of eect-entity), there are several causal links that may provide relevant causal information (see Figure <ref type="figure" target="#fig_4">5</ref>). Obviously the link &lt;⌧, 20DB4B)~?4, (;834&gt; should not be included in training since this the link to be predicted. Other relevant causal links may also lead to model bias, such as &lt;⌧, 20DB4B, ⇠&gt; and &lt;⇠, 20DB43⌫~, ⌧ &gt;, and should not be in the training set. In general, any causal link in the CausalKG that spans across the Markov-based split line should not be used for training in order to minimize model bias which leads to inated model performance <ref type="bibr" target="#b0">[1]</ref>.</p><p>To mitigate the above issue, we introduce an additional preprocessing step using the Markov-based data split before generating a CausalKG. With the Markov-based data split, the initial train and test sets contains 80% and 20% of the total CEGs, respectively. From the 764 CEGs, 612 are in train and 152 are in test set. Next, the CEGs in the test set are further split at depth 1 from the root node, as illustrated by the horizontal dotted line in gure 4. The split is based on the local Markov property of a causal network; i.e. for a given direct cause of a node, it is independent of its non-eects. The nodes and edges on either side of the horizontal dotted line are denoted as markov-train and markov-test sets, depending on the task, i.e. either causal explanation or causal prediction. For the task of causal prediction, the nodes and relations in the upper half of the Markov-based split are included in the Markov-train set and the lower half in the Markov-test set, and vice-versa for causal explanation. Furthermore, causal links spanning across the horizontal dotted line (represented as red-colored edges in gure 4) are masked and moved to the Markov-test set. The CEGs in the train set, along with the nodes and relations in Markov-train set, are used to generate the CausalKG for CLEVRER-Humans which is then subsequently used for training the KG embeddings. The nodes and relations in the Markov-test are used to generate test links for evaluating the KG embeddings. The respective data splits are fed to the KGE algorithms to generate both CausalKGE-Base and CausalKGE-W embeddings which will be used to for the link prediction task for causal explanation and prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Diversifying the Available Knowledge</head><p>The CausalKGE-Base and CasualKGE-W embeddings are generated and evaluated on dierent CLEVRER-Humans CausalKG subgraph structures for the causal explanation and causal prediction tasks, as shown in Figure <ref type="figure" target="#fig_5">6</ref>. Various graph structures are used in order to evaluate how CausalLP performs when dierent types of information are available in the CausalKG. Specically, there are three distinct sub-graph structures dened with an increasing level of expressivity. The rst graph structure C, shown in Figure <ref type="figure" target="#fig_5">6</ref>(a), contains only links with causal relations. The second graph structure CT, shown in Figure <ref type="figure" target="#fig_5">6</ref>(b), contains links with causal relations and causal entity types (i.e. rdf:type). The third graph structure CTP, shown in Figure <ref type="figure" target="#fig_5">6</ref>(c), contains links with causal relations, causal entity types, and objects related to causal entities (i.e. hasParticipant). We optimized the hyper-parameters for each of the above graph structures for both causal explanation and prediction. The CausalKGE models are trained on their respective optimized hyperparameters. The optimized hyper-parameter can be found here <ref type="foot" target="#foot_4">5</ref> . The trained CausalKGEs are then used for causal link prediction tasks using well established KG link prediction methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Evaluation Metrics</head><p>CausalLP is evaluated by following the KG link prediction experiment design. Given the set of causal links ⇢ 2 in CausalKG, a set of  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULT AND DISCUSSION</head><p>CausalLP is evaluated for the causal explanation and prediction task, using the CausalKG generated from the CLEVRER-Humans dataset. Specically, CasualLP has four trained KGE models:</p><p>• CausalKGE-Base with random data split • CausalKGE-Base with Markov-based data split • CausalKGE-W with random data split • CasualKGE-W with Markov-based data split Figure <ref type="figure" target="#fig_6">7</ref> and Figure <ref type="figure">8</ref> show the MRR scores for the four KGE models evaluated on dierent CausalKG structures, i.e., C, CT and CTP. The MRR scores of CausalKGE-W for causal explanation and causal prediction using the random data split, on average across KGE models, outperforms CausalKGE-Base by 43.26% and 79.26% respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Causal relation: A causal relation A 2 2 ' 2 is a relation representing a causal association between entities. There are four types of causal relations: • 20DB4B (A 20DB4B 2 ' 2 ) is a causal relation from the causeentity to the eect-entity. • 20DB43⌫~(A 20DB43⌫~2 ' 2 ) is a causal relation from the eectentity to the cause-entity; i.e. the inverse of 20DB4B. • 20DB4B)~?4 (A 20DB4B) ~?4 2 ' 2 ) is a causal relation from the cause-entity to the type of the eect-entity. • 20DB43⌫~)~?4 (A 20DB43⌫~) ~?4 2 ' 2 ) is a causal relation from the eect-entity to the type of the cause-entity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 1 )</head><label>1</label><figDesc>Causal prediction: given a cause-entity (= 20DB4 2 # 2 ) and the 20DB4B)~?4 relation (A 20DB4B) ~?4 2 ' 2 ), nd the type (C) of the associated eect-entity such that &lt;= 20DB4 , A 20DB4B) ~?4 , C, F 2 &gt; 2 ⌧ holds. (2) Causal explanation: given an eect-entity (= 4 5 5 42C 2 # 2 ) and the 20DB43⌫~)~?4 relation (A 20DB43⌫~) ~?4 2 ' 2 ), nd the type (C) of the associated cause-entity such that &lt;= 4 5 5 42C , A 20DB43⌫~) ~?4 , C, F 2 &gt; 2 ⌧ holds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Reied causal relation, causesType and causedBy-Type. The causesType is a reied relation from a cause-entity instance to the type of an eect-entity. The causedByType is a reied relation from an eect-entity instance to the type of a cause-entity.</figDesc><graphic coords="4,87.97,129.40,172.74,105.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Causal event graph. The nodes in the graph represent events in a video and the edges represent causal relations. The edge label is a human annotated score symbolizing the strength of the causal relation. For example, the edge from event E to A represents the fact that event E causes event A. The edge label of 5 represents that event E is extremely responsible for causing event A. The horizontal dotted line exemplies the Markov-based split.</figDesc><graphic coords="5,62.21,129.40,225.63,105.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: A snapshot of links in CLEVRER-Humans CausalKG derived from nodes A, G, and C in the CEG illustrated in Figure 4.</figDesc><graphic coords="6,62.21,129.40,235.43,89.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Dierent CLEVRER-Humans CausalKG structures used for evaluating causal explanation and prediction tasks: (a) subgraph C which consists of links with only causal relations, i.e. causes, causedBy, causesType, and causedByType, (b) subgraph CT with causal relations and information about entity types, i.e. rdf:type, (c) subgraph CTP with causal relations, entity type relations, and information about the objects that participate in the causal events.</figDesc><graphic coords="7,62.21,129.40,470.87,105.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Evaluation of KGE models without causal weights (i.e. CausalKGE-Base) and with causal weights (i.e., CausalKGE-W) using dierent CausalKG structures and data split strategies (i.e., random-data split or Markov-based data split): (a) CausalKGE-Base vs CausalKGE-W for causal explanation with random data split, (b) CausalKGE-Base vs CausalKGE-W for causal prediction with random data split, (c) CausalKGE-Base vs CausalKGE-W for causal explanation with Markov-based data split, and (d) CausalKGE-Base vs CausalKGE-W for causal prediction with Markov-based data split.</figDesc><graphic coords="7,62.21,298.49,470.86,197.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="8,62.21,129.41,470.85,197.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>, 2 : a set of edges representing causal links connecting pairs of causal entities. Each causal link is a quad &lt;⌘ 2 , A 2 , C 2 , F 2 &gt;, where ⌘ 2 is the head causal entity, A 2 is the causal relation, C 2 is the tail causal entity, and F 2 is the causal weight.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://docs.ampligraph.org/en/latest/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://pypi.org/project/benepar/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://www.nltk.org/index.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://www.w3.org/RDF/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>https://github.com/CausalKG/CausalLP/tree/main</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The MRR scores of CausalKGE-W for causal explanation and causal prediction using Markov-based data split, on average across KGE models, outperforms CausalKGE-Base by 115.05% and 38.96% respectively. The MRR scores of CausalKGE-W using random-based data split when enriched with additional knowledge for causal explanation,i.e., CTP, on average across KGE models, outperforms C by 33.49%. The MRR scores of CausalKGE-W using Markov-based data split for causal explanation, on average across KGE models, outperforms random data split by 0.75%. The MRR scores of CausalKGE-Base using Markov-based data split for causal prediction, on average across KGE models, outperforms random data split by 15.28%. The MRR scores of CausalKGE-W using random-based data split when enriched with additional knowledge for causal prediction,i.e., CTP, on average across KGE models, outperforms C by 28.65%. Along with the MRR score, we also estimated Hit@k for K. The Hit@1, Hit@3 and Hit@10 of CausalKGE-W for causal explanation using random based split outperformed CausalKGE-Base by 37.28%, 31.10%and 68.2%, respectively. The Hit@1, Hit@3 and Hit@10 of CausalKGE-W for causal prediction using random based split outperformed CausalKGE-Base by 84.22%, 64.62%, and 80.57% respectively. The Hit@1, Hit@3 and Hit@10 of CausalKGE-W for causal prediction using Markov-based split outperformed CausalKGE-Base by 29.91%, 34.33%, and 36% respectively. The Hit@1, and Hit@10 of CausalKGE-W for causal explanation using Markov-based split outperformed CausalKGE-Base by 145.65% and 114.38% respectively.</p><p>The evaluation results show improved performance of CausalLP for causal prediction and causal explanation using CausalKGE-W. However, we observed CausalLP for random-data split outperformed the Markov-based data split for both CausalKGE-Base and CausalKGE-W due to issues of data leakage and model bias <ref type="bibr" target="#b0">[1]</ref>.</p><p>We also noticed adding knowledge to the CausalKG structure, the CausalKGE-W signicantly outperform CausalKGE-Base for both random based and markov based data split.</p><p>We restricted our KGE models to TransE, DistMult, ComplEx, HolE due to the implementation limitation of FocusE. FocusE is implemented in ampligraph. The ampligraph currently supports only the above KGE models. However, in the future, we would like to evaluate and compare FocusE with other KGE models as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this paper, we introduced CausalLP, an approach to nding missing relations in an incomplete causal network using knowledge graph link prediction. The approach addresses a crucial gap in the state-of-the-art by considering causal weights along with a causal links. The KGE models trained with causal weights outperform all baseline KGE metrics without causal weights. The results demonstrate that an eective fusion of causal links with causal weights in a KG can facilitate the completion of sparse KGs that may be missing critical causal relations. In the future, the proposed approach will be extended with a more varied selection of KG embedding models.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Realistic re-evaluation of knowledge graph completion methods: An experimental study</title>
		<author>
			<persName><forename type="first">Farahnaz</forename><surname>Akrami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Samiul Saeef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2020 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="1995">2020. 1995-2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Review of causal discovery methods based on graphical models</title>
		<author>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in genetics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">524</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">KGS: Causal Discovery Using Knowledgeguided Greedy Equivalence Search</title>
		<author>
			<persName><forename type="first">Uzma</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Osman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gani</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2304.05493</idno>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Building a Knowledge Graph of Events and Consequences Using Wikipedia and Wikidata</title>
		<author>
			<persName><forename type="first">Oktie</forename><surname>Hassanzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Wiki Workshop at The Web Conference</title>
		<meeting>the Wiki Workshop at The Web Conference</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Causenet: Towards a causality graph extracted from the web</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Heindorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Scholten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henning</forename><surname>Wachsmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM international conference on information &amp; knowledge management</title>
		<meeting>the 29th ACM international conference on information &amp; knowledge management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3023" to="3030" />
		</imprint>
	</monogr>
	<note>Axel-Cyrille Ngonga Ngomo, and Martin Potthast</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An Ontology Design Pattern for Representing Causality</title>
		<author>
			<persName><forename type="first">Utkarshani</forename><surname>Jaimini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cory</forename><surname>Henson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Sheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th Workshop on Ontology Design and Patterns</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">CausalKG: Causal Knowledge Graph Explainability using interventional and counterfactual reasoning</title>
		<author>
			<persName><forename type="first">Utkarshani</forename><surname>Jaimini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Sheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="43" to="50" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName><surname>Steen L Lauritzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graphical models</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="1996">1996</date>
			<publisher>Clarendon Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">CLEVRER-Humans: Describing Physical and Causal Events the Human Way</title>
		<author>
			<persName><forename type="first">Jiayuan</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuelin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xikun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="7755" to="7768" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Learning embeddings from knowledge graphs with numeric edge attributes</title>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Costabello</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.08683</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Causal inference in statistics: An overview</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Causality</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Semantic Sensor Network Ontology, Revamped</title>
		<author>
			<persName><forename type="first">Kerry</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armin</forename><surname>Haller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxime</forename><surname>Lefrançois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raul</forename><surname>Janowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danh</forename><surname>Garcia-Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Le Phuoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Lieberman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claus</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><surname>Stadler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JT@ ISWC</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding: A survey of approaches and applications</title>
		<author>
			<persName><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2724" to="2743" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Knowledgeinfused learning for entity prediction in driving scenes</title>
		<author>
			<persName><forename type="first">Ruwan</forename><surname>Wickramarachchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cory</forename><surname>Henson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Sheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in big Data</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">759110</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">CLEVRER: Collision Events for Video Representation and Reasoning</title>
		<author>
			<persName><forename type="first">Kexin</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunzhu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
