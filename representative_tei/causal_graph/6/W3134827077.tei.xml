<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fuzzy Stochastic Timed Petri Nets for Causal properties representation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-11-24">24 Nov 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alejandro</forename><surname>Sobrino</surname></persName>
							<email>alejandro.sobrino@usc.es</email>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Santiago de Compostela</orgName>
								<address>
									<settlement>Galicia</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eduardo</forename><forename type="middle">C</forename><surname>Garrido-Merchán</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad Autónoma de Madrid</orgName>
								<address>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cristina</forename><surname>Puente</surname></persName>
							<email>cristina.puente@icai.comillas.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Pontificia de Comillas</orgName>
								<address>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fuzzy Stochastic Timed Petri Nets for Causal properties representation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-11-24">24 Nov 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2011.12075v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Imagery</term>
					<term>causal relation</term>
					<term>fuzzy petri networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Imagery is frequently used to model, represent and communicate knowledge. In particular, graphs are one of the most powerful tools, being able to represent relations between objects. Causal relations are frequently represented by directed graphs, with nodes denoting causes and links denoting causal influence. A causal graph is a skeletal picture, showing causal associations and impact between entities. Common methods used for graphically representing causal scenarios are neurons, truth tables, causal Bayesian networks, cognitive maps and Petri Nets. Causality is often defined in terms of precedence (the cause precedes the effect), concurrency (often, an effect is provoked simultaneously by two or more causes), circularity (a cause provokes the effect and the effect reinforces the cause) and imprecision (the presence of the cause favors the effect, but not necessarily causes it). We will show that, even though the traditional graphical models are able to represent separately some of the properties aforementioned, they fail trying to illustrate indistinctly all of them. To approach that gap, we will introduce Fuzzy Stochastic Timed Petri Nets as a graphical tool able to represent time, co-occurrence, looping and imprecision in causal flow.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Imagery and causality</head><p>Since ancient times, imagery has been used to illustrate concepts and actions <ref type="bibr" target="#b42">[43]</ref>. In the very beginning, even if in a rudimentary form, cave paintings schematically represented cognitions about hunting or agricultural activities <ref type="bibr" target="#b1">[2]</ref>. In latest times, automata theory or Chomsky syntagmatic grammar are examples of imagery tools dealing with abstract theories and deep concepts <ref type="bibr" target="#b5">[6]</ref>. Thus, the Turing machine as a central computing unit moving left and right on an infinite tape according to a program pictorially illustrates the universal concept of computability <ref type="bibr" target="#b35">[36]</ref>. In the same way, Chomsky's syntagmatic trees illustrate the geometry of the sentences, depicting the node dominances that a flat description is not able to portray.</p><p>Imagery language is often opposed to verbal sentences, although both aim to mirror the structure of our thoughts <ref type="bibr" target="#b25">[26]</ref>. Oral language, and especially its complement writing, was linked to the social demands of exchange control, codifying laws or recording history in a reliable and precise way. In the scientific area, the relevance of writing was reflected in the name adopted by a prominent school in Philosophy of Science, e. g., 'the statement view'. But as Popper said (1963:28) <ref type="bibr" target="#b27">[28]</ref>: "although clarity is valuable in itself, exactness or precision is not". Under the influence of iconoclastic religions, words have been considered since the Renaissance as the precise way to express thought, but lately the role of images as a source of clarity has been vindicated. Thus, for the Larkin &amp; Simon view <ref type="bibr" target="#b17">[18]</ref>, imagery has advantages, favoring gathering information about a single element by perceiving at a glance its role in the net, and so, facilitating perceptual inferences, quite familiar to human beings and generally difficult to obtain by other means. Imagery and written language work in different ways: while imagery illustrates topological relations, texts show sentence concatenations, but both contribute to the knowledge acquisition, as Paivio <ref type="bibr" target="#b26">[27]</ref> pointed out in his Dual Coding Theory. In his view, cognition uses two different subsystems: the imagery one, based on the observation of objects and events and the relations among them, and the verbal one, attaching the representations in texts.</p><p>Aristotle advocated imagery as a tool for representing any kind of knowledge, being concrete or abstract <ref type="bibr" target="#b2">[3]</ref>. On the contrary, Kant supported that images are suitable to represent perceptual information, but not abstract ideas <ref type="bibr" target="#b36">[37]</ref>. Between them, a new point of view can be considered: the third-person imagery <ref type="bibr" target="#b24">[25]</ref>. That approach changed the focus from a concrete or individual view to a general or collective one, demanding a look from an third or neutral observer, and so validating the role of imagery supporting abstract thoughts. We join the Aristotle view about the functional role of imagery representing human knowledge, being concrete or abstract if the third-person view is adopted. In this view, images have a double role: they outline the essential traits of knowledge and make easier to remember them <ref type="bibr" target="#b26">[27]</ref>.</p><p>Causality, a main characteristic of science, makes an extensive use of images through graphs, a kind of pictures showing the cause-effect link typical of many human cognitions or explanations <ref type="bibr" target="#b7">[8]</ref>. Agreeing with the third-person imagery, causal graphs permit to represent type and token causal relations, the latter considered as prototypes of the particular problems they illustrate. Causal graphs, a kind of imagery representation, provide insight views of causal problems, separating the wheat from the chaff, and supplying adequate explanations of intricate puzzles, illustrating how a node is causally reached from the parent ones.</p><p>Causality is about causal relations, frequently addressed mathematics, philosophy, ecology, economy or psychology <ref type="bibr" target="#b3">[4]</ref>. These subjects used verbal descriptions or mathematical equations to gather causal knowledge. But graphics are not an exception: Philosophy or computational approaches make an extensive use of them. In the sequel, we will show the role of graphs explaining some causal properties associated with some well-known causal puzzles.</p><p>2 Properties of causal relations: time, concurrency, feedback and imprecision.</p><p>A causal relation, e = r(c) : c ∈ U c , e ∈ U e , U c → U e , represents a link between the cause c (simple or complex that belongs to some set U c of causes), and the effect e, provoked by the cause that belongs to a set U e . The intersection between sets U c and U e can be void ∅, can have some elements in common or both sets can be equal U c = U e , depending on the problem. Given the representation of a particular problem, we could have that an effect e j of a cause c j , modelled by the causal relation j, can be the cause c i of another effect e i of a causal relation i. Hence, causes c and effects e are properties of objects o. From now on, we will talk about objects, where being a cause or effect is a semantic property of them. Causality is often represented by causal graphs. A causal graph is a pair G = (V, E) where V is a set whose elements are called vertices, that are the previously defined objects, and E is a set of causal directed relations between pairs of objects that represent the causal semantic information of these objects. E is, for a given problem, then a subset of the relations given by the set of all possible relations between all the objects in a problem U e = r(U c ). A graph is a visual tool for illustrating associations between objects using nodes and directed arrows. The arrows show the link between the cause and the effect, and its direction, the flux of the causal influence. Graphs illustrate paradigmatically the connection from cause U c to effect U e .</p><p>If we define a causal relation by an edge e of the causal graph, this object has four different properties. Inter alia, causal relations E, representing real world problems, are sensitive to time e t , concurrency e c , feedback e f , and imprecision e i . We define these properties below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Time</head><p>Let us consider that X is a cause of Y given a relation r. A causal relation r(X, Y ) is also a function of time, T . That is: r(X, Y, T ), where T is the time spent between the event X generates the event Y . Regarding time, according to Taylor <ref type="bibr" target="#b40">[41]</ref>, causal relations ,E, satisfy the following properties: Irreflexivity: Nihil is causa sui. That is, we can not have X → X, or r(X, X, T ), because the sequence would be infinite. Anti-symmetry: Provided that X and Y are distinct, if r(X, Y, T ), then we can not have r(Y, X, T ), again, because the sequence will also be infinite.</p><formula xml:id="formula_0">Precedence: If r(X, Y ), then X precedes Y . That is, X ∈ pa(Y ).</formula><p>Precedence in causal relations shows the arrow of time: from cause to effect and not the reverse. Even if time is a key factor in causation, it is important to remark that it is not always considered by the usual graphical tools that represent causality, as we will see later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Concurrency</head><p>Frequently, an effect Y demands the simultaneous presence of several causes; i. e., causality is often pluri-causality and concurrency is a type of that. We will denote the set of direct causes X of an effect Y as the one retrieved by the function pa(Y ). We define that a cause X is direct of an effect B if a single edge is needed to link both objects in a causal graph G(V, E). In this paper, we use concurrency to denote co-occurrence of causes. Plural causality was paradigmatically addressed by INUS causality <ref type="bibr" target="#b20">[21]</ref>. Typically, an effect Y has a lot of causes X, some of them possibly grouped into clusters X j . Each cluster X j is sufficient, but not necessary, to provoke the effect Y , that is, r j (X j , Y )∀j where j is the index of a cluster. Causes X j are groups of single factors X and each factor X is an INUS (Insufficient but Nonredundant part of an Unnecessary but Sufficient) condition for the effect Y . Each cluster X j is a set of concurrent factors X able to provoke the effect Y . At the end we have that pluri-causality relations r can be all represented as:</p><formula xml:id="formula_1">∨ J j=1 (∧ I i=1 X i ) j → Y where X i is an INUS, (∧ Ij i=1 X i ) j =</formula><p>X j is a sufficient, but not necessary cluster, J is the number of clusters and I j is the number of INUS for a cluster j. Concurrency of causes is typical in causal scenarios, but it is not addressed by all causal graphs, as we will show below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Feedback</head><p>A causal process r(•, •) frequently shows mutual influence. If an element X influences itself directly or indirectly, this is referred to as a causal loop, i.e., a closed cause/effect feedback X → • • • → X. There are two main classes of causal loops: In positive feedback loops, the loop leads to a reinforcing feedback as cycles increase more and more. Consider f (x), g(y) as functions of random variables and the graphical model f (x) → g(y) → • • • → f (x), where • • • can be from zero to an indeterminate number of functions. If we define i ∈ Z as the i iteration of the execution of every function of the graphical model f and g, then, the positive feedback loop will always comply, for every one of its functions f : f (x|i = j + 1) &gt; f (x|i = j). On the other hand, in negative feedback loops, the loop f (x) → g(y) → ••• → f (x) seeks an equilibrium balancing the fluctuations in the output: if the output increases, the causal loop pushes the input value down and if it decreases, it pushes the value up. Id est, E(f</p><formula xml:id="formula_2">(x|i = j + n)) = f (x|i = j)</formula><p>where n, j ∈ Z.</p><p>A special type of negative feedback is the one that involves a time delay. A delay happens when it takes time before the effect plays out. In this case, the feedback signal can arrive later, turning a positive feedback into a negative one. E. g., sales increase orders, and more orders favor more sales, but if orders are delayed (dotted line), sales may fall. Time delay breaks the balance. Feedback is prevalent in economic or ecologic scenarios, where the notions of reinforcement or balance have a relevant role. Finally, another property emerges if causation is empirically scrutinized:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Imprecision</head><p>Causes X, effects Y and cause-effect links r(x, y) : x ∈ X, y ∈ Y are often qualified by degrees ∈ [0, 1] (percentages) or if the causal relation representation is a text: adverbs w. These adverbs can be modelled by point estimations ∈ [0, 1] or, as we will later describe, by probability distributions p(w) or fuzzy functions f (w). These objects denote a measure of frequency, intensity, or strength, that can be represented by point estimations or different probability mathematical objects. Let us define a causal sentence as a text representation T that includes a semantic meaning involving a causal relation between objects r(X, Y ). Causal sentences t automatically mined from the short papers included in Hawking's Physics Colloquium <ref type="bibr" target="#b30">[31]</ref> show that, even in hard science, causal descriptions are not crisp, but imprecise, in so far as the causal links are frequently tinged with semantic hedges or vague adjectives, as 'too', 'definitely' or 'nearly'. Thus, physical causality is frequently rather approximate than categorical. As we will further see, we can model these adverbs a, by point estimations ∈ [0, 1] representing an adverb by a precise degree of uncertainty. As language is imprecise and depends on context, the time frequency adverb a, given by its signficant, may provide a plethora of significances, that is why Garrido <ref type="bibr" target="#b9">[10]</ref> represents these adverbs by probability distributions p(a|Θ), as we will further see.</p><p>Despite the empirical support, vagueness or imprecision have not always accommodation in the typical graphs representing causality. Concurrency, time, looping and imprecision seem to be usual and relevant aspects involved in many causal processes but insufficiently addressed by graphical methods. Neurons, bayesian networks, cognitive maps or probabilistic causal graphs supply tools for depicting positive, negative, proximate, uncertain, distant and single or plural causality, but neurons exclude imprecision, bayesian networks do not take time into account, cognitive maps do not consider independence in concurrent causality and probabilistic causal graphs do not consider feedback loops. In this paper, we will propose the Fuzzy Stochastic Timed Petri nets (FSTPN) <ref type="bibr" target="#b19">[20]</ref> as a tool that can contribute to represent co-occurrence, time, feedback and imprecision in causal flux. Although co-occurrence is an aspect inherent to basic Petri Nets (PN) (Murata, 1989), time was only incorporated in a later evolution of them known as Timed PN (TPN) <ref type="bibr" target="#b22">[23]</ref>. It should be mentioned that, although TPN still lack mechanisms to deal with imprecision, FSTPN can represent the vagueness involved in the probability of the transitions firing. Thus, FSTPN seem to be a useful tool for representing concurrent systems accounting for time parameters and fuzzy probabilistic causal influences. To accomplish this aim, the rest of the paper is structured as follows: First, traditional visual methods for representing causality are presented. Then, we illustrate deficiencies of the aforementioned methods. We provide a fuzzy stochastic timed Petri nets overcome these issues. Lastly, we summarize the contributions of the proposed method.</p><p>3 Graphical methods for representing causal relations.</p><p>We introduce a review of graphical causal methods that represent some of the properties of causal relations that we have described previously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Neurons.</head><p>Neurons were firstly considered by Lewis <ref type="bibr" target="#b18">[19]</ref> as a way to represent causal relations c(•, •). A neuron N is an oriented graph N (V, E) with nodes V denoted by circles symbolizing the cause x ∈ V or the effect y ∈ V and causal links • → • depicting the causal influence X → Y ∀X, Y ∈ V . Circles are usually labeled with lower case letters. Circles may be shaded or not. If shaded, that we will represent as a normal cause X they are actives and, thus, ready to transmit a causal influence X → Y ∀X, Y ∈ V . If not (in blank, that we will represent as X) they are inoperative and cannot pass any influence to the connected nodes V . Links between nodes • → • are represented by arcs →, which can end in an arrow, which we will represent as •</p><p>•, or in a circle, that we will represent as</p><formula xml:id="formula_3">• •. If ended in an arrow, a connection X Y is stimulatory; if finished in a circle X Y , inhibitory. Let us suppose an arrow that connects a node X with a node Y , that is X → Y . The arc stimulates X Y or inhibits X Y only if X is active, not inactive X. If Y receives both a stimulatory X</formula><p>Y and an inhibitory arrow Z Y , inhibition cancels stimulation. Briefly, neurons satisfy the following principles: A neuron X is activated if it is stimulated by at least another neuron Y X and is not inhibited by any other neuron Z Y . A neuron X is not activated X if it is inhibited by one or more neurons Y X. Lastly, the start neurons have no outside connections. They are active if they are shaded.</p><p>Neurons admit neither time nor imprecision and although they accept pluricausality, using the syntax of neurons we cannot force the concurrence of two or more nodes causing the effect. If a node is active, it can cause the effect by itself, the other node is not necessary. But in many causal scenarios, the joint contribution of two or more causes for reaching the effect is demanded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Boolean functions.</head><p>Representing cause X and effect Y , Boolean functions f (b) involve binary values b for variables and logic formulas for modeling indicative or factual causation. Variables are supposed to be independent of each other, X ⊥ ⊥ Y , and the causal influence is calculated in terms of the present (1), X, or absent (0), X, causes, provoking (1), Y or not (0) the effect Y . For example, let us suppose that a surgical team consists of 4 persons (A, B, C, D), one of them being the chief surgeon (A). The decision to perform a surgery on a patient (S) is made by simple majority and the vote of the chief surgeon has a double value in case of a tie. The following formula f(b) represents the approval of the action:</p><formula xml:id="formula_4">(¬A∧B∧C∧D)∨(A∧¬B∧¬C∧D)∨(A∧¬B∧C∧¬D)∨(A∧¬B∧C∧D)∨ (A∧B∧¬C∧¬D)∨(A∧B∧¬C∧¬D)∨(A∧B∧C∧¬D)∨(A∧B∧C∧D).</formula><p>So, the action is caused if A does not vote positively but B, C and D do or if A and D vote positively but B and C do not. The previous canonic formula is a maxiterm that can be shortened into an equivalent one using minimization algorithms, as the Quine-McCluskey method <ref type="bibr" target="#b31">[32]</ref> or the Karnaugh maps <ref type="bibr" target="#b14">[15]</ref>. Boolean functions f (b) do not show dependencies between indirect causes nor approach time or imprecision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Causal Bayesian networks.</head><p>Bayesian networks are probabilistic graphical models G(V, E) that use Bayesian inference for the computation of the probability of an effect Y given causes X where all the causes and effects are modelled by random variables <ref type="bibr" target="#b13">[14]</ref>. Concerning the described properties of causal relations introduced in the previous section, Bayesian networks try to overcome the limitations of Boolean functions mentioned above by: Detecting the indirect influence of a cause X in the rest of the graph G. Representing imprecision or uncertainty, using random variables p(x), generally associated to Gaussian distributions. Checking independence between variables in the causal process. Concretely, the absence of edges E on bayesian networks model conditional independences between causes and effects.</p><p>Indirect influence depends on the dependency diagnoses between random variables, changing according to: The interventions made on the graph G and the structure of the graph given by its edges. An edge between a cause X and an effect Y is modelled by a factor P (Y |X) of the joint distribution modelled by the Bayesian network.</p><p>A Bayesian network represents independence of events using conditional probabilities P (•|•). Formally, a Bayesian network is a directed acyclic graph (DAG) G(V, E) that models a joint distribution of conditional distributions. The nodes V represent events that are modelled by random variables and the directed arcs E represent causal relations or factors that appear in the joint probability distribution. Nodes are labeled with variables (capital letters) and variables can be instantiated to data, by sampling over the probability distributions p(•) that are associated to the random variables modelled by the nodes. The root nodes (parent nodes pa(X) of a random variable X) are modelled with a priori probabilities p(X|θ), where θ is the set of a priori parameters of the probability distribution p(X) and the children nodes with conditioned probabilities p(Y |pa(Y )), which represents the probability of a node conditioned upon its parents pa(•). Independence is adequately illustrated by conditional probability: X is probabilistically independent of Y conditioned on Z if ∀X, Y, Z, P (X|Y, Z) = P (X|Z); e. g., once the Z value is known, the value of Y does not change the probability of X. But independency diagnosis can vary, ibid, if interventions are performed on the nodes, as we will further observe.</p><p>Consider a graph representing the following causal relations B → A, C → A, A → E. The effect A is represented by the conditional probability p(A|B, C) , id est, A is caused by B or C, having B ⊥ ⊥ C, since there is no arrow from B to C or vice versa. Nonetheless, we can conjecture that there be some relationship between B and C because both events are causes of A. Suppose that we check A and observe that it happens. In that case, knowing the value of one of the causes (e.g., B) informs us about the other cause (C), opening now a communication between them. Even though causal Bayesian networks deal with imprecision through probability distributions and independency diagnoses in causality, they do not address time and feedback influence. But causal loops are usual in social and ecological scenarios, where, in addition, time plays a key role.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Fuzzy cognitive maps.</head><p>First approached by Tolman <ref type="bibr" target="#b41">[42]</ref>, a cognitive map M is a graphical tool for the spatial representation of a situation, favoring, at a quick glance, the identification of the items i involved in the scene as well as the links e ij between them, where e ij is a link from the item i to the item j. Later, Axelrod <ref type="bibr" target="#b0">[1]</ref> used cognitive maps to represent political scenarios with various events or agents causally linked. Kosko <ref type="bibr" target="#b16">[17]</ref> extended cognitive maps to fuzzy cognitive maps in order to host imprecision and uncertainty, characteristic of many daily settings. In so far as the multiple-valued or fuzzy cognitive maps include the Boolean ones as a particular case, next we will address the more general case. Fuzzy cognitive maps are graphs G(V, E) with nodes V labeled by concepts. A concept v i consists of a modifier, often an adjective or a noun, and a quantity (or its negation), usually an adverb. For instance, social stability, instability can cause increasing, decreasing of prices, being stability, instability; increasing, decreasing quantities and social, prices modifiers. Like Bayesian networks, fuzzy cognitive maps illustrate causal influences r(v i , v j , c) from a cause v i to an effect v j decreasing, being neutral or increasing, which is given by the categorical variable c = [+, -, •], but unlike Bayesian networks, they score the causal impact using ordinate values [+, -, •], and not a measure of probability b ∈ R [0,1] . As it has been described, influence admits three valuations: (a) positive (favoring the effect, +), (b) negative (inhibiting the effect, -) or (c) neutral (causing no influence on the effect, no mark). Thus, initially, fuzzy cognitive maps used a trivalent logic, a special type of fuzzy logic for representing the causal influence.</p><p>Kosko <ref type="bibr" target="#b16">[17]</ref> expanded the qualification of the causal influence from threevalued logic [+, -, •] to infinite valued one and later, to a linguistic-valued fuzzy logic. Regarding infinite valued logic, the links can take values in the interval e ∈ R [-1,1] : the sub-interval e p ∈ R (0,1] denoting positive causality, the interval e n ∈ R (-1,0] negative causality and the value 0 the absence of causal influence. Thus, -0.2 denotes a small negative causal influence and 0.6 means a rather positive causal influence.</p><p>Values are aggregated using t-norms and t-conorms, a class of binary operators to model conjunction 1] • in multiplevalued and fuzzy logic <ref type="bibr">(Nguyen, 2006)</ref>. Typical norms are min(x, y) (minimum or Gödel t-norm), x • y (product t-norm) or max(x + y -1, 0) (Lukasiewicz t-norm) and typical t-conorms are max(x, y) (maximum or Gödel t-conorm), x + y -x • y (product t-conorm, probabilistic sum) or min(x + y, 1) (Lukasiewicz t-conorm, bounded sum).</p><formula xml:id="formula_5">•∧ ∈ R [0,1] • and disjunction •∨ ∈ R [0,</formula><p>The most genuinely fuzzy extension of fuzzy cognitive maps was the linguisticvalued one <ref type="bibr" target="#b16">[17]</ref>. Now, the links E between nodes V are labeled with fuzzy quantifiers q ∈ R [0,1] that are associated with an adverb a i → q i (many, most, a lot, etc.) that are aggregated using t-norms and t-conorms quoted above.</p><p>Managing linguistic values, fuzzy-valued cognitive maps facilitate knowledge representation and inference in a human style, furnishing a flexible and realistic tool for handling vague causal influence. Ecological or political systems, areas of frequent fuzzy cognitive maps applications <ref type="bibr" target="#b15">[16]</ref>, are largely dependent on time.</p><p>For instance, geopolitical influence systems are chronologically dependent. Fuzzy time cognitive maps, first approached by <ref type="bibr" target="#b10">[11]</ref>, included temporary annotations t xy in relations between nodes X → txy Y , denoting a delay t xy before the effect Y is reached.</p><p>In fuzzy time cognitive maps, directed arcs X → Y can denote positive R ∈ [0, 1] or negative causal influence R ∈ [-1, 0] from the cause X to the effect node Y , and the delay is represented by t ∈ Z. Numbers denoting time delays can be understood to represent time according to units as hours, days, etc. Fuzzy time cognitive maps illustrate imprecision, loops and time in causal links, but not concurrency, while there is no way to ask the joint action of two or more causes for achieving an effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Probabilistic causal graphs for representing causal text</head><p>sentences.</p><p>Text causal sentences are representation that often involve a set of causes X and effects Y and a time frequency adverb a that expresses how probable is that, given the set of causes X, the set of events Y occur. We can also represent that information, as we have seen, in a probabilistic causal graph G(V, E).</p><p>An important issue happens when we have several text causal sentences concerning the same cause and effect but a different time adverb a. If we want to build a knowledge graph that represents the average time frequency of the event Y given by the cause X, that is p(Y |X), and we have processed text causal sentences with different adverbs, then, how do we properly represent that uncertainty? If the same adverb a, depending on the context, maps to a different degree of uncertainty, how do we properly represent that?</p><p>Garrido <ref type="bibr" target="#b9">[10]</ref> proposed an ad-hoc approach by using a slight modification on Bayesian networks to deal with an accurate model to represent that information, applying it to the detection of fake news <ref type="bibr" target="#b8">[9]</ref>. In a first step <ref type="bibr" target="#b21">[22]</ref>, a process retrieved all the causal sentences w of a text and stored the most representative ones as cause, effect and modifier tuples (c, e, m) <ref type="bibr" target="#b28">[29]</ref>  <ref type="bibr" target="#b29">[30]</ref>. With that tuples w, we can build a weighted graph G(V, E) where causal relations r(c, e, m) are weighted by a quantity m ∈ R [ 0, 1] representing uncertainty. The model let us compute the probability of an event Z that was not directly a cause of an effect X but an indirect one linked by other set of causes. For example, if we have</p><formula xml:id="formula_6">X → Y → Z, we can compute p(Z|X, Y ) as p(Z|X, Y ) = p(Z|Y )p(Y |X). More generally, p(Z|X n , ..., X 1 ) = p(Z|X n ) n-1 i=1 p(X i+1 |X i ).</formula><p>The difference with Bayesian networks is that we are specifically modelling the probability of the connection between two causes and not the probability of the cause as if it was an event. In bayesian networks, we are modelling p(X), here, we just assume that p(X) = 1.</p><p>The previous approach was enhanced <ref type="bibr" target="#b9">[10]</ref> as the probability of a link was being modelled by a point estimation m ∈ R [ 0, 1] and, depending on the context where the adverb appear, this m can vary. To model this uncertainty, we associated to each adverb a a probability distribution p(m), typically a Gaussian, associated m to the mean of the distribution and also providing a standard deviation to represent the uncertainty of the adverb. Each link p(Y |X) is a joint probability distribution of all the tuples t retrieved from text where we can find an effect Y , cause X and an adverb m that is converted into a probability distribution p(m). Then, p(Y |X) = n i=1 p(Y |X, m i ), id est, we are marginalizing the adverbs, generating a joint probability distribution of all the causal sentences involving Y and X. We can still compute p(Z|X n , ..., X 1 ) = p(Z|X n ) n-1 i=1 p(X i+1 |X i ) as in the previous approach or sample a point estimation of the uncertainty of an indirect effect by sampling the first cause relation and then following the link of events.</p><p>The new approach can represent time, in the sense that a new causal text modify each link p(Y |X) by adding a new factor p(Y |X, m i ) but not by having a representation t of the delay. This approach does also not solve feedback lops, as it assumes that there does not exists tuples as r(c, e, m) in the texts. Having reviewed all the most important causal graphical models, we have shown that none of them accurately model the properties mentioned in Section 2, being necessary the proposal of a new graphical causal model that represents them. <ref type="bibr" target="#b3">4</ref> Causal puzzles refractory to be adequately represented by standard graphical tools.</p><p>In spite of the fact that concurrency, time, loops and imprecision are frequent in classical causal puzzles, traditional graphs show limits representing them. In this section, we mention some examples illustrating the deficiencies of the described methods. Regarding concurrency and time, neurons have the problem of symmetrical and asymmetrical overdetermination. Concerning imprecision and time, causal Bayesian networks have the fizzling and trumping issues.</p><p>Let us describe the symmetrical overdetermination problem. A causal scenario is over-determined when the effect is caused jointly by two causes <ref type="bibr" target="#b34">[35]</ref>. Suppose that, for being cured, the joint action of two drugs a and b are needed. For instance, for curing Helicobacter Pylori, clavulanic acid and amoxicillin must be administered (a ∧ b → c). According to the posed problem, c demands the concurrency of two causes (a and b) to be activated. But attending the definition of neuron, it is not possible to guarantee that. Since a and b nodes are active, the link is stimulatory in both cases and c is activated independently by a or by b.</p><p>On the other hand, we have the asymmetrical overdetermination issue. A situation is asymmetrical over-determined when a cause c preempts the other to provoke the effect e <ref type="bibr" target="#b11">[12]</ref>. For example: Let a and b be two incompatible drugs, each of which is sufficient to mitigate an illness. Choosing one of the two drugs means forgetting the other, avoiding thus possible adverse reactions. The effect may be caused by two factors inhibiting each other; so, if they were activated at the same time, the effect vanishes. Time and anticipation are essential in this example to achieve the effect on a track. But anticipation is not considered by neurons.</p><p>Having reviewed the problems with neurons, now we illustrate issues of causal Bayesian networks. Imprecision in causal flux are addressed by Bayes Nets in a probabilistic frame. Suppes <ref type="bibr" target="#b38">[39]</ref> coined positive causality posing that a cause provokes an effect if it increases its probability: i.e., C causes E if P (E|C) &gt; P (E). This postulate has been questioned and the following are some of the most common objections. They fall mainly into two categories. First, fizzling, where a cause may be less likely than other one and yet being the cause of the effect. Second, trumping, where a cause may be as likely as the other one and nevertheless failing to contribute at all to the effect.</p><p>The first case, known as fizzling, refers to a very probable causal factor that contributes to the effect without being its cause. To illustrate this puzzle, a variant of the preemption story was presented: a is a quiet and responsible person and b a very known vandal. Both a and b have a stone in hand and a lamppost in front of them. The probability that the lamp suffers a damage (D) is greater in the presence of b that by the presence of a. In any case, the probability that b breaks the lamp is less that 1 and the probability that a does the same is greater that 0. If a throws the stone, inhibit the action of b, who presumably will desist from throwing his stone if the lamppost is already broken. Let suppose that, in an unexpected rage behavior, a throws the stone against the lamppost breaking it. Although it was more likely that b broke the lamp, it was a who did. Of course, the fizzled disposition of b it was not the cause of the breakage of the lamppost, but its presence increased the probability of such event. Moral: the presence of b favors the effect, but is not sufficient for its causation. Anticipation is determinant for the causal assignment. In the previous story, Bayesian Nets do not consider temporal precedence.</p><p>Trumping shows that even two causes being equally likely to produce the effect, the cause that happens before surpass the other, becoming the actual cause. The effective cause is sufficient, but not necessary, for causing the effect. The next story illustrates trumping <ref type="bibr" target="#b33">[34]</ref>: In a magical land are two wizards, Merlin (Me) and Morgana (Mo). Each of them can throw a spell on the Prince, turning him, at midnight, a frog. The laws of magic say that the first spell to occur during the day will be the one that causes the effect. And it is a matter of fact that Merlin casts his spell (S M e ) in the morning and Morgana (S M o ) in the afternoon. At midnight the Prince turns into a frog (F P ) and there is no doubt that Merlin's spell was the cause. Merlin's action did not disable the Morgana's one; if one of them has no effect, the other does. Although both are equally likely to cause the effect, Merlin preempts Morgana acting before. Merlin is the cause even if he had the same probability as Morgana to provoke the effect. Using Bayesian causal networks, a possible representation of this puzzle is shown in Figure <ref type="figure" target="#fig_0">1</ref>, left: This network is an example of converging connection or explaining away. Recall that causal converging links say that if a node conclusion changes certainty because receives evidence, it opens the communication between its parents. Related to the above graph, if about F P we only know that it may be caused from S M e or S M o , their parents are independent, i.e, to have evidences about one of them as a possible cause do not change the certitudes about the other (knowing that Merlin casts the spell does not indicate anything about Morgana's behav- ior). But if some evidence about F P is provided and information about one of the causes is available, the potential influence of the other cause can be reassessed. In the above graph, if we know that the Prince is now a frog and that is due to the Merlin's spell, then the confidence in Morgana as a possible cause diminishes (who first spell disallows the other and the only chance for Morgana is to act at the same time as Merlin does, although this case is not considered in the puzzle). In order to represent the Merlin's temporal precedence as a preemption factor for the Morgana's action, we may be tempted to modify the previous network and replace it with the network shown in Figure <ref type="figure" target="#fig_0">1</ref>, right. But causal Bayesian networks are governed by the following postulate: if evidence is provided about a node, the causal arrows reaching it are deactivated but all that start from it remain active. Instantiating the node S M e means breaking the relation with the node Me but maintaining the causal flux from S M e to S M o and F P , even if the arrow is excitatory in both cases and it does not cancel the node S M o as a possible influence of F P . In causal networks inhibitory links have no representation. 'Acting before' is key to correctly interpret that puzzle, but inhibitory arcs and temporal precedence has no representation in standard causal Bayesian networks. Petri Nets contribute to solve those deficiencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">A Fuzzy Stochastic Timed Petri Net approach.</head><p>A Petri net (PN) is a graphical tool for modeling dynamic processes. A PN <ref type="bibr" target="#b39">[40]</ref> is a DAG showing the following components. Tokens representing resources in a broad sense, being physical or intangible, denoted by black dots. Places are locations where tokens are stored waiting to be transferred, denoted by a small circle. A circle containing a dot represents a place containing a token. Lastly, transitions, depicting changes in the status of the places and their tokens, representing actions and places, conditions. Places are connected with transitions by directed arrows. Let t be a transition. Each place p having an arrow from p to t is an input place of t. Each place p having an arrow from t to p is an output place of t. Places are marked with tokens. A transition is enabled, for a given marking, if and only if all its input places have at least one token. Once a transition is fired, a token from each of its input places is removed and a token to each of its output places is added. So, if a transition is enabled, a new marking is reached, performing the dynamic behavior of the net.</p><p>Formally, a PN is a quintuple P N = (P, T, I, O, M 0 ), where: P = {p 1 , p 2 , ..., p m } is a finite set of places. T = {t 1 , t 2 , ..., t n } is a finite set of transitions, P ∪ T = ∅. I : (P xT ) → N, is an input function defining directed arcs from places to transitions. I(t i , p j ) represents the number of arcs connecting a place p j with a transition t i . O : (T xP ) → N, is an output function defining directed arcs from transitions to places. O(t i , p j ) represents the number of arcs connecting a transition t i with a place p j . Parallel arcs connecting a place to a transition or vice versa are represented by a single directed arc labeled with its weight, w. If w = 1, the arc is not labeled. M 0 : P → N is the initial marking.</p><p>Marking is the number of token in places. Once a PN is executed, the number and positions of places dynamically change according to the transition firing, governed by the enabling rule and the firing rule, both managing the flows of tokens in the net:</p><p>A transition t is enabled if the number of tokens of each input place p of t is greater than or equal to the weight of the directed arc connecting p to t. On the other hand, a transition t is enabled if the number of tokens of each input place p of t is greater than or equal to the weight of the directed arc connecting p to t.</p><p>A transition without any input place is a source transition and one without any output place is a sink transition. A source transition is unconditionally enabled and the firing of a sink transition consumes but does not generate any token.</p><p>Consider the following PN illustrated in Figure <ref type="figure" target="#fig_1">2</ref>, left: The initial marking M = (p 1 , p 2 , p 3 , p4) of the PN corresponding to figure 12 is M 0 = (2, 2, 0, 0). t 1 is the only transition enabled. Firing it, we reach a new marking M 1 = (0, 1, 1, 0, 0). Now, t 2 or t 3 can be fired. If t 2 is activated, the new marking is M 2 = (0, 1, 0, 1, 0) and if t 3 is fired, M 3 = (0, 1, 0, 0, 1).</p><p>PN can be used to model realistic problems as the next one of the job offer and demand. Imagine a situation in which there is a permanent job offer and three demands of employment, represented by Figure <ref type="figure" target="#fig_1">2</ref>, right.</p><p>The initial marking is M 0 = (3, 1, 0, 0) and t 1 is the only transition enabled. Firing it, a new marking M 1 is reached: M 1 = (2, 0, 1, 0). Now, t 2 and t 3 are enabled, getting the new marking M 2 = (2, 1, 0, 1). Enabling t 3 assures a permanent job offer to every possible demand as the loop suggest. It can be easily seen that the described Petri Nets can model prototypical scenarios of dynamic systems like the following ones: representing a sequential execution where transition t 2 can be enabled only if another transition t 1 is fired. The temporal constraint 't 1 precedes t 2 ' or 't 2 after t 1 ' can be modelled. They can model a case of conflict: both transitions are enabled by the place p 1 , but the firing of one of them disables the other. In this case, assigning probabilities is a usual way to decide in case of conflict. Petri Nets can also symbolize concurrency, e. g., processes that cooperate to achieve a common goal: the firing of a transition t 1 can put a token on two places p 2 and p 3 . Lastly, we can model synchronization: Let a transition t 1 be enabled only if places p 1 and p 2 have a token, hence modeling the joining operation. Sowa firstly used basic PN in causal representation <ref type="bibr" target="#b37">[38]</ref>, modeling the 'Yale shooting problem', originally proposed by <ref type="bibr" target="#b12">[13]</ref> in the context of nonmonotonic temporal reasoning (Cf. <ref type="bibr">Hans and McDermott, 1986</ref>) and adapted by Sowa to be represented with PN. The puzzle refers to a dynamic scenario involving two relevant properties: being loaded (something concerning to a gun) and being alive (something concerning to a victim) and two actions performed in sequence: wait and shoot. The initial situation is that the gun is loaded and the victim is alive and a kind of law of inertia is assumed: usually, properties of things do not change from an initial situation s 0 to others subsequent situations s 1 , s 2 , etc. But the victim may die if in a subsequent situation the gun is fired. Nevertheless, non-monotonic logics do not lead to that conclusion because they disregard the relevance that the causal dependencies have in defeasible knowledge. Sowa aimed to use a single PN to show the relations between the properties and actions involved in the Yale shooting problem:</p><p>Next, we use PN to represent some of the aforementioned causal puzzles. As concurrence in Petri Net are attached to transitions, we will refer the simultaneous presence of causes with the 'co-occurrence' word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Co-occurrence and overdetermination.</head><p>Causal overdetermination can be illustrated using PN as a case of synchronization. Recall that in symmetrical overdetermination two different causes must contribute to provoke the desired effect. For example, to eradicate the Helicobacter Pylory bacterium, clarithromycin and amoxicillin should be jointly administered (Figure <ref type="figure">4</ref>, left).</p><p>In order to the transition be fired, this PN requires the sincronization of both tokens, becoming dependent places. Remember that in asymmetrical over- Inhibition with Petri Nets is modeled inserting an extra node (labeled 'patient'). To provide a remedy, two 'medicines' and a patient should be considered. If a medicine is used by the patient, the patient node loses its token and the other possible transition is deactivated. In this case, delays on transitions are not required and the puzzle becomes adequately represented using a single PN. Note that, unlike Bayes Nets, dependence or independency in PN is a property of the transitions, not of the nodes. In PN, independency is largely related with concurrence. A transition is independent from other if it can be triggered before, after or at the same time; it is dependent if it depends on which other node or transition is enabled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Alternative causes</head><p>Recalling the example of section 2. </p><formula xml:id="formula_7">(A ∧ B) ∨ (A ∧ C) ∨ (A ∧ D) ∨ (B ∧ C ∧ D)</formula><p>denoting that several alternative clusters of necessary causal factors are sufficient to provoke the action. Disjunctive causes have a no transparent representation in PN, because even if we can represent every cluster as a synchronization of causal factors, the surgery can be caused by the concurrency of all of them (A ∧ B ∧ C ∧ D). So, the attempt to represent that case with a basic Petri Net is incomplete, because a dummy transition connecting the existing ones would be required. Basic PN considers neither time, nor probability, even if time and indetermination have a prominent role in discrete-event systems involving causal links. Nevertheless, Merlin and Ramchandani <ref type="bibr" target="#b4">[5]</ref> separately extended ordinary PN for including time delay in two different ways: firing and enabling durations.</p><p>In a basic PN, if a transition is enabled, it can be fired, moving input tokens from one place to another. But if time is considered, the transition will have a time delay. This means that input tokens are instantly transferred, but output tokens are not generated until the time delay is not surpassed. When a transition fires, input tokens are instantly transferred and output tokens just generated, but are not in disposition to enable new transitions until the delay associated to the target place is exceeded.</p><p>In fact, firing and enabing durations are similar ways to represent time in a Petri Net. The difference is only about the delay is positioned, whether in transitions or places. When time is assigned to a place, we denote the amount of time that the tokens generated by the transitions are off for enabling new transitions. When time is allocated in a transition, each input token has the same delay and is the transition delay what decides when the output tokens emerged. In the sequel, we will consider time associated to transitions. Time gets representation in Petri Nets extending the classic PN definition to the Timed Petri Nets (TPN): T P N = (P, T, I, O, M 0 , τ ), where P, T, I, O and M 0 is as in PN and τ : T → R + is a function that associates transitions with time delays. TPN enables the representation of time in a negative causal loop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Time delays in causal loops</head><p>Recall the example of the three orders of sales that are made in a shop. That fact is represented in a PN putting three tokens in the input place (sales). So, a transition t 1 may be fired as many times as tokens are. Let us suppose that the delay associated to the transition t 1 is null (e.g., when a sale is made, an order is executed) and the delay of transition t 2 is 4, denoting 4-days standby in applying the order. Then, as the orders are made effective three days after the sales, the store may be out of supply, stopping the sales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Probability, time, trumping and fizzling.</head><p>Regarding the representation of the trumping and fizzling puzzle, both of them involve time, co-occurrence and also vagueness or indetermination. Indetermination is introduced in Petri Nets using probabilities. Stochastic Timed Petri Net (STPN) is an evolution of TPN dealing with probability in timed transitions <ref type="bibr">[23] [7]</ref>. In a STPN, a transition is qualified with a probable firing delay value. Formally, ST P N = (P, T, I, O, M 0 , τ, ∧), where P, T, I, O, M 0 , τ , is as in TPN and ∧: T → R is a function that associates stochastic probability delays to transitions. Next, we will show how to represent time and imprecision involved in the trumping and fizzling puzzle using a STPN showing a conflict case. Regarding trumping, it can be modeled with a STPN as a situation of conflict assigning probabilities and delays to transitions. The STPN shown in Figure <ref type="figure" target="#fig_4">5</ref> is a case of conflict labeled with time delays and probability marks.</p><p>We remain to represent the fizzling. Fizzling is a causal puzzle concerning a pluri-causal situation in which the effective cause is not the one that provides the greater probability to the effect: a is a quiet and responsible person and b is a vandal. a anticipates b being the cause of the breakage of the lamppost. The fizzled disposition of b is not the cause of the effect, although his presence highly increases the probability of it. 'Highly' is a vague probability qualification and fuzzy set theory provides a way to measure that imprecise estimation. Although both deal with imprecision, crisp and fuzzy probability differ. Meanwhile probability theory deals with randomness, fuzzy set theory approaches vagueness. Fuzzy set theory probabilities can be numerical, based on fuzzy events or linguistic. First, regarding numerical probability, Zadeh's formula <ref type="bibr" target="#b43">[44]</ref> makes probability equal to the integral, or a sum in the discrete case, of an expectation. Regarding linguistic probability, the unit interval values must be distributed; i.e., we have to fix a membership function to each probability predicate or by a function. Thus, fuzzy set theory provides tools to manage imprecise probabilities as 'highly probable' and fuzzy Petri Nets might benefit of its management, for example, using them as thresholds to trigger transitions in the fizzling puzzle. The fizzling puzzle involves fuzzy probabilities and, then, a Fuzzy Stochastic Timed Petri Net (FSTPN) is required to model it. A FSTPN assigns fuzzy probabil-ities to delays in transitions. Formally, F ST P N = (P, T, I, O, M 0 , τ, µ), where P, T, I, O, M 0 and τ is as in STPN and µ:T → R + ∪ Γ is a function that associates to each transition a real value in R + or a linguistic label <ref type="bibr" target="#b23">[24]</ref>, suggesting that the underlying probability to the transition is approximate rather than crisp. The FSTPN shown in Figure <ref type="figure" target="#fig_5">6</ref> illustrates how to represent time and fuzzy indetermination, characteristic of the fizzling puzzle: Although regular graph methods are useful for dealing with causal attributes, they fail to represent co-occurrence, time, circularity and fuzzy indetermination together. To overcome these difficulties, we pointed at the Fuzzy Stochastic Timed Petri Nets as a tool that can contribute to represent all of them. Petri Nets and its extensions seems to be particularly appropriate for representing material causation, based on the view that causes are physically connected to their effects and the causal link transfer a mark from the cause to the effect. The movements of tokens in PN from one place to another through transitions illustrate this flow from cause to effect. However, this interpretation presents some difficulties, some related to causality and others specific to the PN.</p><p>Regarding a causal scenario, negative causality <ref type="bibr" target="#b32">[33]</ref> is a major objection. In some cases the absence of a fact causes the effect and so, nothing is transferred though the causal channel. In that case, no mark is transmitted from the cause to the effect; it is rather the absence that causes the effect. PN are not able to represent negative causality: only if there are tokens moving in the net, the dynamic of the event is reflected. Pluricausality and multiple effects present also problems to be modeled in PN, because the representation of disjunctive events has redundancies. Even if it is possible to represent alternative causes in PN, the semantic of the net does not have a direct reading. And the same goes for multiple effects.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Causal network representing trumping (left). Depicting causal influence from the node SM e to the node SM o (right).</figDesc><graphic coords="12,219.57,123.04,85.04,118.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Petri net representations.</figDesc><graphic coords="13,307.68,472.33,85.04,124.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Fig. 3. Petri Net modeling the Yale shooting problem (redrawn from fig. 4.20 of Sowa [38])</figDesc><graphic coords="15,307.68,283.66,113.38,68.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>2, the voters contributing to the final decision were summarized by the Boolean formula: (A ∧ (B ∨ C ∨ D)) ∨ (B ∧ C ∧ D), meaning that a surgery decision is performed if A votes positively, and B or C or D votes positively or if B and C and D votes positively. The PN representing the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Representation of time and imprecision in a STPN (left). Representing trumping as a conflict in a Petri Net with delays and probabilities. (right)</figDesc><graphic coords="17,191.22,253.13,113.38,66.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Representing fizzling as a conflict in a Petri Net with delays and fuzzy probabilities</figDesc><graphic coords="18,249.45,209.93,113.38,118.71" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The cognitive mapping approach to decision making</title>
		<author>
			<persName><forename type="first">R</forename><surname>Axelrod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structure of decision</title>
		<imprint>
			<biblScope unit="page" from="221" to="250" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Cambridge illustrated history of prehistoric art</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Bahn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On memory and reminiscence aristotle (ca. 350 bc)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Beare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Neurosciences</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">87</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Berzuini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dawid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bernardinell</surname></persName>
		</author>
		<author>
			<persName><surname>Causality</surname></persName>
		</author>
		<title level="m">Statistical perspectives and applications</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A brief survey and synthesis of the roles of time in petri nets</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Bowden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical and Computer Modelling</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="55" to="68" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Chomsky&apos;s universal grammar</title>
		<author>
			<persName><forename type="first">V</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Newson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Petri nets for dynamic event-driven system modeling. Handbook of Dynamic System Modeling</title>
		<author>
			<persName><forename type="first">P</forename><surname>Fishwick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Imaging, empathy, and causal attribution</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Fiske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Etcoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Laufer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="356" to="377" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Fake news detection by means of uncertainty weighted causal graphs</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Garrido-Merchán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Puente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Palacios</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.01065</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Uncertainty weighted causal graphs</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Garrido-Merchán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Puente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sobrino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Olivas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Extended fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hagiwara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Fuzzy Systems</title>
		<meeting>of the Int. Conf. on Fuzzy Systems</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="795" to="801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Causation and pre-emption. Philosophy of science today</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Paul</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nonmonotonic logic and temporal projection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hanks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcdermott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="379" to="412" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Bayesian networks and decision graphs springerverlag</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nielsen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>New york</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The map method for synthesis of combinational logic circuits</title>
		<author>
			<persName><forename type="first">M</forename><surname>Karnaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the American Institute of Electrical Engineers, Part I: Communication and Electronics</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="593" to="599" />
			<date type="published" when="1953">1953</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hidden patterns in combined and adaptive knowledge networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kosko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="377" to="393" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kosko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of man-machine studies</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="65" to="75" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Why a diagram is (sometimes) worth ten thousand words</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Larkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="65" to="100" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Postscripts tocausation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fuzzy stochastic petri nets for modeling biological systems with uncertain kinetic parameters</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Heiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">149674</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The cement of the universe: A study of causation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mackie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974">1974</date>
			<publisher>Clarendon Press</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generating a question answering system from text causal relations</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Merchán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Puente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Olivas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Hybrid Artificial Intelligence Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="14" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Discrete time stochastic petri nets</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Molloy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="417" to="423" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A first course in fuzzy logic</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Walker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Point of view in personal memories</title>
		<author>
			<persName><forename type="first">G</forename><surname>Nigro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Neisser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="467" to="482" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imagery, language, and semantic memory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paivio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Psycholinguistics</title>
		<imprint>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Mind and its evolution. a dual coding theoretical interpretation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paivio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Lawrence Erlbaum Associates, Inc, NJ</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Conjectures and refutations: The growth of scientific knowledge</title>
		<author>
			<persName><forename type="first">K</forename><surname>Popper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>routledge</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Creating a natural language summary from a compressed causal graph</title>
		<author>
			<persName><forename type="first">C</forename><surname>Puente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Olivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Seisdedos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 joint ifsa world congress and nafips annual meeting (ifsa/nafips</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="513" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Summarizing information by means of causal sentences through causal graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Puente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sobrino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Olivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Garrido</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Logic</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Extraction, analysis and representation of imperfect conditional and causal sentences by means of a semi-automatic process</title>
		<author>
			<persName><forename type="first">C</forename><surname>Puente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sobrino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Olivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Merlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on fuzzy systems</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">The comparative method: Moving beyond qualitative and quantitative strategies</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Ragin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Univ of California Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Causation by disconnection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy of Science</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="285" to="300" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Causes as probability raisers of processes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Philosophy</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="75" to="92" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Overdetermining causes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">An International Journal for Philosophy in the Analytic Tradition</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">1/2</biblScope>
			<biblScope unit="page" from="23" to="45" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>Philosophical Studies:</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A universal turing machine with two internal states</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automata studies</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="157" to="165" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Immanuel Kant&apos;s Critique of Pure Reason</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Read Books Ltd</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Knowledge representation: logical, philosophical and computational foundations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Sowa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Brooks/Cole Publishing Co</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">A probabilistic theory of causality</title>
		<author>
			<persName><forename type="first">P</forename><surname>Suppes</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Petri nets: properties, analysis and applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tadao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">A formal logical analysis of causal relations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>University of Sussex</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Cognitive maps in rats and men</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Tolman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page">189</biblScope>
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">The imagery debate</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tye</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Mit Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Fuzzy probabilities</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fuzzy Sets, Fuzzy Logic, And Fuzzy Systems: Selected Papers by Lotfi A Zadeh</title>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="643" to="652" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
