<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CEGRL-TKGR: A Causal Enhanced Graph Representation Learning Framework for Temporal Knowledge Graph Reasoning</title>
				<funder ref="#_n59aFbX #_qCjqsmh">
					<orgName type="full">Fundamental Research Funds for the Central Universities</orgName>
				</funder>
				<funder ref="#_qHSSEb9">
					<orgName type="full">National Key R&amp;D Program of China</orgName>
				</funder>
				<funder ref="#_rmSVgDR">
					<orgName type="full">Key Laboratory of Data Science and Smart Education, Hainan Normal University, Ministry of Education</orgName>
				</funder>
				<funder ref="#_UpPeMtW">
					<orgName type="full">State Key Laboratory of Public Big Data, Guizhou University</orgName>
				</funder>
				<funder ref="#_jvcWS5v">
					<orgName type="full">Australian Research Council Linkage</orgName>
				</funder>
				<funder ref="#_QDCuaKS #_9aSkYEA #_KDqU2kb #_qZuBFcZ #_ckqu42d">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_QmYjmSZ #_dT4ARag">
					<orgName type="full">Natural Science Foundation of Chongqing, China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jinze</forename><surname>Sun</surname></persName>
							<email>ssunjinze@outlook.com</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer and Information Science</orgName>
								<orgName type="institution">Southwest University</orgName>
								<address>
									<postCode>400715</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongpan</forename><surname>Sheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer and Information Science</orgName>
								<orgName type="institution">Southwest University</orgName>
								<address>
									<postCode>400715</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Big Data &amp; Software Engineering</orgName>
								<orgName type="institution">Chongqing University</orgName>
								<address>
									<postCode>401331</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lirong</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yongbin</forename><surname>Qin</surname></persName>
							<email>ybqin@gzu.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="department">School of Information Science and Engineering</orgName>
								<orgName type="institution">Chongqing Jiaotong University</orgName>
								<address>
									<postCode>400074</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">College of Computer Science and Technology</orgName>
								<orgName type="department" key="dep2">The State Key Laboratory of Public Big Data</orgName>
								<orgName type="institution">Guizhou University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ming</forename><surname>Liu</surname></persName>
							<email>m.liu@deakin.edu.au</email>
							<affiliation key="aff4">
								<orgName type="institution">Deakin University</orgName>
								<address>
									<postCode>3125</postCode>
									<region>Victoria</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tao</forename><surname>Jia</surname></persName>
							<email>tjia@swu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer and Information Science</orgName>
								<orgName type="institution">Southwest University</orgName>
								<address>
									<postCode>400715</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CEGRL-TKGR: A Causal Enhanced Graph Representation Learning Framework for Temporal Knowledge Graph Reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Temporal knowledge graph reasoning (TKGR) is increasingly gaining attention for its ability to extrapolate new events from historical data, thereby enriching the inherently incomplete temporal knowledge graphs. Existing graph-based representation learning frameworks have made significant strides in developing evolving representations for both entities and relational embeddings. Despite these achievements, there's a notable tendency in these models to inadvertently learn biased data representations and mine spurious correlations, consequently failing to discern the causal relationships between events. This often leads to incorrect predictions based on these false correlations. To address this, we propose an innovative Causal Enhanced Graph Representation Learning framework for TKGR (named CEGRL-TKGR). This framework introduces causal structures in graph-based representation learning to unveil the essential causal relationships between events, ultimately enhancing the performance of the TKGR task. Specifically, we first disentangle the evolutionary representations of entities and relations in a temporal knowledge graph sequence into two distinct components, namely causal representations and confounding representations. Then, drawing on causal intervention theory, we advocate the utilization of causal representations for predictions, aiming to mitigate the effects of erroneous correlations caused by confounding features, thus achieving more robust and accurate predictions. Finally, extensive experimental results on six benchmark datasets demonstrate the superior performance of our model in the link prediction task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graphs (KGs) have gained significant promise in natural language processing or knowledge engineering perception tasks <ref type="bibr">(Chen et al., 2022a)</ref>. They model real-world factual knowledge using multi-relationship graph structures. However, factual knowledge in reality is constantly evolving, resulting in the form of event knowledge. This has led to the development and application of temporal knowledge graphs (TKGs). TKG encodes the relationship information of entities and events and their timing for capturing the dynamics of entities and their relationships over time <ref type="bibr" target="#b12">(Gastinger et al., 2022)</ref>. Thus, analyzing the TKG provides a comprehensive understanding of the evolving events, based on which various time-dependent applications have been developed, including time-sensitive semantic search <ref type="bibr" target="#b2">(Barbosa et al., 2013)</ref>, policy making <ref type="bibr" target="#b8">(Deng et al., 2020)</ref>, stock forecasting <ref type="bibr" target="#b10">(Feng et al., 2019)</ref>, and more <ref type="bibr">(Chen et al., 2022a)</ref>.</p><p>The reliability of applications depends on accurate predicting, which highly relies on data integrality. However, existing TKGs are inevitably incomplete due to the partial observation of realworld <ref type="bibr" target="#b25">(Liang et al., 2022)</ref>. To address this limitation and enhance the representation capability of the TKG, temporal knowledge graph reasoning (TKGR) models are proposed and aim to extrapolate new facts and relationships in the TKG according to their historical temporal information. Existing models explore different strategies to achieve satisfactory results on the TKGR task. GHNN <ref type="bibr" target="#b14">(Han et al., 2020)</ref> and GHT <ref type="bibr" target="#b32">(Sun et al., 2022)</ref> model historical facts as point-in-time processes. TKGR-RHETNE <ref type="bibr" target="#b34">(Sun et al., 2023)</ref> jointly models the relevant historical event and temporal neighborhood event context of events in the TKG. RE-NET <ref type="bibr" target="#b17">(Jin et al., 2020)</ref> and RE-GCN <ref type="bibr" target="#b24">(Li et al., 2021)</ref> introduce graph neural networks (GNN) into sequence models to capture structural and temporal dependencies between entities. TKGR-GPRSCL <ref type="bibr" target="#b38">(Xiong et al., 2024)</ref> captures complex structure-aware information by encoding paths across entities and obtaining temporal correlations in the complex plane. TLogic <ref type="bibr" target="#b27">(Liu et al., 2022)</ref> and TITer <ref type="bibr" target="#b33">(Sun et al., 2021)</ref> design arXiv:2408.07911v2 <ref type="bibr">[cs.</ref>LG] 24 Jan 2025 interpretable models based on logical rules and reinforcement learning, respectively. Despite the achievements of previous studies, they have overlooked the reality that there are numerous confounding factors in the TKG, such as shallow patterns and noisy links. However, these confounding factors commonly misguide the reasoning process in the TKG, resulting in the acquisition of incorrect dependencies and the generation of non-causal predictions <ref type="bibr" target="#b31">(Sui et al., 2022)</ref>.</p><p>To address the aforementioned issues, we advocate for the integration of causal theory into TKGR to guide learning of the essential causal relationships between events and mitigate the impact of confounding factors on the TKGR task. Specifically, we first construct a structural causal model <ref type="bibr" target="#b40">(Zečević et al., 2021)</ref> to comprehensively analyze and model the TKGR task from a causal perspective. Then, based on the causal model, we propose a new framework, namely Causal Enhanced Graph Representation Learning (CEGRL-TKGR), to disentangle confounding factors from the essential causal factors in the TKG. To the best of our knowledge, this is the first study to incorporate causal intervention in a graph representation learning framework for learning the evolutionary representations of entities and relations in the TKG. To conclude, our contributions in this paper are 3folds:</p><p>• We propose a novel Causal Enhanced Graph Representation Learning framework for Temporal Knowledge Graph Reasoning, called CEGRL-TKGR, to uncover the essential causal relationships between events and mitigate the impact of confounding factors.</p><p>• The proposed CEGRL-TKGR framework disentangles the evolutionary representations of entities and relations into causal and confounding representations. Then, it applies causal interventions to perform backdoor adjustments of representations, prioritizing predicted causal features while minimizing the impact of spurious correlations introduced by confounding features.</p><p>• Comprehensive experimental results demonstrate that CEGRL-TKGR outperforms stateof-the-art baselines on six real-world datasets in the link prediction task. Further, comprehensive studies confirm the contribution of the introduced causal structures and interventions<ref type="foot" target="#foot_0">foot_0</ref> .</p><p>2 Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Temporal Knowledge Graph Reasoning</head><p>TKGR in extrapolation settings focuses on predicting new facts about the future based on historical events. Specifically, CyGNet <ref type="bibr" target="#b44">(Zhu et al., 2021)</ref> uses a copy-generating mechanism to capture the global repetition rate of facts. GHNN <ref type="bibr" target="#b14">(Han et al., 2020)</ref> and GHT <ref type="bibr" target="#b32">(Sun et al., 2022</ref>) construct a temporal point process (TPP) to capture the temporal dynamics of successive events, predicting future facts by estimating the conditional probability of the TPP. In recent years, with the successful application of GNN in many dynamic scenarios <ref type="bibr" target="#b41">(Zhang et al., 2022)</ref>, they have also been introduced into structural-semantic dependency models in TKGR. RE-NET <ref type="bibr" target="#b17">(Jin et al., 2020)</ref> used a neighborhood aggregator and cyclic event encoder to model historical facts as subgraph sequences. RE-GCN <ref type="bibr" target="#b24">(Li et al., 2021)</ref> uses RGCN <ref type="bibr" target="#b30">(Schlichtkrull et al., 2018)</ref> to learn evolutionary representations of entities and relationships at each timestamp. CEN <ref type="bibr">(Li et al., 2022a)</ref> uses length-aware convolutional neural networks (CNNS) to process evolutionary patterns of different lengths. There are also some studies to solve the TKGR problem through path search. For example, TLogic <ref type="bibr" target="#b27">(Liu et al., 2022)</ref> completes link prediction tasks based on temporal logic rules learned from temporal knowledge graphs. TITer <ref type="bibr" target="#b33">(Sun et al., 2021)</ref> proposes a TKG prediction model based on reinforcement learning, which uses time-shaped rewards based on Dirichlet distribution to guide model training. All of the methods discussed above have limitations in modeling entity and relationship representations, in particular ignoring cause-and-effect relationships between different entities, which we believe is key to making correct predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Causal Representation Learning</head><p>In graph causal representation learning, researchers have explored various methods to improve the explanatory power and generalization performance of GNNs. By applying the principles of causal reasoning to graph-structured data, the researchers sought to address the challenges GNNs face when dealing with complex systems such as social networks, molecular maps, and syntax trees of program code. DIR <ref type="bibr" target="#b37">(Wu et al., 2022)</ref> is proposed to reveal the intrinsic interpretability of GNNs by discovering invariant reasons, which involves splitting input graphs into causal and non-causal fruit graphs and training the two classifiers through invariant risk loss functions. GOOD <ref type="bibr">(Chen et al., 2022b)</ref> improves the cross-domain generalization of graphs by distinguishing invariant subgraphs from other parts of graphs that are susceptible to domain transfer. CAL <ref type="bibr" target="#b31">(Sui et al., 2022)</ref> introduces de-confounding training to distinguish the key and secondary parts of the graph and eliminate the confounding effect of the secondary parts on model prediction. CFLP <ref type="bibr" target="#b43">(Zhao et al., 2022)</ref> points out that the causal relationship between graph structure and link presence is often ignored, and proposed to generate counterfactual links to enhance training data and reduce reliance on false associations. Zevcevic et al. <ref type="bibr" target="#b40">(Zečević et al., 2021)</ref> theoretically analyze the relationship between GNNs and structural causal models (SCMs) and design a new class of neuro-causal models. However, none of the work has been done to combine causal learning with the TKGR task.</p><p>3 Preliminary</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Notations and Task Formulation</head><p>A TKG G can be formalized as a sequence of knowledge graph slices {G 1 , G 2 , . . . ., G T }, where G t = {(e s , r, e o , t) ∈ G} denotes a knowledge graph slice that consists of facts that occurred at the timestamp t range from t 0 to t n . Here, e s and e o represent the subject and object entities, respectively, and r denotes the predicate as a relation type.</p><p>Besides, e s , r, e o written in bold represent their embeddings. The objective of TKGR task is to predict either the subject in a give query (?, r, e o , t) or the object in a given query (e s , r, ?, t) with t &gt; t n .</p><p>3.2 A Causal Perspective on the GNN-Based TKGR Task</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">GNN-based TKGR Paradigm</head><p>Inspired by previous GNN-based modeling in a casual look <ref type="bibr" target="#b9">(Didelez and Pigeot, 2001;</ref><ref type="bibr" target="#b31">Sui et al., 2022)</ref>, we abstract the GNN-based TKGR process through a structural causal figure, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>, encompassing five distinct variables. The connectivity from one variable to another epito- mizes the causal relationship, delineated as the cause → effect. The variables are described as follows:</p><p>• Graph data G t : The knowledge graph at each timestamp t, manifests as a directed multirelationship figure.</p><p>• Causal Feature C: These features epitomize the causal essence of the targeted entity, providing a fundamental understanding of its inherent dynamics.</p><p>• Confounding Feature N : These features, discerned from GNN, embody the confounding attributes, unveiling the potential biases or trivial patterns ingrained in graph-based learning methodologies.</p><p>• Representation R: These representations are the entity and relational representations of the output of the final GNN layer after learning for G t .</p><p>• Prediction Y : Denoted as TKGR as the link prediction, this aspect transitions through the decoder, rendering the ultimate reasoning based on the preceding representation.</p><p>The causal embedding encapsulates the causal features C, authentically mirroring the implicit knowledge inherent in the knowledge graph G t . Conversely, N symbolizes the confounding features, which might be spawned by data biases, data noise, or superficial patterns within graph-based learning methodologies. These confounding features forge a backdoor pathway between C and Y , fostering spurious correlations that don't contribute to accurate reasoning. Functionally, the structural operation denoted by C → R ← N portrays a GNN, wherein both the causal features C and the confounding features N , as discerned by the target entity from the graph data, exert a direct impact on the output R of the GNN. Subsequently, the output R of GNN directly sways the model inference outcome, illustrated as R → Y .</p><p>In the graph-based TKGR paradigm, causal and confounding features are not decoupled for each entity or relationship embedding. Using causal graphs, we aspire to explicitly separate causal embeddings and confounding embeddings from entity or relational representations, and aim to mitigate the effects of confounding features by performing causal interventions. This endeavor not only clarifies the inference process but also endeavors to refine the accuracy and reliability of the GNN-based TKGR mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Causal Intervention Strategies</head><p>Beyond fostering a novel comprehension of GNNbased TKGR, causal theory avails analytical instruments predicated on causal figures, such as causal intervention. Causal intervention facilitates a profound examination of the factors precipitating inference outcomes. As delineated by Fig. <ref type="figure" target="#fig_0">1</ref>., confounding feature N and causal feature C can be discerned from the knowledge graph G t . These features are contemplated in the representation R of entities and relations, thereby establishing a backdoor pathway represented as N ← G t → C → R → Y , with N serving as the quick bridge between C and Y .</p><p>To orchestrate a causal prognosis hinging on the causal feature C, it necessitates the modeling of P (Y | C). However, the backdoor path distorts the probability distribution P (Y | C) through the confounding effect of N , thereby necessitating the disentanglement of the backdoor pathway from N to Y . It is imperative to stymie this backdoor pathway to mitigate the repercussions of the hybrid embedding, thereby enabling the model to reason robustly by leveraging the causal feature to the fullest. Causality theory is a potent toolkit to address this backdoor path dilemma.</p><p>We engage the do-calculus for executing causal interventions on variable C, intending to sever the backdoor path N ← G t → C → R → Y. Our objective is to estimate P (Y | do(C)), as opposed to muddling it with P (Y | C). By using Bayes' theorem with the causal postulation, we can extrapolate the ensuing expression:</p><formula xml:id="formula_0">P (Y | do(C)) = n∈N P (Y | C, n)P (n). (1)</formula><p>The equation above illustrates that to gauge the causal influence of C on Y , it's requisite to take into account the inference outcomes of both causal and confounding features. This can be perceived as re-coupling the disentanglement feature embeddings, utilizing them for deductive reasoning at future timestamps. However, C and N are usually unobservable, and it is difficult to obtain them directly at the data level, which makes the calculation of the Eq. (1) very challenging. In the next section, we discuss ways to overcome this problem. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Entity and Relation Evolution Representation</head><p>Within each G t , representation learning of entities and relationships involves the aggregation of multiple relationships, as well as information from multiple hop neighbors under a single timestamp. Between adjacent G t , we expect to accurately capture the order dependencies inherent in the subgraph with different timestamps. Drawing inspiration from the RE-GCN model <ref type="bibr" target="#b24">(Li et al., 2021)</ref>, we employ the ω-layer RGCN, which hinges on structure modeling and a recurrent mechanism to progressively update the representations of entities and relations. This approach allows for a more nuanced understanding and modeling of the dynamic interactions within the graph over time.</p><p>e l+1 o,t = RReLu (es,r,eo)∈Gt</p><formula xml:id="formula_1">1 d eo W l 1 Φ e l s,t , r t + W l 2 e l o,t ,<label>(2)</label></formula><formula xml:id="formula_2">E t = GRU E t-1 , E ′ t .<label>(3)</label></formula><p>In the Eq. ( <ref type="formula" target="#formula_1">2</ref>), we describe how the embedding e l+1 o,t of entity e o at time step t and layer l+1 is computed. We integrate the information of all entities and relations connected to entity e o in the knowledge graph G t . W l 1 , W l 2 is learnable weights and Φ has the option of addition or one-dimensional convolution. In the Eq. ( <ref type="formula" target="#formula_2">3</ref>), we showcase how the entity embedding matrix E t is updated via the GRU. Specifically, we take the entity embedding matrix E t-1 at the previous time step t -1 and the aggregated entity embedding matrix E ′ t as inputs to obtain the entity embedding matrix E t at the current time step t.</p><p>For relations, ensuring consistency with the entity embedding updates within the subgraph sequence is crucial. To achieve this consistency, a specialized GRU tailored for relations is employed for the update process. This mechanism facilitates a harmonized evolution of both entity and relation causal embeddings over the sequence of subgraphs:</p><formula xml:id="formula_3">r ′ t = pooling (E t-1 , R t ) ⊕ r, (4) R t = GRU R t-1 , R ′ t ,<label>(5)</label></formula><p>where r ′ t is an aggregation of all entities connected to relation r via a mean pooling operation, and R ′ t is obtained by concatenating this result with the embeddings of all relations. Eventually, we update the relation embedding matrix R t using a GRU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Disentangled Causal and Confounding Features</head><p>In the previous subsection, the entity and relation representations are learned based on GNN-contained causal and confounding factors, and we separate them at the presentation level, which provides a solution to the previously mentioned problem of not being able to separate these two features at the data level. To do this, we introduce a decoupling module to decouple causal and confounding features. Taking the entity embedding matrix as an example, it is represented as follows:</p><formula xml:id="formula_4">D E,C , D E,N = softmax(MLP(E)), (6) E C = E ⊙ D E,C , E N = E ⊙ D E,N .<label>(7)</label></formula><p>We want the two embeddings learned from the decoupling module to be as independent as possible, which is essential to accurately separate causal and confounding features <ref type="bibr" target="#b4">(Chen et al., 2023)</ref>. Mutual information is a basic quantity to measure the nonlinear correlation of two random variables. Minimizing mutual information is a feasible scheme to decouple causal features from confounding features. Specifically, we implement this process with contrastive log-ratio upper-bound MI estimator <ref type="bibr" target="#b7">(Cheng et al., 2020;</ref><ref type="bibr" target="#b36">Wu et al., 2021)</ref>, which utilizes variational distributions q and a neural network to approximate the true distribution. We define the objective function as follows:</p><formula xml:id="formula_5">L mi = E p(E C ,E N ) [log q θ (E N |E C )] -E p(E C ) E p(E N ) log q θ (E N |E ′ C ) .<label>(8)</label></formula><p>We perform the same operation with relation embedding decoupling, after which we obtain R C and R N .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Temporal Gap Guided Decoder</head><p>After the causal and confounding embeddings of entities and relations in the derived data, we use a specially crafted decoder to determine the likelihood score of potential entities and relations.</p><p>Events or facts in a data stream may span different periods. For example, major political events may occur in rapid succession over a short period, while certain rare natural phenomena may occur sporadically and at longer intervals. With this in mind, it is reasonable to consider the time intervals of events to get an accurate picture of their temporal relationship. The key to the design of our decoder is the time interval vector, which guides the decoding process in considering the event time interval while calculating the fraction. Formulaic as:</p><formula xml:id="formula_6">t s = α s t + β s , t l = α l t + β l .<label>(9)</label></formula><p>Here, α s , β s , α l , and β l signify learnable parameters. Adopting ConvTransE as our decoder, we introduce four variables, which traverse a onedimensional convolutional layer followed by a fully connected layer, culminating in the extraction of a probability vector encompassing all entities. This process is mathematically articulated as:</p><formula xml:id="formula_7">p C (e o | e s , r, t) = ReLU ConvTransE e s,C,t , r C,t , t s , t l E C,t .<label>(10)</label></formula><p>We apply the same decoding process to the confounding features to get p N (e o | e s , r, t).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Causal Intervention and Training Objective</head><p>Causal-based embedding learns the intrinsic causes that cause events to occur, so the reasoning results obtained from causal-based embedding are expected to yield reasonable input results. We define the supervised classification loss as follows:</p><formula xml:id="formula_8">L E,C = (es,r,eo,t)∈G y t log p C (e o | e s , r, t) ,<label>(11)</label></formula><p>where y t is label vector. Conversely, confounding features are conceptualized to address conceivable biases or superficial patterns emanating from the training dataset. Given their inability to aid in inference, we proceed to compute their output average across all entity categories and encapsulate the loss as:</p><formula xml:id="formula_9">L E,N = 1 |E N,t | (es,r,eo,t)∈G KL y u , log p N (e o | e s , r, t) ,<label>(12)</label></formula><p>where KL denotes the KL-Divergence, y u represents the uniform distribution.</p><p>We believe that causal intervention is the manifestation of causal features under the influence of confounding features, but we cannot directly conduct causal intervention at the data level to mitigate confounding effects. Therefore, we obtain intervention features that combine causal features and confounding features at the representation level of entities and relationships. Specifically, according to the backdoor adjustment Eq. ( <ref type="formula">1</ref>), we first introduce a random addition procedure to obtain the intervention feature, and for the intervention feature we expect the decoder to still output the correct result:</p><formula xml:id="formula_10">E I,t = ϕ E C,t , E ′ N,t ,<label>(13)</label></formula><formula xml:id="formula_11">p I (e o | e s , r, t) = ReLU ConvTransE e s,I,t , r I,t , t s , t l E I,t ,<label>(14)</label></formula><p>where E ′ N,t is the confounding feature of the entites randomly sampled from E N,t . Then we define the loss as follows:</p><formula xml:id="formula_12">L E,I = (es,r,eo,t)∈G y t log p I (e o | e s , r, t) . (15)</formula><p>Finally, the loss function of the model for the link prediction task is as follows:</p><formula xml:id="formula_13">L E = L E,C + λ 1 L E,N + λ 2 L mi + λ 3 L E,I , (16)</formula><p>where λ 1 , λ 2 , λ 3 are designated as hyperparameters, and the first two are used to determine the strength of decoupled learning of the model and the latter is used to determine the strength of causal intervention of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings and Implementation Details</head><p>Datasets. We evaluate our model and baselines on six benchmark datasets, including ICEWS14 <ref type="bibr" target="#b11">(Garcia-Duran et al., 2018)</ref>, ICEWS18 <ref type="bibr" target="#b16">(Jin et al., 2019</ref><ref type="bibr">), ICEWS05-15 (Garcia-Duran et al., 2018)</ref>, YAGO <ref type="bibr" target="#b28">(Mahdisoltani et al., 2014)</ref>, WIKI <ref type="bibr" target="#b19">(Leblay and Chekol, 2018)</ref> and GDELT <ref type="bibr" target="#b20">(Leetaru and Schrodt, 2013)</ref>. Statistics of the datasets are summarized in Table <ref type="table" target="#tab_0">1</ref>. Baselines. For the link prediction task, we compare CEGRL-TKGR model with two categories of KGR models: (1) static KGR models, including TransE <ref type="bibr" target="#b3">(Bordes et al., 2013)</ref>, DistMult <ref type="bibr" target="#b39">(Yang et al., 2015)</ref>, ComplEx <ref type="bibr" target="#b35">(Trouillon et al., 2016)</ref> and R-GCN <ref type="bibr" target="#b30">(Schlichtkrull et al., 2018)</ref>. We apply these models in static KGs that ignore timestamp information.</p><p>(2) TKGR models, including TTransE <ref type="bibr" target="#b19">(Leblay and Chekol, 2018)</ref>, <ref type="bibr">TA-DistMult (Garcia-Duran et al., 2018)</ref>, TNTCom-plEx <ref type="bibr" target="#b18">(Lacroix et al., 2019)</ref>, RE-GCN <ref type="bibr" target="#b24">(Li et al., 2021)</ref>, GHT <ref type="bibr" target="#b32">(Sun et al., 2022)</ref>, EvoKG <ref type="bibr" target="#b29">(Park et al., 2022)</ref>, TITer <ref type="bibr" target="#b33">(Sun et al., 2021)</ref>, xERTE <ref type="bibr" target="#b13">(Han et al., 2021)</ref>, TLogic <ref type="bibr" target="#b27">(Liu et al., 2022)</ref> and CEN <ref type="bibr">(Li et al., 2022b)</ref>. Evaluation Metrics. The mean reciprocal rank (MRR) and Hits@k are standard metrics for the TKG link prediction task. MRR is the average reciprocal of the correct query answer rank. Hits@k indicates the proportion of correct answers among the top k candidates. We use a more reasonable time-aware filter setting to report our experimental results<ref type="foot" target="#foot_1">foot_1</ref> . Implementation Details. The whole of training hyper-parameters and model configurations are summarized in Appendix A.1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we revisit the GNN-based TKGR model from the causality perspective, on this basis, we propose a novel CEGRL-TKGR framework. By synergistically integrating causal structures with graph representation learning of the TKG, our framework overcomes the problem of existing TKGR models' learning biased data representations and mining for false correlations unintentionally. Comprehensive experimental results and analysis have proved the effectiveness of CEGRL-TKGR.</p><p>Limitations and Future Work. The proposed CEGRL-TKGR is an innovational causal enhanced graph representation learning framework for optimizing feature representations directly using causal technology for the TGKR task. The limitations of CEGRL-TKGR are as follows:</p><p>• From the dataset's perspective, our research primarily focuses on TKG datasets, which may not verify the generalization ability of the CEGRL-TKGR framework to those timeinterval insensitive graph datasets. Additionally, we aim to further conduct case studies to enhance the interpretability of the framework in the reasoning procedure as future work.</p><p>• From the model's perspective, our research evaluates the TKGR task alone. Theoreti-cally, the GNN-based reasoning paradigm incorporated in the causal structure can be applied to any other graph representation learning tasks, such as triple classification <ref type="bibr" target="#b15">(Jaradeh et al., 2021)</ref>, triple set prediction <ref type="bibr" target="#b42">(Zhang et al., 2024)</ref>, and graph classification <ref type="bibr" target="#b26">(Liu et al., 2023)</ref>. In future work, we desire to explore powerful disentanglement methods and more advanced causal intervention strategies to improve the CEGRL-TKGR's performance for more rich graph representation learning-based tasks. Besides, the increased complexity of causal reasoning in the TKG is untouched.</p><p>• From the adaptation's perspective, to adapt the CEGRL-TKGR framework to more models, there are some hyper-parameters to control causal intervention and training. These hyperparameters are sensitive to different models and datasets, hence it needs to take sufficient time to experiment to find the optimal values and combinations among them. Therefore, how to reduce the consumption in the above adaptation procedure upon the framework is worthy of consideration.      </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The GNN-based structural causal graph for the TKGR task.</figDesc><graphic coords="3,342.71,70.87,145.14,74.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>We detail the CEGRL-TKGR framework for learning representations of entities and relationships based on causal features and confounding features. CEGRL-TKGR consists of three parts: (1) The representation learning part that learns the structure dependence in each G t ; (2) The decoupling learning part that learns the entity and relation representations; (3) The decoder part that is designed based on the time interval. The overall architecture of the framework is shown in Fig.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The overall architecture of our proposed CEGRL-TKGR framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The parameters sensitivity analysis of loss coefficients λ 1 , λ 2 and λ 3 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>w/o CE (b) Hits@1 results on the YAGO dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>w/o CE (c) MRR results on the WIKI dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>w/o CE (d) Hits@1 results on the WIKI dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The performance of CEGRL-TKGR and CEGRL-TKGR w/o CE on the noisy YAGO and WIKI datasets, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of datasets in the experiments.</figDesc><table><row><cell>Dataset</cell><cell cols="6"># Entity # Predict # Train # Valid # Test Time interval</cell></row><row><cell>ICEWS14</cell><cell>7128</cell><cell>230</cell><cell>63685</cell><cell>13823</cell><cell>13222</cell><cell>24 hours</cell></row><row><cell>ICEWS18</cell><cell>23033</cell><cell>256</cell><cell>373018</cell><cell>45995</cell><cell>49545</cell><cell>24 hours</cell></row><row><cell cols="2">ICEWS05-15 10488</cell><cell>251</cell><cell>322958</cell><cell>69224</cell><cell>69147</cell><cell>24 hours</cell></row><row><cell>YAGO</cell><cell>10623</cell><cell>10</cell><cell>161540</cell><cell>19523</cell><cell>20026</cell><cell>1 year</cell></row><row><cell>WIKI</cell><cell>12554</cell><cell>24</cell><cell>539286</cell><cell>67583</cell><cell>63110</cell><cell>1 year</cell></row><row><cell>GDELT</cell><cell>7691</cell><cell>240</cell><cell cols="3">1734399 238765 305241</cell><cell>15 mins</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>and Table 3 report the experimental re-</cell></row><row><cell>sults of the link prediction task on six benchmark</cell></row><row><cell>datasets. Static KG embedding methods fell far</cell></row><row><cell>behind CEGRL-TKGR due to their inability to cap-</cell></row><row><cell>ture temporal dynamics in the TKG. Our method</cell></row><row><cell>is also superior to other TKGR models in predict-</cell></row><row><cell>ing events. The improved performance shows that</cell></row><row><cell>surface patterns and noise are widely present in sev-</cell></row><row><cell>eral real-world TKG datasets. The previous models</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>To illustrate the evaluation of our CEGRL-TKGR framework and facilitate further research on this topic, we have made the experimental details and source code of the framework publicly available at https://github.com/shengyp/ CEGRL-TKGR.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The time-aware filtering setting filters out only the four groups that occur at query time and can simulate extrapolated prediction tasks in the real world<ref type="bibr" target="#b33">(Sun et al., 2021)</ref>.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported by the <rs type="funder">National Natural Science Foundation of China</rs> (Grant No. <rs type="grantNumber">62202075</rs>, No. <rs type="grantNumber">62171111</rs>,  No. <rs type="grantNumber">62376043</rs>), the <rs type="funder">Natural Science Foundation of Chongqing, China</rs> (No. <rs type="grantNumber">CSTB2022NSCQ-MSX1404</rs>, No. <rs type="grantNumber">CSTB2023NSCQ-MSX0091</rs>),</p></div>
			</div>
			<div type="funding">
<div><p><rs type="funder">Fundamental Research Funds for the Central Universities</rs> (No. <rs type="grantNumber">SWU-KR24008</rs>), <rs type="projectName">Science Research Project, Chongqing College of International Business and Economics</rs> (No. <rs type="grantNumber">KYZK2024001</rs>), <rs type="funder">Key Laboratory of Data Science and Smart Education, Hainan Normal University, Ministry of Education</rs> (No. <rs type="grantNumber">DSIE202206</rs>), and the <rs type="funder">State Key Laboratory of Public Big Data, Guizhou University</rs> (No. <rs type="grantNumber">PBD2024-0501</rs>), <rs type="person">Ming Liu</rs>'s research was funded in part by <rs type="funder">Australian Research Council Linkage</rs> (<rs type="grantNumber">LP220200746</rs>). <rs type="person">Yongbin Qin</rs>'s work was supported by the <rs type="funder">National Natural Science Foundation of China</rs> (No. <rs type="grantNumber">62166007</rs>, No. <rs type="grantNumber">62066008</rs>) and the <rs type="funder">National Key R&amp;D Program of China</rs> (No. <rs type="grantNumber">2023YFC3304500</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_QDCuaKS">
					<idno type="grant-number">62202075</idno>
				</org>
				<org type="funding" xml:id="_9aSkYEA">
					<idno type="grant-number">62171111</idno>
				</org>
				<org type="funding" xml:id="_KDqU2kb">
					<idno type="grant-number">62376043</idno>
				</org>
				<org type="funding" xml:id="_QmYjmSZ">
					<idno type="grant-number">CSTB2022NSCQ-MSX1404</idno>
				</org>
				<org type="funding" xml:id="_dT4ARag">
					<idno type="grant-number">CSTB2023NSCQ-MSX0091</idno>
				</org>
				<org type="funded-project" xml:id="_n59aFbX">
					<idno type="grant-number">SWU-KR24008</idno>
					<orgName type="project" subtype="full">Science Research Project, Chongqing College of International Business and Economics</orgName>
				</org>
				<org type="funding" xml:id="_qCjqsmh">
					<idno type="grant-number">KYZK2024001</idno>
				</org>
				<org type="funding" xml:id="_rmSVgDR">
					<idno type="grant-number">DSIE202206</idno>
				</org>
				<org type="funding" xml:id="_UpPeMtW">
					<idno type="grant-number">PBD2024-0501</idno>
				</org>
				<org type="funding" xml:id="_jvcWS5v">
					<idno type="grant-number">LP220200746</idno>
				</org>
				<org type="funding" xml:id="_qZuBFcZ">
					<idno type="grant-number">62166007</idno>
				</org>
				<org type="funding" xml:id="_ckqu42d">
					<idno type="grant-number">62066008</idno>
				</org>
				<org type="funding" xml:id="_qHSSEb9">
					<idno type="grant-number">2023YFC3304500</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Implementation Details</head><p>We set the dimension of all embeddings and hidden states to 200. The number of layers of the R-GCN is set to 1 for YAGO and 2 for the other datasets. The optimal number of historical snapshots is set to 8, 10, 10, 1, 2, and 6 for ICEWS14, ICEWS18, ICEWS05-15, YAGO, WIKI, and GDELT, respectively. To fair comparison, static graph constraints are added for ICEWS14, ICEWS18, and ICEWS05-15. The channel number for decoding is set to 50, and the kernel size is set to 4×3. We try several different values for λ 1 , λ 2 , and λ 3 , and finally chose 0.5, 0.5, 0.3. We use Adam to optimize the parameters, with a learning rate of 0.001. All of the experiments are processed on a Linux server with CPU Xeon Gold 6142, RAM 64G, and Nvidia 4090 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Ablation Study</head><p>We investigate the effectiveness of causally enhanced and time-interval guided decoders for the link prediction task. Specifically, CEGRL-TKGR w/o TD means that no time interval vector is used to guide the decoder to work, and CEGRL-TKGR w/o CE means that the model removes causal decoupling and causal intervention parts. Table <ref type="table">4</ref> shows the results of ablation experiments, which indicate the effectiveness of these two components. As can be seen from the results in the table, for datasets such as YAGO and WIKI that contain relatively regular time intervals, a temporal gap-guided decoder can capture this time interval pattern well enough to make accurate predictions. At the same time, it does not degrade performance even for timeinterval insensitive datasets. Our causal enhancement module, under the independent constraint of emphasizing causal features and confounding features, eliminates the influence of the fast bridge through causal intervention, forcing the model to learn the intrinsic causes of the events. It is worth noting that our causal enhancement module can be seen as a flexible component that can be easily used in several GNN-based reasoning frameworks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Parameter Sensitivity Analysis</head><p>In the CEGRL-TKGR, λ 1 and λ 2 jointly affect the disentanglement intensity of causal and confounding features, and λ 3 controls the intensity of causal intervention. We study the sensitivity of parameters in different benchmark datasets, as depicted in Fig. <ref type="figure">3</ref>. Specifically, one parameter is fixed at 0.5 and the other parameter varies in [0,1] with a step size of 0.1. The model is relatively stable in most parameter selection cases, but on noisy datasets, the model has higher requirements for hyper-parameters, and extreme values will degrade the performance of the model. The best range for λ 1 , λ 2 is about 0.5 to 0.7. λ 3 should be a relatively small value, ranging from 0.3 to 0.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Performance on Noisy Temporal Knowledge Graphs</head><p>To explore whether the proposed CEGRL-TKGR can alleviate noise and surface patterns, we randomly replace a certain percentage of positive triples in the training set of each TKG dataset in form of noisy TKGs. Taking YAGO and WIKI datasets as examples, we test the performance of CEGRL-TKGR and CEGRL-TKGR w/o CE under different noise deviations, respectively. The experimental results are shown in Fig. <ref type="figure">4</ref>. From the experimental results, we can draw the following conclusion: when the noise in the dataset increases, the performance of models lacking the recognition of causal features and confounding features will deteriorate sharply, and the performance of MRR and Hits@1 will decrease, which indicates that the CEGRL-TKGR w/o CE is easy to capture data bias and make wrong predictions based on it. In contrast, CEGRL-TKGR uses the causal enhancement module to effectively reduce the impact of confounding features and shows more stable performance on these two noisy TKG datasets. The performance degradations on MRR and Hits@1 are significantly smaller than those without the causal module.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Table 2: Experimental results of link prediction on ICEWS series dataset. The best result in each column is boldfaced</title>
		<idno>Model ICEWS14 ICEWS18 ICEWS05-15</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Table 3: Experimental results of link prediction on YAGO, WIKI, and GDELT datasets. The best result in each column is boldfaced</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Shallow information extraction for the knowledge web</title>
		<author>
			<persName><forename type="first">Denilson</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haixun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE 29th International Conference on Data Engineering</title>
		<meeting>IEEE 29th International Conference on Data Engineering</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1264" to="1267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual Conference on Neural Information Processing Systems</title>
		<meeting>the 27th Annual Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Causality and independence enhancement for biased node classification</title>
		<author>
			<persName><forename type="first">Guoxin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangda</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinglang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangli</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huawei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 32th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="203" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Qian Huang, and Shaohua Wan. 2022a. An overview of knowledge graph reasoning: key technologies and applications</title>
		<author>
			<persName><forename type="first">Yonghong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yirui</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Sensor and Actuator Networks</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">78</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">2022b. Invariance principle meets out-of-distribution generalization on graphs</title>
		<author>
			<persName><forename type="first">Yongqiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonggang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yatao</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Kaili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binghui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2022: Workshop on Spurious Correlations, Invariance and Stability</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Club: A contrastive log-ratio upper bound of mutual information</title>
		<author>
			<persName><forename type="first">Pengyu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weituo</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiachang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1779" to="1788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dynamic knowledge graph based multievent forecasting</title>
		<author>
			<persName><forename type="first">Songgaojun</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huzefa</forename><surname>Rangwala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Ning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1585" to="1595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Vanessa</forename><surname>Didelez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iris</forename><surname>Pigeot</surname></persName>
		</author>
		<title level="m">Causality: models, reasoning, and inference</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Temporal relational ranking for stock prediction</title>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning sequence encoders for temporal knowledge graph completion</title>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastijan</forename><surname>Dumančić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4816" to="4821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On the evaluation of methods for temporal knowledge graph forecasting</title>
		<author>
			<persName><forename type="first">Julia</forename><surname>Gastinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Sztyler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lokesh</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anett</forename><surname>Schuelke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2022 Temporal Graph Learning Workshop</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">xerte: Explainable reasoning on temporal knowledge graphs for forecasting future links</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunpu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><surname>Volker Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Learning Representations</title>
		<meeting>the 9th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Graph hawkes neural network for forecasting on temporal knowledge graphs</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunpu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName><surname>Volker Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Conference on Automated Knowledge Base Construction</title>
		<meeting>the 2nd Conference on Automated Knowledge Base Construction</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Triple classification for scholarly knowledge graph completion</title>
		<author>
			<persName><forename type="first">Mohamad</forename><surname>Yaser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaradeh</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kuldeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Stocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Knowledge Capture Conference</title>
		<meeting>the 11th Knowledge Capture Conference</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Woojeong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xisen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1904.05530" />
		<title level="m">Recurrent event network: Autoregressive structure inference over temporal knowledge graphs</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Recurrent event network: Autoregressive structure inferenceover temporal knowledge graphs</title>
		<author>
			<persName><forename type="first">Woojeong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xisen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6669" to="6683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tensor decompositions for temporal knowledge base completion</title>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deriving validity time in knowledge graph</title>
		<author>
			<persName><forename type="first">Julien</forename><surname>Leblay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melisachew</forename><forename type="middle">Wudage</forename><surname>Chekol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Web Conference</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1771" to="1776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Gdelt: Global data on events, location, and tone</title>
		<author>
			<persName><forename type="first">Kalev</forename><surname>Leetaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">A</forename><surname>Schrodt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1979" to="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m">ISA annual convention</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">2022a. Complex evolutional pattern learning for temporal knowledge graph reasoning</title>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saiping</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="290" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Jiafeng Guo, and Xueqi Cheng. 2022b. Complex evolutional pattern learning for temporal knowledge graph reasoning</title>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saiping</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<biblScope unit="page" from="290" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Temporal knowledge graph reasoning based on evolutional representation learning</title>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saiping</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huawei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="408" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Ke</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingyuan</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxuan</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sihang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinwang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuchun</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2212.05767" />
		<title level="m">Reasoning over different types of knowledge graphs: Static, temporal and multi-modal</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A survey on graph classification and link prediction based on gnn</title>
		<author>
			<persName><forename type="first">Xingyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Wen</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2307.00865" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Tlogic: Temporal logical rules for explainable link forecasting on temporal knowledge graphs</title>
		<author>
			<persName><forename type="first">Yushan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunpu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Hildebrandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitchell</forename><surname>Joblin</surname></persName>
		</author>
		<author>
			<persName><surname>Volker Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="4120" to="4127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Yago3: A knowledge base from multilingual wikipedias</title>
		<author>
			<persName><forename type="first">Farzaneh</forename><surname>Mahdisoltani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joanna</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th biennial conference on innovative data systems research. CIDR Conference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Evokg: Jointly modeling event time and network structure for reasoning over temporal knowledge graphs</title>
		<author>
			<persName><forename type="first">Namyong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Purvanshi</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Cristofor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifteenth ACM international conference on web search and data mining</title>
		<meeting>the fifteenth ACM international conference on web search and data mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="794" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web: 15th International Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Causal attention for interpretable and generalizable graph classification</title>
		<author>
			<persName><forename type="first">Yongduo</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1696" to="1705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Graph hawkes transformer for extrapolated reasoning on temporal knowledge graphs</title>
		<author>
			<persName><forename type="first">Haohai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shangyi</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="7481" to="7493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Timetraveler: Reinforcement learning for temporal knowledge graph forecasting</title>
		<author>
			<persName><forename type="first">Haohai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunpu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8306" to="8319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Tkgr-rhetne: A new temporal knowledge graph reasoning model via jointly modeling relevant historical event and temporal neighborhood event context</title>
		<author>
			<persName><forename type="first">Jinze</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongpan</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lirong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Neural Information Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="331" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName><forename type="first">Théo</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Éric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2071" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Disenkgat: knowledge graph embedding with disentangled graph attention network</title>
		<author>
			<persName><forename type="first">Junkang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wentao</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenqiang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 30th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2140" to="2149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Discovering invariant rationales for graph neural networks</title>
		<author>
			<persName><forename type="first">Yingxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Learning Representations</title>
		<meeting>the 10th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Xiangnan He, and Tat-Seng Chua</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Tkgr-gprscl: Enhance temporal knowledge graph reasoning with graph structure-aware path representation and supervised contrastive learning</title>
		<author>
			<persName><forename type="first">Lizhu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongpan</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lirong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCF International Conference on Natural Language Processing and Chinese Computing</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="200" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations</title>
		<meeting>the 3rd International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Relating graph neural networks to structural causal models</title>
		<author>
			<persName><forename type="first">Matej</forename><surname>Zečević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Singh Dhami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2109.04173" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dynamic graph neural networks for sequential recommendation</title>
		<author>
			<persName><forename type="first">Mengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueli</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="4741" to="4753" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Start from zero: Triple set prediction for automatic knowledge graph completion</title>
		<author>
			<persName><forename type="first">Wen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zezhong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaoyan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><forename type="middle">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huajun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning from counterfactual links for link prediction</title>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International Conference on Machine Learning</title>
		<meeting>the 39th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="26911" to="26926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning from history: Modeling temporal knowledge graphs with sequential copy-generation networks</title>
		<author>
			<persName><forename type="first">Cunchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changjun</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangquan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 35th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4732" to="4740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Table 4: The ablation study of our model on the six benchmark datasets</title>
		<idno>TD 42.21</idno>
	</analytic>
	<monogr>
		<title level="m">w/o&quot; means &quot;without&quot;. Model ICEWS14 ICEWS18 ICEWS05-15 YAGO WIKI GDELT MRR Hits@10 MRR Hits@10 MRR Hits@10 MRR Hits@10 MRR Hits@10 MRR Hits@10 CEGRL-TKGR</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
