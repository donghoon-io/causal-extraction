<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HyperCausalLP: Causal Link Prediction using Hyper-Relational Knowledge Graph</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-09-12">12 Sep 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Utkarshani</forename><surname>Jaimini</surname></persName>
							<email>ujaimini@email.sc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Artificial Intelligence Institute</orgName>
								<orgName type="institution">University of South Carolina</orgName>
								<address>
									<settlement>Columbia</settlement>
									<region>SC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cory</forename><surname>Henson</surname></persName>
							<email>coryhenson@us.bosch.com</email>
							<affiliation key="aff1">
								<orgName type="department">Bosch Center for Artificial Intelligence</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amit</forename><surname>Sheth</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Artificial Intelligence Institute</orgName>
								<orgName type="institution">University of South Carolina</orgName>
								<address>
									<settlement>Columbia</settlement>
									<region>SC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">HyperCausalLP: Causal Link Prediction using Hyper-Relational Knowledge Graph</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-09-12">12 Sep 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2410.14679v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Causal networks are often incomplete with missing causal links. This is due to various issues, such as missing observation data. Recent approaches to the issue of incomplete causal networks have used knowledge graph link prediction methods to find the missing links. In the causal link A causes B causes C, the influence of A to C is influenced by B which is known as a mediator. Existing approaches using knowledge graph link prediction do not consider these mediated causal links. This paper presents HyperCausalLP, an approach designed to find missing causal links within a causal network with the help of mediator links. The problem of missing links is formulated as a hyper-relational knowledge graph completion. The approach uses a knowledge graph link prediction model trained on a hyper-relational knowledge graph with the mediators. The approach is evaluated on a causal benchmark dataset, CLEVRER-Humans. Results show that the inclusion of knowledge about mediators in causal link prediction using hyper-relational knowledge graph improves the performance on an average by 5.94% mean reciprocal rank.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Causality is traditionally represented using a causal network, where the nodes represent events and edges represent the causal link between two events <ref type="bibr" target="#b13">(Pearl 2009)</ref>. Consider an example of a simple binary causal link: A causes B as shown in Figure <ref type="figure" target="#fig_0">1(A)</ref>. In this case, A is the cause, and B is the effect. Such causal links can also be chained together where A causes B and then B causes C. In a more complex case, there is a causal link between A and C that is mediated by B. The nodes A and C are called the cause and effect respectively, and the node B is called a mediator. A mediator helps in explaining the relationship between cause (independent node) and its effect (dependent node). It provides insights into the pathway linking cause and effect, capturing the contextual information. A complete network with all causal links is important for many downstream applications. In practice, however, causal networks are often incomplete with missing causal links. Recent approaches have successfully resolved this issue by encoding the causal network within a triplebased knowledge graph (i.e., Resource Description Framework (RDF) <ref type="bibr" target="#b5">(Jaimini, Henson, and Sheth 2023)</ref>) and then using knowledge graph link prediction techniques to find the missing causal links <ref type="bibr" target="#b6">(Jaimini, Henson, and Sheth 2024)</ref>. While the existing approaches using knowledge graph (KG) link prediction can predict direct binary causal links, e.g., A causes B, they cannot predict the more complex mediated causal links, e.g., A causes C mediated by B. The mediated link captures the context information. In this paper, we present a Hyper Causal Link Prediction approach, HyperCausalLP<ref type="foot" target="#foot_0">foot_0</ref> ), for finding the missing causal links in an incomplete causal network using hyper-relational KG link prediction. It uses hyper-relational causal knowledge graph (CausalKG) to represent the complex causal relations in the causal network. Figure <ref type="figure" target="#fig_0">1</ref>(C) shows how mediated causal links is encoded as a hyper-relation. RDF-star<ref type="foot" target="#foot_1">foot_1</ref> is used to encode these causal links <ref type="bibr" target="#b5">(Jaimini, Henson, and Sheth 2023)</ref>. The main contributions of this paper are: 1. A novel formulation of the task of finding missing causal links in an incomplete causal network as a hyperrelational KG completion problem. 2. Incorporation of mediated links into causal link prediction, which leads to improved performance. 3. Demonstration of the approach for causal link prediction using a causal benchmark dataset. 4. Use of additional domain knowledge for evaluating causal link prediction. The hyper-relational CausalKG is transformed into a KG embedding (KGE) model using StarE <ref type="bibr" target="#b2">(Galkin et al. 2020)</ref> algorithm, which uses a neural network-based messagepassing framework. This approach to finding missing causal links with mediators is evaluated using a causal benchmark dataset. StarE based hyper-relational KG extend a triple representation with any number of qualifies. It separates the qualifier relation and entity from the main triple. It does not have an upper bound on the number of qualifier per triple. The contributions of this paper are highlighted through the following four research questions:</p><p>• RQ1: Can the information contained in a causal network be effectively encoded into a hyper-relational causal KG? • RQ2: Can KG completion techniques, i.e., link prediction, be harnessed to uncover missing causal links? • RQ3: Does the integration of mediated links lead to improvements in the performance of causal link prediction? • RQ4: Does the integration of additional domain knowledge lead to improvements in the performance of causal link prediction?</p><p>The rest of the paper proceeds as follows: Section 2 describes the related work. Section 3 defines the problem formulation, followed by Section 4, which details the methodology. Section 5 details the evaluation, with the results and discussion outlined in Section 6. Section 7 provides a conclusion with future direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related work</head><p>Knowledge graph link prediction The KG link prediction approach ranges from translation-based models, semantic matching models, and convolutional neural network-based models <ref type="bibr" target="#b14">(Rossi et al. 2021;</ref><ref type="bibr" target="#b20">Wang et al. 2017;</ref><ref type="bibr" target="#b19">Wang, Qiu, and Wang 2021)</ref>. These methods learn embedding for each entity and relation and use a scoring function to predict the likelihood of a triple being true. The graph neural networkbased methods use message-passing approaches utilizing semantically rich neighborhood information present in the KG <ref type="bibr" target="#b18">(Vashishth et al. 2019;</ref><ref type="bibr" target="#b15">Schlichtkrull et al. 2018;</ref><ref type="bibr" target="#b11">Nguyen et al. 2022;</ref><ref type="bibr" target="#b10">Mohamed et al. 2023;</ref><ref type="bibr" target="#b8">Li et al. 2024)</ref>.</p><p>Causal link prediction The existing techniques for causal link prediction typically focus on predicting binary links within knowledge graphs and lack specific tailoring for identifying causal links. The existing approaches often simplify the modeling of causality into a binary triple. The recent work has aimed to generate event-related causal knowledge graphs from sources like Wikipedia and Wikidata, incorporating causal predicates like hasCause and hasEffect (Hassanzadeh 2022). These graphs represent events as nodes and cause-effect relationships as links, with the objective of predicting future events by analyzing the underlying causes and effects of similar past events. Evaluation of causal link prediction tasks often uses established techniques for knowledge graph link prediction. The causal ontology provides a representation platform for both triple-based and more intuitive hyper-relational graph-based causality representation <ref type="bibr" target="#b5">(Jaimini, Henson, and Sheth 2023)</ref>. The recent work on incorporating causal AI and causal network concepts into knowledge graph link prediction laid the foundation for causal link prediction with causal weights using weighted KG embedding model <ref type="bibr" target="#b6">(Jaimini, Henson, and Sheth 2024)</ref>.</p><p>Hyper-relational knowledge graph link prediction The appeal to modelling hyper-relational graphs are motivated from conventional triple-based KG embedding models which simplifies the complex property qualifiers. The convolutional model incorporates complex triples with k qualifiers (key, value) in one fact <ref type="bibr" target="#b3">(Guan et al. 2019)</ref>. However, all the qualifier pairs are treated equally and does not distinguish between main triple and relation-specific qualifiers.</p><p>The HyperCausalLP approach proposed in this paper innovatively builds upon learned causal networks by transforming them into a CausalKG. It is among the first to use the prior causal structure knowledge encoded in a causal network which in turn is represented in the causal knowledge graph. It distinguishes between the main and the mediated causal link. This transformation allows for the application of KG techniques to discover additional, previously unrecognized causal links, thereby enriching and expanding the causal network beyond what is possible with traditional methods alone. The HyperCausalLP approach predicts new causal links in a KG utilizing the causal weight and four causal relations, i.e., causes, causedBy, causesType, and causedByType.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem Formulation</head><p>The causal link prediction is formulated as a KG link prediction problem. This section defines the primary concepts, including causal relations, causal link, causal entity, qualifier, hyper-relation, and causal knowledge graph.</p><p>Causal knowledge graph: A causal knowledge graph CausalKG is a hyper-relational KG that includes causal knowledge in the form of causal relations and causal entities. CausalKG = (N , R, E, E c ):</p><p>• N : a set of nodes representing entities • R: a set of labels representing relations • E ⊆ N ×R×N : a set of edges representing links between pairs of entities. Each link is a triple &lt;h, r, t&gt;, where h is the head entity, r is the relation, t is the tail entity.  Causal entity: A causal entity n c ∈ N c is an entity that is the head or tail of a causal link. There are two types of causal entities: cause-entity (n cause ) and effectentity (n ef f ect ) such that the cause-entity causes the effectentity. However, in the case of a hyper-relation link, causal entity can also be the qualifier entity (n m ∈ N m ).</p><formula xml:id="formula_0">• N c ⊆ N : a set of nodes representing causal entities • R c ⊆ R: a set of labels representing causal relations • R m ⊆ R: a set of labels representing qualifier relations • N m ⊆ N c : a set of nodes representing qualifier entities • E c ⊆ N c × R c × N c × P (R m × N m ): a set</formula><p>Causal relation: A causal relation r c ∈ R c is a relation representing a causal association between entities. There are four types of causal relations:</p><formula xml:id="formula_1">• causes (r causes ∈ R c ) is a causal relation from the cause-entity to the effect-entity. • causedBy (r causedBy ∈ R c ) is a causal relation from</formula><p>the effect-entity to the cause-entity; i.e. the inverse of causes.</p><p>• causesT ype (r causesT ype ∈ R c ) is a causal relation from the cause-entity to the type of the effect-entity. • causedByT ype (r causedByT ype ∈ R c ) is a causal relation from the effect-entity to the type of the cause-entity.</p><p>Causal link: A causal link e c ∈ E c is an edge in the causal KG connecting a pair of causal entities with a causal relation. The causal link is a triple &lt;h c , r c , t c &gt;, where h c is the head causal entity, r c is the causal relation, and t c is the tail causal entity.</p><p>Qualifier pair: A qualifier pair q ∈ Q is a hyper-relation in the causal KG connecting a causal link with its hyperrelation relation-entity pair. Q is a set of qualifier pairs(r m , n m ) with qualifier relation r m , and qualifier entity n m .</p><p>Qualifier entity: A qualifier entity n m ∈ N m is a causal entity that is part of the qualifier pair. In a given serial causal connection, the qualifier entities (i.e., mediators) are the entities in between the cause-entity and effect-entity connected in a sequence, also known as mediators. In this paper, the qualifier entity refers to the mediator in the serial causal connection. In the context of the paper, the word qualifier entity and mediator can be used interchangeably.</p><p>Qualifier relation: A qualifier relation r m ∈ R m is a relation representing an association between causal link and qualifier entities (or mediator entity). There are two types of qualifier relations:</p><p>• hasM ediator (r hasM ediator ∈ R m ) is a qualifier relation from the causal link to the mediator-entity.</p><p>• hasM ediatorT ype (r hasM ediatorT ype ∈ R m ) is a qualifier relation from the causal link to the type of the mediator-entity.</p><p>Causal hyper-relational link: A causal link e c ∈ E c is an edge in the causal KG connecting a pair of causal entities with a causal relation and their associated mediators. Each causal hyper-relational link is a tuple &lt;h c , r c , t c , Q&gt;, where h c is the head causal entity, r c is the causal relation, t c is the tail causal entity, Q is a set of qualifier pairs(r m , n m ) with qualifier relation r m , and qualifier entity n m .</p><p>Causal link prediction: Causal link prediction is the task of finding new causal links in a CausalKG. Given a CausalKG G, this task can be implemented using knowledge graph link prediction. There are two types of distinct causal link prediction tasks: causal prediction and causal explanation.</p><p>1. Causal prediction: given a cause-entity (n cause ∈ N c ), the causesT ype relation (r causesT ype ∈ R c ), and the qualifier pair (Q), find the type (t) of the associated effect-entity such that &lt;n cause , r causesT ype , t, Q&gt; ∈ G holds.</p><p>2. Causal explanation: given an effect-entity (n ef f ect ∈ N c ), the causedByT ype relation (r causedByT ype ∈ R c ), and the qualifier pair (Q), find the type (t) of the associated cause-entity such that &lt;n ef f ect , r causedByT ype , t, Q&gt; ∈ G holds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>The HyperCausalLP approach is structured into four primary phases (see Figure <ref type="figure" target="#fig_2">2</ref>): (1) finding and encoding the known causal relations into a causal network, (2) translating the causal network into a hyper-relational CausalKG, conformant to the hyper-relational causal ontology incorporating the qualifier pairs (i.e. mediated links), (3) learning hyper-relational KG embedding for the CausalKG, and (4) predicting new causal links in the KG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Causal Network</head><p>A causal network is a graphical model structured as a directed acyclic graph <ref type="bibr" target="#b13">(Pearl 2009)</ref>. In this model, nodes represent events, and edges indicate the causal links between these events. The causal network denoted as CN = (N cn , E cn ), such that N cn is the set of nodes in the causal network, E cn is the set of edges between nodes. The direction of each edge in the network indicates the direction of causality. Given a three-node causal network, the causal links can have three different orientation structuresserial, fork, and collider. A serial structure is one where a causal association is traversed in a series, such as the first event is responsible for causing the second event, and the second event is responsible for causing the third event. In the fork structure, the first event is responsible for causing both the second and the third event. In the collider structure, two independent events are together responsible for causing the third event. However, in this paper, we only focus on the serial structure (Figure <ref type="figure" target="#fig_0">1</ref> (A)). The first node is considered a cause-entity, the second node is the mediator-entity, and the third node is the effect-entity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-relational Causal Knowledge Graph</head><p>The process of transforming data from a causal network into a hyper-relational causal knowledge graph (CausalKG) involves several straightforward conversions:</p><p>• N cn → N c : nodes in the causal network become causal entities in the CausalKG. The mediator nodes in the causal network become mediator entities in the CausalKG, which are represented as the qualifier entities. • E cn → E c : edges in the causal network become causal links in the CausalKG, of the form &lt;n cause , r causes ,</p><formula xml:id="formula_2">n ef f ect , r m , n m &gt;</formula><p>The CausalKG also incorporates other causal relations and qualifier relations such as : causedBy, causesT ype, causedByT ype, hasM ediator, and hasM ediatorT ype. The CausalKG consists of all the information from the causal network and is conformant to the hyper-relational causal ontology (Jaimini, Henson, and Sheth 2023; Jaimini and Sheth 2022). The causal ontology is rooted in concepts from causal AI like causal Bayesian networks and do-calculus <ref type="bibr" target="#b5">(Jaimini, Henson, and Sheth 2023)</ref>. It is used to define the semantics and structure of causal relations and the nodes in the causal network. The ontology defines the primary concepts used to structure a CausalKG, including causal entities, causal relations, and mediators.</p><p>The CausalKG is used for causal link prediction using KG link prediction. There are two causal link prediction tasks: causal explanation and causal prediction. The goal of causal explanation is to predict the type of a cause-entity that is linked to an effect-entity. The goal of causal prediction is to predict the type of an effect-entity that is linked to a cause-entity. The goal for both tasks is not to predict the specific cause-entity (in the case of causal explanation) or effect-entity (in the case of causal prediction) instance but the type of these respective entities. The causeentity (in the case of causal explanation) and effect-entity (in the case of causal prediction) are not directly linked with the cause-entity type and effect-entity, respectively. They are two-hop away: &lt;n ef f ect , r causedBy , n cause &gt;, &lt;n cause , rdf : type, type&gt; for causal explanation; and &lt;n cause , r causes , n ef f ect &gt;, &lt;n ef f ect , rdf : type, type&gt; for causal prediction. The embedding models make predictions about directly linked entities. To overcome the issue of two-hop link prediction, CausalKG uses reified relation (see Figure <ref type="figure" target="#fig_3">3</ref>)-1) for causal prediction: causeT ype (r causesT ype ∈ R c ) to add a link connecting a cause-entity with the type of an effect-entity, and 2) for causal explanation: causedByT ype (r causedByT ype ∈ R c ) to add a link connecting an effectentity with the type of a cause-entity. Along with all the above knowledge, the CausalKG also integrates additional domain knowledge associated with the entities that are not distinctly mentioned in the causal network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CausalKG Embedding and Link Prediction</head><p>The CausalKG is converted into a low-dimensional continuous latent vector space representation called KG embeddings (KGE). The KGE is used for downstream tasks such as link prediction, entity classification, triple classification, etc., <ref type="bibr" target="#b20">(Wang et al. 2017</ref>). The proposed Hyper-CausalLP approach uses KG embedding algorithms to generate embedding that will be used for causal link prediction. The proposed approach learns two types of KGEs for a CausalKG: 1) CausalKGE-Base embedding without mediators (no hyper-relations), and 2) CausalKGE-M embeddings with mediators as hyper-relations (represented using qualifier pairs). The CausalKGE-Base embedding is trained using the causal links, ignoring the mediators associated with each link. The CausalKGE-M embedding, on the other hand, is trained using the causal links with the mediators as the hyper-relational links (i.e. qualifiers). The CausalKGE-Figure <ref type="figure">4</ref>: StarE encoder, which encodes a hyper-relations for the causal relation <ref type="bibr" target="#b2">(Galkin et al. 2020</ref>). The hyper-relation qualifier pairs (or mediator pairs) are passed through a composition function ϕ q , which are summed together and transformed by weights W q . The transformed vector is merged with γ and ϕ r . The final node i.e. cause entity combines messages from all the hyper-relation. [Note: As specified in StarE-1) ϕ is a composition function of a node with its respective relation, 2) W γ(r) is a direction-specific shared parameter for outgoing, incoming, and self-looping relations, 3) γ is a function that combines the main relation, (r c ) representation with the representation of its qualifiers, (Q) Base and CausalKGE-M embeddings are evaluated on the task of causal link prediction using KG link prediction. The CausalKG embeddings for CausalKGE-Base are generated using KG embedding algorithms available in the Ampligraph library <ref type="bibr" target="#b1">(Costabello et al. 2019)</ref>. The CausalKGE-Base uses the four prominent KGE algorithms: TransE <ref type="bibr" target="#b0">(Bordes et al. 2013)</ref>, DistMult <ref type="bibr" target="#b22">(Yang et al. 2014)</ref>, HolE <ref type="bibr" target="#b12">(Nickel, Rosasco, and Poggio 2016)</ref>, and ComplEx <ref type="bibr" target="#b17">(Trouillon et al. 2016</ref>) for embedding generation. The CausalKGE-M is generated a graph neural network based, hyper-relational KGE model, StarE <ref type="bibr" target="#b2">(Galkin et al. 2020)</ref>.</p><p>StarE is a graph neural network-based approach. It allows a varied number of qualifier pairs to be associated with the causal link. It combines the causal relation embedding with a fixed-length vector representing the associated qualifier pair. It incorporates qualifiers paired with the causal link into the message passing process. The StarE model comprises two parts: a StarE encoder (Figure <ref type="figure">4</ref>) and a Transformer decode. The StarE encoder and transformer-based decoder are jointly trained. It initializes two embedding matrices, R (relations) and E (entities). StarE iteratively updates the embedding by message passing across edges in the training set. For the task of link prediction, the query is first linearized, and the updated embedding is used to encode the relation and entities. It is then passed through the transformer. The output of the transformer is averaged to get a fixed-dimensional vector representation of the query. The vector is passed through a fully connected layer, multiplied with the entity, and passed through a sigmoid function to obtain probability distribution over all entities. The top n candidate entities for the link pre-diction query are obtained.</p><p>The proposed approach, HyperCausalLP, formalizes the problem of causal link prediction as a KG link prediction task. The trained CausalKG embedding models, i.e. CausalKGE-Base and CausalKGE-M, are used to predict missing causal links between causal entities in the KG. For a given causal link, causal explanation predicts links of form &lt; n ef f ect , r causedByT ype , ?,Q&gt;, and causal prediction predicts links of form &lt; n cause , r causesT ype , ?,Q&gt;. For a given dataset with causal entities, causal relations, and mediators associated with the causal links between the entities, Hy-perCausalLP can be used to create a CausalKG and generate and learn KGE. The generated KGE can be used for causal link prediction. In the next section, we demonstrate and evaluate HyperCausalLP using CLEVRER-Humans, a causal reasoning benchmark dataset <ref type="bibr" target="#b9">(Mao et al. 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>The proposed, HyperCausalLP, hyper-relational graph based causal link prediction approach is evaluated using the KG link prediction for two distinct causal link prediction tasks The above evaluation is demonstrated using a causal benchmark dataset. This section details the data, pre-processing steps, creation of a CausalKG from the dataset, experimental setup, evaluation metrics, and description of the evaluation with additional domain knowledge. (Please refer to supplementary for additional details) Data CLEVRER-Humans is a causal benchmark dataset featuring human-annotated causal judgments about physical events depicted in videos <ref type="bibr" target="#b9">(Mao et al. 2022)</ref>. The videos display moving objects that vary in shape (sphere, cube, and cylinder), color (blue, red, yellow, green, purple, gray, cyan, and brown), and material (metal and rubber). Each object can be involved in one of 27 distinct events, such as enter, exit, collide, move, hit, bump, and roll. CLEVRER-Humans captures the causal information from these events using a Causal Event Graph (CEG), where the graph's nodes represent event descriptions from the videos and the directed edges indicate causal relationships. The edges of the CEGs are evaluated by human annotators to determine the strength of the causal links between the nodes. These edges are scored on a scale from 1 to 5, where 1 means "not responsible at all," 2 means "a bit responsible," 3 means "moderately responsible," 4 means "quite responsible," and 5 means "extremely responsible.". It is the only large scale causal dataset with 891 causal networks (i.e., CEG) which provides ground truth for the causal links.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Pre-processing</head><p>The initial step in generating a CLEVRER-Humans CausalKG involves pre-processing the CEGs. The CEGs serve as a proxy for a causal network, and their preprocessing is crucial to ensure they align with the definition of a causal network. In a causal network, edges represent causal links between nodes. The first step in this process is to remove edges with a score of 1, indicating no causal responsibility between the two nodes. Next, to maintain the structure of a directed acyclic graph, edges that create cycles in the CEGs are removed. Finally, CEGs are excluded if they do not have any remaining causal links or have a depth of less than 2 from the root node to the leaf node. After preprocessing, we are left with 764 CEGs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-relational CausalKG</head><p>A hyper-relational CausalKG is created from CLEVRER-Humans by encoding the causal information within the CEGs in RDF 3 format, adhering to the causal ontology. The proposed approach creates two different KG: CausalKG-Base and CausalKG-M (Figure <ref type="figure" target="#fig_0">1</ref>). The CausalKG-Base is a simple KG with causal links, whereas CausalKG-M is a hyper-relational KG, which consists of mediators as hyperrelations (qualifiers). The hyper-relation with the mediator information between two given nodes in the CEG is encoded using RDF-star format. The KG not only includes causal relationships but also details about events (such as hit, collide, push, etc.), the involved objects, and their attributes. CEGs serve as graphical representations of events in the videos. To represent information from the CEGs, we utilize three ontologies: the causal ontology, the scene ontology (prefixed with "so:"), and the semantic sensor network ontology (prefixed with "ssn:"). The causal ontology is employed for events (as causal entities), causal relations, and their corresponding causal mediators (i.e., qualifier pairs). The scene 3 <ref type="url" target="https://www.w3.org/RDF/">https://www.w3.org/RDF/</ref> and sensor ontologies depict additional video information, such as scenes, objects, and object characteristics <ref type="bibr" target="#b21">(Wickramarachchi, Henson, and Sheth 2021;</ref><ref type="bibr" target="#b16">Taylor et al. 2019)</ref>. Each video is depicted as a scene (so:Scene) using scene ontology concepts. This includes representing and connecting the events within the scene (using the so:includes relation), the objects involved (using the so:hasParticipant relation), and the object characteristics (using the ssn:hasProperty relation) <ref type="bibr" target="#b21">(Wickramarachchi, Henson, and Sheth 2021)</ref>. In total, the CausalKG from CLEVRER-Humans contains &gt;48K links, 5664 entities, 31 entity types, and 10 relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Diversifying the Available Knowledge</head><p>The CausalKGE-Base and CausalKGE-M embeddings are generated and evaluated on different CLEVRER-Humans CausalKG subgraph structures for the tasks of causal explanation and causal prediction, as illustrated in Figure <ref type="figure" target="#fig_5">6</ref>. In the case of CausalKG-M and the given subgraph, the hyper-relations (qualifier pairs) are associated with causes, and causedBy causal relation as shown in Figure <ref type="figure" target="#fig_3">3</ref>. Various graph structures are utilized to assess the performance of HyperCausalLP when different types of information are available in the CausalKG. Specifically, two distinct subgraph structures are defined with increasing levels of expressivity. 1. The first graph structure, C, shown in Figure <ref type="figure" target="#fig_5">6</ref>(a), contains only links with causal relations. 2. The second graph structure, CT, shown in Figure <ref type="figure" target="#fig_5">6</ref>(b), includes links with causal relations and causal entity types (i.e., rdf:type). We optimized the hyper-parameters for each of these graph structures for causal link prediction tasks i.e., causal explanation and prediction tasks. The CausalKGE-Base models for each graph structures are trained on their respective optimized hyper-parameters (Please refer to supplementary text for more details). The CausalKGE-M model is trained on the StarE hyper-parameters <ref type="bibr" target="#b2">(Galkin et al. 2020)</ref>. The trained CausalKGEs are then employed for causal link prediction tasks using well-established link prediction methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>HyperCausalLP was evaluated using the KG link prediction for causal link prediction. For a given set of causal links E c in CausalKG, a set of corrupted links T ′ are generated by altering the tail t c or head h c of a set of causal links, &lt;h c , r c , t c , Q&gt;, with another causal entity in the KG. Such as replacing the head with h ′ c ̸ = h c results in &lt;h ′ c , r c , t c , Q&gt; and replacing the tail with t ′ c ̸ = t c results in &lt;h c , r c , t ′ c , Q&gt;. The model assigns scores to the true link &lt;h c , r c , t c , Q&gt; and corrupted links &lt;h ′ c , r c , t c , Q&gt;, &lt;h c , r c , t ′ c , Q&gt; ∈ T ′ . The scores are sorted to obtain the rank of the true link. The filtered evaluation setting and filtered corrupted links T ′ are used to exclude the links present in the training and validation set. The performance of the HyperCausalLP was evaluated using two metrics-Mean reciprocal rank (MRR), and Hits@K (Hits@K, where K=1,3,10). MRR is the mean over the reciprocal of individual ranks of the test links. Hits@k is the ratio of test links present among the top k-ranked links. The higher values of both metrics signify the better performance of the model. The experiments are performed on a server with NVIDIA TESLA V100 GPU (32 GB GPU memory) and Intel Xeon Platinum 8260 CPU @2.40GHz.</p><p>Table <ref type="table">1</ref>: Evaluation metric results for causal prediction for different subgraph structures as shown in Figure <ref type="figure" target="#fig_5">6</ref>. Hyperrelational CausalKG model with mediator (StaE) show significantly improved performance (underlined) in both mean reciprocal rank (MRR) and Hits@k.</p><p>Table 2: Evaluation metric results for causal explanation for different subgraph structures as shown in Figure <ref type="figure" target="#fig_5">6</ref>. Hyperrelational CausalKG model with mediator (StaE) show significantly improved performance (underlined) in both mean reciprocal rank (MRR) and Hits@k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>To evaluate HyperCausalLP, we first transformed the CEGs (i.e., causal network) in the CLEVRER-Humans dataset to a hyper-relational CausalKG (RQ1). The causal links in the hyper-relational CausalKG preserve the structure of the causal relations. The hyper-relational CausalKG from CLEVRER-Humans is then transformed into KG embeddings. We consider two types of embeddings: baseline embeddings (i.e., without mediators as hyper-relations) and mediated embeddings. HyperCausalLP was evaluated on CausalKG generated from the CLEVRER-Humans dataset for causal link prediction tasks using the trained KG embeddings (RQ2). The approach was evaluated on CausalKG-M with StarE with two hyper-relations (i.e., hasMediator and hasMediatorType) along with different CausalKG subgraphs (Figure <ref type="figure" target="#fig_5">6</ref>) Table <ref type="table">2</ref>, Table <ref type="table">1</ref> shows the performance of MRR and Hit@K(k=1,3,10) for five KGE models evaluated on different CausalKG subgraph which demonstrate the use of additional knowledge. The results (i.e MRR, HitK) shows a significant increase in the performance of CausalKG-M over CausalKG-Base, the baseline models with no hyperrelations (or mediator information) and just links ((RQ3)). The CausalKG-Base was evaluated with four KGE models-TransE, DistMult, HolE, and ComplEx. The incorporation of additional knowledge (i.e., CT) in the CausalKG-M across different mediator setup shows improved MRR performance over the simpler C subgraph by 5.47% on average for the causal link prediction tasks ((RQ4)). The incorporating mediators with causal link provides an additional knowledge which is crucial for the causal link prediction task. The hyper-relation, hasMediator and hasMediatorType performs the best comparing the MRRs and Hit@k across the board. We successfully demonstrated the knowledge incorporated in the hyper-relations (qualifies) significantly improves the causal link prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>The paper introduced an approach to finding missing causal link in an incomplete causal network. The HyperCausalLP, a hyper-relational KG based causal link prediction using KG prediction. The proposed method incorporates the mediator information from the CBN as a hyper-relation in the KG. The KGE models trained with qualifier (mediator, or hyper-relations) outperform all baseline KGE metrics without qualifiers. The results demonstrate that an effective fusion of causal links with qualifier (mediator, or hyper-relations) in a KG can facilitate the completion of incomplete causal network. Future work will investigate incorporating a varied number and type of mediators as hyperrelations, which will allow multi-hop causal entity prediction. We would also like to extend the HyperCausalLP with a selection of hyper-relational KG embedding models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Causal link. (A) A serial causal connection where A causes B and eventually B causes C. The node A is known as a cause, C is known as an effect, and B is known as a mediator. (B) A serial causal link, the link is encoded as a knowledge graph link using RDF format, (C) Causal link as a hyper-relational link where the mediator entity is represented a hyper-relation with the hyper-relation predicate, hasMediator. The link is encoded as a knowledge graph link using RDF-Star format</figDesc><graphic coords="1,331.43,306.43,214.64,158.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>of edges representing causal hyper-relation link connecting pairs of causal entities. P denotes the power set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: HyperCausalLP has four primary phases: 1) encoding the causal associations in data as a causal network, 2) translating the causal network into a causal knowledge graph, 3) learning knowledge graph embeddings (CausalKG-Base and hyperrelational graph based embedding CausalKG-M with mediators as hyper-relations) from the causal knowledge graph, and 4) using the knowledge graph embeddings for causal link prediction tasks.</figDesc><graphic coords="3,54.00,54.00,504.00,127.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The figure shows reified causal relations, causes-Type and causedByType. The causedByType is a reified relation from an effect-entity instance to the type of a causeentity. The causesType is a reified relation from a causeentity instance to the type of an effect-entity. It also illustrates the two qualifier relations associated with causes relation: hasMediator and hasMediatorType. The qualifier relations are also associated with the causedBy relation, which is an inverse of the causes relation.</figDesc><graphic coords="4,101.70,307.79,143.10,141.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: A snapshot of the CausalKG-Base and CausalKG-M representation. (A) A snapshot of collision events in a video at time t-1, t, and t+1 from the CLEVRER-Humans. There are three consecutive collision events that occur: A: the red cube collides with the yellow ball, B: the yellow ball hits the blue cylinder, and C: the blue cylinder moves. The A, B, C are causal entities. A.Type is Collide, B.Type is Hit, and C.Type is Move. (B) The causal event graph of the above snapshot. (C) The causal and mediator (qualifier pairs) links representation in the two different CausalKG.</figDesc><graphic coords="6,77.85,144.98,190.80,170.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: CausalKG structures with additional knowledge (a) subgraph C which consists of links with only causal relations, i.e. causes, causedBy, causesType, and causedByType, (b) subgraph CT with causal relations and information about entity types, i.e. rdf:type In the case of CausalKG-M, the hyper-relations (qualifier pair) are associated with causes, and causedBy causal relation.</figDesc><graphic coords="6,319.50,500.96,238.50,99.21" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Code -https://github.com/CausalKG/HyperCausalLP/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.w3.org/2021/12/rdf-star.html</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">AmpliGraph: a Library for Representation Learning on Knowledge Graphs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Costabello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Van</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcgrath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tabacof</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Galkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Maheshwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Usbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.10847</idno>
		<title level="m">Message passing for hyper-relational knowledge graphs</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Link prediction on n-ary relational data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The world wide web conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Building a Knowledge Graph of Events and Consequences Using Wikipedia and Wikidata</title>
		<author>
			<persName><forename type="first">O</forename><surname>Hassanzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Wiki Workshop at The Web Conference</title>
		<meeting>the Wiki Workshop at The Web Conference</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An Ontology Design Pattern for Representing Causality</title>
		<author>
			<persName><forename type="first">U</forename><surname>Jaimini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Henson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th Workshop on Ontology Design and Patterns</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">CausalLP: Learning causal relations with weighted knowledge graph link prediction</title>
		<author>
			<persName><forename type="first">U</forename><surname>Jaimini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Henson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Sheth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.02327</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CausalKG: Causal Knowledge Graph Explainability using interventional and counterfactual reasoning</title>
		<author>
			<persName><forename type="first">U</forename><surname>Jaimini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="50" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Evaluating graph neural networks for link prediction: Current pitfalls and new benchmarking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shomer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">CLEVRER-Humans: Describing Physical and Causal Events the Human Way</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="7755" to="7768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Locality-aware subgraphs for inductive link prediction in knowledge graphs</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pilutti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Del Bue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pelillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vascon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<biblScope unit="page" from="90" to="97" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Node co-occurrence based graph neural networks for knowledge graph link prediction</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Fifteenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1589" to="1592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Holographic embeddings of knowledge graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Causality</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding for link prediction: A comparative analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Firmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Matinata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Merialdo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="49" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The semantic web: 15th international conference</title>
		<meeting><address><addrLine>Heraklion, Crete, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-06-03">2018. 2018. June 3-7, 2018</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Semantic Sensor Network Ontology, Revamped</title>
		<author>
			<persName><forename type="first">K</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Haller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lefranc ¸ois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Janowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garcia-Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Le Phuoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lieberman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stadler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JT@ ISWC</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bouchard</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2071" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Composition-based multi-relational graph convolutional networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vashishth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nitin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03082</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A survey on knowledge graph embeddings for link prediction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Symmetry</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">485</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding: A survey of approaches and applications</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2724" to="2743" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Knowledge-infused learning for entity prediction in driving scenes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wickramarachchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Henson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in big Data</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">759110</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>-T.; He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6575</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
