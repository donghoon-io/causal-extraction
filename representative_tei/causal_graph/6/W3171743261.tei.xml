<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Explaining Algorithmic Fairness Through Fairness-Aware Causal Path Decomposition</title>
				<funder ref="#_9vPAGFC">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
				<funder ref="#_8wT29ve">
					<orgName type="full">Amazon Web Service</orgName>
					<orgName type="abbreviated">AWS</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Weishen</forename><surname>Pan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Artificial Intelligence</orgName>
								<orgName type="department" key="dep2">Beijing National Research Center for Information Science and Technology (BNRist)</orgName>
								<orgName type="department" key="dep3">Department of Automation</orgName>
								<orgName type="laboratory">State Key Lab of Intelligent Technologies and Systems</orgName>
								<orgName type="institution" key="instit1">Tsinghua University (THUAI)</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<address>
									<country key="CN">P.R.China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sen</forename><surname>Cui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Artificial Intelligence</orgName>
								<orgName type="department" key="dep2">Beijing National Research Center for Information Science and Technology (BNRist)</orgName>
								<orgName type="department" key="dep3">Department of Automation</orgName>
								<orgName type="laboratory">State Key Lab of Intelligent Technologies and Systems</orgName>
								<orgName type="institution" key="instit1">Tsinghua University (THUAI)</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<address>
									<country key="CN">P.R.China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jiang</forename><surname>Bian</surname></persName>
							<email>bianjiang@ufl.edu</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Health Outcomes and Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Artificial Intelligence</orgName>
								<orgName type="department" key="dep2">Beijing National Research Center for Information Science and Technology (BNRist)</orgName>
								<orgName type="department" key="dep3">Department of Automation</orgName>
								<orgName type="laboratory">State Key Lab of Intelligent Technologies and Systems</orgName>
								<orgName type="institution" key="instit1">Tsinghua University (THUAI)</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<address>
									<country key="CN">P.R.China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fei</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Population Health Sciences</orgName>
								<orgName type="institution">Weill Cornell Medicine</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Explaining Algorithmic Fairness Through Fairness-Aware Causal Path Decomposition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>fairness</term>
					<term>explanation</term>
					<term>causal graph</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Algorithmic fairness has aroused considerable interests in data mining and machine learning communities recently. So far the existing research has been mostly focusing on the development of quantitative metrics to measure algorithm disparities across different protected groups, and approaches for adjusting the algorithm output to reduce such disparities. In this paper, we propose to study the problem of identification of the source of model disparities. Unlike existing interpretation methods which typically learn feature importance, we consider the causal relationships among feature variables and propose a novel framework to decompose the disparity into the sum of contributions from fairness-aware causal paths, which are paths linking the sensitive attribute and the final predictions, on the graph. We also consider the scenario when the directions on certain edges within those paths cannot be determined. Our framework is also model agnostic and applicable to a variety of quantitative disparity measures. Empirical evaluations on both synthetic and real-world data sets are provided to show that our method can provide precise and comprehensive explanations to the model disparities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>â€¢ Mathematics of computing â†’ Causal networks; â€¢ Computing methodologies â†’ Supervised learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Machine learning algorithms have been widely applied in a variety of real-world applications including high-stakes scenarios such as loan approvals, criminal justice, healthcare, etc. In these real-world applications, fairness is getting increasing attentions as machine learning algorithms may lead to discrimination against certain disadvantaged sub-populations. This triggers the research on algorithmic fairness, which focus on whether members of specific unprivileged groups are more likely to receive unfavorable decisions made from machine learning algorithms.</p><p>One important line of research in the computational fairness community is to develop metrics for measuring group fairness, such as demographic parity <ref type="bibr" target="#b10">[11]</ref>, equalized opportunity <ref type="bibr" target="#b13">[14]</ref>, accuracy parity <ref type="bibr" target="#b31">[32]</ref>, etc., so that the discrepancy among the decisions made in different groups (a.k.a. disparity) are precisely quantified, which can further inspire the development of fair machine learning models that aim to minimize such disparities <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>Despite the great efforts on fairness quantification and fair model development, one critical issue that has not been studied extensively is the diagnostics of model fairness, i.e., what are the reasons that lead to the model disparity? This information is crucial for understanding the intrinsic model mechanism and provides insights on how to improve model fairness. As an example, under the current pandemic, researchers have found that the racial and ethnic minority groups have been disproportionately affected by COVID-19. African Americans and Hispanics or Latinos are found to be more likely to have positive tests <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b22">23]</ref>, COVID-19 associated hospitalizations and deaths <ref type="bibr" target="#b25">[26]</ref>, compared with non-Hispanic Whites. In this case, it is crucial to figure out whether such disparity is coming from genetic factors or accessibility to adequate healthcare services, which will imply completely different clinical management plans and public health policies for battling with the pandemic.</p><p>In view of this need, recently researchers have leveraged Shapley value based methods <ref type="bibr" target="#b20">[21]</ref> to attribute the model disparity as the sum of individual contributions from input features <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20]</ref>, so that we can understand which feature contributes more or less to the model disparity. However, in real-world problems, the mechanism that causes model disparity could be much more complex. Considering the COVID-19 example above, it turns out that one main factor contributing to such disparity is disproportionate access to care for patients with different races and ethnicity, which can be impacted by both economic status <ref type="bibr" target="#b12">[13]</ref> and food insecurity <ref type="bibr" target="#b29">[30]</ref>. In practice, they correspond to two different causal paths leading to outcome disparity and imply different public health intervention policies.</p><p>In this paper, we propose FACTS (which stands for Fairness-Aware Causal paTh decompoSition), a novel framework for algorithm fairness explanation. FACTS decomposes the model disparity as the sum over the contributions of a set of Fairness-Aware Causal paThs (FACT) linking the sensitive attributes with the outcome variable. In this way, our approach can quantify the different causality mechanisms that can lead to the overall model disparity. Specifically, FACTS includes two steps:</p><p>â€¢ Step 1. FACTs identification, where we propose a method to identify all active paths that link the sensitive attributes and final outcome without colliders given a causal graph constructed on feature variables (which are referred to as FACTs). The graph could be given according to domain knowledge or arXiv:2108.05335v1 [cs.LG] 11 Aug 2021 learned from the training data. One important consideration here is that frequently the causal directions for certain edges on the graph cannot be determined <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b24">25]</ref>, which makes the graph a Partially Directed Acyclic Graph (PDAG). Our proposed algorithm can effectively identify active paths on PDAGs. â€¢ Step 2. Disparity attribution through Shapley value decomposition, where we propose a Shapley value <ref type="bibr" target="#b20">[21]</ref> based method to attribute the quantified model disparity value (e.g., according to demographic parity <ref type="bibr" target="#b10">[11]</ref>) to identified FACTs, so that the contribution of each FACT can be quantified.</p><p>In addition, with the derived attributed disparity on FACTs, we further develop a fair learning approach by selectively removing the FACTs based on their effects on disparity and accuracy through data transformation. Our framework is model agnostic and can be applied to a broad set of popular group-fairness criteria including demographic parity, equalized opportunity, equalized odds, and accuracy parity.</p><p>With experiments on both synthetic and real-world datasets, we show that FACTS can accurately quantify individual path contributions to the model disparity. With qualitative analysis on real-world datasets, we demonstrate how our approach can appropriately explain the sources of disparity and successfully make fair adjustments 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES AND RELATED WORKS 2.1 Notations</head><p>In this paper, we use capitalized/lower-case letters in italics to represent a variable/value of the variable. We use capitalized/lower-case letters in boldface to represent a variable set/values of the variable set. We use {. . . } to represent a set without ordering relationship and use [. . . ] to represent a sequence. ğœ‹ is a function indicating the rank of specific elements in an ordered sequence. For example, for an order pair of features [ğ‘‹ 1 , ğ‘‹ 2 ], we will have ğœ‹ (1) &lt; ğœ‹ (2).</p><p>Suppose we are given a dataset including samples characterized by a set of variables {ğ´, X, ğ‘Œ }, where X = {ğ‘‹ 1 , ..., ğ‘‹ ğ‘€ } is the set of input feature variables. ğ´ âˆˆ {0, 1} is the sensitive attribute and ğ‘Œ âˆˆ {0, 1} is the outcome. We set ğ‘Œ = 1 as the favored outcome. ğ‘“ is a trained model and Å¶ is the predicted outcome.</p><formula xml:id="formula_0">x = (ğ‘¥ 1 , ğ‘¥ 2 , â€¢ â€¢ â€¢ , ğ‘¥ ğ‘€ ) âŠ¤ is a concrete data vector with ğ‘‹ 1 = ğ‘¥ 1 , ğ‘‹ 2 = ğ‘¥ 2 , â€¢ â€¢ â€¢ , ğ‘‹ ğ‘€ = ğ‘¥ ğ‘€ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Causal Model</head><p>We introduce causal model-related concepts that will be used throughout the paper in this subsection. Our descriptions are based on the definitions in <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b27">28]</ref>. Nodes and Edges. A graph G consists of a set of nodes (variables) {ğ´, ğ‘Œ , Å¶ , ğ‘‹ 1 , . . . , ğ‘‹ ğ‘€ } and a set of edges (variable relations). The edges can be either directed (â†’) and undirected (-). We call two nodes are adjacent to each other if there is an edge linking them. The collection of nodes adjacent to ğ‘‹ ğ‘– is denoted as Adj(ğ‘‹ ğ‘– ). Paths. A path ğ‘ from ğ‘‹ ğ‘– to ğ‘‹ ğ‘— in G is a sequence of nodes where every successive nodes are adjacent in G. A path from ğ‘‹ ğ‘– to ğ‘‹ ğ‘— in 1 We upload our source code on <ref type="url" target="https://github.com/weishenpan15/FACTS">https://github.com/weishenpan15/FACTS</ref>. In the example shown in Figure <ref type="figure">1</ref>, there are paths (e.g., ğ´ â†’ ğ‘‹ 3 â† ğ‘‹ 4 ) linking ğ´ and ğ‘‹ 4 , but ğ´ and ğ‘‹ 4 are independent due to fact that they are linked by a collider ğ‘‹ 3 . To characterize the variable relationships, we introduce the following definitions. If a path ğ‘ contains ğ‘‹ ğ‘– â†’ ğ‘‹ ğ‘˜ â† ğ‘‹ ğ‘— as a subpath, then ğ‘‹ ğ‘˜ is a collider on ğ‘. For a given set of nodes C (referred to as the conditioning set), a node ğ‘‹ ğ‘– is active relative to C on a path ğ‘ if either: 1) ğ‘‹ ğ‘– is a not a collider on ğ‘ and not in C; 2) ğ‘‹ ğ‘– is a collider, and ğ‘‹ ğ‘– or any of its descendants is in C. A path is active relative to C only when every node on the path is active relative to C. When C = âˆ…, the definition of an active path is degenerated to that there is no collider on the path. When we say ğ‘ is an active path, we means ğ‘ is an active path relative to âˆ… in this paper.</p><p>As in Figure <ref type="figure">1</ref>, considering the path ğ´ â†’ ğ‘‹ 3 â†’ Å¶ when C = âˆ…, ğ‘‹ 3 is an active node since ğ‘‹ 3 is not a collider. Thus ğ´ â†’ ğ‘‹ 3 â†’ Å¶ is an active path. Similarly, ğ´ â†’ ğ‘‹ 3 â† ğ‘‹ 4 is not an active path because ğ‘‹ 3 is a collider. But ğ´ â†’ ğ‘‹ 3 â† ğ‘‹ 4 is an active path relative to {ğ‘‹ 3 } since ğ‘‹ 3 is a collider in the conditioning set {ğ‘‹ 3 } . Faithfulness. The distribution of the variables and G are faithful to each other means for all ğ‘‹ ğ‘– , ğ‘‹ ğ‘— , C, ğ‘‹ ğ‘– is conditional independent with ğ‘‹ ğ‘— on C if and only if there exists no active path from ğ‘‹ ğ‘– to ğ‘‹ ğ‘— with relative to C. Faithfulness is an important and common assumption in the research field of causality, which will be also used in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Fairness and Disparity</head><p>We list some popular algorithmic fairness definitions as follows: Demographic Parity (DP) <ref type="bibr" target="#b10">[11]</ref>. A prediction Å¶ satisfies demographic parity if ğ‘ƒ ( Å¶ = 1|ğ´ = 1) = ğ‘ƒ ( Å¶ = 1|ğ´ = 0).</p><p>Equalized Odds <ref type="bibr" target="#b13">[14]</ref>. A prediction Å¶ satisfies equalized opportunity if ğ‘ƒ ( Å¶ = 1|ğ‘Œ = ğ‘¦, ğ´ = 1) = ğ‘ƒ ( Å¶ = 1|ğ‘Œ = ğ‘¦, ğ´ = 0), âˆ€ğ‘¦ âˆˆ {0, 1}. Equalized Opportunity (EO) <ref type="bibr" target="#b13">[14]</ref>. A prediction Å¶ satisfies equalized opportunity if ğ‘ƒ ( Å¶ = 1|ğ‘Œ = 1, ğ´ = 1) = ğ‘ƒ ( Å¶ = 1|ğ‘Œ = 1, ğ´ = 0). Accuracy Parity <ref type="bibr" target="#b31">[32]</ref> A prediction Å¶ satisfies accuracy parity if</p><formula xml:id="formula_1">ğ‘ƒ ( Å¶ = ğ‘Œ |ğ´ = 1) = ğ‘ƒ ( Å¶ = ğ‘Œ |ğ´ = 0).</formula><p>In practice, we can take the difference between the two sides of the equalities in the above definitions as a quantification measure for disparity. For example,</p><formula xml:id="formula_2">Î” ğ·ğ‘ƒ = ğ‘ƒ ( Å¶ = 1|ğ´ = 1) -ğ‘ƒ ( Å¶ = 1|ğ´ = 0) (1) Î” ğ¸ğ‘‚ = ğ‘ƒ ( Å¶ = 1|ğ‘Œ = 1, ğ´ = 1) -ğ‘ƒ ( Å¶ = 1|ğ‘Œ = 1, ğ´ = 0) (2)</formula><p>are two popular algorithm disparity measures used in fairness learning algorithms <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b26">27]</ref>. Here we follow the work of <ref type="bibr" target="#b5">[6]</ref> to use signed difference across groups to show which group is privileged. These fairness definitions are based on the (conditional) independence of the Å¶ and the ğ´, which can be determined using the causal graph <ref type="bibr" target="#b4">[5]</ref>. For example, according to the definitions in Section 2.2, Å¶ is independent to ğ´ if there is no active path between them, which can obtain demographic parity. In other words, any non-zero Î” ğ·ğ‘ƒ comes from the active paths linking ğ´ and Å¶ . In the example in Figure <ref type="figure">1</ref>, active paths between ğ´ and Å¶ contain ğ´ â† ğ‘‹ 1 â†’ Å¶ , ğ´ â†’ ğ‘‹ 2 â†’ Å¶ and ğ´ â†’ ğ‘‹ 3 â†’ Å¶ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Shapley Values</head><p>Shapley values is a popular concept that has been used in model interpretation in recent years <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21]</ref>. These methods typically decompose the prediction ğ‘“ (x) for a given x as follows.</p><formula xml:id="formula_3">ğ‘“ (x) = ğœ™ ğ‘“ (0) + âˆ‘ï¸ ğ‘€ ğ‘–=1 ğœ™ ğ‘“ (x) (ğ‘–)<label>(3)</label></formula><p>where ğœ™ ğ‘“ (x) (ğ‘–) is the contribution of feature ğ‘‹ ğ‘– to ğ‘“ (x). ğœ™ ğ‘“ (0) = Eğ‘“ (X) is the averaged prediction with the expectation over the observed data distribution ğ‘ƒ (X). ğœ™ ğ‘“ (x) (ğ‘–) is referred as the Shapley value of feature ğ‘‹ ğ‘– for ğ‘“ (x).</p><p>In order to calculate ğœ™ ğ‘“ (x) (ğ‘–), we firstly assume a sequential order ğœ‹ for all variables in X, such that ğœ‹ (ğ‘–) corresponds to the rank of ğ‘‹ ğ‘– . The Shapley value of ğ‘‹ ğ‘– for ğ‘“ (x) with respect to ğœ‹ is</p><formula xml:id="formula_4">ğœ™ ğœ‹ ğ‘“ (x) (ğ‘–) = ğ‘£ ğ‘“ (x) ({ğ‘‹ ğ‘— : ğœ‹ ( ğ‘—) â‰¤ ğœ‹ (ğ‘–)}) -ğ‘£ ğ‘“ (x) ({ğ‘‹ ğ‘— : ğœ‹ ( ğ‘—) &lt; ğœ‹ (ğ‘–)})<label>(4</label></formula><p>) where ğ‘£ ğ‘“ (x) (S) represents the model's output on a selected coalition of features X S with a feature subset S âŠ‚ {ğ‘‹ 1 , ..., ğ‘‹ ğ‘€ }. ğ‘£ ğ‘“ (x) (S) must satisfy that ğ‘£ ğ‘“ (x) (S) = ğ‘“ (x) when S = X and ğ‘£ ğ‘“ (x) (S) = ğœ™ ğ‘“ (0) when S = âˆ…. With Î  denoting the set of all permutations of features and ğ‘¤ denoting a permutation weight satisfying ğ‘¤ (ğœ‹) &gt; 0 and</p><formula xml:id="formula_5">ğœ‹ âˆˆÎ  ğ‘¤ (ğœ‹) = 1, we can calculate ğœ™ ğ‘“ (x) (ğ‘–) as ğœ™ ğ‘“ (ğ‘¥) (ğ‘–) = âˆ‘ï¸ ğœ‹ âˆˆÎ  ğ‘¤ (ğœ‹)ğœ™ ğœ‹ ğ‘“ (x) (ğ‘–)<label>(5)</label></formula><p>Different versions of Shapley values can be calculated based on different choices of ğ‘£ ğ‘“ (x) (S) and ğ‘¤. An obvious choice would be to take a uniform distribution ğ‘¤ (ğœ‹) = 1 ğ‘€! and calculate ğ‘£ ğ‘“ (x) (S) as the expectation over the observed distribution of unselected features: <ref type="bibr" target="#b20">[21]</ref>. Aas et al. <ref type="bibr" target="#b0">[1]</ref> considered the correlation among x and propose the calculation of ğ‘£ ğ‘“ (x) (S)</p><formula xml:id="formula_6">ğ‘£ ğ‘“ (x) (S) = E X â€² S [ğ‘“ (x S , x â€² S)]</formula><formula xml:id="formula_7">as ğ‘£ ğ‘“ (x) (S) = E X â€² S |X S [ğ‘“ (x S , x â€² S)</formula><p>]. The resulting Shapley-values are referred to as on-manifold Shapley-values. Frye et al. <ref type="bibr" target="#b11">[12]</ref> further considered different choices of ğ‘¤. For example, one reasonable approach is to put weights only on those permutations which are consistent with known causal orderings: </p><formula xml:id="formula_8">ğ‘¤ (ğœ‹) âˆ ï£± ï£´ ï£´ ï£´ ï£² ï£´ ï£´ ï£´ ï£³ 1 if ğœ‹ (ğ‘–) &lt; ğœ‹ ( ğ‘—)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Fairness Explanation</head><p>There have been a few studies trying to derive explanations for model fairness, which can be categorized as either feature-based or path-specific explanation.</p><p>2.5.1 Feature-based Explanation. Lundberg <ref type="bibr" target="#b19">[20]</ref> and Begley et al. <ref type="bibr" target="#b5">[6]</ref> leveraged Shapley values defined in Eq.( <ref type="formula" target="#formula_3">3</ref>) to attribute the feature contributions to Î” ğ·ğ‘ƒ in Eq.( <ref type="formula">1</ref>). Specifically, they proposed to use the group difference of ğœ™ ğ‘“ (ğ‘¥) (ğ‘–) to quantify the contribution of ğ‘‹ ğ‘– to Î” ğ·ğ‘ƒ as follows:</p><formula xml:id="formula_9">Î¦ ğ‘“ (ğ‘–) = E X|ğ´=1 [ğœ™ ğ‘“ (x) (ğ‘–)] -E X |ğ´=0 [ğœ™ ğ‘“ (x) (ğ‘–)]<label>(7)</label></formula><p>Begley et al. <ref type="bibr" target="#b5">[6]</ref> has also extended this formulation to disparity measured on equalized opportunity as in Eq.( <ref type="formula">2</ref>). However, decomposing model disparity into feature contributions ignores the causal structure of the features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Path-Specific Explanations.</head><p>There have been existing research studying fairness and the causal effects on the outcome by flipping the sensitive attribute value. They also studied the causal effects from particular paths, which are called path-specific effects <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b30">31]</ref>. Intuitively, the path-specific effect can be viewed as quantification of path-specific contribution to model disparity. Existing research has only focused on causal paths (paths in which all edges are directed outwards ğ´) so far, this may miss other sources of disparity. For example, in Figure <ref type="figure">1</ref>, ğ´ â† ğ‘‹ 1 â†’ Å¶ is an active path linking ğ´ and Å¶ and thus may contribute to model disparity, but it is not a causal path. Therefore, the sum of the path-specific effects considering only causal paths will not amount to the entire model disparity (e.g., measured by Eq.( <ref type="formula">1</ref>)), which leads to incomplete explanations.</p><p>In this paper, we propose a novel algorithmic fairness explanation method called Fairness-Aware Causal paTh decompoSition (FACTS), which is introduced in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>In this section, we will introduce our framework with Î” ğ·ğ‘ƒ as the model disparity metric. We provide generalizations of our framework to other model disparity metrics in the appendix.</p><p>Our framework is based on a causal graph G, which could be obtained based on domain knowledge or learned from the training data with existing causal discovery algorithms <ref type="bibr" target="#b27">[28]</ref>. According to Section 2.3, active paths from ğ´ to Å¶ are sources of Î” ğ·ğ‘ƒ . If there is no active path between ğ´ and Å¶ , Î” ğ·ğ‘ƒ = 0. If G is a DAG, we can identify all active paths based on the definition above and analyze their contributions to disparity. However, in reality G could be a PDAG, where the causal directions on some edges cannot be determined <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b24">25]</ref>. This makes the problem more challenging.</p><p>In this section, we first propose a corresponding concept potential active path to represent the correlation relations between ğ´ and Å¶ under a PDAG, and each potential active path between ğ´ and Å¶ is referred to as a fairness associated causal path (FACT) in this paper. Then we propose an algorithm to extract all potential active paths from ğ´ to Å¶ . Finally, we decompose Î” ğ·ğ‘ƒ as the sum of the contributions of these paths following the Shapley values strategy.</p><formula xml:id="formula_10">A X 2 X 1 G 1 G 2 G 3 Å¶ A X 2 X 1 Å¶ A X 2 X 1 Å¶ X 3 X 3 X 3</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Potential Active Paths from ğ´ to Å¶</head><p>Potential active paths on a PDAG are defined as follows: Potential Active Paths. A path ğ‘ in G is a potential active path if one of following properties is satisfied:</p><p>(1) All edges on ğ‘ are directed and ğ‘ satisfies the definition of active path in Section 2.2. (2) ğ‘ contains undirected edges. If we add arbitrary directions to all undirected edges (adjacent node pairs) on ğ‘, the resulting path is active. (3) ğ‘ contains undirected edges. Considering all possible directions of undirected edges in G, there exists at least one situation to obtain a DAG G â€² which satisfies: 1) corresponding path obtained from ğ‘ in G â€² is active; 2) the conditional independence relationships among variables encoded in G â€² are consistent with those inferred from observational data. We illustrate the above definition with examples in Figure <ref type="figure" target="#fig_0">2</ref>. For path ğ´ â†’ ğ‘‹ 1 â†’ ğ‘‹ 2 â†’ Å¶ in G 1 , since it is an active path by definition, it is a potential active path as well. As for ğ´ -</p><formula xml:id="formula_11">ğ‘‹ 1 â†’ ğ‘‹ 2 â†’ Å¶ in G 2 , since no matter what direction of ğ´ -ğ‘‹ 1 is, the resulting path ğ´ â†’ ğ‘‹ 1 â†’ ğ‘‹ 2 â†’ Å¶ or ğ´ â† ğ‘‹ 1 â†’ ğ‘‹ 2 â†’ Å¶ is active. Thus ğ´ -ğ‘‹ 1 â†’ ğ‘‹ 2 â†’ Å¶ in G 2 is a potential active path. For ğ´ â†’ ğ‘‹ 1 -ğ‘‹ 2 â†’ Å¶ in G 3 , suppose the conditional independence relation obtained from data is ğ´ Ì¸âŠ¥ âŠ¥ ğ‘‹ 1 |ğ‘‹ 2 , ğ´ Ì¸âŠ¥ âŠ¥ ğ‘‹ 2 |ğ‘‹ 1 , ğ‘‹ 1 Ì¸âŠ¥ âŠ¥ ğ‘‹ 2 |ğ´.</formula><p>Consider the directions of all undirected edges to be ğ‘‹ 1 â†’ ğ‘‹ 2 , the corresponding path ğ´ â†’ ğ‘‹ 1 â†’ ğ‘‹ 2 â†’ Å¶ in G 3 under this case is active and the relationships among variables is consistent with the conditional independence relation observed from the data. So</p><formula xml:id="formula_12">ğ´ â†’ ğ‘‹ 1 -ğ‘‹ 2 â†’ Å¶ is a potential active path.</formula><p>When G is DAG, the potential active path is equivalent to the active path. The potential active paths satisfy the following property: Proposition 3.1. If there is no potential active path between two variables on G, then the two variables are independent.</p><p>This proposition shows the importance of potential active paths between ğ´ and Å¶ when we consider Î” ğ·ğ‘ƒ . Since if there is no potential active path between ğ´ and Å¶ , ğ´ âŠ¥ âŠ¥ Å¶ and Î” ğ·ğ‘ƒ = 0.</p><p>In ordering to search potential active paths more efficiently, we have the following proposition: Proposition 3.2. If ğ‘ is a potential active path in G, then every subpath of ğ‘ is also a potential active path.</p><p>The proofs of propositions are provided in the appendix. Based on this proposition, we propose an algorithm to search all potential active paths from ğ´ to Å¶ as demonstrated in Algorithm 1.</p><p>Algorithm 1 Search Potential Active Paths from ğ´ to Å¶ Input: A PDAG G, Dataset {ğ´, ğ‘‹ } Output: A set of potential active paths from ğ´ to Å¶ : P, A set of features involved in P: X (P) Initialization: P ğ´â†’ = {Path directly connects ğ´ and ğ‘‹ ğ‘– : ğ‘‹ ğ‘– âˆˆ Adj(ğ´)}, P = âˆ… X (P) = Adj(ğ´) âŠ² Adj(ğ´) is the set of nodes adjacent to ğ´ on G. (Here P ğ´â†’ is a temporary set to store the potential active paths from ğ´ during searching) </p><formula xml:id="formula_13">for ğ‘‹ â† Adj(ğ‘ [-1]) do âŠ² ğ‘ [-1] means the last node of ğ‘ 5: ğ‘ â€² = ğ‘ + ğ‘‹ 6:</formula><p>if ğ‘ â€² is a potential active path by definition then 7:</p><formula xml:id="formula_14">X (P) = X (P) âˆª {ğ‘‹ } 8:</formula><p>if ğ‘‹ is not Å¶ then 9: end for 15: end while Table <ref type="table" target="#tab_2">1</ref> summarizes the notations that will be needed for the follow up presentations. As an example in G 1 of Figure <ref type="figure" target="#fig_0">2,</ref><ref type="figure">P</ref>  The set of features involved in P X (P)</p><formula xml:id="formula_15">P ğ´â†’ = P ğ´â†’ âˆª {ğ‘ â€² } 10:</formula><formula xml:id="formula_16">= {ğ´ â†’ ğ‘‹ 1 â†’ Å¶, ğ´ â†’ ğ‘‹ 2 â†’ Å¶, ğ´ â†’ ğ‘‹ 1 â†’ ğ‘‹ 2 â†’ Å¶ }, X (P) = {ğ‘‹ 1 , ğ‘‹ 2 }, X (P) = {ğ‘‹ 3 }. We will have X (P) âŠ¥ âŠ¥ ğ´.</formula><formula xml:id="formula_17">Set of features not involved in P ğœ™ ğ‘“ (x) (ğ‘ ğ‘– ) Contribution of path ğ‘ ğ‘– to ğ‘“ (x) Î¦(ğ‘ ğ‘– ) Contribution of path ğ‘ ğ‘– to Î” ğ·ğ‘ƒ</formula><p>Ordering Relationships with respect to ğ´. For two nodes ğ‘‹ ğ‘– and ğ‘‹ ğ‘— in X (P), ğ‘‹ ğ‘– is defined to be prior to ğ‘‹ ğ‘— with respect to ğ´ if:</p><p>(1) There exist at least one potential active paths from ğ´ to Å¶ that both ğ‘‹ ğ‘– and ğ‘‹ ğ‘— are on these paths;</p><p>(2) For all potential active paths from ğ´ to Å¶ containing both ğ‘‹ ğ‘– and ğ‘‹ ğ‘— , ğ‘‹ ğ‘– precedes ğ‘‹ ğ‘— on them. In the following, we write such relationship as ğ‘‹ ğ‘– â‰» ğ´ ğ‘‹ ğ‘— . We also define: âˆ€ğ‘‹ ğ‘– , ğ´ â‰» ğ´ ğ‘‹ ğ‘– , ğ‘‹ ğ‘– â‰» ğ´ Å¶ .</p><p>If ğ‘‹ ğ‘— â‰» ğ´ ğ‘‹ ğ‘– and ğ‘‹ ğ‘— is adjacent to ğ‘‹ ğ‘– , we call ğ‘‹ ğ‘– is a direct successor of ğ‘‹ ğ‘— with respect to ğ´, and ğ‘‹ ğ‘— is a direct predecessor of ğ‘‹ ğ‘– with respect to ğ´. The set of all direct successors of ğ‘‹ ğ‘– w.r.t.</p><p>ğ´ is denoted by Ds ğ´ (ğ‘‹ ğ‘– ). The set of all direct predecessors of ğ‘‹ ğ‘– w.r.t. ğ´ is denoted by Dp ğ´ (ğ‘‹ ğ‘– ). For G 1 in Figure <ref type="figure" target="#fig_0">2</ref>, we have Dp ğ´ (ğ‘‹ 1 ) = {ğ´}, Dp ğ´ (ğ‘‹ 2 ) = {ğ´, ğ‘‹ 1 }. We will write Dp ğ´ (ğ‘‹ ğ‘– ) as Dp ğ‘– and Ds ğ´ (ğ‘‹ ğ‘– ) as Ds ğ‘– for simplicity in the following. Completely Ordered with respect to ğ´. X (P) is defined to be completely ordered with respect to ğ´ on G if âˆ€ğ‘‹ ğ‘– , ğ‘‹ ğ‘— âˆˆ X (P) , ğ‘‹ ğ‘– âˆˆ Adj(ğ‘‹ ğ‘— ), one of them must be the direct successor or predecessor of the other. This can also be written as âˆ€ğ‘‹ ğ‘– , ğ‘‹ ğ‘— âˆˆ X (P) , ğ‘‹ ğ‘— âˆˆ Adj(ğ‘‹ ğ‘– ), we have ğ‘‹ ğ‘— âˆˆ Dp ğ‘– âˆª Ds ğ‘– . Considering a special case where G is a DAG, we have the following proposition. Proposition 3.3. If G is a DAG and no other node is the parent of ğ´, then X (P) is completely ordered with respect to ğ´ on G.</p><p>where the condition is sufficient but not necessary for completely ordering w.r.t. ğ´. For example, as in G 2 of Figure <ref type="figure" target="#fig_0">2</ref>, even though the edge ğ‘‹ 1 -ğ´ is undirected, we can still have that X (P) is completely ordered with respect to ğ´.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">FACT Decomposition of Model Disparity</head><p>In this subsection, we propose an algorithm to quantitatively attribute the model disparity Î” ğ·ğ‘ƒ to individual FACTs. We first present the algorithm for the case when X (P) is completely ordered with respect to ğ´ on G. The extension of our algorithm to the scenario when the completely-ordered condition does not hold is introduced in Section 3.3.</p><p>Specifically, our algorithm is based on the Shapley values strategy in Section 2.4, and our goal is to decompose Î” ğ·ğ‘ƒ as the sum of contributions from the paths in P as Î” ğ·ğ‘ƒ = ğ‘ ğ‘– âˆˆP Î¦ ğ‘“ (ğ‘ ğ‘– ), and</p><formula xml:id="formula_18">Î¦ ğ‘“ (ğ‘ ğ‘– ) = E X|ğ´=1 [ğœ™ ğ‘“ (x) (ğ‘ ğ‘– )] -E X|ğ´=0 [ğœ™ ğ‘“ (x) (ğ‘ ğ‘– )]<label>(8)</label></formula><p>where ğœ™ ğ‘“ (x) (ğ‘ ğ‘– ) is the Shapley value of FACT ğ‘ ğ‘– . Following Eq.( <ref type="formula" target="#formula_4">4</ref>), we can define ğœ™ ğ‘“ (x) (ğ‘ ğ‘– ) as</p><formula xml:id="formula_19">ğœ™ ğ‘“ (x) (ğ‘ ğ‘– ) = âˆ‘ï¸ ğœ‹ âˆˆÎ  ğ‘£ ğ‘“ (x) ({ğ‘ ğ‘— : ğœ‹ (ğ‘ ğ‘— ) â‰¤ ğœ‹ (ğ‘ ğ‘– )}) -ğ‘£ ğ‘“ (x) ({ğ‘ ğ‘— : ğœ‹ (ğ‘ ğ‘— ) &lt; ğœ‹ (ğ‘ ğ‘– )}) |Î | (9)</formula><p>where ğœ‹ is a permutation function for all FACTs, and Î  is the collection of all permutations. ğ‘£ ğ‘“ (x) (T) is a value function defined on a set of FACTs T âŠ‚ P. In order to appropriately define ğ‘£ ğ‘“ (x) (T), we need to leverage the causality structure encoded in P. In particular, P can be seen as a system which transfer the information of ğ´ downstreams and finally affect the value of Å¶ . So an intuitive idea is to formulate this system as a calculation process started from ğ´, passing through FACTs and finally get the model prediction ğ‘“ (x). During the inference process, each ğ‘‹ ğ‘– âˆˆ X (P) can be estimated as</p><formula xml:id="formula_20">ğ‘‹ ğ‘– = ğ‘” ğ‘‹ ğ‘– Dp ğ‘– , X (P) , ğ¸ ğ‘–<label>(10)</label></formula><p>where ğ‘” ğ‘‹ ğ‘– is the regression link function, Dp ğ‘– is the set of predecessors of ğ‘‹ ğ‘– in P, X (P) is the set of feature variables that are not in X(P), ğ¸ ğ‘– is the random regression error. We assume {ğ¸ ğ‘– } are mutually independent and each ğ¸ ğ‘– is independent of Dp ğ‘– and X (P).</p><p>Hyvarinen et al. <ref type="bibr" target="#b15">[16]</ref> proved that we can always construct such {ğ‘” ğ‘‹ ğ‘– } and {ğ¸ ğ‘– }. In the following we present the calculation process with a concrete example.</p><p>Considering G 1 in Figure <ref type="figure" target="#fig_0">2</ref>, we have</p><formula xml:id="formula_21">X (P) = {ğ‘‹ 1 , ğ‘‹ 2 }, X (P) = {ğ‘‹ 3 }, P = {ğ´ â†’ ğ‘‹ 1 â†’ Å¶, ğ´ â†’ ğ‘‹ 2 â†’ Å¶, ğ´ â†’ ğ‘‹ 1 â†’ ğ‘‹ 2 â†’ Å¶ }.</formula><p>According to Eq.( <ref type="formula" target="#formula_20">10</ref>), we also have ğ‘‹ 1 = ğ‘” ğ‘‹ 1 (ğ´, ğ‘‹ 3 , ğ¸ 1 ), Dp 2 = ğ‘‹ 1 and ğ‘‹ 2 = ğ‘” ğ‘‹ 2 (ğ´, ğ‘‹ 1 , ğ‘‹ 3 , ğ¸ 2 ). For calculating ğ‘£ ğ‘“ (x) (T), we first consider two extreme cases.</p><p>â€¢ T = P. In this case, the actual value of ğ´ is visible to all FACTs, which makes ğ‘£ ğ‘“ (x) (T) = ğ‘“ (x). â€¢ T = âˆ…. In this case, the actual value of ğ´ is visible to none of the FACTs. We can sample ğ´ from its marginal distribution ğ‘ â€² âˆ¼ ğ‘ƒ (ğ´) and calculate ğ‘‹ ğ‘– under ğ´ = ğ‘ â€² , denoted as ğ‘¥ ğ‘– (ğ‘ â€² ), then we calculate ğ‘£ ğ‘“ (x) (T) as</p><formula xml:id="formula_22">ğ‘¥ 1 (ğ‘ â€² ) = ğ‘” ğ‘‹ 1 (ğ‘ â€² , ğ‘¥ 3 , ğ‘’ 1 ) ğ‘¥ 2 (ğ‘ â€² ) = ğ‘” ğ‘‹ 2 (ğ‘ â€² , ğ‘¥ 1 (ğ‘ â€² ), ğ‘¥ 3 , ğ‘’ 2 ) ğ‘£ ğ‘“ (x) (T) = E ğ‘ â€² âˆ¼ğ‘ƒ (ğ´) ğ‘“ (ğ‘¥ 1 (ğ‘ â€² ), ğ‘¥ 2 (ğ‘ â€² ), ğ‘¥ 3 )<label>(11)</label></formula><p>The case of T âŠ‚ P is more complicated. We denote ğ‘¥ ğ‘– (ğ‘ â€² |T) as the value of ğ‘‹ ğ‘– with T. In such process, the values of ğ´ which pass through T will be set to ğ‘, while those passing through P \ T will be set to ğ‘ â€² âˆ¼ ğ‘ƒ (ğ´). Considering the situation T = {ğ´ â†’ ğ‘‹ 1 â†’ ğ‘‹ 2 â†’ Å¶ } in the example, we need to transfer the information of ğ´ = ğ‘ along the path ğ´ â†’ ğ‘‹ 1 â†’ ğ‘‹ 2 â†’ Å¶ but block this information and use a random sample ğ‘ â€² along other paths ğ´ â†’ ğ‘‹ 1 â†’ Å¶ and ğ´ â†’ ğ‘‹ 2 â†’ Å¶ :</p><formula xml:id="formula_23">ğ‘¥ 1 (ğ‘ â€² |T) = ğ‘” ğ‘‹ 1 (ğ‘ â€² , ğ‘¥ 3 , ğ‘’ 1 ) ğ‘¥ 2 (ğ‘ â€² |T) = ğ‘” ğ‘‹ 2 (ğ‘ â€² , ğ‘¥ 1 , ğ‘¥ 3 , ğ‘’ 2 ) ğ‘£ ğ‘“ (x) (T) = E ğ‘ â€² âˆ¼ğ‘ƒ (ğ´) ğ‘“ (ğ‘¥ 1 (ğ‘ â€² |T), ğ‘¥ 2 (ğ‘ â€² |T), ğ‘¥ 3 )<label>(12)</label></formula><p>In this way, we can calculate ğœ™ ğ‘“ (x) (ğ‘ ğ‘– ) as in Eq. <ref type="bibr" target="#b8">(9)</ref>.</p><p>In practice, we can choose ğ‘“ (x) as the probability to predict x to be positive or the binary decision with a threshold on the probability. In the latter case, the decomposed Shapley values of Î” ğ·ğ‘ƒ on FACTs satisfy the following properties (detailed proofs are provided in the appendix).</p><p>(1) (Efficiency)</p><formula xml:id="formula_24">ğ‘ ğ‘– âˆˆP Î¦ ğ‘“ (ğ‘ ğ‘– ) = Î” ğ·ğ‘ƒ (2) (Linearity) Î¦ ğ›¼ ğ‘“ 1 +ğ›½ ğ‘“ 2 (ğ‘–) = ğ›¼Î¦ ğ‘“ 1 (ğ‘–) + ğ›½Î¦ ğ‘“ 2 (ğ‘–); (3) (Nullity) Î¦ ğ‘“ (ğ‘ ğ‘– ) = 0 when ğ‘£ ğ‘“ (x) (Tâˆª{ğ‘ ğ‘– }) = ğ‘£ ğ‘“ (x) (T), âˆ€x, T âŠ‚ P\ğ‘ ğ‘–</formula><p>Our path explanations can also be aggregated to generate featurelevel explanations. To obtain the contribution of feature ğ‘‹ ğ‘– to Î” ğ·ğ‘ƒ , we can sum the path contributions for all paths ended with ". . . ğ‘‹ ğ‘– â†’ Å¶ ".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Algorithm Implementation</head><p>When G is not completely ordered, some of FACTs could be contradictory to each other. Considering G 3 in Figure <ref type="figure" target="#fig_0">2</ref>, we have</p><formula xml:id="formula_25">P = {ğ´ â†’ ğ‘‹ 1 â†’ Å¶, ğ´ â†’ ğ‘‹ 2 â†’ Å¶, ğ´ â†’ ğ‘‹ 1 -ğ‘‹ 2 â†’ Å¶ , ğ´ â†’ ğ‘‹ 2 -ğ‘‹ 1 â†’ Å¶ }. In this case, ğ´ â†’ ğ‘‹ 2 -ğ‘‹ 1 â†’ Å¶ and ğ´ â†’ ğ‘‹ 1 -ğ‘‹ 2 â†’</formula><p>Å¶ cannot be active simultaneously.</p><p>One solution is to consider all orientation possibilities of undirected edges. For example, the direction of ğ‘‹ 1 -ğ‘‹ 2 in G 3 could be either ğ‘‹ 1 â† ğ‘‹ 2 or ğ‘‹ 1 â†’ ğ‘‹ 2 . We can study each situation respectively and then summarize them. However, this makes the exploration space potentially huge (suppose we have ğ‘ ğ‘¢ undirected edges, then we can have 2 ğ‘ ğ‘¢ orientation possibilities to explore).</p><p>We propose to solve this problem by grouping the adjacent feature variables which cause the inconsistency problem. In the example of G 3 in Figure <ref type="figure" target="#fig_0">2</ref>, if we group ğ‘‹ 1 and ğ‘‹ 2 as ğœ’ 1 = {ğ‘‹ 1 , ğ‘‹ 2 } and treat it as a single variable, then G 3 satisfies the completely-ordered condition. Therefore, we propose to first obtain a partition of X (P) as ğœ’ (P) = {ğœ’ 1 , . . . , ğœ’ ğ¾ } so that ğœ’ (P) is completely ordered with respect to ğ´ with these grouped variables {ğœ’ ğ‘˜ } ğ¾ ğ‘˜=1 . Then we can calculate the contributions of the paths with group-level variables. The concrete algorithm implementation steps are as follows.</p><p>Step 1: Identify Potential Active Paths from ğ´ to Å¶ . With G, we find all potential active paths from ğ´ to Å¶ as FACTs with Algorithm 1.</p><p>Step 2: Generate Groups Completely Ordered With Respect To ğ´. We group the feature variables so that the grouped variables are completely ordered with respect to ğ´ with Algorithm 2.</p><p>Step Remove repeated paths in P â€² 14: end function</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Fair Learning Through FACT Selection</head><p>With the FACTs based model disparity decomposition approach, we can obtain the quantitative contribution of each FACT to the model disparity. At the same time, if we also consider the model utility, then we can select the paths with high model utility and low model disparity contributions when building the model.</p><p>Without the loss of generality, we assume the outcome variable ğ‘Œ âˆˆ {0, 1} and the prediction model ğ‘“ (x) can return the prediction of x belonging to 1, then the utility of ğ‘“ can be estimated as</p><formula xml:id="formula_26">U (ğ‘“ ) = E X,ğ‘Œ [ğ‘¦ ğ‘“ (x) + (1 -ğ‘¦)(1 -ğ‘“ (x))]<label>(13)</label></formula><p>For a given data sample {x, ğ‘¦}, we can calculate the specific model utility of this sample as</p><formula xml:id="formula_27">U (ğ‘“ (x)) = ğ‘¦ ğ‘“ (x) + (1 -ğ‘¦)(1 -ğ‘“ (x))<label>(14)</label></formula><p>We can decompose U (ğ‘“ (x)) as the the contributions of FACTs in P. Similar to Eq.( <ref type="formula">9</ref>), we define ğœ“ ğ‘“ (x),ğ‘¦ (ğ‘ ğ‘– ) as</p><formula xml:id="formula_28">ğœ“ ğ‘“ (x),ğ‘¦ (ğ‘ ğ‘– ) = âˆ‘ï¸ ğœ‹ âˆˆÎ  ğ‘£ ğ‘“ğ‘¦ (x) ( {ğ‘ ğ‘— : ğœ‹ (ğ‘ ğ‘— ) â‰¤ ğœ‹ (ğ‘ ğ‘– ) }) -ğ‘£ ğ‘“ğ‘¦ (x) ( {ğ‘ ğ‘— : ğœ‹ (ğ‘ ğ‘— ) &lt; ğœ‹ (ğ‘ ğ‘– ) }) |Î  |<label>(15)</label></formula><p>where ğ‘“ ğ‘¦ (x) = ğ‘“ (x) if ğ‘¦ = 1 and ğ‘“ ğ‘¦ (x) = 1 -ğ‘“ (x) otherwise. In this way, the contribution of</p><formula xml:id="formula_29">ğ‘ ğ‘– to U (ğ‘“ ) is Î¨ ğ‘“ (ğ‘ ğ‘– ) = E X,ğ‘Œ [ğœ“ ğ‘“ (x),ğ‘¦ (ğ‘ ğ‘– )]<label>(16)</label></formula><p>Thus U (ğ‘“ ) can be decomposed as</p><formula xml:id="formula_30">Î¨ ğ‘“ (âˆ…) + âˆ‘ï¸ ğ‘ ğ‘– âˆˆP Î¨ ğ‘“ (ğ‘ ğ‘– )<label>(17)</label></formula><p>where</p><formula xml:id="formula_31">Î¨ ğ‘“ (âˆ…) = E X,ğ‘Œ [ğ‘£ ğ‘“ ğ‘¦ (x) (âˆ…)].</formula><p>With the decomposition of U (ğ‘“ ) and Î” ğ·ğ‘ƒ , we can construct an interpretable fair learning algorithm to achieve trade-off between accuracy and fairness through FACT selection. Specifically, our goal is to select a set of paths T * âŠ‚ P by minimizing the objective:</p><formula xml:id="formula_32">L (T) = - âˆ‘ï¸ ğ‘ ğ‘– âˆˆT Î¨ ğ‘“ (ğ‘ ğ‘– ) + ğœ†| âˆ‘ï¸ ğ‘ ğ‘– âˆˆT Î¦ ğ‘“ (ğ‘ ğ‘– )|<label>(18)</label></formula><p>We propose a greedy algorithm shown in Algorithm 3 to solve this problem by iteratively removing the edges in P to get T * . After we obtain T * , ğ‘£ ğ‘“ (x) (T * ) is used as the new prediction result. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS 4.1 Datasets</head><p>Synthetic Data: We created a dataset with 10 features under a DAG G. The feature variables and the sensitive attribute ğ´ are randomly connected by directed edges. We generated the data in two different settings: 1) ğ‘† 1 : the relation between features and outcome is linear; 2) ğ‘† 2 : the relation between features and outcome is non-linear. The detailed data generation process is described in the appendix. Adult <ref type="bibr" target="#b18">[19]</ref>: The Adult dataset consists of 48,842 samples. The task is to predict whether one's annual income is greater than 50K. We consider gender (male, female) as sensitive attribute and age, nationality, marital status, level of education, working class and hours per week as feature variables similar to <ref type="bibr" target="#b33">[34]</ref>. We set ğ‘Œ = 1 for ğ¼ğ‘›ğ‘ğ‘œğ‘šğ‘’ â‰¥ 50ğ¾ and ğ´ = 1 for male. COMPAS <ref type="bibr" target="#b3">[4]</ref>: The dataset contains 6,172 samples and the goal is to predict whether a defendant will recidivate within two years   or no (ğ‘Œ = 1 for non-recidivism). Race is the sensitive attribute (ğ´ = 1 for white people) and we choose 7 other attributes including age, gender, number of prior crimes, triple of numbers of juvenile felonies/juvenile misdemeanors/other juvenile convictions, original charge degree. Nutrition (National Health and Nutrition Examination Survey) <ref type="bibr" target="#b9">[10]</ref>: This dataset consists of 14, 704 individuals with 20 demographic features and laboratory measurements. The target is to predict 15year survival. We follow the data preprocessing procedures in <ref type="bibr" target="#b28">[29]</ref>. Race (white, non-white) is selected as the sensitive attribute. We set ğ‘Œ = 1 for 15-year survival and ğ´ = 1 for white people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Setting</head><p>We evaluate FACTS from two aspects: 1) path explanations for Î” ğ·ğ‘ƒ ; 2) fair learning through FACT selection. Here are some general settings to train model ğ‘“ and learn the FACTs.</p><p>Model Training: We train ğ‘“ using a 70%/30% train/test split. We randomly split data with this ratio and run experiments 5 times. The average result is reported. The hyper-parameters of the model are tuned by cross-validation. When we calculate path explanations for Î” ğ·ğ‘ƒ , we implement ğ‘“ as MultiLayer Perceptron (MLP) or Xgboost <ref type="bibr" target="#b7">[8]</ref> and report the results respectively. Causal Discovery: For the synthetic dataset, we directly use the ground-truth causal graph. For real-world datasets, the groundtruth causal graphs are not available. For Adult and Nutrition datasets, we use the causal graphs built in previous works <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b28">29]</ref>.</p><p>For COMPAS dataset, we construct the causal graph with PC algorithm <ref type="bibr" target="#b27">[28]</ref>, with directions on certain edges restricted and corrected according to domain knowledge. The PDAGs and rules we use to determine the causal directions are shown in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Path Explanations for Î” ğ·ğ‘ƒ</head><p>4.3.1 Baselines. Since there is no existing method specifically designed to explain disparity by causal paths. We adopt the following explanation methods as baselines:</p><p>â€¢ Feature-based Explanation by Shapley Values: we use different Shapley values (Independent Shapley Values(ISV ) in <ref type="bibr" target="#b20">[21]</ref> and Asymmetric Shapley Values(ASV ) in <ref type="bibr" target="#b11">[12]</ref>) to calculate the feature-based contribution to disparity with Eq.( <ref type="formula" target="#formula_9">7</ref>). â€¢ Path-specific Explanations (PSE): we calculate the path-specific effect of each potential active path as the estimation of its contribution to disparity, following the calculation in <ref type="bibr" target="#b8">[9]</ref>. Since the calculation of path-specific effect requires that the causal relations among ğ‘‹ (P) must be identified in G. We only report the quantitative results on synthetic, Adult and COMPAS datasets, where this condition is satisfied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Evaluation Metric.</head><p>As path-specific effect (PSE) can also provide estimations of path contributions to disparity, we directly compare PSE and FACTS with the following evaluation metrics.</p><p>(1) Accuracy: For synthetic dataset where the ground-truth path contributions is available, we evaluate the methods with the normalized root-mean-square error:</p><formula xml:id="formula_33">âˆšï¸ƒ ğ‘ ğ‘– âˆˆP (ğœƒ ğ‘“ (ğ‘ ğ‘– )-Î¦ ğ‘“ (ğ‘ ğ‘– )) 2 âˆšï¸ƒ ğ‘ ğ‘– âˆˆP (ğœƒ ğ‘“ (ğ‘ ğ‘– )) 2</formula><p>where ğœƒ ğ‘“ (ğ‘ ğ‘– ) is the ground-truth contribution of ğ‘ ğ‘– . (2) Efficiency: Efficiency is the property that the sum of the contribution values from all FACTs exactly equals to the total disparity (Property 1): ğ‘ ğ‘– âˆˆP Î¦ ğ‘“ (ğ‘ ğ‘– ) = Î” ğ·ğ‘ƒ . To show how close methods come to achieving efficiency, we compute normalized absolute difference between summation of path contributions and disparity:</p><formula xml:id="formula_34">| ğ‘ ğ‘– âˆˆP Î¦ ğ‘“ (ğ‘ ğ‘– )-Î” ğ·ğ‘ƒ | |Î” ğ·ğ‘ƒ | .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Quantitative Results on Estimation of Path Contributions.</head><p>The result on accuracy is shown in Table <ref type="table" target="#tab_5">2</ref>. Our FACTS outperforms PSE on different datasets and prediction models, especially when ğ‘“ learns non-linear relation. The result on efficiency is shown in Table <ref type="table" target="#tab_6">3</ref>. We can find that the summation of path explanations obtained by FACTS is closer to the original value of disparity than baseline.</p><p>-0.08 -0.04 0.00 0.04 Ï•f(x) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.3.4</head><p>Qualitative Analysis on Real Dataset. We choose Nutrition as the case study in this section and the results on other datasets are shown in the appendix. We train a model ğ‘“ without any fairness constraint on the dataset. Figure <ref type="figure" target="#fig_2">3</ref>(a) illustrates the causal graph which contains the top paths contributing to Î” ğ·ğ‘ƒ . Table <ref type="table" target="#tab_7">4</ref> shows the feature contributions to Î” ğ·ğ‘ƒ obtained by ISV and ASV. The result of FACTS is shown in Table <ref type="table" target="#tab_8">5</ref>. The first column of the table represents the path contributions to Î” ğ·ğ‘ƒ , while the second column shows the path contributions to the utility. We can see that ğœ’ 1 , which includes the features of economic status {Poverty Idx, Food Program}, has an important effect on Î” ğ·ğ‘ƒ . Here Poverty Idx stands for the Poverty Index of a person and Food Program denotes whether he/she is qualified for food programs. Its contribution calculated from ASV is more dominant than that from ISV. This is because economic status, in addition to its direct impact, indirectly affects the output through sedimentation rate, as shown in Figure <ref type="figure" target="#fig_3">3(a)</ref>. While ISV underestimates the impact of economic status and ASV mixes up all its impacts through different paths, FACTS can provide a more comprehensive and detailed analysis.</p><p>We also plot the histograms of ğœ™ ğ‘“ (x) for selected paths in Figure <ref type="figure" target="#fig_4">4</ref>. We can see that ğœ™ ğ‘“ (x) distributes differently across racial groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Fairness Learning through FACTs Selection</head><p>4.4.1 Baselines. We choose fair learning baselines as in <ref type="bibr" target="#b5">[6]</ref>.</p><p>â€¢ UNFAIR: A baseline model without any fairness constraint.</p><p>â€¢ AFL <ref type="bibr" target="#b32">[33]</ref>: AFL is a fair learning algorithm which trains the model by maximizing the predictors ability to predict ğ‘Œ while minimizing the adversary's ability to predict ğ´.</p><p>â€¢ RFL <ref type="bibr" target="#b2">[3]</ref>: Agarwal proposes an approach to fair classification, which optimize a constrained objective to achieve fairness.</p><p>For fair comparison, we use the same structure of MLP for all methods. For our method, we will first train an UNFAIR model ğ‘“ and apply our algorithm on ğ‘“ to get T * . Then we finetune ğ‘“ and use ğ‘£ ğ‘“ (x) (T * ) as the new prediction result. 4.4.2 Evaluation. We follow the work of <ref type="bibr" target="#b2">[3]</ref> to evaluate the fair learning algorithms. For each method, we run experiments in a range of the weights of fairness constraints (such as ğœ† in Eq.( <ref type="formula" target="#formula_32">18</ref>)). Then we plot the accuracy-disparity curves for each method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Results</head><p>. We firstly compare the path contributions to utility and disparity from Table <ref type="table" target="#tab_8">5</ref> and use Figure <ref type="figure" target="#fig_2">3</ref>(b) to illustrate how our algorithm works. ğ´ â†’ ğœ’ 1 â†’ Å¶ is the largest disparity contributor and makes a major contribution to utility. Other paths also contribute to Î” ğ·ğ‘ƒ , but their contributions to utility are relatively low. Algorithm 3 can determine the optimal sets of selected paths under different ğœ† in Eq.( <ref type="formula" target="#formula_32">18</ref>). In Figure <ref type="figure" target="#fig_2">3</ref>(b), we can see that when ğœ† = 0, T * contains all FACTs to maintain maximal utility. If ğœ† is large enough (ğœ† = 1.0), all FACTs will be removed to meet this strict fairness constraint. As ğœ† = 0.1, T * only contains ğ´ â†’ ğœ’ 1 â†’ Å¶ and ğ´ â†’ ğœ’ 6 â†’ Å¶ . The ratio</p><formula xml:id="formula_35">Î¨ ğ‘“ (ğ‘ ğ‘– ) Î¦ ğ‘“ (ğ‘ ğ‘– ) of ğ´ â†’ ğœ’ 1 â†’ Å¶ is greater than ğœ† = 0.1 so it is selected. ğ´ â†’ ğœ’ 6 â†’ Å¶ is also included because the direction of its Î¦ ğ‘“ (ğ‘ ğ‘– ) is opposite to that of ğ´ â†’ ğœ’ 1 â†’ Å¶ .</formula><p>It may be odd to keep two paths with different directions of Î¦ ğ‘“ (ğ‘ ğ‘– ) to obtain a low absolute value of disparity. This reflects the limitation of treating disparity as a single metric of fairness.</p><p>We show the accuracy-fairness trade-off curves for demographic parity in Figure <ref type="figure" target="#fig_5">5</ref>. Our fair learning algorithm with FACTS achieves comparable results as other fair learning algorithms. It outperforms baselines on COMPAS and Nutrition datasets. While on Adult dataset, most of Î” ğ·ğ‘ƒ comes from a single path (See appendix). After this path is removed, both Î” ğ·ğ‘ƒ and accuracy decrease obviously. Our algorithm can be completely explained by which paths are removed, while the baselines can only obtain black-box models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this work, we propose to a novel framework to explain algorithmic fairness with the causal graph. In particular, we decompose the disparity into contributions from fairness-aware causal paths that link the sensitive attribute and model outcome on a causal graph. We propose an algorithm to identify those paths and calculate their contributions to the disparity. With the path explanations, we can gain more insight into the inequality of a machine learning algorithm and propose an interpretable method to achieve better trade-offs between utility and fairness.  To prove Proposition 3.2 and 3.3, we first prove the following lemma: Lemma A.1. In a DAG, if ğ‘ is an active path, then every subpath of ğ‘ is an active path.</p><p>Proof. Suppose ğ‘ â€² is a subpath of ğ‘. For each ğ‘‹ that is a node on ğ‘ â€² , then ğ‘‹ is also on ğ‘. Since ğ‘ is an active path, then ğ‘‹ is a non-collider. According to the generality of ğ‘‹ , each node on ğ‘ â€² is a non-collider. So ğ‘ â€² is also an active path. â–¡</p><p>Then we will prove Proposition 3.2 with Lemma A.1:</p><p>Proof. (Proposition 3.2) Suppose ğ‘ is a potential active path and ğ‘ â€² is any subpath of ğ‘. We consider the three conditions in the definition of potential active path. If all edges on ğ‘ are directed and ğ‘ satisfies the definition of active path. Then all edges on ğ‘ â€² are also directed and ğ‘ â€² is active according to Lemma A.1, and thus a potential active path. Similarly, for the rest two cases, if ğ‘ satisfies the condition, we can get ğ‘ â€² also satisfies the same condition by Lemma A.1. So we can have ğ‘ â€² is a potential active path. â–¡</p><p>Proof. (Proposition 3.3) Since G is a DAG, a potential active path is equivalent to an active path according to the definition. Assume âˆƒğ‘‹ ğ‘– , ğ‘‹ ğ‘— âˆˆ X (P) , ğ‘‹ ğ‘– âˆˆ Adj(ğ‘‹ ğ‘— ), but neither of them is prior to the other with respect to ğ´. According to the definition, at least one of the following conditions are satisfied:</p><p>â€¢ There is no active path from ğ´ to Å¶ through both ğ‘‹ ğ‘– and ğ‘‹ ğ‘— . Without loss of generality, we let ğ‘‹ ğ‘– â†’ ğ‘‹ ğ‘— . Since ğ‘‹ ğ‘– âˆˆ X (P), there exists an active path from ğ´ to Å¶ through ğ‘‹ ğ‘– .</p><p>We consider its subpath which connects ğ´ and ğ‘‹ ğ‘– and call it ğ‘. ğ‘ is an active path according to Lemma A.1. Considering a new path obtained by appending "ğ‘‹ ğ‘— â†’ Å¶ " to ğ‘, it will be obviously an active path since ğ‘‹ ğ‘— and Å¶ must be noncolliders. This new path is an active path from ğ´ to Å¶ and both ğ‘‹ ğ‘– and ğ‘‹ ğ‘— are on it. So the beginning condition does not hold. â€¢ There exist at least two active paths from ğ´ to Å¶ , one is as</p><formula xml:id="formula_36">"ğ´ â†’ â€¢ â€¢ â€¢ â†’ ğ‘– . . . ğ‘‹ ğ‘— â€¢ â€¢ â€¢ â†’ Å¶ " and the other is as "ğ´ â†’ â€¢ â€¢ â€¢ â†’ ğ‘‹ ğ‘— . . . ğ‘‹ ğ‘– â€¢ â€¢ â€¢ â†’ Å¶ ".</formula><p>The paths are pointed out from ğ´ because ğ´ is a source node in G. Without loss of generality, we let ğ‘‹ ğ‘– â†’ ğ‘‹ ğ‘— . We denote the latter path as ğ‘. And we denote the subpath of ğ‘ from ğ‘‹ ğ‘— to ğ‘‹ ğ‘– as ğ‘ â€² . ğ‘ â€² must be an active path according to Lemma A.1. There are three possibilities:</p><formula xml:id="formula_37">ğ‘‹ ğ‘— â†’ â€¢ â€¢ â€¢ â†’ ğ‘‹ ğ‘– , if it is satisfied, ğ‘ â€² and the edge ğ‘‹ ğ‘– â†’ ğ‘‹ ğ‘— will form a directed cycle, which violates that G is a DAG; ğ‘‹ ğ‘— â† â€¢ â€¢ â€¢ â† ğ‘‹ ğ‘– or ğ‘‹ ğ‘— â† â€¢ â€¢ â€¢ â† ğ‘‹ ğ‘˜ â†’ â€¢ â€¢ â€¢ â†’ ğ‘‹ ğ‘– ,</formula><p>in both cases, ğ‘‹ ğ‘— will be a collider on ğ‘ and ğ‘ is not active. Since all the situation can not be satisfied, the beginning condition dose not hold.</p><p>In conclusion, neither of the conditions above can be satisfied. So the original assumption can not be satisfied, and X (P) is completely ordered with respect to ğ´ on G. â–¡</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Proofs of Properties</head><p>Proof. Efficiency: from Eq. ( <ref type="formula">9</ref>), we will have ğ‘ ğ‘– âˆˆP ğœ™ ğ‘“ (x) (ğ‘ ğ‘– ) = ğ‘£ ğ‘“ (x) (P) -ğ‘£ ğ‘“ (x) (âˆ…). Since ğ‘£ ğ‘“ (x) (P) = ğ‘“ (x), we have: âˆ‘ï¸</p><formula xml:id="formula_38">ğ‘ ğ‘– âˆˆP Î¦ ğ‘“ (ğ‘ ğ‘– ) = (E X |ğ´=1 [ğ‘£ ğ‘“ (x) (P)] -E X|ğ´=0 [ğ‘£ ğ‘“ (x) (P)]) -(E X |ğ´=1 [ğ‘£ ğ‘“ (x) (âˆ…)] -E X |ğ´=0 [ğ‘£ ğ‘“ (x) (âˆ…)])<label>(19)</label></formula><p>where E X |ğ´=1 [ğ‘£ ğ‘“ (x) (P)] -E X|ğ´=0 [ğ‘£ ğ‘“ (x) (P)] = Î” ğ·ğ‘ƒ . And when we calculate ğ‘£ ğ‘“ (x) (âˆ…), we only use ğ¸ ğ‘– and X(P ğ‘Œ )), which are independent to ğ´.</p><formula xml:id="formula_39">So ğ‘£ ğ‘“ (x) (âˆ…) is also independent to ğ´, E X |ğ´=1 [ğ‘£ ğ‘“ (x) (âˆ…)] - E X|ğ´=0 [ğ‘£ ğ‘“ (x) (âˆ…)] = 0. Linearity: In the calculation of ğ‘£ (ğ›¼ ğ‘“ 1 +ğ›½ ğ‘“ 2 ) (x) (T), (ğ›¼ ğ‘“ 1 + ğ›½ ğ‘“ 2 ) (x)</formula><p>can be written as ğ›¼ ğ‘“ 1 (x) + ğ›½ ğ‘“ 2 (x). Then we have ğ‘£ (ğ›¼ ğ‘“ 1 +ğ›½ ğ‘“ 2 ) (x) (T) = ğ›¼ğ‘£ ğ‘“ 1 (x) (T) + ğ›½ğ‘£ ğ‘“ 2 (x) (T) for all possible T. With Eq.( <ref type="formula">9</ref>) and ( <ref type="formula" target="#formula_18">8</ref>), we can prove the Linearity. Nullity: We denote the set of potential active paths from ğ´ to Å¶ relative to ğ‘Œ as P ğ‘Œ . We use an example in Figure <ref type="figure" target="#fig_6">6</ref>(a) to further illustrate the definition. We can get:  If the two following conditions satisfy, then we call ğ‘‹ ğ‘– is an informative successor of ğ‘‹ ğ‘— with respect to ğ´ relative to ğ‘Œ : 1) ğ‘‹ ğ‘— â‰» ğ´ |ğ‘Œ ğ‘‹ ğ‘– ; 2) ğ‘‹ ğ‘— is adjacent to ğ‘‹ ğ‘– or ğ‘‹ ğ‘– , ğ‘‹ ğ‘— are spouses with child ğ‘Œ . And ğ‘‹ ğ‘— is called an informative predecessor of ğ‘‹ ğ‘– with respect to ğ´ relative to ğ‘Œ . The set of all informative successors of ğ‘‹ ğ‘— is denoted as Is ğ´ |ğ‘Œ (ğ‘‹ ğ‘– ). The set of all informative predecessors of ğ‘‹ ğ‘— is denoted as Ip ğ´ |ğ‘Œ (ğ‘‹ ğ‘– ). For Figure <ref type="figure" target="#fig_6">6</ref>(a), we have Ip ğ´ |ğ‘Œ (ğ‘‹ 1 ) = {ğ´}, Ip ğ´ |ğ‘Œ (ğ‘‹ 2 ) = {ğ´, ğ‘‹ 1 }. We will write Ip ğ´ |ğ‘Œ (ğ‘‹ ğ‘– ) as Ip ğ‘– and Is ğ´ |ğ‘Œ (ğ‘‹ ğ‘– ) as Is ğ‘– for simplicity in the following.</p><formula xml:id="formula_40">If ğ‘£ ğ‘“ (x) (T âˆª {ğ‘ ğ‘– }) = ğ‘£ ğ‘“ (x) (T),</formula><formula xml:id="formula_41">P ğ‘Œ = {ğ´ â†’ ğ‘‹ 1 â†’ Å¶, ğ´ â†’ ğ‘‹ 1 â†’ ğ‘Œ â† ğ‘‹ 2 â†’ Å¶ }. ğ´ â†’ ğ‘‹ 1 â†’ Å¶ obviously satisfies the definition, while ğ´ â†’ ğ‘‹ 1 â†’ ğ‘Œ â† ğ‘‹ 2 â†’ Å¶ is not so intuitive. It</formula><p>Completely Ordered With Respect To ğ´ Relative to ğ‘Œ . X (P ğ‘Œ ) is defined to be completely ordered with respect to ğ´ relative to ğ‘Œ on G if: âˆ€ğ‘‹ ğ‘– , ğ‘‹ ğ‘— âˆˆ X (P ğ‘Œ ), we have if ğ‘‹ ğ‘– and ğ‘‹ ğ‘— are adjacent or spouses with child ğ‘Œ , one of them must be the informative successor or predecessor of the other.</p><p>After defining these concepts, we can directly replace the concept of Dp ğ‘– with Ip ğ‘– during the step of grouping features. When we try to decompose ğ‘“ (x) into the path contributions conditioned on ğ‘Œ . We need to learn a two sets of functions {ğ‘” ğ‘‹ ğ‘– |ğ‘Œ =1 } and {ğ‘” ğ‘‹ ğ‘– |ğ‘Œ =0 }, corresponding to different values of ğ‘Œ . And we need to infer ğ‘‹ ğ‘– as ğ‘‹ ğ‘– = ğ‘” ğ‘‹ ğ‘– |ğ‘Œ (Ip ğ‘– , X(P ğ‘Œ )). Thus we have ğœ™ ğ‘“ (x),ğ‘¦ (ğ‘ ğ‘– ) obtain by replacing the function ğ‘” ğ‘‹ ğ‘– with ğ‘” ğ‘‹ ğ‘– |ğ‘Œ in the calculation of ğœ™ ğ‘“ (x),ğ‘¦ (ğ‘ ğ‘– ).</p><p>For equalized opportunity, we compute the path contribution to Î” ğ‘‚ğ‘ƒ as: </p><formula xml:id="formula_42">Î¦ ğ‘“ (ğ‘ ğ‘– ) = E X |ğ‘Œ =1,</formula><p>For equalized odds, we need to consider the disparity conditioned on ğ‘Œ = 1 and ğ‘Œ = 0 respectively.  In experiments on accuracy, we constrain symmetric structure and parameters to obtain the ground-truths. In ğ‘† 1 , the probability of ğ‘Œ = 1 is calculated by the a linear function of features (normalized to be the in range of [0, 1]). While in ğ‘† 2 , the probability is calculated with additional non-linear transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C IMPLEMENTATION DETAILS</head><p>Model Parameters. When we implement ğ‘“ as MLP, we use the network with one hidden layer and the dimensions of hidden layer are 32/16/8/16 for Synthetic/Adult/COMPAS/Nutrition respectively. The models are implemented and trained with the Python package scikit-learn. We choose ADAM to optimize the model. Causal Discovery Results on Real-world datasets. Since there is no widely-used causal graph for COMPAS dataset, we generate a PDAG by the following procedure: first we run the PC algorithm on the data, then we determine and correct the direction following the rules: {race, age, gender} â†’ {numbers of prior crimes, numbers of juvenile felonies/juvenile misdemeanors/other juvenile conviction} â†’ {prior crimes} â†’ {original charge degree}. Estimation of Î¦ ğ‘“ . Since FACTS and all baselines are expensive to compute exactly, we use a Monte Carlo approximation of Eq.( <ref type="formula">9</ref>). In particular, we conduct breadth first search and sample 100 orderings from Î  and average across those orderings. For mixedtype data, we binarize all categorical features and follow the recent work of Wang et al. <ref type="bibr" target="#b28">[29]</ref> to formulate ğ‘” ğ‘‹ ğ‘– and ğ¸ ğ‘– .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D ADDITIONAL EXPERIMENT RESULTS</head><p>The results on Adult and COMPAS dataset are shown in Figure <ref type="figure" target="#fig_6">6</ref>(b) and 6(c). Due to limited space, we only display the top paths of P on the graphs. And the corresponding path contributions are shown in Figure <ref type="figure" target="#fig_8">7</ref>. The edge ğ´ -ğ‘‚ in 6(c) is undirected. In Adult dataset, marital status acts as the essential feature contributing to disparity. While in COMPAS dataset, age is the largest contributor.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Three examples of PDAG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 3</head><label>3</label><figDesc>Select Paths to Achieve Better Trade-off Between Accuracy and Î” ğ·ğ‘ƒ Input: P, {Î¦ ğ‘“ (ğ‘ ğ‘– ) : ğ‘ ğ‘– âˆˆ P}, {Î¨ ğ‘“ (ğ‘ ğ‘– ) : ğ‘ ğ‘– âˆˆ P}, ğœ† Output: T * Initialization: T = P 1: while T â‰  âˆ… do</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: (a): PDAG to explain Î” ğ·ğ‘ƒ on Nutrition, showing top 7 paths contributing to Î” ğ·ğ‘ƒ . The meanings of are in Table 4. (b): The set of selected FACTs (T * ) under different values of ğœ† (larger ğœ† means stronger fairness constraints) on Nutrition dataset. Red paths indicates the paths in T * .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The histograms of ğœ™ ğ‘“ (x) for two selected paths ğ´ â†’ ğ‘‹ 1 â†’ Å¶ and ğ´ â†’ ğ‘‹ 6 â†’ Å¶ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: The accuracy-fairness trade-off curves for Î” ğ·ğ‘ƒ on various datasets. The upper-left corner (high accuracy, low disparity) is preferred. Curves are generated by searching on a range of fair coefficients (for example, ğœ† in Eq.(18))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: (a): A PDAG to illustrate the concepts when considering {ğ‘Œ } as the condition set. (b) PDAG of P on Adult dataset. A:sex, M:marital status, L:level of education, H:working hours per week, R:relationship; (c) PDAG of P on COM-PAS dataset. A:race, O:age, J: triple of numbers of juvenile felonies/juvenile misdemeanors/other juvenile convictions, P:prior crimes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>ğ´=1 [ğœ™ ğ‘“ (x),ğ‘¦ (ğ‘ ğ‘– )] -E X|ğ‘Œ =1,ğ´=0 [ğœ™ ğ‘“ (x),ğ‘¦ (ğ‘ ğ‘– )] (20)For accuracy parity, we have:Î¦ ğ‘“ (ğ‘ ğ‘– ) = E X |ğ´=1 [ğœ™ ğ‘“ ğ‘¦ (x),ğ‘¦ (ğ‘ ğ‘– )] -E X |ğ´=0 [ğœ™ ğ‘“ ğ‘¦ (x),ğ‘¦ (ğ‘ ğ‘– )]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Path explanations on: (a) Adult and (b) COMPAS dataset. The first column shows the contributions of paths to Î” ğ·ğ‘ƒ (Î¦ ğ‘“ (ğ‘ ğ‘– )), the second column shows the contributions of paths to utility(Î¨ ğ‘“ (ğ‘ ğ‘– )).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Figure 1: An example of a causal graph. Here the prediction Å¶ is obtained by a function ğ‘“ which takes ğ‘‹ 1 , . . . , ğ‘‹ 4 as input features.which all edges are directed fromğ‘‹ ğ‘– towards ğ‘‹ ğ‘— (ğ‘‹ ğ‘– â†’ â€¢ â€¢ â€¢ â†’ ğ‘‹ ğ‘— ) is a causal path from ğ‘‹ ğ‘– to ğ‘‹ ğ‘— . Causal Relationships. ğ‘‹ ğ‘– is a parent of ğ‘‹ ğ‘— ifthere is a directed edge from ğ‘‹ ğ‘– to ğ‘‹ ğ‘— , and ğ‘‹ ğ‘— is a child of ğ‘‹ ğ‘– . ğ‘‹ ğ‘– is an ancestor of ğ‘‹ ğ‘— if there is a causal path from ğ‘‹ ğ‘– to ğ‘‹ ğ‘— , and ğ‘‹ ğ‘— is a descendant of ğ‘‹ ğ‘– . Following prior research<ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17]</ref>, Å¶ is the child of all ğ‘‹ ğ‘– , which means the predictor ğ‘“ maps the features variables X to predicted output Å¶ .</figDesc><table><row><cell></cell><cell>A</cell><cell></cell><cell></cell></row><row><cell>X 1</cell><cell>X 2</cell><cell>X 3</cell><cell>X 4</cell></row><row><cell></cell><cell>Å¶</cell><cell></cell><cell></cell></row></table><note><p>DAGs and PDAGs. A directed graph is a graph where all edges are directed. A directed graph without directed cycles is a directed acyclic graph (DAG), where directed cycle is formed as a causal path from ğ‘‹ ğ‘– to ğ‘‹ ğ‘— plus a directed edge ğ‘‹ ğ‘— â†’ ğ‘‹ ğ‘– . A partially directed graph is a graph where edges can be either directed or undirected. Similarly, a partially directed acyclic graph (PDAG) is a partially directed graph without directed cycles. Colliders, Active Nodes and Paths. Even though there are paths linking ğ‘‹ ğ‘– and ğ‘‹ ğ‘— in G, ğ‘‹ ğ‘– and ğ‘‹ ğ‘— are not guaranteed to be dependent.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>for any known ancestor ğ‘‹ ğ‘– of descendant ğ‘‹ ğ‘—</figDesc><table><row><cell>(6)</cell></row><row><cell>0 otherwise</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>1 :</head><label>1</label><figDesc>while P ğ´â†’ â‰  âˆ… do</figDesc><table><row><cell>2:</cell><cell>Let ğ‘ âˆˆ P ğ´â†’</cell></row><row><cell>3:</cell><cell>Remove ğ‘ from P ğ´â†’</cell></row></table><note><p>4:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Important Math Notations</figDesc><table><row><cell>Notation</cell><cell>Meaning</cell><cell></cell></row><row><cell>P</cell><cell>The set of potential active paths from ğ´ to</cell><cell>Å¶</cell></row><row><cell>X (P)</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>3: Calculate Path Contributions to Î” ğ·ğ‘ƒ . For each group level variable ğœ’ ğ‘– , we learn a prediction link function ğ‘” ğœ’ ğ‘– and obtain the error term E ğœ’ ğ‘– (both ğ‘” ğœ’ ğ‘– and E ğœ’ ğ‘– are multi-dimensional, with each dimension corresponding to an individual feature variable in ğœ’ ğ‘– ). Finally we calculate the path contribution on the group-level with the procedure in Section 3.2. Generate Groups Completely Ordered w.r.t ğ´ Input: A PDAG G, P, X (P) Output: A division of X (P) into groups ğœ’ 1 , . . . , ğœ’ ğ¾ , A set of active paths on group-level P â€² Initialization: Create groups {ğœ’ ğ‘– }, each ğœ’ ğ‘– containing ğ‘‹ ğ‘– âˆˆ X (P) and path set P â€² by replacing ğ‘‹ ğ‘– with ğœ’ ğ‘– for all paths in P 1: while {ğœ’ ğ‘– } is not completely ordered w.r.t A do Let ğœ’ ğ‘– : ğœ’ ğ‘— âˆˆ Adj(ğœ’ ğ‘– ), ğœ’ ğ‘— âˆ‰ Dp(ğœ’ ğ‘– ) âˆª Ds(ğœ’ ğ‘– ) Merge ğœ’ ğ‘– and all ğœ’ ğ‘— âˆˆ Adj(ğœ’ ğ‘– ) \ Dp(ğœ’ ğ‘– ) âˆª Ds(ğœ’ ğ‘– ), get ğœ’ *</figDesc><table><row><cell cols="2">Algorithm 2 2:</cell></row><row><cell>3:</cell><cell></cell></row><row><cell cols="2">4: UpdateRelation(ğœ’  10: Merge repeated ğœ’  *  on ğ‘</cell></row><row><cell>11:</cell><cell>end if</cell></row><row><cell>12:</cell><cell>end for</cell></row><row><cell>13:</cell><cell></cell></row></table><note><p>* , P â€² ) 5: end while 6: function UpdateRelation(ğœ’ * , P â€² ) 7: for ğ‘ â† P â€² do 8: if ğ‘ contains node ğœ’ ğ‘– : ğœ’ ğ‘– âŠ‚ ğœ’ * then 9: Replace all ğœ’ ğ‘– (ğœ’ ğ‘– âŠ‚ ğœ’ * ) by ğœ’ * on ğ‘</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Normalized root-mean-square error of estimated path contributions.</figDesc><table><row><cell>MLP</cell><cell></cell><cell>Xgboost</cell><cell></cell></row><row><cell>PSE</cell><cell>Ours</cell><cell>PSE</cell><cell>Ours</cell></row><row><cell cols="4">ğ‘† 1 0.09 (Â± 0.03) 0.06 (Â± 0.02) 0.07 (Â± 0.02) 0.07 (Â± 0.01)</cell></row><row><cell cols="4">ğ‘† 2 0.14 (Â± 0.03) 0.10 (Â± 0.03) 0.20 (Â± 0.07) 0.10 (Â± 0.07)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Normalized absolute difference of the summation of path contributions and Î” ğ·ğ‘ƒ . If the difference equals 0, the Î” ğ·ğ‘ƒ can be completely explained by the contributions.</figDesc><table><row><cell></cell><cell>MLP</cell><cell></cell><cell>Xgboost</cell></row><row><cell></cell><cell>PSE</cell><cell>Ours</cell><cell>PSE</cell><cell>Ours</cell></row><row><cell>ğ‘† 1</cell><cell cols="4">0.05 (Â± 0.03) 0.01 (Â± 0.01) 0.04 (Â± 0.02) 0.01 (Â± 0.01)</cell></row><row><cell>ğ‘† 2</cell><cell cols="4">0.09 (Â± 0.04) 0.01 (Â± 0.01) 0.05 (Â± 0.03) 0.01 (Â± 0.01)</cell></row><row><cell>Adult</cell><cell cols="4">0.23( Â± 0.04) 0.07 (Â± 0.01) 0.29(Â± 0.02) 0.10 (Â± 0.01)</cell></row><row><cell cols="5">COMPAS 0.59( Â± 0.04) 0.06 (Â± 0.03) 0.66(Â± 0.10) 0.15 (Â± 0.07)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Feature explanations on Nutrition. Each column shows the contributions of features to Î” ğ·ğ‘ƒ with ISV/ASV.</figDesc><table><row><cell>Features</cell><cell>ISV</cell><cell>ASV</cell></row><row><cell>Poverty Idx, Food Program (ğœ’ 1 )</cell><cell>0.0318</cell><cell>0.0355</cell></row><row><cell>Blood pressure (ğœ’ 2 )</cell><cell>0.0141</cell><cell>0.0129</cell></row><row><cell>Serum magnesium (ğœ’ 3 )</cell><cell>0.0076</cell><cell>0.0079</cell></row><row><cell>Blood protein (ğœ’ 4 )</cell><cell>0.0064</cell><cell>0.0075</cell></row><row><cell>Sedimentation rate (ğœ’ 5 )</cell><cell>0.0099</cell><cell>0.0061</cell></row><row><cell>White blood cells, Red blood cells (ğœ’ 6 )</cell><cell>-0.0077</cell><cell>-0.0082</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Path explanations on Nutrition dataset. The first column shows the contributions of paths to Î” ğ·ğ‘ƒ (Î¦ ğ‘“ (ğ‘ ğ‘– )), the second column shows the contributions to utility (Î¨ ğ‘“ (ğ‘ ğ‘– )).</figDesc><table><row><cell>Paths</cell><cell>Î¦ ğ‘“ (ğ‘ ğ‘– )</cell><cell>Î¨ ğ‘“ (ğ‘ ğ‘– )</cell></row><row><cell>ğ´ â†’ ğœ’ 1 â†’ Å¶</cell><cell>0.0324</cell><cell>0.0039</cell></row><row><cell>ğ´ â†’ ğœ’ 2 â†’ Å¶</cell><cell>0.0126</cell><cell>0.0009</cell></row><row><cell>ğ´ â†’ ğœ’ 3 â†’ Å¶</cell><cell>0.0081</cell><cell>0.0006</cell></row><row><cell>ğ´ â†’ ğœ’ 4 â†’ Å¶</cell><cell>0.0077</cell><cell>0.0032</cell></row><row><cell>ğ´ â†’ ğœ’ 5 â†’ Å¶</cell><cell>0.0060</cell><cell>0.0006</cell></row><row><cell>ğ´ â†’ ğœ’ 1 â†’ ğœ’ 5 â†’ Å¶</cell><cell>0.0031</cell><cell>0.0009</cell></row><row><cell>ğ´ â†’ ğœ’ 6 â†’ Å¶</cell><cell cols="2">-0.0082 &lt; 0.0001</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>âˆ€x, T âŠ‚ P\ğ‘ ğ‘– , obviously all the item in the summation of Eq. (9) will be 0. Then ğœ™ ğ‘“ (x) (ğ‘ ğ‘– ) and Î¦ ğ‘“ (ğ‘ ğ‘– ) are both 0. If both ğ‘‹ ğ‘– and ğ‘‹ ğ‘— are parents of ğ‘‹ ğ‘˜ , then ğ‘‹ ğ‘– is a of ğ‘‹ ğ‘— and ğ‘‹ ğ‘— is a spouse of ğ‘‹ ğ‘– with child ğ‘‹ ğ‘˜ . Potential Active Paths Relative to ğ‘Œ . The definition of potential active path relative to ğ‘Œ can be obtained by replace the notions "active path" with "active path relative to ğ‘Œ " in the definition of potential active path. To save space, we only write the first condition as an example: if a path ğ‘ is a directed path and satisfies the definition of active path relative to ğ‘Œ in Section2.2, then it is a potential active path relative to ğ‘Œ .The potential active path and potential active path relative to ğ‘Œ have the following relation: Proposition B.1. For any path on G which does not pass through ğ‘Œ , if it is a potential active path, then it is a potential active path relative to ğ‘Œ . Proposition B.2. If there is no potential active path relative to ğ‘Œ between two variables (neither of them is ğ‘Œ ) on G, then the two variables are conditional independent on ğ‘Œ .</figDesc><table /><note><p><p><p><p><p>â–¡</p>B EXTENSION TO OTHER DISPARITY</p>As discussed in previous work by Baer et al.</p><ref type="bibr" target="#b4">[5]</ref></p>, equalized odds and equalized opportunity satisfy when Å¶ âŠ¥ âŠ¥ ğ´|ğ‘Œ . In fact, Å¶ âŠ¥ âŠ¥ ğ´|ğ‘Œ can also induce accuracy parity. To study the conditional dependence between X and Å¶ on ğ‘Œ , we first introduce a new causality concept: Spouse.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>is not an active path from ğ´ to Å¶ . But if we consider the conditioning set {ğ‘Œ }, we can see ğ‘Œ is a collider on this path and belongs to the conditional set. While other nodes {ğ‘‹ 1 , ğ‘‹ 2 } are non-colliders and not in {ğ‘Œ }, according to the definition, ğ´ â†’ ğ‘‹ 1 â†’ ğ‘Œ â† ğ‘‹ 2 â†’ Å¶ is an active path relative to ğ‘Œ .We can propose a similar definition of ordering with respect to ğ´ conditioned on ğ‘Œ . ğ‘‹ ğ‘– â‰» ğ´ |ğ‘Œ ğ‘‹ ğ‘— means ğ‘‹ ğ‘– is prior to ğ‘‹ ğ‘— with respect to ğ´ conditioned on ğ‘Œ . When we further consider the information of ğ´ passes to P ğ‘Œ . It passes through spouses with child</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Generation of Synthetic Data. In experiments on effiency, we generate the data as follows: a feature ğ‘‹ ğ‘– is randomly connected to ğ‘‹ ğ‘— (with ğ‘‹ ğ‘— pointing to ğ‘‹ ğ‘– ) with 0.2 probability if ğ‘– &gt; ğ‘—, otherwise 0. A feature ğ‘‹ ğ‘– is randomly connected to ğ´ (with ğ´ pointing to ğ‘‹ ğ‘– ) with 0.4 probability. The generative function of each feature is linear. ğ‘“ (ğ‘ ğ‘– ) Î¨ ğ‘“ (ğ‘ ğ‘– ) ğ‘“ (ğ‘ ğ‘– ) Î¨ ğ‘“ (ğ‘ ğ‘– )</figDesc><table><row><cell>ğ´ â†’ ğ‘€ â†’ Å¶</cell><cell>0.116</cell><cell>0.034</cell><cell>ğ´ â†’ ğ‘‚ â†’ Å¶</cell><cell>0.109</cell><cell>0.010</cell></row><row><cell>ğ´ â†’ ğ» â†’ Å¶</cell><cell>0.024</cell><cell>0.005</cell><cell>ğ´ â†’ ğ‘ƒ â†’ Å¶</cell><cell>0.066</cell><cell>0.005</cell></row><row><cell>ğ´ â†’ ğ‘€ â†’ ğ¿ â†’ Å¶</cell><cell>0.011</cell><cell>0.001</cell><cell>ğ´ â†’ ğ½ â†’ ğ‘ƒ â†’ Å¶</cell><cell>0.017</cell><cell>0.004</cell></row><row><cell>ğ´ â†’ ğ‘€ â†’ ğ» â†’ Å¶</cell><cell>0.010</cell><cell>0.001</cell><cell>ğ´ â†’ ğ‘‚ â†’ ğ½ â†’ ğ‘ƒ â†’ Å¶</cell><cell>0.005</cell><cell>0.001</cell></row><row><cell>ğ´ â†’ ğ‘… â†’ Å¶</cell><cell>-0.013</cell><cell>&lt;0.001</cell><cell>ğ´ â†’ ğ‘‚ â†’ ğ½ â†’ Å¶</cell><cell>0.005</cell><cell>&lt;0.001</cell></row><row><cell>ğ´ â†’ ğ‘€ â†’ ğ‘… â†’ Å¶</cell><cell>-0.031</cell><cell>&lt;0.001</cell><cell>ğ´ â†’ ğ‘‚ â†’ ğ‘ƒ â†’ Å¶</cell><cell>-0.017</cell><cell>&lt;0.001</cell></row><row><cell>(a)</cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell><cell></cell></row></table><note><p>Paths Î¦ Paths Î¦</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p><rs type="person">Weishen Pan</rs>, <rs type="person">Sen Cui</rs>, and <rs type="person">Changshui Zhang</rs> would like to acknowledge the funding by the <rs type="funder">National Key Research and Development Program of China</rs> (No. <rs type="grantNumber">2018AAA0100701</rs>) and <rs type="projectName">Beijing Academy of Artificial Intelligence (BAAI</rs>). <rs type="person">Fei Wang</rs> would like to acknowledge the support from <rs type="funder">Amazon Web Service (AWS)</rs> <rs type="person">Machine Learning</rs> for <rs type="grantName">Research Award and Google Faculty Research Award</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_9vPAGFC">
					<idno type="grant-number">2018AAA0100701</idno>
					<orgName type="project" subtype="full">Beijing Academy of Artificial Intelligence (BAAI</orgName>
				</org>
				<org type="funding" xml:id="_8wT29ve">
					<orgName type="grant-name">Research Award and Google Faculty Research Award</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Explaining individual predictions when features are dependent: More accurate approximations to Shapley values</title>
		<author>
			<persName><forename type="first">Kjersti</forename><surname>Aas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Jullum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>LÃ¸land</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10464</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Association of black race with outcomes in COVID-19 disease: a retrospective cohort study</title>
		<author>
			<persName><forename type="first">Ayodeji</forename><surname>Adegunsoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iazsmin</forename><forename type="middle">Bauer</forename><surname>Ventura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><forename type="middle">M</forename><surname>Liarski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the American Thoracic Society</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1336" to="1339" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A reductions approach to fair classification</title>
		<author>
			<persName><forename type="first">Alekh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alina</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miroslav</forename><surname>DudÃ­k</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanna</forename><surname>Wallach</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="60" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Machine bias: There&apos;s software used across the country to predict future criminals. And it&apos;s biased against blacks</title>
		<author>
			<persName><forename type="first">Julia</forename><surname>Angwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Mattu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><surname>Kirchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ProPublica</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Fairness criteria through the lens of directed acyclic graphical models</title>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">E</forename><surname>Benjamin R Baer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">T</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><surname>Wells</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.11333</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Explainability for fair machine learning</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Begley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schwedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Frye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Feige</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.07389</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Incorporating causal prior knowledge as path-constraints in bayesian networks and maximal ancestral graphs</title>
		<author>
			<persName><forename type="first">Giorgos</forename><surname>Borboudakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Tsamardinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Coference on International Conference on Machine Learning</title>
		<meeting>the 29th International Coference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="427" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining</title>
		<meeting>the 22nd acm sigkdd international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Path-specific counterfactual fairness</title>
		<author>
			<persName><forename type="first">Silvia</forename><surname>Chiappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7801" to="7808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Plan and operation of the NHANES I Epidemiologic Followup Study, 1992</title>
		<author>
			<persName><forename type="first">Christine</forename><forename type="middle">S</forename><surname>Cox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>National Ctr for Health Statistics</publisher>
			<biblScope unit="volume">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fairness through awareness</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toniann</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd innovations in theoretical computer science conference</title>
		<meeting>the 3rd innovations in theoretical computer science conference</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="214" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Asymmetric Shapley values: incorporating causal knowledge into model-agnostic explainability</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Frye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Rowat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Feige</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Black workers face two of the most lethal preexisting conditions for coronavirus-Racism and economic inequality</title>
		<author>
			<persName><forename type="first">Elise</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valerie</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Economic Policy Institute</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Equality of Opportunity in Supervised Learning</title>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nati</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3315" to="3323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Heskes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evi</forename><surname>Sijben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioan</forename><surname>Gabriel Bucur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Claassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Nonlinear independent component analysis: Existence and uniqueness results</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>HyvÃ¤rinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petteri</forename><surname>Pajunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="429" to="439" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Avoiding discrimination through causal reasoning</title>
		<author>
			<persName><forename type="first">Niki</forename><surname>Kilbertus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateo</forename><surname>Rojas-Carulla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giambattista</forename><surname>Parascandolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="656" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Counterfactual fairness</title>
		<author>
			<persName><forename type="first">Matt</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Loftus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4066" to="4076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Moshe</forename><surname>Lichman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">UCI machine learning repository</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><surname>Lundberg</surname></persName>
		</author>
		<title level="m">Explaining Quantitative Measures of Fairness. Fair &amp; Responsible AI Workshop @ CHI2020</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su-In</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4765" to="4774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning Adversarially Fair and Transferable Representations</title>
		<author>
			<persName><forename type="first">David</forename><surname>Madras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliot</forename><surname>Creager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toniann</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3384" to="3393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<author>
			<persName><forename type="first">Diego</forename><forename type="middle">A</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremiah</forename><forename type="middle">S</forename><surname>Hinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Eili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><forename type="middle">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustapha</forename><surname>Irvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><forename type="middle">R</forename><surname>Saheed</surname></persName>
		</author>
		<author>
			<persName><surname>Page</surname></persName>
		</author>
		<author>
			<persName><surname>Scott R Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SARS-CoV-2 positivity rate for Latinos in the</title>
		<meeting><address><addrLine>Baltimore-Washington, DC Region</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="page" from="392" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fair inference on outcomes</title>
		<author>
			<persName><forename type="first">Razieh</forename><surname>Nabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Shpitser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Identifying causal effects in maximally oriented partially directed acyclic graphs</title>
		<author>
			<persName><forename type="first">Emilija</forename><surname>Perkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="530" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Hospitalization and mortality among black patients and white patients with Covid-19</title>
		<author>
			<persName><forename type="first">G</forename><surname>Eboni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Price-Haywood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonardo</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><surname>Seoane</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<publisher>New England Journal of Medicine</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning controllable fair representations</title>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratyusha</forename><surname>Kalluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengjia</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2164" to="2173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Clark N Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName><surname>Heckerman</surname></persName>
		</author>
		<title level="m">Causation, prediction, and search</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Shapley flow: A graphbased approach to interpreting model predictions</title>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenna</forename><surname>Wiens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Lundberg</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="721" to="729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Food Insecurity and COVID-19: Disparities in Early Effects for US Adults</title>
		<author>
			<persName><forename type="first">Julia</forename><forename type="middle">A</forename><surname>Wolfson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cindy</forename><forename type="middle">W</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nutrients</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">1648</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Pc-fairness: A unified framework for measuring causality-based fairness</title>
		<author>
			<persName><forename type="first">Yongkai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xintao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3404" to="3414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fairness beyond disparate treatment &amp; disparate impact: Learning classification without disparate mistreatment</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Bilal Zafar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><forename type="middle">Gomez</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th international conference on world wide web</title>
		<meeting>the 26th international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1171" to="1180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Mitigating unwanted biases with adversarial learning</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Hu Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blake</forename><surname>Lemoine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society</title>
		<meeting>the 2018 AAAI/ACM Conference on AI, Ethics, and Society</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="335" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Causal modeling-based discrimination discovery and removal: Criteria, bounds, and algorithms</title>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongkai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xintao</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="2035" to="2050" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
