<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Causal Effects on Hypergraphs (Extended Abstract) *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jing</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Virginia</orgName>
								<address>
									<settlement>Charlottesville</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mengting</forename><surname>Wan</surname></persName>
							<email>mengting.wan@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
							<email>longqi.yang@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
							<email>jundong@virginia.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Virginia</orgName>
								<address>
									<settlement>Charlottesville</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Brent</forename><surname>Hecht</surname></persName>
							<email>brent.hecht@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jaime</forename><surname>Teevan</surname></persName>
							<email>teevan@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Causal Effects on Hypergraphs (Extended Abstract) *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hypergraphs provide an effective abstraction for modeling multi-way group interactions among nodes, where each hyperedge can connect any number of nodes. Different from most existing studies which leverage statistical dependencies, we study hypergraphs from the perspective of causality. Specifically, we focus on the problem of individual treatment effect (ITE) estimation on hypergraphs, aiming to estimate how much an intervention (e.g., wearing face covering) would causally affect an outcome (e.g., COVID-19 infection) of each individual node. Existing works on ITE estimation either assume that the outcome of one individual should not be influenced by the treatment of other individuals (i.e., no interference), or assume the interference only exists between connected individuals in an ordinary graph. We argue that these assumptions can be unrealistic on real-world hypergraphs, where higher-order interference can affect the ITE estimations due to group interactions. We investigate high-order interference modeling, and propose a new causality learning framework powered by hypergraph neural networks. Extensive experiments on real-world hypergraphs verify the superiority of our framework over existing baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Group interactions among individuals exist in many scenarios, e.g., massive gathering events. Although the conventional pairwise graph definition covers various applications (e.g., physical contact networks or social networks <ref type="bibr" target="#b7">[Mitchell, 1974]</ref>), it fails to capture the complete information of group interactions (where each interaction may involve more than two individuals) <ref type="bibr" target="#b1">[Bai et al., 2021;</ref><ref type="bibr" target="#b3">Feng et al., 2019]</ref>. Hypergraphs can be introduced to address this limitation. Consider a hypergraph example that individuals are connected via in-person social events, each event can be represented as a hyperedge (Fig. <ref type="figure" target="#fig_1">1a</ref>). Each hyperedge can connect any number of individuals, unlike an ordinary edge connecting exactly two nodes (Fig. <ref type="figure" target="#fig_1">1b</ref>). 1 st -order 2 nd -order 3 rd -order (c) First, second, and third-order interferences with u1. While many studies have been devoted to utilizing such a generalized hypergraph structure to facilitate machine learning tasks <ref type="bibr" target="#b1">[Bai et al., 2021;</ref><ref type="bibr" target="#b3">Feng et al., 2019]</ref>, the majority were still executed at the statistical correlation level. A critical limitation here is the lack of causality, which is particularly important for understanding the impact of a policy intervention (e.g., wearing face covering) on an outcome of interest (e.g., COVID-19 infection). For individuals connected as in Fig. <ref type="figure" target="#fig_1">1a</ref>, one may ask "how would each individual's face covering practice (treatment) causally influence their infection risk (outcome)?" This causal problem is particularly hard on hypergraphs, since the outcome of each individual is not only affected by their own treatment, but also influenced by the treatment of other individuals on the hypergraph (e.g., face covering practice of other individuals who may physically contact the target individual through a gathering event).</p><p>We focus on learning causal effects on hypergraphs. Specifically, we aim to estimate the individual treatment effect (ITE) under hypergraph interference from observational data. Classic ITE estimation relies on the Stable Unit Treat-ment Value (SUTVA) assumption <ref type="bibr" target="#b3">[Fisher, 1936;</ref><ref type="bibr" target="#b10">Splawa-Neyman et al., 1990]</ref> that there is no interference <ref type="bibr" target="#b11">[Tchetgen and VanderWeele, 2012;</ref><ref type="bibr" target="#b4">Hudgens and Halloran, 2008]</ref> (i.e., spillover effect) among individuals/instances (also referred to as units in causal inference literature). That means the outcomes for any instance are not affected by the treatment of other instances. This assumption is often impractical in the real world, especially on graphs where the interference is ubiquitous <ref type="bibr" target="#b0">[Ahluwalia et al., 2001;</ref><ref type="bibr" target="#b13">Yilmaz et al., 2002]</ref>. Most existing studies of interference <ref type="bibr">[Aronow and Samii, 2017;</ref><ref type="bibr">Basse and Feller, 2018;</ref><ref type="bibr" target="#b5">Imai et al., 2020;</ref><ref type="bibr" target="#b5">Kohavi et al., 2013;</ref><ref type="bibr" target="#b11">Tchetgen and VanderWeele, 2012;</ref><ref type="bibr" target="#b12">Ugander et al., 2013;</ref><ref type="bibr" target="#b13">Yuan et al., 2021;</ref><ref type="bibr" target="#b6">Ma and Tresp, 2021]</ref> assume the interference only exists in a pairwise way on ordinary graphs. This pairwise interference notion is insufficient to characterize the high-order interference on hypergraphs. As shown in Fig. <ref type="figure" target="#fig_1">1c</ref>, within a gathering event (hyperedge) between u 1 , u 2 and u 3 , an individual's (u 1 ) infection outcome can be affected by the first-order interference from other individuals (u 2 → u 1 and u 3 → u 1 ) as well as the high-order interference from the interactions among other individuals (the interaction between u 2 and u 3 may also act on influencing the exposure of the virus to u 1 ; consequently, u 1 's infection risk can be affected by this second-order interaction effect, i.e., u 2 × u 3 → u 1 ). This demands techniques capable of modeling high-order interference, but to the best of our knowledge, very little work has been done in this area.</p><p>We propose a novel framework-Causal Inference under Spillover Effects in Hypergraphs (HyperSCI)-to model high-order interference and promote ITE estimation performance. At a high level, this framework controls for the confounders and models high-order interference based on representation learning, then estimates the outcomes based on the learned representations. We evaluate HyperSCI through extensive experiments under different scenarios of high-order interference, and provide in-depth analysis of how our framework acts on different nodes and hyperedges.</p><p>2 Problem Definition Definition 1. (Hypergraph) A hypergraph H = {V, E} consists of a set of n nodes V = {v i } n i=1 and a set of m hyperedges E = {e k } m k=1 . Each hyperedge can connect any number of nodes.</p><p>In the studied problem, the given observational data is denoted by {X, H, T, Y}. Here,</p><formula xml:id="formula_0">X = {x i } n i=1 , T = {t i } n i=1</formula><p>and Y = {y i } n i=1 represent node features, treatment assignments, and observed outcomes, respectively. H = {h i,e } ∈ R n×m is an incidence matrix for hypergraph H. Here, h i,e = 1 if node i is in hyperedge e, otherwise h i,e = 0. The treatment assignment for each node is binary (i.e., t i ∈ {0, 1}). We use H, X, T to denote the random variables for the hypergraph structure, features, and treatment for any node. Definition 2. (Potential outcome) The potential outcome <ref type="bibr" target="#b8">[Rubin, 1980]</ref> of the unit i (denoted by y 1 i or y 0 i ) is defined as the outcome which would be realized for unit i under treatment t i = 1 or t i = 0. These potential outcomes can be obtained via a transformation function</p><formula xml:id="formula_1">Y Ti i = Φ Y (T i , X i , T -i , X -i , H). Here, Φ Y is a (non-deterministic) function, i.e., y ti i = Φ Y (t i , x i , T -i , X -i , H)</formula><p>, where (•) -i denotes all other nodes on H except i.</p><p>Our aim is to estimate ITE in a hypergraph. The ITE in the studied problem is defined as follows: Definition 3. For each node i on the hypergraph H, the individual treatment effect (ITE) τ (x i , T -i , X -i , H) is defined by the difference between potential outcomes corresponding to t i = 1 and t i = 0:</p><formula xml:id="formula_2">τ (x i , T -i , X -i , H) =E[Y 1 i -Y 0 i |X i = x i , T -i = T -i , X -i = X -i , H = H] =E[Φ Y (1, x i , T -i , X -i , H) -Φ Y (0, x i , T -i , X -i , H)].</formula><p>(1)</p><p>Here, we give our main assumptions and theoretical analysis for this study: Assumption 1. (Expressiveness of summary function) There is an expressive summary function</p><formula xml:id="formula_3">o i = SMR(H, T -i , X -i )</formula><p>to summarize the environmental information for each node. For any node i, any values of H, X -i , and T -i , if the output o i is determined, then the value of the potential outcomes y 1 i and y 0 i with feature x i are also determined. Assumption 2. (Unconfoundedness) For any node i, given the node features, the potential outcomes are independent with the treatment assignment and summary of neighbors, i.e.,</p><formula xml:id="formula_4">Y 1 i , Y 0 i ⊥ ⊥ T i , O i |X i .</formula><p>Theorem 1. (Identifiability) The defined ITE can be identifiable from observational data under the above assumptions.</p><p>We refer readers to <ref type="bibr" target="#b6">[Ma et al., 2022]</ref> for a full derivation.</p><p>3 Proposed Method Fig. <ref type="figure" target="#fig_2">2</ref> shows an overview of our framework HyperSCI, which contains three main components: confounder representation learning, interference modeling, and outcome prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Confounder Representation Learning</head><p>HyperSCI learns representations of confounders by mapping the node features x i into a latent space with a multilayer perceptron (MLP) module, i.e., z i = MLP(x i ). The confounder representations for all the nodes are denoted by Z = {z i } n i=1 . Similar as <ref type="bibr" target="#b9">[Shalit et al., 2017]</ref>, a Wasserstein-1 distancebased representation balancing method is used to minimize the distance between the representation distributions of the treatment group and control group, aiming to improve the treatment effect estimation performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Interference Modeling</head><p>An interference modeling module is developed to model the high-order interference among nodes in the hypergraph. More specifically, a function Ψ(•) is learned via a hypergraph neural network module to obtain the interference representations (p i ) for each node i, i.e., p i = Ψ(Z, H, T -i , t i ). The illustration of this module is shown in Fig. <ref type="figure" target="#fig_4">3</ref>. This module is implemented based on a hypergraph convolutional network <ref type="bibr" target="#b1">[Bai et al., 2021;</ref><ref type="bibr">Yadati et al., 2019]</ref> as well as a hypergraph attention mechanism <ref type="bibr" target="#b1">[Bai et al., 2021;</ref><ref type="bibr">Zhang et al., 2019;</ref><ref type="bibr" target="#b2">Ding et al., 2020]</ref>.</p><formula xml:id="formula_5">Hypergraph module ! " ! # × P P ! # ! $ ! % × ! $ ! " ! # ! $ ! % P × ! &amp; " ! &amp; # Hypergraph Convolution $ # $ % $ $ $ " Hyperedge representation % # MLP Confounder Representation Learning ' ( # Interference Modeling % % % $ % " ! # ! % ! $ ! " Concat (! ) , $ ) )</formula><p>Outcome Prediction</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Representation balancing</head><p>Node (treated)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperedge</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Node features Confounder representation</head><p>Interference representation  </p><formula xml:id="formula_6">% " % # % $ % % P × × P P × Node (control) ! " ! # ! $ ! % P Hypergraph module $ # $ % $ $ $ " ' + Attention × P × P P × × ! # P × $ # P P × ! # ! " ! $ ! % ! $ × Interference representation ( ),," ( ),,#</formula><formula xml:id="formula_7">! " ! # × P P ! # ! $ ! % × ! $ ! " ! # ! $ ! % P × ! &amp; " ! &amp; # Hypergraph Convolution $ # $ % $ $ $ " Hyperedge representation % # MLP Confounder Representation Learning ' ( # Interference Modeling % % % $ % " ! # ! % ! $ ! " Concat (! ) , $ ) )</formula><p>Outcome Prediction</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Representation balancing</head><p>Node (treated)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperedge Node features Confounder representation</head><p>Interference representation Here node v1 (highlighted in yellow) is taken as an example.</p><formula xml:id="formula_8">% " % # % $ % % P × × P P × Node (control) ! " ! # ! $ ! % P Hypergraph module $ # $ % $ $ $ " ' + Attention × P × P P × × ! # P × $ # P P × ! # ! " ! $ ! % ! $ × Interference representation ( ),," ( ),,#</formula><p>To learn the interference representations for each node, the treatment and confounder representations are propagated through the hypergraph structure. A vanilla Laplacian matrix for the given hypergraph H can be calculated as:</p><formula xml:id="formula_9">L = D -1/2 HB -1 H ⊤ D -1/2 ,<label>(2)</label></formula><p>where D ∈ R n×n is a diagonal matrix in which each element stands for the node degree (i.e., m e=1 h i,e ). B ∈ R m×m is a diagonal matrix in which each element corresponds to the size of each hyperedge ( n i=1 h i,e ). The hypergraph convolution operation is defined as:</p><formula xml:id="formula_10">P (l+1) = LeakyReLU LP (l) W (l+1) ,<label>(3)</label></formula><p>where P (l) denotes the representations in the l-th layer of the hypergraph module. The input of the first layer is the confounder representation masked by the treatment assignment, i.e., p</p><formula xml:id="formula_11">i = t i * z i .<label>(0)</label></formula><p>Here, * is element-wise multiplication.</p><formula xml:id="formula_12">W (l+1) ∈ R d (l) ×d (l+1)</formula><p>represents the parameter matrix in the (l+1)-th layer of the hypergraph module, where d (l) and d (l+1) are the dimensionality of the l-th layer and (l+1)-th layer, respectively.</p><p>While the hypergraph convolution layer allows for interference modeling through hyperedges, it lacks flexibility to consider the varying significance of interference on different nodes via different hyperedges. To address this, a hypergraph attention mechanism <ref type="bibr" target="#b1">[Bai et al., 2021;</ref><ref type="bibr" target="#b2">Ding et al., 2020;</ref><ref type="bibr">Zhang et al., 2019]</ref> is utilized to capture the intrinsic relationship between nodes and hyperedges. Specifically, the attention weights are learned for each node and its corresponding hyperedges, which allows for a better understanding of how certain individuals, such as those participating in group events, may have a greater influence on or be influenced by others in these groups within the context of a hypergraph, as seen in the COVID-19 example. Specifically, the attention score between a node i and a hyperedge e is calculated as:</p><formula xml:id="formula_13">α i,e = exp(σ(sim(z i W a , z e W a ))) k∈Ei exp(σ(sim(z i W a , z k W a ))) , (<label>4</label></formula><formula xml:id="formula_14">)</formula><p>where σ(•) is an activation function, E i is the set of hyperedges which contain the node i. z e is the representation for each hyperedge e, obtained by aggregating across the representations of its associated nodes. W a denotes a parameter matrix to compute the node-hyperedge attention. sim(•) denotes a similarity function, which can be implemented as:</p><formula xml:id="formula_15">sim(x i , x j ) = a ⊤ [x i , x j ]. (5)</formula><p>Here, a is a weight vector, [•, •] is a concatenation operation.</p><p>The attention scores are used to model the different significance of interference. More specifically, the original incidence matrix H of the hypergraph in Eq. 2 is replaced with an attention-involved matrix H = { hi,e }, where hi,e = α i,e h i,e .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Outcome Prediction</head><p>Based on the confounder representations and the interference representations, the potential outcomes are predicted by:</p><formula xml:id="formula_16">ŷ1 i = f 1 ([z i , p i ]), ŷ0 i = f 0 ([z i , p i ]),<label>(6)</label></formula><p>where f 1 (•) and f 0 (•) are learnable functions which are trained to predict potential outcomes for treatment assignment 1 and 0, respectively. The ITE for each node i is then estimated by: τi = ŷ1 i -ŷ0 i . The prediction for the observed outcome is obtained by ŷi = ŷti i . The final loss function is:</p><formula xml:id="formula_17">L = n i=1 (y i -ŷi ) 2 + αL b + λ∥Θ∥ 2 ,<label>(7)</label></formula><p>where the first term is the outcome prediction loss, which can be implemented by standard mean squared error. L b is the representation balancing loss, as introduced in Section 3.1.</p><p>Θ denotes all the model parameters. α and λ are hyperparameters that control the weights for representation balancing and model regularization, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Evaluation</head><p>It is often very hard to obtain the ground-truth counterfactuals as only one of the two potential outcomes can be obtained in the observational data. Hence, we follow a standard practice to evaluate our framework and the alternative approaches on three semi-synthetic datasets Contact, GoodReads, and Microsoft Teams. We leverage as much real-world information as possible in the simulated environment. Our datasets are all based on real-world hypergraphs, and we retain the treatment allocations as well as node features (covariates) if they are available. We simulate the outcome generation process to assess the true ITEs, which allow us to evaluate the performance of ITE estimation. Full details of the datasets, baselines, and experimental settings can be found in <ref type="bibr" target="#b6">[Ma et al., 2022]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">ITE Estimation Performance</head><p>The performance of ITE estimation in hypergraph is shown in Table <ref type="table" target="#tab_0">1</ref>. HyperSCI outperforms all the baselines under different (linear and quadratic) simulation settings of the outcome generation function. As for the reasons, HyperSCI can leverage the hypergraph structure to model the high-order interference. In this way, it mitigates the influence of the interference on ITE estimation performance. Among baselines, some of them consider the pairwise network interference (GCN-HSIC and GNN-HSIC <ref type="bibr" target="#b6">[Ma and Tresp, 2021]</ref>), or use the graph structure to infer the hidden confounders <ref type="bibr">(Netdeconf [Guo et al., 2020]</ref>). These methods perform better than those baselines <ref type="bibr">(LR, CEVAE [Louizos et al., 2017]</ref>, CFR <ref type="bibr" target="#b9">[Shalit et al., 2017]</ref>) which cannot handle graph information. Furthermore, in the simulation, the hyperparameter β controls the level of hypergraph spillover effect in the outcome simulation. The ITE estimation results under different values of β are shown in Fig. <ref type="figure">4</ref>. When β increases, the outcome is more strongly affected by interference, and larger performance gains can be observed from HyperSCI compared with the baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">A Closer Look at High-Order Interference</head><p>We further take a closer look at high-order interference. We investigate how HyperSCI responds to hyperedges with dif- ferent sizes. More specifically, we remove the hyperedges with size larger than k, denote the modified hypergraph as H (k) , and vary the value of k. In Fig <ref type="figure">5</ref>, we compare the ITE estimation performance of HyperSCI with its variant on the projected ordinary graph HyperSCI-G. We observe that: 1) When k = 2 (hyperedge size ≤ 2), the performance of HyperSCI-G is close to HyperSCI. Because when k = 2, graph convolution can be regarded as a special case of hypergraph convolution with small differences in the graph Laplacian matrix (as illustrated in <ref type="bibr" target="#b1">[Bai et al., 2021]</ref>). Empirically this leads to a minor performance difference between HyperSCI-G and HyperSCI; 2) When k increases, the performance of ITE estimation from both methods are gradually improved, but such an improvement becomes less significant when k is larger. Besides, we notice HyperSCI consistently outperforms HyperSCI-G and such a difference becomes larger as k increases, indicating its efficacy on modeling high-order interference especially on large hyperedges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We study an important research problem of ITE estimation with the existence of high-order interference on hypergraphs. We identify and analyze the influence of high-order interference in causal effect estimation. To address this problem, we propose a novel framework HyperSCI, which estimates the ITEs based on representation learning. More specifically, HyperSCI learns the representation of confounders, models the high-order interference with a hypergraph neural network module, then predicts the potential outcomes for each instance with the learned representations. Extensive experiments conducted on semi-synthetic data based on real-world hypergraphs consistently validate the effectiveness of Hyper-SCI in ITE estimation under different interference scenarios.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) An illustrative example of group interactions on a hypergraph, where each circle represents a hyperedge (group); (b) An ordinary graph projected from this hypergraph; (c) Illustration of interferences with u1 from its neighbors on the hypergraph. Note interference on (b) is pairwise (first-order only) while higher-order interference exists on the original hypergraph (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An illustration of HyperSCI, including confounder representation learning, interference modeling, and outcome prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An illustration of the hypergraph module in HyperSCI.Here node v1 (highlighted in yellow) is taken as an example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: ITE estimation performance under different values of β in linear setting on GoodReads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>ITE estimation performance. "CT", "GR" and "MS" refer to Contact, GoodReads, and Microsoft Teams datasets, respectively.</figDesc><table><row><cell cols="2">Data Method</cell><cell cols="2">Linear √ ϵP EHE</cell><cell>ϵAT E</cell><cell cols="2">Quadratic √ ϵP EHE ϵAT E</cell></row><row><cell>CT</cell><cell>LR</cell><cell>25.41</cell><cell></cell><cell>9.11</cell><cell>38.22</cell><cell>20.28</cell></row><row><cell></cell><cell>CEVAE</cell><cell>22.88</cell><cell></cell><cell>8.29</cell><cell>35.28</cell><cell>18.22</cell></row><row><cell></cell><cell>CFR</cell><cell>24.04</cell><cell></cell><cell>7.17</cell><cell>32.24</cell><cell>17.28</cell></row><row><cell></cell><cell>Netdeconf</cell><cell>10.22</cell><cell></cell><cell>4.29</cell><cell>21.23</cell><cell>11.39</cell></row><row><cell></cell><cell>GNN-HSIC</cell><cell>7.42</cell><cell></cell><cell>2.06</cell><cell>16.28</cell><cell>7.28</cell></row><row><cell></cell><cell>GCN-HSIC</cell><cell>7.28</cell><cell></cell><cell>2.08</cell><cell>14.23</cell><cell>6.27</cell></row><row><cell></cell><cell>HyperSCI</cell><cell>3.45</cell><cell></cell><cell>1.39</cell><cell>9.20</cell><cell>2.24</cell></row><row><cell>GR</cell><cell>LR</cell><cell>23.01</cell><cell></cell><cell>13.42</cell><cell>48.56</cell><cell>31.19</cell></row><row><cell></cell><cell>CEVAE</cell><cell>22.69</cell><cell></cell><cell>12.49</cell><cell>45.21</cell><cell>29.22</cell></row><row><cell></cell><cell>CFR</cell><cell>20.30</cell><cell></cell><cell>13.21</cell><cell>41.72</cell><cell>26.28</cell></row><row><cell></cell><cell>Netdeconf</cell><cell>18.39</cell><cell></cell><cell>12.20</cell><cell>35.18</cell><cell>21.20</cell></row><row><cell></cell><cell>GNN-HSIC</cell><cell>17.20</cell><cell></cell><cell>12.18</cell><cell>27.22</cell><cell>16.87</cell></row><row><cell></cell><cell>GCN-HSIC</cell><cell>16.01</cell><cell></cell><cell>12.06</cell><cell>25.42</cell><cell>16.28</cell></row><row><cell></cell><cell>HyperSCI</cell><cell>15.68</cell><cell cols="2">11.81</cell><cell>19.23</cell><cell>13.33</cell></row><row><cell>MS</cell><cell>LR</cell><cell>22.80</cell><cell></cell><cell>21.41</cell><cell>414.17</cell><cell>192.80</cell></row><row><cell></cell><cell>CEVAE</cell><cell>19.36</cell><cell></cell><cell>8.63</cell><cell>315.01</cell><cell>188.47</cell></row><row><cell></cell><cell>CFR</cell><cell>25.23</cell><cell></cell><cell>18.28</cell><cell>392.56</cell><cell>189.75</cell></row><row><cell></cell><cell>Netdeconf</cell><cell>11.11</cell><cell></cell><cell>9.22</cell><cell>241.02</cell><cell>147.29</cell></row><row><cell></cell><cell>GNN-HSIC</cell><cell>9.38</cell><cell></cell><cell>6.91</cell><cell>114.28</cell><cell>81.21</cell></row><row><cell></cell><cell>GCN-HSIC</cell><cell>8.27</cell><cell></cell><cell>6.60</cell><cell>109.57</cell><cell>77.75</cell></row><row><cell></cell><cell>HyperSCI</cell><cell>5.13</cell><cell></cell><cell>4.46</cell><cell>81.08</cell><cell>74.41</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence (IJCAI-23) Sister Conferences Best Papers Track</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>&amp; ' #&amp;</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Aronow and Samii, 2017] Peter M Aronow and Cyrus Samii. Estimating average causal effects under general interference, with application to a social network experiment</title>
		<author>
			<persName><surname>Ahluwalia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1912" to="1947" />
			<date type="published" when="2001">2001. 2001. 2017</date>
		</imprint>
	</monogr>
	<note>Journal of Marketing research</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Basse and Feller, 2018] Guillaume Basse and Avi Feller. Analyzing two-stage experiments in the presence of interference</title>
		<author>
			<persName><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">521</biblScope>
			<biblScope unit="page" from="41" to="55" />
			<date type="published" when="2018">2021. 2021. 2018</date>
		</imprint>
	</monogr>
	<note>Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Be more with less: Hypergraph attention networks for inductive text classification</title>
		<author>
			<persName><surname>Ding</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.00387</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning individual causal effects from networked observational data</title>
		<author>
			<persName><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
		<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="1936">2019. 2019. 1936. 1936. 2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="232" to="240" />
		</imprint>
	</monogr>
	<note>Proceedings of the AAAI Conference on Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Toward causal inference with interference</title>
		<author>
			<persName><forename type="first">Halloran ;</forename><surname>Hudgens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hudgens</surname></persName>
		</author>
		<author>
			<persName><surname>Elizabeth Halloran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">482</biblScope>
			<biblScope unit="page" from="832" to="842" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Causal inference with interference and noncompliance in two-stage randomized experiments</title>
		<author>
			<persName><surname>Imai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 19th ACM SIGKDD international conference on Knowledge discovery and data mining<address><addrLine>Uri Shalit, Joris M Mooij, David Sontag, Richard Zemel, and Max Welling</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2020. 2020. 2013. 2013. 2017</date>
			<biblScope unit="page" from="1168" to="1176" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Causal inference under networked interference and intervention policy enhancement</title>
		<author>
			<persName><forename type="first">Tresp</forename><forename type="middle">;</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunpu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2021">2021. 2021. 2022. 2022</date>
			<biblScope unit="page" from="3700" to="3708" />
		</imprint>
	</monogr>
	<note>International Conference on Artificial Intelligence and Statistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Clyde Mitchell. Social networks. Annual review of anthropology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="279" to="299" />
			<date type="published" when="1974">1974. 1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Randomization analysis of experimental data: The fisher randomization test comment</title>
		<author>
			<persName><forename type="first">Rubin</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">371</biblScope>
			<biblScope unit="page" from="591" to="593" />
			<date type="published" when="1980">1980. 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Estimating individual treatment effect: generalization bounds and algorithms</title>
		<author>
			<persName><surname>Shalit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName><surname>Splawa-Neyman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Jerzy Splawa-Neyman</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On the application of probability theory to agricultural experiments. essay on principles. section 9</title>
		<author>
			<persName><surname>Dorota M Dabrowska</surname></persName>
		</author>
		<author>
			<persName><surname>Speed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tchetgen</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><forename type="middle">J</forename><surname>Tchetgen</surname></persName>
		</author>
		<author>
			<persName><surname>Vanderweele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical methods in medical research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="75" />
			<date type="published" when="1990">1990. 2012. 2012</date>
		</imprint>
	</monogr>
	<note>Statistical Science</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Graph cluster randomization: Network exposure to multiple universes</title>
		<author>
			<persName><surname>Ugander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>Madhav</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="329" to="337" />
		</imprint>
	</monogr>
	<note>Yadati et al., 2019] Naganand Yadati</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Geographic and network neighbors: Spillover effects of telecommunications infrastructure</title>
		<author>
			<persName><forename type="first">Prateek</forename><surname>Nimishakavi</surname></persName>
		</author>
		<author>
			<persName><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Vikram Nitin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Partha</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName><surname>Yilmaz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02613</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2002">2019. 2002. 2002. 2021. 2021. 2019. 2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="3359" to="3370" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Hyper-sagnn: a self-attention based graph neural network for hypergraphs</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
