<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Log2graphs: An Unsupervised Framework for Log Anomaly Detection with Efficient Feature Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-09-18">18 Sep 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Caihong</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<settlement>Sichuan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Du</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<settlement>Sichuan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zonghang</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Machine Learning</orgName>
								<orgName type="department" key="dep2">Mohamed bin Zayed</orgName>
								<orgName type="institution">University of Artificial Intelligence</orgName>
								<address>
									<settlement>Abu Dhabi</settlement>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Log2graphs: An Unsupervised Framework for Log Anomaly Detection with Efficient Feature Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-09-18">18 Sep 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2409.11890v1[cs.CR]</idno>
					<note type="submission">Preprint submitted to BB September 19, 2024</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Feature Extraction</term>
					<term>Log Anomaly Detection</term>
					<term>BERT</term>
					<term>Graph Neural Networks</term>
					<term>Graph Clustering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the era of rapid Internet development, log data has become indispensable for recording the operations of computer devices and software. These data provide valuable insights into system behavior and necessitate thorough analysis. Recent advances in text analysis have enabled deep learning to achieve significant breakthroughs in log anomaly detection. However, the high cost of manual annotation and the dynamic nature of usage scenarios present major challenges to effective log analysis. This study proposes a novel log feature extraction model called DualGCN-LogAE, designed to adapt to various scenarios. It leverages the expressive power of large models for log content analysis and the capability of graph structures to encapsulate correlations between logs. It retains key log information while integrating the causal relationships between logs to achieve effective feature extraction. Additionally, we introduce Log2graphs, an unsupervised log anomaly detection method based on the feature extractor. By employing graph clustering algorithms for log anomaly detection, Log2graphs enables the identification of abnormal logs without the need for labeled data. We comprehensively evaluate the feature extraction capability of DualGCN-LogAE and the anomaly detection performance of Log2graphs using public log datasets across five different scenarios. Our evaluation metrics include detection accuracy and graph clustering quality scores. Experimental results demonstrate that the log features extracted by DualGCN-LogAE outperform those obtained by other methods on classic classifiers. Moreover, Log2graphs surpasses existing unsupervised log detection methods, providing a robust tool for advancing log anomaly detection research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the rapid advancement of information technology, the Internet has become an essential infrastructure across various sectors, including the economy, military, and public services. However, the inherent complexity and openness of network systems have exposed them to increasingly severe security threats. Numerous network attacks, such as DDoS, malware intrusions, and data breaches, continuously emerge, posing significant risks to system stability and data confidentiality.</p><p>According to official reports from DNV (Det Norske Veritas), on January 7, 2023, DNV was compromised by ransomware, disrupting services for approximately 1,000 ships. In the same month,T-Mobile, a prominent US telecommunications operator, experienced a security breach that exposed the personal information of 3,700 users. Alarmingly, this was not an isolated inci-dent for T-Mobile; the company faced additional cyber attacks later that year. These incidents not only inflicted direct losses on the affected organizations but also precipitated a severe trust crisis among the public and the market, impacting the long-term viability of these enterprises.</p><p>The frequent occurrence of such incidents has driven the continuous evolution of network security technologies. Traditional security measures, such as firewalls, intrusion detection systems (IDS), and antivirus software, have provided some level of protection. However, as the proverb goes, the higher the tree, the stronger the wind, as these defenses increase, so does the sophistication and intensity of cyber attacks. Consequently, the efficacy of conventional network security measures has diminished.</p><p>Traditional protection methods typically rely on known attack signatures for detection, making them sluggish in responding to novel and unknown threats. Advanced Persistent Threats (APTs), which often have prolonged incubation periods before launching attacks, can remain undetected by traditional means during their latency phase. Moreover, current network security technologies struggle to identify covert attacks. For instance, malicious mining programs and stealthy data leaks do not significantly disrupt normal system operations, rendering them difficult to detect using conventional methods.</p><p>As an important part of network security, log anomaly detection can support many aspects, such as early threat detection, compliance support, and incident investigation. By using advanced analysis technology, organizations can improve their overall security posture and promptly respond to and prevent potential security threats. Log anomaly detection has also received widespread attention from network security researchers because of these advantages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Existing Solutions and Motivations</head><p>In the field of log anomaly detection, several advanced methods have emerged in recent years, including Log2vec <ref type="bibr" target="#b27">[28]</ref>, DeepSyslog <ref type="bibr" target="#b46">[47]</ref>, and Airtag <ref type="bibr" target="#b11">[12]</ref>. Log2vec constructs logs as fixed key-value graphs, representing logs with similar structures as the same node, and uses Word2Vec to extract log features. This method effectively captures the temporal relationships between logs and the similarity of logs with analogous structures. Log2vec clusters the extracted low-dimensional normal log features and sets a threshold to detect abnormal logs. However, this approach overlooks the actual log content, depends heavily on a large number of normal logs for clustering, and the threshold setting is highly experience-dependent.</p><p>DeepSyslog and Airtag focus more on log content in feature extraction. DeepSyslog processes log parameters and structured parts separately to enhance the utilization efficiency of log information, while Airtag leverages the computational power of the BERT to capture associations between words within logs. In the final stage, these methods employ fully connected layersupervised classification and semi-supervised learning OC-SVM for log anomaly detection. Although these techniques effectively extract key information from individual log entries, they neglect the causal properties unique to log data. Additionally, similar to Log2vec, both methods require manually labeled data, with OC-SVM being particularly sensitive to parameter settings, limiting its practicality.</p><p>To address these shortcomings, we propose a novel log feature extraction method that comprehensively considers both the critical content information and causal relationships of log entries. Furthermore, we try to develop a completely unsupervised log anomaly detection method, eliminating the need for labeled data. This approach seeks to enhance the adaptability of log anomaly detection and reduce reliance on costly manual data labeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Our Soluiton and Challenges</head><p>Our proposed DualGCN-LogAE offers a promising solution for efficient feature extraction in log anomaly detection by integrating pre-trained large language s and graph neural networks. Building on this foundation, the Log2graphs node semantic extraction is combined with a graph clustering method to identify potential abnormal behaviors within the system without needing labeled data.</p><p>While our approach demonstrates significant potential, its implementation also presents notable challenges. In the following discussion, we will comprehensively analyze the various challenges encountered and elucidate the inherent complexities of the implementation process.</p><p>Challenge 1: Dependence on manually labeled logs. The high cost of manually labeled training data has long been a major challenge in machine learning, prompting the research community to explore alternative solutions. Some studies have attempted to mitigate this cost by using a limited number of labeled samples or by training solely on normal logs. Nevertheless, the reliance on labeled data remains an unavoidable obstacle.</p><p>Challenge 2: Rich contextual information. Logs capture a variety of system states, events, and operations, providing the complex contextual details necessary to understand system behaviors and user actions. However, the extensive amount of contextual data increases the complexity and dimensionality of the dataset, posing significant challenges to current research efforts.</p><p>Challenge 3: High heterogeneity. The heterogeneity of log data, stemming from different systems, applications, and devices, complicates its processing and analysis. Variations in data formats, fields, and semantics from different sources exacerbate the complexity of log data management, creating substantial obstacles to effective coordination.</p><p>Challenge 4: Massive data. The sheer volume of log data generated by systems and applications is vast, containing significant amounts of invalid and redundant information. This presents a substantial challenge to log management and processing. Extracting key information from such extensive log data demands considerable computing resources and storage capacity, resulting in resource-intensive processes that diminish processing efficiency, degrade system performance, and increase resource consumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Contributions</head><p>The main contributions of this paper are summarized as follows:</p><p>• This study integrates different log sources into a unified graph-based framework, enhancing the capability of log analysis technologies to address complex system behaviors and evolving network security threats.</p><p>• We propose a novel log feature extraction framework named DualGCN-LogAE, which extracts critical information from log data by combining both log content and log context.</p><p>• Utilizing DualGCN-LogAE, we employ graph clustering methods for log anomaly detection, fully considering the highly imbalanced nature of data in log anomaly detection research to distinguish between normal and abnormal logs. Importantly, our Log2graphs approach operates without requiring any labeled information.</p><p>• We introduce three clustering quality evaluation metrics to assess the performance of our clustering methodology on unlabeled log datasets. These metrics quantitatively evaluate the clustering consistency and separation of unlabeled log data, thereby extending the applicability of anomaly detection techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4.">Organization</head><p>The rest of this paper is organized as follows. Section 2 provides an overview of our framework. Section 3 details the architecture and results of the experiments conducted in this study. Section 4 discusses the limitations of this work and potential future solutions. Section 5 reviews related research in the field of log anomaly detection. Finally, Section 6 presents the conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Design of Our Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Overview</head><p>We propose an efficient log feature extraction to improve the stability of log detection s in dynamic environments and reduce the high costs associated with manually labeling log data. Building on this, we developed a log anomaly detection method that operates without the need for labeled data. Our approach leverages the intrinsic properties of graph structures to effectively capture the semantic, temporal, and causal relationships inherent in log data. By preserving essential information about the log content, our method significantly compresses the log atlas, facilitating a more streamlined analysis of abnormal logs (Fig. <ref type="figure" target="#fig_1">1</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Preprocessing</head><p>Log data records the operations of systems and applications, making it highly valuable. With continuous advancements in computer technology, the volume of log data has significantly increased. However, original log data often suffers from issues such as nonstandard formatting and poor quality, which impede effective analysis and utilization. Therefore, preprocessing log data is essential. This part focuses on the preprocessing operations necessary for effective log data analysis and utilization (Fig. <ref type="figure">2</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Parsing</head><p>Logs are generated by print statements embedded in program source code and typically consist of two components: a header and content. Log parsing involves retaining the constant elements of the log content and replacing variable elements with wildcards (&lt;*&gt;) to create a log template <ref type="bibr" target="#b45">[46]</ref>.</p><p>Currently, there are several methods for log parsing. Zhu et al. <ref type="bibr" target="#b47">[48]</ref> compared and analyzed six well-known automatic parsing methods: LKE <ref type="bibr" target="#b17">[18]</ref>, IPLoM <ref type="bibr" target="#b28">[29]</ref>, SHISO <ref type="bibr" target="#b31">[32]</ref>, LogCluster <ref type="bibr" target="#b38">[39]</ref>, Spell <ref type="bibr" target="#b13">[14]</ref>, and Drain <ref type="bibr" target="#b23">[24]</ref>. Among these methods, Drain demonstrated superior performance. Consequently, we chose the Drain method for our study. Drain is an online parser that organizes logs using a tree structure. It employs a heuristic approach to incrementally classify logs into appropriate groups as it processes the log stream. Next, we use a specific dataset to explain the detailed operations involved in log parsing.</p><p>To illustrate the log parsing process, we use the Hadoop Distributed File System (HDFS) dataset. This dataset contains logs generated by the various components of the HDFS system. Each log entry typically consists of a header and content. The header includes metadata such as the timestamp, log level, and component name, while the content contains the actual message generated by the system. To facilitate analysis, log parsing retains constant elements (e.g., "Block", "blockReport completed in") and replaces variable elements (e.g., block IDs, IP addresses, time durations) with wildcards (&lt;*&gt;). This process generates a structured log template, as illustrated Table <ref type="table" target="#tab_2">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Encoding</head><p>The parsed logs are still in text format. Building graph structures directly from text sentences presents substantial storage and computational challenges, potentially affecting the accuracy of semantic understanding and query efficiency. To address this issue, we use natural language processing (NLP) s to convert text into vector representations, thereby simplifying the construction and analysis of graph structures.</p><p>Common NLP s such as TF-IDF, Word2Vec <ref type="bibr" target="#b30">[31]</ref>, and GloVe <ref type="bibr" target="#b34">[35]</ref> are well-suited for smaller datasets. Fast-Text <ref type="bibr" target="#b25">[26]</ref> excels at processing text data with a large number of out-of-vocabulary words. For larger and more complex natural language understanding tasks, BERT <ref type="bibr" target="#b10">[11]</ref> is particularly effective, making it an ideal choice for scenarios involving significant changes and variations.</p><p>This study aims to provide a general log feature extraction framework for complex and varied log analysis scenarios, thus BERT was chosen. BERT, a language designed to capture semantic information in text data, has significantly improved performance in various NLP tasks by learning language representations from largescale text corpora and leveraging its bidirectional encoding capabilities.</p><p>In our experiments, we treat each log message as a template containing a set of words and subwords. By leveraging the text semantic expression capabilities of the pre-trained BERT , each log event is encoded into a fixed-dimensional vector representation of 768 dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3.">Constructing</head><p>The content of a single log often cannot independently reflect the state or behavior of a system or application. Understanding the entire process of an event requires analyzing the associations and causal relationships between multiple logs. Logs chronologically record system or application events, but a single log entry is often just a fragment, failing to reveal the complete event or behavior. By integrating the context provided by preceding and succeeding logs, the full process of an event can be reconstructed. Additionally, a single event in a system may trigger multiple subsequent events, each recorded as individual logs. Different logs may describe various aspects of the same system component or application, and by correlating these logs, a comprehensive understanding of the system state is achievable.</p><p>Graphs are particularly well-suited for describing the relationships between objects. The causal relationships in log data align well with the relational patterns between nodes in graph structures. In this representation, log events are depicted as nodes, while causal relationships between these events are depicted as edges. However, constructing graphs from large datasets presents significant challenges.</p><p>Firstly, the vast number of logs can result in an excessively large graph, leading to an unmanageable number of nodes and edges, which can severely impact storage and computational resources. Secondly, within such large datasets, causal relationships may become obscured and difficult to discern. The time intervals and correlations between log events can be diluted by irrelevant data, complicating the identification of true causal relationships.</p><p>To address these challenges, we employ a windowbased partitioning approach for log datasets. This method involves dividing log data into sequential windows based on time order and constructing a corresponding graph structure within each window. This approach helps to manage the dataset size and enhances the clarity of causal relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">DualGCN-LogAE</head><p>Graph structures provide a robust framework for representing complex relationships in log data. However, directly processing graph-structured data poses significant challenges, including potential information loss and limited generalization capacity. These issues can obstruct a comprehensive understanding of the underlying relational data. To address these challenges, graph representation learning has emerged as a crucial technique, converting nodes and edges into low-dimensional vectors <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b18">19]</ref>. This transformation facilitates the effective application of machine learning algorithms to graph data.</p><p>In this paper, we propose an autoencoder network based on GCN <ref type="bibr" target="#b26">[27]</ref> to learn robust representations of log data within graph structures. The architecture of our proposed DualGCN-LogAE is illustrated in Fig. <ref type="figure" target="#fig_0">3</ref>. The following subsections will provide an in-depth discussion of this architecture. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">GCN</head><p>The Graph Convolutional Network (GCN), which forms the backbone of the DualGCN-LogAE module, is a deep learning architecture tailored for graphstructured data. GCNs are specifically designed to learn node representations by aggregating the features of a node and its neighbors through convolutional operations. These aggregated features are then subjected to linear transformations followed by nonlinear activations to produce updated node representations. The following formula mathematically represents the process:</p><formula xml:id="formula_0">H (l+1) = σ( D-1 2 Ã D-1 2 H (l) W (l) ).<label>(1)</label></formula><p>Here, Ã = A + I N denotes the adjacency matrix of the undirected graph G with added self-connections, ensuring that each node's features contribute to its own update during the message-passing process, where I N is the identity matrix. The degree matrix D is introduced for normalization, with Dii = j Ãi j representing the degree of each node after the self-connections are included. Node features are transformed by a weight matrix W (l) and subsequently passed through a non-linear activation function σ(•), allowing the to capture complex patterns and interactions within the graph. The matrix H (l) ∈ R N×D represents the activations at the l th layer, where the initial layer H 0 is set to the input feature matrix X. GCN effectively aggregates the nodes' and neighbors' features to capture the rich structural information within a graph. This capability makes it well-suited for a wide range of supervised and semi-supervised learning tasks and adaptable to various types of graph structures. However, it also has notable limitations <ref type="bibr" target="#b41">[42]</ref>. As the number of layers increases, node representations tend to converge to similar values, which degrades performance. Additionally, GCN faces significant challenges when applied to graphs with limited or no labeled nodes, reducing their effectiveness in certain unsupervised scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Presentation Multi-Graphs</head><p>In this part, we present DualGCN-LogAE, a novel framework designed for log feature extraction. This framework is specifically developed to overcome certain challenges inherent in GCN when applied to deep learning tasks. To mitigate the performance degradation typically encountered in deeper architectures, our approach employs a simplified two-layer structure. This architecture is seamlessly integrated into an encoder-decoder framework, which allows GCNs to adapt effectively to datasets without labeled data. The following sections offer a detailed exploration of the framework. Our autoencoder architecture consists of two primary components: an encoder and a decoder, as illustrated in Algorithm 1. The encoder employs a GCN to project the input graph data into a low-dimensional space, capturing essential structural features. The decoder reconstructs the original graph data from this low-dimensional representation by applying operations that invert the encoding process. Through the minimization of reconstruction error, the autoencoder learns to generate compact and informative representations of the graph data.</p><p>Specifically, the input to the encoder is a composite atlas, denoted as</p><formula xml:id="formula_1">M G = {G 1 , G 2 , ..., G N }, where N indi- cates the number of graphs. Each graph G i = (V, E, W)</formula><p>consists of nodes V with a corresponding feature matrix X, edges E represented by an adjacency matrix A, and edge weights W associated with a weight matrix W G . The encoder generates outputs Z = {Z 1 , Z 2 , ..., Z N }, where each Z j = {z j1 , z j2 , ..., z jm } represents the lowdimensional embeddings of the nodes within G j . By reconstructing the low-dimensional representations Z, the original feature representations G can be effectively retrieved through the inverse operations.</p><p>To enhance the efficiency of the feature extraction framework, we propose a composite loss function, denoted by L DualGCN-LogAE . This loss function is composed of two principal components: a reconstruction loss and a regularization loss. The reconstruction loss is further divided into three distinct components: node reconstruction loss, edge reconstruction loss, and weight reconstruction loss. These components collectively maintain the structural and feature integrity of the graph. The formal definition of the reconstruction loss is provided as follows:</p><formula xml:id="formula_2">L DualGCN-LogAE = L rec + λL reg .</formula><p>(</p><formula xml:id="formula_3">)<label>2</label></formula><p>During training, the original graph data is first fed into the encoder to obtain a low-dimensional representation. This representation is then passed through the decoder to reconstruct the original data. The training process involves calculating the reconstruction loss, denoted as L rec , which measures the difference between the reconstructed and the original graph data. Additionally, a regularization loss, L reg , is computed to prevent </p><formula xml:id="formula_4">H (0) ← G ▷ Initial node features 4:</formula><p>for l = 1 to L do ▷ L layers of GCN 5: </p><formula xml:id="formula_5">H (l) ← f (X, A, W, H (l-</formula><formula xml:id="formula_6">H (0) dec ← Z ▷ The input of Decoder 12:</formula><p>for l = 1 to L do ▷ L layers of GCN 13:</p><formula xml:id="formula_7">H (l) dec ← g(Z, H (0) dec ) ▷ Graph Convolution 14:</formula><p>end for 15:</p><formula xml:id="formula_8">X rec , A rec , W rec ← H (L) dec ▷ Reconstructed node features 16:</formula><p>Â ← sigmoid(H (L)  dec H (L)T dec ) ▷ Reconstructed adjacency matrix store Ĝ to MG 37: end for 38: return MG overfitting and ensure generalization. These two losses are balanced by a hyperparameter λ, which controls the trade-off between the accuracy of reconstruction and the strength of regularization. The parameters of the encoder and decoder are iteratively adjusted using backpropagation to minimize the overall loss function, comprising both L rec and L reg . The progression of the training loss, which reflects the effectiveness of this process, is depicted in Fig. <ref type="figure" target="#fig_3">4</ref>. This approach harnesses the GCN's capability to effectively capture the underlying structure of graphs, thereby facilitating efficient learning of graph representations. The log features extracted by this method not only preserve critical information from the log content but also enhance the representation of causal relationships between logs within the graph structure. Importantly, this method operates without requiring labeled data, which broadens its applicability for log anomaly detection across various scenarios.</p><p>Our experimental results validate that these enhancements significantly improve the adaptability and performance of GCNs when applied to graph-structured data. By addressing challenges inherent to deep GCN architectures, large-scale graph processing, and the absence of labeled datasets, our method offers a more robust and efficient solution for graph-based learning tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Clustering</head><p>Identifying anomalies within log atlases presents significant challenges, primarily due to the resourceintensive nature of manual labeling and the difficulty in adapting to temporal and contextual variations. To address these issues, we aim to detect anomalies through graph clustering techniques that do not require labeled data.</p><p>Graph clustering <ref type="bibr" target="#b32">[33]</ref> is a fundamental technique in graph theory and data mining, designed to partition graph nodes into clusters characterized by dense intracluster connections and sparse inter-cluster connections. This approach is widely applied in fields such as social network analysis, recommendation systems, bioinformatics, and network security.</p><p>Among the various graph clustering techniques available (including K-means <ref type="bibr" target="#b22">[23]</ref>, spectral clustering <ref type="bibr" target="#b39">[40]</ref>, agglomerative hierarchical clustering <ref type="bibr" target="#b8">[9]</ref>, and DB-SCAN <ref type="bibr" target="#b15">[16]</ref>), we have chosen spectral clustering due to its effectiveness with dimensionally reduced data. This is particularly advantageous for our application, where the log atlas has been compressed by an encoder. By using the feature vectors generated by the encoder to construct a similarity matrix, spectral clustering facilitates effective partitioning of the data.</p><p>Spectral clustering is especially proficient in identifying clusters of arbitrary shapes, which is crucial for uncovering complex patterns within log atlases. This method leverages the eigenvectors of the Laplacian matrix derived from the graph, ensuring robustness and stability in the clustering process (Fig. <ref type="figure" target="#fig_4">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Metrics</head><p>In our experiments, we utilized both labeled and unlabeled datasets. The labeled datasets were evaluated using conventional supervised learning metrics such as accuracy. However, these metrics are not suitable for evaluating unlabeled datasets due to the absence of ground truth labels. To address this challenge, we drew upon methodologies discussed in the literature concerning clustering quality assessment, specifically the works of <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b1">2]</ref>. For the evaluation of clustering performance on unlabeled data, we employed three well-established metrics: the Silhouette coefficient, the Davies-Bouldin index, and the Calinski-Harabasz index. The following is a detailed description of the three indicators:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1.">Silhouette Coefficient</head><p>The Silhouette Coefficient <ref type="bibr" target="#b35">[36]</ref> measures clustering quality by considering both cluster cohesion and separation. For each sample, it calculates the average distance to other samples within the same cluster (cohesion) and the average distance to samples in the nearest neighboring cluster. The silhouette coefficient s i for a sample is defined as:</p><formula xml:id="formula_9">s i = b i -a i max(a i , b i ) ,<label>(3)</label></formula><p>where a i is the average distance to other samples in the same cluster, and b i is the average distance to samples in the nearest neighboring cluster. s i range between -1 and 1, where s i closer to 1 indicate better clustering, s i close to -1 indicate incorrect clustering, and s i around 0 suggest overlapping clusters. The overall Silhouette Coefficient for a dataset is given by:</p><formula xml:id="formula_10">S C = N i=1 s i N .<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2.">Davies-Bouldin Index</head><p>The Davies-Bouldin Index <ref type="bibr" target="#b7">[8]</ref> evaluates clustering by examining the ratio of within-cluster scatter to betweencluster separation. It is calculated as:</p><formula xml:id="formula_11">DB = 1 k k i=1 max i j,i, j∈[1,K] d i + d j M i j ,<label>(5)</label></formula><p>where d i (Eq. 6) is the average distance between each point in cluster i and the cluster centroid, and M i j (Eq. 7) is the distance between cluster centroids i and j. A lower Davies-Bouldin Index indicates better clustering quality. The within-cluster scatter d i is defined as:</p><formula xml:id="formula_12">d i =          1 n n j=1 |X i j -A i | q          1 q ,<label>(6)</label></formula><p>here, X i j is point j in class j, A i is the center of class i, n is the count of class i. When q = 1, d i is mean distanse of each points to center, and q = 2 means the standard deviation of the distance from each point to the center, they can be used to measure the degree of dispersion. where X i j is point j in cluster i, A i is the centroid of cluster i, and n is the number of points in cluster i. When q = 1, d i represents the mean distance of each point to the centroid. When q = 1, d i represents the standard deviation of the distances from each point to the centroid, both of which measure the degree of dispersion. The between-cluster separation M i j is defined as:</p><formula xml:id="formula_13">M i j =        K k=1 |a ki -a k j | q        1 q , (<label>7</label></formula><formula xml:id="formula_14">)</formula><p>where a ki represents the value of the k-th attribute of the center point of the i-th category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.3.">Calinski-Harabasz Index</head><p>The Calinski-Harabasz Index <ref type="bibr" target="#b4">[5]</ref>, also known as the Variance Ratio Criterion, assesses clustering effectiveness by comparing the ratio of between-cluster dispersion to within-cluster dispersion. It is calculated as:</p><formula xml:id="formula_15">CH = tr(B k )(N -K) tr(W k )(K -1) ,<label>(8)</label></formula><p>where tr(B k ) is the trace of the between-group dispersion matrix and tr(W k ) is the trace of the within-cluster dispersion matrix. Higher values indicate better clustering performance. The details of B k and B k are as follows:</p><formula xml:id="formula_16">B k = k q=1 n q (c q -c e )(c q -c e ) T ,<label>(9)</label></formula><formula xml:id="formula_17">W k = k q=1 x∈C q (c q -c e )(c q -c e ) T .<label>(10)</label></formula><p>Where c q represents the center point of class q, c e represents the center point of the data set, n q represents the number of data in class q, and c q represents the data set of class q. These indicators provide a comprehensive evaluation of clustering results. By applying these metrics, we can thoroughly assess the performance of our algorithm on unlabeled datasets, offering reliable guidance for anomaly detection tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Evaluate</head><p>To verify the adaptability of our method across different scenarios, we conducted a series of experiments on five distinct datasets. This section outlines our experimental setup and provides a detailed description of the datasets used, and the algorithms chosen for comparison. Additionally, we present and analyze the results of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Experiment Setup</head><p>Our method, along with the comparison methods, was implemented using Python 3.7.0, PyTorch 1.9.0, and PyG 2.0.3. All experiments were conducted on a machine running Ubuntu 18.04.4 LTS, equipped with a GeForce RTX 3080 GPU, 64 CPUs clocked at 2.10 GHz, and 20,480 MiB of main memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Datasets</head><p>We selected five widely used public log datasets from the LogHub repository <ref type="bibr" target="#b24">[25]</ref>: HDFS, BGL, HPC, Zookeeper, and Proxifier, as summarized in Table <ref type="table" target="#tab_4">2</ref>, where A&amp;P indicates the percentage of abnormal data. These datasets cover various application scenarios and exhibit diverse characteristics. Notably, the HDFS and BGL datasets are labeled, while the remaining three are unlabeled. This selection enables a comprehensive evaluation of the performance and applicability of our method across both labeled and unlabeled data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">HDFS</head><p>The HDFS dataset is used for log data analysis in distributed storage and processing systems, capturing detailed operations in Hadoop clusters, such as file operations, node status, and task execution. These logs, stored in text format, include timestamps, operation types, and node information, making them valuable for large-scale distributed system analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">BGL</head><p>Originating from the Blue Gene/L supercomputer system logs, the BGL dataset is utilized for analyzing supercomputer performance, as well as detecting and diagnosing faults. BGL logs encompass various operations and events, including task scheduling and communication messages, and contain extensive time-series data and performance metrics, making them suitable for high-performance computing environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">HPC</head><p>The HPC dataset includes log data from various highperformance computing environments, such as scientific computing and engineering simulations. These logs, which vary by application, include task execution, resource scheduling, and application output. Due to their large, complex, and diverse nature, they require specialized analysis methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4.">Zookeeper</head><p>The Zookeeper dataset is derived from the logs of the Zookeeper distributed coordination service, recording node status changes, election processes, and client requests. Despite their smaller size, Zookeeper logs are crucial for monitoring and diagnosing distributed system status due to their real-time and consistency requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5.">Proxifier</head><p>The Proxifier dataset is used for log analysis of network proxy servers, recording network requests and responses, including website visits and data transmissions. Although small in volume, these logs contain sensitive information such as IP addresses and access history, necessitating careful privacy protection and security analysis.</p><p>Our experimental design aims to provide a comprehensive understanding of our method's performance across diverse data types and scenarios. This approach not only enhances the robustness of our method but also offers valuable insights for future research in anomaly detection. By testing our method with challenging, realistic tasks, we seek to improve its practicality and reliability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Compared Methods</head><p>To evaluate the effectiveness of the proposed method, we compared it with two state-of-the-art algorithms using five classic public datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Log2vec</head><p>Log2vec is a method specifically designed to detect network threats within enterprises. It leverages heterogeneous graph embedding technology to distinguish malicious operations by constructing graphs, learning representation vectors of operations, and employing detection algorithms. The approach consists of three main components: graph construction, graph embedding, and detection algorithms.</p><p>First, Log2vec integrates multiple relationships between log entries by constructing a heterogeneous graph. Second, it uses graph embedding technology to learn the representation vector of each operation. This vectorization allows for a direct comparison of similarities between user operations, thereby identifying abnormal behaviors. Finally, the detection algorithm effectively clusters malicious operations into separate groups for identification.</p><p>Log2vec primarily uses simple login information and other self-collected log data. Due to the small data volume and simplicity of the log information, we adapted its rules to suit larger and more complex datasets for a fair comparison with our algorithm. For the HDFS dataset, we constructed the graph using session size, while for several other datasets, we used window size for graph construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">AIRTAG</head><p>AIRTAG employs the BERT pre-training to embed expressions in logs, followed by classifiers to detect malicious logs. The original classifier used in the article is OC-SVM, which requires normal data for training. However, three of the datasets used in this study lack label information. Therefore, we adopted two approaches for this algorithm.</p><p>First, we followed the original method and used OC-SVM to evaluate the results on the labeled HDFS and BGL datasets. For the other datasets, which lack labels, we followed the original procedure up to the final evaluation step, where we used the clustering algorithm proposed in this study for evaluation. For easy distinction, we named it Bert Cluster.</p><p>By comparing our method against Log2vec and AIRTAG, we demonstrated its superior performance in handling both labeled and unlabeled datasets, showcasing its robustness and effectiveness in detecting network threats.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Results and Analysis</head><p>To validate the feature extraction framework DualGCN-LogAE for log data proposed in this paper, we conducted a series of supervised and semi-supervised learning experiments on two labeled datasets: HDFS and BGL. The specific results are presented in Fig. <ref type="figure">6</ref> and Fig. <ref type="figure">7</ref>. As illustrated in these figures, our method enhances detection accuracy across all tested approaches compared to BERT, the feature extraction method used in AIRTAG. This indicates that our method is effective for log feature extraction.</p><p>To verify our proposed unsupervised log anomaly detection framework, Log2graphs, for the DualGCN-LogAE framework, we conducted experiments by randomly selecting a portion of samples from two labeled datasets, as detailed in Table <ref type="table" target="#tab_5">3</ref>. The proportion of abnormal samples was 2.3% and 10.3%, respectively, reflecting the rarity of abnormal events in real-world systems. We detect anomalies by clustering log entries into two groups. Given the pronounced imbalance in the datasets, we hypothesize that the larger clusters primarily consist of normal samples, while the smaller clusters contain abnormal samples. Based on this assumption, we further analyzed the clustering results.</p><p>The number of clusters identified in the two datasets is summarized in Table <ref type="table" target="#tab_4">2</ref>. For the HDFS dataset, cluster HDFS-0 contains 11,101 samples, and cluster HDFS-1 contains 204 samples. We classify HDFS-0 as the normal cluster and HDFS-1 as the abnormal cluster. As shown in Figure <ref type="figure" target="#fig_7">8</ref>, our detection accuracy for HDFS is 97.39%, which is 21% higher than Bert Cluster, 19% higher than AIRTAG, and 11% higher than Log2vec. For the BGL dataset, cluster BGL-0 contains 9,309 samples, while cluster BGL-1 contains 791 samples. Similarly, we identify BGL-0 as the normal cluster and BGL-1 as the anomaly cluster. Our detection accuracy for BGL is 88.88%, which is 14% higher than Bert Cluster, 23% higher than AIRTAG, and 7% higher than Log2vec. These results demonstrate that our method significantly outperforms existing approaches in the task of log anomaly detection. Notably, our algorithm does not require any labeled data, yet it outperforms the AIRTAG algorithm, which relies on normal logs for training the detection . This further underscores the superior performance and efficiency of our method.  To demonstrate the applicability of our method across multiple scenarios, we introduce three clustering quality evaluation metrics: the Silhouette Coefficient, the Davies-Bouldin Index, and the Calinski-Harabasz Index. These indicators comprehensively assess the quality of clustering results, enabling the inclusion of unlabeled datasets in academic research on log anomaly detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HDFS</head><p>Existing log feature extraction methods typically con-sider relatively simple factors, resulting in only dozens or hundreds of identical templates after extraction. In such cases, applying clustering algorithms often leads to significant sample overlap at the same point, making it unsuitable for calculating clustering scores. Consequently, we did not compare this aspect with existing studies. Instead, we applied three different clustering algorithms after using the feature extraction proposed in this paper to validate the feasibility of these three metrics in evaluating unsupervised log anomaly detection.</p><p>The results are presented in Fig. <ref type="figure">9</ref>, 10, and 11. Here, "SP" denotes the spectral clustering algorithm. The Silhouette Coefficient results, shown in Fig. <ref type="figure">9</ref>, indicate that a value closer to 1 signifies better clustering, while a value closer to -1 suggests incorrect clustering and values near 0 indicate cluster overlap. The spectral clustering result is evidently closer to 1, indicating superior clustering. The Davies-Bouldin Index, shown in Fig. <ref type="figure" target="#fig_1">10</ref>, reveals that a smaller value corresponds to better clustering, with spectral clustering achieving significantly lower values than the other methods. The Calinski-Harabasz Index compares the ratio of inter-cluster dispersion to intra-cluster dispersion to evaluate clustering effectiveness, with larger values indicating better clustering. Since only two clusters are formed in our study, the Calinski-Harabasz Index values are relatively high overall. For comparative purposes, we log-transformed the original values before plotting the graph, as shown in Fig. <ref type="figure" target="#fig_9">11</ref>. The results demonstrate that spectral clustering consistently outperforms the other two methods.</p><p>Overall, spectral clustering is a highly suitable choice for our graph clustering algorithm. Furthermore, the consistency of the results across both labeled and unlabeled datasets for these three metrics suggests that these indicators are indeed applicable in the study of unsupervised log anomaly detection methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Disscusion</head><p>Our proposed method employs graph clustering in the anomaly detection stage, utilizing a completely unsupervised classification approach. To thoroughly evaluate the strengths and weaknesses of this method, we compared it with a classic supervised learning approach using a multi-layer perceptron (MLP) for classification. The results demonstrate that the MLP achieves a detection accuracy of 97.04% on the HDFS dataset and 98.99% on the BGL dataset. While the performance of the supervised method is comparable to our proposed method on HDFS, there is a significant performance disparity on BGL. This difference verifies the effectiveness of our proposed graph convolutional network with DualGCN-LogAE in log representation to a certain extent but also shows that graph clustering has poor adaptability in different scenarios. Future research should explore other unsupervised detection algorithms with broad adaptability or design specialized unsupervised algorithms tailored to specific scenarios.</p><p>Detecting anomalies in large log datasets using graph clustering introduces challenges such as computational complexity, memory consumption, and algorithm convergence speed. To address these issues, this paper adopts a random data block scheme, where small data blocks are randomly extracted from the overall dataset for performance testing. However, the distribution of these randomly extracted data blocks may slightly dif- fer from the data not involved in detection, and testing each block increases the overall computational burden. Future work could consider employing a lighter unsupervised algorithm to mitigate the system's computational complexity associated with increased data volume and implementing strategies to discard historical data to reduce storage pressure. Additionally, developing a distributed computing could alleviate the computational load on a single detector.</p><p>Our proposed method assumes a significant distribution difference between abnormal and normal categories, with high similarity within samples of the same category. If these characteristics are absent in certain scenarios, our anomaly detection method may fail. In the future, we plan to design a large with sufficient prior knowledge to assist in determining categories that could enhance the effectiveness of unsupervised anomaly detection. This approach would broaden the applicability of unsupervised learning in anomaly detection, allowing our proposed method to be used in a wider range of scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related work</head><p>Log anomaly detection is a crucial aspect of network security, instrumental in identifying potential security threats and system failures. Various approaches are employed in log anomaly detection, including rulebased, statistical-based, machine learning-based, timeseries analysis, and graph-based methods. Rule-based methods rely on predefined patterns to detect anomalies, while statistical methods identify deviations from established statistical norms. Machine learning-based methods leverage algorithms to learn from historical data and predict anomalies. Time-series analysis focuses on temporal patterns in the data to identify unusual events. Lastly, graph-based methods analyze the relationships between different log entries to uncover anomalies. Each technique offers unique strengths, contributing to a comprehensive security strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Rule-Based Methods</head><p>Early log anomaly detection primarily employed rule-based methods. These approaches rely on security experts to manually define normal log formats and thresholds based on the system's business logic. Deviations from these preset standards are marked as anomalies. For instance, Nagappan et al., <ref type="bibr">Barringer et al.</ref>, and Cinque et al. used predefined rules and conditions to detect abnormal activities in system logs by leveraging their understanding of specific business processes <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b6">7]</ref>. While these methods provide quick and direct security protection, they typically depend on predefined rules from security experts, limiting their capability to detect unknown anomalies and attacks. Log anomaly detection is of great significance in the field of network security and has always received widespread attention. Researchers have proposed a variety of methods to solve the problem of anomaly detection in logs, which can be mainly divided into rule-based methods, machine learning methods, and time series methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Statistical-Based Methods</head><p>Statistical-based methods identify anomalies through statistical analysis of normal behavior, without relying on predefined rules. Harada et al. applied the local outlier factor (LOF) algorithm to detect anomalies in system logs for automatic aquarium management systems <ref type="bibr" target="#b21">[22]</ref>. Debnath et al. proposed Loglenss, which learns structures from "correct logs" to generate s that capture normal system behaviors <ref type="bibr" target="#b9">[10]</ref>. These s are then used to analyze real-time production logs and detect anomalies. Wurzenberger et al. introduced the Variable Type Detector (VTD), which combines normal and abnormal information with an automatic identification mechanism to select variables suitable for anomaly detection <ref type="bibr" target="#b42">[43]</ref>. Statistical-based methods offer a flexible and effective approach to anomaly detection by analyzing the statistical characteristics of log data, demonstrating significant advantages in discovering unknown threats and complex behavior patterns. However, they require substantial computing resources and depend on accurate baseline data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Machine Learning-Based Methods</head><p>The advent of artificial intelligence has brought increased attention to machine learning-based log anomaly detection. Machine learning methods offer significant advantages, including higher detection accuracy, adaptability, automation, and scalability. For example, Cao et al. proposed an anomaly detection system for web log files using a two-level machine learning algorithm <ref type="bibr" target="#b5">[6]</ref>, while Han et al. introduced the ROEAD robust online evolutionary anomaly detection framework using Support Vector Machine(SVM) <ref type="bibr" target="#b20">[21]</ref>. These methods significantly improve detection accuracy but also have drawbacks such as high computational complexity, strong data dependence, difficulty in parameter tuning, high real-time requirements, and poor interpretability.</p><p>Additionally, unsupervised learning methods, such as clustering and isolation forest algorithms, avoid the need for data labeling. Logcluster applies K-means clustering directly to log data <ref type="bibr" target="#b38">[39]</ref>. Turgeman et al. use Word2vec to embed log alert indicators into a common latent space, followed by a customized incremental clustering algorithm to cluster the alerts <ref type="bibr" target="#b37">[38]</ref>. Farzad et al. proposed an unsupervised log message anomaly detection using isolation forests and two deep autoencoder networks <ref type="bibr" target="#b16">[17]</ref>. While these methods can monitor abnormal logs without labeled data, they suffer from issues like lack of label guidance, unclear anomaly definitions, high false alarm rates, poor interpretability, sensitivity to data quality, complex parameter adjustments, high computational resource consumption, and inability to fully capture complex behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Time Series-Based Methods</head><p>Log data inherently possesses time series properties, making time series-based log anomaly detection a crucial research direction. These methods detect abnormal behavior by focusing on the time series patterns and dependencies between log events. Deeplog utilizes a long short-term memory (LSTM) deep neural network to treat system logs as natural language sequences, automatically learning log patterns from normal execution and detecting anomalies when deviations occur <ref type="bibr" target="#b14">[15]</ref>. Loganomaly builds on Deeplog by using tem-plate2vec to extract hidden semantic information from log templates, then employing LSTM to learn normal log patterns <ref type="bibr" target="#b29">[30]</ref>. LogBert employs bidirectional encoder representations from transformers (BERT) to extract semantic features <ref type="bibr" target="#b19">[20]</ref>, while DeepSyslog uses sentence embeddings to extract log event information <ref type="bibr" target="#b46">[47]</ref>. PLELog leverages a gated recurrent unit (GRU) neural network with an attention mechanism to learn normal log patterns <ref type="bibr" target="#b44">[45]</ref>. AIRTAG combines these improvements, using BERT for log semantic extraction and introducing one-class support vector machine (OC-SVM), in the detection module <ref type="bibr" target="#b11">[12]</ref>. Time series-based log anomaly detection methods show great potential in improving detection accuracy and capturing complex abnormal patterns. However, they often struggle with capturing complex multi-time dependencies and perform poorly with nonlinear and long-distance dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Graph-Based Methods</head><p>Graph-based methods address many limitations of traditional time series methods by capturing complex multi-event dependencies, processing high-dimensional time series data, identifying nonlinear and long-distance dependencies, and adapting to the simultaneous occurrence of multiple events. This makes log anomaly detection more comprehensive and accurate. Log2vec uses random walks and Word2vec to represent graph nodes formed by log events, then applies the K-means clustering algorithm on normal log nodes, and finally calculates the normal threshold to identify abnormal logs <ref type="bibr" target="#b27">[28]</ref>. ATLAS uses LSTM to learn normal log sequence patterns based on the graph structure <ref type="bibr" target="#b0">[1]</ref>. LogGD employs graph attention networks (GAT) to learn log representations, followed by a forward propagation network for supervised learning classification <ref type="bibr" target="#b43">[44]</ref>. Although these graph-based log anomaly detection methods offer significant advantages in capturing complex dependencies and processing multidimensional data, they often suffer from low efficiency in log event representation and a continued reliance on labeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper introduces a robust log feature extraction framework that leverages graph structures, combining causal relationships between logs with the content information of the logs themselves. Additionally, we propose a log anomaly detection method based on this framework that does not require labeled data, and we introduce three metrics to evaluate the experimental results on unlabeled data. Our proposed method effectively detects anomalies in logs from different systems without the need for labeled data, addressing a significant challenge in this field. Furthermore, our approach broadens the scope of log anomaly detection research by enabling the use of unlabeled log datasets for both anomaly detection and evaluation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: It collaboratively compresses high-dimensional graphstructured log data into low-dimensional vector representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1</head><label>1</label><figDesc>DualGCN-LogAE Require: A collection of graphs M G = {G 1 , G 2 , . . . , G N }, where each graph G = (V, E, W) Ensure: Reconstructed graphs MG = { Ĝ1 , Ĝ2 , . . . , ĜN } 1: Initialize: GCN Encoder weights θ enc , GCN Decoder weights θ dec 2: function GCN Encoder(G, θ enc ) 3:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>17 :H</head><label>17</label><figDesc>return (X rec , A rec , W rec ) 18: end function 19: function Train(M G , θ enc , θ dec ) (L) ← GCN Encoder(G, θ enc ) 23: (X recon , Â) ← GCN Decoder(H (L) , θ dec ) 24: L rec ← MSE(M G , MG ) ▷ Reconstruction loss 25: L reg ← Tr(Z, A, Â) ▷ Regularization loss 26: L ← L rec + λL reg ▷ Total loss 27: Update θ enc and θ dec using gradient descent on L 28: end for 29: end function 30: Training Phase: 31: Train(M G , θ enc , θ dec ) 32: Reconstruction Phase: 33: for G ∈ M G do 34: Z ← GCN Encoder(G, θ enc ) 35: Ĝ ← GCN Decoder(Z, θ dec ) 36:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The train loss of DualGCN-LogAE on five datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Flowchart of the spectral clustering algorithm. a. Construct the similarity matrix S of the samples. b. Construct the adjacency matrix W and the degree matrix D based on the similarity matrix S . c. Calculate and standardize the Laplacian matrix L. d. Spectral decomposition. e. Construct a new feature matrix. f. K-Means clustering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: The detection accuracy of classic algorithms on HDFS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The detection accuracy of graph clustering on different datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :Figure 10 :</head><label>910</label><figDesc>Figure 9: The Silhouette coefficient of different algorithms on different datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: The Calinski-Harabasz index of different algorithms on different datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>The example analysis of log format.</figDesc><table><row><cell>Date/Time/Pid</cell><cell>Level Thread</cell><cell>Message</cell><cell></cell><cell></cell><cell>Template</cell></row><row><cell cols="5">081109/204015/308 INFO dfs.DataNode$PacketResponder PacketResponder 2 for block</cell><cell>PacketResponder</cell></row><row><cell></cell><cell></cell><cell cols="3">blk 8229193803249955061</cell><cell>&lt;*&gt; for block</cell></row><row><cell></cell><cell></cell><cell>terminating</cell><cell></cell><cell></cell><cell>blk &lt;*&gt; termi-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>nating</cell></row><row><cell cols="2">081109/203521/1438 INFO dfs.DataNode$DataXceiver</cell><cell>Received</cell><cell>block</cell><cell>blk -</cell><cell>Received block</cell></row><row><cell></cell><cell></cell><cell cols="3">1608999687919862906 src:</cell><cell>blk &lt;*&gt;</cell><cell>src:</cell></row><row><cell></cell><cell></cell><cell cols="3">/10.251.215.16:52002 dest:</cell><cell>&lt;*&gt; dest: &lt;*&gt;</cell></row><row><cell></cell><cell></cell><cell cols="2">/10.251.215.16:50010</cell><cell>of</cell><cell>of sizecm&lt;*&gt;</cell></row><row><cell></cell><cell></cell><cell>size 911784</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Detailed information of datasets.</figDesc><table><row><cell>Name</cell><cell>Description</cell><cell>Window</cell><cell>Entries</cell><cell>A&amp;P</cell><cell>Label</cell></row><row><cell>HDFS</cell><cell>Hadoop distributed file system log</cell><cell>session</cell><cell cols="2">11175629 2.93%</cell><cell>Label</cell></row><row><cell>BGL</cell><cell>Blue Gene/L supercomputer log</cell><cell>100 logs</cell><cell cols="2">4747963 10.3%</cell><cell>Label</cell></row><row><cell>HPC</cell><cell>High performance cluster log</cell><cell>100 logs</cell><cell>433489</cell><cell>-</cell><cell>Unlabel</cell></row><row><cell>Zookeeper</cell><cell>ZooKeeper service log</cell><cell>100 logs</cell><cell>74380</cell><cell>-</cell><cell>Unlabel</cell></row><row><cell>Proxifier</cell><cell>Proxifier software log</cell><cell>100 logs</cell><cell>21329</cell><cell>-</cell><cell>Unlabel</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>The number of normal and unnormal logs.</figDesc><table><row><cell cols="4">Cluster Quantity Proportion Judged</cell></row><row><cell>HDFS 0</cell><cell>11101</cell><cell>98.20%</cell><cell>Normal</cell></row><row><cell>HDFS 1</cell><cell>204</cell><cell>1.80%</cell><cell>Abnormal</cell></row><row><cell>BGL 0</cell><cell>9309</cell><cell>92.17%</cell><cell>Normal</cell></row><row><cell>BGL 1</cell><cell>791</cell><cell>7.83%</cell><cell>Abnormal</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">{ATLAS}: A sequence-based learning approach for attack investigation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alsaheel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Walkup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Celik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th USENIX security symposium (USENIX security 21)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3005" to="3022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Finding compact and well-separated clusters: Clustering using silhouette coefficients</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bagirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Aliguliyev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sultanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page">109144</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Formal analysis of log files</title>
		<author>
			<persName><forename type="first">H</forename><surname>Barringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Groce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Havelund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of aerospace computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="365" to="390" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A comprehensive survey of graph embedding: Problems, techniques, and applications</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C C</forename><surname>Chang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1616" to="1637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A dendrite method for cluster analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Caliński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harabasz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics-theory and Methods</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Machine learning to detect anomalies in web log analysis</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lyu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="519" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Event logs for the analysis of software failures: A rule-based approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cinque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cotroneo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pecchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="806" to="821" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A cluster separation measure</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Bouldin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="1979">1979</date>
			<biblScope unit="page" from="224" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient algorithms for agglomerative hierarchical clustering methods</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Edelsbrunner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of classification</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7" to="24" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Loglens: A real-time log analysis system</title>
		<author>
			<persName><forename type="first">B</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Solaimani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A G</forename><surname>Gulzar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lumezanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 38th international conference on distributed computing systems (ICDCS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="1052" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">{AIRTAG}: Towards automated attack investigation by unsupervised learning with log texts</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">32nd USENIX Security Symposium (USENIX Security</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="373" to="390" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Estimating the optimal number of clusters in categorical data clustering by silhouette coefficient</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fujinami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Huynh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge and Systems Sciences: 20th International Symposium</title>
		<meeting><address><addrLine>Da Nang, Vietnam</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-11-29">2019. 2019. November 29-December 1, 2019</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
	<note>KSS</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Spell: Streaming parsing of system event logs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 16th International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="859" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deeplog: Anomaly detection and diagnosis from system logs through deep learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Srikumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2017 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1285" to="1298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<editor>kdd</editor>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="226" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised log message anomaly detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Farzad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Gulliver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICT Express</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="229" to="237" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Execution anomaly detection in distributed systems through unstructured log analysis</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Graph embedding techniques, applications, and performance: A survey</title>
		<author>
			<persName><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ferrara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="78" to="94" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Logbert: Log anomaly detection via bert</title>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 international joint conference on neural networks (IJCNN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Log-based anomaly detection with robust feature extraction and online learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="2300" to="2311" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Logbased anomaly detection of cps using a statistical method</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamagata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mizuno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 8th International Workshop on Empirical Software Engineering in Practice (IWESEP), IEEE</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Algorithm as 136: A kmeans clustering algorithm</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Hartigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the royal statistical society. series c (applied statistics)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="100" to="108" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Drain: An online log parsing approach with fixed depth tree</title>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE international conference on web services (ICWS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.06448</idno>
		<title level="m">Loghub: A large collection of system log datasets towards automated log analytics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.03651</idno>
		<title level="m">Fasttext. zip: Compressing text classification models</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Log2vec: A heterogeneous graph embedding based approach for detecting cyber threats within enterprise</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2019 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1777" to="1794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A lightweight algorithm for message type extraction in system application logs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Makanju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Zincir-Heywood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Milios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1921" to="1936" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Loganomaly: Unsupervised detection of sequential and quantitative anomalies in unstructured logs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="4739" to="4745" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m">Efficient estimation of word representations in vector space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Incremental mining of system log format</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mizutani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Services Computing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="595" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Graph clustering with graph neural networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Analysis of execution log files</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nagappan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering</title>
		<meeting>the 32nd ACM/IEEE International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="409" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational and applied mathematics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Cluster quality analysis using silhouette score, in: 2020 IEEE 7th international conference on data science and advanced analytics (DSAA)</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Shahapure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nicholas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="747" to="748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Context-aware incremental clustering of alerts in monitoring systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Turgeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Avrashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Azaizah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="page">118489</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Logcluster-a data clustering and pattern mining algorithm for event logs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vaarandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pihelgas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th International conference on network and service management</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName><forename type="first">Von</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An improved index for clustering validation based on silhouette index and calinski-harabasz index</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IOP Conference Series: Materials Science and Engineering</title>
		<imprint>
			<publisher>IOP Publishing</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">52024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Analysis of statistical properties of variables in log data for advanced anomaly detection in cyber security</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wurzenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Höld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Skopik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Security</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page">103631</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Loggd: Detecting anomalies from system logs with graph neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Babar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE 22nd International Conference on Software Quality, Reliability and Security</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="299" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Semi-supervised log-based anomaly detection via probabilistic label estimation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1448" to="1460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">System log parsing: A survey</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Castellano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pianese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deepsyslog: Deep anomaly detection on syslog using sentence embedding and metadata</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="3051" to="3061" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Tools and benchmarks for automated log parsing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
