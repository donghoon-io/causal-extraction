<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LEARNING CAUSAL NETWORKS TOPOLOGY FROM STREAMING GRAPH SIGNALS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mircea</forename><surname>Moscu</surname></persName>
							<email>mircea.moscu@oca.eu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire Lagrange</orgName>
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">OCA</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<settlement>Nice</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roula</forename><surname>Nassif</surname></persName>
							<email>roula.nassif@epfl.ch</email>
							<affiliation key="aff1">
								<orgName type="institution">Ecole Polytechnique Fédérale de Lausanne</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fei</forename><surname>Hua</surname></persName>
							<email>fei.hua@oca.eu</email>
							<affiliation key="aff2">
								<orgName type="department">School of Marine Science and Technology</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cédric</forename><surname>Richard</surname></persName>
							<email>cedric.richard@unice.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire Lagrange</orgName>
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">OCA</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<settlement>Nice</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LEARNING CAUSAL NETWORKS TOPOLOGY FROM STREAMING GRAPH SIGNALS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.23919/EUSIPCO.2019.8902826</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Network topology</term>
					<term>graph signal processing</term>
					<term>distributed learning</term>
					<term>online learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modern data analysis and processing tasks usually involve large sets of data structured by a graph. Typical examples include brain activity supported by neurons, data shared by users of social media, and traffic on transportation or energy networks. There are often settings where the graph is not readily available, and has to be estimated from data. This paper focuses on estimating a network structure capturing the dependencies among streaming graph signals in the form of a possibly directed, weighted adjacency matrix. Several works proposed centralized offline solutions to address this problem, without paying much attention to the distributed nature of networks. We start from a centralized setting and show how, by introducing a simple yet powerful data model, we can infer a graph structure from streaming data with a distributed online learning algorithm. Our algorithm is tested experimentally to illustrate its usefulness, and successfully compared to a centralized offline solution of the literature.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In the last past years, data has become a raw resource that needs to be collected and refined before becoming useful information. Data are abundant and diverse, taking different forms, stemming from different sources: e-commerce, sporting events, entertainment media, and social interactions, to name a few. Structured data, where each component is linked in some way to others, are ubiquitous and generally evolve over time, making it difficult to process and analyze. Since seminal works such as <ref type="bibr" target="#b1">[1]</ref>, graph signal processing (GSP) has attracted great attention due to the potential applications it offers. Typical examples include brain activity imaging, social media analysis, and transportation or energy networks monitoring.</p><p>Most graph signal processing algorithms introduced in the last five years assume prior knowledge of the graph structure. However, there are often settings where the graph is not readily available, and has to be inferred from data by capturing the underlying relationship between the characteristics of the observations at each node. This paper focuses on estimating a network structure capturing the dependencies among streaming graph signals in the form of a possibly directed, weighted adjacency matrix. Definitions: A graph G consists of a set N of N nodes, and a set E of edges such that if nodes m and n are linked, then (m, n) ∈ E. For undirected graphs, these node pairs are unordered. Notation Nn stands for the set of indices of nodes in the neighbourhood of node n, i.e., Nn = {m : (m, n) ∈ E}.</p><p>At the node level, we collect a signal x [x1, . . . , xN ] , assumed to be real-valued, where xn is the sample of the signal x at node n. We endow the graph G with a shift operator <ref type="bibr" target="#b1">[1]</ref>, defined as an N × N matrix S. Entries snm are non-zero if (m, n) ∈ E. This matrix encodes the underlying graph connectivity. Valid choices for this operator are the adjacency matrix (weighted or not) or Laplacian matrix (and its variations) <ref type="bibr" target="#b2">[2]</ref>. Operation Sx is called a graph shift and can be performed locally at each node n by aggregating samples in its neighborhood, i.e., m∈Nn snmxm. Also, S k x represents a shift of order k that aggregates samples from k-hop neighbors. Prior works: For topology identification, several works have been put forward. A very early proposition is in <ref type="bibr" target="#b3">[3]</ref>, where a covariance estimation based method of inferring links is introduced. On the same line, in <ref type="bibr" target="#b4">[4]</ref> the graphical Lasso is employed in order to estimate the inverse covariance matrix from data. In <ref type="bibr" target="#b5">[5]</ref>, the authors advocate that connectivity can be recovered from spectral templates, under the assumptions that the graph signal x is stationary and generated through a diffusion process. They estimate the shift operator S under a set of constraints that yields a matrix with desirable properties, such as zeros on the diagonal, sparsity and symmetry. The authors in <ref type="bibr">[6]</ref> propose an adaptive algorithm for learning the topology from streaming graph signals driven by a diffusion process.</p><p>Under a graph signal smoothness assumption, the so-called pairwise distances matrix Z with entries defined as zmn xm -xn 2 , is introduced in <ref type="bibr" target="#b7">[7]</ref> to estimate a weighted adjacency matrix W. The problem is then solved by assigning smaller weights to far away nodes, while reducing the number of less connected nodes and exceedingly large weights. Other solutions include the use of dictionaries. The authors in <ref type="bibr" target="#b8">[8]</ref> devise a method for learning a dictionary that is able to efficiently represent the signals as linear combinations of atoms. Structural equation models are used in <ref type="bibr" target="#b9">[9]</ref> to track slowly time-varying networks, with application to contagion propagation. Kernels have seen widespread use in topology inference problems. One of these works is <ref type="bibr" target="#b10">[10]</ref> where kernels, chosen to best fit the data, model nonlinear relationships between nodes based on measurements at successive time instants. The authors present an auto-regressive framework that allows to track graph connectivity over time, proving useful in providing insights on brain connectivity. The multi-kernel approach in <ref type="bibr" target="#b11">[11]</ref> uses partial correlations to encode graph topology and p-norm regression to enhance performance. A review of the state of the art methods for graph topology inference is given in <ref type="bibr" target="#b12">[12]</ref>.</p><p>Encoding the graph topology with the shift matrix S is ubiquitous in graph signal models. This operator describes the interactions between entities and, by extension, it can be considered as a tool for representing relationships between data. Unlike existing meth-ods, this paper focuses on identifying the topology of a graph from streaming graph signals in a distributed and online manner. Notations: Normal font letters denote scalars, and boldface lowercase and uppercase letters stand for column vectors and matrices, respectively. Uppercase calligraphic letters denote sets. We denote by supp{A} the support of A, and by |N | the cardinality of N . λmax(•) stands for the largest eigenvalue of its matrix argument.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">CENTRALIZED PROBLEM FORMULATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Shift-invariant graph filtering</head><p>In this work, we focus on graph-based filtering framework. A graph filter takes a signal on graph x(i) as input, and outputs a signal y(i) given by y = Hx indexed by the same graph <ref type="bibr" target="#b13">[13]</ref>. Different forms have been considered for H in the literature. For example, the K-th order linear shift invariant graph filter is defined as <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b15">15]</ref>:</p><formula xml:id="formula_0">y(i) = K-1 k=0 h k S k x(i), i ≥ 0,<label>(1)</label></formula><p>with S a shift matrix and {h k } K-1 k=0 the filter coefficients. Observe that the previous model assumes the instantaneous diffusion of information, which may appear as a limitation of this model. A dynamical model was introduced to overcome this restriction <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b17">17]</ref>:</p><formula xml:id="formula_1">y(i) = K-1 k=0 h k S k x(i -k), i ≥ K -1.<label>(2)</label></formula><p>Assuming that the shift matrix S is known, the authors in <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b18">18]</ref> show how diffusion adaptation strategies can be applied to estimate the filter coefficients {h k } K-1 k=0 from streaming data {x(i), y(i)}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Network topology inference</head><p>One possible tool for causal network topology inference is the multivariate autoregressive model defined as:</p><formula xml:id="formula_2">y(i) = K-1 k=0 S k x(i -k) + v(i), i ≥ K -1<label>(3)</label></formula><p>where S k {s nm,k } in the above power series contains autoregressive coefficients that describe the influence of node m on node n at a distance of k hops, and v(i) is innovation noise. This model is helpful to asses Granger causality, where xm is said to Granger-cause x if knowledge of the former improves the prediction of the latter <ref type="bibr" target="#b19">[19]</ref>. Consider a connected network with N nodes. We assume that each node knows the set of its neighbors N with which it communicates. We however assume that the support of S is unknown. The problem is to estimate S from streaming data {x(i), y(i)}. We assume that signal x(i) is zero-mean wide-sense stationary, i.e., correlation sequence Rx(k) = E{x(i)x (i -k)} is a function of the time lag k only. The noise v(i) = [v1(i), . . . , vN (i)] is assumed zero-mean, i.i.d., with covariance Rv = diag{σv,n} N n=1 . Under these assumptions, estimating matrix S in (3) can be performed by solving the following mean-square-error problem:</p><formula xml:id="formula_3">S * = argmin S E y(i) - K-1 k=0 S k x(i -k) 2 + η Φ(S) subject to snm = 0 if m / ∈ Nn, n = 1, . . . , N<label>(4)</label></formula><formula xml:id="formula_4">x (i -2) m x m (i -1) p x p (i -2) n x n (i)</formula><p>s m p sm s nm Fig. <ref type="figure">1</ref>. Data paths toward node n. Links are depicted as directed edges in order to illustrate the flow of weighted data. In order to estimate its own snm, node n receives from its neighbour m the</p><formula xml:id="formula_5">(K -1)-element vector [xm(i-1), smpxp(i-2)+s m x (i-2)] .</formula><p>with η &gt; 0. The objective function in (4) includes a regularization term Φ(S) to account for some prior knowledge of S such as symmetry or sparsity. The constraints aim at forcing to zero the entries snm of S corresponding to node pairs (n, m) / ∈ E. Formulation ( <ref type="formula" target="#formula_3">4</ref>) is non-convex, due to the matrix polynomial. This leads any resolution algorithm to possibly converge toward a local minimum rather than a global one. Reference <ref type="bibr" target="#b17">[17]</ref> considers a similar problem in a centralized setting where the data across the network are collected and processed by a fusion center. In the next section, we shall show how the entries of S can be estimated in a distributed manner where nodes perform local computations and exchange information only with their neighbors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DISTRIBUTED SOLUTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem reformulation</head><p>The following strategy allows each node to locally estimate its own non-zero entries in S. According to (3), the output yn(i) at each node n is given by:</p><formula xml:id="formula_6">yn(i) = K-1 k=0 S k x(i -k) n + vn(i)<label>(5)</label></formula><p>This can be rewritten as:</p><formula xml:id="formula_7">yn(i) = xn(i) + s n [x(i -1)]m∈N n + . . . + s n [S K-2 x(i -K + 1)]m∈N n + vn(i),<label>(6)</label></formula><formula xml:id="formula_8">with sn = col{snm : m ∈ Nn}<label>(7)</label></formula><p>the |Nn| × 1 vector aggregating all non-zero entries of the n-th row of S. By subtracting xn(i) from yn(i), (6) can be expressed as:</p><formula xml:id="formula_9">ȳn(i) yn(i) -xn(i) = z n (i)sn + vn(i),<label>(8)</label></formula><p>where zn(i) is a |Nn| × 1 column vector defined as:</p><formula xml:id="formula_10">zn(i) = col K-2 k=0 S k x(i -k -1) m : m ∈ Nn .<label>(9)</label></formula><p>Reformulating <ref type="bibr">(6)</ref> in the form (8) has the following rationale. Consider node n. At time instant i, this node weights the incoming data from its neighbors with the corresponding entries of the n-th row of S. The same reasoning holds for any neighboring node m of n, as illustrated in Fig. <ref type="figure">1</ref>, which weights its own incoming data with entries of the m-th row of S. This means that two-hop data sent by node at time instant i-2, passing through node m at time instant i -1, and received by node n at time instant i, are successively weighted by s m and snm. Therefore, when estimating S, node n can simply focus on its own weights stored in the n-th row of S provided that every other node in the network does the same with its own weights. Reformulation ( <ref type="formula" target="#formula_8">7</ref>)-( <ref type="formula" target="#formula_10">9</ref>) comes along with several benefits compared to the centralized solution in <ref type="bibr" target="#b17">[17]</ref>. The main one concerns computational efficiency since only one-hop regressors zn(i) are considered at each node n. These one-hop transfers also translate into lower communication costs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Algorithm</head><p>We reformulate problem (4) by introducing the following aggregate cost function:</p><formula xml:id="formula_11">J(S) = N n=1 Jn(sn)<label>(10)</label></formula><p>where Jn(sn) denotes the mean-square-error cost at node n, namely,</p><formula xml:id="formula_12">Jn(sn) E ȳn(i) -z n (i)sn 2 + ηnΦ(sn).<label>(11)</label></formula><p>This form allows each node n to estimate its known entries sn of S, and to possibly account for some prior knowledge of S via Φ(sn).</p><p>For illustration purpose, we shall impose a symmetry constraint on S. Following the strategy in <ref type="bibr" target="#b20">[20]</ref>, we address this problem by considering the following local cost function:</p><formula xml:id="formula_13">Jn(sn) E ȳn(i) -z n (i)sn 2 + ηn m∈Nn (snm -smn) 2 (12)</formula><p>where parameter ηn &gt; 0 controls the relative importance of respecting the symmetry constraint on S <ref type="bibr" target="#b21">[21]</ref>. To minimize <ref type="bibr" target="#b12">(12)</ref>, we propose an incremental solution based on gradient descent, namely,</p><formula xml:id="formula_14">sn(i + 1) = sn(i) + µn[rz n y -Rz n sn(i) -ηnδ(i)]<label>(13)</label></formula><p>where δ(i) = sn(i) -sn(i) with sn = col{smn : m ∈ Nn}, µn a sufficiently small positive step-size, and:</p><formula xml:id="formula_15">Rz n E zn(i)z n (i) and rz ny E {zn(i)ȳn(i)} . (<label>14</label></formula><formula xml:id="formula_16">)</formula><p>Step-sizes µn in (13) must satisfy 0 &lt; µn &lt; 2/λmax(Rz n + ηnI) in order to guarantee stability in the mean under certain independence conditions on the data <ref type="bibr" target="#b22">[22]</ref>. However, since second-order moments are rarely available beforehand, a stochastic gradient descent strategy has to be devised. It consists of choosing instantaneous approximations such as:</p><formula xml:id="formula_17">Rz n ≈ zn(i)z n (i) and rz n y ≈ zn(i)ȳn(i). (<label>15</label></formula><formula xml:id="formula_18">)</formula><p>We used the adapt-then-penalize approach introduced in <ref type="bibr" target="#b23">[23]</ref> to implement the algorithm ( <ref type="formula" target="#formula_14">13</ref>) with <ref type="bibr" target="#b15">(15)</ref>. Setting n(i) ȳn(i)z n (i)sn(i), and introducing the intermediate estimate φ n (i), this strategy translates (13) into:</p><formula xml:id="formula_19">φ n (i + 1) = sn(i) + µn n(i)zn(i), (<label>16a</label></formula><formula xml:id="formula_20">)</formula><formula xml:id="formula_21">sn(i + 1) = φ n (i + 1) -µnηn[φ n (i + 1) -φ n (i + 1)] (16b)</formula><p>with φ n (i + 1) col [φ m (i + 1)] n : m ∈ Nn the column vector that aggregates all partial estimates related to node n in partial estimates of its neighboring nodes. The algorithm is synthesized hereafter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Local estimation of graph topology</head><p>For every node n: Inputs: Parameters µn and ηn Initialization: Randomly set all entries of sn(0) Algorithm: At each time instant i ≥ 1 Get weighted data S k-1 x(i -k) m∈Nn from neighbors Compute the regressor zn(i) with ( <ref type="formula" target="#formula_10">9</ref>) Update the local estimate sn with (16)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head><p>Multiple synthetic experiments were conducted with the goal of estimating sn at each node n using the proposed algorithm. The resulting estimates were then aggregated into an estimate of S. Next, this estimated matrix S was used in the context of spectral clustering for illustration purpose only. This particular application was chosen for its simplicity to illustrate how estimates obtained with our algorithm can provide useful insight into the topology of the graph.</p><p>Setting: An undirected community graph was generated using GSPBOX <ref type="bibr" target="#b24">[24]</ref>, with N = 32 nodes forming two communities. The adjacency matrix is shown in Fig. <ref type="figure" target="#fig_1">2</ref>(a). The graph shift operator S was chosen to be W /[1.1 • λmax(W )], the normalized weighted adjacency matrix. Weights wmn were set to exp(-γ cmcn 2 ), where cn are the coordinates of the 2D embedding for node n.</p><p>In order to illustrate the adaptation abilities of the method, we changed the shift operator during the experiment. Parameter γ was set to 0.1 during the first part of the experiment, and then changed to 0.6 for the second part. We considered an i.i.d. zeromean Gaussian signal x(i) with covariance matrix Rx chosen to be the solution of the Lyapunov equation SRxS -Rx + I = 0. Noise v(i) was also zero-mean Gaussian with covariance matrix Rv = diag{σ 2 v,n } N n=1 . Variances σ 2 v,n were generated from the uniform distribution U(0.1, 0.15). We set the filter order to K = 3. Output data y(i) were generated with model <ref type="bibr" target="#b3">(3)</ref>. We used a constant step-size µ for all nodes and parameters ηn were set to 300. For each experiment, estimates were averaged over 50 Monte-Carlo runs. Experiment 1: Learning algorithm ( <ref type="formula" target="#formula_19">16</ref>) was run to estimate S. The estimated mean squared deviation (MSD) learning curve, defined as:</p><formula xml:id="formula_22">MSD(i) = 1 N N n=1 E s * n -sn(i) 2<label>(17)</label></formula><p>is depicted in Fig. <ref type="figure" target="#fig_1">2(c</ref>). It shows that the algorithm converged monotonically to a reasonably low MSD, and succeeded in adapting to the change in S at time i = 50000. Experiment 2: Data were generated as in Experiment 1, with a new shift matrix S such that supp{S } ⊆ supp{S}. This allowed us to consider a new setting where, even if a node m is linked to a node n, i.e., (m, n) ∈ E, the output signal yn(i) at node n does not necessarily depend on the input signal xm(i-1) at node m via model (3). To design S , we selected a subset of nodes in one of the two communities of the initial community graph, and we divided their connection weights in S with all other nodes by 100. The resulting shift matrix S is depicted in Fig. <ref type="figure" target="#fig_1">2(b</ref>). In this way, we obtained two clusters according to the adjacency matrix A, and three clusters according to the shift matrix S . Learning algorithm <ref type="bibr" target="#b16">(16)</ref> was run to estimate S . The learning curve represented in Fig. <ref type="figure" target="#fig_1">2(c</ref>) shows that the algorithm converged to a reasonably low MSD, at a slower rate than in Experiment 1 possibly because of the larger number of clusters. To check this  assumption, we computed the eigen-decomposition of the estimated shift matrix to infer the number of clusters <ref type="bibr" target="#b25">[25]</ref>. It was numerically found to be equal to 3. Finally, we performed a spectral clustering of the nodes with a k-means algorithm based on the first k = 3 eigenvectors. The result depicted in Fig. <ref type="figure" target="#fig_2">3</ref> is in accordance with the experimental setup. Experiment 3: Comparisons were conducted with the centralized batch algorithm derived in <ref type="bibr" target="#b17">[17]</ref>, called benchmark algorithm (BA). We considered the same experimental setup as in Experiment 1, except that the number of nodes was set to N = 20. No regularization term Φ(•) was used. Since it deals with a more complex polynomial model than our algorithm, we simplified the BA model by setting its extra coefficients to 0. As BA is a batch-mode algorithm which estimates model parameters from training data, we successively set the size of the training set to T1 = 10 5 , T2 = 7.5 • 10 4 , and T3 = 5 • 10 4 samples. In each case, parameters of BA were set to achieve the best possible MSD. Next we set the step-sizes µn of our algorithm to achieve the same MSD at steady-state as BA. The results are presented in Fig. <ref type="figure" target="#fig_3">4</ref>. We observe that our algorithm was able to achieve the same MSD with half of the training samples. From a computational point of view, note that our method needs to process every sample only once, whereas the BA processes the whole training set many more times, depending on the chosen solver.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>In this paper, we proposed a distributed online strategy for topology identification based on graph signals. This framework allows to estimate a weighted adjacency matrix based on local one-hop computations. Since most of state-of-the-art topology inference algorithms work in a batch mode, this online approach represents a step forward. A second step forward is that our algorithm can adapt in an online way to changes in the graph shift operator.</p><p>For future work, multiple directions of research can be followed. A first one would be using other regularizers in the optimization problem, such as Lasso or group-Lasso in order to control the number of estimated connections. Another option would be to extend our method by considering a kernel-based framework in order to cope with nonlinear relationships between agents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) Adjacency matrix considered for the two experiments. (b) Shift matrix S used in Experiment 2. (c) MSD learning curves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Spectral clustering performed during Experiment 2. Two communities can be observed in the graph topology. At the graph signal level, three clusters are identified.</figDesc><graphic coords="5,175.92,72.22,127.55,118.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Comparison of our algorithm with BA for 3 training set sizes: T1 = 10 5 , T2 = 7.5 • 10 4 and T3 = 5 • 10 4 samples.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="83" to="98" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Algebraic Graph Theory</title>
		<author>
			<persName><forename type="first">N</forename><surname>Biggs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Covariance selection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="157" to="175" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sparse inverse covariance estimation with the graphical Lasso</title>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="432" to="441" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Network topology inference from spectral templates</title>
		<author>
			<persName><forename type="first">S</forename><surname>Segarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mateos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal and Information Processing over Networks</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="467" to="483" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Online graph learning from sequential data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vlaski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Maretic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nassif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Data Science Workshop</title>
		<meeting>IEEE Data Science Workshop<address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="190" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">How to learn a graph from smooth signals</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kalofolias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Artificial Intelligence and Statistics</title>
		<meeting>International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="920" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning parametric dictionaries for signals on graphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Thanou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">15</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dynamic structural equation models for tracking topologies of social networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Baingana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mateos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing</title>
		<meeting>IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive essing<address><addrLine>CAM-SAP; St. Martin, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="292" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Topology inference of directed graphs using nonlinear structural vector autoregressive models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Baingana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6513" to="6517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Going beyond linear dependencies to unveil connectivity of meshed grids</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP), Curac ¸ao, Dutch Antilles</title>
		<meeting>IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive essing (CAMSAP), Curac ¸ao, Dutch Antilles</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning graphs from data: A signal representation perspective</title>
		<author>
			<persName><forename type="first">Xiaowen</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dorina</forename><surname>Thanou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Rabbat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Frossard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.00848</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discrete signal processing on graphs: Graph filters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sandryhaila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M F</forename><surname>Moura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>IEEE International Conference on Acoustics, Speech and Signal essing<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="6163" to="6166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distributed signal processing via Chebyshev polynomial approximation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kressner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions Signal and Information Processing over Networks</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="736" to="751" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discrete signal processing on graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sandryhaila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M F</forename><surname>Moura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1644" to="1656" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distributed diffusion adaptation over graph signals</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nassif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>IEEE International Conference on Acoustics, Speech and Signal essing (ICASSP)<address><addrLine>Calgary, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4129" to="4133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Signal processing on graphs: Causal modeling of unstructured data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M F</forename><surname>Moura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2077" to="2092" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A preconditioned graph diffusion LMS for adaptive graph signal processing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nassif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Signal Processing (EUSIPCO)</title>
		<meeting>European Conference on Signal essing (EUSIPCO)<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Causal network inference via group sparse regularization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bolstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Van Veen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nowak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2628" to="2641" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Diffusion LMS for multitask problems with local linear equality constraints</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nassif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="4979" to="4993" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adaptive penalty-based distributed stochastic convex optimization</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Towfic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="3924" to="3938" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
		<title level="m">Adaptive Filters</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning by networked agents under partial information</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>IEEE International Conference on Acoustics, Speech and Signal essing (ICASSP)<address><addrLine>New Orleans, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3874" to="3878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">GSPBOX: A toolbox for signal processing on graphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Perraudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Paratte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kalofolias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Hammond</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-08">Aug. 2014</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Accelerated spectral clustering using graph filtering of random signals</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tremblay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Puy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Borgnat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>IEEE International Conference on Acoustics, Speech and Signal essing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4094" to="4098" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
