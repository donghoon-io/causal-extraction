<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interactive Causal Discovery in Knowledge Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Melanie</forename><surname>Munch</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR MIA-Paris</orgName>
								<orgName type="institution" key="instit1">AgroParisTech</orgName>
								<orgName type="institution" key="instit2">INRA</orgName>
								<orgName type="institution" key="instit3">Universit Paris-Saclay</orgName>
								<address>
									<postCode>75005</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Juliette</forename><surname>Dibie</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR MIA-Paris</orgName>
								<orgName type="institution" key="instit1">AgroParisTech</orgName>
								<orgName type="institution" key="instit2">INRA</orgName>
								<orgName type="institution" key="instit3">Universit Paris-Saclay</orgName>
								<address>
									<postCode>75005</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pierre-Henri</forename><surname>Wuillemin</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 7606</orgName>
								<orgName type="institution" key="instit1">Sorbonne University</orgName>
								<orgName type="institution" key="instit2">UPMC</orgName>
								<orgName type="institution" key="instit3">Univ Paris 06</orgName>
								<orgName type="institution" key="instit4">CNRS</orgName>
								<address>
									<postCode>LIP6 75005</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cristina</forename><surname>Manfredotti</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR MIA-Paris</orgName>
								<orgName type="institution" key="instit1">AgroParisTech</orgName>
								<orgName type="institution" key="instit2">INRA</orgName>
								<orgName type="institution" key="instit3">Universit Paris-Saclay</orgName>
								<address>
									<postCode>75005</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Interactive Causal Discovery in Knowledge Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Causal discovery</term>
					<term>Probabilistic Relational Models</term>
					<term>Knowledge Graph</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Being able to provide explanations about a domain is a hard task that requires from a probabilistic reasoning's viewpoint a causal knowledge about the domain variables, allowing one to predict how they can influence each others. However, causal discovery from data alone remains a challenging question. In this article, we introduce a way to tackle this question by presenting an interactive method to build a probabilistic relational model from any given relevant domain represented by a knowledge graph. Combining both ontological and expert knowledge, we define a set of constraints translated into a so-called relational schema. Such a relational schema can then be used to learn a probabilistic relational model, which allows causal discovery.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Probabilistic models such as Bayesian networks (BNs) are a good approach to represent complex domains, as they allow to express probabilistic links between variables. However, correlation does not imply causality, and as a consequence these models lack explainability. Yet it could be useful while studying a disease to identify the cause (the actual illness) and the consequence (the symptoms). Uncovering causal relations from data alone is a difficult task, and while previous works have presented the use of interventions to construct causal models <ref type="bibr" target="#b20">[21]</ref>, these interventions require to be able to change certain variables while keeping other constant, which is not always easily doable. For instance, to assess the impact of one's genotype and cigarettes smoking habits on lung cancer, we theoretically need to intervene on both of these criteria. If controlling whether one is smoking or not is possible (yet not really ethical), it is however impossible to directly control the genotype. As a consequence, for practical, ethical as well as economical reasons, direct interventions are often not available to learn causal relations. In this article, we present an interactive method that offers to introduce ontological and expert knowledge into the learning of a probabilistic model from a given knowledge graph (KG) <ref type="bibr" target="#b11">[12]</ref>, in order to discover causal knowledge. Indeed, causality helps to better explain a domain, as it allows to reason on higher levels: a complete causal graph can help to answer causal questions such as "If I take this drug, will I still be sick?"; or even answer counter factual questions as "Had I not taken this drug, would I still be sick?". We propose to achieve this by using probabilistic relational models (PRMs) <ref type="bibr" target="#b13">[14]</ref>. PRMs extend BNs with the notion of classes from the domain of relational databases, thus allowing a better representation between the different attributes. However, their learning can be tricky due to this specificity. Using the semantic and structural information contained in a KG, this learning can be greatly eased and, thus, be guided toward a learned model close to the reality. However, many different probabilistic models can be deduce from a same KG depending on the user (a domain expert) expectation. We present in this paper an interactive method to help such a user to build a probabilistic reasoning model from a KG able to answer his/her questions. The first section of this paper presents the background and state of the art, especially on PRM and causal discovery. The second section presents our approach to learn a PRM guided by the ontology and the user's knowledge. The third section presents an application of our method on a portion of DBPedia. The last section concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and State of the Art</head><p>The main idea of our method is to learn a probabilistic model under causal constraints given both by a user and the ontology. From the learned model we then are able to extract causal knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Probabilistic Models: BN and PRM</head><p>A BN is the representation of a joint probability over a set of random variables that uses a directed acyclic graph (DAG) to encode probabilistic relations between variables. Learning a BN requires learning both its structure and parameters. In our case, since learning is done under causal constraints, we need to express the conditional independence of this BN, which could give us new insight on the causality of this graph. Indeed, even if a found correlation between two variables of a BN does not prevail on the arc's orientation (explaining why causal discovery from data alone is difficult to achieve), some of these arcs also indicates conditional independence and are necessary to ensure the probabilistic information encoded in the BN. An essential graph (EG) <ref type="bibr" target="#b15">[16]</ref> is a semi-directed graph associated to a BN. They both share the same skeleton, but the EG's edges' orientation depends on the BN's Markov equivalence class. If the edge's orientation is the same for all the equivalent BNs, then it means that its orientation is necessary to keep the underlying probabilistic relations encoded in the graph: in this case, the edge is also oriented in the EG, and is called an essential arc. On the contrary, if the edge's orientation is not the same for all the equivalent BNs, then it means that its orientation can be both ways without changing the probabilistic relations, and it stays unoriented in the EG. Thus the EG expresses whether an orientation between two nodes can be reversed without modifying the probabilistic relations encoded in the graph: whenever the constraint given by an essential arc is violated, the conditional independence requirements are changed and the structure of the model itself has to be changed. With a BN learned under causal constraints such as in our method, the EG can then give us a new insight: if an arc is oriented, then it has to be kept if we want to conserve all the information we have provided during the learning.</p><p>However, our method also requires to use ontology's classes to group attributes by specific causal relations in order to learn them, and BNs lack such notion of modularity. As a consequence we turn to PRMs, that extend BNs' representation with the oriented-object notion of classes and instantiations. PRMs <ref type="bibr" target="#b13">[14]</ref> are defined by two parts: a high-level, qualitative description of the structure of the domain that defines the classes and their attributes (i.e. the relational schema RS as shown Fig. <ref type="figure" target="#fig_0">1 (a)</ref>), and a low-level, quantitative information given by the probability distribution over the different attributes (i.e. its relational model RM as shown in Fig. <ref type="figure" target="#fig_0">1 (b)</ref>). Classes in the RS are linked together by so-called relational slots, that indicates the direction of probabilistic links. For instance, Fig. <ref type="figure" target="#fig_0">1</ref> has two classes 1 and 2 with a relational slot toward Class 3: it means that probabilistic links can exist between the attributes of class 1 and 2 with class 3's, and that they have to be oriented from the attributes of class 1 and 2 towards those of class 3. Using the RS structural constraints, each class can then be learned like a BN (in our case, we use the classical statistical methods Greedy Hill Climbing). As a consequence, a system of instantiated classes linked together is equivalent to a bigger BN composed of small repeated BNs, and thus can be associated to an EG.</p><p>Numerous related works have established that using constraints while learning BNs brings more efficient and accurate results, for parameters learning <ref type="bibr" target="#b8">[9]</ref> or structure learning <ref type="bibr" target="#b9">[10]</ref>. In case of smaller databases, constraining the learning can also greatly improve the accuracy of the model <ref type="bibr" target="#b18">[19]</ref>. In this article we define structural constraints as an ordering between the different variables. The K2 algorithm <ref type="bibr" target="#b6">[7]</ref>, for instance, requires a complete ordering of the attributes before learning a BN, allowing the introduction of precedence constraints between the attributes. This particular algorithm needs a complete knowledge over all the different attributes precedences; however problems of learning with partial order have also been tackled <ref type="bibr" target="#b19">[20]</ref>. In our case we will likewise transcribe incomplete knowledge as partial structural organization for the PRM's RS in order to discover new causal relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Causal Discovery</head><p>Causal models are DAGs allowing one to express causality between its different attributes <ref type="bibr" target="#b20">[21]</ref>. Their construction is complex and requires interventions or controlled randomized interventions, which are often difficult or impossible to test. As a consequence the task of discovering causal relations using data, known as causal discovery, has been researched in various fields over the last few years. There are two types of methods for structure learning from data: independencebased ones, such as the PC algorithm <ref type="bibr" target="#b21">[22]</ref>, and score-based ones, such as Greedy Equivalent Search (GES) <ref type="bibr" target="#b5">[6]</ref>. Usually independence-based methods give a better outlook on causality between the attributes by finding the "true" arc orientation, while the score-based ones offer a structure that maximizes the likelihood considering the data. Finally, other algorithms such as MIIC <ref type="bibr" target="#b22">[23]</ref> use independencebased algorithms to obtain information considered as partially causal and thus allowing to discover latent variables. In this article we propose to explore if combining ontological and user's knowledge with BN learning score-based algorithms allows causal discovery. Other works have already proposed the use of EG: <ref type="bibr" target="#b14">[15]</ref> for instance proposes two optimal strategies for suggesting interventions in order to learn causal models with score-based methods and the EG. Integrating knowledge in the learning has also been considered: <ref type="bibr" target="#b7">[8]</ref> uses ontological causal knowledge to learn a BN and discover new causal relations with the EG; <ref type="bibr" target="#b3">[4]</ref> offers a method to iterative causal discovery by integrating knowledge from beforehand designed ontologies to causal BN learning; <ref type="bibr" target="#b1">[2]</ref> proposes two new scores for score-based algorithms using experts knowledge and their reliability; and <ref type="bibr" target="#b4">[5]</ref> presents a tool combining ontological and causal knowledge in order to generate different argument and counterarguments in favor of different facts by defining enriched causal knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Ontology and Probabilistic Models</head><p>Using ontological knowledge in order to build probabilistic models has already been presented in numerous works. <ref type="bibr" target="#b12">[13]</ref> uses the structure of an ontology to build and modify a BN by addressing three main tasks: the determination of the relevant variables, the determination of relevant properties and the computing of the probabilities. The learned model can then be used to reason on the domain. <ref type="bibr" target="#b0">[1]</ref> presents a method for autonomic decision making combining BNs and ontologies, using the framework BayesOWL <ref type="bibr" target="#b10">[11]</ref>. This framework allow the expression of a BN using the OWL standardization. More precisely, it offers a set of rules aiming to automate the translation from an ontology to a BN. <ref type="bibr" target="#b2">[3]</ref> presents a method to generate Object Oriented Bayesian Networks from ontologies using a set of rules they have defined. While PRM offers a way to express and consider the expert knowledge in learning, to the best of our knowledge no causality learning method that combines ontological and user's knowledge has been proposed yet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Causal Discovery Driven by an Ontology</head><p>In this article we present an interactive method aiming to build a RS from a KG relying on the ontological and user's knowledge. This RS presents the different PRM's classes, relational slots and attributes, and is used to learn a PRM under causal constraints, allowing the deduction of causal knowledge. This method is split into three parts: (1) building a first RS from the ontological knowledge;</p><p>(2) helping the user improving the proposed RS;</p><p>(3) learning a PRM from the RS from which causal knowledge can be deduced. In a previous work <ref type="bibr" target="#b16">[17]</ref> we present a method to help the user to build the RS but without fully exploiting the ontological knowledge. In this article, we focus on the first and second parts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Relevant KGs</head><p>In theory, a PRM can be learned from any knowledge graph. However, not all are interesting to do so and some selection criteria (SC) must be fulfilled in order to learn a relevant probabilistic reasoning model. As an illustration we define a simple ontology dedicated to an university representation (Fig. <ref type="figure" target="#fig_1">2</ref>). It is composed of three main classes: the University class, the Student class and the Course class. An university is defined by its name and its fees; a student is defined by his/her name, sex, social standing, mean note and his/her subject of interest; a course is defined by its subject and its difficulty.</p><p>SC1. The domain the KG is dedicated to must contain causal information to be deduced. Our model can be used to simply discover simple probabilistic relations. However, it best shines when it encompasses causal knowledge, as it allows a far better explainability of the represented domain. Therefore, the user must have a causal question or at least an idea to search for causality information. In our university example, one might be interested in studying the influence of a student's social standing with his/her choice of courses and university. SC2. The KG contains datatype properties (DPs) whose values can be discretized. The PRM's learning is based on classical BNs learning methods, which uses statistical analysis to learn the probabilistic relations. Therefore, our method needs data, which is given by DPs: they define our model's attributes. As a consequence, they must be relevant for the domain and their values discretizable for the learning: a DP indicating a student's ID is not interesting, as it is different for each student. SC3. The classes of the KG are instantiated enough and there are not too many missing DPs. As stated before, the learning is based on statistical methods. As a consequence the studied KG must have enough instantiations in order to study their variability. Since all instances of the same class are compared together using their DPs, each instance's missing DP is considered as a missing value: as a consequence, each missing DP can decrease the precision of the model. For example, a single student's instance would not be enough to study the relations between a student and his/her courses; likewise, if we have multiple student's instances, but only one of them has a DP about his/her social standing, then we will not be able to study the influence of social standing over other parameters.</p><p>In order to deal with the causality, we consider in this article that the KG is complete and verified: all important variables are present (no confounding factor possible), and the distribution of the different values is balanced (none is arbitrarily prominent over others). Confounding factors occurs when a correlation is found between two attributes, but with no direct causal link, and that the explanatory variable is missing. A classical example is the study of the correlation between one's reading ability and shoes' size: while both are indeed correlated, it is arguably not due to the fact that one causes the other. Indeed, both are in reality explained by one's age: the older we are, the better we can read and the bigger our shoes are. As a consequence, confounding factors can lead to false causal reasoning, and must be avoided. In the rest of this article, we will consider that it is possible to learn from our data the true causal model of the domain (or at least a part of it). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Interactive Building of a RS</head><p>From the ontological knowledge we automatically generate a first draft of a RS. The aim of this generation is to give the user a good preliminary overview of the KG in order to help the user building a probabilistic reasoning model. This transformation is done in three steps: ( In a regular situation, we would then be able to study the probabilistic relations between a teacher and a student, or a teacher and an university. However, if the student instances are not numerous enough to learn, then the Student RS class has to be removed, leaving the Teacher RS class isolated. As a consequence, it would not be possible anymore to study the probabilistic relations between a teacher and a university: the Teacher RS class has also to be removed. SR3 The attributes must be useful. Since the learning of the PRM is based on statistical methods, we need our data to be useful: for instance, too many missing data, values that do not repeat (such as for instance an ID, different for each instance) or that are not different (in our example, if we study the same university, the name of the so-called university is useless) are to be removed from the RS. In our example, if we had 50 students but only 3 of them had a DP about their social standing, then the corresponding attribute cannot be used to learn and is removed from the RS. SR4 The symmetric relational slots are deleted. The PRM does not support cyclic relations, symmetric OPs cannot therefore be kept: as a consequence one of the corresponding relational slot in the RS must be discarded. In a first time, we automatically keep if possible the relational slot that corresponds to the most instantiated OP; if not, we randomly select one.</p><p>Once defined the RS is presented to the user who can intervene on different points. These user modifications (UMs) also directly modifies the RS: UM1. The choice of attributes. Despite being instantiated enough, some selected DPs may be irrelevant according to the user, and thus their corresponding attributes need to be removed. UM2. The choice of relational slots. The orientation of the relational slots has a great influence on the causal learning: if there is a relational slot from a class A to a class B, then all probabilistic links learned between attributes of class A and B have to be identically oriented. Broadly speaking it means that class A's attributes can explain class's B attributes, but not the contrary. However, not all ontology's OP are causal by default: as a consequence we need the user to validate when possible the orientation of the relational slots, or reverse it to express causality. He is also able to remove or add relations slots between classes if necessary. UM3. The choice of RS classes. The orientation of the relational slots have a great influence over the learning of the causal knowledge. However, some RS classes' attributes might be intricate, meaning that two RS classes can be both explaining of and explained by a same other RS class. In our example, we can consider the relation between a student and his/her courses: the student's interest might explain his/her courses' subject; however, the courses' difficulty might explain the student's note. Fig. <ref type="figure" target="#fig_2">3</ref> (a) shows a first RS, in which both the interest and the note can explain the course's subject and difficulty. This is inconsistent with the idea that, on the contrary, the course's difficulty should explained the student's note. As a consequence, we offer the user a tool to split the RS classes in order to reflect this causal information. In Fig. <ref type="figure" target="#fig_2">3</ref> (b), the Student RS class has been split in two: a first RS class above with the interest attribute that can still explain the course's attributes, and a second below with the note attribute that can be explained by both the student's interest and the course's subject and difficulty. UM4. The choice of attributes. As mentioned before the user can choose whether a DP can be kept or not in the RS. By default, a DP is directly translated into an attribute. However, when multiple identical DPs are involved it requires an intervention of the user: it can be the case when a single instance has several time the same DP (such as a Student who has multiple interests), or when a same RS class's instance can be explained (through a relational slot) by multiple instances of another RS class (e.g. a single course instance can be attended by many students). Here, the repeated DPs cannot be distinguished given the ontology: in these particular cases, we need to aggregate the given DP in order to allow a statistical learning. The aggregation can take many forms, depending on what the user wants (e.g. the mean value, the maximum value, if a certain value is present or not). For example, if we consider that a single course can have a variable number of different students, then it is not possible to learn a statistical model: some course will have 5 students, other 30, 12... No comparison is possible, and even if two courses had the same number of students, there is no way to distinguish one from another. As a consequence we need to transform these possible multiple attributes in the RS in an unique one, which is what aggregation allows us to do. For instance, instead of considering all the student's notes, we calculate the mean value: each course now have one attribute for the note, whether they had 1 or 100 students in the beginning.</p><p>Aggregator must be defined by the user. If no aggregator can be found to characterize an aggregated attribute corresponding to a group of DPs, then this group of corresponding DPs attributes must be removed from the RS. UM5. The choice of instances in the KG. Sometimes the user wants to be able to study only a particular part of the KG (e.g. students that are registered in at least one course). This UM allows some conditions to be defined in order to select the instances that are consistent with the building of the RS: if we have a relational slot from the University RS class to the Student RS class, then all student instances in the KG must be registered in an university.</p><p>Once the user has done all the modifications he deemed necessary, we can learn the probabilistic model using the RS. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Student</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Model Validation</head><p>The RS has been defined using constraints from both the ontological and the user's knowledge. As a consequence the PRM learned using this RS has been learned under causal constraints, and then can be used to deduce causal knowledge. However, the RS are not good enough to discover new causal relations. Since it is easier for a user to criticize when confronted to mistakes, we have devised a method to validate the learned model <ref type="bibr" target="#b16">[17]</ref>. First, the inter RS classes relations are presented to the user. Those relations flow directly from the relational slots defined during the RS building: their orientation has been fixed either by the ontology or by the user. They are thus easier to criticize for the user than if they have been built from scratch: if their orientation contradicts a piece of knowledge the user has about the domain, then the RS has been badly constructed, and has to be reconsidered. Then, the intra RS classes relations are presented. Their orientation is not ruled by the RS, so in order to criticize them we need to look at the EG. If this arc is not an essential arc, then it can be reversed without consequences; however, if it is not, then the RS has to be modified in order to reflect this change. Finally, if the user challenges a learned relation that should not exist (for instance, between two attributes he knows are independent), then it means that the KG is not balanced enough: for example, scientists that might have tested too much of an hypothesis and not enough of an other. In this case, we cannot continue, as our data is not robust enough to deduce causality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Causal Knowledge Discovery</head><p>Once the RS has been built using the ontological and user's knowledge (Sec. 3.2) and the learned model validated by the user (Sec. 3.3), we can use it to discover causal knowledge. Causal knowledge can be validated by three means:</p><p>-the Ontology: if a relation is learned between two attributes of two different RS classes defined from the ontology (e.g. between a student and his/her university), then the orientation has been constrained by the causal information given by the ontology. -the User: During the RS's interactive building, the user was able to inject causal knowledge with UMs. If a relation is learned between two attributes from two RS classes (or whose relational slot has been) defined by the user (e.g. between the classes Student 1 and Course in Fig. <ref type="figure" target="#fig_2">3</ref>), then the learning has been constraint by the user who validates the causal knowledge discovery. -the EG: Since the model has been learned under causal constraints given by the ontology and the user, the EG's essential arcs can give causal information. Indeed, an oriented arc in the EG is oriented for all of Markov's equivalence's classes of the learned BN, meaning that, if our model has been learned under right conditions (i.e. complete data set, good given constraints), then it is highly probably causal, allowing the discovery of causal knowledge between attributes of a same RS class (e.g. a student's Interest and his/her Note).</p><p>The interest of this discovery has two goals: first, it can help a user validate his/her hypothesis on a domain; second, it can suggest new experiments to conduct to test new hypothesis. For instance, using this method, <ref type="bibr" target="#b17">[18]</ref> suggests a strong link between plausible control variables and some parameters of the studied cheese, whereas it also indicates that some other experiments had to be conducted to understand the whole process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Application on DBpedia</head><p>We illustrate our method with a part of the DBpedia<ref type="foot" target="#foot_0">foot_0</ref> KG dedicated to writers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset Presentation</head><p>The DBpedia database collects and organize all available information from the Wikipedia<ref type="foot" target="#foot_1">foot_1</ref> encyclopedia. Since it describes 4.58 things (including persons, places, ...), we have decided for our test to only study a small part of it, on a subject simple enough where we could easily play the role of an expert. As a consequence, we have restrained our study to a much smaller KG<ref type="foot" target="#foot_2">foot_2</ref> , dedicated to writers. During this first pre-selection, we have selected four classes to represent our domain: Writer, University, Country and Book. The selected KG is presented in Fig. <ref type="figure" target="#fig_3">4</ref>. Considering all possible DPs for every instances of these classes, and also all OPs between them, we have a dataset of 2,966,073 triples. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Interactive Construction of the RS</head><p>First, we translate all the selected classes as new RS's classes, and all DPs as new RS's attributes. In our case, there is no symmetric OPs, so we keep the original ones present in DBpedia (as depicted in Fig. <ref type="figure" target="#fig_3">4</ref>) to define the direction of the relational slots. By applying the selection rule SR3, a first automatic selection removes all attributes that correspond to DPs that are not represented enough: for instance, over the 32,511 instances of writers, only 12,188 have the DP occupation. This selection is coupled with the expert selection using UM1 that removes attributes that correspond to uninteresting DPs. We also apply UM5, which filters some instances: for example, in our case, we want to study writers that have written books. However, on the whole database, only 6,028 writers instances are linked to at least one book instance. As a consequence, we remove authors with no books since they are out of the scope of our study. Then as a user we apply UM2. Since we consider that a country can explains the values of an university's variables, and not the contrary: we reverse the relational slot corresponding to the OP dbp:country. One country can have multiple universities, but one university can only have one country: reversing the relational slot removes the aggregation of universities and creates a simple linear relation, since now one university can be explained by at most one country. Moreover, we want to study the possible influence of an university over a writer's work, so we need to reverse the relational slot corresponding to the OP dbp:almaMatter. Since a person can register in one or more universities, then his/her attributes can be explained by a combination of his/her universities'. We apply UM4 and create an aggregation from universities to writers. For each writer, we create two aggregated variables: the highest rank and the highest endowment among all of the universities he/she went to. But doing so break the relation between the Country RS class and the Writer RS class, since they are linked trough the University RS class. The only way to keep a relational slot between the country and the writer is to also aggregate the country's attributes. However, the only available country's attribute is the label, and there is no way of intelligently ag-gregating it. As a consequence, with the aggregation of universities, we loose the information about countries for the writers and their books. In the end thanks to the rule SR3, only interesting attributes which have no missing values and are easily discretizable are kept. For each class, we keep the following attributes:</p><p>-dbo:Country: each country is only represented by its label. Since the majority of our writers are Anglo-Saxon, we distinguish five categories: USA, Canada, Great Britain, Europa and Asia. -dbo:University: each university is represented by its Academic Ranking of World Universities (ARWU), and its endowment. The endowment is split by its median value. The ARWU ranking is split between the first hundred universities, and the rest. -dbo:Writer: each writer is represented by his/her gender, his/her genre and his/her birth date. Genders are split between male and female, while genres are split between fiction and non-fiction. Birth dates are separated by their median, 1950. Two aggregated attributes have been also added: the highest rank among all universities he/she went to, and the highest endowment he/she went to, with the same discretization used before. -dbo:Book: each book is represented by its number of pages and its release date. The number of pages is split between books with 250 pages or less and the others; the release date attribute is split between books published before 1980 and those published after.</p><p>In the end we have drastically dropped the number of instances to 6,908 triples and 185 writers. The final RS defined both by ontological and user's knowledge is presented in Fig. <ref type="figure" target="#fig_4">6</ref>. The direction of relational slots indicates how the considered variables can influence each other: for instance, a writer's genre or highest university rank can influence the number of pages of his/her books.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Country</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Label</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>University</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARWU rank Endowment</head><p>Writer Gender Genre Birthdate</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Book</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Pages Release Date</head><p>Aggregator Max Min Fig. <ref type="figure">5</ref>. Relation Schema defined from ontological and user's knowledge. Since a writer can have multiple universities, we introduced an aggregation between the two classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Using the dataset and the RS, it is now possible to learn a PRM and study its EG (respectfully Fig. <ref type="figure" target="#fig_4">6</ref> (a) and (b)). We apply the discretization presented in Sec. <ref type="bibr" target="#b3">4</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Discussion</head><p>Despite not being experts of the domain, most of our results appears to agree with common sense. For instance, it seems logical that an university's ARWU rank and its endowment are correlated, itself explained by its university's country. However our KG's representativeness casts doubts on other results. For instance, we find that a book's release date can be explained by both the highest rank of the university its author went to, and its author's birth date (the joint probability is presented in Table. 1). Basically, authors born before 1950 tend to publish more before 1980 when they are from a top-tiers school. On an other hand, youngest authors tend to publish after 1980, which at first seems logical: writers born after 1980 would hardly be able to publish books prior to their birth. However, we have no instance in our dataset of books published before 1980 written by persons born after 1950, which explain why we learned this relation. This underlines the importance of a complete and verified KG: if our dataset is representative, then we acknowledge the fact youngest authors cannot publish before 1980. On another hand, if our dataset is not representative, then it means that our learned relation cannot be causal, as we are missing arguments. In the end, the main point of this example is to illustrate our method:</p><p>1. The RS construction from the KG is simplified thanks to selection rules that preemptively remove RS classes, attributes... that are not learnable.</p><p>In our case, numerous attributes corresponding to DPs with not enough instantiations were removed (such as dbp:occupation for the writer). 2. The user introduced causal knowledge in the RS with UMs: UM1 to remove attributes irrelevant for the problem (e.g. the wikipedia page ID), UM2 to reverse relational slot to express causality (e.g. between a writer and his/her universities), UM4 to formulate aggregations (e.g. since writers had a variable number of universities, we had to aggregate the universities' attributes), and UM5 to remove instances that did not have certain properties (e.g. all writers with no book or no birth date). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The high (a) and low (b) level structures of a PRM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Excerpt of a KG about students and universities</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Example of a RS class splitting in a PRM. The Student RS class of (a) has been split in two RS classes Student 1 and Student 2 in (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Schema of the used excerpt of DBPedia with the DPs kept in the final RS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. (a) PRM learned. Plain arrows indicates probabilistic relations. (b) Associated EG. Plain arrows indicates essential arcs, unoriented ones indicate the edges. Dashed arrows only serve as a visual cue to indicate aggregation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1) All ontology's classes become RS classes. With our university ontology we thus have three RS classes, University, Student and Course. (2) All ontology's DPs become attributes in the RS associated to their respective RS classes. In our example the University RS class owns two attributes, Name and Fees. (3) All ontology's object properties (OPs) become relational slots in the RS. In our example, the University RS class has two relational slots: one toward the Student RS class, and one toward the Course RS class. Before being presented to the user, we apply selection rules (SR) based on the selection criteria presented above. These rules directly modifies the RS: SR1. The RS classes with too few instances are removed. SR2. The isolated RS classes are deleted. If by applying SR1 we break a path between two others RS classes, leading to the isolation of one of them (meaning there is no other relational slots linking this RS class), then the isolated RS class is also removed. We can illustrate this by adding a new OP in our example, hasForTeacher, taking for domain the Student class and for range a new Teacher class.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>.2, and consider any missing data as a new category "Unknown".Inter RS classes relations. We have three inter RS classes relations: one between Label and Endowment, one between the highest ARWU rank and the book's release date, and another one between the author's birth date and the book's release date. Since the RS classes was built from the ontology, and the relational slot's direction decided by the user, then we have a causal discovery validated by both the ontological and user's knowledge. Intra RS class relations. Three relations are oriented in the EG (see Fig.1(b)), but only one is an intra RS class relation: from Release Date toward Number of Pages. Thus, the causality of this relation is validated by the EG. There is another intra RS class relation (between ARWU Rank and the Endowment), but it is not oriented in the EG: the given RS and dataset are not enough to assume the causality between those two attributes.</figDesc><table><row><cell cols="2">Country</cell><cell></cell></row><row><cell></cell><cell>Label</cell><cell></cell></row><row><cell cols="2">University</cell><cell></cell></row><row><cell>ARWU rank</cell><cell cols="2">Endowment</cell></row><row><cell>Min</cell><cell></cell><cell>Max</cell></row><row><cell></cell><cell>Writer</cell><cell></cell></row><row><cell>Birthdate</cell><cell>Genre</cell><cell>Gender</cell></row><row><cell></cell><cell>Book</cell><cell></cell></row><row><cell>Release Date</cell><cell cols="2">Number of Pages</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Joint probability of the attribute releaseDate depending on the attributes writer.birthDate and writer.min arwu. The low values 0.01 are an artefact of learning, and indicates that these combinations are not encountered in the dataset.</figDesc><table><row><cell cols="2">writer.birthDate writer.min arwu</cell><cell cols="2">releaseDate</cell></row><row><cell></cell><cell></cell><cell cols="2">before 1980 after 1980</cell></row><row><cell>before 1950</cell><cell>100 or less</cell><cell>0.58</cell><cell>0.42</cell></row><row><cell>after 1950</cell><cell>100 or less</cell><cell>0.01</cell><cell>0.99</cell></row><row><cell>before 1950</cell><cell>101 or more</cell><cell>0.44</cell><cell>0.56</cell></row><row><cell>after 1950</cell><cell>101 or more</cell><cell>0.01</cell><cell>0.99</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>https://wiki.dbpedia.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>https://www.wikipedia.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>https://bit.ly/2X0eeCw</p></note>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>UM3 was not used here. However, should we have had a variable about an author's success, it would then have been possible to study the impact of an author's books on his/her success. To do so, we would have split the author RS class in two, to see how an aggregation of the books' attributes would have influenced this variable. Fig. <ref type="figure">7</ref> presents the corresponding RS: we can see that since it is the same RS class split in two, both the writer's other attributes (genre, gender, birth date) and the aggregated book attributes (mean number of pages, oldest release date) can explain the writer's success.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>While causal knowledge can be useful for explaining a domain, causal discovery is a hard task, especially from data alone. In this paper, we present an interactive method aiming to allow a user to combine his/her knowledge with that of a KG in order to learn a probabilistic model from a KG able to help him/her uncover new causal explanations. The main idea is to combine the knowledge of both of these sources in order to interactively build a RS able to guide and causally constraint the learning of a PRM. This method is split into three parts: (1) automatic design of a first RS from the KG; (2) modification of this RS by the user;</p><p>(3) learning of the PRM using the RS. This method is interactive (i.e. the user can interact with the algorithm to give his/her inputs and influence the learning) and generic (i.e. it can be applied on any KG as long as it is relevant for causal discovery). It is also dependant on the quality of the dataset: it has to be checked (i.e. no errors) and complete (i.e. no missing attributes or incomplete data). Our future work will focus on the explanation of the discovered causal relations in order to help the user to improve his/her knowledge (e.g. by enriching the ontology) and clarify his/her reasoning needs.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Autonomie decision making based on bayesian networks and ontologies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aguilar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-07">07 2016</date>
			<biblScope unit="page" from="3825" to="3832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploiting experts knowledge for structure learning of bayesian networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Amirkhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rahmati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J F</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hommersom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2154" to="2170" />
			<date type="published" when="2017-11">Nov 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Ontology-based generation of object oriented bayesian networks</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Ishak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ben Amor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2011-01">01 2011</date>
			<biblScope unit="volume">818</biblScope>
			<biblScope unit="page" from="9" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Integrating ontological knowledge for iterative causal discovery and visualization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ben Messaoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Leray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ben Amor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symbolic and Quantitative Approaches to Reasoning with Uncertainty</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Sossai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Chemello</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="168" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Arguments using ontological and causal knowledge</title>
		<author>
			<persName><forename type="first">P</forename><surname>Besnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cordier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Moinard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Information and Knowledge Systems -8th International Symposium, FoIKS</title>
		<meeting><address><addrLine>Bordeaux, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-03-03">2014. March 3-7, 2014. 2014</date>
			<biblScope unit="page" from="79" to="96" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Optimal structure identification with greedy search</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="507" to="554" />
			<date type="published" when="2003-03">Mar 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A bayesian method for the induction of probabilistic networks from data</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Herskovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="309" to="347" />
			<date type="published" when="1992-10">Oct 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>uti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gini</surname></persName>
		</author>
		<title level="m">Creating causal representations from ontologies and bayesian networks</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving bayesian network parameter learning using constraints</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>De Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">19th International Conference on Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008-12">2008. Dec 2008</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Structure learning of bayesian networks using constraints</title>
		<author>
			<persName><forename type="first">C</forename><surname>De Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
	<note>ICML &apos;09</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
		<title level="m">BayesOWL: Uncertainty Modeling in Semantic Web Ontologies</title>
		<meeting><address><addrLine>Berlin Heidelberg, Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="3" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Towards a definition of knowledge graphs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ehrlinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2016-09">09 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting experts knowledge for structure learning of bayesian networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fenz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="73" to="88" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning probabilistic relational models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pfeffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Sixteenth International Joint Conference on Artificial Intelligence<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-08-06">July 31 -August 6, 1999. 1999</date>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="1300" to="1309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Two optimal strategies for active learning of causal models from interventional data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bhlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Approx. Reasoning</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="926" to="939" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bayesian model averaging and model selection for markov equivalence classes of acyclic digraphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Madigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Perlman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics-Theory and Methods</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2493" to="2519" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards interactive causal relation discovery driven by an ontology</title>
		<author>
			<persName><forename type="first">M</forename><surname>Munch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dibie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wuillemin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Manfredotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second International Florida Artificial Intelligence Research Society Conference</title>
		<meeting>the Thirty-Second International Florida Artificial Intelligence Research Society Conference<address><addrLine>Sarasota, Florida, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">May 19-22 2019</date>
			<biblScope unit="page" from="504" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Identifying control parameters in cheese fabrication process using precedence constraints</title>
		<author>
			<persName><forename type="first">M</forename><surname>Munch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wuillemin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dibie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Manfredotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Allard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Buchin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Guichard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Discovery Science -21st International Conference</title>
		<meeting><address><addrLine>Limassol, Cyprus</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10-29">2018. October 29-31, 2018. 2018</date>
			<biblScope unit="page" from="421" to="434" />
		</imprint>
	</monogr>
	<note>DS</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning probabilistic relational models using an ontology of transformation processes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Munch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Wuillemin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Manfredotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dibie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dervaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">On the Move to Meaningful Internet Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="198" to="215" />
		</imprint>
	</monogr>
	<note>OTM 2017 Conferences</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Finding optimal bayesian networks using precedence constraints</title>
		<author>
			<persName><forename type="first">P</forename><surname>Parviainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koivisto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1387" to="1415" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Causality: Models, Reasoning and Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<title level="m">Causation, Prediction, and Search</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning causal networks with latent variables from multivariate information in genomic data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Verny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Affeldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Isambert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">1005662</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
