<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Causal Attention for Interpretable and Generalizable Graph Classification</title>
				<funder ref="#_zTSAj6U">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
				<funder>
					<orgName type="full">CCCD Key Lab of Ministry of Culture and Tourism</orgName>
				</funder>
				<funder ref="#_JpGz355 #_xNgf5Ye">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2022-06-13">13 Jun 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yongduo</forename><surname>Sui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Causal Attention for Interpretable and Generalizable Graph Classification. In</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of Science and Technology of China Jiancan Wu</orgName>
								<orgName type="institution" key="instit3">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit4">University of Science and Technology of China Tat-Seng Chua</orgName>
								<orgName type="institution" key="instit5">National University of Singapore</orgName>
								<address>
									<addrLine>KDD &apos;22 August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Causal Attention for Interpretable and Generalizable Graph Classification. In</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of Science and Technology of China Jiancan Wu</orgName>
								<orgName type="institution" key="instit3">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit4">University of Science and Technology of China Tat-Seng Chua</orgName>
								<orgName type="institution" key="instit5">National University of Singapore</orgName>
								<address>
									<addrLine>KDD &apos;22 August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
							<email>xiangwang1223@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Causal Attention for Interpretable and Generalizable Graph Classification. In</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of Science and Technology of China Jiancan Wu</orgName>
								<orgName type="institution" key="instit3">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit4">University of Science and Technology of China Tat-Seng Chua</orgName>
								<orgName type="institution" key="instit5">National University of Singapore</orgName>
								<address>
									<addrLine>KDD &apos;22 August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Causal Attention for Interpretable and Generalizable Graph Classification. In</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of Science and Technology of China Jiancan Wu</orgName>
								<orgName type="institution" key="instit3">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit4">University of Science and Technology of China Tat-Seng Chua</orgName>
								<orgName type="institution" key="instit5">National University of Singapore</orgName>
								<address>
									<addrLine>KDD &apos;22 August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Causal Attention for Interpretable and Generalizable Graph Classification. In</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of Science and Technology of China Jiancan Wu</orgName>
								<orgName type="institution" key="instit3">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit4">University of Science and Technology of China Tat-Seng Chua</orgName>
								<orgName type="institution" key="instit5">National University of Singapore</orgName>
								<address>
									<addrLine>KDD &apos;22 August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Min</forename><surname>Lin</surname></persName>
							<email>linmin@sea.com</email>
							<affiliation key="aff0">
								<orgName type="department">Causal Attention for Interpretable and Generalizable Graph Classification. In</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of Science and Technology of China Jiancan Wu</orgName>
								<orgName type="institution" key="instit3">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit4">University of Science and Technology of China Tat-Seng Chua</orgName>
								<orgName type="institution" key="instit5">National University of Singapore</orgName>
								<address>
									<addrLine>KDD &apos;22 August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Causal Attention for Interpretable and Generalizable Graph Classification. In</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of Science and Technology of China Jiancan Wu</orgName>
								<orgName type="institution" key="instit3">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit4">University of Science and Technology of China Tat-Seng Chua</orgName>
								<orgName type="institution" key="instit5">National University of Singapore</orgName>
								<address>
									<addrLine>KDD &apos;22 August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiancan</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Causal Attention for Interpretable and Generalizable Graph Classification. In</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of Science and Technology of China Jiancan Wu</orgName>
								<orgName type="institution" key="instit3">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit4">University of Science and Technology of China Tat-Seng Chua</orgName>
								<orgName type="institution" key="instit5">National University of Singapore</orgName>
								<address>
									<addrLine>KDD &apos;22 August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
							<email>xiangnanhe@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Causal Attention for Interpretable and Generalizable Graph Classification. In</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of Science and Technology of China Jiancan Wu</orgName>
								<orgName type="institution" key="instit3">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit4">University of Science and Technology of China Tat-Seng Chua</orgName>
								<orgName type="institution" key="instit5">National University of Singapore</orgName>
								<address>
									<addrLine>KDD &apos;22 August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tat- Seng</forename><forename type="middle">2022</forename><surname>Chua</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Causal Attention for Interpretable and Generalizable Graph Classification. In</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of Science and Technology of China Jiancan Wu</orgName>
								<orgName type="institution" key="instit3">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit4">University of Science and Technology of China Tat-Seng Chua</orgName>
								<orgName type="institution" key="instit5">National University of Singapore</orgName>
								<address>
									<addrLine>KDD &apos;22 August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Causal Attention for Interpretable and Generalizable Graph Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-06-13">13 Jun 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3534678.3539366</idno>
					<idno type="arXiv">arXiv:2112.15089v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graph Neural Networks</term>
					<term>Graph Classification</term>
					<term>Causal Intervention</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In graph classification, attention-and pooling-based graph neural networks (GNNs) prevail to extract the critical features from the input graph and support the prediction. They mostly follow the paradigm of "learning to attend", which maximizes the mutual information between the attended graph and the ground-truth label. However, this paradigm makes GNN classifiers recklessly absorb all the statistical correlations between input features and labels in the training data, without distinguishing the causal and noncausal effects of features. Instead of underscoring the causal features, the attended graphs are prone to visit the noncausal features as the shortcut to predictions. Such shortcut features might easily change outside the training distribution, thereby making the GNN classifiers suffer from poor generalization.</p><p>In this work, we take a causal look at the GNN modeling for graph classification. With our causal assumption, the shortcut feature serves as a confounder between the causal feature and prediction. It tricks the classifier to learn spurious correlations that facilitate the prediction in in-distribution (ID) test evaluation, while causing the performance drop in out-of-distribution (OOD) test data. To endow the classifier with better interpretation and generalization, we propose the Causal Attention Learning (CAL) strategy, which discovers the causal patterns and mitigates the confounding effect of shortcuts. Specifically, we employ attention modules to estimate the causal and shortcut features of the input graph. We then parameterize the backdoor adjustment of causal theory -combine each causal feature with various shortcut features. It encourages the stable relationships between the causal estimation and the prediction, regardless of the changes in shortcut parts and distributions. Extensive experiments on synthetic and real-world datasets demonstrate the effectiveness of CAL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graph neural networks (GNNs) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b16">17]</ref> have exhibited impressive performance of graph classification across various domains, such as chemical molecules, social networks, and transaction graphs. Such a success mainly comes from the powerful representation learning of GNNs, which incorporates the graph structure and encodes them into the representations in an end-to-end way. Hence, it is crucial to emphasize the critical part of the input graph, while filtering the trivial part out <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref>. For example, when classifying the mutagenic property of a molecular graph <ref type="bibr" target="#b23">[24]</ref>, GNNs are expected to latch on the functional groups (i.e., nitrogen dioxide (NO 2 )), instead of the irrelevant patterns (i.e., carbon rings) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b45">46]</ref>; when detecting fraud in a transaction network, malicious behaviors or coalitions of users are more informative than benign features.</p><p>Towards specifying the critical parts in graphs, some follow-on studies <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b44">45]</ref> adopt the paradigm of "learning to attend" <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b39">40]</ref> -maximizing the mutual information between the attended graph and the ground-truth label -to find the attended graph that maximizes the predictive performance. Specifically, there are two research lines in this paradigm: (1) Attention-based methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35]</ref>. They often utilize the attention modules for nodes or edges to locate the attended graphs. These attention modules act like soft masks to identify the importance of each edge and node to the final representations and predictions. <ref type="bibr" target="#b1">(2)</ref> Pooling-based methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b48">49]</ref>. They directly adopt hard masks to select a subset of nodes or edges as the attended graphs, to perform the information propagations. These attended graphs aim to approach the features that are beneficial for minimizing the training loss, instead of distinguishing the causal and noncausal effects.</p><p>Unfortunately, recent efforts <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18]</ref> have shown that the current attention or pooling learning methods are prone to exploit the shortcut features to make decisions. These shortcuts usually come from the data selection biases, noisy features, or some trivial patterns from graphs, which are noncausal but discriminative in training data. Due to the existence of these shortcuts, models can capture shortcut features to finish the classification tasks without struggling to learn causal features. For example, instead of probing into the causal effect of the functional groups, the attended graphs prefer "carbon rings" as the cues of the "mutagenic" class, because most training "mutagenic" molecules are in the "carbon rings" context. While such correlations represent statistical relations inherent in the training data and are beneficial to the in-distribution (ID) test evaluations, they inevitably cause a huge performance drop in the out-of-distribution (OOD) test data that are at odds with the training distribution. Taking the molecule classification as an example again, when most test "non-mutagenic" molecules appear in the "carbon rings" context, the attended graphs mislead the GNNs to still predict "mutagenic". As the assumption that the test data conforms to the training distribution is often infeasible in real-world scenarios, the poor generalization of these methods hinders their deployment on critical applications.</p><p>To resolve this issue, we first take a causal look at the decisionmaking process of GNNs for graph classification, which delineates the relationships among the causal feature, shortcut feature, and prediction. With our causal assumption in Figure <ref type="figure" target="#fig_0">1</ref>, the shortcut feature serves as a confounder <ref type="bibr" target="#b26">[27]</ref>. It opens a backdoor path <ref type="bibr" target="#b25">[26]</ref> and makes the causal feature and prediction spuriously correlated, e.g., misclassifying "non-mutagenic" molecules with "carbon rings" to the "mutagenic" molecules. Hence, mitigating the confounding effect is promising to exploit the causal features while filtering out the shortcut patterns, thereby enhancing the generalization.</p><p>Towards this end, we propose the Causal Attention Learning (CAL) strategy -maximizing the causal effect of the attended graph on predicting the label, while reducing the confounding effect of the shortcut features. Our attended graph aims to approach the causal features in the graph (e.g., nitrogen dioxide), while its complement targets the shortcut features (e.g., carbon rings). Specifically, we first apply attention modules to generate the estimations of the causal and shortcut features from the input graphs. We then parameterize the backdoor adjustment in the causal theory <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>, which combines each causal estimation with various shortcut estimations and encourages these combinations to maintain a stable prediction. It encourages the invariant relationships between the causal patterns and the predictions, regardless of the changes in the shortcut parts and distribution shifts. We apply CAL to various GNN architectures for graph classification. Experimental results on numerous synthetic and real-world datasets demonstrate the better generalization and insightful interpretations of CAL.</p><p>Our technical contributions are summarized as:</p><p>â€¢ We emphasize the generalization issue of current attention-and pooling-based GNNs in graph classification. From the causal perspective, we ascribe such an issue to the confounding effect of the shortcut features.</p><p>â€¢ We present a novel Causal Attention Learning (CAL) strategy for graph classification. It makes GNNs exploit the causal features while filtering out the shortcut patterns.</p><p>â€¢ Extensive experiments on synthetic and real-world datasets justify the effectiveness of CAL. More visualizations with in-depth analyses demonstrate the interpretability and rationality of CAL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES 2.1 Notations</head><p>We denote a graph by G = {A, X} with the node set V and edge set E. Let X âˆˆ R |V |Ã—F be the node feature matrix, where x ğ‘– = X[ğ‘–, :] is the F-dimensional attribute vector of node ğ‘£ ğ‘– âˆˆ V. We use the adjacency matrix A âˆˆ R </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Attention Mechanism in GNNs</head><p>In GNNs, attention can be defined over edges or nodes. For edgelevel attentions <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35]</ref>, they utilize weighted message passing and aggregation to update node representations H â€² :</p><formula xml:id="formula_0">H â€² = GConv (A âŠ™ M ğ‘ , H)<label>(1)</label></formula><p>where M ğ‘ âˆˆ R |V |Ã—|V | denotes the attention matrix that is often derived from trainable parameters and node representations. For node-level attention, several studies <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22]</ref> define the selfattention mask to select the most attentive node representations:</p><formula xml:id="formula_1">H â€² = GConv (A, H âŠ™ M ğ‘¥ )<label>(2)</label></formula><p>where M ğ‘¥ âˆˆ R |V |Ã—1 represents the node-level attentions, which can be generated by a network (e.g., GNNs or MLPs); âŠ™ is the broadcasted element-wise product. Hereafter, we can make further pooling operation <ref type="bibr" target="#b18">[19]</ref> for the output node representations H ğ‘œğ‘¢ğ‘¡ and summarize the graph representation h G for graph G via the readout function ğ‘“ readout (â€¢). Then we use a classifier Î¦ to project the graph representation into a probability distribution z G :</p><formula xml:id="formula_2">h G = ğ‘“ readout {h ğ‘œğ‘¢ğ‘¡ ğ‘– |ğ‘– âˆˆ V} , ğ‘§ G = Î¦(h G ).<label>(3)</label></formula><p>These methods follow the paradigm of "learning to attend" by minimizing the following empirical risk:</p><formula xml:id="formula_3">L CE = - 1 |D| âˆ‘ï¸ G âˆˆD y âŠ¤ G log(z G ). (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>where L CE is the cross-entropy loss over the training data D, and y G is the ground-truth label vector of G. However, this learning strategy heavily relies on the statistical correlations between the input graphs and labels. Hence, they will inevitably capture the noncausal shortcut features to make predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>In this section, we first analyze the GNN learning from the perspective of causality. From our causal assumption, we identify the shortcut feature as a confounder. Then we propose the causal attention learning strategy to alleviate the confounding effect. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">A Causal View on GNNs</head><p>We take a causal look at the GNN modeling and construct a Structural Causal Model (SCM) <ref type="bibr" target="#b26">[27]</ref> in Figure <ref type="figure" target="#fig_0">1</ref>. It presents the causalities among five variables: graph data ğº, causal feature ğ¶, shortcut feature ğ‘†, graph representation ğ‘…, and prediction ğ‘Œ , where the link from one variable to another indicates the cause-effect relationship: cause â†’ effect. We list the following explanations for SCM: Scrutinizing this SCM, we recognize a backdoor path between ğ¶ and ğ‘Œ , i.e., ğ¶ â† ğº â†’ ğ‘† â†’ ğ‘… â†’ ğ‘Œ , wherein the shortcut feature ğ‘† plays a confounder role between ğ¶ and ğ‘Œ . Even if ğ¶ has no direct link to ğ‘Œ , the backdoor path will cause ğ¶ to establish a spurious correlation with ğ‘Œ , e.g., making wrong predictions based on shortcut feature ğ‘† instead of causal feature ğ¶. Hence, it is crucial to cut off the backdoor path and make the GNN exploit causal features.</p><formula xml:id="formula_5">â€¢ ğ‘ª â† ğ‘® â†’ ğ‘º.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Backdoor Adjustment</head><p>We have realized that shielding the GNNs from the confounder ğ‘† is the key to exploiting causal features. Instead of modeling the confounded ğ‘ƒ (ğ‘Œ |ğ¶) in Figure <ref type="figure" target="#fig_0">1</ref>, we should achieve the graph representation learning by eliminating the backdoor path. But how to achieve this? Fortunately, causal theory <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref> provides us with a feasible solution: we can exploit the do-calculus on the variable ğ¶ to remove the backdoor path by estimating ğ‘ƒ ğ‘š (ğ‘Œ |ğ¶) = ğ‘ƒ (ğ‘Œ |ğ‘‘ğ‘œ (ğ¶)). It needs to stratify the confounder ğ‘† between ğ¶ and ğ‘Œ . Therefore, we can obtain the following three essential conclusions:</p><p>â€¢ The marginal probability ğ‘ƒ (ğ‘† = ğ‘ ) is invariant under the intervention, because the shortcut feature will not be affected by cutting off the backdoor path. Thus, ğ‘ƒ (ğ‘ ) = ğ‘ƒ ğ‘š (ğ‘ ). </p><p>where T denotes the confounder set; ğ‘ƒ (ğ‘Œ |ğ¶, ğ‘ ) represents the conditional probability given the causal feature ğ¶ and confounder ğ‘ ; ğ‘ƒ (ğ‘ ) is the prior probability of the confounder. Equation ( <ref type="formula" target="#formula_6">5</ref>) is usually called backdoor adjustment <ref type="bibr" target="#b25">[26]</ref>, which is a powerful tool to eliminate the confounding effect. However, there exist two challenges for implementing Equation ( <ref type="formula" target="#formula_6">5</ref>): i) The confounder set T is commonly unobservable and hard to obtain. ii) Due to the discrete nature of graph data, it seems difficult to directly manipulate the graph data, conditioning on domain-specific constraints (e.g., valency rules in molecule graphs). In section 3.4.3, we will introduce a simple yet effective solution to overcome these issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Causal and Trivial Attended-graph</head><p>Given a graph G = {A, X}, we formulate the soft masks on the graph structure and node feature as</p><formula xml:id="formula_7">M ğ‘ âˆˆ R |V |Ã—|V | and M ğ‘¥ âˆˆ R |V |Ã—1</formula><p>, respectively. Wherein, each element of the masks indicates the attention score relevant to the task of interest, which often falls into the range of (0, 1). Given an arbitrary mask M, we define its complementary mask as M = 1 -M, where 1 is the all-one matrix. Therefore, we can divide the full graph G into two attended-graphs:</p><formula xml:id="formula_8">G 1 = {A âŠ™ M ğ‘ , X âŠ™ M ğ‘¥ } and G 2 = {A âŠ™ M ğ‘ , X âŠ™ M ğ‘¥ }.</formula><p>With the inspection on the data-generating process, recent studies <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b43">44]</ref> argue that the label of a graph is usually determined by its causal part. Considering a molecular graph, its mutagenic property relies on the existence of relevant functional groups <ref type="bibr" target="#b36">[37]</ref>; Taking the digit image in the form of superpixel graph as another example, the coalition of digit-relevant nodes determines its label. Formally, given a graph G, we define the attended graph collecting all causal features as the causal attended-graph G ğ‘ , while the counterpart forms the trivial attended-graph G ğ‘¡ . However, the ground-truth attended-graph is usually unavailable in real-world applications. Hence, we aim to capture the causal and trivial attended-graph from the full graph by learning the masks:</p><formula xml:id="formula_9">G ğ‘ = {A âŠ™ M ğ‘ , X âŠ™ M ğ‘¥ } and G ğ‘¡ = {A âŠ™ M ğ‘ , X âŠ™ M ğ‘¥ }.</formula><p>Learning to identify causal attended-graphs not only guides the representation learning of GNNs, but also answers "What knowledge does the GNN use to make predictions?", which is crucial to the applications on explainability, privacy, and fairness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Causal Attention Learning</head><p>To implement the aforementioned backdoor adjustment, we propose the Causal Attention Learning (CAL) framework: 3.4.1 Estimating soft masks. Towards effective causal intervention, it is necessary to separate the causal and shortcut features from the full graphs. To this end, we hire attention modules, which yield two branches for the causal and trivial proposals. Given a GNN-based encoder ğ‘“ (â€¢) and a graph G = {A, X}, we can obtain  the node representations:</p><formula xml:id="formula_10">H = ğ‘“ (A, X).<label>(6)</label></formula><p>Then we adopt two MLPs: MLP node (â€¢) and MLP edge (â€¢) to estimate the attention scores from two orthogonal perspectives: node-level and edge-level. For node ğ‘£ ğ‘– and edge (ğ‘£ ğ‘– , ğ‘£ ğ‘— ) we can obtain:</p><formula xml:id="formula_11">ğ›¼ ğ‘ ğ‘– , ğ›¼ ğ‘¡ ğ‘– = ğœ (MLP node (h ğ‘– )),<label>(7)</label></formula><formula xml:id="formula_12">ğ›½ ğ‘ ğ‘– ğ‘— , ğ›½ ğ‘¡ ğ‘– ğ‘— = ğœ (MLP edge (h ğ‘– ||h ğ‘— )),<label>(8)</label></formula><p>where ğœ (â€¢) is softmax function, || denotes concatenation operation; ğ›¼ ğ‘ ğ‘– , ğ›½ ğ‘ ğ‘– ğ‘— represent the node-level attention score for node ğ‘£ ğ‘– and edge-level attention score for edge (ğ‘£ ğ‘– , ğ‘£ ğ‘— ) in causal attendedgraph; analogously, ğ›¼ ğ‘¡ ğ‘– , ğ›½ ğ‘¡ ğ‘– ğ‘— are for trivial attended-graph. Note that ğ›¼ ğ‘ ğ‘– + ğ›¼ ğ‘¡ ğ‘– = 1, and ğ›½ ğ‘ ğ‘– ğ‘— + ğ›½ ğ‘¡ ğ‘– ğ‘— = 1. These attention scores indicate how much the model pays attention to each node or edge in the corresponding attended-graph. Now we can construct the soft masks M ğ‘¥ , M ğ‘¥ , M ğ‘ , and M ğ‘ based on the attention scores ğ›¼ ğ‘ ğ‘– , ğ›¼ ğ‘¡ ğ‘– , ğ›½ ğ‘ ğ‘– ğ‘— , and ğ›½ ğ‘¡ ğ‘– ğ‘— , respectively. Finally, we can decompose the original graph G into the initial causal and trivial attended-graphs:</p><formula xml:id="formula_13">G ğ‘ = {A âŠ™ M ğ‘ , X âŠ™ M ğ‘¥ } and G ğ‘¡ = {A âŠ™ M ğ‘ , X âŠ™ M ğ‘¥ }.</formula><p>3.4.2 Disentanglement. Until now, we have distributed the attention scores at the granularity of nodes and edges to create the initial attended-graphs. Now we need to make the causal and trivial attended-graphs to capture the causal and shortcut features from the input graphs, respectively. Specifically, we adopt two GNN layers to obtain the representations of attended-graphs and make predictions via readout function and classifiers:</p><formula xml:id="formula_14">h G ğ‘ = ğ‘“ readout (GConv ğ‘ (A âŠ™ M ğ‘ , X âŠ™ M ğ‘¥ )), z G ğ‘ = Î¦ ğ‘ (h G ğ‘ ), (9) h G ğ‘¡ = ğ‘“ readout (GConv ğ‘¡ (AâŠ™M ğ‘ , XâŠ™M ğ‘¥ )), z G ğ‘¡ = Î¦ ğ‘¡ (h G ğ‘¡ ). (10)</formula><p>The causal attended-graph aims to estimate the causal features, so we classify its representation to the ground-truth label. Thus, we define the supervised classification loss as:</p><formula xml:id="formula_15">L sup = - 1 |D| âˆ‘ï¸ G âˆˆ D y âŠ¤ G log(z G ğ‘ ). (<label>11</label></formula><formula xml:id="formula_16">)</formula><p>where L sup is the cross-entropy loss over the training data D. The trivial attended-graph aims to approach the trivial patterns that are unnecessary for classification. Hence, we push its prediction evenly to all categories and define the uniform classification loss as:</p><formula xml:id="formula_17">L unif = 1 |D| âˆ‘ï¸ G âˆˆD KL(y unif , z G ğ‘¡ ). (<label>12</label></formula><formula xml:id="formula_18">)</formula><p>where KL denotes the KL-Divergence, y unif represents the uniform distribution. By optimizing the above two objectives, we can effectively disentangle causal and trivial features. Please note that prior efforts <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b43">44]</ref> have shown that the mutual information between the causal part and label is greater than that between the full graph and label, due to the widespread trivial patterns or noise. Hence, the proposed disentanglement will not make the captured causal attended-graph converge to the full graph (noiseless full graph is a special case), which is not an optimal solution. See Section 4.5 for more supporting evidence and analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Causal intervention.</head><p>As shown in Equation ( <ref type="formula" target="#formula_6">5</ref>), one promising solution to alleviating the confounding effect is the backdoor adjustment -that is, stratifying the confounder and pairing the target causal attended-graph with every stratification of trivial attended-graph to compose the "intervened graphs". However, due to the irregular graph data, it is impossible to make the intervention on data-level, e.g., changing a graph's trivial part to generate a counterfactual graph data. Towards this end, we make the implicit intervention on representation-level and propose the following loss guided by the backdoor adjustment:</p><formula xml:id="formula_19">z G â€² = Î¦(h G ğ‘ + h G ğ‘¡ â€² ),<label>(13)</label></formula><formula xml:id="formula_20">L caus = - 1 |D| â€¢ | T | âˆ‘ï¸ G âˆˆD âˆ‘ï¸ ğ‘¡ â€² âˆˆ T y âŠ¤ G log (z G â€² ),<label>(14)</label></formula><p>where z G â€² is the prediction from a classifier Î¦ on "implicit intervened graph" G â€² ; h G ğ‘ is the representation of causal attended-graph G ğ‘ derived from Equation ( <ref type="formula">9</ref>); while h G ğ‘¡ â€² is the representation of stratification G ğ‘¡ â€² obtained via Equation (10); T is the estimated stratification set of the trivial attended-graph, which collects the appearing trivial features from training data. In practice, we apply random addition to make the intervention in Equation <ref type="bibr" target="#b12">(13)</ref>. We define the Equation ( <ref type="formula" target="#formula_20">14</ref>) as the causal intervention loss. It pushes the predictions of such intervened graphs to be invariant and stable across different stratifications, due to the shared causal features. Finally, the objective of CAL can be defined as the sum of the losses:</p><formula xml:id="formula_21">L = L sup + ğœ† 1 L unif + ğœ† 2 L caus (<label>15</label></formula><formula xml:id="formula_22">)</formula><p>where ğœ† 1 and ğœ† 2 are hyper-parameters that determine the strength of disentanglement and causal intervention, respectively. The detailed algorithm of CAL is provided in Appendix A.1, Alg.1, and the overview of CAL is depicted in Figure <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>To verify the superiority and effectiveness of the proposed CAL, we conduct experiments to answer the following research questions:</p><p>â€¢ RQ1: How effective is the proposed CAL in alleviating the outof-distribution (OOD) issue?  â€¢ Synthetic graphs: Following <ref type="bibr" target="#b43">[44]</ref>, we create the synthetic dataset for graph classification, which contains a total of 8,000 samples with 4 classes, and keeps balance (2,000 samples) for each class. As shown in Figure <ref type="figure" target="#fig_3">3</ref>, each sample consists of two parts: causal subgraph and trivial subgraph. More details about the causal and trivial subgraph are provided in Appendix A.2. The task is to predict the type of the causal part in the whole graph. For simplicity, we choose the "House" class to define the bias-level:</p><formula xml:id="formula_23">ğ‘ = #Tree-House #House (<label>16</label></formula><formula xml:id="formula_24">)</formula><p>where #Tree-House denotes the number of "House" causal subgraphs with the "Tree" trivial subgraphs, and #House presents the number of graphs in the "House" class, which is 2,000. We set the proportion of "Tree" in the other three classes to 1 -ğ‘.</p><p>Obviously, for the unbiased dataset, ğ‘ = 0.5. We abbreviate the synthetic dataset with bias-level ğ‘ as SYN-ğ‘. We keep the same bias-level on the training/validation set and keep the testing set unbiased. Please refer to Appendix A.2 for more details. â€¢ Real-world graphs: We conduct experiments on three biological datasets (MUTAG, NCI1, PROTEINS), three social datasets (COLLAB, IMDB-B, IMDB-M) <ref type="bibr" target="#b23">[24]</ref>, and two superpixel datasets (MNIST, CIFAR-10) <ref type="bibr" target="#b17">[18]</ref>. More details, such as statistics and splitting of datasets, are provided in Appendix A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Baselines.</head><p>To verify the superiority of CAL, we adopt the following prevalent graph classification solutions as baselines:</p><p>â€¢ Attention-based methods: GAT <ref type="bibr" target="#b34">[35]</ref>, GATv2 <ref type="bibr" target="#b3">[4]</ref>, SuperGAT <ref type="bibr" target="#b15">[16]</ref>, GlobalAttention <ref type="bibr" target="#b21">[22]</ref>, AGNN <ref type="bibr" target="#b32">[33]</ref>. â€¢ Pooling-based methods: SortPool <ref type="bibr" target="#b48">[49]</ref>, DiffPool <ref type="bibr" target="#b44">[45]</ref>, Top-ğ‘˜ Pool <ref type="bibr" target="#b9">[10]</ref>, SAGPool <ref type="bibr" target="#b18">[19]</ref>. â€¢ Kernel-based methods: Graphlet kernel (GK) <ref type="bibr" target="#b30">[31]</ref>, Weisfeiler Lehman Kernel (WL) <ref type="bibr" target="#b29">[30]</ref>, Deep Graph kernels (DGK) <ref type="bibr" target="#b41">[42]</ref>. â€¢ GNN-based methods: GCN <ref type="bibr" target="#b16">[17]</ref>, GIN <ref type="bibr" target="#b40">[41]</ref> Besides these methods, we also consider the state-of-the-art algorithms: IRM <ref type="bibr" target="#b1">[2]</ref> and DRO <ref type="bibr" target="#b28">[29]</ref>, which are particularly designed for OOD issues. Please note that these methods require specific environments or group annotations for each training example, therefore we consider them as the methods with upper bound performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance on Synthetic Graphs (RQ1)</head><p>To explore whether CAL can alleviate the OOD issue, we first conduct experiments on SYN-ğ‘ with different biases: ğ‘ âˆˆ {0.1, 0.2, ..., 0.9}. The experimental results are summarized in Table <ref type="table" target="#tab_4">1</ref> and Figure <ref type="figure" target="#fig_5">4</ref>. We have the following Observations:</p><p>Obs 1: Refining discriminative features without considering the causality leads to poor OOD generalization. For the unbiased dataset, most attention-and pooling-based baselines, such as GlobalAtt, SuperGAT, SortPool, Top-ğ‘˜ Pool, outperform GCN. It indicates the effectiveness of extracting discriminative features in the ID setting. However, as the bias-level goes to extremes, the performance dramatically deteriorates. For instance, the performance drop of attention-based methods ranges from 7.37% âˆ¼ 12.75% on SYN-0.1, and 3.79% âˆ¼ 13.79% on SYN-0.9; Pooling-based methods drop from 7.82% âˆ¼ 14.24% and 3.99% âˆ¼ 12.10% for SYN-0.1 and SYN-0.9. These indicate that simply extracting discriminative features by attention or pooling module is prone to capture the data biases. These are also beneficial for reducing the training loss but lead to poor OOD generalization. Taking SYN-0.9 as an example, most "House" co-occur with "Tree" in the training data, so the model will mistakenly learn shortcut features from the "Tree"-type trivial subgraphs to make predictions, instead of probing the "House"-type causal subgraphs. This will mislead the model to adopt the "Tree" pattern to make decisions in the inference stage.</p><p>Obs 2: GNNs with better ID performance tend to have worse OOD generalization. For the unbiased dataset, GIN achieves the best performance (96.74%), while GAT (92.69%) outperforms the GCN (90.94%). This indicates that the in-distribution (ID) performance of these models exhibits such an order: GIN &gt; GAT &gt; GCN. However, when the bias is changed to 0.1 and 0.9, the performance of GIN drops by 9.55% and 7.36%, GAT drops by 8.71% and 5.47% and GCN drops by 6.60% and 5.43%, respectively. It shows that the rankings of models' robustness against OOD issues are in the opposite order: GCN &gt; GAT &gt; GIN. This indicates that GNNs with better ID performance are prone to learn more shortcut features. Similar trends also occur in other baselines. After adopting the proposed CAL, this phenomenon is significantly alleviated, which verifies the effectiveness of CAL in overcoming the OOD issue. Obs 3: Mitigating the confounder achieves more stable performance on OOD datasets. We first define the performance discount on SYN-ğ‘ as the accuracy on SYN-ğ‘ normalized by the accuracy on unbiased SYN-0.5. It indicates the degree of the performance degradation on biased synthetic datasets, without considering the model's ID generalization. We plot the performance discount curves on SYN-ğ‘ with ğ‘ âˆˆ {0.1, 0.2, ..., 0.9}. As depicted in Figure <ref type="figure" target="#fig_5">4</ref>, we observe that pooling-based methods outperform GIN in a small range of bias-levels (0.2 âˆ¼ 0.8), while the performance drops sharply when ğ‘ = 0.1 or 0.9. For example, the performance discount of Top-ğ‘˜ Pool drops from 0.95 to 0.88 as ğ‘ reduces from 0.2 to 0.1. Attentionbased methods perform worse than GIN when ğ‘ &lt; 0.5. For ğ‘ &gt; 0.5, AGNN achieves better performance than GIN, while GlobalAttention often performs worse. These results reflect that attention-or pooling-based methods all have their own weaknesses, such that they cannot consistently overcome the diverse distribution shifts. Equipped with CAL, GIN (red curve) consistently outperforms all the baselines on all ranges of bias-levels and obviously keeps a large gap, which further demonstrates the significance of mitigating the confounding effect, and the effectiveness of CAL. For comprehensive comparisons, we also plot two upper bound methods: IRM and DRO (dash lines), which require additional annotation information of trivial subgraphs for training. We observe that, even without additional information, CAL achieves comparable performance with these upper bound methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance on Real-world Graphs (RQ2)</head><p>Unlike synthetic graphs, there may not exist visible or specific patterns of the causal/trivial subgraphs in real-world graphs. However, there still exist irregular core-subgraphs <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b43">44</ref>] that determine the predictions, which will inevitably involve different degrees of biases caused by the complementary parts. Similar to SYN-ğ‘, they mislead the GNNs to learn the spurious correlations. Hence, we verify the practicability of CAL on eight real-world  datasets. We report the results of the baselines from the original papers by default and reproduce the missing results. The results are summarized in Table <ref type="table" target="#tab_5">2</ref> and we make the following Observations: Obs 4: The OOD issue is widespread in real-world datasets. Attention-based and pooling-based methods are on a par with GNNs, and they both outperform graph kernel-based methods in most cases. It can be seen from the last six rows in Table <ref type="table" target="#tab_5">2</ref>, when CAL is applied to different GNN models, it consistently produces further performance improvements. It demonstrates that the distribution shifts also widely exist in real-world datasets. Specifically, we can find that GCN often performs worse than other GNNs, attention-based or pooling-based methods, while the performance significantly improves after adopting CAL. For instance, on IMDB-B and MNIST datasets, GCN+CAL achieves 1.92% and 4.52% relative improvements, respectively. This indicates that GCN is vulnerable to the distribution shift in certain datasets. Thanks to the causality, CAL will push GCN to pay more attention to causal features, which can establish robustness against the widespread OOD issues and achieve better generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Study (RQ3)</head><p>In this section, we investigate the impact of the node/edge attention, random combination and the loss coefficients ğœ† 1 and ğœ† 2 .</p><p>Node Attention v.s. Edge Attention. Node Attention (NA) and Edge Attention (EA) refine the features from two orthogonal views: node-level and edge-level. Here we want to examine the effect of adopting NA or EA alone. We adopt GCN as the encoder to conduct experiments on four biased synthetic datasets and two real-world datasets. GCN+CAL w/o NA or EA represents the node/edge attention scores in Equation ( <ref type="formula" target="#formula_11">7</ref>)/(8) are evenly set as 0.5. The experimental results are shown in Figure <ref type="figure">5</ref>. We can find that: (1) Comparing NA with EA, the performance of CAL without NA is significantly worse than that without EA, which indicates that the node feature contains more significant information compared with graph structure. (2) Just adopting NA or EA alone still achieves better performance than baselines, which demonstrates that only applying NA or EA can also disentangle the causal/trivial attended-graph and achieve causal intervention to some extent. Random Combination. We need to stratify the confounder distribution for causal intervention. With the random combination, each causal feature will combine with different types of trivial patterns. To verify its importance, we change the "Random Addition" module in Figure <ref type="figure" target="#fig_1">2</ref> to "Addition", which just adopts the addition operation orderly, and we rename it as "GCN+CAL w/o RD". The experimental results are shown in Figure <ref type="figure">5</ref>. We can find that: (1) The performance drops severely compared with GCN+CAL, which demonstrates the importance of the causal intervention. (2) GCN+CAL w/o RD can also outperform the GCN baselines. We conjecture that just implementing disentanglement makes GNN pay more attention to the causal features, which will slightly ignore the data biases or trivial patterns. These results also reflect that disentanglement and causal intervention will help each other to improve their own effectiveness.</p><p>Loss coefficients ğœ† 1 and ğœ† 2 . According to Equation ( <ref type="formula" target="#formula_21">15</ref>), ğœ† 1 denotes the strength of the disentanglement for the causal/trivial features, while ğœ† 2 controls the strength of the causal intervention. To explore their impacts, we use GCN as the encoder and conduct experiments on two biased synthetic datasets and two real-world datasets. We fix one coefficient as 0.5 and change the other one in (0, 1) with a step size of 0.1. The experimental results are shown in Figure <ref type="figure">6</ref>. We can find that: (1) ğœ† 1 achieves better performance in a range of 0.3 âˆ¼ 0.7. Too small or too large values will cause performance degradation. (2) ğœ† 2 is not as stable as ğœ† 1 . The optimal range is around 0.3 âˆ¼ 0.5. It leads to a strong decline at 0.5 âˆ¼ 0.8, which indicates that coefficient ğœ† 2 should be set prudently. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Visualization and Analysis (RQ4)</head><p>Causal attended-graphs. We plot node/edge attention areas of the causal attended-graphs based on the attention scores in CAL. We adopt a GCN-based encoder and apply CAL on SYN-ğ‘ and MNIST superpixel graphs. The visualizations are shown in Figure <ref type="figure" target="#fig_7">7</ref>. Nodes with darker colors and edges with wider lines indicate higher attention scores. We surprisingly find that almost all the darker colors and wider lines precisely distribute on the deterministic areas, such as the causal subgraphs we defined in the synthetic dataset and the nodes located on digit pixels in MNIST superpixel graphs. It further demonstrates that the proposed CAL can effectively capture the causal features with insightful interpretations. The explanation for performance improvements. Figure <ref type="figure" target="#fig_9">8</ref> displays the distribution of misclassification on SYN-ğ‘. The abscissa represents the predictions, and the ordinate denotes the groundtruth types. The numbers in each row denote the proportion for each class. Figure <ref type="figure" target="#fig_9">8</ref> (Left) shows that the wrong predictions of graphs with "BA" are mainly distributed in "Cycle", "Grid" and "Diamond" classes, while the wrong predictions of graphs with "Tree" mainly concentrate on the "House" class (highlighted by the red circle). On one hand, most of the "House" co-occur with "Tree" in the training data, GCN tends to capture the shortcut features, e.g., "Tree" patterns, to make decisions. Therefore, the other three causal subgraphs with "Tree" will mainly be misclassified as "House" in the testing set. On the other hand, only a few "House" causal subgraphs co-occur with "BA", so the other three causal subgraphs with "BA" will almost not be misclassified as "House". In contrast, Figure <ref type="figure" target="#fig_9">8</ref> (Right) shows that, by applying CAL, the concentration of misclassification is obviously alleviated. This demonstrates that CAL improves performance by mitigating the confounding effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Attention Mechanism selects the informative features from data, which has obtained great success in computer vision <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">43]</ref> and natural language processing tasks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b33">34]</ref>. In recent years, attention mechanism has gradually become prevalent in the GNN field. The attention modules for GNNs can be defined over edges <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35]</ref> or over nodes <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22]</ref>. Despite effectiveness, attention learning still stays at how to better fit the statistical correlations between data and labels. Hence, the learned attentions are inherently biased in OOD settings. Recent studies <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b42">43]</ref> propose the causal attention modules to alleviate the bias. CaaM <ref type="bibr" target="#b35">[36]</ref>    adopts the adversarial training to generate the data partition in each iteration to achieve the causal intervention. CATT <ref type="bibr" target="#b42">[43]</ref> proposes in-sample and cross-sample attentions based on front-door adjustment. However, they are both tailored for computer vision tasks, while cannot transfer to graph learning tasks, due to the irregular and challenging graph-structure data. Distinct from them, we utilize the disentanglement and causal intervention strategies to strengthen the attention modules for GNNs.</p><p>OOD Generalization <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref> has been extensively explored in recent years. IRM <ref type="bibr" target="#b1">[2]</ref> minimizes the empirical risk under different environments. Group-DRO <ref type="bibr" target="#b28">[29]</ref> adversarially explores the group with the worst risk and achieves generalization by minimizing the empirical risk of the worst group. Existing efforts <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref> mainly focus on computer vision or natural language processing tasks, while the GNN field is of great need but largely unexplored. Furthermore, these methods require the environment or group prior information for each training sample, which is expensive in practice. To alleviate this dilemma, we adopt causal intervention to strengthen the causal relationship between the causal feature and prediction, thereby achieving better generalization.</p><p>Causal Inferences <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref> endows the model with the ability to pursue real causality. A growing number of studies <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b47">48]</ref> have shown that causal inference is beneficial to diverse computer vision tasks. CONTA <ref type="bibr" target="#b47">[48]</ref> uses backdoor adjustment to eliminate the confounder in weakly supervised semantic segmentation tasks. DDE <ref type="bibr" target="#b14">[15]</ref> proposes to distill the colliding effect between the old and the new data to improve class-incremental learning. Unlike computer vision, the application of causal intervention in the GNN community is still in its infancy. CGI <ref type="bibr" target="#b8">[9]</ref> explores how to select trustworthy neighbors for GNN in the inference stage, and demonstrates its effectiveness in node classification. Recent work <ref type="bibr" target="#b46">[47]</ref> studies the connection between GNNs and SCM from a theoretical perspective. Different from them, we introduce a causal attention learning strategy to mitigate the confounding effect for GNNs. It encourages GNNs to pay more attention to causal features, which will enhance the robustness against the distribution shift.</p><p>In this work, we revisit the GNN modeling for graph classification from a causal perspective. We find that current GNN learning strategies are prone to exploit the shortcut features to support their predictions. However, the shortcut feature actually plays a confounder role. It establishes a backdoor path between the causal feature and the prediction, which misleads the GNNs to learn spurious correlations. To mitigate the confounding effect, we propose the causal attention learning (CAL) strategy for GNNs. CAL is guided by the backdoor adjustment from the causal theory. It encourages the GNNs to exploit causal features while ignoring the shortcut parts. Extensive experimental results and analyses verify its effectiveness. Future studies include adopting powerful disentanglement methods and more advanced causal intervention strategies to improve the CAL. We will also make efforts to apply CAL to other graph learning tasks, such as node classification or link prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX A.1 Algorithm</head><p>We provide the detailed implementation of the proposed casual attention learning (CAL) in Algorithm 1. We adopt the causal attended-graph for prediction in the inference stage. for ğ‘˜ â† 1 to ğ‘€ do 3:</p><formula xml:id="formula_25">H ğ‘˜ â† ğ‘“ (A ğ‘˜ , X ğ‘˜ }) 4:</formula><p>Compute ğ›¼ ğ‘ ğ‘– , ğ›¼ ğ‘¡ ğ‘– â† Equation ( <ref type="formula" target="#formula_11">7</ref>) for all nodes of G ğ‘˜  Update all the trainable parameters to minimize L 24: end for</p><formula xml:id="formula_26">G ğ‘˜ ğ‘ â† {A ğ‘˜ âŠ™ M ğ‘˜ ğ‘ , X ğ‘˜ âŠ™ M ğ‘˜ ğ‘¥ } // causal 9: G ğ‘˜ ğ‘¡ â† {A ğ‘˜ âŠ™ M ğ‘˜ ğ‘ , X ğ‘˜ âŠ™ M ğ‘˜ ğ‘¥ } // trivial</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Datasets Details</head><p>In this section, we give more details about the synthetic datasets and real-world datasets.</p><p>1) Synthetic graphs. For each synthetic graph instance, it consists of two subgraphs: trivial and critical subgraphs. We introduce the proposed trivial subgraph and critical subgraph as follows:</p><p>â€¢ Trivial subgraph. There exist two types of trivial subgraphs:</p><p>BA-SHAPES and Tree. The BA-SHAPES is a BarabÃ¡si-Albert (BA) graph <ref type="bibr" target="#b2">[3]</ref>, and we abbreviate it as "BA" in this paper. The "Tree" graph is a base 12-level balanced binary tree <ref type="bibr" target="#b43">[44]</ref>. To reduce the influence, we control the number of nodes in the two kinds of trivial subgraphs to be similar. â€¢ Causal subgraph. There are four types of causal subgraphs: "House", "Cycle", "Grid", "Diamond". The visualizations of these trivial subgraphs and causal subgraphs are depicted in Figure <ref type="figure" target="#fig_3">3</ref>. For each synthetic graph instance, a causal subgraph is randomly attached on one node of a trivial subgraph. Then the resulting graph is further perturbed by adding 10% random edges. We take the one-hot form of the node degree as the node feature and set the dimension of node feature to 20. The synthetic graph examples are displayed in Figure <ref type="figure" target="#fig_3">3</ref>. The statistics of the synthetic datasets are summarized in Table <ref type="table" target="#tab_10">3</ref>. We split the dataset into training, validation and testing set with the ratio of 7: 1: 2. </p><p>2) Real-world graphs. To demonstrate the practicality of the proposed CAL, we conduct experiments on TUDataset <ref type="bibr" target="#b23">[24]</ref> and Superpixel graphs <ref type="bibr" target="#b17">[18]</ref>. For TUDataset, we gather three biological datasets (MUTAG, NCI1, PROTEINS) and three social networks datasets (COLLAB, IMDB-B, IMDB-M), which are commonly used in graph classification benchmarks <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b40">41]</ref>. Following <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b44">45]</ref>, we use 10-fold cross-validation and report average accuracy and standard deviation. The superpixel graphs <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18]</ref> includes MNIST and CIFAR-10, which are classical image classification datasets converted into graphs using superpixels technology <ref type="bibr" target="#b0">[1]</ref> and assigning each node's features as the superpixel coordinates and intensity. Following <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18]</ref>, we split the MNIST and CIFAR-10 to 55K training/5K validation/10K testing, and 45K training/5K validation/10K testing, respectively. All the detailed statistics about the real-world datasets are summarized in Table <ref type="table" target="#tab_10">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Hyper-parameters</head><p>As for training parameters, we train the models for 100 epochs with batch size of 128. We optimize all models with the Adam optimizer. For SYN-ğ‘ and TUDataset, we use GCN, GIN and GAT as GNN encoders with 3 layers and 128 hidden units. For Superpixel graphs MNIST and CIFAR-10, we use the GNN encoders with 4 layers and 146 hidden units as <ref type="bibr" target="#b7">[8]</ref>. For all the baselines, we follow the default settings from original papers and reproduce the missing results. For the proposed CAL, we search ğœ† 1 and ğœ† 2 in (0.1, 1.0) with a step size of 0.1 and report the results with the best settings. We adopt NVIDIA 2080 Ti (11GB GPU) to conduct all our experiments, the training time comparison is shown as Table <ref type="table" target="#tab_11">4</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Structural causal model for graph classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The overview of the proposed Causal Attention Learning (CAL) framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of the synthetic datasets. â€¢ RQ2: Can the proposed CAL achieve performance improvements on real-world datasets? â€¢ RQ3: For the different components in CAL, what are their roles and impacts on performance? â€¢ RQ4: Does CAL capture the causal attended-graphs with significant patterns and insightful interpretations? 4.1 Experimental Settings 4.1.1 Datasets. We conduct experiments on both synthetic datasets and real-world datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>4. 1 . 3</head><label>13</label><figDesc>Hyper-parameters. All training hyper-parameters and model configurations are summarized in Appendix A.3. Codes are released at https://github.com/yongduosui/CAL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The performance discount on synthetic datasets with different bias-levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 : 9 Figure 6 :</head><label>596</label><figDesc>Figure 5: The comparison of different components in CAL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Visualizations of causal attended-graphs. (Left): Synthetic graphs, (Right): MNIST superpixel graphs.</figDesc><graphic coords="8,184.53,112.26,89.80,89.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The misclassification distribution. Red circle highlights the concentration degree of misclassification.</figDesc><graphic coords="8,348.92,96.95,78.77,157.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Algorithm 1 :</head><label>1</label><figDesc>Casual Attention Learning Input: Dataset D, ğ‘“ (â€¢), attention modules, classifiers, ğœ† 1 , ğœ† 2 Output: The trained parameters. 1: for sampled ğ‘€ graphs {G ğ‘˜ = {A ğ‘˜ , X ğ‘˜ }} ğ‘€ ğ‘˜=1 do 2:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>|V |Ã—|V | to delineate the whole graph structure, where A[ğ‘–, ğ‘—] = 1 if edge (ğ‘£ ğ‘– , ğ‘£ ğ‘— ) âˆˆ E, otherwise A[ğ‘–, ğ‘—] = 0. We define GConv(â€¢) as a GNN layer module and denote the node representation matrix by H âˆˆ R |V |Ã—ğ‘‘ , whose ğ‘–-th row h</figDesc><table /><note><p>ğ‘– = H[ğ‘–, :] denotes the representation of node ğ‘£ ğ‘– .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The variable ğ¶ denotes the causal feature that truly reflects the intrinsic property of the graph data ğº. While ğ‘† represents the shortcut feature which is usually caused by the data biases or trivial patterns. Since ğ¶ and ğ‘† naturally coexist in graph data ğº, these causal effects are established.â€¢ ğ‘ª â†’ ğ‘¹ â† ğ‘º. The variable ğ‘… is the representation of the given graph data ğº. To generate ğ‘…, the conventional learning strategy takes the shortcut feature ğ‘† and the causal feature ğ¶ as input to distill discriminative information. â€¢ ğ‘¹ â†’ ğ’€ . The ultimate goal of graph representation learning is to predict the properties of the input graphs. The classifier will make prediction ğ‘Œ based on the graph representation ğ‘….</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>â€¢</head><label></label><figDesc>The conditional probability ğ‘ƒ (ğ‘Œ |ğ¶, ğ‘ ) is invariant, because ğ‘Œ 's response to ğ¶ and ğ‘† has nothing to do with the causal effect between ğ¶ and ğ‘†. Then we can get: ğ‘ƒ ğ‘š (ğ‘Œ |ğ¶, ğ‘ ) = ğ‘ƒ (ğ‘Œ |ğ¶, ğ‘ ).â€¢ Obviously, the variables ğ¶ and ğ‘† are independent under the causal intervention, which we have: ğ‘ƒ ğ‘š (ğ‘  |ğ¶) = ğ‘ƒ ğ‘š (ğ‘ ).</figDesc><table><row><cell cols="3">Based on the above conclusions, we have:</cell></row><row><cell cols="3">ğ‘ƒ (ğ‘Œ |ğ‘‘ğ‘œ (ğ¶)) = ğ‘ƒ ğ‘š (ğ‘Œ |ğ¶)</cell></row><row><cell>=</cell><cell>âˆ‘ï¸ ğ‘  âˆˆT</cell><cell>ğ‘ƒ ğ‘š (ğ‘Œ |ğ¶, ğ‘ )ğ‘ƒ ğ‘š (ğ‘  |ğ¶) (ğµğ‘ğ‘¦ğ‘’ğ‘  ğ‘…ğ‘¢ğ‘™ğ‘’)</cell></row><row><cell>=</cell><cell>âˆ‘ï¸ ğ‘  âˆˆT</cell><cell>ğ‘ƒ ğ‘š (ğ‘Œ |ğ¶, ğ‘ )ğ‘ƒ ğ‘š (ğ‘ ) (ğ¼ğ‘›ğ‘‘ğ‘’ğ‘ğ‘’ğ‘›ğ‘‘ğ‘’ğ‘›ğ‘ğ‘¦)</cell></row><row><cell>=</cell><cell>âˆ‘ï¸ ğ‘  âˆˆT</cell><cell>ğ‘ƒ (ğ‘Œ |ğ¶, ğ‘ )ğ‘ƒ (ğ‘ ),</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Test Accuracy (%) of graph classification on synthetic datasets with diverse biases. The number in brackets represents the performance degradation compared with the unbiased dataset. Our methods are highlighted with a gray background.</figDesc><table><row><cell>Method</cell><cell>SYN-0.1</cell><cell>SYN-0.3</cell><cell>Unbiased</cell><cell>SYN-0.7</cell><cell>SYN-0.9</cell></row><row><cell>GATv2 [4]</cell><cell>87.25 (â†“ 7.37%)</cell><cell>92.19 (â†“ 2.12%)</cell><cell>94.19</cell><cell>93.31 (â†“ 0.93%)</cell><cell>90.62 (â†“ 3.79%)</cell></row><row><cell>SuperGAT [16]</cell><cell>83.81 (â†“ 12.75%)</cell><cell>91.94 (â†“ 4.29%)</cell><cell>96.06</cell><cell>88.50 (â†“ 7.89%)</cell><cell>82.81 (â†“ 13.79%)</cell></row><row><cell>GlobalAtt [22]</cell><cell>87.19 (â†“ 10.40%)</cell><cell>93.75 (â†“ 3.66%)</cell><cell>97.31</cell><cell>94.62 (â†“ 2.76%)</cell><cell>91.50 (â†“ 5.97%)</cell></row><row><cell>AGNN [33]</cell><cell>84.56 (â†“ 11.69%)</cell><cell>93.06 (â†“ 2.81%)</cell><cell>95.75</cell><cell>94.81 (â†“ 0.98%)</cell><cell>88.12 (â†“ 7.97%)</cell></row><row><cell>DiffPool [45]</cell><cell>82.28 (â†“ 8.69%)</cell><cell>88.02 (â†“ 2.32%)</cell><cell>90.11</cell><cell>88.83 (â†“ 1.42%)</cell><cell>84.50 (â†“ 6.23%)</cell></row><row><cell>SortPool [49]</cell><cell>80.70 (â†“ 14.24%)</cell><cell>92.33 (â†“ 1.88%)</cell><cell>94.10</cell><cell>92.14 (â†“ 2.08%)</cell><cell>90.35 (â†“ 3.99%)</cell></row><row><cell>Top-ğ‘˜ Pool [10]</cell><cell>84.31 (â†“ 11.81%)</cell><cell>93.53 (â†“ 2.17%)</cell><cell>95.60</cell><cell>94.44 (â†“ 1.21%)</cell><cell>88.02 (â†“ 7.93%)</cell></row><row><cell>SAGPool [19]</cell><cell>88.08 (â†“ 7.82%)</cell><cell>90.86 (â†“ 4.91%)</cell><cell>95.55</cell><cell>92.22 (â†“ 3.49%)</cell><cell>83.99 (â†“ 12.10%)</cell></row><row><cell>GCN [17]</cell><cell>84.94 (â†“ 6.60%)</cell><cell>89.38 (â†“ 1.72%)</cell><cell>90.94</cell><cell>90.25 (â†“ 0.76%)</cell><cell>86.00 (â†“ 5.43%)</cell></row><row><cell>GCN + CAL</cell><cell>89.38 (â†“ 6.03%)</cell><cell>93.50 (â†“ 1.70%)</cell><cell>95.12</cell><cell>95.06 (â†“ 0.06%)</cell><cell>93.31 (â†“ 1.90%)</cell></row><row><cell>GIN [41]</cell><cell>87.50 (â†“ 9.55%)</cell><cell>93.94 (â†“ 2.89%)</cell><cell>96.74</cell><cell>94.88 (â†“ 1.92%)</cell><cell>89.62 (â†“ 7.36%)</cell></row><row><cell>GIN + CAL</cell><cell>93.19 (â†“ 3.87%)</cell><cell>96.31 (â†“ 0.65%)</cell><cell>96.94</cell><cell>96.56 (â†“ 0.39%)</cell><cell>95.25 (â†“ 1.74%)</cell></row><row><cell>GAT [35]</cell><cell>84.62 (â†“ 8.71%)</cell><cell>89.50 (â†“ 3.44%)</cell><cell>92.69</cell><cell>92.31 (â†“ 0.41%)</cell><cell>87.62 (â†“ 5.47%)</cell></row><row><cell>GAT + CAL</cell><cell>92.44 (â†“ 4.37%)</cell><cell>96.25 (â†“ 0.42%)</cell><cell>96.66</cell><cell>96.12 (â†“ 0.56%)</cell><cell>92.56 (â†“ 4.24%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Test Accuracy (%) of classification. For TUDataset, we perform 10-fold cross-validation and report the mean and standard derivations. Our methods are highlighted with gray background. If the performance improves, the number is bolded.</figDesc><table><row><cell>Dataset</cell><cell>MUTAG</cell><cell>NCI1</cell><cell>PROTEINS</cell><cell>COLLAB</cell><cell>IMDB-B</cell><cell>IMDB-M</cell><cell>MNIST</cell><cell>CIFAR-10</cell></row><row><cell>GK [31]</cell><cell>81.58Â±2.11</cell><cell>62.49Â±0.27</cell><cell>71.67Â±0.55</cell><cell>72.84Â±0.28</cell><cell>65.87Â±0.98</cell><cell>43.89Â±0.38</cell><cell>-</cell><cell>-</cell></row><row><cell>WL [30]</cell><cell>82.05Â±0.36</cell><cell>82.19Â±0.18</cell><cell>74.68Â±0.50</cell><cell>79.02Â±1.77</cell><cell>73.40Â±4.63</cell><cell>49.33Â±4.75</cell><cell>-</cell><cell>-</cell></row><row><cell>DGK [42]</cell><cell>87.44Â±2.72</cell><cell>80.31Â±0.46</cell><cell>75.68Â±0.54</cell><cell>73.09Â±0.25</cell><cell>66.96Â±0.56</cell><cell>44.55Â±0.52</cell><cell>-</cell><cell>-</cell></row><row><cell>GlobalAtt [22]</cell><cell>88.27Â±8.65</cell><cell>81.17Â±1.04</cell><cell>72.60Â±4.37</cell><cell>81.48Â±1.46</cell><cell>69.10Â±3.80</cell><cell>51.40Â±2.91</cell><cell>-</cell><cell>-</cell></row><row><cell>AGNN [33]</cell><cell>79.77Â±8.54</cell><cell>79.96Â±2.37</cell><cell>75.66Â±3.94</cell><cell>81.10Â±2.39</cell><cell>73.10Â±4.07</cell><cell>49.73Â±3.72</cell><cell>-</cell><cell>-</cell></row><row><cell>DiffPool [45]</cell><cell>85.61Â±6.22</cell><cell>75.06Â±3.66</cell><cell>76.25Â±4.21</cell><cell>79.24Â±1.66</cell><cell>74.47Â±3.84</cell><cell>49.20Â±3.10</cell><cell>-</cell><cell>-</cell></row><row><cell>SortPool [49]</cell><cell>86.17Â±7.53</cell><cell>79.00Â±1.68</cell><cell>75.48Â±1.62</cell><cell>77.84Â±1.22</cell><cell>73.00Â±3.50</cell><cell>49.53Â±2.29</cell><cell>-</cell><cell>-</cell></row><row><cell>GCN [17]</cell><cell>88.20Â±7.33</cell><cell>82.97Â±2.34</cell><cell>75.65Â±3.24</cell><cell>81.72Â±1.64</cell><cell>73.89Â±5.74</cell><cell>51.53Â±3.28</cell><cell>90.49</cell><cell>54.68</cell></row><row><cell>GCN + CAL</cell><cell>89.24Â±8.72</cell><cell>83.48Â±1.94</cell><cell>76.28Â±3.65</cell><cell>82.08Â±2.40</cell><cell>74.40Â±4.55</cell><cell>52.13Â±2.96</cell><cell>94.58</cell><cell>56.21</cell></row><row><cell>GIN [41]</cell><cell>89.42Â±7.40</cell><cell>82.71Â±1.52</cell><cell>76.21Â±3.83</cell><cell>82.08Â±1.51</cell><cell>73.40Â±3.78</cell><cell>51.53Â±2.97</cell><cell>96.51</cell><cell>56.36</cell></row><row><cell>GIN + CAL</cell><cell>89.91Â±8.34</cell><cell>83.89Â±1.93</cell><cell>76.92Â±3.31</cell><cell>82.68Â±1.25</cell><cell>74.13Â±5.21</cell><cell>52.60Â±2.36</cell><cell>96.93</cell><cell>56.63</cell></row><row><cell>GAT [35]</cell><cell>88.58Â±7.54</cell><cell>82.11Â±1.43</cell><cell>75.96Â±3.26</cell><cell>81.42Â±1.41</cell><cell>72.70Â±4.37</cell><cell>50.60Â±3.75</cell><cell>95.53</cell><cell>64.22</cell></row><row><cell>GAT + CAL</cell><cell>89.94Â±8.78</cell><cell>83.55Â±1.42</cell><cell>76.39Â±3.65</cell><cell>82.12Â±1.95</cell><cell>73.30Â±4.16</cell><cell>50.93Â±3.84</cell><cell>95.91</cell><cell>66.16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>5 :</head><label>5</label><figDesc>Compute ğ›½ ğ‘ ğ‘– ğ‘— , ğ›½ ğ‘¡ ğ‘– ğ‘— â† Equation (8) for all edges of G ğ‘˜ ğ‘˜ ğ‘¥ based on ğ›½ ğ‘ ğ‘– ğ‘— and ğ›¼ ğ‘ ğ‘– ğ‘˜ ğ‘¥ based on ğ›½ ğ‘¡ ğ‘– ğ‘— and ğ›¼ ğ‘¡ ğ‘–</figDesc><table><row><cell>6: ğ‘ and M 7: Get masks M ğ‘˜ Get masks M ğ‘˜ ğ‘ and M 8:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 3 :</head><label>3</label><figDesc>Statistics of datasets used in experiments.</figDesc><table><row><cell>Dataset</cell><cell>#Graphs</cell><cell>#Nodes</cell><cell>#Edges</cell><cell>#Classes</cell></row><row><cell>SYN-ğ‘</cell><cell>8000</cell><cell>230âˆ¼247</cell><cell>542âˆ¼1000</cell><cell>4</cell></row><row><cell>MUTAG</cell><cell>188</cell><cell>17.93</cell><cell>19.79</cell><cell>2</cell></row><row><cell>NCI1</cell><cell>4110</cell><cell>29.87</cell><cell>32.30</cell><cell>2</cell></row><row><cell>PROTEINS</cell><cell>1113</cell><cell>39.06</cell><cell>72.82</cell><cell>2</cell></row><row><cell>COLLAB</cell><cell>5000</cell><cell>74.49</cell><cell>2457.78</cell><cell>3</cell></row><row><cell>IMDB-B</cell><cell>1000</cell><cell>19.77</cell><cell>96.53</cell><cell>2</cell></row><row><cell>IMDB-M</cell><cell>1500</cell><cell>13.00</cell><cell>65.94</cell><cell>3</cell></row><row><cell>MNIST</cell><cell>70000</cell><cell>70.57</cell><cell>564.66</cell><cell>10</cell></row><row><cell>CIFAR-10</cell><cell>60000</cell><cell>117.63</cell><cell>941.04</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 4 :</head><label>4</label><figDesc>Training time (minutes) comparison.</figDesc><table><row><cell>Method</cell><cell cols="5">SYN-ğ‘ MUTAG NCI1 IMDB-M MNIST</cell></row><row><cell>GCN</cell><cell>4.16</cell><cell>1.03</cell><cell>12.71</cell><cell>4.61</cell><cell>57.20</cell></row><row><cell>GCN + CAL</cell><cell>6.67</cell><cell>1.35</cell><cell>17.37</cell><cell>6.16</cell><cell>75.80</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">ACKNOWLEDGMENTS</head><p>This work is supported by the <rs type="funder">National Key Research and Development Program of China</rs> (<rs type="grantNumber">2020AAA0106000</rs>), and the <rs type="funder">National Natural Science Foundation of China</rs> (<rs type="grantNumber">U19A2079</rs>, <rs type="grantNumber">U21B2026</rs>). This research is also supported by <rs type="funder">CCCD Key Lab of Ministry of Culture and Tourism</rs> and <rs type="institution">Sea-NExT Joint Lab</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_zTSAj6U">
					<idno type="grant-number">2020AAA0106000</idno>
				</org>
				<org type="funding" xml:id="_JpGz355">
					<idno type="grant-number">U19A2079</idno>
				</org>
				<org type="funding" xml:id="_xNgf5Ye">
					<idno type="grant-number">U21B2026</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SLIC superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName><forename type="first">Radhakrishna</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Appu</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelien</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabine</forename><surname>SÃ¼sstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">LÃ©on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<title level="m">Invariant risk minimization</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Emergence of scaling in random networks</title>
		<author>
			<persName><forename type="first">Albert-LÃ¡szlÃ³</forename><surname>BarabÃ¡si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">RÃ©ka</forename><surname>Albert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="509" to="512" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">How Attentive are Graph Attention Networks?</title>
		<author>
			<persName><forename type="first">Shaked</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Yahav</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity</title>
		<author>
			<persName><forename type="first">Asim</forename><surname>Kumar Debnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosa</forename><forename type="middle">L</forename><surname>Lopez De Compadre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gargi</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">J</forename><surname>Shusterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corwin</forename><surname>Hansch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of medicinal chemistry</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="1991">1991. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>et al. 2020. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In ICLR</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Prakash Dwivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chaitanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00982</idno>
		<title level="m">Benchmarking graph neural networks</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Xiangnan He, Xin Xin, Qifan Wang, and Tat-Seng Chua. 2021. Should graph convolution trust neighbors? a simple causal inference method</title>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiran</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<biblScope unit="page" from="1208" to="1218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Graph u-nets</title>
		<author>
			<persName><forename type="first">Hongyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2083" to="2092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Shortcut learning in deep neural networks</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">JÃ¶rn-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="665" to="673" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patricia</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distilling Causal Effect of Data in Class-Incremental Learning</title>
		<author>
			<persName><forename type="first">Xinting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian-Sheng</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">How to find your friendly neighborhood: Graph attention design with self-supervision</title>
		<author>
			<persName><forename type="first">Dongkwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Oh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Understanding Attention and Generalization in Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Boris</forename><surname>Knyazev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><forename type="middle">R</forename><surname>Amer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4204" to="4214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Self-attention graph pooling</title>
		<author>
			<persName><forename type="first">Junhyun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inyeop</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3734" to="3743" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Graph classification using structural attention</title>
		<author>
			<persName><forename type="first">John</forename><surname>Boaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1666" to="1674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Graph convolutional networks with motif-based attention</title>
		<author>
			<persName><forename type="first">John</forename><surname>Boaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungchul</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunyee</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anup</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="499" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Gated Graph Sequence Neural Networks</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generative causal explanations for graph neural networks</title>
		<author>
			<persName><forename type="first">Wanyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baochun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6666" to="6679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Tudataset: A collection of benchmark datasets for learning with graphs</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><forename type="middle">M</forename><surname>Kriege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franka</forename><surname>Bause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petra</forename><surname>Mutzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marion</forename><surname>Neumann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>ICMLW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Counterfactual vqa: A cause-effect look at language bias</title>
		<author>
			<persName><forename type="first">Yulei</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian-Sheng</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<idno>CVPR. 12700-12710</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Interpretation and identification of causal mediation</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological methods</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">459</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<title level="m">Models, reasoning and inference</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2000">2000. 2000</date>
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The Risks of Invariant Risk Minimization</title>
		<author>
			<persName><forename type="first">Elan</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Kumar Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Risteski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization</title>
		<author>
			<persName><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Weisfeiler-Lehman graph kernels</title>
		<author>
			<persName><forename type="first">Nino</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Van Leeuwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Efficient graphlet kernels for large graph comparison</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename><surname>Nino Shervashidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Petri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect</title>
		<author>
			<persName><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Attention-based graph neural network for semi-supervised learning</title>
		<author>
			<persName><forename type="first">Chong</forename><surname>Kiran K Thekumparampil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewoong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Jia</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.03735</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Attention is All you Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In NeurIPS. 5998-6008</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Graph Attention Networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>VeliÄkoviÄ‡</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>LiÃ²</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Causal Attention for Unbiased Visual Recognition</title>
		<author>
			<persName><forename type="first">Tan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3091" to="3100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Xiangnan He, and Tat-Seng Chua. 2022. Reinforced Causal Explainer for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Xiangnan He, and Tat seng Chua. 2021. Towards Multi-Grained Explainability for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Discovering Invariant Rationales for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Yingxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Xiangnan He, and Tat-Seng Chua</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">How Powerful are Graph Neural Networks?</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep graph kernels</title>
		<author>
			<persName><forename type="first">Pinar</forename><surname>Yanardag</surname></persName>
		</author>
		<author>
			<persName><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Causal attention for vision-language tasks</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guojun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9847" to="9857" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">GNNExplainer: Generating Explanations for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Bourgeois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9240" to="9251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Hierarchical Graph Representation Learning with Differentiable Pooling</title>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4805" to="4815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">XGNN: Towards Model-Level Explanations of Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Hao Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuiwang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="430" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">Matej</forename><surname>ZeÄeviÄ‡</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Singh Dhami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petar</forename><surname>VeliÄkoviÄ‡</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.04173</idno>
		<title level="m">Relating Graph Neural Networks to Structural Causal Models</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Xian-Sheng Hua, and Qianru Sun. 2020. Causal Intervention for Weakly-Supervised Semantic Segmentation</title>
		<author>
			<persName><forename type="first">Dong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An end-to-end deep learning architecture for graph classification</title>
		<author>
			<persName><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhicheng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marion</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
