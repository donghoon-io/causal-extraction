<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unbiased Scene Graph Generation via Two-stage Causal Modeling</title>
				<funder ref="#_5Pvsmv9 #_6u3rQrg #_g7XuHak #_E38ZrCd">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_RA8kyhw">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
				<funder ref="#_Bxywr6K">
					<orgName type="full">Academy of Finland</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shuzhou</forename><surname>Sun</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shuaifeng</forename><surname>Zhi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qing</forename><surname>Liao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Janne</forename><surname>Heikkil</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">College of Electronic Science</orgName>
								<orgName type="institution">National University of Defense Technology (NUDT)</orgName>
								<address>
									<settlement>Changsha</settlement>
									<region>Hunan China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">University of Oulu</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Center for Machine Vision and Signal Analysis</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Oulu</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unbiased Scene Graph Generation via Two-stage Causal Modeling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Scene graph generation</term>
					<term>causal inference</term>
					<term>counterfactuals</term>
					<term>representation learning</term>
					<term>long-tailed distribution</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite the impressive performance of recent unbiased Scene Graph Generation (SGG) methods, the current debiasing literature mainly focuses on the long-tailed distribution problem, whereas it overlooks another source of bias, i.e., semantic confusion, which makes the SGG model prone to yield false predictions for similar relationships. In this paper, we explore a debiasing procedure for the SGG task leveraging causal inference. Our central insight is that the Sparse Mechanism Shift (SMS) in causality allows independent intervention on multiple biases, thereby potentially preserving head category performance while pursuing the prediction of high-informative tail relationships. However, the noisy datasets lead to unobserved confounders for the SGG task, and thus the constructed causal models are always causal-insufficient to benefit from SMS. To remedy this, we propose Two-stage Causal Modeling (TsCM) for the SGG task, which takes the long-tailed distribution and semantic confusion as confounders to the Structural Causal Model (SCM) and then decouples the causal intervention into two stages. The first stage is causal representation learning, where we use a novel Population Loss (P-Loss) to intervene in the semantic confusion confounder. The second stage introduces the Adaptive Logit Adjustment (AL-Adjustment) to eliminate the long-tailed distribution confounder to complete causal calibration learning. These two stages are model agnostic and thus can be used in any SGG model that seeks unbiased predictions. Comprehensive experiments conducted on the popular SGG backbones and benchmarks show that our TsCM can achieve state-of-the-art performance in terms of mean recall rate. Furthermore, TsCM can maintain a higher recall rate than other debiasing methods, which indicates that our method can achieve a better tradeoff between head and tail relationships.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Scene Graph Generation (SGG), first proposed by Scherrer et al. <ref type="bibr" target="#b0">[1]</ref>, is an emerging, critical, and challenging intermediate scene-understanding task and has received increasing attention, especially during the past few years <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, due to its potential to be a bridge between computer vision and natural language processing. SGG aims to generate a structured representation of a scene that jointly describes objects and their attributes, as well as their pairwise relationships, and is typically formulated as a set of &lt;subject, relationship, object&gt; triplets. Such representations can provide a deep understanding of a scene, and thus SGG has been employed for many downstream tasks, such as imagetext retrieval <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b3">[4]</ref>, visual question answering <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, visual captioning <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, etc.</p><p>While early SGG work has made significant progress <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, which, however, as discussed in <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, tends to generate biased predictions, i.e., informative fine-grained relationships (e.g., standing on) are predicted as less informative coarsegrained relationships (e.g., on) due to the long-tailed distribution problem. As an example, we consider the distribution of the relationships in VG150 <ref type="bibr" target="#b12">[13]</ref>, a popular benchmark in the SGG task, which, as shown in Fig. <ref type="figure" target="#fig_8">1 (a)</ref>, clearly suffers from severe long-tailed distribution problems. The SGG model, naturally, cannot learn to represent the features of the head and tail relationships simultaneously from the skewed distribution and, hence, easily yields False Predictions (FP) on head relationships (see Fig. <ref type="figure" target="#fig_8">1 (c)</ref>).</p><p>For the above biased predictions, many debiasing methods <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> have been proposed to overcome this problem. Unlike earlier work, the primary goal of debiasing methods, however, is to pursue the unbiased scene graphs. Existing debiasing methods can be roughly categorized into four groups: 1) Resampling methods <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref> upsample the tail relationships and/or downsample the head relationships to rebalance the training data distribution. 2) Reweighting methods <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref> revise the contribution of different relationships during training, for instance, weighting the prediction loss to strengthen the model's representation ability to the tail categories. 3) Adjustment methods <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref> modify the learned biased model to obtain unbiased predictions, for example, by adjusting the output logits to increase the likelihood of more informative fine-grained relationships. 4) Hybrid methods <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref> combine some/all of the above methods. Although debiasing research is rather active in the SGG community, the above methods often fall short in preserving head category performance while pursuing the prediction of informative tail relationships <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b13">[14]</ref>. More importantly, the current debiasing methods mainly focus on a single bias, i.e., the long-tailed distribution problem, whereas it overlooks other biases.</p><p>Unlike existing work that focuses on a single bias, we reveal the fact that there are multiple biases for the SGG task in this paper. This stems from our observation that some of the False Predictions (FP) are clearly not caused by the long-tailed distribution bias, e.g., FP on tail relationships (see Fig. <ref type="figure" target="#fig_8">1 (c)</ref>). We therefore argue that there are other biases that have not yet been observed and explored with current debiasing methods.</p><p>Cognitive psychology <ref type="bibr" target="#b33">[34]</ref> and studies on the human visual arXiv:2307.05276v1 [cs.CV] 11 Jul 2023</p><p>Head relationships, e.g., 'on'=34.8%, 'has'=13.6%, etc.</p><p>Tail relationships, e.g., 'standing on'=0.7%, 'carrying'=0.3%, etc.</p><p>Head objects, e.g., 'man'=4.7%, 'tree'=4.2%, etc.</p><p>Tail objects, e.g., 'bird'=0.4%, 'tie'=0.2%, etc. False Predictions (FP) on head relationships, and FP on tail relationships (further divided into two cases depending on whether the predictions are tail-similar relationships or not) of the MotifsNet <ref type="bibr" target="#b8">[9]</ref> framework. Formally, in this paper, head relationships refer to on, has, in, of, and wearing, since they account for more than 50%, and the rest are tail relationships, but note often different grouping criteria were also adopted in the literature <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>. For a given category, similar and dissimilar relationships are those found within and outside its population, respectively. A formal introduction to the concept of population is provided in Section 3.3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Standing on</head><p>system <ref type="bibr" target="#b34">[35]</ref> suggest that humans struggle to distinguish similar objects. Inspired by this fact, we hypothesize that the source of the bias of FP on tail relationships is semantic confusion, which refers to two relationships sharing similar semantic information. For instance, as shown in Fig. <ref type="figure" target="#fig_0">1</ref> (b), both carrying and holding are semantic concepts composed of a people and objects in his/her hands. To demonstrate our premise, as shown in Fig. <ref type="figure" target="#fig_0">1</ref> (c), we additionally split FP on tail relationships into FP on tailsimilar relationships and FP on tail-dissimilar relationships. As expected, most of the FP on tail relationships occur in tail-similar relationships. This suggests that SGG models, like humans, have difficulties in distinguishing similar relationships. As a result, we take semantic confusion as the second bias.</p><p>For the multiple biases in the SGG task, we seek causal inference <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>, an inference procedure that achieves impressive performance in statistics, econometrics, and epidemiology, which has also attracted significant attention in the deep learning community in recent years. Our central insight is that the Sparse Mechanism Shift (SMS) <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref> in causal inference allows independent intervention on multiple biases, thereby potentially preserving head category performance while pursuing higher performance in fine-grained tail relationships. Inspired by Pearl Causal Hierarchy (PCH) <ref type="bibr" target="#b39">[40]</ref>, in particular its highest layer, counterfactual, we pose two questions: 1) What happens if there is no semantic confusion between any two relationships in the observed data? 2) What happens if the distribution of relationships in the observed data is balanced? To answer these two counterfactual questions, we first build Structural Causal Models (SCM) <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, a causal modeling method that can support counterfactual inference, based on two observed biases as confounders. In practice, unfortunately, not all confounders for the SGG task can be observed, which means that the built SCM is causal-insufficient (see Section 3.2 for a detailed analysis). Causal-insufficient assumption will invalidate the SMS hypothesis because the variables of the SCM are entangled in this case. Put another way, when we use existing causal intervention methods to overcome the observed biases, unobserved biases could be disturbed and bring about unwanted consequences. To allow SCM with causal-insufficient assumption to also benefit from the SMS hypothesis, we decouple the causal interventions into two stages and, on this basis, propose a novel causal modeling method, Two-stage Causal Modeling (TsCM), tailored for the SGG task.</p><p>Our TsCM consists of two stages: 1) Stage 1, causal representation learning, where despite the causal-insufficient assumption of the built SCM, we find that similarity relationships have inherently sparse properties (see Section 3.3), and, hence, sparse perturbations and independent interventions on semantic confusion bias are attainable. To achieve this, we proposed the Population Loss (P-Loss), which intervenes in the model training process to increase the prediction gap between similar relationships, allowing the trained model to obtain the causal representation that can eliminate the semantic confusion bias. As a result, this stage disentangles the confusion bias from the variables of the built SCM, thereby getting a disentangled factorization. 2) Stage 2, causal calibration learning, where thanks to the disentangled factorization obtained in stage 1, we calibrate the model's causal representation to remove the long-tailed distribution bias. Specifically, this is achieved by our proposed Adaptive Logit Adjustment (AL-Adjustment), which can adaptively learn a set of adjustment factors from the observed data for sparse perturbations and independent interventions.</p><p>In summary, the contributions of our work are three-fold:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>We thoroughly analyze the sources of bias in the biased SGG model and experimentally verify the bias, i.e., semantic confusion bias, ignored by current debiasing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>We propose a new causal modeling framework, Twostage Causal Modeling (TsCM), to disentangle the multiple biases from the biased SGG model. Our TsCM decouples the causal intervention into two stages. Stage 1 leverages the proposed P-Loss to remove the semantic confusion bias and obtain a disentangled factorization even in the case of insufficient causality, thereby providing the causal representation that can distinguish similar relationships. Stage 2 further calibrates the causal representation to eliminate the long-tailed distribution bias by using the proposed AL-Adjustment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>Comprehensive experiments on various SGG backbones and the popular benchmark demonstrate the state-of-theart mean recall rate of the proposed TsCM. Furthermore, our TsCM can maintain a higher recall rate than other debiasing methods, achieving a better tradeoff between head and tail relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Scene Graph Generation</head><p>SGG produces a structured representation of the scene by assigning appropriate relationships to object pairs and enables a more comprehensive understanding of the scene for intelligent agents <ref type="bibr" target="#b0">[1]</ref>. Most early works struggled with employing advanced network structures, e.g., Convolutional Neural Network, Recurrent Neural Network, Graph Neural Network, for better feature extraction and representation <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b42">[43]</ref>. Despite continuous improvements in the recall rate, these methods fall into the trap of biased prediction, i.e., informative fine-grained relationships are predicted as less informative coarse-grained relationships. As a result, debiasing methods have attracted unprecedented attention in the SGG community in recent years.</p><p>To keep focus, here we mainly review the debiasing methods for the SGG task. Existing debiasing methods can be roughly categorized into four groups as follows.</p><p>Resampling methods downsample the head category relationships and/or upsample the tail ones to balance the training data distribution, and often the prior knowledge, e.g., language prior, is taken into account, too. For instance, instead of relying on box-level annotations, SegG <ref type="bibr" target="#b18">[19]</ref> argues that pixel-level grounding would naturally be more valuable and, hence, create segmentation annotations for the SGG dataset with the help of auxiliary datasets. Recently, TransRwt <ref type="bibr" target="#b19">[20]</ref> rectified the skewed distribution by creating an enhanced dataset using Internal Transfer and External Transfer, the former for transferring the coarse-grained relationships to the fine-grained ones and the latter for re-labeling the relationships that are missing annotations. However, resampling methods may lead to overfitting (oversampling) or information loss (undersampling) by altering relationship category sample distributions.</p><p>Reweighting methods design debiasing loss functions to make the model pay more attention to the tail category relationships or to create advanced networks to improve the representation ability of these relationships. Some works in this group begin by extracting prior knowledge from biased distributions, e.g., cognitive structure in CogTree <ref type="bibr" target="#b20">[21]</ref>, predicate lattice in FGPL <ref type="bibr" target="#b29">[30]</ref>, relationship probability distribution in PPDL <ref type="bibr" target="#b16">[17]</ref>, etc., and then combine the proposed debiasing loss functions to supervise the model training. Besides, GCL <ref type="bibr" target="#b15">[16]</ref> presents a Stacked Hybrid-Attention network to achieve intra-modal refinement and intermodal interaction and then enhances the representation ability of tail relationships. Nonetheless, reweighting methods may result in an imbalanced focus on relationship categories and suboptimal, unstable performance due to manual or heuristic weight adjustments.</p><p>Adjustment methods adjust the output of the biased trained model to obtain unbiased predictions. The adjustment procedure can be based on prior knowledge. For example, Logit-reweight <ref type="bibr" target="#b43">[44]</ref> uses label frequencies to adjust the logit outputs by the biased model. DLFE <ref type="bibr" target="#b23">[24]</ref> considers the SGG task as a Learning from Positive and Unlabeled data (PU learning) problem, where a target PU dataset contains only positive examples and unlabeled data. However, its prior knowledge, i.e., label frequencies, is obtained iteratively during the training process by the proposed Dynamic Label Frequency Estimation method. Furthermore, adjustment procedures can also be modeled by causal inference. For instance, TDE <ref type="bibr" target="#b13">[14]</ref> first builds a causal graph for the SGG task and then draws counterfactual causality from the trained model to infer the effect from the negative bias. Note that adjustment methods will increase computational complexity with post-training output adjustments and may cause a decline in other relationship category performances.</p><p>Hybrid methods combine some/all of the above techniques. HML <ref type="bibr" target="#b27">[28]</ref> and CAME <ref type="bibr" target="#b32">[33]</ref> first divide the long-tailed distribution into some balanced subsets. HML <ref type="bibr" target="#b27">[28]</ref> then trains the model with coarse-grained relationships and finally learns the finegrained categories. While CAME <ref type="bibr" target="#b32">[33]</ref> then proposes to use a mixture of experts to handle different subsets. RTPB <ref type="bibr" target="#b28">[29]</ref> enhances the impact of tail relationships on the training process based on prior bias and designs a contextual encoding backbone network to improve feature extraction capabilities. However, hybrid methods Increase implementation complexity, more challenging parameter tuning, higher computational costs, and potential performance instability due to the interplay of combined methods.</p><p>Despite achieving impressive results, the above debiasing methods focus almost exclusively on a single bias, i.e., longtailed distribution bias, which clearly, makes complete debiasing impossible. Moreover, these methods sacrifice head relationships in pursuit of tail category performance. Differently, our method considers multiple biases and removes them using the causal inference technique. Our causal model TsCM consists of two stages covering both the reweighting and adjustment approaches. Thanks to the SMS mechanism, the two stages in our method independently intervene in different biases. In contrast, the different stages in existing hybrid methods only intervene in the same bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Causal Inference</head><p>Causal analysis has achieved encouraging performance in health, social, behavioral sciences, etc., and it has also attracted increasing attention in deep learning community in recent years, such as scene graph generation <ref type="bibr" target="#b13">[14]</ref>, out-of-distribution generalization <ref type="bibr" target="#b44">[45]</ref>, and salient object detection <ref type="bibr" target="#b45">[46]</ref>. Compared with deep learning models, the causal inference approaches can eliminate the influence of biases/confounders when making predictions <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b46">[47]</ref>. A typical causal inference paradigm usually starts with establishing a graphical model, e.g., the Structural Causal Model (SCM) <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b47">[48]</ref>, which models the dependencies of causal variables. It then intervenes in (e.g., dointerventions <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b46">[47]</ref>) these variables to pursue causal inference of interest. The models can therefore be generalized to different distributions.</p><p>It should be emphasized that the above interventions can be achieved because the causal variables satisfy the principle of sparse perturbation and independent intervention, which is the cornerstone of causal inference. The independent intervention principle in causality emphasizes that the conditional distribution of each causal variable, given its causes (i.e., its mechanism), does not inform or influence the other mechanisms. The sparse perturbation principle refers to small distribution changes that tend to manifest themselves in a sparse or local way <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b48">[49]</ref>. The sparse principle is extended by independence, which can be seen as a consequence of independence, too <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b47">[48]</ref>. Benefiting from the independent intervention principle, Scherrer et al. <ref type="bibr" target="#b49">[50]</ref> decompose the causal mechanism into modules with knowledge, which, different from monolithic models where full knowledge will be learned directly, enables adaptation to distribution shifts by only updating a subset of parameters. Thanks to the sparse perturbation principle, Ahuja et al. <ref type="bibr" target="#b48">[49]</ref> achieve weakly supervised representation learning by perturbing the causal mechanism sparsely. Inspired by the above work and the multiple confounders in the SGG task, the model proposed in this paper removes these confounders independently and sparsely, which allows our model to preserve the performance of the head categories while pursuing debiasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>The primary goal of SGG is to model the objects existing in the scene and their pairwise relationships. Most existing works first detect the objects (e.g., "man", "horse" ) in the scene with an object detector and then recognize their pairwise relationships (e.g., "riding", "standing on") with a relationship classifier. The object detector extracts information about objects, like their bounding boxes, categories, and features. Then the relationship classifier predicts relationships for each pair of objects. Simply, a scene graph is a set of visual triples in the formulation of &lt;subject, relationship, object&gt;. Formally, let D = {(x i , y i )} N D i=1 denote the observed data with N D samples, where x i is i-th image and y i ∈ R Ni×K is N i relationships in this sample, y ij is K dimension one-hot vector denoting the label of j-th relationship in x i . We therefore need to label the dataset D with visual triplets</p><formula xml:id="formula_0">{&lt; (o sub i , b sub i ), y i , (o obj i , b obj i ) &gt;} N D i=1 to support model training, where o sub i , o obj i ∈ R Ni×C and b sub i , b obj i ∈ R Ni×4</formula><p>, o ij and b ij denoting the category and bounding box information of subject or object of j-th relationship in x i respectively. C and K are the numbers of categories of objects and relationships in the observed data, respectively. Although labeling the visual triples is very costly, early efforts have contributed a few benchmarks to the SGG community, such as Visual Genome <ref type="bibr" target="#b50">[51]</ref>, Scene Graph <ref type="bibr" target="#b0">[1]</ref>, and Open Images V4 <ref type="bibr" target="#b51">[52]</ref>. However, SGG models trained on these datasets typically suffer from two challenges: (1) Semantic confusion, and (2) Long-tailed distribution.</p><p>In this work, we address the above two challenges from the perspective of causal inference. Specifically, in Section 3.2, we firstly consider the aforementioned two challenges, i.e., semantic confusion and long-tailed distribution, as confounders for the standard SGG framework (see Fig. <ref type="figure" target="#fig_2">2 (a)</ref>). Therefore, our method leverages the data-level confounders to model the causality for the SGG task. Compared to model-level confounders <ref type="bibr" target="#b13">[14]</ref>, our approach is model-agnostic, i.e., transferable to arbitrary SGG models. We then propose the Population Loss in Section 3.3 to remove the semantic confusion confounder and get a disentangled factorization for the causal model (see Stage 1 in Fig. <ref type="figure" target="#fig_2">2 (b)</ref>). Next, in Section 3.4, we propose AL-Adjustment to remove the long-tailed distribution confounder to obtain unbiased predictions (see Stage 2 in Fig. <ref type="figure" target="#fig_2">2</ref>). Finally, in Section 3.5, we show that our method is Fisher-consistent and highlight the differences from existing statistical-based approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Modeling structural causal model</head><p>One can use a variety of frameworks to model the causality of their system of interest, such as Causal Graphical Models (CGM), Structural Causal Models (SCM), and Potential Outcomes (PO) <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b47">[48]</ref>. The causality modeling ability of CGM is limited since it cannot support counterfactual inference. PO is active in the system with binary treatment variables, but it is awkward when dealing with special treatment and outcome variables. Considering the limitations of CGM and PO, in this work, we model the causality using SCM, a structural method that contains variables, structural functions, and distributions over the variables (see Definition 1). Definition 1 (Structural Causal Model (SCM) <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>). A structural causal model (SCM ) M is a 4-tuple ⟨V, U, F, P (U)⟩, where</p><formula xml:id="formula_1">U = {U 1 , U 2 , • • •, U n } is a set of exogenous variables; V = {V 1 , V 2 , • • •, V n } is a set of endogenous (observed) variables; F = {F 1 , F 2 , • • •, F n }</formula><p>is the set of structural functions determining V; P (U) is a distribution over the exogenous variables. Definition 2 (Submodel <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>). For the SCM M, let V be a set of variables in V, and v a particular value of</p><formula xml:id="formula_2">V. A submodel M v (of M ) is a 4-tuple: M v = ⟨V, U, F v , P (U)⟩, where F v = {F i : V i / ∈ V} ∪ { V ← v },</formula><p>and all other components are preserved from M.</p><p>Endogenous variables are the fundamental elements of an SCM. However, determining variable V in the SGG task is very challenging because its inputs, i.e., images, differ greatly from the structured units in traditional causal discovery and reasoning tasks <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b47">[48]</ref>. Inspired by FP on head/tail relationships in Fig. <ref type="figure" target="#fig_0">1</ref>, in this paper, we propose a modelagnostic data-level variable that takes semantic confusion and long-tailed distribution as the confounders. As a result, the induced submodel M v in our work is ⟨V, U, F v , P (U)⟩ (see <ref type="bibr">Definition 2)</ref>. Where V = {X, Y, S, L}, X is input (images in SGG task), Y is output (relationships), S is the semantic confusion confounder, L is the long-tailed distribution confounder;</p><formula xml:id="formula_3">U = {U X , U Y , U S , U L }; F v = {F 1 , F 2 , F 3 , F 4 , F 5 }; P (U X , U Y , U S , U L )</formula><p>is the distribution over the exogenous variables. The SCM is shown in Fig. <ref type="figure" target="#fig_3">3</ref> (Biased SGG), and thus the structural equations are:</p><formula xml:id="formula_4">S = P (S), L = P (L), X = F 1 (L, P (L)) + F 2 (S, P (S)), Y = F 3 (X, P (X)) + F 4 (L, P (L)) + F 5 (S, P (S)),<label>(1)</label></formula><p>Intuitively, we can directly use interventions to remove the confounders in SCM (see Definition 3). These interventions, however, do not update P (U), and thus the intervened results are noisy causal effects in most cases <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b41">[42]</ref>. Definition 3 (Interventions in SCM <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b47">[48]</ref>). An intervention do (V i := v ′ ) in an SCM M is modeled by replacing the i-th structural equation by V i := v ′ , where v ′ is a V i -independent value. Definition 4 (Counterfactual in SCM <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b47">[48]</ref>). A counterfactual in an SCM M is modeled by replacing the i-th structural equation by V i := v ′ and update the P (U), where v ′ shares the same meaning as it does in Definition 3. The above counterfactual intervention induces the submodel M Vi . Assumption 1 (Causal-insufficient). The exogenous variable U in M satisfies that:</p><formula xml:id="formula_5">P (U 1 , . . . , U n ) ̸ = P (U 1 ) × P (U 2 ) × • • • × P (U n ).</formula><p>Fortunately, counterfactual, the highest-level reasoning procedure of cognitive ability <ref type="bibr" target="#b35">[36]</ref>, overcomes this limitation by imagining pre/post-intervention results (see <ref type="bibr">Definition 4)</ref>. Note that counterfactual is unfalsifiable since its imaginary results cannot be observed. However, significant designs (e.g., average  treatment effect) in statistics, econometrics, and epidemiology can estimate the counterfactuals and are proven effective. The principle difference between intervention and counterfactual is that the latter updates P (U) when manipulating the structural equations <ref type="bibr" target="#b41">[42]</ref>. Thus, one can partially seek the intervention technique to calculate the counterfactuals. Inspired by the above facts, we therefore leverage the counterfactual inference to eliminate the semantic confusion confounder S and long-tailed distribution confounder L to obtain an unbiased SCM M S,L v for the SGG task. The counterfactuals results can be calculated as:</p><formula xml:id="formula_6">E[Y | X, do (S := s), do (L := l)] = E S E L E[Y | X, s, l] = s l E[Y | X, s, l]P (s)P (l).<label>(2)</label></formula><p>where s/l is a S/L-independent value. do interventions involve manipulating one or more variables to investigate causal relationships <ref type="bibr" target="#b35">[36]</ref>, where do (L := l) signifies setting the value of variable L to l and observing the outcome. Note that, causal sufficiency is an essential assumption for Equation (2), i.e., the exogenous variables U i are jointly independent:</p><formula xml:id="formula_7">P (U 1 , . . . , U n ) = P (U 1 ) × P (U 2 ) × • • • × P (U n ).</formula><p>Thanks to the causal sufficiency assumption, the endogenous variables V in M can be formulated as a causal/disentangled factorization:</p><formula xml:id="formula_8">P (V 1 , V 2 , . . . , V n ) = n i=1 P (V i | pa(V i )) ,<label>(3)</label></formula><p>where pa(V i ) are the parents of V i . In the SGG task, confounders can be, for instance, the observed confounders such as the semantic confusion confounder and the long-tailed distribution confounder, as well as unobserved ones caused by missing labeled relationships and mislabeled relationships. The latter has been discussed in much literature <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b30">[31]</ref>. We therefore do not expect and cannot model a causal sufficient SCM for the SGG task due to the unobserved confounders. In accordance with this, we assume that M v is causal-insufficient (see Assumption 1), and thus its endogenous variables can only be formulated as an entangled factorization:</p><formula xml:id="formula_9">P (V 1 , V 2 , . . . , V n ) = n i=1 P (V i | V i+1 , . . . , V n ) .<label>(4)</label></formula><p>Assumption 2 (Sparse Mechanism Shift (SMS) <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>). Small distribution changes tend to manifest themselves sparsely or locally in the causal/disentangled factorization (see Equation ( <ref type="formula" target="#formula_8">3</ref>)), that is, they should usually not affect all factors simultaneously. Assumption 2 tells us that for a disentangled factorization, a sparse operation allows the learner to remove the confounders and even generalize to unseen distributions. However, unfortunately, M v is causal-insufficient since the SGG task inevitably contains the unobserved confounders, and it, therefore, cannot benefit from the SMS hypothesis. In response to this challenge, we decouple causal modeling into two stages to achieve the goal of intervening in the endogenous variables sparsely:</p><formula xml:id="formula_10">E[Y | X, do (S := s) , do (L := l)] = E X [E[Y ′ | X, do(S := s)] stage 1 + E[Y | X, Y ′ , do(L := l)] stage 2 ].<label>(5)</label></formula><p>where stage 1 exploits the inherent sparse property of similar relationships, even under the condition of causal-insufficient assumption, it can achieve sparse perturbations on variable S to remove the semantic confusion confounder as well as learn </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Causal representation learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Population Loss</head><p>In the SGG task, similar relationships are those with only slightly different visual and semantic features. However, existing SGG models perform poorly in discriminating these similar relationships, for instance, easily mispredicting standing on as walking on or vice versa. This is not surprising, as distinguishing these similar relationships is even challenging for humans. Naturally, one may be curious and then imagine: Would the above error still occur if standing on and walking on are no longer similar? While this only happens in our imagined spaces, it can be formally calculated by counterfactual (see Definition 4) in the causal inference paradigm:</p><formula xml:id="formula_11">P (y|x, do(S := s)) = P (y|x, do(S := s 1 )) -P (y|x, do(S := s 0 )),<label>(6)</label></formula><p>where (x, y) is a particular value of (X, Y ), (X, Y ) ∼ D; s 1 and s 0 indicate that the relationship y is similar or dissimilar to other relationships, respectively. In fact, the above counterfactual formulated in Equation ( <ref type="formula" target="#formula_11">6</ref>) simulates the potential outcomes of different interventions, i.e., do(S := s 1 ) and do(S := s 0 ).</p><p>It is critical because one can often benefit from imagining; for instance, Einstein's thought experiment brought the Special Theory of Relativity to the world. Despite being promising, however, calculating Equation ( <ref type="formula" target="#formula_11">6</ref>) takes a lot of work. TDE <ref type="bibr" target="#b13">[14]</ref> is highly relevant to our work, which simulates two interventions by inferring pre/post-processed inputs to obtain counterfactual results. However, it requires two model inferences for each input, thereby introducing unbearable costs. In contrast, Average Treatment Effect (ATE) <ref type="bibr" target="#b52">[53]</ref> estimates the counterfactuals in one shot by leveraging statistical knowledge. Thanks to its high estimation efficiency, ATE is a commonly used technique in causal inference, such as exploring the ATE estimation with binary treatments and continuous outcomes in <ref type="bibr" target="#b53">[54]</ref> and discussing the propensity score if the average treatment effect is identifiable from observational data in <ref type="bibr" target="#b54">[55]</ref>. Inspired by ATE, in this paper, we use statistical knowledge from the observed data D to estimate counterfactuals:</p><formula xml:id="formula_12">E[y|x, do(S := s)] = E X [E(Y |X, do(S := s 1 )) -E(Y |X, do(S := s 0 ))].<label>(7)</label></formula><p>Definition 5 (Population in SGG). Let y = {y 1 , y 2 , • • •, y K } be relationship categories in observed data D, and let P yi α be population of y i . Then, P yi α is a relationship set containing the α most similar relationships to y i .</p><p>Formally, we first extract knowledge P α , P α = {P yi α } K i=1 , from the observed data (the calculation of P α is placed in Section 3.3.2). P yi α is the population of relationship y i , a relationship set containing the statistical knowledge of similar relationships; see Definition 5. Inspired by penalized head categories in <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b43">[44]</ref>, here we punish similar relationships based on knowledge P α . Specifically, we discard the widely used cross-entropy loss ℓ and supervise the SGG model f through the proposed Population Loss (P-Loss) l:</p><formula xml:id="formula_13">l(P α , y, f (x)) = log[1 + y ′ ∈P y α π y ′ π y × e (f y ′ (x)-fy(x)) + y ′ / ∈P y α ,y ′ ̸ =y e (f y ′ (x)-fy(x)) ],<label>(8)</label></formula><formula xml:id="formula_14">θ * = arg min θ E[ E (x,y)∼D l(P α , y, f (x))],<label>(9)</label></formula><p>where π is category frequencies on the observed data D and θ * is the parameter used to parameterize SGG model f θ * . x and y (y = {y i } K i=1 ) are the input (e.g., image) and output relationship categories, respectively. As an example, for relationship y i , the P-Loss l penalizes its confusing relationships with the help of statistical knowledge π and P yi α extracted from the observed data D. The penalty term in Equation ( <ref type="formula" target="#formula_13">8</ref>) can be seen as do(S := s) in Equation ( <ref type="formula" target="#formula_11">6</ref>) since it intervenes in the sparse P α and makes the model more capable of distinguishing between similar relationships. In other words, P-Loss can remove the confounder S in M v . Thus, the counterfactual can be estimated by the statistical knowledge P α as:</p><formula xml:id="formula_15">P (y|x, do(S := s)) = P (y|x, P α , π) = f θ * (x) .<label>(10)</label></formula><p>Assumption 3 (Similar relationships are sparse). Let y = {y i } K i=1 be relationships in observed data D. For any relationship y i (i ∈ {1, 2, • • • , K}), there exist k relationships similar to it. Then, it holds that k ≪ K. Despite achieving the goal of calculating the counterfactuals, however, it is critical to note that our causal-insufficient assumption determines that our manipulation (do(S := s)) in Equation ( <ref type="formula" target="#formula_12">7</ref>) may perturb other variables simultaneously since the entangled factorization of M v does not satisfy the SMS hypothesis. Fortunately, in this paper, we empirically find that similar relationships hold the sparse property (see Assumption 3). Based on our observations, relationships within the SGG dataset are often similar to a few specific relationships but not to most others. For example, standing on is only similar to on, walking on, etc., but differs from most other relationships. Therefore, Assumption 3, which shows similar relationships have the sparse property that SMS highlighted, guarantees that even an entangled factorization can be intervened sparsely on the confounder S. In other words, even if M v is causalinsufficient, our proposed P-Loss can still intervene in S without worrying about perturbing other exogenous variables, such as confounder L.</p><p>Furthermore, we argue that do(S := s) partially disentangles the M v as it removes the confounder S and allows us to get a better causal representation. Thus, the endogenous variables in the induced submodel M S v can be roughly formulated as a disentangled factorization:</p><formula xml:id="formula_16">P (X, Y, L) . = P (X) × P (Y ) × P (L). (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>Disentangled factorization is considered to be the key to representation learning due to its potential in abstract reasoning, interpretability, generalization to unseen scenarios, etc. Although it has attracted significant attention, evaluating the disentangled representation is still challenging <ref type="bibr" target="#b55">[56]</ref>. We will design experiments in the ablation study (Section 4.3) to demonstrate our disentangled claim in Equation <ref type="bibr" target="#b10">(11)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Calculate the relationship-populations</head><p>As a supplement to Section 3.3.1, this section shows how to calculate the relationship-populations P α . For P α , we give three assumptions (Assumptions 4-6) based on the inspirations of causality as well as the hallmarks of the relationships in the SGG task. Assumption 4 (Relationship-population is learner independent). Let f θ1 and f θ2 be SGG models parameterized by θ 1 and θ 2 , respectively. Then,</p><formula xml:id="formula_18">E[P ′ α | f θ1 ] = E[P ′′ α | f θ2 ]. Assumption 5 (Relationship-population is distribution insensitive).</formula><p>Let D 1 obs and D 2 obs be two observed datasets. Then,</p><formula xml:id="formula_19">E[P ′ α | D 1 obs ] = E[P ′′ α | D 2 obs ]</formula><p>. Assumption 6 (Relationship-population is asymmetric). Let y i and y j be two relationships. Then, y i ∈ P yj α ⇎ y j ∈ P yi α . Assumption 4 states that whether two relationships are similar is irrelevant to the SGG model. Standing on and walking on, for instance, should share the same features no matter what model we use. In light of this, we should not use any SGG model when calculating P α . Assumption 5 illustrates no correlation between the distribution of two relationships and their similarity. We highlight this because we observe that the SGG dataset often suffers from the long-tailed distribution issue at both the relationship and object levels, which may perturb the calculation procedure of P α . Assumption 6 is inspired by the fact that cause and effect are directed, i.e., the cause can determine the effect, but not vice versa.</p><p>To satisfy Assumption 4, we design a model-agnostic relationship feature extraction method. Consider two objects, o i and o j , whose bounding boxes are b</p><formula xml:id="formula_20">i x, b i ȳ , b i h , b i w and [b j x, b j ȳ , b j h , b j w ],</formula><p>respectively. Where, as an example, for the bounding box of o i , (b i</p><p>x, b i ȳ ) is the center point, and b i w and b i h are the width and height. We denote the model-agnostic feature of the relationship between these two objects as ψ &lt;oi,oj &gt; :</p><formula xml:id="formula_21">[ 2(b i x + b j x) -(b i w + b j w ) 4b i h , 2(b i ȳ + b j ȳ ) -(b i h + b j h ) 4b i h , 2(b i x + b j x) + (b i w + b j w ) 4b i h , 2(b i ȳ + b j ȳ ) + (b i h + b j h ) 4b i h , b j h b i h , b j w b i w ].<label>(12)</label></formula><p>Our proposed model-agnostic feature emphasizes the relative position between object pairs, which is inspired by the fact that it is intrinsically linked to the relationships in SGG. For example, the object pairs of standing on are up-down, while behind is front-back. Thanks to the molecules of Equation ( <ref type="formula" target="#formula_21">12</ref>), ψ &lt;oi,oj &gt; is position-insensitive, as the upper left corners of all object pairs are moved to the same coordinate. Besides, the denominator of Equation ( <ref type="formula" target="#formula_21">12</ref>) normalizes the object pairs, ensuring that ψ &lt;oi,oj &gt; is scale-insensitive. The position/scale-insensitive design in our model-agnostic feature extraction method can overcome the problem that the distance of the lens can make the same relationship vary greatly, thereby generalizing to unseen object pairs. Before extracting the relationship features in the observed data using the above method, however, there is a problem that needs to address: The object-level long-tailed distribution problem may perturb the model-agnostic feature extraction. Consider an example with 90% &lt;people, standing on, road&gt; and 10% &lt;people, standing on, beach&gt; in the observed data. It is fusing the features of standing on will undoubtedly bias towards &lt;people, standing on, road&gt; due to its dominance in the observed data, which is detrimental to extracting the feature of standing on. We address this problem by extracting the object-to-object level features ξ y and then normalizing them. Our method is inspired by Inverse Probability Weighting (IPW) <ref type="bibr" target="#b56">[57]</ref>, a bias correction method commonly used in statistics, econometrics, epidemiology, etc. As a result of this improvement, the proposed method satisfies Assumption 5 since it eliminates the disturbance of distribution from the feature extraction. Specifically, ξ y ∈ R 4 (C × C × K × 6) is a four-dimensional statistic:</p><formula xml:id="formula_22">ξ y =    ξ (1,1) y ξ (1,2) y • • • ξ (1,C) y • • • • • • • • • • • • ξ (C,1) y ξ (C,2) y • • • ξ (C,C) y    ,<label>(13)</label></formula><p>where ξ (i,j)</p><formula xml:id="formula_23">y = {ξ (i,j)</formula><p>yt } K t=1 is the normalized features of relationship &lt; o i , y t , o j &gt;, and it can be calculated as: | are the fusion features and numbers of all relationships &lt; o i , y t , o j &gt; in the observed data D, respectively. We then calculate the feature of each relationship, for instance, for the t-th relationship ξ yt :</p><formula xml:id="formula_24">ξ (i,j) yt = ξ &lt;oi,oj &gt; yt /|ξ &lt;oi,oj &gt; yt |,<label>(14)</label></formula><formula xml:id="formula_25">ξ yt = C i=1 C j=1 ξ (i,j) yt /C 2 § . (<label>15</label></formula><formula xml:id="formula_26">)</formula><p>For relationship-populations P α , P α = {P yi α } K i=1 , the population of y t can be calculated as:</p><formula xml:id="formula_27">P yt α = arg smal α t,t ′ ∈{1,2,••• ,K},t̸ =t ′ ξ yt -ξ y t ′ ,<label>(16)</label></formula><p>where arg smal α is a computation kernel that selects similar relationships based on feature distances. As an example, Equation ( <ref type="formula" target="#formula_27">16</ref>) takes the α relationships with the smallest feature distance from ξ yt . Our method guarantees that the head and tail relationship categories have the same population scale and thus satisfy Assumption 6. As such, different relationships yield different feature distance thresholds in Equation ( <ref type="formula" target="#formula_27">16</ref>), resulting in asymmetric relationship-populations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Causal calibration learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Adaptive Logit Adjustment</head><p>Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the severe long-tailed distribution problem in the SGG task. The current SGG models, therefore, easily predict informative fine-grained relationships as less informative coarsegrained relationships. For instance, looking at is predicted as near.</p><p>To end this, let us seek the imagination again: If one collected the balanced data, or, in particular, looking at and near share the same distribution in the observed data D, will the above error still occur? Similar to Equation ( <ref type="formula" target="#formula_11">6</ref>), this question can also be answered with the counterfactual:</p><formula xml:id="formula_28">P (y|x, do(L := l)) = P (y|x, do(L := l 1 )) -P (y|x, do(L := l 0 )),<label>(17)</label></formula><p>where l 1 and l 0 represent the head and tail categories, respectively; as such, Equation <ref type="bibr" target="#b16">(17)</ref> simulates the potential outcomes of different interventions, i.e., do(L := l 1 ) and do(L := l 0 ). Inspired by logit adjustment <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b57">[58]</ref>, <ref type="bibr" target="#b58">[59]</ref>, in which the class prior knowledge (also known as adjustment factors) extracted from the training data are used to adjust the model results, we §. Object pair &lt; o i , o j &gt; theoretically has C 2 triplet categories. However, the annotations in SGG dataset are very sparse, i.e., &lt; o i , o j &gt; usually only covers a few triplet categories, resulting in a much smaller number of triplet categories than C 2 . As a result, the numerator term in Equation ( <ref type="formula" target="#formula_25">15</ref>) should be determined by the observed data D. For instance, for yt, the numerator term should be the number of triplet categories composed of yt in D.</p><p>extract the statistical knowledge from the observed data D via model f θ * to estimate counterfactuals:</p><formula xml:id="formula_29">E[y|x, do(L := l)] = E X [E(Y |X, do(L := l 1 )) -E(Y |X, do(L := l 0 ))].<label>(18)</label></formula><p>Specifically, we leverage the extracted statistical knowledge, adjustment factors T β , to maximize the recall rate of f θ * on the observed data (the computation of T β is placed in Section 3.4.2). Compared to existing logit adjustment methods, our adjustment factors T β not only extract knowledge from D but, more importantly, it fits adaptively to the SGG model f θ * . Holding this advantage, our adjustment factors T β outperform the traditional adjustment method by a clear margin (see the experiments in Section 4.3). Despite this, the knowledge extracted directly from f θ * and D is still suboptimal. We think this is because background relationships will perturb the model training, resulting in 1) the logits of the foreground relationships being less discriminative; 2) the logits of alternating positive and negative make it impossible for the learned factors to adjust to some predictions correctly (see the qualitative results in Fig. <ref type="figure" target="#fig_12">7</ref>). Where foreground relationships in the SGG task are those within annotated triplets in the observed data, and background relationships are the ones that are absent between object pairs. To overcome these problems, we augment the logits of f θ * :</p><formula xml:id="formula_30">fθ * ,y (x) = e f θ * ,y (x) × f bg θ * ,y (x),<label>(19)</label></formula><p>where f bg θ * ,y (x) is the logit of the corresponding background relationship output by f θ * . f bg θ * ,y (x) acts as a guidance term that can make the augmented logits fθ * ,y (x) more discriminative, which is inspired by the impressive performance of the traditional adjustment methods in the simple classification task. Augmented logits allow us to get better adjustment factors, and then the final prediction y x of input x can be calculated as:</p><formula xml:id="formula_31">y x = arg max y∈{y1,••• ,yK} {( fθ * ,y (x) × T β ) y∈T β ∩ ( fθ * ,y (x)) y / ∈T β }. (<label>20</label></formula><formula xml:id="formula_32">)</formula><p>Consider a typical false prediction: For an input x belonging to the tail category y i , the largest and next largest output logits correspond to y j and y i , where y j is a head category. However, our proposed adjustment factors can correct this false prediction by penalizing the logits corresponding to the head categories and encouraging the tail categories, thus, eliminating the negative effect caused by the long-tailed distribution problem. Our proposed AL-Adjustment acts as do(L := l) in Equation <ref type="bibr" target="#b17">(18)</ref> to remove the confounder L in the induced submodel M S v . Therefore, the estimated counterfactual by the statistical knowledge T β is:</p><formula xml:id="formula_33">P (y|x, do(L := l)) = P (y|x, T β , fθ * ) = fθ * ,y (x) × T β .<label>(21)</label></formula><p>In Section 3.3.1, we show that M S v can be decomposed into a disentangled factorization. As a result, manipulating the factor in M S v , in most cases, should not affect all factors simultaneously (SMS hypothesis, see Assumption 2). We therefore argue that do(L := l) in Equation <ref type="bibr" target="#b17">(18)</ref> does not affect the exogenous variables X and Y , and then the induced submodel M S,L v obtained in this stage can be further roughly formulated as a disentangled factorization:</p><formula xml:id="formula_34">P (X, Y ) . = P (X) × P (Y ). (<label>22</label></formula><formula xml:id="formula_35">)</formula><p>We will design experiments in the ablation study (Section 4.3) to demonstrate our disentangled claim in Equation ( <ref type="formula" target="#formula_34">22</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Calculate the adjustment factors</head><p>This subsection shows how to extract statistical knowledge T β from the observed data D and the SGG model fθ * , which can be used to adjust the logits to remove the confounder L in submodel M S v . For adjustment factors T β , we have two assumptions (Assumptions 7-8). Assumption 7 (Adjustment effect should be sparse). Let T Assumption 7 is inspired by the SMS hypothesis, and it holds due to the disentangled factorization (Equation ( <ref type="formula" target="#formula_16">11</ref>)) obtained in stage 1. This assumption also stems from our insight that the false predictions in most cases belong to the largest few logits (see Table <ref type="table" target="#tab_7">8</ref>). As such, Assumption 7 allows us to correct the false predictions with sparse adjustment factors. However, the existing methods adjust all logits. Assumption 8 views the SMS hypothesis through the relationship level to highlight the causality between the relationships. Here is an intuition for this assumption: To correct any false prediction logits of a binary classification task, we only have to adjust one of these two logits. Assumption 8 allows us to learn the adjustment factors of each relationship independently.</p><p>Our proposed adaptive adjustment factors T β is a twodimensional (K × β) matrix:</p><formula xml:id="formula_36">T β =    T y1,l1 β T y1,l2 β • • • T y1,l β β • • • • • • • • • • • • T yK,l1 β T yK,l2 β • • • T yK,l β β    ,<label>(23)</label></formula><p>where T yi,lj β adjusts the j-th largest prediction logit to correspond to the i-th relationship, and it can be calculated as: </p><p>where T ∈ R and TP (X,Y ) (f ) is a computation kernel that calculates the true prediction numbers (e.g., recall rate (R@K) in SGG task) of model f on dataset (X, Y ). D yi,lj is all relationships with the j-th largest prediction logit to correspond to the i-th category reasoned by f θ * , and it can be further divided into true predictions T D yi,lj obs and false predictions FD yi,lj obs . Thus, our method is to maximize the recall rate of model f θ * on the observed data D by the adjustment factors learned in Equation <ref type="bibr" target="#b23">(24)</ref>.</p><p>We then propose an upper-lower bound-based method to compute Equation ( <ref type="formula" target="#formula_37">24</ref>) quickly. As shown in Fig. <ref type="figure">4</ref>, for each relationship in T D yi,lj obs , we can compute a lower bound that keeps the correct prediction. Similarly, we can obtain for each relationship in FD yi,lj obs an upper bound that can adjust it to the correct prediction. We denote the lower and upper bounds of D yi,lj as ⊻ yi,lj and ⊼ yi,lj , respectively. It is clear that we only need to let T yi,lj β satisfy the most bounds to maximize the number of correct predictions. Therefore, maximizing the recall rate of model f θ * on the observed data D by the adjust factor is equivalent to another task that finds the factor that satisfies the most bounds in ⊻ yi,lj and ⊼ yi,lj . As a result, T yi,lj β in Equation ( <ref type="formula" target="#formula_37">24</ref>) can also be calculated by:  <ref type="formula" target="#formula_38">25</ref>) will be adjusted to:</p><formula xml:id="formula_38">T yi,lj β = arg max t∈T ( |⊻ y i ,l j | m=1 1(t ≥ ⊻ m yi,lj )+ |⊼ y i ,l j | n=1 1(t &lt; ⊼ n yi,lj )),<label>(25)</label></formula><formula xml:id="formula_39">T yi,lj β = arg max t∈T ( min(|⊻ y i ,l j |,|⊼ y i ,l j |) m=1 1(t ≥ ⊻ ′ m yi,lj )+ min(|⊻ y i ,l j |,|⊼ y i ,l j |) n=1 1(t &lt; ⊼ ′ n yi,lj )). (<label>26</label></formula><formula xml:id="formula_40">)</formula><p>Note that in Equation ( <ref type="formula" target="#formula_39">26</ref>), T yi,lj β is an interval with extremely close upper and lower bounds, thereby selecting any value within this interval as the adjustment factor has a negligible impact on the results. Consequently, in this paper, we randomly sample a value from T yi,lj β as the learned adjustment factor. Finally, for each relationship, we learn only β adjustment factors corresponding to the 1-β positions in the prediction logits. Thus, this sparse adjustment mechanism enables our method to satisfy Assumption 7. Meanwhile, the adjustment factors for each relationship are independently learned by Equation ( <ref type="formula" target="#formula_39">26</ref>), so our method satisfies Assumption 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Discussion</head><p>This subsection first shows that our method is Fisher consistent, i.e., models based on popular learning strategies (e.g., empirical risk minimization (ERM)) lead to the Bayes optimal rule of classification that minimizes the balanced error <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b60">[61]</ref>. This is very important for the SGG task, as it prevents the model from heading down a confusing path, i.e., biased towards predicting head categories for a high recall rate. We then highlight the differences and advantages of the proposed causal framework with existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">Fisher consistency</head><p>To demonstrate that our method is Fisher consistent, we start with the Bayes perspective. <ref type="bibr" target="#b43">[44]</ref> thoroughly explored the relationship between the posterior probability of the balanced class-probability function P bal (y | x) and the unbalanced one P (y | x), and it defined P bal (x | y) ∝ P (x | y)/P (x). In the SGG task, however, we find that the models suffer from confounders other than the long-tailed distribution problem, such as semantic confusion confounder, as well as unobserved ones like missing labeled relationship confounder and mislabeled relationship confounder. As such, here we define:</p><formula xml:id="formula_41">P bal (x | y) ∝ P (x | y)/P (x)P (S)P (U o ),<label>(27)</label></formula><p>where U o is unobserved confounders. Also, consider:</p><formula xml:id="formula_42">P bal (y | x) = (P bal (x | y)P bal (y))/P bal (x),<label>(28)</label></formula><p>we therefore have:</p><p>P bal (y | x) ∝ (P (x | y)P (X)P bal (y))/(P (X)</p><formula xml:id="formula_43">P (Y )P (S)P (U o )P bal (x)). (<label>29</label></formula><formula xml:id="formula_44">)</formula><p>For fixed class-conditionals P (x|y), the optimal predictions will not be affected by P (Y ) <ref type="bibr" target="#b43">[44]</ref>, hence:</p><formula xml:id="formula_45">P bal (y | x) ∝ P (y | x)/(P (S)P (U o )P bal (x)).<label>(30)</label></formula><p>Then, according to the SMS hypothesis (Assumption 2) and small distribution changes hypothesis in <ref type="bibr" target="#b38">[39]</ref>, there exists an intervention I such that:</p><formula xml:id="formula_46">arg max y∈{y1,••• ,yK} f θ I (x) = arg max y∈{y1,••• ,yK} ( fθ * ,y (x) × T β ). (<label>31</label></formula><formula xml:id="formula_47">)</formula><p>Note that we cannot model the intervention I directly since the induced submodel M v can only be formulated as an entangled factorization. We define the adjustment factors corresponding to intervention I as T I β , that is:</p><formula xml:id="formula_48">arg max y∈{y1,••• ,yK} f θ I (x) = arg max y∈{y1,••• ,yK} ( fθ * ,y (x) × T I β ). (<label>32</label></formula><formula xml:id="formula_49">)</formula><p>Based on the Theorem 1 in the <ref type="bibr" target="#b61">[62]</ref>, we have</p><formula xml:id="formula_50">argmax y∈{y1,••• ,yK} fθ * ,y (x) = argmax y∈{y1,••• ,yK} P (x | y), thus: arg max y∈{y1,••• ,yK} f θ I (x) = arg max y∈{y1,••• ,yK} ((P (y | x)P (y)/P (x)) × T I β ).<label>(33</label></formula><p>) Considering both Equation <ref type="bibr" target="#b29">(30)</ref> and Equation ( <ref type="formula" target="#formula_50">33</ref>), when</p><formula xml:id="formula_51">T I β ∝ P (Y )/(P (S)P (X)P (U o )P bal (x)),<label>(34)</label></formula><p>then</p><formula xml:id="formula_52">arg max y∈{y1,••• ,yK} f θ I (x) = arg max y∈{y1,••• ,yK} P bal (y | x). (<label>35</label></formula><formula xml:id="formula_53">)</formula><p>This means that our manipulations on confounder S and confounder L can lead to a minimal balanced error (mR@K in SGG task), and thus our method is Fisher consistent. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2">Sparsity and independency</head><p>Causal representation learning (stage 1) in our proposed causal framework is inspired by the loss-weighting methods <ref type="bibr" target="#b62">[63]</ref>, <ref type="bibr" target="#b63">[64]</ref>, <ref type="bibr" target="#b64">[65]</ref>, <ref type="bibr" target="#b65">[66]</ref>, and causal calibration learning (stage 2) is inspired by post-hoc adjustment approaches <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b57">[58]</ref>, <ref type="bibr" target="#b58">[59]</ref>. In all of these heuristic works, statistical priors (e.g., category frequencies) are extracted from the observed data to calibrate the decision boundaries. However, we leverage the extracted statistical knowledge to estimate the counterfactual to eliminate confounders S and L. Where the statistical knowledge in stage 1 is extracted via the proposed model-agnostic method, and that of in stage 2 is adaptively extracted from the learned model f θ * and the observed data D. Besides, our method differs fundamentally from these works in that the interventions using knowledge are sparse and independent, which is the key to preserving head category performance while pursuing the prediction of highinformative tail relationships. Causal inference models the observed data with modular knowledge, and interventions on partial knowledge can achieve rapid distribution changes <ref type="bibr" target="#b37">[38]</ref>. These sparse perturbations simulate human learning, i.e., the reuse of most knowledge, and thus, have great potential for practical applications, especially for open-world learning. Both stage 1 and stage 2 of our causal framework are sparse, specifically, α in P α and β in T β . The former means that each relationship only takes the α most similar ones as its population. Therefore, Equation (8) only sparsely adjusts the loss for very few relationships. The latter represents that only the top-β predict logits will be adjusted. Thus, Equation ( <ref type="formula" target="#formula_31">20</ref>) is a sparse adjustment technique.</p><p>Independent Causal Mechanisms (ICM) <ref type="bibr" target="#b49">[50]</ref> tells us that changing one causal mechanism does not change others. Note that ICM requires causal sufficiency, but the SGG task does not satisfy this. However, as analyzed in Section 3.3.1, our proposed P-Loss can intervene in confounder S without losing the independent property due to the sparse nature of similar relationships. The result of stage 1 can be roughly formulated as a disentangled factorization. Furthermore, the different logit positions of T β are independently learned. These enable independent intervention in stage 2.</p><p>In addition, <ref type="bibr" target="#b43">[44]</ref> shows that loss-reweight and logit-reweight are identical, and merging them brings no further gain. The latter even cancels out the improvement from the former in some cases. However, the post-hoc adjustment factors in our causal framework are adaptively learned from the model obtained in the previous stage and thus always yield positive adjustment effects. More importantly, our method can make the decision boundaries between similar relationships clearer, which traditional methods cannot achieve. We show the two above merge routes in Fig. <ref type="figure" target="#fig_9">5</ref> to compare the boundary adjustment processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Implementation</head><p>Datasets. We evaluate our method on VG150 <ref type="bibr" target="#b12">[13]</ref>, a subset of the VG dataset <ref type="bibr" target="#b50">[51]</ref> that includes the most frequent 150 object categories and 50 relationship classes. VG150 has about 94k images, and we follow the split in <ref type="bibr" target="#b13">[14]</ref>, i.e., 62k training images, 5k validation images, and 26k test images.</p><p>Evaluation modes. Following MotifsNet <ref type="bibr" target="#b8">[9]</ref>, we use three evaluation modes: 1) Predicate classification (PredCls). This mode requires the SGG model to predict relationships given the ground truth boxes and object classes. 2) Scene Graph Classification (SGCls). This mode requires the SGG model to predict object classes and relationships given the ground truth boxes. 3) Scene Graph Detection (SGDet). This mode requires the SGG model to predict object classes, boxes, and relationships.</p><p>Evaluation metrics. Following <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, we adopt three evaluation metrics: 1) Recall rate (R@K). R@K is one of the most commonly used evaluation metrics, which calculates the fraction of times the correct relationship is predicted in the top K confident relationship predictions. Typically, K is set to 20, 50, and 100, i.e., R@20, R@50, and R@100. 2) mean recall rate (mR@K). mR@K calculates the mean of the R@K for each relationship. Compared with R@K, mR@K can comprehensively evaluate the model performance on all relationship categories, especially the tail relationships. 3) Mean of R@K and mR@K (MR@K). Due to the severely long-tailed distribution, the SGG model only needs to perform well on a few head categories to achieve high R@K. Although some current works can achieve a high mR@K, they greatly sacrifice the R@K of the head categories, which is certainly not what we expected since the head categories account for significant proportions in realistic scenarios. We therefore aim to achieve a favorable tradeoff between R@K and mR@K, allowing the model to accommodate both head and tail relationships, which in turn enhances the practical value of the generated scene graph. For this purpose, we calculate the mean of R@K and mR@K, denoted as MR@K, to evaluate the model comprehensively.</p><p>Training and testing. We evaluate our model-agnostic method on the popular SGG backbones, including MotifsNet <ref type="bibr" target="#b8">[9]</ref>, VCTree <ref type="bibr" target="#b10">[11]</ref>, and Transformer <ref type="bibr" target="#b66">[67]</ref>, in the repository provided by <ref type="bibr" target="#b13">[14]</ref>. We follow most of the settings of this repository: 1) The object detector in the pipeline is the Faster R-CNN <ref type="bibr" target="#b67">[68]</ref> with the backbone of ResNeXt-101-FPN <ref type="bibr" target="#b68">[69]</ref>. The detector was trained with the VG training set and achieved 28.14 mAP on the VG test set. 2) The detector is then frozen and outputs the bounding boxes, categories, and features of the detected objects for the relationship classifier in the pipeline. The classifier is supervised by our proposed P-Loss and optimized by SGD. For MotifsNet <ref type="bibr" target="#b8">[9]</ref> and VCTree <ref type="bibr" target="#b10">[11]</ref>, the batch size and initial learning rate are set to 12 and 0.01, while these parameters in Transformer <ref type="bibr" target="#b66">[67]</ref> are 16 and 0.001. We set α in Equation ( <ref type="formula" target="#formula_13">8</ref>) to 5 unless otherwise mentioned. 3) In the testing phase, the logits will first be augmented by Equation <ref type="bibr" target="#b18">(19)</ref> and then adjusted by the adjustment factors learned by Equation ( <ref type="formula" target="#formula_31">20</ref>) to obtain the final predictions. The β in Equation ( <ref type="formula" target="#formula_36">23</ref>) is set to 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison with state-of-the-art</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Backbones and baselines</head><p>Backbones. We evaluate our proposed method with three popular SGG backbones, i.e., MotifsNet <ref type="bibr" target="#b8">[9]</ref>, VCTree <ref type="bibr" target="#b10">[11]</ref>, and Transformer Quantitative results (mR@K) of our method and other baselines on the MotifsNet backbone PredCls SGCls SGDet mR@20 mR@50 mR@100 AVG mR mR@20 mR@50 mR@100 AVG mR mR@20 mR@50 mR@100 AVG mR MotifsNet (backbone) <ref type="bibr" target="#b8">[9]</ref> 12 AVG mR is the average of mR@20, mR@50, mR@100. ∆, ♦, and ♢ indicate resampling methods, reweighting methods, and adjustment methods, respectively. † and ‡ indicate model-agnostic and model-dependent, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 2</head><p>Quantitative results (mR@K) of our method and other baselines on the VCTree backbone PredCls SGCls SGDet mR@20 mR@50 mR@100 AVG mR mR@20 mR@50 mR@100 AVG mR mR@20 mR@50 mR@100 AVG mR VCTree (backbone) <ref type="bibr" target="#b10">[11]</ref> 12 AVG mR is the average of mR@20, mR@50, mR@100. ∆, ♦, ♢, † and ‡ are with the same meanings as in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 3</head><p>Quantitative results (mR@K) of our method and other baselines on the Transformer backbone PredCls SGCls SGDet mR@20 mR@50 mR@100 AVG mR mR@20 mR@50 mR@100 AVG mR mR@20 mR@50 mR@100 AVG mR Transformer (backbone) <ref type="bibr" target="#b66">[67]</ref> 12.4 AVG mR is the average of mR@20, mR@50, mR@100. ∆, ♦, ♢, † and ‡ are with the same meanings as in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 5</head><p>Quantitative results (MR@K) of our method and other baselines on the MotifsNet, VCTree, and Transformer backbones MR@K is the average of AVG mR and AVG R . ∆, ♦, ♢, † and ‡ are with the same meanings as in Table <ref type="table">1</ref>. traditional logit-adjusted methods <ref type="bibr" target="#b43">[44]</ref> in terms of unbiased prediction. We attribute this to the inability of conventional logit-adjusted methods, particularly those employing nonheuristic prior knowledge, to effectively adjust for severely biased models in the presence of extremely long-tailed data within the SGG task. Compared with other methods, for instance, in PredCls mode, TsCM achieves 11.7%/13.8% gains on MotifsNet/Transformer. We believe that these exciting improvements come from sparse perturbations in our method, which do not perturb the SGG model largely, thus preserving the performance of head categories while pursuing unbiased predictions. 6) Table <ref type="table">5</ref> shows that our method can achieve a better tradeoff between R@K and mR@K. Besides methods that benefit from recall rate (e.g., Logit-reweight <ref type="bibr" target="#b43">[44]</ref>), our method achieves 6.4%/7.4%/5.4% improvements in the backbones of MotifsNet/VCTree/Transformer. This illustrates that our method also preserves head category performance while pursuing informative tail category predictions. Qualitative results analysis. Fig. <ref type="figure" target="#fig_11">6</ref> shows the qualitative results generated by the original MotifsNet <ref type="bibr" target="#b8">[9]</ref> and MotifsNet equipped with our TsCM. From these qualitative results, we have the following observations: 1) Our proposed method tends to predict more informative relationships, for instance, { &lt;girl, standing on, ski&gt; vs &lt;girl, on, ski&gt; } and { &lt;dog, laying on, bed&gt; vs &lt;dog, on, bed&gt; }. We believe these improvements are due, in part, to the fact that our proposed AL-Adjustment can refine less  simple information (e.g., the distance between objects). We think the optimized features are achieved by our proposed P-Loss, which can learn representations that build causality between relationships. The evaluation mode here is PredCls.</p><formula xml:id="formula_54">PredCls SGCls SGDet AV G mR AV G R MR@K AV G mR AV G R MR@K AV G mR AV G R MR@K MotifsNet (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input images</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation Study</head><p>Exploring the contributions of the two stages. TsCM consists of P-Loss and AL-Adjustment to eliminate the confounders S and L, respectively. We first ablate our proposed causal framework using different combinations of P-Loss and AL-Adjustment, and the results are shown in Table <ref type="table" target="#tab_5">6</ref>. The results show that both components of TsCM contribute a lot to the performance. Specifically, for AL-Adjustment, it can significantly improve the mean recall rate of the model. For example, VCTree <ref type="bibr" target="#b10">[11]</ref> equipped with AL-Adjustment has 11.2%/14.9%/16.5% gains on the metrics of mR@20/50/100. Although we can only observe trivial boosts for P-Loss alone, its purpose is to obtain causal representations that can well distinguish similar relationships. Therefore, these trivial boosts can be seen as by-products of the pursuit of causal representations. Table <ref type="table" target="#tab_5">6</ref> shows that the causal representation greatly enhances AL-Adjustment. For instance, AL-Adjustment equipped with P-Loss achieves 8.7%/8.4%/8.4% improvements on the backbone of VCTree <ref type="bibr" target="#b10">[11]</ref>. We also present the output logits, the augmented logits, and the adjusted logits in Fig. <ref type="figure" target="#fig_12">7</ref> to show the process of P-Loss and AL-Adjustment adjusting the SGG model. These results show that AL-Adjustment can adjust less informative predictions Ordering i means that the logit corresponding to the correct prediction is ranked in the i position. The evaluation mode here is PredCls.</p><p>to high-informative ones. For example, &lt;bear, on, chair&gt; is adjusted to &lt;bear, standing on, chair&gt; (see Fig. <ref type="figure" target="#fig_12">7</ref> (a)). Then, thanks to the proposed P-Loss, compared with MotifsNet <ref type="bibr" target="#b8">[9]</ref>, TsCM performs better at distinguishing similar relationships, i.e., similar relationships have more significant logit gaps. As an example shown in Fig. <ref type="figure" target="#fig_12">7</ref> (b): In the output logits of MotifsNet <ref type="bibr" target="#b8">[9]</ref>, carrying has a 1.31× logit gap over holding, but in TsCM, it is 2.18×. Large logit gaps will clarify the decision boundary between similar relationships, thereby overcoming semantic confusion. Finally, we can observe the issues discussed in Section 3.4.1, i.e., the logits of the foreground relationships being less discriminative and the logits of alternating positive and negative. It is possible, however, to unify logits to positive values and improve their discrimination, especially for the top few large logits, by using our logit augmentation method (Equation ( <ref type="formula" target="#formula_30">19</ref>)). We argue that the logit augmentation procedure is critical for learning adjustment factors. To prove this, we ablate our logit augmentation method and show the results in Table <ref type="table" target="#tab_6">7</ref>. These results demonstrate that our logit augmentation method can provide significant improvements. In addition, the guidance term f bg θ * ,y (x) in Equation ( <ref type="formula" target="#formula_30">19</ref>) also contributes a lot to the results. We think this is because the guidance term can make the augmented logits fθ * ,y (x) more discriminative.</p><p>Hyperparameters in TsCM. This subsection ablates two critical hyperparameters, α in Equation ( <ref type="formula" target="#formula_13">8</ref>) and β in Equation <ref type="bibr" target="#b22">(23)</ref>, that enable causal intervention on model sparsity. Fig. <ref type="figure" target="#fig_13">8</ref> varies the α and β, and the results show that a suitable combination of hyperparameters is essential for our TsCM. We observe that the performance of the model increases when β ∈ <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3]</ref>, but decreases when β &gt; 3. This can be explained by the facts shown in Table <ref type="table" target="#tab_7">8</ref>: For a false prediction, the logit corresponding to the ground truth category is often ranked at the top of all logits and, in most cases, is the second largest. Therefore, most false predictions can be corrected by adjusting the first few logits. Table <ref type="table" target="#tab_7">8</ref> shows the distribution of the ordering of the logits corresponding to the correct categories in the false predictions. Furthermore, adjusting logits that are ranked low often requires  The evaluation mode here is PredCls. sharp adjustment factors (refer to the logits shown in Fig. <ref type="figure" target="#fig_13">8</ref>), which in effect, learn a set of factors that overfit the observed data. Fig. <ref type="figure" target="#fig_13">8</ref> also shows that the model performs best when α = 5. We think that when α is small, P α will miss some similar relationships, and conversely when α is large, many dissimilar relationships will be included in P α . It is worth noting that α should be set according to observed data. In other words, for 50 relationship categories in VG150, α = 5 is the optimal choice, but α may have other optimal values for other datasets.</p><p>Disentangled claim in Equation <ref type="bibr" target="#b10">(11)</ref>. We set up three baseline loss functions to support our disentangled claims: 1) Crossentropy loss ℓ. 2) Modified P-Loss l▷ . This baseline loss function replaces P α in Equation ( <ref type="formula" target="#formula_13">8</ref>) with P ▷ α . P ▷ α means to take the α relationships with the largest feature distance (dissimilar relationships) as relationship-population. 3) Modified P-Loss l△ . This baseline loss function replaces P α in Equation ( <ref type="formula" target="#formula_13">8</ref>) with P △ α . P △ α means to take the α ′ relationships with the largest feature distance as relationship-population (α ′ &gt; α, α ′ = 8). 4) Modified P-Loss l◁ . This baseline loss function replaces P α in Equation ( <ref type="formula" target="#formula_13">8</ref>) with P ◁ α . P ◁ α means to take the α relationships with the largest feature distance belonging to the tail category as the relationship-population. Table <ref type="table" target="#tab_8">9</ref> reports the model results supervised by different loss functions. The results of ℓ, l◁ , and l△ are very close, which proves that intervening in dissimilar tail relationships has very limited impacts. Even with the possible inclusion of head categories, the supervised performance of l▷ is still close to ℓ and l◁ . This further shows that only intervening in dissimilar relationships has tiny perturbations to the model. However, P-Loss observes drastic changes due to intervening in similar relationships. Hence, we argue that P-Loss can intervene in similar relationships sparsely. In other words, it eliminates confounder S without affecting other confounders. As a result, the model trained with P-Loss can be roughly formulated as a disentangled factorization.</p><p>Disentangled claim in Equation <ref type="bibr" target="#b21">(22)</ref>. This subsection designs a new metric, i.e., mean Correction Rate (mC@K), to support our disentangled claims. mC@K calculates the balanced fraction of rates that the false relationships are corrected, where K shares the same meaning as in mainstream metrics (e.g., R@K and mR@K). In keeping with the claim to be demonstrated, Fig. <ref type="figure" target="#fig_14">9</ref> shows mC@K on the tail categories, which allows us to evaluate the performance of the AL-Adjustment in alleviating the long-tailed distribution problem. These results clearly show that AL-Adjustment can adjust a considerable number of false predictions of tail categories to correct ones, and, hence, the longtailed distribution confounder can be removed by our proposed adjustment procedure. Taking together the disentangled claim in Equation <ref type="bibr" target="#b10">(11)</ref>, we can naturally come to the disentangled claim in Equation <ref type="bibr" target="#b21">(22)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we have proposed a novel causal modeling framework, TsCM, for unbiased scene graph generation, which decouples the causal intervention into two stages to eliminate semantic confusion bias and long-tailed distribution bias, where the former bias is rarely explored in the existing debiasing methods. In stage 1, we analyzed that the SCM modeled for SGG is always causal-insufficient and the sparsity of relationship categories. On this basis, a causal representation learning method is proposed to achieve sparse interventions on semantic confusion bias in the case of insufficient causality. As a result, this stage also provides a disentangled factorization. Benefiting from this factorization, stage 2 then proposes causal calibration learning to intervene sparsely and independently in the long-tailed distribution bias to achieve unbiased predictions. Experiments were conducted on the popular SGG backbones and dataset, and our method achieved state-of-the-art debiasing performance. Furthermore, our method achieved a better tradeoff between recall rate and mean recall rate thanks to the sparse causal interventions.</p><p>Although our method can remove multiple biases in the SGG task, it is still challenging to overcome the unobservable biases. In the future, we will focus on exploring the unobservable biases and develop the automatic debiasing causal framework to pursue unbiased SGG predictions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The motivations of TsCM. (a) illustrates the long-tailed distribution bias. (b) shows the semantic confusion bias. (c) reports the True Predictions (TP),False Predictions (FP) on head relationships, and FP on tail relationships (further divided into two cases depending on whether the predictions are tail-similar relationships or not) of the MotifsNet<ref type="bibr" target="#b8">[9]</ref> framework. Formally, in this paper, head relationships refer to on, has, in, of, and wearing, since they account for more than 50%, and the rest are tail relationships, but note often different grouping criteria were also adopted in the literature<ref type="bibr" target="#b29">[30]</ref>,<ref type="bibr" target="#b30">[31]</ref>,<ref type="bibr" target="#b31">[32]</ref>,<ref type="bibr" target="#b32">[33]</ref>. For a given category, similar and dissimilar relationships are those found within and outside its population, respectively. A formal introduction to the concept of population is provided in Section 3.3.2.</figDesc><graphic coords="2,28.85,146.79,553.79,92.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Adjusted logitsUnbiased prediction: Predicting the correct relationships. (e.g., &lt;woman, holding, racket&gt;) Biased prediction: Predicting fine-grained relationships as coarse-grained relationships (e.g., &lt;woman, has, racket&gt;).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The illustrations of the standard framework and our proposed pipeline. The standard SGG framework is supervised by cross-entropy loss. While TsCM consists of two stages: Stage 1 learns causal representation learning that can better distinguish semantic confusion as well as disentangle the causalinsufficient SCM. Specifically, we achieve this through the proposed Population Loss. Stage 2 leverages the proposed Adaptive Logit Adjustment to calibrate the entangled factorization from the previous stage. As a result, the adjusted logits can avoid the SSG model biases towards the head relationships.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The proposed Causal Graphical Model (SCM) for SGG. S and L are data-level confounders, i.e., the semantic confusion confounder and the longtailed distribution confounder. X and Y are the input image and the predicted relationships, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>factors of i-th and j-th prediction logits, respectively. Then, P (y i | x) = P (y i | x, T yj β ), P (y j | x) = P (y j | x, T yi β ). Assumption 8 (Adjustment factors should be independent of each other). Let T yi β and T yj β are adjustment factors of i-th and jth prediction logits, respectively. Then, P (y | x, M ax(T yi β , T yj β )) = M ax(P (y | x, T yi β ), P (y | x, T yj β )), where M ax(•|•) is a computation kernel to take the maximum value of the corresponding positions of the two sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>y)∼D y i ,l j ( fθ * ,y (x) × T yi,lj β ) true prediction with adjustment -TP (x,y)∼D y i ,l j ( fθ * ,y (x)) ) true prediction without adjustment ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>[ 5 .Fig. 4 .</head><label>54</label><figDesc>Fig. 4. The proposed upper-lower bound-based method of calculating Equation (24). Each False/True prediction logit corresponds to an upper/lower bound. The most optimal adjustment factor needs to satisfy the most bounds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>where 1 (</head><label>1</label><figDesc>•) is an indicator function (equals 1 if the expression is true and 0 for false) and | • | is the length/size of the given set/list. However, we further find that the long-tailed distribution problem may perturb the adjustment effect of T yi,lj β . Specifically, if y i is a head category, | ⊻ yi,lj | ≪ | ⊼ yi,lj |, and if it is a tail category, then | ⊼ yi,lj | ≫ | ⊻ yi,lj |. It is due to biased training caused by the skewed distribution. To this issue, for relationship y i , we randomly sample the same number (e.g., min(|⊻ yi,lj |, |⊼ yi,lj |)) of bounds ⊻ ′ yi,lj and ⊼ ′ yi,lj separately from the original lower/upper bounds to ensure unbiased adjustment factors. Therefore, Equation (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The merging effect of statistical-based methods (top) and our proposed causal components (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Qualitative results of our method and baseline approach (MotifsNet<ref type="bibr" target="#b8">[9]</ref>). Different relationship predictions are highlighted in blue.</figDesc><graphic coords="13,309.31,360.75,81.59,61.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The ablation study results of our method and baselines. Each image shows only one relationship for clarity. The red and blue bounding boxes represent subjects and objects, respectively.</figDesc><graphic coords="14,150.45,113.62,418.57,70.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Model performance with different α and β. The evaluation mode here is PredCls. The shaded areas represent the upper and lower bounds of performance for different combinations of α and β.</figDesc><graphic coords="15,42.89,33.42,148.10,100.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. The performance of tail categories on the proposed metric mC@K. The evaluation mode here is PredCls.</figDesc><graphic coords="15,42.36,431.83,244.07,190.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>a disentangled representation of M v at the same time, see Section 3.3. Based on the disentangled factorization obtained, we then, in stage 2, manipulate variable L in a sparse way to remove the long-tailed distribution confounder, see Section 3.4. Both stages are sparse interventions, thereby satisfying the SMS assumption, which allows our method to achieve unbiased prediction while protecting the performance of head relationships. Specifically, stage 1, involving interventions on similar relationships, naturally doesn't harm head relationships.</figDesc><table><row><cell>Moreover, the adjustment mechanism in stage 2, adaptively</cell></row><row><cell>learned from stage 1, further ensures the protection of head</cell></row><row><cell>relationships.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 6</head><label>6</label><figDesc>Results under different combinations of P-Loss and AL-Adjustment</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>PredCls</cell><cell>SGCls</cell><cell>SGDet</cell></row><row><cell></cell><cell cols="2">P-L AL-Adj</cell><cell>mR@20/50/100</cell><cell>mR@20/50/100</cell><cell>mR@20/50/100</cell></row><row><cell></cell><cell>✗</cell><cell>✗</cell><cell>12.2/15.5/16.8</cell><cell>7.2/9.0/9.5</cell><cell>5.2/7.2/8.5</cell></row><row><cell>MotifsNet</cell><cell>✓ ✗ ✓</cell><cell>✗ ✓ ✓</cell><cell>12.9/16.9/20.1 24.4/30.7/33.3 31.8/37.8/40.9</cell><cell>7.4/9.6/11.2 14.2/17.1/18.4 18.7/22.4/23.8/</cell><cell>5.3/7.6/8.8 8.1/10.8/13.3 13.7/17.4/19.7</cell></row><row><cell></cell><cell>✗</cell><cell>✗</cell><cell>12.4/15.4/16.6</cell><cell>6.3/7.5/8.0</cell><cell>4.9/6.6/7.7</cell></row><row><cell>VCTree</cell><cell>✓ ✗ ✓</cell><cell>✗ ✓ ✓</cell><cell>12.7/16.4/19.8 23.6/30.3/33.1 32.3/38.7/41.5</cell><cell>8.4/10.6/11.4 17.6/20.5/22.7 23.4/26.9/28.9</cell><cell>5.8/7.4/9.8 10.4/13.7/15.9 12.5/16.9/19.3</cell></row><row><cell>Transformer</cell><cell>✗ ✓ ✗ ✓</cell><cell>✗ ✗ ✓ ✓</cell><cell>12.4/16.0/17.5 13.1/17.2/20.3 24.8/31.2/33.9 32.8/40.1/42.3</cell><cell>7.7/9.6/10.2 9.4/11.3/12.4 14.3/17.8/19.4 19.6/23.7/25.1</cell><cell>5.3/7.3/8.8 6.6/8.1/9.4 9.8/13.5/16.5 13.8/18.3/21.2</cell></row><row><cell cols="6">P-L and AL-Adj represent the two key components of TcCM: P-Loss and</cell></row><row><cell cols="4">AL-Adjustment, respectively.</cell><cell></cell><cell></cell></row></table><note><p>informative predictions into high-informative outputs, and we will discuss this in the ablation study. 2) Our method performs well in distinguishing similar relationships, for example, { &lt;wire, attached to, surfboard 1&gt; vs &lt;surfboard 1, has, wire&gt; }. Besides, for objects where two bounding boxes do not intersect, our method can still generate meaningful relationships, e.g., { &lt;person, behind, girl&gt; vs &lt;person, near, girl&gt; }. It is evident from the above improvements that our method can optimize the features of the model and classify relationships based on more than just</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 7</head><label>7</label><figDesc>Results obtained by different logit augmentation strategies</figDesc><table><row><cell></cell><cell cols="2">Logit augmentation</cell><cell cols="3">mR@20 mR@50 mR@100</cell></row><row><cell>MotifsNet</cell><cell cols="2">No augmentation e f θ  *  ,y (x) × 1 e f θ  *  ,y (x) × 2</cell><cell>28.3 30.9 30.7</cell><cell>34.1 36.4 36.5</cell><cell>37.4 39.7 40.3</cell></row><row><cell></cell><cell>e f θ  *  ,y (x) × f</cell><cell>bg θ  *  ,y (x)</cell><cell>31.8</cell><cell>37.8</cell><cell>40.9</cell></row><row><cell>VCTree</cell><cell cols="2">No augmentation e f θ  *  ,y (x) × 1 e f θ  *  ,y (x) × 2</cell><cell>29.6 31.6 31.4</cell><cell>35.1 38.1 37.3</cell><cell>38.2 40.8 40.9</cell></row><row><cell></cell><cell>e f θ  *  ,y (x) × f</cell><cell>bg θ  *  ,y (x)</cell><cell>32.3</cell><cell>38.7</cell><cell>41.5</cell></row><row><cell>Transformer</cell><cell cols="2">No augmentation e f θ  *  ,y (x) × 1 e f θ  *  ,y (x) × 2</cell><cell>30.4 31.9 32.2</cell><cell>36.2 38.4 38.0</cell><cell>38.7 41.7 41.5</cell></row><row><cell></cell><cell>e f θ  *  ,y (x) × f</cell><cell>bg θ  *  ,y (x)</cell><cell>32.8</cell><cell>40.1</cell><cell>42.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 8</head><label>8</label><figDesc>The distribution (%) of the ordering of the logits corresponding to the correct categories in the false predictions</figDesc><table><row><cell></cell><cell cols="5">Ordering 2 Ordering 3 Ordering 4 Ordering 5 Ordering 6</cell></row><row><cell>MotifsNet</cell><cell>72.5</cell><cell>16.3</cell><cell>7.3</cell><cell>1.4</cell><cell>0.8</cell></row><row><cell>VCTree</cell><cell>69.6</cell><cell>14.8</cell><cell>6.8</cell><cell>2.7</cell><cell>1.4</cell></row><row><cell>Transformer</cell><cell>68.1</cell><cell>18.1</cell><cell>7.9</cell><cell>1.2</cell><cell>0.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 9</head><label>9</label><figDesc>Model performance trained with different loss functionsLossmR/R@20 mR/R@50 mR/R@100</figDesc><table><row><cell></cell><cell>ℓ</cell><cell>12.2/59.5</cell><cell>15.5/66.0</cell><cell>16.8/67.9</cell></row><row><cell>MotifsNet</cell><cell>l▷ l△ l◁</cell><cell>12.3/58.8 12.3/58.5 12.5/57.7</cell><cell>15.7/65.1 15.8/64.2 16.1/63.3</cell><cell>17.2/66.3 17.5/65.9 17.9/65.4</cell></row><row><cell></cell><cell>l</cell><cell>12.9/53.5</cell><cell>16.9/59.4</cell><cell>20.1/61.8</cell></row><row><cell></cell><cell>ℓ</cell><cell>12.4/59.8</cell><cell>15.4/66.2</cell><cell>16.6/68.1</cell></row><row><cell>VCTree</cell><cell>l▷ l△ l◁</cell><cell>12.3/59.3 12.4/58.8 12.5/58.2</cell><cell>15.6/65.4 15.6/64.3 15.9/63.8</cell><cell>17.4/67.2 17.8/66.4 18.2/65.9</cell></row><row><cell></cell><cell>l</cell><cell>12.7/54.3</cell><cell>16.4/59.9</cell><cell>19.8/62.3</cell></row></table><note><p>Transformer ℓ 12.4/58.5 16.0/65.0 17.5/66.7 l▷ 12.5/58.2 16.2/64.2 17.6/65.1 l△ 12.7/57.9 16.3/63.8 17.6/64.9 l◁ 12.8/57.4 16.6/63.6 18.1/63.7 l 13.1/50.8 17.2/58.1 20.3/61.2</p></note></figure>
		</body>
		<back>

			<div type="funding">
<div><p>• This work was partially supported by the <rs type="funder">National Key Research and Development Program of China</rs> No. <rs type="grantNumber">2021YFB3100800</rs>, the <rs type="funder">Academy of Finland</rs> under grant <rs type="grantNumber">331883</rs>, <rs type="projectName">Infotech</rs> Project <rs type="projectName">FRAGES</rs>, and the <rs type="funder">National Natural Science Foundation of China</rs> under Grant <rs type="grantNumber">61872379</rs>, <rs type="grantNumber">62022091</rs>, <rs type="grantNumber">62201603</rs> and <rs type="grantNumber">62201588</rs></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_RA8kyhw">
					<idno type="grant-number">2021YFB3100800</idno>
				</org>
				<org type="funded-project" xml:id="_Bxywr6K">
					<idno type="grant-number">331883</idno>
					<orgName type="project" subtype="full">Infotech</orgName>
				</org>
				<org type="funded-project" xml:id="_5Pvsmv9">
					<idno type="grant-number">61872379</idno>
					<orgName type="project" subtype="full">FRAGES</orgName>
				</org>
				<org type="funding" xml:id="_6u3rQrg">
					<idno type="grant-number">62022091</idno>
				</org>
				<org type="funding" xml:id="_g7XuHak">
					<idno type="grant-number">62201603</idno>
				</org>
				<org type="funding" xml:id="_E38ZrCd">
					<idno type="grant-number">62201588</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr">TABLE 4</ref> <p>Quantitative results (R@K) of our method and other baselines on the MotifsNet, VCTree, and Transformer backbones PredCls SGCls SGDet R@20 R@50 R@100 AVG R R@20 R@50 R@100 AVG R R@20 R@50 R@100 AVG R MotifsNet (backbone) <ref type="bibr" target="#b8">[9]</ref> 59.5 66.0 67.9 64. <ref type="bibr" target="#b4">5</ref>  AVG R is the average of R@20, R@50, R@100. ∆, ♦, ♢, † and ‡ are with the same meanings as in Table <ref type="table">1</ref>. <ref type="bibr" target="#b66">[67]</ref>. Specifically, we first replace the loss function of the above backbones with the P-Loss to supervise the model training. We then leverage AL-Adjustment to optimize the logits outputted by the trained model during inference.</p><p>Baselines. We classify existing baselines from two perspectives to comprehensively evaluate our proposed framework. 1) Debiasing perspective. We divide the baselines into four groups, resampling methods, reweighting methods, adjustment methods, and hybrid methods. Resampling methods include SegG <ref type="bibr" target="#b18">[19]</ref> and TransRwt <ref type="bibr" target="#b19">[20]</ref>. Reweighting methods include CogTree <ref type="bibr" target="#b20">[21]</ref>, EBM-loss <ref type="bibr" target="#b14">[15]</ref>, Loss-reweight <ref type="bibr" target="#b43">[44]</ref>, FGPL <ref type="bibr" target="#b29">[30]</ref>, GCL <ref type="bibr" target="#b15">[16]</ref>, PPDL <ref type="bibr" target="#b16">[17]</ref>, and LS-KD(Iter) <ref type="bibr" target="#b31">[32]</ref>. Adjustment methods include TDE <ref type="bibr" target="#b13">[14]</ref>, DLFE <ref type="bibr" target="#b23">[24]</ref>, Logit-reweight <ref type="bibr" target="#b43">[44]</ref>, and PKO <ref type="bibr" target="#b24">[25]</ref>. Hybrid methods include BPL+SA <ref type="bibr" target="#b26">[27]</ref>, HML <ref type="bibr" target="#b27">[28]</ref>, RTPB <ref type="bibr" target="#b28">[29]</ref>, NICE <ref type="bibr" target="#b30">[31]</ref>, and CAME <ref type="bibr" target="#b32">[33]</ref>. We group from this perspective because Stage 1 in our framework is the reweighting method and Stage 2 is the adjustment method, and thus our TsCM is a hybrid method. 2) Model perspective. We divide the baselines into two groups, model-agnostic and model-dependent methods. The former group includes TDE <ref type="bibr" target="#b13">[14]</ref>, Loss-reweight <ref type="bibr" target="#b43">[44]</ref>, Logitreweight <ref type="bibr" target="#b43">[44]</ref>, BPL+SA <ref type="bibr" target="#b26">[27]</ref>, CogTree <ref type="bibr" target="#b20">[21]</ref>, DLFE <ref type="bibr" target="#b23">[24]</ref>, HML <ref type="bibr" target="#b27">[28]</ref>, FGPL <ref type="bibr" target="#b29">[30]</ref>, TransRwt <ref type="bibr" target="#b19">[20]</ref>, SegG <ref type="bibr" target="#b18">[19]</ref>, EBM-loss <ref type="bibr" target="#b14">[15]</ref>, PPDL <ref type="bibr" target="#b16">[17]</ref>, NICE <ref type="bibr" target="#b30">[31]</ref>, PKO <ref type="bibr" target="#b24">[25]</ref>, LS-KD (Iter) <ref type="bibr" target="#b31">[32]</ref>, and the latter group includes GCL <ref type="bibr" target="#b15">[16]</ref>, RTPB <ref type="bibr" target="#b28">[29]</ref>, CAME <ref type="bibr" target="#b32">[33]</ref>. It is generally possible to easily transfer model-agnostic methods to different SGG backbones, thereby generalizing well in real-world applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Performance analysis</head><p>Quantitative results analysis. We report the quantitative results in Table <ref type="table">1</ref>, Table <ref type="table">2</ref>, Table <ref type="table">3</ref>, Table <ref type="table">4</ref>, and Table <ref type="table">5</ref>. Our proposed method achieves state-of-the-art performance on mR@K, the most popular metric for evaluating unbiased SGG. Besides, the proposed method shows more gains on the metrics of R@K and MR@K, which indicates that TsCM obtains a better tradeoff between head and tail categories.</p><p>From the quantitative results, we have the following observations: 1) Adjustment methods <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b43">[44]</ref> are the most relevant to our proposed AL-Adjustment approach since they share the same insight in encouraging predicting more informative tail relationships by adjusting the output logits. However, the adjustment factors in our method are adaptively learned from the observed data and thus can support causal calibration since they are sparse and independent. Benefiting from this, for instance, in PredCls mode, TsCM achieves 6.7%/6.5% performance gains on MotifsNet (Table <ref type="table">1</ref>)/VCTree (Table <ref type="table">2</ref>) compared with adjustment methods. 2) Reweighting methods <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b43">[44]</ref> suppress partial relationships by modifying the loss function and are thus highly related to our proposed P-Loss as well. However, the difference is that our method focuses on relationships with semantic confusion, which this group of baseline methods has not explored yet. Thanks to P-Loss for providing the causal representation that can distinguish similar relationships, for example, in SGCls mode, TsCM surpasses the reweighting methods on MotifsNet (Table <ref type="table">1</ref>)/Transformer (Table <ref type="table">3</ref>) by 1.3%/2.5%. 3) Compared with hybrid methods <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b32">[33]</ref>, for example, in SGDet mode, our method observes 2.8%/3.6% improvements on VCTree (Table <ref type="table">2</ref>)/Transformer (Table <ref type="table">3</ref>). We believe this is mainly due to the fact that the two stages in our causal framework target different biases. While baseline methods mix different techniques, they only target the same bias. 4) We model the SCM with the data-level confounders so that our method is model-agnostic. TsCM can therefore be used for any SGG backbone that wants to pursue unbiased predictions. Compared with model-agnostic methods <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b43">[44]</ref>, for instance, in SGDet mode, we observe 2.7%/2.8% improvements on MotifsNet (Table <ref type="table">1</ref>)/Transformer (Table <ref type="table">3</ref>). 5) Table <ref type="table">4</ref> shows that our method is slightly weaker than logitreweight <ref type="bibr" target="#b43">[44]</ref> in terms of R@K. However, <ref type="bibr" target="#b43">[44]</ref> provides biased prediction, resulting in a poor performance in mR@K, e.g., 14.8% mR@K in the PredCls mode of the MotifsNet backbone <ref type="bibr" target="#b8">[9]</ref>, while our method achieves 36.8% in the same set-up. This indicates that our approach significantly outperforms</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image retrieval using scene graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3668" to="3678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A comprehensive survey of scene graphs: Generation and application</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural belief propagation for scene graph generation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bober</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning semantic relationships for better action retrieval in images</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1100" to="1109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning conditioned graph structures for interpretable visual question answering</title>
		<author>
			<persName><forename type="first">W</forename><surname>Norcliffe-Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vafeias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parisot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 32nd Int. Conf. Neural Inf</title>
		<meeting>32nd Int. Conf. Neural Inf</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="8334" to="8343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Explainable and explicit visual reasoning over scene graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8376" to="8384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Auto-encoding scene graphs for image captioning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">694</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unpaired image captioning via scene graph alignments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/CVF Int. Conf. Comput. Vis</title>
		<meeting>IEEE/CVF Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">332</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural motifs: Scene graph parsing with global context</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5831" to="5840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Visual relationship detection with language priors</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="852" to="869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to compose dynamic tree structures for visual contexts</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6619" to="6628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Knowledge-embedded routing network for scene graph generation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6163" to="6171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Scene graph generation by iterative message passing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5410" to="5419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unbiased scene graph generation from biased training</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3716" to="3725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Energy-based learning for scene graph generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Suhail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Siddiquie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Broaddus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eledath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sigal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">945</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Stacked hybridattention and group collaborative learning for unbiased scene graph generation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">436</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">PPDL: Predicate probability distribution based loss for unbiased scene graph generation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">456</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Landmark: Language-guided representation enhancement framework for scene graph generation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.01080</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Segmentation-grounded scene graph generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Suhail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sigal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/CVF Int. Conf. Comput. Vis</title>
		<meeting>IEEE/CVF Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">889</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Finegrained scene graph generation with data transfer</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="409" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Cogtree: Cognition tree loss for unbiased scene graph generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.07526</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Retrieval augmented classification for long-tail visual recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Purkait</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6959" to="6969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9268" to="9277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recovering the unbiased scene graphs from the biased ones</title>
		<author>
			<persName><forename type="first">M.-J</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 29th ACM Int. Conf. Multi</title>
		<meeting>29th ACM Int. Conf. Multi</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1581" to="1590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Rethinking the evaluation of unbiased scene graph generation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.01909</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adaptive logit adjustment loss for long-tailed visual recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf</title>
		<meeting>AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="3472" to="3480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">From general to specific: Informative scene graph generation via balance adjustment</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/CVF Int. Conf. Comput. Vis</title>
		<meeting>IEEE/CVF Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">392</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hierarchical memory learning for fine-grained scene graph generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="266" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Resistance training using prior bias: toward unbiased scene graph generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf</title>
		<meeting>AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="212" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fine-grained predicates learning for scene graph generation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">475</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Nicest: Noisy label correction and training for robust scene graph generation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.13316</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Label semantic knowledge distillation for unbiased scene graph generation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.03763</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">CAME: Context-aware mixtureof-experts for unbiased scene graph generation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.07109</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Cognitive psychology</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Sternberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Harcourt Brace College Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Contour integration by the human visual system: evidence for a local &quot;association field</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Hess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="193" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Causality</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A causal framework for distribution generalization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Jakobsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gnecco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6614" to="6630" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A meta-transfer objective for learning to disentangle causal mechanisms</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rahaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bilaniuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Toward causal representation learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sch Ölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE</title>
		<meeting>of the IEEE</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="612" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Causal diagrams for empirical research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Models, reasoning and inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>CambridgeUniversityPress</publisher>
			<biblScope unit="volume">19</biblScope>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Causal fairness analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Plecko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.11385</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Quaternion relation embedding for scene graph generation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Multimedia</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Long-tail learning via logit adjustment</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Meta-causal feature learning for out-of-distribution generalization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="530" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A causal debiasing framework for unsupervised salient object detection</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf</title>
		<meeting>AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1610" to="1619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Statistics and causal inference: A review</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Test</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="281" to="345" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">From statistical to causal learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V K</forename><surname>Bernhard Sch Ölkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.00607</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Weakly supervised representation learning with sparse perturbations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hartford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 36nd Int. Conf. Neural Inf</title>
		<meeting>36nd Int. Conf. Neural Inf</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">528</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">On the generalization and adaption performance of causal models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Scherrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Ke</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.04620</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Visual genome: Connecting language and vision using crowdsourced dense image annotations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kravitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="73" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The open images dataset v4</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Alldrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Krasin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kamali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Popov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Malloci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1956" to="1981" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Moving towards best practice when using inverse probability of treatment weighting (IPTW) using the propensity score to estimate causal treatment effects in observational studies</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Stuart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in medicine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">28</biblScope>
			<biblScope unit="page" from="3661" to="3679" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Adapting neural networks for the estimation of treatment effects</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Veitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 36nd Int. Conf. Neural Inf. Process. Syst</title>
		<meeting>36nd Int. Conf. Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2507" to="2517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Causal classification: Treatment effect estimation vs. outcome prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fernández-Loría</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">59</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A framework for the quantitative evaluation of disentangled representations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Eastwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Review of inverse probability weighting for dealing with missing data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Seaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical methods in medical research</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="278" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kalantidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Long-tailed visual recognition via gaussian clouded logit adjustment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-M</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6929" to="6938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">A probabilistic theory of pattern recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Devroye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lugosi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A note on margin-based loss functions in classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics &amp; probability letters</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="82" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Reviving threshold-moving: a simple plug-in bagging ensemble for binary and multiclass imbalanced data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Collell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Prelec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Patil</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.08698</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Rethinking class-balanced methods for long-tailed visual recognition from a domain adaptation perspective</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7610" to="7619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The logit model and response-based samples</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Manski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="283" to="302" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Equalized focal loss for dense long-tailed object detection</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6990" to="6999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Targeted supervised contrastive learning for long-tailed recognition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6918" to="6928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31nd Int. Conf. Neural Inf</title>
		<meeting>31nd Int. Conf. Neural Inf</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1149" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
