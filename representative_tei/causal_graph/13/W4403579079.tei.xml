<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Published as a conference paper at ICLR 2025 SYSTEMS WITH SWITCHING CAUSAL RELATIONS: A META-CAUSAL PERSPECTIVE</title>
				<funder>
					<orgName type="full">European Health and Digital Executive Agency (HaDEA)</orgName>
				</funder>
				<funder ref="#_hN6Juza">
					<orgName type="full">German Federal Ministry of Education and Research (BMBF)</orgName>
				</funder>
				<funder ref="#_ZErKwZX #_qXREmpy">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_jDeWBCP">
					<orgName type="full">National High-Performance Computing project for Computational Engineering Sciences</orgName>
				</funder>
				<funder ref="#_ta3DKAh">
					<orgName type="full">EU</orgName>
				</funder>
				<funder ref="#_V3HG4tN">
					<orgName type="full">Hessian Ministry of Higher Education, Research, Science and the Arts (HMWK</orgName>
				</funder>
				<funder ref="#_wRHR4F5">
					<orgName type="full">Department of Mathematics and Computer Science</orgName>
				</funder>
				<funder ref="#_ZQhBKWt">
					<orgName type="full">German Science Foundation (DFG)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-04-17">17 Apr 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Moritz</forename><surname>Willig</surname></persName>
							<email>moritz.willig@cs.tu-darmstadt.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tim</forename><forename type="middle">Nelson</forename><surname>Tobiasch</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Florian</forename><forename type="middle">Peter</forename><surname>Busch</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Hessian Center for AI (hessian.AI)</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jonas</forename><surname>Seng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Devendra</forename><forename type="middle">Singh</forename><surname>Dhami</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Mathematics and Computer Science</orgName>
								<orgName type="institution">Eindhoven University of Technology</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Hessian Center for AI (hessian.AI)</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Centre for Cognitive Science</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">German Research Center for AI (DFKI)</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Published as a conference paper at ICLR 2025 SYSTEMS WITH SWITCHING CAUSAL RELATIONS: A META-CAUSAL PERSPECTIVE</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-04-17">17 Apr 2025</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2410.13054v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most work on causality in machine learning assumes that causal relationships are driven by a constant underlying process. However, the flexibility of agents' actions or tipping points in the environmental process can change the qualitative dynamics of the system. As a result, new causal relationships may emerge, while existing ones change or disappear, resulting in an altered causal graph. To analyze these qualitative changes on the causal graph, we propose the concept of meta-causal states, which groups classical causal models into clusters based on equivalent qualitative behavior and consolidates specific mechanism parameterizations. We demonstrate how meta-causal states can be inferred from observed agent behavior, and discuss potential methods for disentangling these states from unlabeled data. Finally, we direct our analysis towards the application of a dynamical system, showing that meta-causal states can also emerge from inherent system dynamics, and thus constitute more than a context-dependent framework in which mechanisms emerge only as a result of external factors.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Structural Causal Models (SCM) have become the de facto formalism in causality by representing causal relations as structural equation models <ref type="bibr">(Pearl (2009)</ref>; <ref type="bibr" target="#b51">Spirtes et al. (2000)</ref>). While SCM are most useful for representing the intricate mechanistic details of systems, it can be challenging to derive the general qualitative behavior that emerges from the interplay of individual equations. Talking about the general type of relation emitted by particular mechanisms generalizes above the narrow computational view and has the ability to inspect causal systems from a more general perspective.</p><p>In addition to that, causal graphs can be subject to change whenever novel mechanisms emerge or vanish within a system. Prominently, agents can 'break' the natural unfolding of systems dynamics by forecasting system behavior and preemptively intervening in the course of events. As inherent parts of the environment, agents commonly establish or suppress the emergence of causal connections <ref type="bibr" target="#b63">(Zhang &amp; Bareinboim, 2017;</ref><ref type="bibr" target="#b34">Lee &amp; Bareinboim, 2018;</ref><ref type="bibr" target="#b15">Dasgupta et al., 2019)</ref>.</p><p>Consider the scenario shown in Figure <ref type="figure">1</ref> (left), where an agent A (with position A X ) follows an agent B (with position B X ) according to its internal policy A π . We are interested in answering the question 'What is the cause of the current position of agent A?'. In general, the observed system can be formalized as follows: A X := f A (B X , U A ) and B X := f B (U B ). Note that, from a classical causal perspective, we observe B → A, since A self-conditions itself to follow B, by instantiating the equation f A via its policy and thus becomes dependent on B. Classical causal considerations, which only consider how relations between variables are constructed, cannot give the correct answer. Only when we take a meta-causal stance and think about how equation f A came to be -how metacausal states induce qualitative changes in behavior-, we can give a sufficient answer to this question. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classical Attribution Meta-Causal Attribution</head><p>Figure <ref type="figure">1</ref>: Meta-Causality Identifies the Policy as a Meta Root Cause. Agent A intends to maintain its distance from agent B by conditioning its position A X on the position B X , which establishes a control mechanism, A X := f (B X ). In standard causal inference, we would infer B X → A X and, therefore, B to be the root cause. Taking a meta-causal perspective reveals however, that A π establishes the edge B X → A X in the first place (A π → (B X → A X )) such that A π is considered the root cause on the meta-level. (Best Viewed in Color)</p><p>Causal models do not exist in isolation, but emerge from the environmental dynamics of an underlying mediation process <ref type="bibr" target="#b28">(Hofmann et al., 2020;</ref><ref type="bibr" target="#b2">Arnellos et al., 2006)</ref>. Changes in causal relations due to intervention or environmental change are often assumed to be helpful conditions for identifying causal structures <ref type="bibr">(Pearl, 2009;</ref><ref type="bibr" target="#b43">Peters et al., 2016;</ref><ref type="bibr" target="#b63">Zhang &amp; Bareinboim, 2017;</ref><ref type="bibr" target="#b15">Dasgupta et al., 2019;</ref><ref type="bibr" target="#b21">Gerstenberg, 2024)</ref>. These operations often work on the individual causal graphs, but never reason about the emerging meta-causal structure that governs the transitions between the different SCM.</p><p>As a first formalization of metacausal models in this area, we describe how qualitative changes in the causal graphs can be summarized by metacausal models.</p><p>Contributions and Structure. The contributions of this work are as follows:</p><p>• To the best of our knowledge, we are the first to formally introduce typing mechanisms that generalize edges in causal graphs, and the first to provide a formalization of metacausal models (MCM) that are capable of capturing the switching type dynamics of causal mechanisms.</p><p>• We present an approach to discover the number of meta-causal states in the bivariate case.</p><p>• We demonstrate that meta-causal models can be more powerful than classical SCM when it comes to expressing qualitative differences within certain system dynamics.</p><p>• We show how meta-causal analysis can lead to a different root cause attribution than classical causal inference, and is furthermore able to identify causes of mechanistic changes even when no actual change in effect can be observed.</p><p>We proceed as follows: In Section 2 we describe the necessary basics of Pearlian causality, mediation processes, and typing assumptions. In Sec. 3 we introduce meta-causality by first formalizing metacausal frames, and the role of types as a generalization to a binary edge representations. Finally we define meta-causal models that are able to capture the qualitative dynamics in SCM behavior. In Sec. 4, we showcase several examples of meta-causal applications. Finally, we discuss connections to related work in Sec. 5 and conclude our findings in Sec. 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>Providing a higher-level perspective on meta-causality touches on a number of existing works that leverage meta-causal ideas, even if not explicitly stated. We will highlight relations of these works in the 'Related Work' of section 5. Here, we continue to provide the necessary concepts on causality, mediation processes and typing, needed for the definitions in our paper:</p><p>Causal Models. A common formalization of causality is provided via Structural Causal Models (SCM; <ref type="bibr" target="#b51">(Spirtes et al., 2000;</ref><ref type="bibr">Pearl, 2009)</ref>). An SCM is defined as a tuple M := (U, V, F, P U ), where U is the set of exogenous variables, V is the set of endogenous variables, F is the set of structural equations determining endogenous variables, and P U is the distribution over exogenous variables U. Every endogenous variable V i ∈ V is determined via a structural equation</p><formula xml:id="formula_0">v i := f i (pa(v i ))</formula><p>that takes in a set of parent values pa(v i ), consisting of endogenous and exogenous variables, and outputs the value of v i . The set of all variables is denoted by X = U ∪ V with values x ∈ X and N = | X |. Every SCM M entails a graph G M that can be constructed by adding edges (X i , X j ) ∈ X × X for each variable X j ∈ X and its parents X i ∈ Pa(X j ). This can be expressed as an adjacency matrix A ∈ B N ×N where A ij := 1 if (i, j) ∈ G and A ij := 0 otherwise.</p><p>Mediation Processes. Causal effects are embedded in an environment that governs the dynamics and mediates between different causes and effects. To reason about the existence of causal relations, we need to consider this process-embedding environment. We define a mediation process E = (S, σ), adapted from Markov Decision Processes <ref type="bibr" target="#b4">(Bellman (1957)</ref>) for our setting. Here, S is the state space of the environment and σ : S → S is the (possibly non-deterministic) transition function that takes the current state and outputs the next one. If we also have an initial state s 0 ∈ S, we call (E, s 0 ) an initialized mediation process. As we are concerned with the general mediation process, we omit the common notion of a reward function r. Furthermore, we omit an explicit action space A and agents' policy π and model actions directly as part of the transition function σ. In accordance to considerations of <ref type="bibr" target="#b13">Cohen (2022)</ref>, this eases treatment of environment processes and agent actions as now both are defined on the same domain. The emergence of SCM from mediation processes can be studied under a measure-theoretic theory, as considered in <ref type="bibr" target="#b41">Park et al. (2023)</ref>. Similarly, Janzing &amp; Mejia (2022) discuss the role of elementary actions towards the constitution of causal variables.</p><p>Typing. In the following section, we will make use of an identification function I to determine the presence or absence of edges between any two variables. In particular, one can make use of different identification functions to identify different types of edges. Previous work on typing causality exists <ref type="bibr" target="#b6">(Brouillard et al., 2022)</ref>, but primarily considers the types of variables that are causally related, rather than the type of structural relation itself. Other works in the field of cognitive science consider the perception of different types of mechanistic relations (e.g., 'causing', 'enabling', 'preventing', 'despite') based on the role that different objects play in physical scenes <ref type="bibr" target="#b10">(Chockler &amp; Halpern, 2004;</ref><ref type="bibr" target="#b59">Wolff, 2007;</ref><ref type="bibr" target="#b49">Sloman et al., 2009;</ref><ref type="bibr" target="#b55">Walsh &amp; Sloman, 2011;</ref><ref type="bibr" target="#b20">Gerstenberg, 2022)</ref>. Since all objects are usually governed by the same physical equations, this assignment of types serves to provide post hoc explanations of a scene, rather than to identify inherent properties of its computational aspects. <ref type="bibr" target="#b21">Gerstenberg (2024)</ref> provides an 'intuitive psychology' example that fits well with our scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">META-CAUSALITY</head><p>Similar to <ref type="bibr" target="#b42">Pearl &amp; Mackenzie (2018)</ref>, we define Meta-Causality to be the [science of] change in qualitative cause-effect behavior. Usually, the mediating process may be too fine-grained to yield interpretable models. Therefore, we consider a set of variables of interest X modeled by an SCM and introduced by an abstraction φ : S → X . (We provide a brief discussion on the emergence of SCM from mediating processes in Appendix A). Here, φ could be defined as a summarization or causal abstraction over the state space <ref type="bibr" target="#b44">(Rubenstein et al., 2017;</ref><ref type="bibr" target="#b3">Beckers &amp; Halpern, 2019;</ref><ref type="bibr" target="#b0">Anand et al., 2022;</ref><ref type="bibr" target="#b54">Wahl et al., 2023;</ref><ref type="bibr" target="#b32">Kekić et al., 2023;</ref><ref type="bibr" target="#b61">Willig et al., 2023)</ref>. In order to identify the type of causal relations from a mediating process, we need to be able to decide on what constitutes a type. Definition 1 (Meta-Causal Frame). For a given mediation process E = (S, σ) a meta-causal frame is a tuple F = (E, X, (τ ij ), I) with:</p><p>• type-encoders τ ij : X i × X S → T that assign a type t ∈ T to the functional dependence of X j on X i , induced by the underlying process (S, σ). This relation is between X i (values of X i ) and the abstraction of the transition function φ • σ ∈ X S = {ψ : S → X }.</p><p>• an identification function</p><formula xml:id="formula_1">I : S × X × X → T with I(s, X i , X j ) → t := τ ij (φ(s), φ • σ)</formula><p>that assigns a type to every pair of causal variables for any state of the environment.</p><p>Types generalize the role of edges in causal graphs, while type encoders τ ij determine the particular type of edges from properties of the underlying functional relations φ•σ. In most classical scenarios, the co-domain T of the type encoder τ ij is chosen to be Boolean, representing the existence or absence of edges. In other cases, different values t ∈ T can be understood as particular types of edges, like positive, negative, or the absence of influence. This will help us to distinguish metacausal states that share the same graph adjacency. The only requirement for T is that it must contain a special value 0 , which indicates the total absence of an edge. Meta-causal states now generalize the idea of binary adjacency matrices. We, intentionally, do not restrict the identification function in any way. However, particular choices, e.g. functions identifying only direct causal effects, are more likely to result in classical SCM. We provide a short discussion on this in Appendix B. Definition 2 (Meta-Causal State). In a meta-causal frame F = (E, X, τ ij , I), a meta-causal state is a matrix T ∈ T N ×N . For a given environment state s ∈ S, the actual meta-causal state T s has the entries T s,ij := I(s, X i , X j ) = τ ij (φ(s), φ • σ).</p><p>A meta-causal state T ∈ T N ×N represents a graph containing edges e ij of a particular type t ∈ T .</p><p>In particular T ij indicates the presence (T ij ̸ = 0 ) or absence (T ij = 0 ) of individual edges. Our goal for meta-causal models (MCM) is to capture the dynamics of the underlying model. In particular, we are interested in modeling how different meta-causal states transition into each other. This behavior allows us to model them in a finite-state machine <ref type="bibr" target="#b40">(Moore et al., 1956)</ref>: Definition 3 (Meta-Causal Model). For a meta-causal frame F = (E, X, σ, I), a meta-causal model is a finite-state machine defined as a tuple A = (T N ×N , S, δ), where the set of meta-causal states T N ×N is the set of machine states, the set of environment states S is the input alphabet, and δ : T N ×N × S → T N ×N is a transition function.</p><p>Usually, we have the objective to learn the transition function δ for an unknown state transition function σ. The state transition function δ can be approximated as δ(T, s)</p><formula xml:id="formula_2">:= I(σ(T, s), X i , X j ) = τ ij (φ(s), φ • σ(T, s)).</formula><p>As standard causal relations emerge from the underlying mediation process, the meta-causal states emerge from different types of causal effects. The transition conditions of the finite-state machine are the configurations of the environment where the quality of some environmental dynamics represented by a type t ∈ T changes.</p><p>Inferring the Meta-Causal States. Even if the state transition function is known, it may be unclear from a single observation which exact meta-causal state led to the generation of a particular observation S. This is especially the case when two different meta-causal states can fit similar environmental dynamics. Even in the presence of latent factors (e.g., an agent's internal policy), the current dynamics of a system (e.g., induced by the agent's current policy) can sometimes be inferred from a series of observed environment states. This requires knowledge of the meta-causal dynamics, and is subject to the condition that sequences of observed states uniquely characterize the meta-causal state. Since MCM are defined as finite state machines, the exact condition for identifying the meta-causal state is that observed sequences are homing sequences <ref type="bibr" target="#b40">(Moore et al., 1956)</ref>. Note that the following example of a game of tag presented below exactly satisfies this condition, where the meta-causal states produce disjoint sets of environment states ('agent A faces agent B', or 'agent B faces agent A'), and thus can be inferred from either a single observation, when movement directions are observed, or two observations, when they need to be inferred from the change in position of two successive observations.</p><p>'Game of Tag' Example. Consider an idealized game of tag between two agents, with a simple causal graph and two different meta-states. In general, we expect agent B to make arbitrary moves that increase its distance to A, while A tries to catch up to B, or vice versa. In essence, this is a cyclic causal relationship between the agents, where both states have the same binary adjacency matrix. Note, however, that the two states differ in the type of relationship that goes from A to B (and B to A). We can use an identification function that analyzes the current behavior of the agents to identify each edge. Since A can tag B, the behavior of the system changes when the directions of the typed arrows are reversed, so that the type of the edges is either 'escaping' or 'chasing'.</p><p>While the underlying policy of an agent may not be apparent from observation as an endogenous variable, it can be inferred by observing the agents' actions over time. Knowing the rules of the game, one can assume that the encircling agent faces the other agent and thus moves towards it, while the fleeing agents show the opposite behavior:</p><formula xml:id="formula_3">(t B→A = "A Chasing") ⇐⇒ ( Ȧpos • (B pos -A pos ) &gt; 0)</formula><p>where Ȧpos is the velocity vector of agent A (possibly computed from the position of two consecutive time steps); A pos and B pos are the agent positions, and • is the dot product. Once the edge types are known, the policy can be identified immediately.</p><p>Causal and Anti-Causal Meta-Causal States. Assigning meta-causal states to particular system observations can be understood as labeling the individual observations. However, it is generally unclear whether the meta-causal state has an observational or a controlling character on the system under consideration. One could ask the question whether the system dynamics cause the metacausal state, whether the meta-causal state causes the system dynamics, (or whether they are actually the same concept), similar to the well-known discussion "On Causal and Anticausal Learning" by <ref type="bibr" target="#b48">Schölkopf et al. (2012)</ref>, but from a meta-causal perspective.</p><p>At this point in time, we cannot give definitive conditions on how to answer this question, but we present two examples that support either one of two opposing views. First, in Sec. 4.3 we present a scenario of a dynamical system where the structural equations of both meta-causal states are the same, since the system dynamics are governed by its self-referential system dynamics. Intervening on the meta-causal state will therefore have no effect on the underlying structural equations, and thus can have no effect on the actual system dynamics. In such scenarios, the meta-causal is rather a descriptive label and cannot be considered an external conditioning factor. In the following, we discuss the opposite example, where a meta-causal state can be modeled as an external variable conditioning the structural equations.</p><p>Role of Contextual Independencies. Changes in the causal graph are often attributed to changes in the environment modeled by some exogenous variables Z, as, for example, leveraged with the invariant causal prediction <ref type="bibr" target="#b43">(Peters et al., 2016)</ref>. In this case, we get MCM where the transition function only contains self-loops. This makes it clear that MCM are a more general tool in analyzing meta-causal structures. If we introduce a 'no-edge' type t = 0 for this scenario, a meta-causal model can describe the condition that X i and X j are contextually independent for some Z = z. For a suitable type-encoder with a surjective mapping ψ : Z → T N ×N and a given family of compatible</p><formula xml:id="formula_4">(see Appendix C) decomposed structural equations (f z ij ) z∈Z we have f z j := ⃝ i∈1..N f ij |Z and f ij |Z := f z ij if ψ(z) ij ̸ = 0 (&lt; * ) otherwise<label>(1)</label></formula><p>where f z ij are the structural equations of the edge e ij that are active under the environment Z and (in a slight imprecision in the actual definition) (&lt; * ) is the function that carries on the previous function of the composition and discards X j . While the 'no-edge' type 0 could be handled like any other type, we have listed it for clarity such that individual variables X i become contextually independent whenever f ij |Z = 0 . We provide conditions for the reduction of MCM in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPLICATIONS</head><p>In this section, we discuss several applications of the meta-causal formalism. First, we revisit the motivational example and consider how meta-causal models can be used to attribute responsibility. Next, we identify the presence of multiple mechanisms for the bivariate case from sets of unlabeled data. Finally, we analyze the emergence of meta-causal states from a dynamical system, highlighting that meta-causal states are more expressive than simple conditionings of the adjacency matrix. Code is made available at <ref type="url" target="https://github.com/MoritzWillig/metaCausalModels">https://github.com/MoritzWillig/metaCausalModels</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">ATTRIBUTING RESPONSIBILITY</head><p>Consider again the motivational example of Figure <ref type="figure">1</ref>, where an agent A with position A X follows an agent B with position B X as dictated by its policy A π . In this scene, we can imagine a counterfactual scenario in which we replace the 'following' policy of agent A with, e.g., a 'standing still' policy and find that the B X → A X edge vanishes. As a result, we infer the meta-causal mechanism A π → (B X → A X ) for the system and thus A π as the root cause of for values of A X . In conclusion, while A is conditioned on B on a low level, the meta-causal reason for the existence of the edge B → A is caused by the A π . Both attributions, tracing back causes through the structural equations A X := f (B X ) or our meta-causal approach, are valid conclusions in their own regard.</p><p>Note that in this scenario, a classic counterfactual consideration, A Aπ=standing still X -A Aπ=following X , would also have inferred an effect of A π on A X from a purely value-based perspective. Attributing effects via observed changes in variable values is a valid approach, but it fails to explain preventative mechanisms. For example, consider the simple scenario where two locks prevent a door from opening. Classical counterfactual analysis would attribute zero effect to the opening of either lock. predictions. '-' indicates setups where the algorithm did not make a decision. In general, the algorithm is rather conservative in its predictions. In all cases where a decision is made, the number of correct predictions along the diagonals dominate. The first and second most frequent predictions are marked in green and orange, respectively. (Best Viewed in Color)</p><formula xml:id="formula_5">d = 0.0 d = 0.1 d = 0.2 k * k ′ - 1 2 3 4 - 1 2 3 4 - 1 2</formula><p>A meta-causal perspective would reveal that the opening of the first lock already changes the metacausal state of the model by removing its causal mechanisms that condition the state of the door. In a sense, our meta-causal causal perspective is similar to that of the actual causality framework <ref type="bibr" target="#b26">(Halpern, 2016;</ref><ref type="bibr" target="#b10">Chockler &amp; Halpern, 2004)</ref>. However, actual causality operates at the 'actual', i.e. value-based, level and does not take the mechanistic meta-causal view into perspective. Meta-causal models already allow us to reason about causal effects after opening the first lock due to a change in the causal graph, without us having to consider the effects of opening the second lock at some point to reach that conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">DISCOVERING META-CAUSAL STATES IN THE BIVARIATE CASE</head><p>Our goal in this experiment is to recover the number of meta-causal states K ∈ [1..4] from data that exists between two variables X, Y that are directly connected by a linear equation with added noise. We assume that each meta-causal state gives rise to a different linear equation</p><formula xml:id="formula_6">f k := α k X + β k + N , k ∈ N,</formula><p>where α k , β k are the slope and intercept of the respective mechanism and N is a zero-centered, symmetric, and quasiconvex noise distribution<ref type="foot" target="#foot_0">foot_0</ref> . Without loss of generality, we apply Laplacian noise, for which an L1-regression can estimate the true parameters of the linear equations <ref type="bibr" target="#b29">(Hoyer et al., 2008)</ref>. The causal direction of the mechanism is randomly chosen between different meta-causal states. The exact sampling parameters and plots of the resulting distributions are described in Sec. G (and plots of sample distributions are shown in Fig. <ref type="figure" target="#fig_1">3</ref> in the Appendix). In general, this scenario corresponds to the setting described above of inferring the values of a latent variable Z (with K = |Z|) that indicate a particular meta-causal state of the system. Our goal is to recover the number of parameterizations of the causal mechanisms, and as a consequence to be able to reason about which points were generated by which mechanism.</p><p>Approach. The empirical observed convergence rates of the EM algorithm drastically reduce the theoretical derived bound of required samples. This reveals that convergence assumptions where chosen to be quite conservative, and attests a good fit of the EM algorithm for regressing mechanism parameters.</p><p>Assuming for the moment that the correct number of mechanisms k * has been chosen, we assume that the EM algorithm is able to regress the parameters of the mechanisms, α * k , β * k , whenever there exists a pair of points for each of the mechanisms, where both points of the pair are samples generated by that particular mechanism. The chances of sampling such an initial configuration decrease rapidly with an increasing number of mechanisms (e.g. 0.036% probability for k = 4 and equal class probabilities). Furthermore, we assume that the sampling probabilities of the individual mechanisms in the data can deviate from the mean by up to a certain factor d. In our experiments, we consider setups with d ∈ {0.0, 0.1, 0.2}. Given the number of classes and the maximum sample deviation of the mechanisms, one can compute an upper bound on the number of resamples required to have a 95% chance of drawing at least one valid initialization. The bound is maximized by assigning the first half of the classes the maximum deviation probability P k-max = (1 + d)/k and the other half the minimum deviation probability P k-min = (1 -d)/k. We provide the formulas for the upper bound estimation and in Sec. E in the Appendix and provide the calculated required resample counts in Table <ref type="table" target="#tab_1">2</ref>. In the worst case, for a scenario with k = 4 mechanisms and d = 0.2 maximum class probability deviation, nearly 14, 900 restarts of the EM algorithm are required, drastically increasing the potential runtime.</p><p>In our experiments, we find that our assumptions about EM convergence are rather conservative. Our evaluations show that the EM algorithm is still likely to be able to regress the true parameters, given that some of the initial points are sampled from incorrect mechanisms. We measure the empirical convergence rate by measuring the convergence rate of the EM algorithm over 5,000 different setups (500 randomly generated setups with 10 parameter resamples each). We perform 5 EM steps for setups with k = 1 and k = 2 mechanisms, and increase to 10 EM iterations for 3 and 4 mechanisms. For each initialization, we count the EM algorithm as converged if the slope and intercept of the true and predicted values do not differ by more than an absolute value of 0.2.</p><p>Determining the Number of Mechanisms. The above approach is able to regress the true parameterization of mechanisms when the real number of parameters k * is given. However, it is still unclear how to determine the correct k * . Computing the parameters for all k ∈ K and comparing for the best goodness of fit is generally a bad indicator for choosing the right k, since fitting more mechanisms usually captures additional noise and thus reduces the error. In our case, we take advantage of the fact that we assumed the noise to be Laplacian distributed. Thus, the residuals of the samples assigned to a particular mechanism can be tested against the Laplacian distribution.</p><p>The EM algorithms return the estimated parameters α ′ k , β ′ k , and the mean standard deviation b ′ k of the Laplacian<ref type="foot" target="#foot_1">foot_1</ref> . This allows one to compute the class densities k(x i , y</p><formula xml:id="formula_7">i ; α ′ k , β ′ k , b ′ k )</formula><p>for a pair of values (x i , y i ). Since the assignment of mechanisms to a data point may be ambiguous due to the overlap in the estimated PDFs, we normalize the density values of all mechanisms per data point and consider only those points for which the probability of the dominant mechanism is 0.4 higher than the second class: (x j , y j ) := ((x i , y</p><formula xml:id="formula_8">i )|#1 = j; f #2 i &lt; P #1 i × (1 -0.4))</formula><p>, where #n indicates the class with the n-th highest density value. Finally, the residuals</p><formula xml:id="formula_9">y j -f ′j k (x j , y j ; α ′ k , β ′ k , b ′ k ) are</formula><p>computed for all data points (x j , x j ) assigned to a particular predicted mechanism f ′j k . We choose the parameterization that best fits the data for each k ∈ [1..4] and, make use of the Anderson-Darling test (Anderson &amp; <ref type="bibr" target="#b1">Darling, 1952)</ref> to test the empirical distribution function of the residuals against the Laplacian distribution with an α = 0.95 using significance values estimated by <ref type="bibr" target="#b8">Chen (2002)</ref>. If all residual distributions of all mechanisms for a given k ′ pass the Anderson-Darling test, we choose that number as our predicted number of mechanisms. If the algorithm finds that none of the k ∈ [1..4] setups pass the test, we refrain from making a decision. We provide the pseudo code for our method in Algorithm. 1 in the Appendix.</p><p>Evaluation and Results. We evaluate our approach over all k ∈ [1..4] by generating 100 different datasets for every particular number of mechanisms. For every dataset we sample 500 data points from each mechanism</p><formula xml:id="formula_10">(x k i , y k i ) = f k (α k x k i + β k + l i )</formula><p>where l i ∼ L(0, b k ), using the same sampling method as before (c.f. Appendix G). Finally, the algorithm recovers the number of mechanisms.</p><p>We compare theoretically computed and empirical in convergence results in Table <ref type="table" target="#tab_1">2</ref>. In practice, we observe that the convergence of the EM algorithm is more favorable than estimated, reducing from 23 to 8 required examples for the simple case of k = 2, d = 0.0, and requiring up to 83-times fewer samples for the most challenging setup of k = 4, d = 0.2, reducing from a theoretical of 14,859 to an empirical estimate of 177 samples. The actual convergence probabilities and the formula for deriving to sample counts are given in Table <ref type="table" target="#tab_4">3</ref> and Sec. F of the Appendix.</p><p>Table <ref type="table" target="#tab_0">1</ref> shows the confusion matrices between the actual number of mechanism and the predicted number for different values of maximum class imbalances. In general, we find that our approach is rather conservative when in assigning a number of mechanisms. However, when only considering the cases where the number of mechanisms is assigned, the correct predictions along the main diagonal dominate with over 60% accuracy for k = 4 and d ∈ {0.0, 0.1} and rising above 80% for k ̸ = 4 for. In the case of d = 0.2, the results indicate higher confusion rates with 41.6% accuracy for the overall worst case of K = 4.</p><p>Extension to Meta-Causal State Discovery on Graphs. Our results indicate that identifying metacausal mechanisms even in the bivariate case comes with an increasing number of uncertainty when it comes to increasing numbers of mechanisms. Given that the number of mechanisms could be reliably inferred from data for all variables, the meta-causal states could be identified as all unique combinations of mechanisms that are jointly active at a certain point in time. To recover the full set of meta-causal states, one needs to be able to simultaneously estimate the triple of active parents for every mechanism, the mechanisms parameterizations, and the resulting meta-state assignment of all data points for every meta-state of the system. All of the three components can vary between each meta-causal state (e.g. edges vanishing or possibly switching direction, thus altering the parent sets). Note that whenever any of the three components is known, the problem becomes rather trivial. However, without making any additional assumptions on the model or data and given the results on the already challenging task of identifying mechanisms in the bivariate case, the extension to a unsupervised full-fledged meta-causal state discovery is not obvious to us at the time of writing and we leave it to future work to come up with a feasible algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">A META-STATE ANALYSIS ON STRESS-INDUCED FATIGUE</head><p>Stress is a major cause of fatigue and can lead to other long-term health problems <ref type="bibr" target="#b38">(Maisel et al., 2021;</ref><ref type="bibr" target="#b19">Franklin et al., 2012;</ref><ref type="bibr" target="#b17">Dimsdale, 2008;</ref><ref type="bibr" target="#b5">Bremner, 2006)</ref>. While short-term exposure may be helpful in enhancing individual performance, long-term stress is detrimental and resilience may decline over time <ref type="bibr" target="#b56">(Wang &amp; Saudino, 2011;</ref><ref type="bibr" target="#b38">Maisel et al., 2021)</ref>. While actual and perceived stress levels <ref type="bibr" target="#b12">(Cohen et al., 1983;</ref><ref type="bibr" target="#b5">Bremner, 2006;</ref><ref type="bibr" target="#b47">Schlotz et al., 2011;</ref><ref type="bibr" target="#b23">Giannakakis et al., 2019)</ref> may vary between individuals <ref type="bibr" target="#b7">(Calkins, 1994;</ref><ref type="bibr" target="#b24">Haggerty, 1996)</ref>, the overall effect remains the same. We want to model such a system as an example. For simplicity, we present an idealized system that is radically reduced to the only factors of external stress, modeling everyday environmental factors, and the selfinfluencing level of internal/perceived stress.</p><p>While being rather simple in setup, the example serves as a good demonstration on how dynamical systems induce meta-causal states that exhibit qualitative different behavior, while employing the same set of underlying structural equations. As such, the inherent behavior of the system is not only due to a conditioning external factor. We use an identification function to distinguish between two different modes of operation of a causal mechanism. In particular, we are interested whether 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 the inherent dynamics of the internal stress level are self-reinforcing or self-suppressing. For easier analysis of the system we decompose the dynamics of the internal stress variable into a 'decayed stress' d and 'resulting stress' s computation. The first term are the previous stress levels decayed over time with external factors added. The resulting stress is then the output of a Sigmoidal function (Fig. <ref type="figure">2</ref>, left) that either reinforces or suppresses the value (Fig. <ref type="figure">2</ref>,center). The structural equations are defined as follows and we assume that all values lie in the interval of [0, 1]:</p><formula xml:id="formula_11">f d := 0.95 clip [0,1] (s ′ + 0.5 × ext.</formula><p>Stress) and f s := 1.01( 1 1 + exp(-15x + 7.5) -0.5) + 0.5</p><p>where s and d are the resulting and decayed stress levels, and s ′ is the previous stress level of s.</p><p>We now define the identification function to be I := sign( fs ), where fs is the second order derivative of the Sigmoidal f s , with either positive or negative effect on the stress level. The described system has two stable modes of dynamics. Note how the second-order inflection point at 0.5 of the Sigmoid acts as a transition point on the behavior of the mechanism. Stress values below 0.5 get suppressed, while values above 0.5 are amplified. Transitions between the two stable states can only be initiated via external stressors. Effectively this results in three possible meta-causal states which are governed via the following transition function:</p><formula xml:id="formula_12">σ : (t, s) → 1 a 0 0 with a := sign( fs ) = sign(s -0.5) ∈ {-1, 0, 1}</formula><p>Role of Latent Conditioning. A key takeaway of this example is that the current meta-state persists due to the inherent stress level and dynamics of the system. In contrast to other examples where system dynamics where purely due to the meta-causal state, variable values play a role in the overall system dynamics. As a result, the stressed state of a person would persist even when the initiating external stressors disappear. Intervening on the meta-causal state of the system is now ill-defined, as both positive and negative reinforcing effects are governed by the same equation. Thus, creating a disparity between the intervened meta-causal state and the systems' identified functional behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Causal Transportability and Reinforcement Learning. Meta-causal models cover cases that reduce to conditionally dependent causal graphs due to changing environments <ref type="bibr" target="#b43">(Peters et al., 2016;</ref><ref type="bibr" target="#b27">Heinze-Deml et al., 2018)</ref>, but also extend beyond that for dynamical systems. In this sense, the work of <ref type="bibr" target="#b52">Talon et al. (2024)</ref> takes a meta-causal view by transporting edges of different causal effects between environments. In general, the transportability of causal relations <ref type="bibr" target="#b63">(Zhang &amp; Bareinboim, 2017;</ref><ref type="bibr" target="#b34">Lee &amp; Bareinboim, 2018;</ref><ref type="bibr" target="#b14">Correa et al., 2022)</ref> can be thought of as learning identification functions that identify general conditions of the underlying processes to transfer certain types of causal effects between environments <ref type="bibr" target="#b50">Sonar et al. (2021)</ref>; <ref type="bibr" target="#b60">Yu et al. (2024)</ref>; <ref type="bibr" target="#b6">Brouillard et al. (2022)</ref>. This has been studied to some extent under the name of meta-reinforcement learning, which attempts to predict causal relations from the observations of environments Sauter et al. ( <ref type="formula">2023</ref>); <ref type="bibr" target="#b15">Dasgupta et al. (2019)</ref>. Generally, transferability has been considered in reinforcement learning, where the efficient use of data is omnipresent and causality provides guarantees regarding the transferability of mechanisms between environments <ref type="bibr" target="#b45">(Saemundsson et al., 2018;</ref><ref type="bibr" target="#b15">Dasgupta et al., 2019;</ref><ref type="bibr" target="#b62">Zeng et al., 2023)</ref>.</p><p>Gating Models. Modeling switching causal relations <ref type="bibr" target="#b37">(Liu et al., 2023)</ref> via so called 'gates' has been considered in prior works <ref type="bibr" target="#b39">Minka &amp; Winn (2008)</ref>; <ref type="bibr" target="#b58">Winn (2012)</ref>. While MCMs extend beyond context-specific independencies, gates pose a practical way of modeling switching relations in cases where MCMs can be reduced to context-conditioned SCM.</p><p>Large Language Models (LLMs). Meta-causal representations are an important consideration for LLMs and other foundation models, since these models are typically limited to learning world dynamics from purely observational textual descriptions. LLMs need to learn meta-causal models that allow them to simulate the consequences of interventions <ref type="bibr" target="#b33">(Lampinen et al., 2024;</ref><ref type="bibr" target="#b35">Li et al., 2021;</ref><ref type="bibr">2022)</ref>. To the best of our knowledge, <ref type="bibr" target="#b61">Zečević et al. (2023)</ref> made the first attempt to define explicit meta-causal models that integrate with the Pearlian causal framework. However, their MCM are purely defined as adjacency matrix memorization, such that causal reasoning in LLMs equals a simple knowledge recall (X → Y ) ⇔ (e XY ∈ Mem) and thus fails to generalize to novel scenarios.</p><p>Actual Causality, Attribution and Cognition. Our MCM framework can be used to infer and attribute responsibility, as shown in Sec. 4.1, and therefore touches on the topics of fairness, actual causation (AC) and work on counterfactual reasoning in cognitive science. <ref type="bibr" target="#b53">(Von Kügelgen et al., 2022;</ref><ref type="bibr" target="#b31">Karimi et al., 2021;</ref><ref type="bibr" target="#b25">Halpern, 2000;</ref><ref type="bibr" target="#b26">2016;</ref><ref type="bibr" target="#b10">Chockler &amp; Halpern, 2004;</ref><ref type="bibr" target="#b22">Gerstenberg et al., 2014;</ref><ref type="bibr" target="#b21">Gerstenberg, 2024)</ref>. The similarities also extend to how MCM encourage reasoning about the dependence between actual environmental contingencies and qualitative types of causal mechanisms. In this sense, MCM allow for the direct characterization of actual causes of system dynamics types, but a rigorous formalization is open for future work. While AC in combination with classical SCM only describes relationships between causal variable configurations and observable events, there are cases where we can take an MCM and derive an SCM that encodes the meta-causal types with instrumental variables, thus allowing a similar meta-causal analysis within the AC framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We formally introduced meta-causal models that are able to capture the dynamics of switching causal types of causal graphs and, in many cases, better express the qualitative behavior of the system under consideration. Within MCM, types generalize the notion of specific structural equations and abstract away unnecessary detail. We presented a motivating example of how a classical causal and a meta-causal inference might disagree on the attribute of root causes. We extended claims by considering that MCM are still able attribute changes in mechanistic behavior of a system, even when no actual changes becomes apparent. We presented a first approach to recover meta-causal states in the bivariate case. Although our experimental results only represent a first preliminary approach, we find that MCM are a powerful tool for modeling, reasoning, and inferring system dynamics. We demonstrated how MCM can be deployed dynamical systems and proved that they extend beyond conventional SCM.</p><p>Limitations and Future Work. While we have formally introduced meta-causal models, there remain several open directions to pursue, which we briefly touch on in Appendix H. We have been able to provide examples that illustrate the differences between standard causal, and meta-causal attribution. In particular, the combined application of standard and meta-causal explainability will allow for the joint consideration of actual and mechanistic in future attribution methods. However, our approach to recovering meta-causal states from unlabeled data is open to extension. Discovery on the full causal graphs is a desirable goal that is difficult to achieve for the reasons discussed in this paper. Finally, we made a first attempt to present examples for and against the controlling or observational role of meta-causal models, which we briefly discuss further in Appendix I. While, the presented observational perspective on MCM is mainly of interest for analytical applications, the application to agent systems and reinforcement learning might open up further fields of application.</p><p>be the result of an indirect relation via an (possibly unobserved) intermediate variable. Consider, how this notion of edge types over unobserved variables is already in use in CPDAGs -as for example produced by the PC or GES algorithms <ref type="bibr" target="#b51">(Spirtes et al., 2000;</ref><ref type="bibr" target="#b9">Chickering, 2002)</ref>-to indicate undirected edges for which the orientation is currently unknown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C COMPATIBILITY OF DECOMPOSED EQUATIONS</head><p>In this section, we provide a brief discussion on the existence and compatibility of functions X as considered in Equation <ref type="formula" target="#formula_4">1</ref>.</p><p>Since the conditioned SCM in Eq. 1 is modeled after an the particular causal model that exists under a meta-causal state indexed by z, it follows that a particular composition of functions f z ij has to exist (and that the functions are compatible), since the full function f z j exists for each meta-causal state. In a naïve approach, the order of composition i ∈ {1..N } enforces a particular evaluation order of the functions, and in particular requires this order to be the same for every meta-causal state.</p><p>Generally, the presented function composition might not work, in the case that the individual functions get chosen badly from the start. A simple solution to overcome such problem is to assume compositions of lifted functions and assume their signatures to be compatible (which is always permitted due to the known existence of the composed f z j ). Note that functions f z ij , f z ′ ij , whose functional type t ij did not change under a change of z to z ′ , to make signatures compatible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Common handling of compositionality in SCM:</head><p>The adjustment of signatures is in fact often considered in the case of compositional SCM, e.g. additive noise models, where the signature of an outer 'merging function' f j (f 1j , . . . , f N j ), e.g. i∈pa(j) f ij , is in fact adjusted based on the number of parents (or, otherwise, zero weight edges are incorrectly excluded from the parent set).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D REDUCTION OF META-CAUSAL MODELS TO CONDITIONED SCM</head><p>In this section, we provide a condition under which meta-causal models can be reduced to ordinary SCM with structural equations conditioned on some external variable as related to Eq. 1. Definition 4 (MCM Reducability). For a given mediation process E = (S, σ) and abstraction φ : S → X we call a meta-causal model A = (T N ×N , S, δ) reducible to a conditioned SCM if there is some SCM over X ∪{Z} where the types of functional dependencies between X i , X j ∈ X can be fully determined by Z. Theorem D.1 (Specific Criterion for Meta-Causal Reducability). If for a given mediation process E = (S, σ) and abstraction φ : S → X , a meta-causal model A = (T N ×N , S, δ) all its transitions are loops, then it is reducible to a conditioned SCM.</p><p>Proof. If a meta-causal model only has loops as transitions, the meta-causal types are independent of the modeled mediation process. While types can differ for different starting conditions in the environment, its transition process never results in a type change. Hence, meta-causal types induce an equivalence relation on S, compatible with σ and we can introduce an exogenous variable Z with Z = T N ×N or, alternatively, with values Z for each connected component in E = (S, σ).</p><p>We also see some potential to weaken this criterion and, therefore, find a more general condition for reducibility by further examination of the abstraction that links the mediating process with the causal variables for future work. The primary obstacle in this regard is that meta-causal models abstract away some information about structural equations, such that interventions on Z might lead to a mismatch between the resulting SCM and the underlying mediation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E PROBABILITIES FOR SAMPLE COMPUTATION AND UPPER BOUNDS</head><p>Consider a dataset D ∈ R m×2 of m samples over two variables where we want to separate n different functions. We assume that the data distribution contains a uniform number of samples from each function, where each class could be under-or overrepresented by an offset of d. Specifically, we  (3)</p><p>P n (S) is the (lower bound on the) probability of selecting a correct set of samples. We can calculate the number of trials k needed to find such a set of samples with at least 95% probability. The opposite probability, of never finding it with less than 5% probability, is easier to calculate:</p><formula xml:id="formula_13">(1 -P (S)) k ≤ 1 -0.95 = 0.05 k ln(1 -P (S)) ≤ ln(0.05) k ≤ ln(0.05) ln(1 -P (S))</formula><p>This allows us to determine how many attempts might be necessary. Note that while this would leave a 5% chance of not picking the right samples, there are various practical reasons why the actual probability of finding a working set of samples will be higher, e.g., if the number of samples from each class is not as uneven as assumed, or if some samples are distributed in such a way that even picking a sample from the "wrong" class might still lead to the identification of the correct mechanisms.</p><p>For example, if n = 2 and d = 0.2, we have an expected probability of E[P (S)] = 2! 2 2•2 = 0.125 and a lower bound of P 2 (S) = P (S new even )P (S same even ) ≥ 0.8 2 • 2 2 • 1.2 2 • 0.8 2 = 0.096. Larger deviations decrease the probability while a deviation of d = 0 results in the same probability as with E[P (S)]. For the lower bound, this results in k = 30 samples for a confidence of 95% using the above calculation steps. All resulting sample counts can be found in Table <ref type="table" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F EM CONVERGENCE RESULTS</head><p>The required number of resamples for a 95% success rate of the RANSAC algorithm is calculated by log(0.05)/log(1 -C 1 ), where S1 are the convergence rates for the individual samples computed in Sec. E.</p><p>Empirical convergence probabilities and resulting resampling counts for the LO-RANSAC algorithm are shown in Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table" target="#tab_4">3</ref>. Table <ref type="table">4</ref> lists the goodness of fit for all converged samples. In general, we find that in cases where the approach is able to converge, it undercuts the required parameter convergence boundary of 0.2 by factors of 4.8 and 3.5 for the slope and intercept, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G MECHANISM SAMPLING</head><p>For our experiments in Sec. 4.2 we uniformly sample the number of mechanisms to be in K ∈ {1..4}. The slopes of the linear equations are uniformly sampled between α ∈ ±[0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H PRACTICAL APPLICATIONS OF META-CAUSAL MODELS</head><p>As the main focus of our initial work on meta-causal model lies on providing a first, formal, definition of meta-causal models, we tried to approach MCM from a spectrum of different theoretical Class Deviation 1 Mechanism 2 Mechanisms 3 Mechanisms 4 Mechanisms 0.0 0.0349|0.0590 0.0370|0.0543 0.0380|0.0592 0.0389|0.0516 0.1 " 0.0381|0.0555 0.0381|0.0566 0.0346|0.0528 0.2 " 0.0414|0.0548 0.0412|0.0567 0.0402|0.0570</p><p>Table <ref type="table">4</ref>: Mean average error for the slope and intercept of the correctly predicted mechanism for different class imbalances and number of mechanisms. Mechanisms are accepted if their parameters do not differ by more than 0.2 from the ground truth parameterization. The results show that converged samples are typically estimated with an error well below the threshold.</p><p>perspectives. In this Section, we provide a brief discussion on two possible practical fields of applications for MCM.</p><p>Health and Medicine. First, we would like to expand on our stress-induced fatigue example as it can not be reduced to a standard SCM, and provide an actionable perspective on MCM. While we still assume the underlying neuropsychological process to be more complex, with multiple interplaying factors to influence each other, we consider the same simplified model as presented in the paper. We now assume that some drug exists that is able to influence certain health related processes within the patient, such that the underlying -previously self-reinforcing-stress relation is unconditionally changed to a suppressing one. (Upon closer consideration, the previous intervention might constitute a meta-causal do-operator, as we detach the functional type from the underlying dynamics and fix its particular functional type.)</p><p>This perspective not only allows the forecast of system changes, but also yields an actionable model which can be actively steered between meta-causal states. To permanently treat a patient, one could consider the objective to reach a self-stabilizing meta-causal state. Note how this meta-causal objective might be different to that of a classical causal one, where stress levels would similarly be reduced, but no attention is placed on the (possibly unchanged) system dynamics, such that stress levels might rise up again after the intervention ends.</p><p>Economics. Second, recall that our MCMs are defined as finite state machines. Figuring out exact transition conditions that induce meta-causal state transitions also yield important insights on the volatility/stability of systems in terms of risk analysis and policy making. Such scenarios might commonly arise in economics, where relations in markets can change due to the sudden appearance of disrupting factors (e.g. a new competitor entering the market or a financial crisis) while effects might persist even with the disrupting factor having vanished.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I ASSERTIVE META-CAUSAL MODELS</head><p>In this section we will briefly touch upon possible assertive properties of meta-causal models. In this initial paper we chose to utilize a very general definition of types, which intentionally held flexible to allow for the most descriptive models. As for this definition, there might exist a gap between between the descriptive modeling of MCM and their 'assertive', data generating, properties. This gap primarily stems from the mapping of specific structural equations onto abstract types, which prevents a back projection of types to structural equations in the general case. With the special class of conditionally reducible SCM we, however, presented a particular class of MCM that yield 'assertive' properties by being able to translate types back onto the level of structural equations. Further restrictions on types and their relations to structural equations might be placed in specific applications, to shield users from misuse of the framework. Still, we where able to present several relevant applications of MCM even with this this most general formalization of MCM.</p><p>While meta-causal states might be mapped back to configurations of 'classical' causal models, we highlight that MCM are primarily concerned with the modeling of the overarching meta-causal state transitions. By modeling MCM as (possibly non-deterministic) finite-state machines, we, in fact, can make predictions about a systems' future course on the meta-level. This includes the sampling of state trajectories and making assertions about their stability and similar properties.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Sampled Mechanisms. The figure shows a selection of different randomly sampled mechanism distributions, ranging from one to up to four simultaneously present mechanisms. The gray dotted lines represent the generating ground truth mechanisms. (Best Viewed In Color)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Confusion Matrices for Identifying Meta-Causal Mechanisms. The table shows identification results for predicting the number of mechanisms for the bivariate case for 100 randomly sampled meta-causal mechanisms. d is the maximum sample deviation from the average mechanism probability. Rows indicate the true number of mechanisms, while columns indicate the algorithms'</figDesc><table><row><cell>3 4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>The problem we are trying to solve is twofold : first, we are initially unaware of the underlying meta-causal state t that generated a particular data point (x i , y i ), which prevents us from estimating the parameterization (α k , β k ) of the mechanism. Conversely, our lack of knowledge about the mechanism parameterizations (α k , β k ) k∈[1..K] prevents us from assigning class probabilities to the individual data points. Since neither the state assignment nor the mechanism parameterizations are initially known, we perform an Expectation-Maximization (EM;<ref type="bibr" target="#b16">Dempster et al. (1977)</ref>) procedure to iteratively estimate and assign the observed data points to the discovered meta-causal state parameterizations. Due to the local convergence properties of the EM algorithm, we further embed it into a locally optimized local random sample consensus approach (LO-RANSAC; Fischler Estimated Number of Required Resamples for Obtaining a 95% Convergence Rate with the LO-RANSAC Algorithm per Number of Mechanisms and Maximum Class Deviation.</figDesc><table><row><cell></cell><cell cols="5">Analysis Type 1 Mechanism 2 Mech. 3 Mech. 4 Mech.</cell></row><row><cell>Max. Class</cell><cell>Theoretical</cell><cell>1</cell><cell>23</cell><cell>363</cell><cell>8,179</cell></row><row><cell>Deviation = 0.0</cell><cell>Empirical</cell><cell>2</cell><cell>8</cell><cell>24</cell><cell>173</cell></row><row><cell>Max. Class</cell><cell>Theoretical</cell><cell>1</cell><cell>26</cell><cell>429</cell><cell>10,659</cell></row><row><cell>Deviation = 0.1</cell><cell>Empirical</cell><cell>2</cell><cell>8</cell><cell>25</cell><cell>177</cell></row><row><cell>Max. Class</cell><cell>Theoretical</cell><cell>1</cell><cell>30</cell><cell>526</cell><cell>14,859</cell></row><row><cell>Deviation = 0.2</cell><cell>Empirical</cell><cell>2</cell><cell>8</cell><cell>26</cell><cell>177</cell></row></table><note><p><p><p><p><ref type="bibr" target="#b18">&amp; Bolles (1981)</ref></p>;</p><ref type="bibr" target="#b11">Chum et al. (2003)</ref></p>). RANSAC approaches repeatedly sample initial parameter configurations to avoid local minima, and successively perform several steps of local optimizationhere the EM algorithm -to regress the true parameters of the mechanism.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Mechanistic Decomposition asMeta-Causal States. (left)  The effect of the stress level on itself (orange) plotted against the identity (blue; corresponding to a non-self-reinforcing effect). Once a certain threshold is reached, the function switches its behavior from self-suppressing to a self-reinforcing effect. (center) Contribution of the stress level mechanism for varying external stressors. Red arrows indicate a self-reinforcing effect, while green arrows indicate a suppressive effect. The gray area highlights the system configuration without external stressors. Although all states are governed by the same structural equations, our meta-causal analysis identifies the mechanistic difference and decomposes the corresponding initial conditions into different meta-causal states. (right) The standard SCM gets decomposed into different meta-causal states. While the graph adjacency remains the same, the different starting conditions identify different behavioral types of the causal mechanism. (Best viewed in color.)</figDesc><table><row><cell>Stress Level t</cell><cell>0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0</cell><cell>Stress Level t-1</cell><cell>Stress Level</cell><cell>0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.2 0.1 0.0</cell><cell>0.0</cell><cell>0.2 External Stressors 0.4 0.6</cell><cell>0.8</cell><cell>1.0</cell><cell>E E E</cell><cell>S S S</cell></row><row><cell cols="2">Figure 2:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Empirical estimated convergence percentage of the EM algorithm for different class imbalances and number of mechanisms. The table shows the number of samples converged and the convergence rates (in parentheses) for a single random initialization and for estimating the parameterization of the underlying system for a given number of mechanisms. All results are reported per 5000 samples.</figDesc><table><row><cell cols="2">In total, the probability of selecting of a correct sample set is the product of the two probabilities</cell></row><row><cell>above, i.e,</cell><cell></cell></row><row><cell>P n (S) =</cell><cell>P n (S new even )P n (S same even ) if n is even P n (S new odd )P n (S same odd ) if n is odd.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Implying unimodality and monotonic decreasing from zero allows us to distinguish the noise mean and intercept and to recover the parameters from a simple linear regression</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Since mechanisms can go in both directions, X → Y and Y → X (cyclic relations are not considered), we repeat the regression for both directions and use an Anderson-Darling test (Anderson &amp;<ref type="bibr" target="#b1">Darling, 1952)</ref> on the residual to test which of the distributions more closely resembles a Laplacian distribution at each step.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Note in this context, that we assume structural equations to be uniquely identifiable. This might be implemented via type-theoretic considerations in which every variable of the underlying process gets assigned a unique type, such that for every si ∈ Si, ∀i, j.i ̸ = j ⇒ Si ̸ = Sj hold. Even though two functions might be isomorphic they can be thus be differentiated via their domain and codomain. In practice, one might additionally consider the computations graph of the mediation process to uniquely differentiate between isomorphic functions</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The Technical University of Darmstadt authors received funding by the <rs type="funder">EU</rs> project <rs type="projectName">EXPLAIN</rs>, funded by the <rs type="funder">German Federal Ministry of Education and Research (BMBF)</rs> (grant <rs type="grantNumber">01-S22030D</rs>). They acknowledge the support of the <rs type="funder">German Science Foundation (DFG)</rs> project "<rs type="projectName">Causality, Argumentation</rs>, and <rs type="person">Machine Learning</rs>" (<rs type="grantNumber">CAML2</rs>, <rs type="grantNumber">KE 1686/3-2</rs>) of the SPP 1999 "<rs type="projectName">Robust Argumentation Machines</rs>" (RATIO). This work is supported by the <rs type="funder">Hessian Ministry of Higher Education, Research, Science and the Arts (HMWK</rs>; projects "The <rs type="projectName">Third Wave of AI</rs>"). It was funded by the <rs type="funder">European Union</rs>. Views and opinions expressed are, however, those of the author(s) only and do not necessarily reflect those of the European Union or the <rs type="funder">European Health and Digital Executive Agency (HaDEA)</rs>. Neither the <rs type="funder">European Union</rs> nor the granting authority can be held responsible for them. Grant Agreement no. <rs type="grantNumber">101120763 -TANGO</rs>. This work was supported from the <rs type="funder">National High-Performance Computing project for Computational Engineering Sciences</rs> (<rs type="grantNumber">NHR4CES</rs>).</p><p>The <rs type="institution">Eindhoven University of Technology</rs> authors received support from their <rs type="funder">Department of Mathematics and Computer Science</rs> and the <rs type="projectName">Eindhoven Artificial Intelligence Systems Institute</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_ta3DKAh">
					<orgName type="project" subtype="full">EXPLAIN</orgName>
				</org>
				<org type="funding" xml:id="_hN6Juza">
					<idno type="grant-number">01-S22030D</idno>
				</org>
				<org type="funded-project" xml:id="_ZQhBKWt">
					<idno type="grant-number">CAML2</idno>
					<orgName type="project" subtype="full">Causality, Argumentation</orgName>
				</org>
				<org type="funded-project" xml:id="_V3HG4tN">
					<idno type="grant-number">KE 1686/3-2</idno>
					<orgName type="project" subtype="full">Robust Argumentation Machines</orgName>
				</org>
				<org type="funded-project" xml:id="_ZErKwZX">
					<orgName type="project" subtype="full">Third Wave of AI</orgName>
				</org>
				<org type="funding" xml:id="_qXREmpy">
					<idno type="grant-number">101120763 -TANGO</idno>
				</org>
				<org type="funding" xml:id="_jDeWBCP">
					<idno type="grant-number">NHR4CES</idno>
				</org>
				<org type="funded-project" xml:id="_wRHR4F5">
					<orgName type="project" subtype="full">Eindhoven Artificial Intelligence Systems Institute</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX FOR "SYSTEMS WITH SWITCHING CAUSAL RELATIONS: A META-CAUSAL PERSPECTIVE"</head><p>The appendix is structured as follows: In Sec. A we describe the general emergence of causal relations in SCM from the underlying mediating process. In Sec. B we discuss desirable classes of identification functions. In Sec. C we consider the existence and compatibility of decomposed equations. In Sec. D we prove a condition for the reduction for meta-causal models to conditioned SCM. In Sec. E we derive the formula for the theoretical upper bound of the 95% confidence interval. Sec F present the sample statistics and convergence results of the applied LO-RANSAC algorithm. In Sec. G we present the exact parameters for sampling bivariate meta-causal mechanism data. In Sec. H we discuss further practical applications of meta-causal models. Finally, in Sec. I, we discuss possible assertive properties of meta-causal models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A EMERGENCE OF CAUSAL EFFECTS FROM MEDIATING PROCESSES</head><p>The definition of a meta-causal frames (Def. 1) grounds the emergence of standard SCM to an underlying mediating process E. In particular, for any meta-causal frame, particular causal interactions are read via the identification function. While the underlying mediation process is time-dependent, the resulting causal graph is the projection of all causal interactions within the process onto a graphical structure. Note, however, that the resulting SCM still preserves the sequence of causal interactions through the DAG induced partial ordering of variables. This 'logical' time ordering (induced via the partial order) can be seen as an abstraction of the underlying process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B DESIRABLE CLASSES OF IDENTIFICATION FUNCTIONS</head><p>Particular choices of different identification functions will result in different identified meta-causal states. However, from a classical causal perspective it might be desirable to choose particular classes of functions to identify faithful SCM. In particular, one could ask the question whether indirect effects are of interest and should also be identified by the identification function. Consider a scenario where three variables X, Y, Z are considered as part of an to-be-identified SCM from an underlying process. In our scenario we identify the direct causal effects X → Y and Y → Z and -under the assumption that no further direct edges can be identified-, assume the graph to be faithful and we do not identify the indirect causal relation X → Z. This however changes, once variable Y is dropped out of the variable set X of the SCM. Now, with the same underlying mediating process we want our identification function to identify X → Z, which was omitted before. Generally, we assume that in most cases identification function that identify direct causal effects with regard to X are the most common.</p><p>Following this rather high-level discussion, we frame the previous procedure in terms of the identification function and functional relation. Given all functional relations X S , the type decoder can determine whether the whole functional relation X j between variables X j is mediated by some other (set of) intermediate mechanism(s) X z 3 . In situations where X i → X z → X j the type encoder needs to identify whether the relation X i → X j is purely mediated via X S z (meaning that all computational paths from X i to X j in X S j that does not passes through X S z ) or some additional direct effect exists that are not 'shielded' by X S z . Conversely, whenever some X k ∈ X z of the intermediate set is dropped/marginalized from the causal variables, the mechanism X S k ⊂ X S j is no longer identified as the mechanism of a causal variable within the overall X S j and (given that the remaining X S z\{k} does not shield X i from X j ) a direct arrow X i → X j can be inferred. Given our meta-causal framework we, however, have the freedom to identify the indirect relations. In that case one might assign these edges a particular '[1-hop] indirection' type, indicating it to assume that each function is represented by (1±d) 1 n |D| samples, i.e., the probability of encountering a particular class X is 1-d n ≤ P (X) ≤ 1+d n and E[P (X)] = 1 n . To identify all functions between these two variables, we assume linearity and apply EM with RANSAC on random pairs of samples (see Section 4.2). By selecting n pairs, there is a chance that one pair is chosen from each function (we will refer to such a set of pairs as a "correct" set of samples). In this section, we derive the probability of a correct pair being chosen at random, so that we can estimate how many times pairs need to be sampled to reliably encounter a correct set of samples.</p><p>We denote S as the event of "correctly" sampling all n pairs from all n different functions. If all classes have the same number of samples, the chance of randomly selecting a pair from a new class is n n • 1 n for the first pair of samples, n-1 n • 1 n for the second, . . . , and 1 n • 1 n for the last; in short:</p><p>If the data distribution is not perfectly uniform, i.e., d ̸ = 0, we can also calculate a lower bound for the same probability. Consider two probabilities per sample: the probability of selecting a new class P n (S new ) and the probability of selecting a second sample of the same class P n (S same ) afterwards. Across all samples, these correspond to n! n n and ( 1 n ) n in E[P n (S)], respectively. Let us first consider the probability of selecting a new class. When the first sample is taken, only one new class can be selected (probability of 1). If this sample was taken from the largest class first, the probability that subsequent samples will be taken from new classes decreases, since the space of "unsampled" classes is smaller. For this lower bound, we therefore assume that maximally large classes are sampled from as much and as early as possible. According to our assumptions, the largest classes each take up a fraction of 1+d n of the data. Therefore, the probability of selecting a new class for successive samples has the following probabilities n n , n-( <ref type="formula">1+d</ref>) n , n-(1+d)2 n , . . . . First, consider the case where n is even. Here, after all the n 2 largest classes have been selected, only the small classes remain. For the last, second to last, . . . classes, this probability is represented by</p><p>, . . . . Overall, we get the probability</p><p>If n is uneven, an average size class between the largest and smallest classes must be included:</p><p>The probability of selecting a second sample of the same class is easier to calculate. Instead of constant probabilities as in the expectation with 1 n , we now have two different probabilities in the even case and three in the odd case. In the even case, we have n 2 large batches and the same number of small batches, so the probability of choosing the right batch each time is</p><p>In the uneven case, we also have to also consider the batch that has an average size</p><p>.</p><p>Note that for both P n (S new ) and P n (S same ), the distribution of the data into the largest and smallest possible batches (according to our assumptions) results in the smallest possible probabilities; hence, the computed probability is a lower bound. If the batches were more evenly sized, the probability would be larger. We can also see that a deviation of up to 1 results in a probability of 0, since it is impossible to sample from a class that is not represented in the data. (α, β, b, d) ← bestParameters 27:</p><p>x l , y l , c l ← selectClass(x, y, c, l) ▷ Select points where argmax c = l.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>28:</head><p>x l , y l ← filter(x l , y l , c l , 0.4) ▷ Keep points s.t. max #2 c l &lt; 0.4(1max #1 (c l ).</p><p>29: r = LinEq(x l , y l ; α l , β l , d l ) -y l 30:</p><p>if not AndersonDarling(r, 0.95) then </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><surname>Tara V Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adèle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><surname>Bareinboim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.12263</idno>
		<title level="m">Effect identification in cluster causal diagrams</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Asymptotic theory of certain&quot; goodness of fit&quot; criteria based on stochastic processes. The annals of mathematical statistics</title>
		<author>
			<persName><forename type="first">Theodore</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Anderson</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">A</forename><surname>Darling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1952">1952</date>
			<biblScope unit="page" from="193" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dynamic interactions in artificial environments: causal and non-causal aspects for the emergence of meaning</title>
		<author>
			<persName><forename type="first">Argyris</forename><surname>Arnellos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Spyrou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Darzentas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Systemics, Cybernetics and Informatics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="82" to="89" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Abstracting causal models</title>
		<author>
			<persName><forename type="first">Sander</forename><surname>Beckers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">Y</forename><surname>Halpern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the aaai conference on artificial intelligence</title>
		<meeting>the aaai conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2678" to="2685" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A markovian decision process</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Bellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of mathematics and mechanics</title>
		<imprint>
			<biblScope unit="page" from="679" to="684" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Traumatic stress: effects on the brain</title>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Bremner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogues in clinical neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="445" to="461" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Typing assumptions improve identification in causal discovery</title>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Brouillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Perouz</forename><surname>Taslakian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Drouin</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Causal Learning and Reasoning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="162" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Origins and outcomes of individual differences in emotion regulation. The Development of Emotion Regulation: Biological and Behavioral Considerations</title>
		<author>
			<persName><surname>Calkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Monographs of the Society for Research in Child Development</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tests for the goodness-of-fit of the laplace distribution</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics-Simulation and Computation</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Optimal structure identification with greedy search</title>
		<author>
			<persName><forename type="first">David</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chickering</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="507" to="554" />
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Responsibility and blame: A structural-model approach</title>
		<author>
			<persName><forename type="first">Hana</forename><surname>Chockler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">Y</forename><surname>Halpern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="93" to="115" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Locally optimized ransac</title>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiří</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition: 25th DAGM Symposium</title>
		<title level="s">Proceedings</title>
		<meeting><address><addrLine>Magdeburg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">September 10-12, 2003. 2003</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="236" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A global measure of perceived stress</title>
		<author>
			<persName><forename type="first">Sheldon</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kamarck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Mermelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of health and social behavior</title>
		<imprint>
			<biblScope unit="page" from="385" to="396" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Towards a grounded theory of causation for embodied ai</title>
		<author>
			<persName><forename type="first">Taco</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.13973</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Counterfactual transportability: a formal approach</title>
		<author>
			<persName><forename type="first">Sanghack</forename><surname>Juan D Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4370" to="4390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Ishita</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvia</forename><surname>Chiappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jovana</forename><surname>Mitrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeb</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08162</idno>
		<title level="m">Causal reasoning from meta-reinforcement learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the em algorithm</title>
		<author>
			<persName><forename type="first">Nan</forename><forename type="middle">M</forename><surname>Arthur P Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the royal statistical society: series B (methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Psychological stress and cardiovascular disease</title>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">E</forename><surname>Dimsdale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American College of Cardiology</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1237" to="1246" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography</title>
		<author>
			<persName><forename type="first">A</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="381" to="395" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural mechanisms of stress resilience and vulnerability</title>
		<author>
			<persName><forename type="first">Bechara</forename><forename type="middle">J</forename><surname>Tamara B Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabelle</forename><forename type="middle">M</forename><surname>Saab</surname></persName>
		</author>
		<author>
			<persName><surname>Mansuy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="747" to="761" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">What would have happened? counterfactuals, hypotheticals and causal judgements</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Gerstenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B</title>
		<imprint>
			<biblScope unit="volume">377</biblScope>
			<biblScope unit="page">20210339</biblScope>
			<date type="published" when="1866">1866. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Counterfactual simulation in causal cognition</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Gerstenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">From counterfactual simulation to causal judgment</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Gerstenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lagnado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the annual meeting of the cognitive science society</title>
		<meeting>the annual meeting of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Review on psychological stress detection using biosignals</title>
		<author>
			<persName><forename type="first">Giorgos</forename><surname>Giannakakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Grigoriadis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katerina</forename><surname>Giannakaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olympia</forename><surname>Simantiraki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on affective computing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="440" to="460" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Alexandros Roniotis, and Manolis Tsiknakis</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><surname>Haggerty</surname></persName>
		</author>
		<title level="m">Stress, risk, and resilience in children and adolescents: Processes, mechanisms, and interventions</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Axiomatizing causal reasoning</title>
		<author>
			<persName><surname>Joseph Y Halpern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="317" to="337" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Actual causality</title>
		<author>
			<persName><surname>Joseph Y Halpern</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>MiT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Invariant causal prediction for nonlinear models</title>
		<author>
			<persName><forename type="first">Christina</forename><surname>Heinze-Deml</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Causal Inference</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">20170016</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Beyond linear mediation: Toward a dynamic network approach to study treatment processes</title>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">E</forename><surname>Stefan G Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">C</forename><surname>Curtiss</surname></persName>
		</author>
		<author>
			<persName><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Psychology Review</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">101824</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Nonlinear causal discovery with additive noise models</title>
		<author>
			<persName><forename type="first">Patrik</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergio</forename><surname>Hernan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garrido</forename><surname>Mejia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09024</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">Phenomenological causality. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Algorithmic recourse: from counterfactual explanations to interventions</title>
		<author>
			<persName><surname>Amir-Hossein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><surname>Valera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM conference on fairness, accountability, and transparency</title>
		<meeting>the 2021 ACM conference on fairness, accountability, and transparency</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Targeted reduction of causal models</title>
		<author>
			<persName><forename type="first">Armin</forename><surname>Kekić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Besserve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR 2024 Workshop on AI4DifferentialEquations In Science</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Passive learning of active causal strategies in agents and language models</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishita</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Structural causal bandits: Where to intervene?</title>
		<author>
			<persName><forename type="first">Sanghack</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Implicit representations of meaning in neural language models</title>
		<author>
			<persName><forename type="first">Belinda Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.00737</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aspen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernanda</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Hanspeter</surname></persName>
		</author>
		<author>
			<persName><surname>Wattenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.13382</idno>
		<title level="m">Emergent world representations: Exploring a sequence model trained on a synthetic task</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Graph switching dynamical systems</title>
		<author>
			<persName><forename type="first">Yongtuo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Magliacane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miltiadis</forename><surname>Kofinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Efstratios</forename><surname>Gavves</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="21867" to="21883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fatigue as the chief complaint: epidemiology, causes, diagnosis, and treatment</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Maisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erika</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norbert</forename><surname>Donner-Banzhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Deutsches Ärzteblatt International</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page">566</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Tom</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">Winn</forename><surname>Gates</surname></persName>
		</author>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Gedanken-experiments on sequential machines</title>
		<author>
			<persName><surname>Edward F Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automata studies</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="129" to="153" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A measure-theoretic axiomatisation of causality</title>
		<author>
			<persName><forename type="first">Junhyung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krikamol</forename><surname>Muandet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="28510" to="28540" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">The book of why: the new science of cause and effect. Basic books</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Mackenzie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Causal inference by using invariant prediction: identification and confidence intervals</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bühlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B: Statistical Methodology</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="947" to="1012" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Paul K Rubenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Weichwald</surname></persName>
		</author>
		<author>
			<persName><surname>Bongers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Grosse-Wentrup</surname></persName>
		</author>
		<author>
			<persName><surname>Schölkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.00819</idno>
		<title level="m">Causal consistency of structural equation models</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Steindór</forename><surname>Saemundsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katja</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deisenroth</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07551</idno>
		<title level="m">Meta reinforcement learning with latent variable gaussian processes</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A meta-reinforcement learning algorithm for causal discovery</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erman</forename><surname>Sauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Lavet</forename><surname>Francois</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Causal Learning and Reasoning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="602" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The perceived stress reactivity scale: measurement invariance, stability, and validity in three countries</title>
		<author>
			<persName><forename type="first">Wolff</forename><surname>Schlotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilona</forename><forename type="middle">S</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peggy</forename><forename type="middle">M</forename><surname>Zoccola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological assessment</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">80</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eleni</forename><surname>Sgouritsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joris</forename><surname>Mooij</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.6471</idno>
		<title level="m">On causal and anticausal learning</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Causal models: The representational infrastructure for moral judgment</title>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">M</forename><surname>Steven A Sloman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Fernbach</surname></persName>
		</author>
		<author>
			<persName><surname>Ewing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of learning and motivation</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Invariant policy optimization: Towards stronger generalization in reinforcement learning</title>
		<author>
			<persName><forename type="first">Anoopkumar</forename><surname>Sonar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Pacelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudha</forename><surname>Majumdar</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Learning for Dynamics and Control</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="21" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Causation, prediction, and search</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Clark N Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName><surname>Heckerman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">Davide</forename><surname>Talon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Lippe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessio</forename><surname>Del Bue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Magliacane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.09830</idno>
		<title level="m">Towards the reusability and compositionality of causal representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">On the fairness of causal algorithmic recourse</title>
		<author>
			<persName><forename type="first">Julius</forename><surname>Von Kügelgen</surname></persName>
		</author>
		<author>
			<persName><surname>Amir-Hossein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Umang</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="9584" to="9594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Wahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urmi</forename><surname>Ninad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Runge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.07047</idno>
		<title level="m">Foundations of causal discovery on groups of variables</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The meaning of cause and prevent: The role of causal mechanism</title>
		<author>
			<persName><forename type="first">Clare R</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">A</forename><surname>Sloman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mind &amp; Language</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="52" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Emotion regulation and stress</title>
		<author>
			<persName><forename type="first">Manjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimberly</forename><forename type="middle">J</forename><surname>Saudino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Adult Development</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="95" to="103" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Do not marginalize mechanisms, rather consolidate</title>
		<author>
			<persName><forename type="first">Matej</forename><surname>Moritz Willig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Zečević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Singh Dhami</surname></persName>
		</author>
		<author>
			<persName><surname>Kersting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Conference on Neural Information Processing Systems (NeurIPS)</title>
		<meeting>the 37th Conference on Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Causality with gates</title>
		<author>
			<persName><forename type="first">John</forename><surname>Winn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1314" to="1322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Representing causation</title>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Wolff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology: General</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">82</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Learning causal dynamics models in objectoriented environments</title>
		<author>
			<persName><forename type="first">Zhongwei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingqing</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dengpeng</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.12615</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Causal parrots: Large language models may talk causality but are not causal</title>
		<author>
			<persName><forename type="first">Matej</forename><surname>Zečević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Willig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Singh Dhami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">A survey on causal reinforcement learning</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruichu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuchun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Libo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Hao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.05209</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Transfer learning in multi-armed bandit: a causal approach</title>
		<author>
			<persName><forename type="first">Junzhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems</title>
		<meeting>the 16th Conference on Autonomous Agents and MultiAgent Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1778" to="1780" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
