<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Simpson&apos;s paradox, a tale of causality</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2017-12-15">December 15th, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Antoine</forename><surname>Chambaz</surname></persName>
							<email>antoine.chambaz@parisdescartes.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Paris Descartes</orgName>
								<orgName type="institution" key="instit2">Université Paris-Sorbonne</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Paris Descartes</orgName>
								<orgName type="institution" key="instit2">Université Paris-Sorbonne</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Isabelle</forename><surname>Drouet</surname></persName>
							<email>isabelle.drouet@paris-sorbonne.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Paris Descartes</orgName>
								<orgName type="institution" key="instit2">Université Paris-Sorbonne</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Paris Descartes</orgName>
								<orgName type="institution" key="instit2">Université Paris-Sorbonne</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sonia</forename><surname>Memetea</surname></persName>
							<email>sonia.memetea@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Paris Descartes</orgName>
								<orgName type="institution" key="instit2">Université Paris-Sorbonne</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Paris Descartes</orgName>
								<orgName type="institution" key="instit2">Université Paris-Sorbonne</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Simpson&apos;s paradox, a tale of causality</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-12-15">December 15th, 2017</date>
						</imprint>
					</monogr>
					<note type="submission">Submitted on 15 Dec 2017</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>causality, Simpson&apos;s paradox</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L'archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Résumé</head><p>Le paradoxe de Simpson peut induire en erreur jusqu'au mathématicien prudent. Nous présentons le paradoxe de Simpson et discutons sa nature en nous appuyant sur trois exemples. Il apparaît que pour se faire prendre à son piège, il suffit (a) de combiner un raisonnement probabiliste hasardeux avec un raisonnement causal inattaquable, ou bien (b) de confondre le concept évidentiel d'apprentissage à partir de l'observation, qui pour des agents rationnels procède par conditionnement selon les données, avec le concept causal d'action tel qu'il est représenté en analyse causale par une intervention dans un graphe. Mots-clefs : causalité, paradoxe de Simpson</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Overview</head><p>The literature on Simpson's paradox is vast. Early accounts date back to <ref type="bibr" target="#b27">(Yule, 1900;</ref><ref type="bibr" target="#b23">Pearson, 1900;</ref><ref type="bibr" target="#b15">Cohen and Nagel, 1934)</ref> well before the phrase "Simpson's paradox" was coined by <ref type="bibr" target="#b10">Blyth in 1972.</ref> We do not aim to provide an original solution or an extensive review of the literature, but rather to offer a teaser to the present volume.</p><p>The reason why this introductory article, in a volume on causal analysis, is devoted to Simpson's paradox is that we endorse <ref type="bibr" target="#b20">Pearl (2011</ref><ref type="bibr" target="#b21">Pearl ( , 2014))</ref>'s view that this paradox is essentially a causal one. Following <ref type="bibr" target="#b25">Quine (1976)</ref> we will construe a paradox as "a conclusion that at first sounds absurd but has an argument to sustain it". Our claim is that in the case of Simpson's paradox the air of absurdity originates in a conflicting (often covert) causal interpretation of the premises of the sustaining argument. More precisely, it stems from a conflict between the probabilistic characterization of those situations that count as instances of the paradox and the naive causal reading we more or less naturally make of these situations. The main aim of the article is to substantiate this claim and to explain how unreflective reasoning based on an undue causal interpretation can elicit the surprising elements evinced by Simpson's paradox on a first encounter.</p><p>To pursue this argument, we turn to a close examination of three concrete examples. Our investigation aims to bring out into the open the causal nature of the psychological surprise elicited by Simpson's paradox, and thus to throw light on the nature of the paradox.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Simpson's paradox illustrated</head><p>The time-honored probabilistic characterization of Simpson's paradox is silent on the question of causality. Narrowly construed, Simpson's paradox is simply a pattern of probabilistic reversal, which involves the reversal or cancellation of a global association between two variables, when conditioned upon a third. Yet to bring out its specific interest and challenge, it is necessary to supplement the probabilistic account with narrative information, to characterize scenarios, that is, interpreted instances of the mathematical pattern of reversal adumbrated above. In this section we present three plausible scenarios, both to exemplify the phenomenon and to structure the ensuing discussion.</p><p>The first example is taken from <ref type="bibr" target="#b18">(Julious and Mullee, 1994)</ref>. The actual data are reported in Table <ref type="table" target="#tab_1">1</ref>.</p><p>Example A (Comparing kidney stone removal modus operandi). <ref type="bibr" target="#b13">Charig et al. (1986)</ref> undertook a historical comparison of success rates in removing kidney stones. Overall, open surgery (method m 1 ) had a smaller success rate than percutaneous nephrolithotomy (method m 2 ). However, the success rates looked rather different when stone diameter was taken into account. For stones of diameter smaller than 2cm, open surgery was more successful compared with percutaneous nephrolithotomy. Likewise, for stones of diameter larger than 2cm, open surgery was more successful than percutaneous nephrolithotomy.</p><p>Discussed at greater length in Section 3, Example A is a straightforward instance of Simpson's paradox, insofar as the association between method and success is quite evidently reversed when conditioning on the stone diameter. Yet even a cursory glance at Example A reveals obvious causal underpinnings. The puzzling probabilistic reversal baffles our causal intuition to the effect that if the best way to cure a disease in subpopulations is to apply a certain method, then that method ought to prevail in the aggregated population as a whole. But the probabilistic pattern appears to tell a different story; to wit, that contrary to our intuitive causal projection, the outperformed method seems to be the optimal choice at the aggregated level (later on we will argue that it is not, and that it is a mere probabilistic quirk, an artifact of a specific kind of causal model).</p><p>Example A is an easy case for us in the sense that its causal dimension is quite explicit. For this same reason, it is insufficient to establish that Simpson's paradox in general is causal in nature. This motivates the introduction and discussion of Example B. Taken from <ref type="bibr" target="#b8">(Bandyoapdhyay et al., 2011)</ref>, it is attributed to J. G. Bennett. Table 2 gives a synthetic numerical example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example B (Bags of marbles).</head><p>Suppose we have two bags of marbles, all of which are either big or small, and red or blue. Suppose that in each bag the proportion of red to blue is higher among the large than among the small marbles. Now suppose we pour all the marbles from both bags into one box. Would we expect it to be more probable to be red for large marbles of the box than for small marbles of the box? Most of us would indeed expect it and therefore would be surprised to find out that this may fail to be the case. Table <ref type="table" target="#tab_2">2</ref> exhibits such a failure.</p><p>In stark contrast with Example A, no causality is at play in Example B. Does our uneasiness merely stem from what we would like to call an "arithmetical surprise", that is, the revelation that seemingly natural but in fact reckless arithmetical derivations are invalid? Yes, but only partly. Section 4 mainly aims at showing that there is more to Example A than the mere arithmetical surprise. We argue that our uneasiness is completely explained only once we realize that we cannot help but reading the situation causally. To sustain this claim, in presence of marbles, we argue by appealing to several betting games that involve marbles.</p><p>Elaborating on Sections 3 and 4, Section 5 finally develops our analysis of the nature of Simpson's paradox. We characterize it as a graded problem. Starting again from its probabilistic facet, we explore its evidential and, most importantly, causal dimensions. As the so called causal sure thing principle is at the core of the discussion, we devote Section 6 to sure thing principles and their relationship to Simpson's paradox.</p><p>All of this leaves open the question of the reality of Simpson's paradox. It does happen. However, one should not jump to conclusions too quickly. Consider for instance the following third and last example (which does not naturally lend itself to being accompanied by contingency tables because, contrary to Examples A and B, it does not reduce to counts).</p><p>Example C (Synthetic microbial system).</p><p>The evolution of cooperation offers a puzzle to solve. In the presence of producers and nonproducers of a "common good", where the latter benefit from the shared resource without bearing its cost of production, why does natural selection allow the former to survive? <ref type="bibr" target="#b14">Chuang et al. (2009)</ref> shed light on the problem by analyzing a series of synthetic microbial systems where the proportions of producers at the start of the experiment, controlled by design, range across 0%, 10%, . . . , 90%, 100%. They find that, in each non-pure system, the proportion of producers decreases during the fixed duration of the experiment, revealing that non-producers are advantaged indeed and grow faster than producers. However, the authors also find that the overall proportion of producers in a mixture of equal volumes of each non-pure system is larger at the end of the experiment than at its start (when it was 45%). <ref type="bibr" target="#b14">Chuang et al. (2009)</ref> claim that Example C is another real-life example of Simpson's paradox. Is it, really? Section 7 answers this question and closes the article. It suggests guidelines to decide whether or not putative instances of Simpson's paradox are genuine.</p><p>3 Example A: a causal surprise</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Association reversal</head><p>We make the statistical assumption that the empirical probabilities below estimate their theoretical counterparts. Being sure that they do would require knowing more about how the data set was built. To emphasize that the probabilities are empirical, we use the symbol P n in lieu of P .</p><p>On the one hand, considering the stone diameters separately, we observe that</p><formula xml:id="formula_0">P n (success|d &lt; 2, m 1 ) = 81 87 ≈ 93% &gt; P n (success|d &lt; 2, m 2 ) = 234 270 ≈ 87%,<label>(1)</label></formula><formula xml:id="formula_1">P n (success|d ≥ 2, m 1 ) = 192 263 ≈ 73% &gt; P n (success|d ≥ 2, m 2 ) = 55 80 ≈ 69%<label>(2)</label></formula><p>(in probability, open surgery is more successful than percutaneous nephrolithomy to remove stones of both small and large diameters). On the other hand, neglecting the stone diameters, we observe that</p><formula xml:id="formula_2">P n (success|m 1 ) = 273 350 ≈ 78% &lt; P n (success|m 2 ) = 289 350 ≈ 83%<label>(3)</label></formula><p>(in probability, percutaneous nephrolithomy is more successful than open surgery). The data in Table <ref type="table" target="#tab_1">1</ref> may be deemed surprising because they suggest that one method performs better than the other when stone diameter is taken into account, but performs worse when stone diameter is neglected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Causal construal of the case</head><p>The misleading suggestion originates in an unwary causal construal of the three probabilistic statements</p><formula xml:id="formula_3">P (success|d &lt; 2, m 1 ) &gt; P (success|d &lt; 2, m 2 ),<label>(4)</label></formula><formula xml:id="formula_4">P (success|d ≥ 2, m 1 ) &gt; P (success|d ≥ 2, m 2 ),<label>(5)</label></formula><p>P (success|m 1 ) &lt; P (success|m 2 ). (6)</p><p>Interpreting causally (4), ( <ref type="formula" target="#formula_4">5</ref>) and ( <ref type="formula">6</ref>) would commit us to a medical model where the presumed causal mechanism responsible for the successful removal of stones both of small and of large diameters somehow ceases to operate when stone diameter is neglected. Nothing in our understanding of causality can license this implication. This is where the paradox lies. But perhaps the reader finds this statement a little peremptory, so let us try to better articulate it. Suppose that we are asked which surgical method to perform to remove a kidney stone. If (6) were to express a genuine causal statement, then we ought to recommend performing percutaneous nephrolithomy. However, if (4) and (5) were to be interpreted as genuine causal statements too, then we ought to recommend performing open surgery, for we know that the stone diameter is necessarily either smaller or larger than 2cm. This is unsettling because we end up with two contradictory answers to the same question.</p><p>To elaborate, this situation arises from the underdetermination of the causal structure underlying (4), ( <ref type="formula" target="#formula_4">5</ref>), (6). It is simply impossible to go by the sole basis of these equations. To make a decision, it is necessary to supplement them with a causal model, for instance, a causal graph.</p><p>We assume that no other variable influences at least two among stone diameter, method and success. Therefore, there are 27 possible (as opposed to plausible) such graphs, of which we exclude the two cyclic ones. Some of the remaining graphs are not compatible with the dependence structure encapsulated in the data presented in Table <ref type="table" target="#tab_1">1</ref>. For instance, it cannot be the case that the graph features no arrow. However, the data alone do not single out a unique causal graph.</p><p>In particular, the two causal graphs of Figure <ref type="figure" target="#fig_0">1</ref> are undistinguishable based on the sole data. The LHS graph assumes that method influences causally success directly and indirectly, through stone diameter. Stone diameter is a mediating variable between method and success. Consequently, (6) can be interpreted causally, as opposed to (4) and ( <ref type="formula" target="#formula_4">5</ref>). On the contrary, the RHS graph assumes that stone diameter influences causally both method and success. Then stone diameter is a confounder and confounding is at play. Consequently, (4) and ( <ref type="formula" target="#formula_4">5</ref>) can be interpreted causally, as opposed to (6). In this light, Simpson's paradox can be viewed as an attempt to reconcile contradictory causal graphs such as those of Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>In Example A, the choice between graphs facilitates the solution to the puzzle. Intuitively given prior knowledge of cause and effect in the etiology of disease, it seems fair to assume (i) that both stone diameter and method do influence success causally, and (ii) that neither the method nor the success of the removal can causally influence stone diameter. The contrary would blatantly violate the chronology of events, which in general coincides with the causal ordering. Consequently, the choice of the RHS as the correct or most plausible causal representation of the scenario mandates the choice of open surgery.</p><p>The argument developed in the three previous paragraphs hinges on the assumption that no other variable influences at least two among stone diameter, method and success. If, on the contrary, age (for instance) is identified as a factor susceptible to causally influence all of stone diameter, choice of surgical method and success of the removal, then (4) and ( <ref type="formula" target="#formula_4">5</ref>) cannot be statements about causality anymore. Disaggregating the two LHS contingency tables in Table <ref type="table" target="#tab_1">1</ref> by conditioning on age may, or may not, suggest a different rule to choose which surgical method to use on a case-by-case basis. To understand how conditioning on age may in turn reverse, say, (4), it suffices to understand how conditioning on stone diameter reverses (6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Lessons for the representation of causality</head><p>All of this is quite difficult to express and still more to handle correctly. This establishes the usefulness of Pearl's do-operator in causal analysis <ref type="bibr" target="#b19">(Pearl, 2000)</ref>. In the remainder of the article, we will resort to do-calculus without further ado. We refer the unfamiliar reader to the above monograph or to ♣REFERENCES♣ in the present special issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Example B: an arithmetical surprise?</head><p>Our analysis of Example A makes it a causal paradox, which baffles our causal intuitions or, more precisely, our intuitive causal interpretations of probabilistic associations. It seems, however, that such an analysis cannot be given for all instances of Simpson's paradox.</p><p>Attributed to J. G. Bennett by <ref type="bibr" target="#b8">Bandyoapdhyay et al. (2011)</ref>, the conception of Example B was driven by the intention to exclude causality. For this reason, there ought to be no causality involved in our discomfort with Example B. In this case it looks as if the surprise were arithmetical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Arithmetical construal of the case</head><p>Consider the data in Table <ref type="table" target="#tab_2">2</ref>, which summarizes Example B. We observe that P (red|large, bag 1) = 12 30 = 40% &gt; P (red|small, bag 1) = 3 10 = 30%, ( <ref type="formula">7</ref>)</p><formula xml:id="formula_5">P (red|large, bag 2) = 8 10 = 80% &gt; P (red|small, bag 2) = 21 30 = 70%<label>(8)</label></formula><p>("in each bag, the proportion of large marbles that are red is bigger than the proportion of small marbles that are red") whereas</p><formula xml:id="formula_6">P (red|large) = 20 40 = 50% &lt; P (red|small) = 24 40 = 60%<label>(9)</label></formula><p>("overall, the proportion of large marbles that are red is not bigger than the proportion of small marbles that are red").</p><p>Here, probabilities are ratios or proportions that are computed out of contingency tables. Correspondingly, it can be argued that example B traces the following elementary mathematical fact: the inequalities</p><formula xml:id="formula_7">a a + b &gt; c c + d and e e + f &gt; g g + h (10) do not imply the inequality a + e a + b + e + f &gt; c + g c + d + g + h . (<label>11</label></formula><formula xml:id="formula_8">)</formula><p>Likewise, the equality</p><formula xml:id="formula_9">1 a + 1 b = 1 + 1 a + b holds if and only if a = b = 0. Now,</formula><p>a pupil may be surprised at first when they learn it. Yet, this peculiarity of elementary arithmetic does not qualify as a paradox. . . What makes Simpson's peculiarity a paradox? Our answer to this question is that the specificity of Simpson's paradox considered as an arithmetical oddity is precisely that it can be given a causal interpretation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Causal reasoning in disguise</head><p>It must be conceded that facts about elementary arithmetic, however peculiar, are neither causal in nature, nor do they entail any particular relationship to a specific causal structure. It would therefore seem that if the explanation of Example B is satisfactorily given in terms of a priori mathematical facts about ratios, then it is otiose to pursue the characterization of the paradox in causal terms (at least in this specific instance; the case at large is moot). More precisely, the danger is that it is either plainly superfluous to supplement the a priori explanation causally, or it is plainly incoherent to appeal to the wrong sort of explanans in the attempt to shed light on the explanandum. Nevertheless, in our search for a unified causal explanation of Simpson's paradoxical phenomenon, we will explore this seemingly purely a-causal arithmetical scenario from a causal perspective. We hope to persuade the reader that this is neither perverse nor fruitless; on the contrary, it shows that causal reasoning is deeply ingrained and inescapable. In short, whilst we grant that the a priori explanation in terms of ratios satisfactorily explains the superficial arithmetical surprise, to account for the deep pressure of the paradox in full we cannot avoid causal reasoning, albeit in disguise.</p><p>The critical reader may already baulk at the introduction of a distinction between surface and depth in the nature of paradox, no less than at the new-fangled notion of causal reasoning in disguise. To dispel the obscurity of these terms, we will say at the outset just what we take the crucial terms to be. With respect to the former concern, we do not invidiously mean that arithmetical peculiarities count as surface peculiarities merely because they are arithmetical. Rather, we treat the arithmetical facts as surface because they are easily explained. What is harder to explain is (as we make clear below) the type of game-playing (optimal betting behavior) that we might still be puzzled by, and that only makes sense in light of an assumed causal story (which we term causal reasoning in disguise). Thus, as regards the latter concern, we take causal reasoning in disguise to mean acting as if there is a substantive causal story to tell, so as to make reasonable a certain type of strategy in a game-playing context.</p><p>Why games? We invoke games for two reasons. First, appealing to games serves a dialectical purpose in the presentation of our argument. But more importantly, the deeper reason is that we want to capitalize on the insatiable appetite for play that lies at the core of personhood <ref type="bibr" target="#b11">(Caillois, 1958)</ref>. Thus we believe that our strategy to uncover causal reasoning in disguise is both widely applicable and natural in the context of our example.</p><p>When we, for instance, are presented with Example B, we may be tempted to reconstruct it in imagination as a game the aim of which is to draw a ball of a particular color, say red, from the bags of marbles. In fact, several games can be considered along these lines -see Table <ref type="table" target="#tab_3">3</ref> for a summary of the five games we focus on. In the simplest one, game I, we are merely given the opportunity to pick the first marble that we touch in the box where all marbles have been poured ("the box" for short). Since</p><formula xml:id="formula_10">P (red) = 44 80 = 55%</formula><p>the probability that we win, that is, draw a red marble, is 55%. In the second game, game II, we can choose the bag from which we pick the first marble that we touch. Because</p><formula xml:id="formula_11">P (red|bag 1) = 15 40 = 37.5% &lt; P (red|bag 2) = 29 40 = 72.5%,<label>(12)</label></formula><p>the optimal strategy for game II is to draw a marble from bag 2. Its winning probability equals 72.5% (versus 37.5% for a player who would pick the first marble that they touch in bag 1). Games I and II are elementary because they neglect the size of the marbles. This remark prompts the introduction of two additional, more exciting games. Game II + extends game II: we can choose the bag from which we pick a marble and, then, we are allowed to select the marble based on its size.</p><p>Judging by ( <ref type="formula">7</ref>) and ( <ref type="formula" target="#formula_5">8</ref>), the optimal strategy for game II + is to select a large marble from bag 2. Its winning probability is a glorious 80%. Note that if we opt for selecting a marble from bag 1, then it is optimal to select a large one too, and the winning probability is the more modest 40%.</p><p>Note that the order of choice does not matter to the solution in game II + if played with the full description of the game in view. Suppose we are offered a variant in terms of first choosing size, and then choosing bag. Since one knows one is to choose some bag (even before making the choice of specific bag), and in each bag the proportion of red to blue marbles predominates among the large relative to the small, one might as well first choose size (large), and then choose bag (bag 2). Observe moreover that the independence of order of choice in game II + is premised on being able to anticipate that one will be offered the choice of bag at stage two; if one does not know one gets to choose bag as well, then the justification for choosing large falls through.</p><p>This marks an important difference between the two order-specific variants of game II + . No knowledge of the further step of choosing size is necessary to justify choosing bag 2 in the original game II + . To make the point even clearer, consider the games, choose bag, then surprise! choose size; versus, choose size, then surprise! choose bag. (The sup-rise! indicates the step at which it is revealed to the player that she can make a further choice.) The solutions in these games come apart. The first player will rationally choose bag 2, then large. The second player will rationally choose small, then bag 2. It would seem that the justification for choosing bag 2 is order independent in the surprise games, whereas the justification for size is not.</p><p>Game I + extends game I in the same way as game II + extends game II. Concretely, in game I + , we are allowed to select our marble from the box based on its size. For this game, (9) implies that the optimal strategy is to select a small marble, with a winning probability equal to 60%, to be compared to a winning probability of 50% if we selected a large marble from the box. Now, this seems peculiar, or even perhaps paradoxical, since selecting a large marble is always a better option than selecting a small marble when picking from either bag 1 or bag 2 in game II + , with winning probabilities equal to 40% or 80%, respectively. . . The apparent incompatibility is striking.</p><p>In order to discredit the weak strategy consisting in selecting a large marble (not a small one) in game I + , the simplest argument is to emphasize that in this a-causal story where none of bag, size and color can be viewed intrinsically either as (being part of) a cause or an effect, pouring all the marbles in the box dissolves the bag feature. With no causation behind the arithmetic, reasoning from the fact that it would be more advantageous to pick a large marble than a small one whichever bag the marble originates from is irrelevant.</p><p>A more informed argument hinges on causal graphs and do-calculus, in the spirit of the conclusions drawn in Section 3.3. The key causal graph representing Example B is given in the LHS graph of Figure <ref type="figure" target="#fig_1">2</ref>. Naturally, the a-causal story results in a degenerate causal graph, where none of the bag, size and color features is a cause of another feature. The probabilistic dependence structure stems from the unobserved (hence the circle around it) common cause denoted by U .</p><p>In Game I, drawing a marble boils down to sampling the latent U from its distribution, hence the observed features. In Game I + , we are allowed to sample U from its conditional distribution given the resulting size. Symmetrically, in game II (in game II + , respectively), we are allowed to sample U from its conditional distribution given the resulting bag (given the resulting bag and size couple, respectively). We recover the earlier conclusions about the optimal strategies from the relevant comparisons of conditional probabilities, see ( <ref type="formula">7</ref>), ( <ref type="formula" target="#formula_5">8</ref>), ( <ref type="formula" target="#formula_6">9</ref>), ( <ref type="formula" target="#formula_11">12</ref>).</p><p>We are now well equipped to explain why the optimal strategies in games I + and II + may seem contradictory. As already stated, the problem comes from an undue causal interpretation of the games. First we claim that, maybe because of the narrative of game II + , we think of it in terms of interventions in the causal graph represented in the RHS of Figure <ref type="figure" target="#fig_1">2</ref>. Determining the optimal strategy within the postulated causal model gives the right answer, because P (red|do(bag, size)) = P (red|bag, size) is maximized at (bag 2, large). The prime symbol is meant to emphasize that the do operator in the above equation refers to the causal graph represented in the RHS of Figure <ref type="figure" target="#fig_1">2</ref>. Second, we believe that the causal story we tacitly (or covertly) appeal to in justifying game II + is surreptitiously extended to give the wrong answer to game I + . In this case, determining the optimal strategy within the postulated causal model gives the wrong answer, because P (red|do(large)) = P (bag 1) × P (red|large, bag 1) + P (bag 2) × P (red|large, bag 2) To sum up, we suggest that the paradox presented by simple, apparently purely arithmetical instances of Simpsons paradox in fact goes far deeper than the surface surprise involving ratios, notwithstanding the evident sufficiency of an a-causal a priori explanation of the latter. In choosing the optimal strategy for our series of simple games, we often act as though there were a causal story in the offing. In some cases this is appropriate and underwrites the optimal answer; in others it is not. Ultimately the paradox devolves upon the clash of causal intuition, however "purely arithmetical" the original set up we started off with. 1</p><formula xml:id="formula_12">=</formula><p>In conclusion, our uneasiness stems from an unduly causal construal of standard conditional probabilities. A causal reasoning is in disguise. The two salient features of our argument are the introduction of games on the one hand, and the assessment of whether it is adequate or not to reason in terms of interventions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Grades of paradoxical involvement</head><p>It is now time to take a step back and reflect on the grades of paradoxical involvement at play in Simpson's paradox. For the mathematically wary and unwary alike, Simpson's paradox may well function as a permanent invitation to error. To run afoul of Simpson's paradox it suffices to (a) conflate a probabilistically invalid inference with a valid instance of unassailable causal reasoning, or (b) confuse the evidential concept of learning from observation, which for rational agents proceeds by conditioning on the evidence, with the causal concept of acting, represented in causal analysis by the operation of intervening in a causal graph.</p><p>To make these points we present in order of ascending importance three glosses on the Simpson paradoxical reversal inequalities, in terms of comparative probability, evidential relevance, and causal bearing.</p><p>1. Under what circumstances would a causal reasoning based on the causal graph in the RHS of Figure <ref type="figure" target="#fig_1">2</ref> be adequate? Answering this question complements our argument. It requires to make a causal story out of the originally a-causal story by changing the narrative considerably. We can for instance assert that we have handy six pouches of different textures and that, instead of pouring all the marbles in the box, first we gather them in four pouches consisting of marbles similar in size and originating from the same bag; second, we gather in two outer pouches the two inner pouches consisting of marbles from bag 1 on the one hand and from bag 2 on the other; third, we finally place those two outer pouches in the box. Thus, sampling a marble from the box decomposes now as the successive random selection of an outer pouch, then an inner pouch within the first one, then a marble from the second one. In order to reflect the overall distribution of marbles in the original story, we postulate that the two outer pouches are both sampled with probability one half and that within the pouch consisting of marbles from bag b (b ∈ {1, 2}), the conditional probability to sample the pouch of large marbles equals P (large|bag b). These possibly unequal probabilities may represent an unconscious ordering of textures by preference. In this more intricate story, picking a marble based on its size is a full-fledged causal intervention. Pearl's do-calculus yields ( <ref type="formula">13</ref>) and ( <ref type="formula">14</ref>), revealing that the optimal strategy in game I + is to pick a large marble. To implement this strategy, we would pick randomly one of the two outer pouches (with equal probabilities), extract the two inner pouches, assert which one contains large marbles, then finally pick one marble from it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Comparative probability</head><p>Consider the following naive expectation concerning the ranking of contrastive effects:</p><p>Tentative principle: comparative contrast. If X is more likely given Y rather than ¬Y , both if Z and ¬Z, then X is more likely given Y rather than ¬Y , tout court.</p><p>In point of fact, any numerical instance of Simpson's paradox reformulated as a statement about comparative probability is a conclusive counterexample to the above tentative principle, see for instance (1), ( <ref type="formula" target="#formula_1">2</ref>) and (3) from the discussion of Example A in Section 3. It shows that failure to attend to the possibility of paradox results in a tempting but disastrous pattern of probabilistically invalid reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evidential relevance</head><p>In the context of the Bayesian framework, the gloss on Simpson's paradox in terms of contrastive probability connects seamlessly with the hallowed but not uncontested construal of evidential relevance as probabilistic relevance, relative to the agent's background knowledge. Usually, the evidential Bayesian formalizes an agent's antecedent beliefs as the conditioning of some maximally uninformed probability distribution pr on her background knowledge K, an informed probability distribution denoted by pr K . In the wake of <ref type="bibr" target="#b12">Carnap (1962)</ref> it is customary to posit a principle of evidential relevance along the following lines, for e, f , g three objects in the underlying algebra representing propositions or events.</p><p>Bayesian evidence principle. It occurs that f is neutral with respect to g in relation to e if pr K (g|f, e) = pr K (g|e). Otherwise, f is evidence for (respectively, against) g in relation to e if pr K (g|f, e) &gt; pr K (g|e)</p><p>(respectively, if pr K (g|f, e) &lt; pr K (g|e)).</p><p>Note that f is evidence for g in relation to e if</p><p>(1 -pr K (f |e)) × (pr K (g|f, e) -pr K (g|¬f, e)) &gt; 0.</p><p>On the face of it, the Bayesian evidential principle licenses an epistemic interpretation of Simpson's inequalities. Under this reading, any paradoxical reversal directly belies the following theoretically naive Bayesian view of evidential relevance as cumulative and uniform:</p><p>Tentative Bayesian evidence annihilation principle (proved wrong by any occurrence of Simpson's paradox). If f is evidence for g, both given e and ¬e, then f is evidence for g, tout court.</p><p>Contrary to the naive view of cumulative evidential import, assumptions about evidential relevance do not project systematically across epistemic partitions. At the very least, Simpson's paradox functions as a salutary and essential qualification for a system of unguarded evidential management.</p><p>In this connection, we remark that it is a moot point whether Simpson's paradox irreparably impugns the Bayesian construal of evidence, or whether the challenge can be obviated. Nevertheless one cannot dismiss the paradoxical phenomenon as applied to evidence on the grounds that it is merely one more probabilistic vagary in a catalog replete with similar counterintuitive consequences, stemming from a too-close identification of evidential and probabilistic relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Causal bearing</head><p>Consider now the third and paramount gloss on the Simpson Paradox inequalities, with causal concepts explicitly brought to bear on the interpretation. In this context, let us state a naive causal counterpart to the tentative comparative contrast and Bayesian evidence annihilation principles of Sections 5.1 and 5.2:</p><p>Tentative causal sure thing principle (proved wrong by some occurrences of Simpson's paradox). If Y causally promotes or inhibits X, with respect to a population partitioned by Z, then Y promotes or inhibits X, in the population as a whole.</p><p>Example A discussed in Section 3 is in accordance with the tentative principle. As Pearl has convincingly argued <ref type="bibr" target="#b20">(Pearl, 2011</ref><ref type="bibr" target="#b21">(Pearl, , 2014</ref><ref type="bibr" target="#b22">(Pearl, , 2016))</ref>, there is no mistaking the causal nature of the inviolable common-sense intuition that there can be no magical drug (Y ) that is beneficial (X) to women (Z) and men (¬Z) separately, but detrimental (¬X) to the population as a whole.</p><p>However, a do-calculus <ref type="bibr" target="#b19">Pearl (2000)</ref> analysis reveals that there is something wrong with the tentative principle. Indeed, P (X|do(Y ), Z) &gt; P (X|do(¬Y ), Z) and P (X|do(Y ), ¬Z) &gt; P (X|do(¬Y ), ¬Z)</p><formula xml:id="formula_13">do not necessarily yield P (X|do(Y )) &gt; P (X|do(¬Y )),</formula><p>contrary to what the tentative principle claims. They do whenever the condition P (Z|do(Y )) = P (Z|do(¬Y )) is met. This fact entails a valid counterpart to the above tentative principle:</p><p>Causal sure thing principle. If Y causally promotes or inhibits X, with respect to a population partitioned by Z, then Y promotes or inhibits X, in the population as a whole, provided that Y has no causal bearing on Z, according to our background knowledge.</p><p>Going back to the drug example, what guides the paradigmatically sensible reasoning is that we assume that drug has no effect on gender. Causal intervention to hand, Simpson's Paradox loses its sting.</p><p>In the next section, we reframe the causal sure thing principle in the context of decision theory, where the original sure thing principle was coined.</p><p>6 Sure thing principles 6.1 Savage's sure thing principle Since the publication of Savage's Foundations of Statistics <ref type="bibr" target="#b26">(Savage, 1972)</ref>, the sure thing principle has attained to an exalted status. By its staunch admirers it has been deemed severally to be the cornerstone of Savage's theory <ref type="bibr" target="#b17">(Joyce, 1999)</ref>, a fundamental principle of human cognition <ref type="bibr" target="#b19">(Pearl, 2000</ref><ref type="bibr" target="#b22">(Pearl, , 2016))</ref>, and a unanimity-gathering "extralogical axiom" of rationality <ref type="bibr">(Savage himself</ref>). Yet it has not gone entirely unchallenged, in both content and validity <ref type="bibr" target="#b16">(Gibbard and Harper, 1978)</ref>.</p><p>The first to raise the suspicion that Simpson's paradox might put pressure on the principle was the mathematician Colin Blyth. The ensuing discussion takes its cue from his classic presentation in <ref type="bibr" target="#b10">(Blyth, 1972)</ref>.</p><p>Savage states the principle as follows:</p><p>If [a rational agent] would not prefer A to B, either knowing that the event E obtained, or knowing that the event ¬E obtained, then he [ought] not to prefer A to B. Moreover (provided that he does not regard E as virtually impossible), if he would definitely prefer A to B knowing that E obtained, and if he would not prefer B to A, knowing that E did not obtain, then he will definitely prefer A to B.</p><p>Savage's structural axioms on preference ranking guarantee that any action f can be decomposed over a logical partition into a mixture of conditional actions of the form "do f if condition C is met". In the simplest case, where Z is an event of interest to the rational agent, a given action f is equivalent to an extended mixed action "do f if Z and do f if ¬Z". This decomposition comes down to</p><formula xml:id="formula_14">f = f Z &amp;f ¬Z</formula><p>where f Z and f ¬Z are the actions "do f if Z" and "do f if ¬Z". Leaving aside certain internal complications pertaining to virtually null events, it is helpful (and customary) to take a simpler restatement as the core idea: Sure thing principle. If an agent would prefer both an option f Z to g Z , and an option f ¬Z to g ¬Z , then she ought to prefer f = f Z &amp;f ¬Z to g = g Z &amp;g ¬Z .</p><p>How does Simpson's paradox impinge on this eminently reasonable principle? For dialectical reasons we will continue to adapt the present considerations to Example B. Recall game I + introduced and discussed in Section 4.2. It consists in drawing a marble based on its size from the box where all marbles have been poured. Consider the following pair of Blyth-actions defined as follows:</p><p>-f , draw a large marble; -g, draw a small marble.</p><p>Now apply Savage's conditional decomposition referencing the condition Z, the marble comes from bag 1, to both f and g respectively, to generate a fourfold proliferation of actions. Recapitulating the presentation of the data, it is straightforward to see that 1. f Z dominates g Z ; 2. f ¬Z dominates g ¬Z ; 3. g dominates f .</p><p>But by the sure thing principle, 1, 2, together with the pair of conditional decompositions f = f Z &amp;f ¬Z , and g = g Z &amp;g ¬Z , the agent should find herself expecting that, in contradiction with 3, 4. f dominates g.</p><p>It is worth observing that the method by which the actions are constructed is entirely general, indeed a-causal, rendering the threat of invalidity ubiquitous in reach and range. Accepting the argument at face value, it would seem that Simpson's paradox invalidates the sure thing principle (systematically and a-causally), and consequently, that the sure thing principle must either be rejected or modified in such a way as to render it proof against Blyth's ingeniously constructed counterexamples. It is no surprise that systematic rejection, or else causal modification of the sure thing principle, is the most often encountered theoretical solution to the conundrum of the sure thing. In either case, a more or less radical departure from the original form of Savage's "extralogical axiom" is apparently enforced by Simpson's paradox.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Pearl's sure thing principle</head><p>Pearl's causal modification of the sure thing principle is in part a concession to the force of Blyth's strategy for invalidating the principle. Let us rephrase the principle in decision-theoretic terms:</p><p>Causal sure thing principle (bis). Let f and g be two actions, and Z any event that is equally probable under f and under g, that is, P (Z|do(f )) = P (Z|do(g)). If a person prefers f to g, either knowing that the event Z obtains, or knowing that it does not, then she ought to prefer f to g if she knows nothing about Z.</p><p>As remarked, Blyth's method is uniformly general, exploiting the pattern of probabilistic dependencies characterizing Simpson's paradox. Interestingly, Pearl blocks the generation of counterexamples equally uniformly by exploiting the very same pattern. Specifically, the proposed causal restriction on Savage's sure thing principle allows for stochastic dependence between states (or events) and actions but requires that states be equiprobable under acting or intervening. The pair of actions defined by Blyth do not meet this condition, hence do not enter into the causally qualified form of sure thing reasoning. Likewise, in Example B where the agent engages in game I + , since P (bag 1|do(f )) = P (bag 1|large) differs from P (bag 1|do(g)) = P (bag 1|small), actions f and g do not yield equiprobable partitions under intervention hence cannot be related by sure thing reasoning.</p><p>7 Example C: Simpson's paradox in real life?</p><p>Simpson's paradox is not only a philosophical topic. It happens in reality with real data. <ref type="bibr" target="#b14">Chuang et al. (2009)</ref> claim that they identify a real-life instance of Simpson's paradox in a series of synthetic microbial systems described in Example C. In this section, we analyze the case and argue that Simpson's paradox is in fact not at play here.</p><p>We do not pretend to do justice to the refinements of <ref type="bibr" target="#b14">Chuang et al. (2009)</ref>'s biological experiment. For the sake of argumentation, it suffices to focus on a similar thought-experiment presented under the form of a causal graph in Figure <ref type="figure" target="#fig_2">3</ref>.</p><p>At time t = 0, for each π in, say, {20%, 60%}, a test-tube is prepared with 2N × π producers and 2N × (1 -π) non-producers (see (2N p 0a , 2N np 0a ) and (2N p 0b , 2N np 0b ) in Figure <ref type="figure" target="#fig_2">3</ref>). Immediately, at time t = 0 + , a third test-tube is prepared by mixing half of the above homogenized test-tubes (see (N p 0c , N np 0c ) in Figure <ref type="figure" target="#fig_2">3</ref>). By experimental design, the ratios N p 0a /(N p 0a + N np 0a ), N p 0b /(N p 0b + N np 0b ) and N p 0c /(N p 0c + N np 0c ) of producers in the three test-tubes equal 20%, 60% and 40%, respectively. The third test-tube is discarded. The contents of the two others are let to evolve independently but in similar experimental conditions from time t = 0 + to time t = 1.</p><p>At time t = 1, the ratios of producers in the test-tubes are N p 1a /(N p 1a + N np 1a ) and N p 1b /(N p 1b + N np 1b ) (see Figure <ref type="figure" target="#fig_2">3</ref>) and we observe that they are smaller than 20% and 60%, respectively, revealing that nonproducers are advantaged and grow faster than producers in each test-tube. At time t = 1 + , a fourth test-tube is prepared by mixing the contents of the two others. Its ratio of producers is N p 1d /(N p 1d + N np 1d ) (see Figure <ref type="figure" target="#fig_2">3</ref>).</p><p>It occurs that the ratio of producers in the fourth test-tube is larger than the ratio of producers in the third test-tube. The same conclusion holds when the experiment is replicated. The biological reason for this is that the content of the test-tube with the larger initial ratio of producers grows substantially more than the other one, sufficiently to counterbalance globally the local advantage of non-producers. This is nicely illustrated in <ref type="bibr" target="#b14">(Chuang et al., 2009</ref>, Figure <ref type="figure" target="#fig_0">1</ref>).</p><p>The observed reversal evokes the reversal of association between two variables when conditioning on a third one, which characterizes Simpson's paradox. However, the causal graph of Figure <ref type="figure" target="#fig_2">3</ref> suggests that this impression is misleading. Firstly, if there were a variable to condition upon, that would necessarily be a variable indicating which test-tube is considered. Whereas it is clear what means focusing on the first or second test-tube at times t = 0 + and t = 1, it is unclear what means neglecting which test-tube is under consideration. In particular, the latter does not consist in focusing on either the third test-tube at time t = 0 + or the fourth test-tube at time t = 1 + . Secondly, the fourth test-tube is not the by-product of the third test-tube in the same way as the first and second test-tube at time t = 1 are the by-products of themselves at time t = 0 + . Thirdly, contrary to the Examples A and B viewed as experiments, Example C viewed as an experiment is not the aggregation of two separate sub-experiments. In Example A, each realization of the experiment falls into one of two categories, depending on the stone diameter. In Example B viewed as a game, each realization of the experiment falls into one of two categories, depending on the bag from which the marble happens to be drawn. By contrast, in Example C, there is one single category of realization of the experiment, despite the fact that there is one sub-experiment for each initial ratio of producers and two additional mixing sub-experiments. Lastly, the objects of the reversed inequalities are fundamentally different in nature in Examples A and B on the one hand and in Example C on the other hand. In the former, the reversed inequalities concern measures of association, such as conditional probabilities like in (1), ( <ref type="formula" target="#formula_1">2</ref>) and (3). They are features of the law of the experiment. In the latter, the reversed inequalities concern random variables, namely</p><formula xml:id="formula_15">N p 0a /(N p 0a + N np 0a ), N p 0b /(N p 0b + N np 0b ), N p 0c /(N p 0c +N np 0c ) and N p 1d /(N p 1d +N np<label>1d</label></formula><p>). They are by-products (realizations) of the law of the experiment, as opposed to features of it. This shows that it can be difficult sometimes to decide whether a putative instance of Simpson's paradox is a real one or not. We think that the analysis of the paradox laid out in this article may be helpful in this regard.  Both graphs assume (i) that stone diameter and method influence causally success and (ii) that stone diameter and method are correlated. In the LHS graph, stone diameter is a mediating variable between method and success. In the RHS graph, stone diameter has a causal influence on method.   The variables of interest N p tx and N np tx ((t, x) ∈ {(0, a), (1, a), (0, b), (1, b), (0, c), (1, d)}) stand for numbers of producers and non-producers at the start (t = 0) and end (t = 1) of the experiment in four different settings. By experimental design, we have (N p 0a , N np 0a ) = 2N × (20%, 80%), (N p 0b , N np 0b ) = 2N × (60%, 40%) and (N p 0c , N np 0c ) = N × (40%, 60%) where N is a reference number. There are several kinds of arrows. Two-headed arrows represent deterministic mechanisms, of which there are two kinds: two-headed arrows with tails are merely of algebraic nature (with no experimental counterpart) whereas two-headed arrows without tails model a controlled experimental process (such as mixing the content of two test-tubes). Single-headed arrows correspond to uncontrolled biological processes. The + and -signs distinguish between positive and negative associations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Two causal graphs that are compatible with the data arising from the experiment of Example A.Both graphs assume (i) that stone diameter and method influence causally success and (ii) that stone diameter and method are correlated. In the LHS graph, stone diameter is a mediating variable between method and success. In the RHS graph, stone diameter has a causal influence on method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Left: Degenerate causal graph representing the a-causal story of Example B. The probabilistic dependence structure between bag, size and color stems from the unobserved (hence the circle around it) common cause denoted by U . Right: Wrongly postulated causal graph representing the a-causal story of Example B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A causal graph representing a thought-experiment inspired by Chuang et al. (2009)'s experiment.The variables of interest N p tx and N np</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparing kidney stone removal modus operandi. Success in removing kidney stones. Method m 1 stands for open surgery, method m 2 for percutaneous nephrolithotomy, and d for the stone's diameter.</figDesc><table><row><cell></cell><cell>d &lt;2cm</cell><cell></cell><cell>d ≥2cm</cell><cell></cell><cell>all ds</cell><cell></cell></row><row><cell></cell><cell cols="6">success failure success failure success failure</cell></row><row><cell>m 1</cell><cell>81</cell><cell>6</cell><cell>192</cell><cell>71</cell><cell>273</cell><cell>77</cell></row><row><cell>m 2</cell><cell>234</cell><cell>36</cell><cell>55</cell><cell>25</cell><cell>289</cell><cell>61</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Bags of marbles. A numerical example where polarity of the dependence between two variables (color and size) is reversed when disaggregating with respect to a third variable (bag), see Example B.</figDesc><table><row><cell></cell><cell>bag 1</cell><cell></cell><cell>bag 2</cell><cell></cell><cell cols="2">bags 1, 2</cell></row><row><cell></cell><cell cols="6">red blue red blue red blue</cell></row><row><cell>large</cell><cell>12</cell><cell>18</cell><cell>8</cell><cell>2</cell><cell>20</cell><cell>20</cell></row><row><cell>small</cell><cell>3</cell><cell>7</cell><cell>21</cell><cell>9</cell><cell>24</cell><cell>16</cell></row><row><cell cols="2">stone diameter</cell><cell></cell><cell></cell><cell></cell><cell cols="2">stone diameter</cell></row><row><cell>method</cell><cell cols="2">success</cell><cell cols="2">method</cell><cell></cell><cell>success</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Irresistible games. These games can be played in the context of Example B. In each of them, the aim is to draw a red marble.</figDesc><table><row><cell cols="2">game rule</cell><cell></cell><cell></cell><cell></cell><cell>optimal strategy winning</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>prob.</cell></row><row><cell>I</cell><cell cols="4">Pick the first marble that one touches</cell><cell>no strategy</cell><cell>55.0%</cell></row><row><cell></cell><cell cols="4">from the box where all marbles have been</cell></row><row><cell></cell><cell>poured.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>I +</cell><cell cols="4">Pick a marble from the box where all mar-</cell><cell>pick a small</cell><cell>60.0%</cell></row><row><cell></cell><cell cols="4">bles have been poured knowing whether it</cell><cell>marble (see (9))</cell></row><row><cell></cell><cell>is large or small.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>II</cell><cell cols="4">Choose a bag then pick from it the first</cell><cell>pick from bag 2</cell><cell>72.5%</cell></row><row><cell></cell><cell cols="2">marble that one touches.</cell><cell></cell><cell></cell><cell>(see (12))</cell></row><row><cell>II +</cell><cell cols="4">Choose a bag then pick a marble from it</cell><cell>pick a large</cell><cell>80.0%</cell></row><row><cell></cell><cell cols="3">knowing whether it is large or small.</cell><cell></cell><cell>marble</cell><cell>from</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>bag 2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(see (7) and (8))</cell></row><row><cell>III</cell><cell cols="4">Pick a bag (equiprobably), then pick a</cell><cell>pick a large</cell><cell>60%</cell></row><row><cell></cell><cell cols="4">marble from it knowing whether it is large</cell><cell>marble (see (7)</cell></row><row><cell></cell><cell>or small.</cell><cell></cell><cell></cell><cell></cell><cell>and (8))</cell></row><row><cell></cell><cell cols="2">(2N p 0a , 2N np 0a )</cell><cell></cell><cell></cell><cell>(2N p 0b , 2N np 0b )</cell></row><row><cell></cell><cell cols="2">N p 0a 0a +N np N p 0a</cell><cell cols="2">(N p 0c , N np 0c )</cell><cell>N p 0b 0b +N np N p 0b</cell></row><row><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell></row><row><cell></cell><cell>+</cell><cell>N p 1a 1a +N np N p 1a</cell><cell>N p 0c 0c +N np N p 0c</cell><cell></cell><cell>N p 1b 1b +N np N p 1b</cell><cell>+</cell></row><row><cell></cell><cell>N p 1a + N np 1a</cell><cell cols="2">(N p 1a , N np 1a )</cell><cell cols="2">(N p 1b , N np 1b )</cell><cell>N p 1b + N np 1b</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(N p 1d , N np 1d )</cell></row><row><cell></cell><cell></cell><cell></cell><cell>N p 1d 1d +N np N p 1d</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Boy. -Yes Sir.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Silence.</head><p>Vladimir </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Epilogue Did Simpson come after all? Will he?</title>
		<imprint/>
	</monogr>
	<note>Let us see how the third act unfolds</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Acte troisième, seconde partie Estragon retourne ses chaussures, les secoue, en fait tomber caillous et fruits, petits et gros</title>
		<imprint/>
	</monogr>
	<note>Il se love, s&apos;assoupit</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Au garçon.) Tu ne me reconnais pas ? Garc ¸on. -Non monsieur. Vladimir. -C&apos;est toi qui es venu hier ? Garc ¸on. -Non monsieur</title>
		<editor>Garc ¸on. -Monsieur. . . (Vladimir se retourne.) Monsieur Albert. . . Vladimir. -Reprenons.</editor>
		<imprint/>
	</monogr>
	<note>Un temps. est la première fois que tu viens ? Garc ¸on. -Oui monsieur</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Vladimir. -C&apos;est de la part de monsieur Simpson ? Garc ¸on. -Oui monsieur. Vladimir. -Il ne viendra pas ce soir ? Garc ¸on</title>
	</analytic>
	<monogr>
		<title level="j">Silence</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">-Comment va ton frère ? Garc ¸on. -Il va mieux, monsieur. Vladimir. -Ah c&apos;est bien ça. Silence. Garc ¸on. -Qu&apos;est-ce que je dois dire à monsieur Simpson, monsieur ? Vladimir. -Tu lui diras -(il s&apos;interrompt) -tu lui diras que tu m&apos;as vu et que -(il réfléchit) -que tu m&apos;as vu et que je le remercie. Silence. Soudain, le garçon se sauve comme une flèche. Silence. Le soleil se couche et la lune se lève. Estragon se réveille, se lève, va vers Vladimir, le regarde</title>
		<author>
			<persName><surname>Vladimir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Mais il viendra demain. Garc ¸on. -Oui monsieur. Vladimir. -Sûrement. Garc ¸on. -Oui monsieur. Silence. Vladimir.</title>
		<imprint/>
	</monogr>
	<note>Estragon. -Qu&apos;est-ce que tu as ? Vladimir. -Je comprends mieux. Estragon. -C&apos;est bien ? Vladimir. -Je crois</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Estragon. -Moi je m&apos;en vais. Vladimir. -Moi aussi. Silence. Estragon. -Où irons-nous ? Vladimir. -Pas loin. Estragon. -Si si, allons-nous en loin d&apos;ici ! Vladimir. -On ne peut pas. Estragon. -Pourquoi ? Vladimir. -Il faut revenir demain. Estragon. -Pour quoi faire ? Vladimir. -Attendre Simpson. Estragon. -C&apos;est vrai</title>
	</analytic>
	<monogr>
		<title level="s">Silence. Estragon. -Il y avait longtemps que je dormais ? Vladimir. -Je ne sais pas. Silence.</title>
		<imprint/>
	</monogr>
	<note>Il n&apos;est pas venu ? Vladimir. -Non</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Et maintenant il est trop tard. Vladimir. -Oui, c&apos;est la nuit</title>
		<author>
			<persName><surname>Estragon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Silence. Vladimir. -Alors, on y va ? Estragon. -Allons-y. Ils ne bougent pas</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Vladimir walks around the tree, waving and mumbling. Enter Boy left. He halts. Silence. Boy. -Mister. . . (Vladimir turns.) Mister Albert. . . Vladimir. -Off we go again. (Pause.) Do you not recognize me? Boy. -No Sir. Vladimir. -It wasn&apos;t you came yesterday</title>
		<idno>rideau 8.2</idno>
		<imprint/>
	</monogr>
	<note>Third act, second part Estragon turns over his shoes, shakes them, makes the pebbles and fruits, big and small, fall from them. He curls up, dozes off. Boy. -No Sir. Vladimir. -This is your first time? References</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Bandyoapdhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Greenwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brittan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The logic of Simpson&apos;s paradox</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="page" from="185" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">En attendant Godot</title>
		<author>
			<persName><forename type="first">S</forename><surname>Beckett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1952">1952</date>
			<publisher>Editions de Minuit</publisher>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On Simpson&apos;s paradox and the sure-thing principle</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Blyth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Lindley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Good</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">W</forename><surname>Pratt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<editor>
			<persName><forename type="first">Colin</forename><forename type="middle">R</forename><surname>Blyth</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="373" to="381" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Caillois</surname></persName>
		</author>
		<title level="m">Les jeux et les hommes. Editions Gallimard. Le masque et le vertige</title>
		<imprint>
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Logical foundations of probability</title>
		<author>
			<persName><forename type="first">R</forename><surname>Carnap</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962">1962</date>
			<publisher>University of Chicago press</publisher>
			<pubPlace>Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparison of treatment of renal calculi by open surgery, percutaneous nephrolithotomy, and extracorporeal shockwave lithotripsy</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Charig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Wickham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin Res Ed)</title>
		<imprint>
			<biblScope unit="volume">292</biblScope>
			<biblScope unit="issue">6524</biblScope>
			<biblScope unit="page" from="879" to="882" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
	<note>BMJ</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Simpson&apos;s paradox in a synthetic microbial system</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rivoire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="issue">5911</biblScope>
			<biblScope unit="page" from="272" to="275" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">An introduction to logic and the scientific method</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nagel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1934">1934</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Counterfactuals and two kinds of expected utility</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gibbard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Harper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ifs. Conditionals, Belief, Decision, Chance and Time</title>
		<title level="s">The Western Ontario Series in Philosophy of Science</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Harper</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Stalnaker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Pearce</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page" from="153" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Cambridge Studies in Probability, Induction, and Decision Theory</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Joyce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
	<note>The foundations of causal decision theory</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Confounding and Simpson&apos;s paradox</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Julious</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Mullee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMJ</title>
		<imprint>
			<biblScope unit="volume">309</biblScope>
			<biblScope unit="issue">6967</biblScope>
			<biblScope unit="page" from="1480" to="1481" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Causality</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cambridge. Models, reasoning, and inference</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Simpson&apos;s paradox: An anatomy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, UCLA</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Comment: understanding Simpson&apos;s paradox</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="13" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Sure-Thing Principle</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Causal Inference</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="86" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mathematical contributions to the theory of evolution. VII. on the correlation of characters not quantitatively measurable</title>
		<author>
			<persName><forename type="first">K</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London</title>
		<imprint>
			<date type="published" when="1900">1900</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Containing Papers of a Mathematical or Physical Character</title>
		<author>
			<persName><forename type="first">A</forename><surname>Series</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">195</biblScope>
			<biblScope unit="page" from="1" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The ways of paradox and other essays</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V</forename><surname>Quine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976">1976</date>
			<publisher>Harvard University Press</publisher>
			<biblScope unit="page" from="2" to="18" />
			<pubPlace>Cambridge, Massachusetts and London, England</pubPlace>
		</imprint>
	</monogr>
	<note>chapter The ways of paradox</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The foundations of statistics</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Savage</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<publisher>Dover Publications, Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>revised edition</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the association of attributes in statistics: with illustrations from the material of the childhood society, &amp;c</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">U</forename><surname>Yule</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London. Series A</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="257" to="319" />
			<date type="published" when="1900">1900</date>
		</imprint>
	</monogr>
	<note>Mathematical or Physical Character</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
