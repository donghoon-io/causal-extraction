<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Identifying biological perturbation targets through causal differential networks</title>
				<funder ref="#_EH463dE">
					<orgName type="full">National Science Foundation Graduate Research Fellowship</orgName>
				</funder>
				<funder ref="#_rGauVEs">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-05-30">30 May 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Menghua</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Umesh</forename><surname>Padia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sean</forename><forename type="middle">H</forename><surname>Murphy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Identifying biological perturbation targets through causal differential networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-05-30">30 May 2025</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2410.03380v4[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Identifying variables responsible for changes to a biological system enables applications in drug target discovery and cell engineering. Given a pair of observational and interventional datasets, the goal is to isolate the subset of observed variables that were the targets of the intervention. Directly applying causal discovery algorithms is challenging: the data may contain thousands of variables with as few as tens of samples per intervention, and biological systems do not adhere to classical causality assumptions. We propose a causalityinspired approach to address this practical setting. First, we infer noisy causal graphs from the observational and interventional data. Then, we learn to map the differences between these graphs, along with additional statistical features, to sets of variables that were intervened upon. Both modules are jointly trained in a supervised framework, on simulated and real data that reflect the nature of biological interventions. This approach consistently outperforms baselines for perturbation modeling on seven single-cell transcriptomics datasets. We also demonstrate significant improvements over current causal discovery methods for predicting soft and hard intervention targets across a variety of synthetic data. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Cells form the basis of biological systems, and they take on a multitude of dynamical states throughout their lifetime. In addition to natural factors like cell cycle, external perturbations (e.g. drugs, gene knockdown) can alter a cell's state. While perturbations can affect numerous downstream variables, identifying the root causes, or targets, that induce these transitions has vast therapeutic implications, from cellular reprogramming <ref type="bibr" target="#b12">(Cherry &amp; Daley, 2012)</ref> to mechanism of action elucidation <ref type="bibr" target="#b65">(Schenone et al., 2013)</ref>.</p><p>Machine learning methods have primarily been designed to infer the effects of perturbations on cells, with the goal of generalizing to unseen perturbations <ref type="bibr" target="#b62">(Roohani et al., 2023)</ref>, or unseen cell distributions <ref type="bibr" target="#b44">(Lotfollahi et al., 2023;</ref><ref type="bibr" target="#b8">Bunne et al., 2023)</ref>. In principle, these models can be used within an active learning framework to discover intervention targets <ref type="bibr" target="#b29">(Huang et al., 2024;</ref><ref type="bibr">Zhang et al., 2023a)</ref>. However, the number of candidate sets scales exponentially with the number of variables under consideration, and there are limited training data for combinatorial perturbations (&lt; 150 pairs in <ref type="bibr" target="#b56">Norman et al. (2019)</ref>). Thus, this option may be impractical for larger search spaces.</p><p>Alternatively, some methods predict targets by comparing pairs of "before" and "after" cell states, similar to this paper. They do so by attributing observed differences to sparse, mechanistic changes. Specifically, relationships between variables are represented through a graph, e.g. a gene regulatory network <ref type="bibr" target="#b2">(Babu et al., 2004)</ref>. Existing methods often use data-mined relations as priors for this graph, and search for modifications to the set of edges that best explain the interventional data <ref type="bibr" target="#b15">(Cosgrove et al., 2008;</ref><ref type="bibr">Gonzalez et al., 2024)</ref>. However, biological knowledge graphs are incomplete and noisy priors. They contain heterogeneous, potentially conflicting information, since the reported findings were observed under diverse contexts <ref type="bibr" target="#b1">(Ashburner et al., 2000)</ref>. Moreover, different cell populations may exhibit distinct gene regulatory behavior <ref type="bibr" target="#b30">(Huttlin et al., 2021)</ref>, leading to incomplete knowledge, especially of less wellcharacterized systems.</p><p>In this paper, we propose causal differential networks (CDN): a causality-inspired approach to identify variables that drive desired shifts in cell state, while estimating their mechanistic structure directly from data. Given a pair of observational and interventional datasets, we train a causal structure learner to predict causal graphs that could have generated each dataset. The pair of graphs is input to an attentionbased classifier, which predicts whether each variable was subject to intervention. To address the challenges of data noise and sparsity, and to simulate the structure of biological interventions, these models are trained jointly in a supervised (amortized) framework <ref type="bibr" target="#b34">(Ke et al., 2023;</ref><ref type="bibr" target="#b58">Petersen et al., 2023)</ref>, over thousands of synthetic or real datasets.</p><p>We evaluate CDN on real transcriptomic data and synthetic settings. CDN outperforms the state-of-the-art in perturbation modeling (deep learning and statistical approaches), evaluated on the five largest Perturb-seq datasets at the time of publication <ref type="bibr" target="#b61">(Replogle et al., 2022;</ref><ref type="bibr">Nadig et al., 2024)</ref> without using any external knowledge. Furthermore, CDN generalizes with minimal performance drop to unseen cell lines, which have different supports (genes), causal mechanisms (gene regulatory networks), and data distributions. On synthetic settings, CDN outperforms causal discovery approaches for estimating unknown intervention targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background and related work 2.1. Problem statement</head><p>We consider a system of N random variables X i ∈ X, whose relationships are represented by directed graph G = (V, E), where nodes i ∈ V map to variables X i , and edges (i, j) ∈ E to relationships from X i to X j . Samples from the data distribution P X are known as observational. We can perform interventions by assigning new conditionals</p><formula xml:id="formula_0">P (X i | X πi ) ← P (X i | X πi ),<label>(1)</label></formula><p>where π i denotes the parents of node i in G. Hard interventions remove all dependence between X i and π i , while soft interventions maintain the relationship with a different conditional. We denote the joint interventional distribution as PX . Given an observational dataset D obs ∼ P X and an interventional dataset D int ∼ PX , our goal is to predict the set of nodes I for which</p><formula xml:id="formula_1">P (X i | X πi ) ̸ = P (X i | X πi ), ∀i ∈ I.<label>(2)</label></formula><p>In the context of molecular biology, a perturbation is a hard or soft intervention, and I is the set of perturbation targets, where ∥I∥ ≥ 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Modeling perturbations</head><p>Perturbation experiments result in datasets of the form D obs , {(I k , D k int )}, where D obs ∼ P X , D k int ∼ P k X . In this paper, we focus on the transcriptomic data modality, where variables X i represent the levels of gene i; the number of variables N ranges from hundreds to thousands; D obs contains thousands of samples; and each D int contains tens to hundreds of samples <ref type="bibr" target="#b61">(Replogle et al., 2022)</ref>.</p><p>Each experiment is conducted in a single cell line, which represents a distinct set of variables X, distribution P X , and graph G. These three objects may share similarities across cell lines, as certain genes or pathways are essential for survival. However, the empirical discrepancy can be quite large between experiments. For example, <ref type="bibr">Nadig et al. (2024)</ref> reports that the median correlation in log-fold change of genes under the same perturbation, across two experiments in the same cell line, by the same lab, was 0.16.</p><p>Early efforts to map the space of cells measured the distribution of gene levels as a surrogate for cell state <ref type="bibr" target="#b38">(Lamb et al., 2006)</ref>. Diseases, drugs, or genetic perturbations that induce similar changes in this distribution were thought to act through similar mechanisms. However, it is intractable to map all combinations of starting cell states and perturbations through experiment alone. This bottleneck has led to two directions in the in-silico modeling of perturbations.</p><p>To reduce experimental costs, which scale with the number of cell lines and perturbations, one option is to infer the postintervention distribution of cells. That is, given D obs ∼ P X and I, the goal is to infer PX . Works such as scGen <ref type="bibr" target="#b43">(Lotfollahi et al., 2019)</ref>, CPA <ref type="bibr" target="#b44">(Lotfollahi et al., 2023)</ref>, Chem-CPA <ref type="bibr" target="#b25">(Hetzel et al., 2022)</ref>, and CellOT <ref type="bibr" target="#b8">(Bunne et al., 2023)</ref> aim to generalize to new settings P X , e.g. unseen cell lines or patients. Alternatively, models like GEARS <ref type="bibr" target="#b62">(Roohani et al., 2023)</ref>, graphVCI <ref type="bibr" target="#b82">(Wu et al., 2023)</ref>, AttentionPert <ref type="bibr" target="#b3">(Bai et al., 2024)</ref>, and GIM <ref type="bibr" target="#b66">(Schneider et al., 2024)</ref> infer the effects of unseen perturbations. This setting is also a common application for single cell foundation models <ref type="bibr" target="#b75">(Theodoris et al., 2023;</ref><ref type="bibr" target="#b16">Cui et al., 2024;</ref><ref type="bibr">Hao et al., 2024)</ref>. These latter methods generalize by modeling the relationships between seen and unseen perturbations. For example, GEARS leverages literature-derived relationships in the Gene Ontology knowledge graph <ref type="bibr" target="#b1">(Ashburner et al., 2000)</ref>, and graphVCI learns to refine the gene regulatory relationships implied by ATAC-seq data <ref type="bibr" target="#b21">(Grandi et al., 2022)</ref>.</p><p>Approaches for inferring the effects of interventions do not explicitly predict targets, but if the space of perturbations I can be efficiently enumerated, these models are useful for comparing different I <ref type="bibr">(Zhang et al., 2023a;</ref><ref type="bibr" target="#b29">Huang et al., 2024)</ref>. For example, given an oracle ϕ : D obs , I → P , the I * associated with P * is</p><formula xml:id="formula_2">I * = arg min I∈I d( P * , ϕ(D obs , I))<label>(3)</label></formula><p>for some dissimilarity d. However, recent works have reported that the predictive ability of current models does not exceed that of naive baselines <ref type="bibr">(Kernfeld et al., 2023;</ref><ref type="bibr">Ahlmann-Eltze et al., 2024;</ref><ref type="bibr" target="#b49">Märtens et al., 2024)</ref>, reflecting that phenotype prediction is currently unsolved.</p><p>Perturbation datasets can also be used to train models for predicting targets of interest, as is the focus of this work. A common strategy is to relate observed changes (e.g. disease, gene levels) to mechanistic explanations (e.g. pathways), in which the targets are involved. To draw this connection, current approaches use external information such as knowledge graphs <ref type="bibr" target="#b15">(Cosgrove et al., 2008;</ref><ref type="bibr">Gonzalez et al., 2024)</ref> and natural language <ref type="bibr" target="#b63">(Roohani et al., 2025)</ref>. However, these information are collected from highly inhomogenous sources <ref type="bibr" target="#b1">(Ashburner et al., 2000)</ref>, and it is difficult to quantify their correctness and completeness in each new setting.</p><p>An alternative is to infer the mechanistic structure directly from data, either explicitly <ref type="bibr" target="#b18">(di Bernardo et al., 2005)</ref> or as a model parameter <ref type="bibr" target="#b55">(Noh &amp; Gunawan, 2016)</ref>. In this work, we follow the latter strategy, while allowing for a richer (non-linear) class of relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Causal discovery</head><p>The task of inferring causal mechanisms from data is known as causal discovery, or causal structure learning <ref type="bibr" target="#b69">(Spirtes et al., 2001)</ref>. In the simplest setting, the goal is to infer G from D obs . The earliest works were discrete search algorithms, which operated over the combinatorial space of potential graphs <ref type="bibr" target="#b68">(Spirtes et al., 1995;</ref><ref type="bibr">Tian &amp; Pearl, 2001;</ref><ref type="bibr" target="#b13">Chickering, 2002;</ref><ref type="bibr" target="#b67">Shimizu et al., 2006)</ref>. More recently, a number of works have reframed the task as a constrained optimization over continuous adjacency matrices <ref type="bibr">(Zheng et al., 2018;</ref><ref type="bibr" target="#b37">Lachapelle et al., 2020;</ref><ref type="bibr" target="#b64">Sanchez et al., 2023)</ref>.</p><p>If data from multiple environments are available, they can provide additional identifiability regarding the system <ref type="bibr" target="#b32">(Jaber et al., 2020;</ref><ref type="bibr">Zhang et al., 2023b)</ref>. Differences between these environments, e.g. intervention targets I, are either given as input or part of the inference task. As in the observational case, discovery algorithms can be categorized into discrete search <ref type="bibr" target="#b24">(Hauser &amp; Bühlmann, 2012;</ref><ref type="bibr" target="#b20">Ghassami et al., 2018;</ref><ref type="bibr" target="#b33">Ke et al., 2019;</ref><ref type="bibr" target="#b28">Huang et al., 2020;</ref><ref type="bibr" target="#b52">Mooij et al., 2020)</ref> or continuous optimization <ref type="bibr" target="#b7">(Brouillard et al., 2020;</ref><ref type="bibr" target="#b22">Hägele et al., 2023)</ref>. Additionally, <ref type="bibr" target="#b76">Varici et al. (2022)</ref> and <ref type="bibr" target="#b83">Yang et al. (2024)</ref> frame intervention target prediction as its own task, similar to this paper. However, the former strictly as-sumes linearity, while the latter requires at least as many environments as ∥I∥ (we only consider before and after perturbation). Finally, several works aim to infer differences between causal mechanisms (edges), rather than identifying the full causal structure <ref type="bibr" target="#b78">(Wang et al., 2018;</ref><ref type="bibr" target="#b4">Belyaeva et al., 2021;</ref><ref type="bibr" target="#b10">Chen et al., 2023;</ref><ref type="bibr" target="#b48">Malik et al., 2024)</ref>. Our work is also motivated by the idea that differences between summary statistics (e.g. regression coefficients in DCI) are informative of changes between systems. Thus, CDN can be viewed as implementing similar operations within an end-to-end, supervised framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Amortized causal inference</head><p>While the majority of causal discovery algorithms must be fit or run from scratch for each data distribution, amortized causal discovery algorithms have addressed this task as a supervised machine learning problem. Using large numbers of synthetic datasets, generated by synthetic graphs, a neural network is trained to map D directly to G <ref type="bibr" target="#b39">(Li et al., 2020;</ref><ref type="bibr" target="#b34">Ke et al., 2023;</ref><ref type="bibr" target="#b40">Lorch et al., 2022;</ref><ref type="bibr" target="#b58">Petersen et al., 2023;</ref><ref type="bibr" target="#b81">Wu et al., 2025)</ref>. Compared to traditional approaches, these algorithms trade explicit assumptions for implicit characteristics of the data simulation process <ref type="bibr" target="#b51">(Montagna et al., 2024)</ref>. These models are also fast and robust to noise. In this work, we simulate interventions that reflect biological perturbations, and our model architecture builds upon that of <ref type="bibr" target="#b81">Wu et al. (2025)</ref>, as it scales easily to hundreds of variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head><p>We introduce causal differential networks (CDN), a causality inspired method for predicting intervention targets. On a high level, CDN is motivated by the idea that differences in observations D obs and D int can be explained by the changes to their underlying causal mechanisms (Figure <ref type="figure" target="#fig_0">1B</ref>).</p><p>Our model is composed of two modules: a causal structure learner (Section 3.1), and a differential network classifier (Section 3.2). Given a single dataset D, the causal structure learner predicts a putative G. The pair of datasets D obs and D int yields graphs G obs and G int , whose features are input to the differential network, to predict targets I (Figure <ref type="figure" target="#fig_0">1C</ref>). Both modules are trained jointly, supervised by classification losses for the graph and predicted targets. Finally, individual samples are known to be noisy in single-cell biology and are often analyzed in "pseudo-bulk" <ref type="bibr" target="#b6">(Blake et al., 2003)</ref>. Thus, instead of operating over raw data, we also represent datasets in terms of their summary statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Causal structure learner</head><p>The causal structure learner takes as input dataset D and outputs the predicted G. In principle, this module can be implemented with any data-efficient causal discovery model.</p><p>Here, we based the architecture on SEA <ref type="bibr" target="#b81">(Wu et al., 2025)</ref>, as its runtime complexity does not explicitly depend on the number of samples (which can be large for D obs ).</p><p>Input featurization We represent dataset D through two types of statistics. First, we compute global statistics ρ ∈ R N ×N (pairwise correlation) over all variables. This statistic is an inexpensive way for the model to filter out edges that are not likely to occur. Second, we obtain estimates of local causal structure to orient edges, by running classical causal discovery algorithms over small subsets of variables. Specifically, we run the FCI algorithm T times over subsets of k variables <ref type="bibr" target="#b68">(Spirtes et al., 1995)</ref>, which are sampled proportional to their pairwise correlation. We denote the set of estimates as E ′ ∈ E k×k×T , where E is the space of possible edge types inferred by FCI (e.g. ↔, -, →).</p><p>The size and number of local estimates, k and T , are hyperparameters that trade off accuracy vs. runtime (Section 3.3).</p><p>To compare ρ and E ′ in the same space, we linearly project elements of ρ from R to R d , and map categorical edge types into R d using a learned embedding, i.e. like token embeddings in language models <ref type="bibr" target="#b17">(Devlin et al., 2019)</ref>. Thus, the dataset D is summarized into a matrix of size R N ×N ×T ×d .</p><p>Model architecture Both the causal structure learner and differential network are implemented with a series of attention-based blocks. Since scaled dot-product attention scales quadratically as sequence length <ref type="bibr" target="#b77">(Vaswani et al., 2017)</ref>, we attend over one dimension at a time. For example, given a N 2 entries in an adjacency matrix, naive self-attention would cost O(N 4 ) operations. Instead, we apply self-attention along all nodes in the "outgoing edge" direction, with the "incoming edges" as a batch dimension, followed by the opposite -resulting in two operations, each of cost O(N × N 2 ). Following <ref type="bibr">Rao et al. (2021)</ref>, we use pre-layer normalization on each self-attention, followed by dropout and residual connections:</p><formula xml:id="formula_3">h ← h + Dropout(Self-Attn(LayerNorm(h))) (4)</formula><p>where h ∈ R •••×d denotes an intermediate hidden representation. This design takes after Transformer models for higher dimensional data in other domains, e.g. Axial Transformers for videos <ref type="bibr" target="#b27">(Ho et al., 2019)</ref> and MSA Transformers for aligned protein sequences <ref type="bibr">(Rao et al., 2021)</ref>. A key difference is the graph modality: when making edge or node-level predictions, the model should be equivariant to node labeling. This is accomplished by adding randomlypermuted "positional" embeddings to each node and edge representation. For more details, please see Appendix A.</p><p>Edge-level outputs Let h obs , h int ∈ R N ×N ×d denote the final layer representations of each dataset, after pooling over the T dimension. These representations are input to the differential network. In addition, we introduce a graph prediction head,</p><formula xml:id="formula_4">z i,j = FFN([h i,j , h j,i ]) (logits) (5) P (E i,j = e) = σ(z i,j ) e (softmax) (6)</formula><p>where σ denotes softmax over the set of output edge types (forwards, backwards, or no edge). The graph prediction loss L G is simply the cross entropy loss between the predicted and true edge types, summed over the entire graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Differential network</head><p>Given a pair of graph representations h obs , h int , the differential network predicts I, the set of intervention targets.</p><p>Input featurization In addition to pairwise representations h, we compute node-level statistics (mean, variance), which are mapped to R d via a feed-forward network, and concatenated along "incoming edge" dimension. This results in graph representation h ′ ∈ R N ×(N +1)×d .</p><p>We combine the graph representations either through concatenation or subtraction:</p><formula xml:id="formula_5">h cat = [h ′ obs , h ′ int ] ∈ R N ×(N +1)×2d<label>(7)</label></formula><formula xml:id="formula_6">h diff = h ′ int -h ′ obs ∈ R N ×(N +1)×d . (<label>8</label></formula><formula xml:id="formula_7">)</formula><p>The former can express richer relationships between the two graphs, while the latter is more efficient on large graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model architecture</head><p>The differential network closely follows the architecture of the causal structure learner. However, since paired graph representation lacks the T dimension (introduced by marginal estimates E ′ ), the model only needs to attend over two "length" dimensions (rows and columns of adjacency matrix). After the attention layers, we mean over all "incoming edges" and linearly project to binary node-level predictions, where a normalized 1 indicates an intervention target, and 0 indicates otherwise. The target prediction loss L I is the binary cross entropy loss between the predicted and true targets, computed independently for each node. This is to accommodate interventions with multiple targets, e.g. drugs with off-target effects.</p><formula xml:id="formula_8">Interventional D int Observational D obs Differential network N ⨉ (N+1) ⨉ d N ⨉ d</formula><p>Remark We take an amortized causal discovery approach because it is hard to specify what assumptions a biological system ought to follow. This makes it difficult to provide identifiability guarantees without simplifying aspects of either the data or modeling framework. Instead, in Appendix C, we show that the differential network is a wellspecified class of models. That is, there exist parametrizations of its attention architecture that map predicted graphs and global statistics (for hard and soft interventions) to the set of targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Implementation details</head><p>Training procedure The overall training loss is L = L G + L I with L2 weight regularization. Both L G and L I supervise the causal structure learner, while only the latter supervises the differential network. We use the synthetic and real datasets as follows. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model parameters</head><p>Marginal estimates E ′ are computed using the classic FCI algorithm <ref type="bibr" target="#b68">(Spirtes et al., 1995)</ref> with k = 5 and T = 100, and global statistic ρ is pairwise correlation, as it is fast to compute and numerically stable. We swept over the number of differential network layers (Figure <ref type="figure" target="#fig_3">4</ref>) on synthetic data, and we used 3 layers for h cat and 2 layers for h diff . Following SEA, we adopted hidden dimension d = 64, the AdamW optimizer <ref type="bibr" target="#b42">(Loshchilov &amp; Hutter, 2019)</ref>, learning rate 1e-4, batch size 16, and weight decay 1e-5. On the real data, where N = 1000, we changed to a batch size of 1, decreased the learning rate to 5e-6, and finetuned the models with half precision (FP16). We trained both h cat and h diff models on synthetic data, but only finetuned the h diff architecture on the real data (memory constraint).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>While our method is intended to be used in cases where true targets are unknown, we can only evaluate on datasets where the target is known. Thus, we demonstrate that CDN can recover perturbation targets on seven transcriptomics datasets, with comparisons to state-of-the-art models for these applications (Section 4.1). For completeness, we also benchmarked CDN against multiple causal discovery algorithms for unknown interventions in variety of controlled settings (Section 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Biological experiments</head><p>Datasets We validate CDN on five Perturb-seq <ref type="bibr" target="#b19">(Dixit et al., 2016)</ref>   <ref type="formula">2024</ref>). Each dataset is a realvalued matrix of gene expression levels: the number of examples M is the number of cells, the number of variables N is the number of genes, and each entry is a log-normalized count of how many copies of gene j was measured from cell i. In Perturb-seq datasets, we aim to recover the gene whose promoter was targeted by the CRISPR guide, and in Sci-Plex datasets, we aim to identify the gene that corresponds to the drug's intended target (discussion in Appendix D.1).</p><p>Biologically, many perturbations do not affect the cell's production of mRNA (they may affect other factors like protein activity, which transcriptomics does not measure).</p><p>To ensure that P obs and P int are distinct, we filtered perturbations to those that induced over 10 differentially-expressed genes (statistically significant change, compared to control), of which the true target should be present. This excludes perturbations with insufficient cells (low statistical power), with minimal to no effect (uninteresting), and those that did not achieve the desired effect (low CRISPR efficiency). In the Sci-Plex data, several drugs have known off-targets, but we did not observe differential expression of any of them (adjusted p-value ≈ 1).</p><p>Evaluation We consider two splits: seen and unseen cell lines. In the former, models may be trained on approximately half of the perturbations from each cell line, and are evaluated on the unseen perturbations. In the latter, we hold out one cell line at a time, and models may be trained on data from the remaining cell lines. To ensure that our train and test splits are sufficiently distinct, we cluster perturbations based on their log-fold change and assign each cluster to the same split (Figure <ref type="figure" target="#fig_4">5</ref>). Since the Sci-Plex data are limited, we use them only as test sets without finetuning.</p><p>We limited the set of candidate targets to the top 1000 differentially expressed genes by log-fold change, per perturbation. If too few genes passed the significance threshold (p &lt; 0.05), we added additional candidates with the largest log-fold change until we reached a minimum of 100 genes. Genetic perturbations have highly specific effects compared to chemical perturbations, so we focused on the subset for which the intended target was not trivially identifiable as the gene with the largest log-fold change.<ref type="foot" target="#foot_0">foot_0</ref> </p><p>While perturbation target prediction appears to be a simple classification task, standard metrics are not well-suited for these real data. Not all genes are present in the baselines' domain knowledge (e.g. isolated node in graph), so their effects as perturbations cannot be predicted. In addition, due to genetic redundancy, it is common for multiple perturbations to elicit similar responses <ref type="bibr">(Kernfeld et al., 2023)</ref>.</p><p>An "incorrect" top 1 prediction may not necessarily reflect poor performance. Thus, we propose the following metrics.</p><p>• We order genes based on the similarity of their predicted effect to the ground truth target effect, or based on their predicted probability of being a target. The rank is the index of the true target, normalized by the number of candidate genes. Rank ranges from 0 (worst, bottom of list) to 1 (best, top of list).</p><p>• We measure the similarity between the perturbation effect (log-fold change) of the top 1 predicted target and the true target with the Spearman rank correlation ρ and the Pearson correlation r. These range from -1 to 1, where 1 is best.</p><p>• To emulate "virtual screening," we plot recall at p: the fraction of targets recovered within the p ∈ (0, 1) candidates. Recall ranges from 0 to 1, where 1 is best. Rank is equivalent to the expected recall at p.</p><p>Baselines We compare to both algorithms that infer the effects of perturbations on cells (used as scoring functions, Equation <ref type="formula" target="#formula_2">3</ref>), and algorithms that directly predict targets. All baselines were run with their official implementations and/or latest releases. For details, please see Appendix B.2.</p><p>GEARS <ref type="bibr" target="#b62">(Roohani et al., 2023)</ref> and GENEPT <ref type="bibr">(Chen &amp; Zou, 2023)</ref> predict the effects of unseen genetic perturbations. GEARS is a graph neural network that regresses log-fold change upon perturbation, using the Gene Ontology knowledge graph as an undirected backbone. GENEPT is a set of large language model-derived embeddings that have been shown to achieve state-of-the-art performance <ref type="bibr" target="#b49">(Märtens et al., 2024)</ref> with simple downstream models like logistic regression (used here). Both are trained per cell line.</p><p>PDGRAPHER (Gonzalez et al., 2024) is a graph neural network that predicts the perturbation targets of genetic or chemical perturbations, on seen or unseen cell lines, with the Human Reference Interactome <ref type="bibr" target="#b46">(Luck et al., 2020)</ref> as the knowledge graph. To the best of our knowledge, PDGRA-PHER is the only published deep learning baseline for the target prediction task on transcriptomic data. Therefore, we compare against additional statistical and naive baselines.</p><p>DGE stands for differential gene expression <ref type="bibr" target="#b45">(Love et al., 2014)</ref>, i.e. the process of identifying statistically significant changes in genes between settings. Specifically, we run the Wilcoxon ranked-sum test with Benjamini-Hochberg correction <ref type="bibr" target="#b79">(Wilcoxon, 1945;</ref><ref type="bibr" target="#b5">Benjamini &amp; Hochberg, 2000)</ref> between control and perturbed cells, as implemented by <ref type="bibr" target="#b80">Wolf et al. (2018)</ref>. Genes are ranked by adjusted p-value.</p><p>LINEAR and MLP take as input the mean expression of all perturbation targets, plus the top 2000 highly-variable genes <ref type="bibr" target="#b80">(Wolf et al., 2018)</ref>. They are trained to predict a binary label for each gene on each cell line independently.</p><p>Results CDN consistently outperforms all baselines on the five Perturb-seq datasets, in both the seen and unseen cell line settings (Table <ref type="table" target="#tab_2">1</ref>). There is minimal drop in between seen and unseen cell lines, suggesting that the functional characteristics of genetic perturbations are highly transferrable, even to different data distributions. Notably, no other deep learning method exceeds simple statistical tests (DGE). This is more evident in Figure <ref type="figure">3</ref>, in which CDN achieves higher recall at p at nearly all points. Finally, if we ablate the finetuning step ("synthetic" vs. "Perturb-seq"), we find that finetuning leads to significant improvements.</p><p>Chemical perturbations are much less specific than genetic perturbations (Figures <ref type="figure">6</ref> and<ref type="figure" target="#fig_5">7</ref>), and it is less clear whether drug effects should be reflected in mRNA levels (via feedback mechanisms), as drugs act upon their protein products. Still, on the two chemical perturbation datasets, CDN finds the true target within the top 100 candidates for 3/6 cases (Table <ref type="table">2</ref>). Due to the low performance of DGE on several cases, we hypothesized that gene-level changes may not be as predictive. Indeed, an ablation of CDN, trained without node-level statistics, improves where DGE fails ("no µ").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Synthetic experiments</head><p>While it would be ideal to evaluate all algorithms on real data, current causal discovery algorithms that support unknown interventions are not tractable on datasets with more than tens of variables. In fact, many baselines require hours on even N = 10 datasets, and they do not scale favorably (Table <ref type="table" target="#tab_8">6</ref>). Our transcriptomics datasets contain hundreds of genes, even after filtering to those that are differentially expressed (Figure <ref type="figure" target="#fig_6">8</ref>). At the same time, existing models for biological perturbations all rely on some form of domain knowledge, and their performance is inseparable from the choice and quality of these external data. Synthetic data allow us to assess the model's capacity to predict intervention targets in isolation.</p><p>Datasets Each evaluation setting consists of 5 unseen, i. MB+CI is inspired by <ref type="bibr" target="#b28">Huang et al. (2020)</ref>. We introduce a domain index (indicator of environment), compute its Markov boundary using graph lasso, and use conditional mutual information to identify true children of the domain index (intervention targets). DCI with stability selection <ref type="bibr" target="#b4">(Belyaeva et al., 2021)</ref> predicts edge-level differences between two causal graphs. We take each node's proportion of changed edges as its likelihood of being an intervention target. While DCI was also motivated by biological applications, it only scales to around a hundred variables at most, so we evaluate it alongside other causal discovery methods here.</p><p>Evaluation In the synthetic case, we are not constrained by biological redundancy or incomplete predictions, so we report standard classification metrics: mean average precision (mAP) and area under the ROC curve (AUC). Both metrics are computed independently for each variable and averaged over all regimes of the same number of targets. Their values range from 0 to 1 (perfect). The mAP random baseline depends on the positive rate, while the AUC random baseline is 0.5 (per edge).</p><p>Results On synthetic data, CDN achieves high performance across intervention types and data-generating mechanisms (Table <ref type="table" target="#tab_3">3</ref>), while running in seconds (Table <ref type="table" target="#tab_8">6</ref>). As an ablation study, we investigated removing the graph loss and the pretrained weights, with no change to the graph-centric architecture. We found that supervising based on the graph is almost always helpful ("no L G " row), and pretraining leads to more stable training dynamics (Figure <ref type="figure" target="#fig_0">10</ref>).</p><p>DCI and MB+CI are the best baselines, which is encourag- ing, as they are designed with the intuition that detecting differences is easier than reproducing the entire causal graph. Surprisingly, most other baselines perform poorly at recovering intervention targets. In the case of DCDI and BACADI, this may be because it is hard to select a single sparsity threshold for varying sizes of intervention sets, and to balance the sparsity regularizer with the generative modeling objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>This work introduces causal differential networks (CDN), which focuses on the application of predicting perturbation targets for efficient experimental design. On a high level, our goal is to lower the cost and scale of experiments, by reducing the search space. Our key technical contribution is the idea of using supervised causal discovery as a pretraining objective, to obtain dataset representations useful for downstream tasks like inferring targets. Specifically, CDN trains a causal graph learner that maps a pair of observational and interventional datasets to their data-generating mechanisms, and a differential network classifier to identify variables whose conditional independencies have changed.</p><p>We demonstrated that our approach outperforms state-ofthe-art methods in perturbation modeling and causal discovery, across seven transcriptomics datasets and a variety of synthetic settings. Overall, these results highlight the potential of our method to design more efficient experiments, by reducing the search space of perturbations.</p><p>There are several limitations of this work and directions for future research. First, our implementation does not address cyclic, feedback relationships or time-resolved, dynamic systems -both of which are common in biology. Modeling these cases may require data simulation schemes that can sample from the steady-state of a cyclic system, or architectures that directly predict the parameters of a system of stochastic differential equations <ref type="bibr" target="#b66">(Lorch et al., 2024)</ref>. In addition, current supervised causal discovery algorithms, which we use for the causal graph learner, tend to assume causal sufficiency, i.e. that there are no unseen confounders. This assumption is unrealistic in biology, as it is not physically possible to measure all relevant variables. Thus, there is an opportunity to extend this work for the latent confounding setting. Finally, since it is difficult to simulate biology, there will be an inevitable domain shift between synthetic and real data. However, there does exist plentiful unlabeled single-cell data <ref type="bibr" target="#b14">(Consortium* et al., 2022)</ref>, which could be used with self-supervised objectives to bridge the gap <ref type="bibr" target="#b74">(Sun et al., 2020)</ref>. In conclusion, we hope that this work will enable efficient experimental design and interpretation, as well as future machine learning efforts towards these tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact statement</head><p>Our work proposes a machine learning method to improve understanding of large-scale perturbation experiments, in the context of molecular biology. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Model architecture A.1. Attention layers</head><p>To balance expressivity and efficiency, our model is designed around series of "axial" attention layers, similar to <ref type="bibr" target="#b27">Ho et al. (2019)</ref>; <ref type="bibr">Rao et al. (2021)</ref>; <ref type="bibr" target="#b81">Wu et al. (2025)</ref>. The causal structure learner closely resembles the architecture of SEA <ref type="bibr" target="#b81">(Wu et al., 2025)</ref>, while the differential network is slightly different (since the input space is different). Briefly, the input to the causal structure learner is a matrix of shape N × N × T × d. However, the (dense) global statistic does not span the T dimension, and the local graph estimates are generally sparse. Thus, the causal graph learner separately attends over the N × N × d and K × T × d components (K is the number of unique edges in sparse format), with "messages" to align the representations between each attention layer. In contrast, the differential network only operates over the dense N × (N + 1) × d (or 2d) representation. Thus, it omits the message passing layers and directly stacks dense attention layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Edge embeddings</head><p>Since attention itself is invariant to input ordering, Transformer-style architectures use absolute <ref type="bibr" target="#b17">(Devlin et al., 2019)</ref> or relative <ref type="bibr" target="#b73">(Su et al., 2024)</ref> positional embeddings to distinguish input elements. Images and sequences have a natural ordering among their elements. This structure inherently induces distances between positions, which provides signal for learning models. In contrast, models over graphs should be equivariant to the labeling of nodes. That is, if 1 → 2 is an edge, while 2 and 3 are not connected, then re-labeling the nodes (1, 2, 3) → (2, 3, 1) should result in edge 2 → 3 and no edge between 3 and 1.</p><p>If we assign an arbitrary ordering to each graphx, the Transformer will be able to distinguish between nodes. However, there are several practical issues. Since synthetic data are generated in the topological ordering of the nodes, always assigning the root nodes to low positions may lead to unintended information leakage. Furthermore, if the model is trained on graphs of up to N = 100, but tested on larger graphs, the positional embeddings associated with N &gt; 100 will be entirely random and out of distribution. Following <ref type="bibr" target="#b81">Wu et al. (2025)</ref>, we randomly sample a permutation of the maximum graph size to each graph. Each edge embedding is the concatenation of its constituent nodes' embeddings, combined via a feed-forward network:</p><formula xml:id="formula_9">Embed(i, j) = FFN([Embed(i), Embed(j)])<label>(9)</label></formula><p>where i, j are arbitrarily assigned, but consistent within the graph. This embedding is added to the hidden representation h i,j before the first layer of attention.</p><p>In the differential network, the additional "column" associated with node-level statistics is not subject to any embedding (which implicitly differentiates it from the remaining inputs), while the "row" identifies the node these statistics were computed for.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation details B.1. CDN training</head><p>We trained until convergence (no improvement for 50 epochs on synthetic; 10 epochs on Perturb-seq) and selected the best model based on validation mAP (Figure <ref type="figure" target="#fig_3">4</ref>). The validation distribution was identical to training and did not contain test causal mechanisms. During training, we used 15 CPU workers (primarily for local graph estimates) and 1 A6000 GPU. CDN took around 6 hours to train on synthetic data, and 1 hour to finetune on real data. Unless otherwise noted, the causal structure learner was initialized from the SEA inverse covariance, FCI pretrained weights <ref type="bibr" target="#b81">(Wu et al., 2025)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Baselines</head><p>We used the latest releases of all baselines.</p><p>GEARS is a graph neural network that predicts the effects of unseen genetic perturbations, based on the Gene Ontology knowledge graph <ref type="bibr" target="#b1">(Ashburner et al., 2000)</ref>. We trained GEARS on each cell line separately, and predicted the effects of perturbing every expressed gene. Then we ranked candidates based on cosine similarity to the interventional data. Figure <ref type="figure">9</ref> depicts the low, but non-trivial proportion of differentially expressed genes for which GEARS was unable to make a prediction, due to lack of node coverage in their processed gene ontology graph <ref type="bibr" target="#b1">(Ashburner et al., 2000)</ref>. These genes were not considered in the rankings or evaluations for GEARS. GENEPT utilized the v2 March 2024 update, which used newer models and additional protein data, compared to their initial paper (GenePT gene protein embedding model 3 text). We concatenated each perturbation's gene embedding to the log-fold change of the top 5000 highly-variable genes <ref type="bibr" target="#b80">(Wolf et al., 2018)</ref> and trained a logistic regression model on each cell line to predict true vs. decoy perturbations. Candidates were ranked based on predicted probability. Of the 2,842 unique genetic perturbations, only 2,819 (99.1%) mapped to GENEPT embeddings. The remainder used the mean gene embedding (within the dataset) as the language-based embedding.</p><p>PDGRAPHER was published on the union of three distinct knowledge graphs, but their harmonized graphs were not available publicly, and the authors did not respond to requests for data sharing. As a result, we relied on solely the human reference interactome <ref type="bibr" target="#b46">(Luck et al., 2020)</ref> graph, as it was the only one of the three that could be easily processed. All test perturbation targets could be inferred through PDGRAPHER.</p><p>UT-IGSP used the official implementation from commit 7349396, since the repository is not back-compatible.</p><p>BACADI is evaluated using the fully-connected implementation, since it performed better than the linear version. However, since the linear version is significantly faster, we include its runtime in Table <ref type="table" target="#tab_8">6</ref>.</p><p>MB+CI was implemented using scikit-learn <ref type="bibr" target="#b57">(Pedregosa et al., 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Theoretical motivation</head><p>While this paper focuses on biological applications, we show that the differential network is well-specified as a class of models, i.e. a correct solution is contained within the space of possible parametrizations.</p><p>Preliminary note In this analysis, we assume that the "causal" representations h contains enough information both to retain global statistics and recover the true graph E. The former is reasonable due to high model capacity, and the latter is based on high empirical performance in graph reconstruction <ref type="bibr" target="#b81">(Wu et al., 2025)</ref>. We emphasize that the latter is an empirical judgment, which may not hold on all datasets in practice.</p><p>Attention-based architecture Our differential network is implemented using an attention layer, which is composed of two self-attention layers (one along each axis of the adjacency matrix) and a feed-forward network. For simplicity, we follow prior work <ref type="bibr" target="#b84">(Yun et al., 2019)</ref> and ignore layer normalization and dropout.</p><p>Our inputs h ∈ R 2d×N ×N are 2d-dimension features, which represent a pair of N × N causal graphs. We use h •,j to denote a length N row for a fixed column j, and h i,• to denote a length N column for a fixed row i. The attention layer implements:</p><formula xml:id="formula_10">Attn row (h •,j ) = h •,j + W O W V h •,j • σ (W K h •,j ) T W Q h •,j , Attn col (h i,• ) = h i,• + W O W V h i,• • σ (W K h i,• ) T W Q h i,• , FFN(h) = h + W 2 • ReLU(W 1 • h + b 1 ) + b 2 ,</formula><p>where</p><formula xml:id="formula_11">W O ∈ R 2d×2d , W V , W K , W Q ∈ R 2d×2d , W 2 ∈ R 2d×m , W 1 ∈ R m×2d , b 2 ∈ R 2d , b 1 ∈ R m ,</formula><p>and m is the FFN hidden dimension. We have omitted the i and j subscripts on the W s, but they use separate parameters. Any self attention can take on the identity mapping by setting</p><formula xml:id="formula_12">W O , W V , W K , W Q to 2d × 2d matrices of zeros.</formula><p>Hard interventions Let G = (V, E) be a causal graphical model associated with data distribution P X . Let G ′ = (V, E ′ ) and PX denote the causal graph and data distribution after an unknown intervention, with ground truth targets I ⊊ V . For convenience, we use E, E ′ both to denote sets of edges, as well as the equivalent adjacency matrices.</p><p>In the case of perfect interventions,</p><formula xml:id="formula_13">f (x i ) ← z i , ∀i ∈ I (10)</formula><p>where z i ⊥ ⊥ X are independent random variables. PX is associated with mutilated graph E ′ , where</p><formula xml:id="formula_14">E ′ = E \ i∈I {(j, i)} (j,i)∈E .<label>(11)</label></formula><p>In terms of the associated adjacency matrices, E -E ′ has 1s in each column i ∈ I and 0s elsewhere.</p><p>Here, the attention layer should implement h -h ′ , so that when we collapse over the incoming edges, the output is non-zero only at the edge differences. Suppose the first dimension of the 2d feature stores E, and the second dimension stores E ′ . The row self-attention implements the identity (in the first two dimensions). Then we can set W K,Q to zero, W V to the identity, and W O to</p><formula xml:id="formula_15">W O = 1 -1 0 0 - 1 0 0 1 (12)</formula><p>to account for the residual. The FFN implements the identity, so that when we take the mean over along the rows, we recover non-zero elements at all nodes whose incoming edges were removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Soft interventions</head><p>We also study soft interventions the context of causal models with non-multiplicative noise, in which intervention targets are scaled by constant factors,</p><formula xml:id="formula_16">f (x i ) ← c i f (x), c i &gt; 0<label>(13)</label></formula><p>where c i are sampled at random per synthetic dataset. This choice is inspired by the fact that biological perturbation effects are measured in fold-change. Here, the adjacency matrices are the same, but global statistics differ. In particular, we focus on two statistics: the correlation matrix R and the covariance matrix Σ. Note that while we do not explicitly provide the covariance matrix as input, we do provide marginal variances, from which the same information can be derived.</p><p>Suppose x is an intervention target.</p><p>• R -R ′ is non-zero in all entries i, j and j, i where i is a descendent of x, and j is any node for which R i,j ̸ = 0 (e.g. ancestors, descendants, and x, if P X is faithful to G).</p><p>• Σ -Σ ′ is non-zero in all entries i, j and j, i where i is a descendent of x or i = x, and j is any node for which Σ i,j ̸ = 0 (e.g. ancestors, descendants, and x, if P X is faithful to G).</p><p>All descendants are always affected, due to the non-multiplicative noise term. These two differ in the row and column that correspond to x since</p><formula xml:id="formula_17">Corr(c • x, y) = Corr(x, y) (14) Cov(c • x, y) = c • Cov(x, y).<label>(15)</label></formula><p>Therefore, to identify x, we should find the index in which Σ differs but not R. Suppose that dimensions 3-6 of h encode R, R ′ , Σ, Σ ′ . Following the same strategy as the hard interventions, we can use the row attention to compute R -R ′ , Σ -Σ ′ and store them in dimensions 3, 4. Then we use the column attention to filter out variables that are independent from x by storing the sum of each column in dimensions 5, 6. While not strictly impossible, it is unlikely that a variable dependent on x would result in a column that sums to exactly 0. Thus, all columns with non-zero sums are either ancestors, descendants, or x. The feedforward network implements</p><formula xml:id="formula_18">FFN(h •,3-6 ) = 1 h •,3 = 0, h •,4 ̸ = 0, h •,5 ̸ = 0 0 otherwise. (<label>16</label></formula><formula xml:id="formula_19">)</formula><p>This results in 1s in the rows and columns where ∆R and ∆Σ differ. After collapsing over incoming edges and normalizing to probabilities, the maximum probabilities can be found at the intervention targets.</p><p>Supporting both intervention types Recall that the final output layer is a linear projection from 2d to 1. If this layer implements a simple summation over all 2d, the predicted intervention targets are consistent with both hard and soft interventions. For soft interventions, E = E ′ , so the hard intervention dimensions will be 0. Likewise, for hard interventions, both R and Σ will differ as the same locations, as the underlying variable has changed, so the soft intervention dimensions will be 0. Since the two techniques produce mutually exclusive predictions, this means that both hard and soft interventions can co-exist and be detected on different nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Datasets</head><p>D.1. Biological datasets Data processing We converted all single cell datasets to log-normalized, transcripts per 10,000 UMIs. Perturb-seq genes were mapped to standard identifiers and filtered by the authors. Sci-Plex dataset variables represented genes that appeared in at least 5,000 cells (threshold chosen to achieve a similar number of genes). We performed differential expression analysis via the scanpy package <ref type="bibr" target="#b80">(Wolf et al., 2018)</ref>, using the Wilcoxon signed-rank test <ref type="bibr" target="#b79">(Wilcoxon, 1945)</ref> with Benjamini-Hochberg p-value correction and a threshold of adjusted p-value &lt; 0.05. Table <ref type="table" target="#tab_5">4</ref> reports statistics of the raw, unprocessed datasets.</p><p>For Perturb-seq datasets, we kept perturbations with &gt; 10 differentially-expressed genes (DEGs), and clustered them using k-means with k = 200, chosen heuristically based on log-fold change heatmaps (Figure <ref type="figure" target="#fig_4">5</ref>). These clusters were used to inform data splits for seen cell lines, where the largest cluster was allocated to the training set, and all remaining clusters were split equally among train and test. The largest cluster(s) appear to contain perturbations with smaller effects. For Sci-Plex datasets, only 6 drug perturbations across 2 cell lines resulted in differential expression of their known protein targets (Supplementary Table <ref type="table" target="#tab_10">8</ref> from <ref type="bibr" target="#b50">McFaline-Figueroa et al. (2024)</ref>). Therefore, we used these exclusively as test sets.</p><p>Table <ref type="table" target="#tab_6">5</ref> reports statistics of the final, processed datasets. Figure <ref type="figure" target="#fig_6">8</ref> plots the full distribution of number of cells and DEGs per perturbation.</p><p>Top differentially expressed genes Here, we limited our analysis to the top 1000 DEGs. In the literature, it is quite common to restrict analysis to subsets of genes, though the threshold and criteria may vary <ref type="bibr" target="#b47">(Luecken &amp; Theis, 2019)</ref>.</p><p>Selecting the top 1000 genes (based on differential expression p-value) is reasonably permissive, since these genes are selected per perturbation. For a sense of scale, <ref type="bibr">Nadig et al. (2024)</ref> writes:</p><p>"In a genome-scale Perturb-seq screen, we find that a typical gene perturbation affects an estimated 45 genes, whereas a typical essential gene perturbation affects over 500 genes."</p><p>A classic approach for identifying drug targets argues that targets are not highly differentially expressed, but network-based approaches are useful for predicting them from gene expression <ref type="bibr" target="#b31">(Isik et al., 2015)</ref>.This work also samples 1000 candidate targets as decoys.</p><p>Gene co-expression Figures 6 and 7 depict the differences in gene co-expression matrices between control and perturbed cells. Genetic perturbations tend to have much clearer phenotypes compared to chemical perturbations, whose effects are more diffuse.</p><p>Sci-Plex drug targets The full names of the Sci-Plex drugs and their targets are as follows. These targets were collated by the authors <ref type="bibr" target="#b50">(McFaline-Figueroa et al., 2024)</ref>, and are each are well-documented in the literature.</p><p>• Infigratinib ("infig") binds target FGFR1 with nano-molar affinities <ref type="bibr" target="#b36">(Knox et al., 2024)</ref>.</p><p>• Nintedanib ("nint") and target FGFR1 have been probed through structural studies <ref type="bibr" target="#b26">(Hilberg et al., 2008)</ref>.</p><p>• Palbociclib ("palb") has been co-crystallized (PDB 5L2I) with its target CDK6.</p><p>• Doxorubicin ("doxo") and target TOP2A are associated in a number of works <ref type="bibr" target="#b36">(Knox et al., 2024)</ref>.</p><p>• Volasertib ("vola") has been co-crystallized (PDB 3FC2) with PLK1 and a number of works confirm specificity for PLK2 <ref type="bibr" target="#b9">(Chen et al., 2021)</ref>.  It is important to note that these drugs are also associated with known off-targets. However, we did not observe differential expression of any off-target, adjusted p ≈ 1, perhaps because the impact on their mRNA expression is negligible. Protein activity would be more suitable for quantifying the impact of a drug on a cell. However, this cannot be measured at scale. In fact, even protein abundance is difficult to measure at single-cell resolution, as it relies on mass spectrometry to differentiate proteins <ref type="bibr" target="#b54">(Newman et al., 2006)</ref>, while mRNA can be exhaustively enumerated and sequenced (based on the known human genome). Therefore, this chemical perturbation study is primarily a proof of concept, to probe whether targets can be inferred from mRNA expression, and if so, to what extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. Synthetic data</head><p>Synthetic data were generated using code modified from DCDI <ref type="bibr" target="#b7">(Brouillard et al., 2020)</ref> for soft interventions. We used the following implementations for causal mechanisms f (x), where x is the variable in question, M is a binary mask for the parents of x, X contains measurements of all variables, E is independent Gaussian noise, and W is a random weight matrix.</p><p>• Linear: f</p><formula xml:id="formula_20">(x) = M XW + E. • Neural network, non-additive f (x) = Tanh((X, E)W in )W out • Neural network, additive: f (x) = Tanh(XW in )W out + E • Polynomial: f (x) = W 0 + M XW 1 + M X 2 W 2 + E • Sigmoid: f (x) = d i=1 W i • sigmoid(X i ) + E</formula><p>Linear and the neural network variants were used for training. Polynomial and sigmoid were only used for testing.</p><p>Root causal mechanisms are uniform. For hard interventions, we set f (x) ← z, where z ∼ Uniform(-1, 1). For soft "scale" interventions, we set</p><formula xml:id="formula_21">f (x) ← z Sign(z) 1 • f (x) z 1 ∼ Uniform(2, 4) z ∼ Uniform(-1, 1).</formula><p>That is, we multiply f (x) by a scaling factor that is equal probability ≶ 1 (constant across all observations). Figure <ref type="figure">6</ref>: Difference between observational and interventional correlation matrices on K562 genome-wide. In some cases, the changes are minimal and specific; in others, they are more diffuse.</p><p>For soft "shift" interventions, we set</p><formula xml:id="formula_22">f (x) ← f (x) + Sign(z) • z 1 z 1 ∼ Uniform(2, 4) z ∼ Uniform(-1, 1).</formula><p>That is, we translate f (x) by a scaling factor that is equal probability ≶ 0 (constant across all observations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Additional analyses</head><p>Runtime We compared the runtimes of various algorithms on the Perturb-seq and synthetic datasets. On the Perturb-seq data, all models finished running within minutes with the exception of GEARS (Figure <ref type="figure" target="#fig_0">11</ref>). Runtimes of the various causal algorithms varied significantly (Table <ref type="table" target="#tab_8">6</ref>). The slowest method was DCDI, with an average runtime of around 10 hours on N = 20 datasets, while the fastest were UT-IGSP and the MLP variant of CDN. All models were benchmarked on equivalent hardware (A6000 GPU, 1 CPU core).</p><p>Perturb-seq uncertainty quantification Due to space limitations, we report uncertainty estimates in Tables <ref type="table" target="#tab_9">7</ref> and<ref type="table" target="#tab_10">8</ref>. Multiple baselines produce deterministic results (LINEAR, DGE, GENEPT), so instead of model randomness, we report uncertainties over the sampling of single cells (Table <ref type="table" target="#tab_9">7</ref>). Specifically, for each perturbation with M cells, we sample</p><formula xml:id="formula_23">M ′ = min(M, max(50, 0.8M ))<label>(17)</label></formula><p>cells uniformly at random, repeated 5 times. We also consider the robustness of our model to samplings of the test set (Table <ref type="table" target="#tab_10">8</ref>). Typically, the largest cluster (assigned to train, e.g. nearly 1/3 of K562) contains weak perturbations with minimal phenotype, so different clusterings don't introduce significant heterogeneity. Instead, we can partition all perturbations uniformly into 5 sets for the unseen cell line setting, across which the variation in results is minimal.</p><p>Perturb-seq trivial perturbations For the main results in Table <ref type="table" target="#tab_2">1</ref>, we focus on genetic perturbations for which the intended gene target was not the gene with the greatest log-fold change. This is because genetic perturbations are (unrealistically) specific, compared to drugs or transcription factors. In Table <ref type="table">9</ref>, we show that our model performs nearly perfectly in this easy setting.   <ref type="table" target="#tab_6">5</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph loss</head><p>We assess the value of predicting the causal graph, as opposed to only training a supervised classifier (Figure <ref type="figure" target="#fig_0">10</ref>). Without modifying the architecture (which has inductive biases towards the graph modality), we train a version of CDN without any graph labels (causal graph learner no longer pretrained; remove graph loss L G ). Across the validation loss and various metrics, we find that the full CDN is more stable, and leads to better results. This model corresponds to the "no L G " test results in Table <ref type="table" target="#tab_3">3</ref>.</p><p>Additional synthetic results During model development, we realized that if the model is allowed to train on all types of perturbations, it can easily overfit and learn these distributional shifts very well. For example, in Table <ref type="table" target="#tab_2">10</ref>, the models trained on both types of soft interventions performs perfectly (unrealistic) in many cases, even though the graphs and causal mechanism parameters are completely novel. Therefore, to assess whether our model can generalize, we chose to hold out a class of soft intervention for our main results in Table <ref type="table" target="#tab_3">3</ref>.</p><p>Table <ref type="table" target="#tab_2">11</ref> reports results on larger graphs. There is some drop in performance, especially Polynomial. This could be attributed to error propagation from the causal graph predictor, which performs less well (at predicting graphs) on larger graphs, and could potentially be ameliorated by finetuning on larger synthetic data (similar to how Perturb-seq models were finetuned to be larger). Linear + Soft remains quite good, perhaps because the theory (Appendix C) suggests that the summary statistics are sufficient for predicting targets, without the graph prediction. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (A) Biological applications. (B) Differences between observation dataset D obs and interventional dataset D int can be attributed to changes in the underlying causal mechanisms. (C) We use an amortized causal discovery model to predict G obs and G int , whose hidden representations are input to a perturbation target classifier. Both modules are jointly trained.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Our model is composed of a causal structure learner and a differential network. Learned components in yellow (causal structure learner) and green (differential network). Both modules are trained jointly to optimize L = L G + L I .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1.</head><label></label><figDesc>Initialize the causal structure learner with pretrained weights from<ref type="bibr" target="#b81">Wu et al. (2025)</ref> (except ablations). 2. Train both modules jointly on synthetic data. 3. Finetune both modules jointly with only L I (no ground truth graphs), on each training split of the real datasets. For the synthetic training data, we generated 8640 datasets with hard and soft interventions, which vary in causal mechanism, intervention type, and graph topology. To emulate transcriptomics data, in which perturbation effect sizes are quantified in (log) fold change, we introduced soft interventions: "shift" x ← f (π x ) + c, where c ∈ R, and "scale" x ← cf (π x ), where c is a positive scaling factor, with equal probability c ≶ 1. We also sampled interventions with multiple targets, to simulate off-target effects. Details are available in Section 4.2 and Appendix D.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Hyperparameter search: number of differential network layers. We selected 3 layers based on validation metrics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Heatmap of correlation between log-fold change, sorted by cluster, used for data splits.</figDesc><graphic coords="20,55.44,67.06,486.00,106.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Difference between observational and interventional correlation matrices on Sci-Plex datasets. Effects are much more diffuse than in genetic perturbations (Figure 6).</figDesc><graphic coords="21,150.15,175.73,97.20,107.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Transcriptomics dataset statistics, after processing. See Table5for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Rényi graphs with N = 10, 20 nodes and E = N, 2N expected edges; causal mechanism parameters; and observations of each variable, in topological order. We sampled 3N distinct subsets of 1-3 nodes (N each) as intervention targets. Hard interventions set x ← z, where z is uniform. For soft interventions (Section 3.3), we trained on shift and tested on scale for synthetic experiments (see Table10for explanation). Real experiments trained on all interventions.Baselines We compare against discrete and continuous causal discovery algorithms for unknown interventions. UT-IGSP(Squires et al., 2020)  infers causal graphs and unknown targets by greedily selecting the permutation of variables that minimizes their proposed score function. DCDI<ref type="bibr" target="#b7">(Brouillard et al., 2020)</ref> and BACADI<ref type="bibr" target="#b22">(Hägele et al., 2023)</ref> are continuous causal discovery algorithms that fit generative models to the data, where the causal graph and intervention targets are model parameters. DCDI's -G and -DSF suffixes correspond to Gaussian and deep sigmoidal flow parametrizations of the likelihood. BACADI's -E and -M suffixes indicate empirical (standard) and mixture (bootstrap) variants.</figDesc><table /><note><p>i.d. sampled graphs. To assess the generalization capacity of our framework, we tested the model on seen (linear) and unseen causal mechanisms (polynomial, sigmoid), and unseen soft interventions. To generate observational data, we sampled Erdős-</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Results on 5 Perturb-seq datasets. Top: Train on all cell lines jointly. Bottom: Leave one cell line out of training. Test sets (unseen perturbations) are identical in both settings. CDN (synthetic) and DGE do not require training on real Perturb-seq data. Metrics, from left to right: normalized rank of ground truth, top 1 Spearman and Pearson correlations. Uncertainty quantification in Table 7. Runtimes in Table 11.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">K562 (gw)</cell><cell></cell><cell cols="2">K562 (es)</cell><cell></cell><cell></cell><cell>RPE1</cell><cell></cell><cell></cell><cell>HepG2</cell><cell></cell><cell>Jurkat</cell></row><row><cell cols="4">Setting Model</cell><cell></cell><cell>rank</cell><cell>ρ</cell><cell cols="2">r rank</cell><cell>ρ</cell><cell cols="2">r rank</cell><cell>ρ</cell><cell cols="2">r rank</cell><cell>ρ</cell><cell cols="2">r rank</cell><cell>ρ</cell><cell>r</cell></row><row><cell></cell><cell></cell><cell></cell><cell>LINEAR</cell><cell></cell><cell cols="13">0.51 0.18 0.23 0.48 0.22 0.25 0.49 0.42 0.52 0.51 0.35 0.43 0.50 0.20 0.23</cell></row><row><cell></cell><cell></cell><cell></cell><cell>MLP</cell><cell></cell><cell cols="13">0.45 0.18 0.21 0.49 0.08 0.11 0.53 0.32 0.41 0.48 0.33 0.40 0.45 0.24 0.29</cell></row><row><cell cols="2">Seen</cell><cell></cell><cell>GENEPT</cell><cell></cell><cell cols="13">0.52 0.29 0.32 0.42 0.16 0.19 0.41 0.37 0.46 0.31 0.32 0.40 0.51 0.31 0.36</cell></row><row><cell cols="3">cell line</cell><cell>GEARS</cell><cell></cell><cell cols="13">0.56 0.19 0.22 0.45 0.18 0.20 0.49 0.35 0.44 0.54 0.32 0.40 0.50 0.22 0.26</cell></row><row><cell></cell><cell></cell><cell></cell><cell>PDG</cell><cell></cell><cell cols="13">0.54 0.25 0.29 0.49 0.20 0.23 0.48 0.41 0.52 0.54 0.37 0.43 0.52 0.31 0.35</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="15">CDN (Perturb-seq) 0.92 0.72 0.74 0.95 0.81 0.82 0.92 0.67 0.76 0.94 0.69 0.75 0.98 0.83 0.84</cell></row><row><cell></cell><cell></cell><cell></cell><cell>DGE</cell><cell></cell><cell cols="13">0.82 0.50 0.54 0.89 0.60 0.62 0.79 0.56 0.64 0.86 0.51 0.51 0.84 0.45 0.50</cell></row><row><cell cols="3">Unseen</cell><cell>PDG</cell><cell></cell><cell cols="13">0.39 0.10 0.13 0.44 0.24 0.28 0.54 0.38 0.48 0.48 0.34 0.41 0.57 0.31 0.35</cell></row><row><cell cols="3">cell line</cell><cell cols="2">CDN (synthetic)</cell><cell cols="13">0.79 0.46 0.49 0.80 0.59 0.62 0.82 0.61 0.71 0.84 0.56 0.63 0.87 0.64 0.67</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="15">CDN (Perturb-seq) 0.91 0.69 0.71 0.95 0.81 0.82 0.92 0.65 0.74 0.93 0.67 0.72 0.97 0.84 0.85</cell></row><row><cell></cell><cell>1.0</cell><cell></cell><cell cols="2">K562 (gw)</cell><cell cols="2">K562 (es)</cell><cell></cell><cell></cell><cell>RPE1</cell><cell></cell><cell></cell><cell>HepG2</cell><cell></cell><cell></cell><cell cols="2">Jurkat</cell><cell>CDN (P) CDN (S)</cell></row><row><cell>Recall</cell><cell>0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PDG GEARS GenePT</cell></row><row><cell></cell><cell>0.0</cell><cell>0</cell><cell>0.5 top p</cell><cell>1</cell><cell>0</cell><cell>0.5 top p</cell><cell>1</cell><cell>0</cell><cell>0.5 top p</cell><cell>1</cell><cell>0</cell><cell>0.5 top p</cell><cell>1</cell><cell>0</cell><cell cols="2">0.5 top p</cell><cell>1</cell><cell>DGE Linear MLP</cell></row><row><cell cols="10">Table 2: Rank of drug targets on chemical perturbation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">datasets (McFaline-Figueroa et al., 2024). A172 and T98G</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">are unseen cell lines. Highlighted: Within top 100. Drug</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">names and details in Appendix D.1.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>A172</cell><cell></cell><cell></cell><cell cols="2">T98G</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Model</cell><cell></cell><cell cols="7">infig. nint. palb. doxo. palb. vola.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DGE</cell><cell></cell><cell></cell><cell>0.12</cell><cell cols="2">0.64 0.28</cell><cell cols="4">0.94 0.24 0.83</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>PDG</cell><cell></cell><cell></cell><cell>0.72</cell><cell cols="2">0.35 0.39</cell><cell cols="4">0.06 0.34 0.42</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CDN</cell><cell></cell><cell></cell><cell>0.14</cell><cell cols="2">0.81 0.01</cell><cell cols="4">0.89 0.93 0.53</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">CDN (no µ) 0.88</cell><cell cols="2">0.44 0.58</cell><cell cols="4">0.06 0.54 0.65</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>Figure 3: Recall at p (normalized over number of candidate genes on 5 Perturb-seq datasets. For CDN, (P) and (S) denote "Perturb-seq" and "synthetic" training data.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Intervention target prediction results on synthetic datasets with N = 20, E = 40. Top: hard interventions (uniform); bottom: soft interventions (scale). Neither polynomial nor "scale" soft interventions were seen during training. Number in parentheses indicates number of intervention targets. Uncertainty is standard deviation over 5 i.i.d. datasets. Runtimes in Table 6. Extended results in Table 12.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Linear (1)</cell><cell cols="2">Linear (3)</cell><cell cols="2">Polynomial (1)</cell><cell cols="2">Polynomial (3)</cell></row><row><cell cols="2">Type Model</cell><cell>mAP↑</cell><cell>AUC↑</cell><cell>mAP↑</cell><cell>AUC↑</cell><cell>mAP↑</cell><cell>AUC↑</cell><cell>mAP↑</cell><cell>AUC↑</cell></row><row><cell></cell><cell>UT-IGSP</cell><cell cols="8">0.10±.01 0.63±.03 0.18±.01 0.52±.03 0.19±.02 0.70±.02 0.23±.03 0.56±.03</cell></row><row><cell></cell><cell>DCDI-G</cell><cell cols="8">0.16±.02 0.50±.02 0.27±.05 0.50±.04 0.15±.03 0.45±.04 0.26±.02 0.51±.04</cell></row><row><cell></cell><cell>DCDI-DSF</cell><cell cols="8">0.15±.02 0.46±.03 0.26±.03 0.47±.04 0.18±.05 0.48±.08 0.28±.04 0.52±.05</cell></row><row><cell></cell><cell>BACADI-E</cell><cell cols="8">0.18±.09 0.71±.06 0.28±.02 0.69±.03 0.20±.06 0.84±.04 0.37±.07 0.82±.05</cell></row><row><cell>Hard</cell><cell>BACADI-M</cell><cell cols="8">0.10±.02 0.66±.05 0.21±.01 0.63±.02 0.09±.02 0.71±.05 0.24±.03 0.70±.05</cell></row><row><cell></cell><cell>DCI</cell><cell cols="8">0.58±.07 0.85±.04 0.63±.06 0.84±.03 0.55±.08 0.82±.04 0.56±.08 0.79±.05</cell></row><row><cell></cell><cell>MB+CI</cell><cell cols="8">0.47±.12 0.68±.08 0.58±.09 0.71±.06 0.77±.05 0.88±.03 0.79±.04 0.88±.02</cell></row><row><cell></cell><cell>CDN</cell><cell cols="8">0.82±.05 0.96±.02 0.88±.04 0.95±.02 0.85±.05 0.97±.01 0.90±.04 0.96±.02</cell></row><row><cell></cell><cell cols="9">CDN (no LG) 0.65±.07 0.86±.06 0.72±.09 0.84±.07 0.81±.05 0.95±.02 0.86±.03 0.94±.01</cell></row><row><cell></cell><cell>UT-IGSP</cell><cell cols="8">0.10±.01 0.69±.03 0.19±.01 0.56±.03 0.18±.02 0.77±.02 0.22±.01 0.60±.01</cell></row><row><cell></cell><cell>DCDI-G</cell><cell cols="8">0.17±.03 0.50±.05 0.23±.01 0.44±.03 0.14±.03 0.48±.03 0.30±.04 0.54±.04</cell></row><row><cell></cell><cell>DCDI-DSF</cell><cell cols="8">0.17±.04 0.46±.04 0.24±.02 0.47±.03 0.16±.02 0.50±.05 0.26±.02 0.48±.02</cell></row><row><cell></cell><cell>BACADI-E</cell><cell cols="8">0.25±.07 0.65±.03 0.40±.13 0.68±.08 0.43±.22 0.81±.09 0.49±.15 0.77±.05</cell></row><row><cell>Soft</cell><cell>BACADI-M</cell><cell cols="8">0.11±.01 0.61±.02 0.26±.07 0.64±.06 0.25±.10 0.80±.09 0.38±.10 0.76±.06</cell></row><row><cell></cell><cell>DCI</cell><cell cols="8">0.48±.02 0.78±.02 0.53±.06 0.77±.04 0.62±.09 0.89±.04 0.55±.04 0.80±.04</cell></row><row><cell></cell><cell>MB+CI</cell><cell cols="8">0.46±.10 0.65±.06 0.49±.04 0.64±.03 0.97±.02 0.98±.01 0.92±.05 0.94±.03</cell></row><row><cell></cell><cell>CDN</cell><cell cols="8">0.83±.10 0.95±.05 0.76±.07 0.89±.04 0.97±.03 1.00±.00 0.96±.02 0.99±.01</cell></row><row><cell></cell><cell cols="9">CDN (no LG) 0.77±.06 0.95±.03 0.81±.08 0.93±.04 0.94±.03 0.99±.00 0.96±.02 0.99±.01</cell></row><row><cell></cell><cell>exclude scale</cell><cell cols="8">0.32±.07 0.64±.04 0.34±.09 0.65±.08 0.06±.02 0.63±.02 0.08±.02 0.61±.06</cell></row><row><cell></cell><cell>exclude scale</cell><cell cols="8">0.44±.04 0.92±.01 0.43±.09 0.90±.03 0.06±.01 0.72±.02 0.10±.02 0.73±.02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Extended biological dataset statistics (raw).</figDesc><table><row><cell>Type</cell><cell>Source</cell><cell>Accession</cell><cell cols="4">Cell line # Perts # Genes # NTCs</cell><cell># Cells</cell></row><row><cell></cell><cell></cell><cell></cell><cell>K562 gw</cell><cell>9,866</cell><cell cols="3">8,248 75,328 1,989,578</cell></row><row><cell></cell><cell cols="2">Replogle et al. (2022) Figshare 20029387</cell><cell>K562 es</cell><cell>2,057</cell><cell cols="3">8,563 10,691 310,385</cell></row><row><cell>Genetic</cell><cell></cell><cell></cell><cell>RPE1</cell><cell>2,393</cell><cell cols="3">8,749 11,485 247,914</cell></row><row><cell></cell><cell>Nadig et al. (2024)</cell><cell>GSE220095</cell><cell>HepG2 Jurkat</cell><cell>2,393 2,393</cell><cell cols="3">9,624 8,882 12,013 262,956 4,976 145,473</cell></row><row><cell>Chemical</cell><cell>McFaline-Figueroa et al. (2024)</cell><cell>GSM7056151</cell><cell>A172 T98G</cell><cell>23 23</cell><cell>8,393 8,393</cell><cell>8,660 6,921</cell><cell>58,347 58,347</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Extended biological dataset statistics (processed).</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Perturbations</cell><cell></cell><cell>Genes</cell><cell>Cells</cell></row><row><cell cols="7">Dataset Train Test Trivial Non-trivial Unique # DE Median # DE</cell></row><row><cell cols="3">K562 gw 1089 678</cell><cell>587</cell><cell>91</cell><cell>7,378</cell><cell>81 492,096</cell></row><row><cell>K562 es</cell><cell cols="2">640 420</cell><cell>348</cell><cell>72</cell><cell>8,492</cell><cell>226 213,552</cell></row><row><cell>RPE1</cell><cell cols="2">564 397</cell><cell>233</cell><cell>164</cell><cell>8,641</cell><cell>399 179,696</cell></row><row><cell>HepG2</cell><cell cols="2">364 263</cell><cell>162</cell><cell>101</cell><cell>9,282</cell><cell>271 79,309</cell></row><row><cell>Jurkat</cell><cell cols="2">679 333</cell><cell>262</cell><cell>71</cell><cell>8,432</cell><cell>162 174,698</cell></row><row><cell>A172</cell><cell>-</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell>445</cell><cell>324 18,196</cell></row><row><cell>T98G</cell><cell>-</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell>1,644</cell><cell>508 13,126</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 12</head><label>12</label><figDesc>reports results on all synthetic test datasets, averaging over all interventions for each dataset. We also include the Figure11: Inference runtimes on Perturb-seq datasets. K562 datasets are reported together. All models run on a single A6000 GPU, no constraint on memory (up to 500G). Only GEARS required over ∼20G of memory. To the best of our ability, we normalized batch size to 1.</figDesc><table><row><cell cols="5">Inference runtime on Perturb-seq cell lines</cell></row><row><cell></cell><cell>1000</cell><cell></cell><cell></cell></row><row><cell>Minutes</cell><cell>600 800 400</cell><cell></cell><cell></cell><cell>GEARS PDGrapher GenePT Ours</cell></row><row><cell></cell><cell>200</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>K 5 6 2</cell><cell>R P E 1 Dataset H e p G 2</cell><cell>J u r k a t</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Runtimes on synthetic datasets (sec).</figDesc><table><row><cell cols="2">Nodes Model</cell><cell cols="3">Min Max Mean</cell><cell>Std</cell></row><row><cell></cell><cell>UT-IGSP</cell><cell>1</cell><cell>98</cell><cell>26</cell><cell>31</cell></row><row><cell></cell><cell>DCDI-G</cell><cell cols="4">31 27908 18731 9857</cell></row><row><cell></cell><cell>DCDI-DSF</cell><cell cols="4">7118 44440 23798 5688</cell></row><row><cell>10</cell><cell>DCI BACADI</cell><cell cols="4">41 1438 4005 9483 6284 1584 404 365</cell></row><row><cell></cell><cell>BACADI-L</cell><cell cols="3">1076 1403 1272</cell><cell>76</cell></row><row><cell></cell><cell>CDN (MLP)</cell><cell>1</cell><cell>5</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell>CDN</cell><cell>17</cell><cell>147</cell><cell>39</cell><cell>27</cell></row><row><cell></cell><cell>UT-IGSP</cell><cell>1</cell><cell>78</cell><cell>19</cell><cell>26</cell></row><row><cell></cell><cell>DCDI-G</cell><cell cols="4">45 46281 35032 16068</cell></row><row><cell></cell><cell cols="5">DCDI-DSF 23181 55406 30076 7200</cell></row><row><cell>20</cell><cell>DCI BACADI</cell><cell cols="4">325 21414 4415 4707 15082 50737 26020 9044</cell></row><row><cell></cell><cell>BACADI-L</cell><cell cols="3">2862 3819 3461</cell><cell>252</cell></row><row><cell></cell><cell>CDN (MLP)</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>0</cell></row><row><cell></cell><cell>CDN</cell><cell>36</cell><cell>86</cell><cell>54</cell><cell>13</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Uncertainty quantification on Perturb-seq datasets, seen cell lines, by sub-sampling to 80% of cells per perturbation (or 50, whichever is higher). Note that results may be slightly different from Table 1 due to sub-sampling. Standard deviation reported over 5 seeds. GENEPT performance is highly variable. DGE is quite sensitive to sub-sampling on K562 genome-wide. 83±.00 0.49±.01 0.50±.01 0.78±.01 0.44±.02 0.49±.02 GENEPT 0.50±.13 0.39±.07 0.45±.06 0.51±.07 0.36±.11 0.40±.11 GEARS 0.51±.00 0.38±.00 0.45±.00 0.52±.01 0.24±.00 0.30±.00 PDG 0.49±.00 0.34±.01 0.41±.01 0.49±.01 0.29±.00 0.34±.00 CDN 0.93±.00 0.67±.01 0.73±.01 0.96±.01 0.83±.04 0.85±.03</figDesc><table><row><cell></cell><cell></cell><cell>K562 gw</cell><cell></cell><cell cols="2">K562 es</cell><cell></cell><cell>RPE1</cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>rank</cell><cell>ρ</cell><cell>r</cell><cell>rank</cell><cell>ρ</cell><cell>r</cell><cell>rank</cell><cell>ρ</cell><cell>r</cell></row><row><cell>LINEAR</cell><cell cols="9">0.50±.00 0.17±.01 0.20±.01 0.50±.01 0.25±.01 0.28±.01 0.48±.00 0.40±.01 0.49±.01</cell></row><row><cell>MLP</cell><cell cols="9">0.48±.00 0.17±.00 0.20±.00 0.48±.00 0.16±.00 0.19±.00 0.53±.00 0.30±.00 0.39±.00</cell></row><row><cell>DGE</cell><cell cols="9">0.72±.01 0.48±.02 0.52±.02 0.86±.00 0.59±.02 0.61±.02 0.74±.00 0.56±.00 0.64±.00</cell></row><row><cell cols="10">GENEPT 0.54±.09 0.26±.08 0.29±.08 0.50±.08 0.36±.10 0.39±.10 0.51±.10 0.43±.08 0.51±.07</cell></row><row><cell>GEARS</cell><cell cols="9">0.50±.01 0.19±.01 0.22±.01 0.51±.00 0.20±.01 0.23±.00 0.46±.00 0.33±.01 0.41±.02</cell></row><row><cell>PDG</cell><cell cols="9">0.49±.01 0.22±.00 0.25±.00 0.50±.01 0.28±.01 0.32±.01 0.49±.01 0.38±.01 0.47±.01</cell></row><row><cell>CDN</cell><cell cols="9">0.91±.01 0.71±.02 0.72±.02 0.95±.00 0.80±.03 0.81±.03 0.92±.00 0.65±.02 0.74±.01</cell></row><row><cell></cell><cell></cell><cell>HepG2</cell><cell></cell><cell>Jurkat</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>rank</cell><cell>ρ</cell><cell>r</cell><cell>rank</cell><cell>ρ</cell><cell>r</cell><cell></cell><cell></cell><cell></cell></row><row><cell>LINEAR</cell><cell cols="6">0.49±.00 0.34±.01 0.42±.01 0.50±.00 0.23±.01 0.27±.01</cell><cell></cell><cell></cell><cell></cell></row><row><cell>MLP</cell><cell cols="6">0.50±.00 0.34±.00 0.41±.00 0.47±.00 0.25±.00 0.31±.00</cell><cell></cell><cell></cell><cell></cell></row><row><cell>DGE</cell><cell>0.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>To quantify the uncertainty across draws of the test set (perturbations, instead of cells), we partition all perturbations uniformly into 5 sets for the unseen cell line setting on K562 genome-wide. The variation across test sets is minimal. = 353, ×5) 0.973 ±0.009 0.917 ±0.017 0.923 ±0.016 0.696 ±0.031 0.908 ±0.032 0.961 ±0.021</figDesc><table><row><cell>Test Split</cell><cell>rank</cell><cell>ρ</cell><cell>r</cell><cell>Recall@1</cell><cell>Recall@5</cell><cell>Recall@20</cell></row><row><cell>Original (n = 678)</cell><cell>0.974</cell><cell>0.915</cell><cell>0.921</cell><cell>0.699</cell><cell>0.900</cell><cell>0.957</cell></row><row><cell>New splits (n</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>CDN predicts trivial perturbations nearly perfectly (Table9).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This material is based upon work supported by the <rs type="funder">National Science Foundation Graduate Research Fellowship</rs> under Grant No. <rs type="grantNumber">1745302</rs>. We would like to acknowledge support from the <rs type="funder">NSF</rs> <rs type="grantName">Expeditions grant</rs> (award 1918839: Collaborative Research: Understanding the World Through Code), <rs type="person">Machine Learning</rs> for <rs type="institution">Pharmaceutical Discovery and Synthesis (MLPDS) consortium</rs>, and the <rs type="institution">Abdul Latif Jameel Clinic</rs> for Machine Learning in Health.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_EH463dE">
					<idno type="grant-number">1745302</idno>
				</org>
				<org type="funding" xml:id="_rGauVEs">
					<orgName type="grant-name">Expeditions grant</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. We found that if the model is allowed to see the class of soft intervention ("all mechanisms") during training, it can easily learn (overfit) the distribution shift perfectly, even though test datasets and graphs are novel. Thus, our main results in Table <ref type="table">3</ref> treat "scale" as an unseen soft intervention. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning-based predictions of gene perturbation effects do not yet outperform simple linear methods</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ahlmann-Eltze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Anders</surname></persName>
		</author>
		<idno type="DOI">10.1101/2024.09.16.613342</idno>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Gene ontology: tool for the unification of biology</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ashburner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Botstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dolinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Dwight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Eppig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Issel-Tarver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kasarskis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Matese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ringwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Genetics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="25" to="29" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Structure and evolution of transcriptional regulatory networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Luscombe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Aravind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Teichmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current opinion in structural biology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="283" to="291" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">AttentionPert: accurately modeling multiplexed genetic perturbations with multi-scale effects</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Ellington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btae244</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<idno type="ISSN">1367-4811</idno>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<date type="published" when="2024">i453-i461, 06 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">DCI: learning causal differences between gene regulatory networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Belyaeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Squires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Uhler</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btab167</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<idno type="ISSN">1367- 4803</idno>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="3067" to="3069" />
			<date type="published" when="2021">03 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the adaptive control of the false discovery rate in multiple testing with independent statistics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<idno type="ISSN">10769986</idno>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="60" to="83" />
			<date type="published" when="2000">2000. 19351054</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Noise in eukaryotic gene expression</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Cantor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">422</biblScope>
			<biblScope unit="issue">6932</biblScope>
			<biblScope unit="page" from="633" to="637" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Differentiable causal discovery from interventional data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Brouillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Drouin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="21865" to="21877" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning single-cell perturbation responses using neural optimal transport</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bunne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Del Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Levesque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-V</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pelkmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1759" to="1768" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Pharmacological inhibition of pi5p4kα/β disrupts cell energy metabolism and selectively kills p53-null tumor cells</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chandra Tjin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ellman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">21</biblScope>
			<date type="published" when="2021">2002486118. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">iSCAN: identifying causal mechanism shifts among nonlinear additive noise models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Aragam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="44671" to="44706" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simple but hard-to-beat foundation model for genes and cells built from ChatGPT</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><surname>Genept</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.10.16.562533</idno>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reprogramming cellular identity for regenerative medicine</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Daley</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cell.2012.02.031</idno>
		<ptr target="https://doi.org/10.1016/j.cell.2012.02.031" />
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<idno type="ISSN">0092-8674</idno>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1110" to="1122" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Optimal structure identification with greedy search</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="507" to="554" />
			<date type="published" when="2002-11">November 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Tabula Sapiens: A multiple-organ, single-cell transcriptomic atlas of humans</title>
		<author>
			<persName><forename type="first">*</forename><surname>Consortium</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Karkanias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krasnow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pisco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Quake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Salzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bulthaup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<biblScope unit="issue">6594</biblScope>
			<biblScope unit="page">4896</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Predicting gene targets of perturbations via networkbased filtering of mRNA expression compendia</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Cosgrove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Kolaczyk</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btn476</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<idno type="ISSN">1367-4803</idno>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="2482" to="2490" />
			<date type="published" when="2008-09">09 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">scGPT: toward building a foundation model for single-cell multi-omics using generative AI</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Maan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Chemogenomic profiling on a genome-wide scale using reverse-engineered gene networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Di Bernardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Chobot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Eastwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Wojtovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Schaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Biotechnology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="383" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Perturb-seq: Dissecting molecular circuits with scalable single-cell RNA profiling of pooled genetic screens</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dixit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Parnas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Fulco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jerby-Arnon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Marjanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dionne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Burks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raychowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Adamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Lander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Weissman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Regev</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cell.2016.11.038</idno>
		<ptr target="https://doi.org/10.1016/j.cell.2016.11.038" />
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<idno type="ISSN">0092-8674</idno>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1853" to="1866" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Combinatorial prediction of therapeutic perturbations using causally-inspired neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghassami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kiyavash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Herath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veselkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<idno type="DOI">10.1101/2024.01.03.573985</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
	<note>Multi-domain causal structure learning in linear systems</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Chromatin accessibility profiling by ATAC-seq</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Grandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Modi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kampman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Corces</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naturef Protocols</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1518" to="1552" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bayesian causal discovery with unknown interventions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hägele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rothfuss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lorch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Somnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><surname>Bacadi</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 26th International Conference on Artificial Intelligence and Statistics</title>
		<meeting>The 26th International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2023-04">Apr 2023</date>
			<biblScope unit="volume">206</biblScope>
			<biblScope unit="page" from="25" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Large-scale foundation model on single-cell transcriptomics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41592-024-02305-7</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Characterization and greedy learning of interventional markov equivalence classes of directed acyclic graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">79</biblScope>
			<biblScope unit="page" from="2409" to="2464" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Predicting cellular responses to novel drug perturbations at a single-cell resolution</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hetzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kilbertus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Theis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="26711" to="26722" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">BIBF 1120: triple angiokinase inhibitor with sustained receptor blockade and good antitumor efficacy</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hilberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krssak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kautschitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sommergruber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Tontsch-Grunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Garin-Chesa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zoephel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Quant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Research</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4774" to="4782" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Axial attention in multidimensional transformers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.12180</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Causal discovery from heterogeneous/nonstationary data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sanchez-Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">89</biblScope>
			<biblScope unit="page" from="1" to="53" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sequential optimal experimental design of perturbation screens guided by multi-modal priors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Hütter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Regev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Research in Computational Molecular Biology</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="17" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dual proteome-scale networks reveal cell-specific remodeling of the human interactome</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Huttlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Navarrete-Perea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Cannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Baltier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gebreab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Gygi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thornock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zarraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">184</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3022" to="3040" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Drug target prioritization by perturbed gene expression and network information</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Isik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Baldow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Cannistraci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">17417</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Causal discovery from soft interventions with unknown targets: Characterization and learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kocaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9551" to="9561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bilaniuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01075</idno>
		<title level="m">Learning neural causal models from unknown interventions</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to induce causal structure</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bornschein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A systematic comparison of computational methods for expression forecasting</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kernfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Weinstock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cahan</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.07.28.551039</idno>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">DrugBank 6.0: the DrugBank knowledgebase for 2024</title>
		<author>
			<persName><forename type="first">C</forename><surname>Knox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Strawbridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">D1</biblScope>
			<biblScope unit="page" from="1265" to="D1275" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Gradient-based neural DAG learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brouillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The connectivity map: Using gene-expression signatures to connect small molecules, genes, and disease</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Peck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Modell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Blat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wrobel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Brunet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hieronymus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Haggarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Clemons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Lander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Golub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page" from="1929" to="1935" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.04697</idno>
		<title level="m">Supervised whole DAG causal discovery</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Amortized inference for causal structure learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lorch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sussex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rothfuss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="13104" to="13118" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Causal modeling with stationary diffusions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lorch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 27th International Conference on Artificial Intelligence and Statistics</title>
		<meeting>The 27th International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<biblScope unit="volume">238</biblScope>
			<biblScope unit="page" from="2" to="04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">scGen predicts single-cell perturbation responses</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lotfollahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Theis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="715" to="721" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Predicting cellular responses to complex perturbations in high-throughput screens</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lotfollahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Klimovskaia Susmelj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>De Donno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hetzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">L</forename><surname>Ibarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Srivatsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naghipourfar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Daza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">11517. 2023</date>
			<publisher>Molecular Systems Biology</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Love</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Anders</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13059-014-0550-8</idno>
	</analytic>
	<monogr>
		<title level="j">Genome Biology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="550" to="550" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A reference map of the human binary protein interactome</title>
		<author>
			<persName><forename type="first">K</forename><surname>Luck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lambourne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Spirohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Begg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Brignall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cafarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Campos-Laborie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Charloteaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">580</biblScope>
			<biblScope unit="issue">7803</biblScope>
			<biblScope unit="page" from="402" to="408" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Current best practices in single-cell RNA-seq analysis: a tutorial</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Luecken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Theis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecular systems biology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">8746</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Identifying causal changes between linear structural equation models</title>
		<author>
			<persName><forename type="first">V</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghoshal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Honorio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 40th Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Enhancing generative perturbation models with LLMinformed gene embeddings</title>
		<author>
			<persName><forename type="first">K</forename><surname>Märtens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Donovan-Maiye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferkinghoff-Borg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR 2024 Workshop on Machine Learning for Genomics Explorations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Multiplex single-cell chemical genomics reveals the kinase dependence of the response to targeted therapy</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcfaline-Figueroa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Srivatsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gasperini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Domcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Regalado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lazarchuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Monnat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shendure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Trapnell</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.xgen.2023.100487</idno>
		<ptr target="https://doi.org/10.1016/j.xgen.2023.100487" />
	</analytic>
	<monogr>
		<title level="j">Cell Genomics</title>
		<idno type="ISSN">2666-979</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">100487</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Demystifying amortized causal discovery with transformers</title>
		<author>
			<persName><forename type="first">F</forename><surname>Montagna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cairney-Leeming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Locatello</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.16924</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Joint causal inference from multiple contexts</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Magliacane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Claassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<idno type="ISSN">1532-4435</idno>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020-01">Jan 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Transcriptome-wide characterization of genetic perturbations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nadig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Replogle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Pogson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mccarroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Weissman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename></persName>
		</author>
		<idno type="DOI">10.1101/2024.07.03.601903</idno>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Single-cell proteomic analysis of S. cerevisiae reveals the architecture of biological noise</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghaemmaghami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ihmels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Breslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Noble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Derisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Weissman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">441</biblScope>
			<biblScope unit="issue">7095</biblScope>
			<biblScope unit="page" from="840" to="846" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Inferring gene targets of drugs and chemical compounds from gene expression profiles</title>
		<author>
			<persName><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gunawan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="2120" to="2127" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Exploring genetic interaction manifolds constructed from rich single-cell phenotypes</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Horlbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Replogle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Weissman</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aax4438</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">365</biblScope>
			<biblScope unit="issue">6455</biblScope>
			<biblScope unit="page" from="786" to="793" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Causal discovery for observational sciences using supervised machine learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Ekstrøm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<idno type="DOI">10.6339/23-JDS1088</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Data Science</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="255" to="280" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Verkuil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sercu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rives</surname></persName>
		</author>
		<author>
			<persName><surname>Transformer</surname></persName>
		</author>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="8844" to="8856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName><surname>Pmlr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Mapping informationrich genotype-phenotype landscapes with genome-scale Perturb-seq</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Replogle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Pogson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Hussmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lenail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mascibroda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Adelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lithwick-Yanai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Iremadze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Oberstrass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lipson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Bonnar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Weissman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="2559" to="2575" />
			<date type="published" when="2022-07">Jul 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Predicting transcriptional outcomes of novel multigene perturbations with gears</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Roohani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Biotechnology</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">BioDiscoveryAgent: An AI agent for designing genetic perturbation experiments</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Roohani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Diffusion models for causal discovery via topological ordering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Q</forename><surname>O'neil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Tsaftaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Target identification and mechanism of action in chemical biology and drug discovery</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schenone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dancík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Clemons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Chemical Biology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="232" to="240" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Generative intervention models for causal perturbation modeling</title>
		<author>
			<persName><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lorch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kilbertus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2411.14003</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A linear non-gaussian acyclic model for causal discovery</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kerminen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">72</biblScope>
			<biblScope unit="page" from="2003" to="2030" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Causal inference in the presence of latent variables and selection bias</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence, UAI&apos;95</title>
		<meeting>the Eleventh Conference on Uncertainty in Artificial Intelligence, UAI&apos;95<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="499" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Causation, Prediction, and Search</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/1754.001.0001</idno>
		<ptr target="https://doi.org/10.7551/mitpress/1754.001.0001" />
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Permutation-based causal structure learning with unknown intervention targets</title>
		<author>
			<persName><forename type="first">C</forename><surname>Squires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Uhler</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<idno>PMLR</idno>
		<title level="m">Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</editor>
		<meeting>the 36th Conference on Uncertainty in Artificial Intelligence (UAI)</meeting>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="3" to="06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Massively multiplex chemical transcriptomics at single-cell resolution</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Srivatsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcfaline-Figueroa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pliner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Daza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Steemers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shendure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Trapnell</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aax6234</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="issue">6473</biblScope>
			<biblScope unit="page" from="45" to="51" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Roformer: Enhanced transformer with rotary position embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">568</biblScope>
			<biblScope unit="page">127063</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Test-time training with self-supervision for generalization under distribution shifts</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9229" to="9248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Transfer learning enables predictions in network biology</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Theodoris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">R</forename><surname>Al Sayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mantineo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Brydon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</editor>
		<meeting>the Seventeenth conference on Uncertainty in artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2001">2023. 2001</date>
			<biblScope unit="volume">618</biblScope>
			<biblScope unit="page" from="512" to="521" />
		</imprint>
	</monogr>
	<note>Causal discovery from changes</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Intervention target estimation in the presence of latent variables</title>
		<author>
			<persName><forename type="first">B</forename><surname>Varici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sattigeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tajer</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2013" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Direct estimation of differences in causal graphs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Squires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Belyaeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Uhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Individual comparisons by ranking methods</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wilcoxon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics Bulletin</title>
		<idno type="ISSN">00994987</idno>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="80" to="83" />
			<date type="published" when="1945">1945</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Scanpy: largescale single-cell gene expression data analysis</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Angerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Theis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Sample, estimate, aggregate: A recipe for causal discovery foundation models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Predicting cellular responses with variational causal inference and refined relational information</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Donno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Voloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Learning unknown intervention targets in structural causal models from heterogeneous data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salehkaleybar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kiyavash</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 27th International Conference on Artificial Intelligence and Statistics</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Mandt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</editor>
		<meeting>The 27th International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2024-05">May 2024</date>
			<biblScope unit="volume">238</biblScope>
			<biblScope unit="page" from="2" to="04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Are Transformers universal approximators of sequence-to-sequence functions?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<idno>CoRR, abs/1912.10077</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Active learning for optimal intervention design in causal models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cammarata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Squires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Sapsis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Uhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1066" to="1075" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Identifiability guarantees for Table 12: Intervention target prediction results on synthetic datasets, extended results. Uncertainty is standard deviation over 5 i.i.d. datasets. Metrics are averaged over all 3N perturbations for a given dataset (1-3 targets). CDN (full) denotes that we trained on all intervention mechanisms jointly</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Greenewald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Squires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Uhler</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
	<note>i.e. as in Table</note>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">N E Model</forename><surname>Linear</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Hard</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dcdi-G</surname></persName>
		</author>
		<idno>39±.04 .52±.04 .40±.04 .51±.04 .38±.03 .49±.02 .36±.03 .49±.03 .37±.03 .49±.03 .40±.04 .52±.06</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dcdi-Dsf</surname></persName>
		</author>
		<idno>36±.02 .51±.04 .40±.05 .53±.05 .37±.02 .50±.01 .38±.02 .49±.03 .37±.02 .50±.02 .37±.02 .48±.03</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title/>
		<author>
			<persName><surname>Bacadi-E</surname></persName>
		</author>
		<idno>.26±.03 .61±.05 .42±.13 .63±.11 .25±.03 .61±.05 .30±.05 .61±.04 .28±.04 .64±.06 .43±.12 .69±.09</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title/>
		<author>
			<persName><surname>Bacadi-M</surname></persName>
		</author>
		<idno>23±.01 .56±.03 .37±.11 .62±.11 .22±.02 .56±.04 .30±.05 .61±.04 .25±.03 .61±.05 .42±.11 .69±.09 DCI .55±.08 .79±.04 .50±.08 .70±.05 .47±.09 .71±.06 .41±.02 .67±.01 .59±.07 .80±.05 .51±.05 .76±.04</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title/>
		<author>
			<persName><surname>Cdn</surname></persName>
		</author>
		<idno>LG) .67±.09 .78±.07 .82±.05 .89±.05 .82±.08 .91±.05 .91±.04 .96±.02 .89±.05 .95±.03 .94±.03 .97±.02 CDN (full) .87±.01 .94±.01 .99±.01 1.0±.00 .82±.08 .91±.05 1.0±.00 1.0±.00 .95±.05 .98±.02 1.0±.00 1.0±.00</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dcdi-G</surname></persName>
		</author>
		<idno>42±.02 .54±.02 .40±.03 .51±.04 .40±.06 .53±.05 .39±.02 .51±.03 .37±.02 .50±.01 .35±.03 .49±.04</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dcdi-Dsf</surname></persName>
		</author>
		<idno>41±.03 .52±.03 .39±.05 .52±.05 .39±.02 .51±.02 .39±.03 .50±.05 .36±.03 .50±.05 .36±.03 .49±.03</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title/>
		<author>
			<persName><surname>Bacadi-E</surname></persName>
		</author>
		<idno>34±.04 .68±.03 .53±.08 .71±.04 .33±.03 .72±.04 .64±.07 .78±.05 .34±.05 .71±.04 .51±.07 .73±.04</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title/>
		<author>
			<persName><surname>Bacadi-M</surname></persName>
		</author>
		<idno>27±.02 .63±.03 .48±.09 .71±.04 .27±.04 .64±.08 .59±.09 .77±.06 .28±.03 .65±.05 .45±.08 .71±.05 DCI .59±.03 .78±.03 .57±.04 .77±.03 .68±.07 .82±.04 .65±.08 .84±.05 .70±.03 .84±.02 .66±.06 .83±.05</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title/>
		<author>
			<persName><surname>Cdn</surname></persName>
		</author>
		<idno>LG) .79±.06 .90±.04 .77±.04 .86±.02 .94±.01 .97±.01 .95±.05 .96±.04 .87±.02 .93±.02 .94±.02 .96±.01 CDN (full) .89±.03 .94±.02 .98±.02 .99±.01 .97±.01 .99±.00 1.0±.00 1.0±.00 .96±.03 .98±.01 .98±.02 .99±.01</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dcdi-G</surname></persName>
		</author>
		<idno>.24±.02 .49±.02 .22±.02 .49±.02 .22±.03 .50±.03 .22±.02 .49±.03 .22±.02 .50±.04 .22±.02 .50±.03</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dcdi-Dsf</surname></persName>
		</author>
		<idno>24±.02 .50±.02 .23±.02 .50±.03 .22±.01 .50±.02 .20±.01 .48±.02 .22±.02 .50±.04 .21±.02 .47±.03</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title/>
		<author>
			<persName><surname>Bacadi-E</surname></persName>
		</author>
		<idno>14±.01 .61±.03 .25±.10 .60±.06 .22±.06 .76±.06 .30±.06 .74±.05 .15±.02 .65±.03 .17±.05 .57±.05</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title/>
		<author>
			<persName><surname>Cdn</surname></persName>
		</author>
		<idno>LG) .50±.08 .73±.07 .87±.03 .96±.01 .76±.09 .90±.05 .92±.03 .98±.01 .71±.04 .89±.02 .93±.02 .99±.00 CDN (full) .75±.03 .91±.02 .99±.01 1.0±.00 .79±.08 .93±.04 1.0±.00 1.0±.00 .76±.05 .92±.02 1.0±.00 1.0±.00</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dcdi-G</surname></persName>
		</author>
		<idno>.22±.03 .49±.03 .21±.02 .48±.03 .22±.02 .49±.02 .22±.02 .50±.02 .21±.01 .48±.02 .23±.01 .51±.02</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dcdi-Dsf</surname></persName>
		</author>
		<idno>21±.02 .46±.03 .21±.02 .47±.02 .23±.02 .50±.03 .21±.01 .49±.03 .21±.02 .49±.02 .21±.03 .49±.02</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title/>
		<author>
			<persName><surname>Bacadi-E</surname></persName>
		</author>
		<idno>23±.05 .70±.04 .33±.10 .67±.04 .29±.08 .83±.04 .45±.18 .78±.06 .20±.05 .73±.05 .51±.13 .79±.04</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title/>
		<author>
			<persName><surname>Cdn</surname></persName>
		</author>
		<idno>LG) .69±.09 .85±.07 .80±.06 .94±.03 .84±.03 .94±.01 .95±.02 .99±.00 .84±.05 .93±.03 .91±.02 .98±.00 CDN (full) .89±.06 .97±.02 .99±.01 1.0±.00 .89±.03 .97±.01 1.0±.00 1.0±.00 .93±.03 .98±.01 1.0±.00 1.0±.00</idno>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
