<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Active learning of causal probability trees</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Tue</forename><surname>Herlau</surname></persName>
							<email>tuhe@dtu.dk</email>
							<affiliation key="aff0">
								<orgName type="institution">DTU Compute Technical University of Denmark</orgName>
								<address>
									<postCode>2800</postCode>
									<settlement>Lyngby</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Active learning of causal probability trees</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Causal learning</term>
					<term>Bayesian methods</term>
					<term>active learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The past two decades have seen a growing interest in combining causal information, commonly represented using causal graphs, with machine learning models. Probability trees provide a simple yet powerful alternative representation of causal information. They enable both computation of intervention and counterfactuals, and are strictly more general, since they allow context-dependent causal dependencies. Here we present a Bayesian method for learning probability trees from a combination of interventional and observational data. The method quantifies the expected information gain from an intervention, and selects the interventions with the largest gain. We demonstrate the efficiency of the method on simulated and real data. An effective method for learning probability trees on a limited interventional budget will greatly expand their applicability.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The past two decades have seen an increasing use of causal reasoning within fairness <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, AI safety <ref type="bibr" target="#b2">[3]</ref>, medicine <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, and reinforcement learning <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b8">[9]</ref>. This is thanks to its ability to model and predict relationships that are not statistical, such as the result of interventions and counterfactual queries, and the increasing understanding that these relationships are important in AI and machine learning <ref type="bibr" target="#b9">[10]</ref>. As a consequence, causal induction, that is learning causal relationships in the first place, can be expected to play an increasingly important role in machine learning <ref type="bibr" target="#b10">[11]</ref>.</p><p>Causal relationships are traditionally described using structural causal models (SCMs) <ref type="bibr" target="#b11">[12]</ref> or causal Bayesian networks (CBNs) <ref type="bibr" target="#b12">[13]</ref>, both of which represent the statistical independence properties implied by the causal model as a graph. Although versatile, both SCMs and CBNs are limited by the assumption that causal relationships between the observed variables must follow a partial order <ref type="bibr" target="#b13">[14]</ref>. This work considers a more general representation of causal relationships, namely a discrete probability tree <ref type="bibr" target="#b14">[15]</ref> (see fig. <ref type="figure" target="#fig_0">1</ref>). Probability trees are able to express context-specific dependencies (that is, situations where the causal order depends on the value of variables in the causal model, see fig. <ref type="figure" target="#fig_0">1 (c)</ref>)). Recent work has shown how interventions and counter-factual queries can be computed from a probability tree <ref type="bibr" target="#b15">[16]</ref>, but does not provide a method for learning probability trees in the first place.</p><p>In this paper, we consider the problem of efficiently learning causal relationships, as represented by probability trees, from a combination of observational and interventional data. Specif- ically, we consider an active-learning setting where an agent must decide which one of the available interventions should be attempted in each step, so as to learn which probability tree represents the generative process of the data. Although this problem has previously been studied for both SCMs and CBNs, this is, to our knowledge, the first work which considers the problem for probability trees.</p><formula xml:id="formula_0">(a) (b) (c)<label>(d)</label></formula><p>Our approach combines two ideas: First, we make use of the ability of probability trees to represent context-dependent relationships by representing the different causal hypothesis as sub-trees in a single large probability tree, thereby reducing the problem of causal induction to a simple inference problem in this larger probability tree, which can be solved using Bayes theorem; second, by combining the causal hypotheses in a single model, we can predict the information gain associated with each intervention in advance, and thus select the intervention which has the highest gain, thereby leading to a natural activelearning method for causal induction on probability trees <ref type="foot" target="#foot_0">1</ref> . a) Related work: Information theory has previously been used to quantify the causal effect between variables <ref type="bibr" target="#b16">[17]</ref>, or to specify circumstances where the causal orientation of categorical variables can be determined from observational data <ref type="bibr" target="#b17">[18]</ref>. Information geometry was used to infer causal orientation from observational data, using assumptions on generative mechanisms <ref type="bibr" target="#b18">[19]</ref>, however both settings are different from the Bayesian learning problem considered here. Most relevant to our work is the active-learning method discussed in <ref type="bibr" target="#b19">[20]</ref>, where interventions are selected by their expected reduction of a certain cost-function, defined using the entropy of the edgedistribution. The method is used as a point of comparison in section III. Context-dependent relationships occur naturally in a variety of places, such as probabilistic programming <ref type="bibr" target="#b20">[21]</ref>, or as an additional node type in factor graphs <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. METHODS</head><p>A probability tree describes the generative process of the data and is easiest defined recursively. We will be concerned with m discrete stochastic variables X = (X 1 , . . . , X m ), so that X ∈ V is the range of values of X . A probability tree describes the generative process of X as a path through the tree, starting at the root, where at each node of the tree one or more variables in X is assigned its value. Suppose n ∈ T is a node in the tree. We represent n as a tuple n = (u, S, θ (n) ) where u is a unique integer identifying the node, S is a list of statements specifying which variables are assigned at n (in all our examples, just a single statement of the form X = x ) and θ</p><formula xml:id="formula_1">(n) 1 , . . . , θ (n) |ch(n)| ∈ [0, 1]</formula><p>is the transition probability from n to each of its children ch(n). For completeness, the root will be associated with the dummy variable O = 1, which can only take a single value.</p><p>A total realization is a path τ = (n 1 , . . . , n l ) from the root to a leaf in the tree. We assume that the tree is constructed such that the statements associated with the nodes on any path form a partition of all variables X 1 , . . . , X m ; that is, when traversing from the root to the leaf, all variables are assigned a value once. The probability of a realization is simply the product of the probabilities θ (n) i of each node encountered along the path. Examples of Bayesian networks and their corresponding probability trees are given in fig. <ref type="figure" target="#fig_0">1 (a-b</ref>).</p><p>An event, such as X k = x k or {X 1 = 3, X 5 = 7}, is identified with the set of all total realizations which traverses nodes with statements X k = x k . The probability of an event is the sum of probability of the total realizations, thereby defining the joint distribution P (X 1 , . . . , X m ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Intervention</head><p>Interventions in probability trees are defined following <ref type="bibr" target="#b15">[16]</ref>: An intervention X = x in a probability tree simply means that during the generative process, at the node where the value X is decided, the path is forced to choose the branch corresponding to X = x with probability 1. Formally, an intervention on T can be defined as a new tree T identical to T , except for all nodes n = (v, S, θ (n) ) which have a child in which X is assigned a value, we change θ (n) so if the child Fig. <ref type="figure">2:</ref> A single probability tree with a context-dependent variable G can represent the S = 2 causal hypothesis for the variables X, Y, Z. Depending on the value of G, the causal ordering of X, Y, Z will differ, as illustrated by the two CBNs.</p><p>has an assignment X = x it is selected with probability 0, and if the child has a statement of the form X = x it is selected with probability 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Causal hypothesis</head><p>An appealing feature of probability trees is that selecting between different causal hypotheses, i.e. the causal orderings of the variables X 1 , . . . , X m , can be treated as a contextdependent causal problem. Suppose T 1 , . . . , T S are trees of the form described earlier, which denote different causal hypotheses for the variables X 1 , . . . , X m and we let G = 1, . . . , S be a stochastic variable denoting each hypothesis. We can then represent the problem using a new tree, where the root has S children, each of the form n k = (k, G = k, θ (n k ) ), and corresponding to one of the trees T k . An illustration is given in fig. <ref type="figure">2</ref> using S = 2 causal hypothesis over three variables X, Y, Z, where the plates indicate the two different causal hypotheses shown as CBNs. A total realization in the new tree T then corresponds both to selecting a causal orientation, G = k, and a realization of the variables X 1 , . . . , X m according to T k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Bayesian learning</head><p>We will be concerned with the case where interventions occur on single variables, i.e. are of the form J = {X = x}, and the empty intervention J = ∅ will correspond to passively observing the system. The available data D is therefore a sequence of interventions and the realized values of the m variables D = (X (1) , J (1) ), . . . , (X (N ) , J (N ) ).</p><p>Assuming a uniform prior over the S causal hypothesis,</p><formula xml:id="formula_2">θ (n O ) = P (G = k) = 1</formula><p>S , the probability of a given causal order is immediately available using Bayes theorem</p><formula xml:id="formula_3">P (G = k|D, θ) = P (D|G = k, θ) S k =1 P (D|G = k , θ)<label>(1)</label></formula><p>where θ = (θ (n) ) n∈T k are the split probabilities. To compute the marginal likelihoods, note that each observation</p><formula xml:id="formula_4">X (i) = (X (i) 1 , . . . , X<label>(i)</label></formula><p>m ) in the data set corresponds to a total realization of each of the trees T k , and the probability can therefore be obtained by simply using the generative procedure outlined earlier. Specifically, for a node n ∈ T k , we let N j|n be the total number of realizations passing through the node n and selecting child j ∈ ch(n), but not counting those of the total realizations, where the choice j was forced by the intervention (see section II-A). The probability of the data conditional on tree T k is therefore:</p><formula xml:id="formula_5">P (D|G = k, θ) = n∈T k   j∈ch(n) θ (n) j N j|n   .<label>(2)</label></formula><p>Assuming each</p><formula xml:id="formula_6">θ (n) ∼ Dir(α (n) 1 |ch(n)|×1|</formula><p>) has a Dirichlet prior with concentration parameter α (n) , the marginal likelihood is obtained by integrating eq. ( <ref type="formula" target="#formula_5">2</ref>):</p><formula xml:id="formula_7">P (D|G = k) = n∈T k dθ (n) P (θ (n) ))P (D|G = k, θ) = n∈T k j∈ch(n) Γ(N j|n + α (n) )) Γ( j∈ch(n) N j|n + |ch(n)|α (n) ) .<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Priors</head><p>For most choices of concentration parameters α (n) , the probability tree model will learn a causal orientation from observational data alone, and therefore create a bias towards a particular causal orientation prior to performing interventions. To prevent this, the concentration parameters should be chosen so that:</p><formula xml:id="formula_8">1 S = P (G = k|D observational ).<label>(4)</label></formula><p>To ensure this, suffice it to select the concentration parameter in a node n to be proportional to the number of descendants of n divided by the number of immediate children, i.e.</p><formula xml:id="formula_9">α (n) = |{descendants of n}| |ch(n)| α<label>(5)</label></formula><p>for a common factor α &gt; 0. This is easily seen by noting that most factors in eq. ( <ref type="formula" target="#formula_7">3</ref>) cancel, and the marginal likelihood simply reduces to a product over the leaves:</p><formula xml:id="formula_10">P (D observational |G = k) = n∈T k , j is a leaf Γ(N j|n + α) Γ(N + |T |α) .</formula><p>Thus, the probability of a given causal hypothesis T k computed using eq. ( <ref type="formula" target="#formula_3">1</ref>) will depend on the data D and a single parameter α &gt; 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Active learning</head><p>The amount of evidence, measured in nats, in favor of a hypothesis h relative to the alternative is log P (h|D) log P (¬h|D) <ref type="bibr" target="#b22">[23]</ref>. A natural criterion by which to choose between interventions is how much they are expected to change the evidence in favor of the true causal hypothesis. Since the agent only has access to limited data, we distinguish between the agent's estimate of the probability assignment, indicated by the symbol Q, and the true probability assignment indicated by P .</p><p>Suppose the agent performs an intervention do(X = x ) = x and observes the realization x of X. We define the information gained in favor of a causal hypothesis G = k from observing the effect of x , in the context of an existing data set D, as the increase in evidence in favor of k:</p><formula xml:id="formula_11">I(k|D, (x, x )) = log Q(k|D, (x, x )) S k =k Q(k |D, (x, x )) -log Q(k|D) S k =g Q(k |D) .<label>(6)</label></formula><p>In the above, the symbol Q(k|D) refers to the agent's belief as computed using eq. ( <ref type="formula" target="#formula_3">1</ref>) and eq. ( <ref type="formula" target="#formula_7">3</ref>). Note that this quantity reflects the agent's internal belief about the truth of a hypothesis G = k.</p><p>Assume that the (true) causal orientation is among the S causal hypotheses. The chance k is the (true) causal hypothesis given the data is P (G = k|D, θ), where importantly we use P to signify this quantity is computed using the true model of the system (i.e, the likelihood is computed using eq. ( <ref type="formula" target="#formula_5">2</ref>) with the true values of θ (n) ).</p><p>Thus, the information gain in favor of the true causal hypothesis is given as the expected gain in information for a given hypothesis k, computed using eq. ( <ref type="formula" target="#formula_11">6</ref>), weighted by the chance that k is actually the true hypothesis P (G = k|D, θ). Specifically, we define the actual information gain as:</p><formula xml:id="formula_12">∆ Actual x = E k|D,x |g,D,x [I(k|D, (x, x )] = S k=1</formula><p>P (k|D,θ)</p><p>x P (x|k,x )I(k|D, (x, x )). <ref type="bibr" target="#b6">(7)</ref> This quantity represents the actual information gain experienced by the agent under the model assumptions, and is what we ideally would wish to compute. However, since it depends the true probabilities P , we instead define the expected gain as:</p><formula xml:id="formula_13">∆ Expected x = S k=1 Q(k|D) x Q(x|k, x , D)I(k|D, (x, x )) (8)</formula><p>which can be computed using known quantities prior to interventions. The method therefore simply ranks the possible interventions using eq. ( <ref type="formula">8</ref>) and selects the intervention with the highest expected gain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. The two-variable case</head><p>It is instructive to consider the simple case of m = 2 variables X 1 and X 2 , and where the data D only consists of observational data. We consider the case of two causal orientations, k = 1 corresponding to X 1 → X 2 and k = 2 corresponding to X 2 → X 1 , and without loss of generality assume an intervention x1 is performed on X 1 = x 1 and we observe X 2 = x 2 . In this case, it follows from symmetry that I(k = 1|D, (x, x )) = -I(k = 2|D, (x, x )) and eq. ( <ref type="formula" target="#formula_11">6</ref>) becomes</p><formula xml:id="formula_14">I(k = 1|D, (x 2 , x1 )) = log Q(k = 1|D, (x 2 , x1 )) Q(k = 2|D, (x 2 , x1 ) = Q(D, (x 2 , x1 )|k = 1) Q(D, (x 2 , x1 )|k = 2) .<label>(9)</label></formula><p>Using eq. ( <ref type="formula" target="#formula_7">3</ref>), and noting that the single intervention only changes the pseudo-counts N j|n by a single value, the expression simply reduces to the α-robust estimate of the probabilities:</p><formula xml:id="formula_15">I(k = 1|D, (x 2 , x1 )) = log Q(x 2 |x 1 , D) Q(x 2 |D)<label>(10)</label></formula><p>where:</p><formula xml:id="formula_16">Q(x 2 |x 1 , D) = n(x 1 , x 2 ) + α x2∈V2 n(x 1 , x 2 ) + |V 1 |α , Q(x 2 |D) = x1∈V1 n(x 1 , x 2 ) + |V 1 |α N + |V 1 ||V 2 |α .</formula><p>In this expression, n(x 1 , x 2 ) is the number of observations in D where</p><formula xml:id="formula_17">X 1 = x 1 and X 2 = x 2 .</formula><p>Similarly, the outer expectations in eq. ( <ref type="formula">7</ref>) over x = (x 1 , x 2 ) are easily expressed using the conditional/marginal probabilities, for instance:</p><formula xml:id="formula_18">P (x|k = 1, x1 ) = P (X 2 = x 2 |X 1 = x1 )δ x1,x1 ,<label>(11a)</label></formula><formula xml:id="formula_19">P (x|k = 2, x1 ) = P (X 2 = x 2 )δ x1,x1 .<label>(11b)</label></formula><p>The actual expected gain of information in favor of the true causal direction, when an intervention x1 is performed on</p><formula xml:id="formula_20">X 1 = x 1 , is therefore ∆ Actual x1 = 1 2 x2 [P (x 2 |x 1 ) -P (x 2 )] log Q(x 2 |x 1 , D) Q(x 2 |D)<label>(12)</label></formula><p>The expression for the expected gain is even simpler, and can be expressed using the Jeffrey divergence <ref type="bibr" target="#b23">[24]</ref> between the conditional and marginal distributions D J (p; q) = x (p(x)q(x)) log p(x) q(x) :</p><formula xml:id="formula_21">∆ Expected x1 = D J (Q(X 2 |x 1 , D); Q(X 2 |D)).<label>(13)</label></formula><p>The intuition behind this expression is that for two variables, the suitability of an intervention is assessed based on how much the conditional distribution differs from the marginal, as measured by the Jeffrey divergence which corresponds to the case where an intervention may give a particularly surprising result. The Jeffrey divergence may become very large when the probabilities are close to zero, however, this simply corresponds to the case where certain interventions can lead to configurations which are highly atypical for the system, and therefore are highly informative with respect to the causal orientation.</p><p>This does present a potential problem when the exact probability P in eq. ( <ref type="formula" target="#formula_20">12</ref>) is replaced by the finite-sample approximations in eq. ( <ref type="formula" target="#formula_21">13</ref>). This means that the regularization parameter α can be expected to play an important role. However, in our experiments, we found that values between α = 1 or α = 2 worked well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTS</head><p>The most relevant work to compare against is the active learning method for causal Bayesian networks proposed by <ref type="bibr" target="#b19">[20]</ref> (Entropy in the following). The method uses a costfunction based approach to rank interventions based on their expected outcome, and the cost-function is constructed as follows: For each possible edge i, j in the Bayesian network, there are three possible outcomes (X i → X j , X j → X i and no edge between i, j), which can be considered the outcome of a categorical distribution. Given the current data set, consisting of observations and interventions, the method considers the entropy of these categorical distributions, and constructs the cost-function as the expected value of the sum of all such entropies. The main difference in our approach is that we consider the full structure of the causal network, and instead of the entropy we consider the evidence in favor of a given causal orientation.</p><p>We note that the authors propose a sampling-based approach to generate candidate Bayesian networks, however, we will consider a direct implementation of the cost function as this is feasible in our experiments. The probabilities used in computing the entropies are obtained using the same method (i.e., using α-soft estimates) as our method. Note that this method is only applicable to probability trees which can be represented as CBNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Information gain with two variables</head><p>Continuing the example with two variables, consider the case where the variables are perfectly correlated and can take K values</p><formula xml:id="formula_22">|V i | = K. Assume that the joint distribution is symmetric, p(x 1 , x 2 ) = ρ K δ x1,x2 + 1-ρ K(K-1) (1 -δ x1,x2</formula><p>), and that the observational data is proportional to p, i.e. n(x 1 , x 2 ) = N p(x 1 , x 2 ), the actual information gain from any intervention x1 will be given by eq. ( <ref type="formula">7</ref>). In the case K = 2 it is:</p><formula xml:id="formula_23">∆ x = 1 2 (ρ - 1 2 ) log N ρ + 2α N (1 -ρ) + 2α . (<label>14</label></formula><formula xml:id="formula_24">)</formula><p>Thus, in the case of perfectly correlated variables, the actual gain in information from the first intervention will be proportional to log N and independent of the intervention. We simulated the setup in an active learning setting up to 20 interventions, where actions were selected using either the actual gain, expected gain or the Entropy method described previously using K = 4 and ρ = 0.9. The simulations were hot-started using N = 300 non-interventional observations and results were averaged over T = 100 random restarts. The error bars indicate the standard deviation of the mean. The result can be seen in fig. <ref type="figure" target="#fig_1">3 (a)</ref>. All methods performed well, since the symmetry of the problem makes all possible interventions roughly equally informative.</p><p>A more interesting problem is obtained when the joint distribution is asymmetric. Specifically, we consider the case K = 4, where the true causal orientation is X 1 → X 2 , and where p(1, x 2 ) = p(4, 1) = ρ 5 , and otherwise p(x 1 , x 2 ) = The intervention X1 = 1 is predicted to offer more information than the other across a varying number of observations N . In all cases, the expected gain eq. ( <ref type="formula">8</ref>) is close to the idealized exact gain eq. ( <ref type="formula">7</ref>). The result is born out when using the active-learning method in (c), where the proposed active-learning scheme uses far fewer interventions to determine the true causal orientation.  . Both the actual and expected gain of all possible interventions are shown in fig. <ref type="figure" target="#fig_1">3</ref>, here averaged over T = 100 random restarts, and it is clearly seen that the intervention X 1 = x 1 is optimal. It is notable that when probabilities are estimated from relatively few observations, the expected and actual gain still tend to coincide. When the problem is considered in an active learning setting similar to fig. <ref type="figure" target="#fig_1">3</ref>, we see that selecting interventions using the expected gain leads to much quicker convergence than random interventions. Somewhat surprisingly, the entropy-based method performs on par with random intervention selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The Pairs database</head><p>The Pairs database <ref type="bibr" target="#b24">[25]</ref> consists of 108 small data sets intended to provide realistic examples of real-world cause and effect pairs. We limit ourselves to the case S = 2 and select the variables as the first columns marked as cause and effect. The data set is pre-processed by binning into K = 5 equiprobable bins, and the results are reported using the weighting procedure (to account for some data sets being similar) as suggested by the authors <ref type="bibr" target="#b24">[25]</ref>.</p><p>The methods for selecting interventions were evaluated by first generating a varying number N of observational datapoints, and then for each data set, performing 40 interventions. In all cases we used α = 1. The result were averaged over T = 20 random restarts.</p><p>As an evaluation metric, we considered the average time until the method was at least 95% certain about the correct causal orientation (the method defaults to 40 interventions in case the method did not obtain certainty about the true causal orientation). The results can be found in table I. As expected, all methods perform better with more observational data. The overall trend is that the actual gain, computed using eq. ( <ref type="formula">7</ref>), outperforms the expected gain eq. ( <ref type="formula" target="#formula_21">13</ref>). This is to be expected, since the actual gain is more informed about the problem, but in both cases the proposed method learns the causal orientation far quicker than random interventions, or the method of <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Information gain with three variables</head><p>To test the method in a more challenging setting, which can nevertheless still be represented as a CBN, we consider the case of m = 3 variables, X 1 ,X 2 ,X 3 , and where the actual causal relationship is X 1 → X 2 , X 3 and (X 1 , X 2 ) → X 3 . We consider the problem of determining this causal relationships among all graphs obtained by permuting the node labels, i.e. there are S = 6 possible graphs. This can be represented as a probability tree similar to fig. <ref type="figure">2</ref>, but where the root has six children.</p><p>Each variable could take |V i | = 6 values, and to avoid the case where the variables are highly correlated (and all interventions have roughly the same value), we selected the joint distribution by selecting an arbitrary sparsity pattern p(x 1 , x 2 , x 3 ) ∈ {0, 1} and normalizing p(</p><formula xml:id="formula_25">x 1 , x 2 , x 3 ) = ρ M p(x 1 , x 2 , x 3 ) + 1-ρ 6 3 -M (1 -p(x 1 , x 2 , x 3 )) where M = x1,x2,x3 p(x 1 , x 2 , x 3 ).</formula><p>Details can be found in the supplementary code, and the qualitative outcome is not sensitive to this choice. Next, we simulated the methods using similar settings as in the two-variable case and using ρ = 0.9. The results can be found in fig. <ref type="figure" target="#fig_2">4</ref> and N = 300. Since the probabilities are estimated using relatively less data, the difference between the expected and actual gain is relatively larger. However, selecting interventions according to the expected gain performs far better than random intervention selection. The results are averaged over T = 15 random restarts.</p><p>Surprisingly, the entropy method performs as well than random intervention selection. We attribute this to our use of a deterministic version of the objective function, and believe that the method would perform better with increasing randomization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Context-dependent causality</head><p>Finally, we consider a context-dependent causal problem which cannot be represented using a CBN. We considered m = 3 variables each capable of taking |V i | = 3 values. We considered three causal hypotheses: In the first, the nodes were ordered as in the previous example, i.e.</p><p>1 → X 2 , X 3 ) (X , X 2 ) → X 3 . In the other hypotheses, we let X 1 determine the causal order of X 2 X , so that in the first case X 1 = 1 the causal order between X 2 and X 3 were reversed (similar to the example in fig. <ref type="figure" target="#fig_0">1  (d)</ref>), and in the other case the causal re-ordering of X 2 and X 3 occurs when X 1 = 2. The reasoning behind including two context-dependent cases is to ensure that the method does not simply distinguish between effect vs. no context-dependent effect. We consider the correlated case, p(x 1 , x 2 , x 3 ) = δ x1,x2 δ x2,x3 to avoid unintended bias.</p><p>The methods were run using a similar setup as before, using N = 400 observations, ρ = 0.9, and were averaged over T = 400 random restarts, see fig. <ref type="figure" target="#fig_3">5</ref>. We included both the case where the true causal graph had a context-dependent causal effect, and the case where it did not. The performance of the method was similar in the two cases, and shows that true causal orientation can be determined to a given degree of certainty using roughly half as many samples, compared to the case where random interventions are used. We do not include results from the entropy method as it is not applicable to context-dependent effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DISCUSSION AND CONCLUSION</head><p>Probability trees provide a conceptually simple representation of causal relationships, which is nevertheless strictly more general than SCMs and CBNs by allowing context-dependent causal relationships. This flexibility redefines the problem of causal induction, giving it a self-contained formulation as an inference problem in a single probability tree. Despite this, probability trees have seen very limited use as a means to represent causal relationships up to this point <ref type="bibr" target="#b15">[16]</ref>. A likely reason is that, in contrast to CBNs and SCMs, the independence properties of the variables are not visually apparent from the tree, and although the effect of interventions and counterfactuals can be predicted efficiently from the tree algorithmically, probability trees do not provide convenient tools, such as the do-calculus <ref type="bibr" target="#b11">[12]</ref>, which makes them more difficult to use. However, in machine learning there is an increasing interest in learning causal relationships automatically from data <ref type="bibr" target="#b10">[11]</ref>, so these drawbacks are less pronounced. This also means that methods for finding the correct tree structure for a given problem can be expected to become a key challenge in furthering the use of probability trees.</p><p>In this paper, we have presented the first such method, to our knowledge. Our approach formulates the problem of causal induction as an inference problem in a single probability tree. We can then define the potential gain in information given the current data using Bayes theorem, and select interventions which are associated with the greatest expected gain. We evaluated the method both by comparing it to a random intervention selection and a deterministic implementation of the cost function from <ref type="bibr" target="#b19">[20]</ref>. In our experiments, the proposed method is able to find the correct causal ordering using fewer samples than the alternative methods, both in the case of relationships that could be represented using CBNs and in context-dependent relationships.</p><p>The computational cost is determined by the joint sum over all causal hypotheses and potential outcomes of an intervention. For larger problems, this cost can quickly become prohibitively large, but this can be overcome by only considering hypotheses which are close to the current most likely hypothesis (as in <ref type="bibr" target="#b19">[20]</ref>), and by replacing the sum over potential outcomes with a finite sample.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: (a) Example of a probability tree for two binary variables X, Y , each path from the root O to a leaf denotes an assignment of the variables and (b) the corresponding CBN. (c-d) Probability trees can model context-dependent causal dependency, in this case the value of X determines the causal orientation of Y and Z.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: (a) Probability of determining the true causal orientation in the perfectly correlated two-variable problem described in section III-A. The methods are evaluated using a fixed number of observations N and varying number of interventions. The different interventions provide nearly the same information gain. (b) Illustration of the expected/actual gain in information for different interventions in the asymmetric two-variable problem.The intervention X1 = 1 is predicted to offer more information than the other across a varying number of observations N . In all cases, the expected gain eq. (8) is close to the idealized exact gain eq. (7). The result is born out when using the active-learning method in (c), where the proposed active-learning scheme uses far fewer interventions to determine the true causal orientation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Fig.4: Result of selecting between the six possible fully-connected CBNs defined on a three-variable problem where each variable can take 6 values using a similar setup as considered in fig.3 (a,b). In this case, our method (expected gain) outperforms random selection, and the entropy-based cost function tends to get stuck on sub-optimal interventions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Fig.5: A context-dependent intervention-selection problem defined over three variables. The two conditions correspond to the case where the actual graph is either a CBN or contains a context-dependent causal relation. Our method uses about half as many samples as random intervention selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>Interventions required in the Pairs data set.</figDesc><table><row><cell>1-ρ</cell></row><row><cell>11</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Code to reproduce all plots in this paper can be found at http://github. com/anonymized for review</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Counterfactual fairness: Unidentification, bound and algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/199</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/199" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1438" to="1444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Path-specific counterfactual fairness</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7801" to="7808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Agent incentives: A causal perspective</title>
		<author>
			<persName><forename type="first">T</forename><surname>Everitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Langlois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence,(AAAI-21). Virtual. Forthcoming</title>
		<meeting>the Thirty-Fifth AAAI Conference on Artificial Intelligence,(AAAI-21). Virtual. Forthcoming</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improving the accuracy of medical diagnosis with causal machine learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Richens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Johri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Causal inference and counterfactual prediction in machine learning for actionable healthcare</title>
		<author>
			<persName><forename type="first">M</forename><surname>Prosperi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sperrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">E</forename><surname>Buchan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="369" to="375" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bandits with unobserved confounders: A causal approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Forney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1342" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mitrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08162</idno>
		<title level="m">Causal reasoning from meta-reinforcement learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Causal confusion in imitation learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>De Haan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="11" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interventional few-shot learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The book of why: the new science of cause and effect. Basic books</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mackenzie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Causality for machine learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10500</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Models, reasoning and inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>CambridgeUniversityPress</publisher>
			<biblScope unit="volume">19</biblScope>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<title level="m">Causation, prediction, and search</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Beware of the dag</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dawid</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v6/dawid10a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Causality: Objectives and Assessment at NIPS 2008, ser. Proceedings of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</editor>
		<meeting>Workshop on Causality: Objectives and Assessment at NIPS 2008, ser. Machine Learning Research<address><addrLine>Whistler, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2010-12-12">12 Dec 2010</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="59" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The Art of Causal Conjecture, ser. Artificial Management</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shafer</surname></persName>
		</author>
		<ptr target="https://books.google.dk/books?id=sY7os7OCykUC" />
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Algorithms for causal reasoning in probability trees</title>
		<author>
			<persName><forename type="first">T</forename><surname>Genewein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mcgrath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Delétang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Ortega</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12237</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Information theoretic causal effect quantification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wieczorek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">975</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Entropic causal inference: Identifiability and finite sample results</title>
		<author>
			<persName><forename type="first">S</forename><surname>Compton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kocaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Greenewald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.03501</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Information-geometric approach to inferring causal directions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lemeire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zscheischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Daniušis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Steudel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Active learning for structure in bayesian networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on artificial intelligence</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="863" to="869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Probabilistic programming</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vajda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Causality with gates</title>
		<author>
			<persName><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1314" to="1322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Probability theory: The logic of science</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Jaynes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The theory of probability</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jeffreys</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>OUP</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distinguishing cause from effect using observational data: methods and benchmarks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zscheischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1103" to="1204" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
