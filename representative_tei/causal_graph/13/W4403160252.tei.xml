<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Context-Aware Reasoning On Parametric Knowledge for Inferring Causal Variables</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-09-25">25 Sep 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ivaxi</forename><surname>Sheth</surname></persName>
							<email>ivaxi.sheth@cispa.de</email>
							<affiliation key="aff0">
								<orgName type="department">CISPA Helmholtz Center for Information Security</orgName>
								<address>
									<addrLine>2 Microsoft</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sahar</forename><surname>Abdelnabi</surname></persName>
							<email>saabdelnabi@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">CISPA Helmholtz Center for Information Security</orgName>
								<address>
									<addrLine>2 Microsoft</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
							<email>fritz@cispa.de</email>
							<affiliation key="aff0">
								<orgName type="department">CISPA Helmholtz Center for Information Security</orgName>
								<address>
									<addrLine>2 Microsoft</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Context-Aware Reasoning On Parametric Knowledge for Inferring Causal Variables</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-09-25">25 Sep 2025</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2409.02604v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Scientific discovery catalyzes human intellectual advances, driven by the cycle of hypothesis generation, experimental design, evaluation, and assumption refinement. Central to this process is causal inference, uncovering the mechanisms behind observed phenomena. While randomized experiments provide strong inferences, they are often infeasible due to ethical or practical constraints. However, observational studies are prone to confounding or mediating biases. While crucial, identifying such backdoor paths is expensive and heavily depends on scientists' domain knowledge to generate hypotheses. We introduce a novel benchmark where the objective is to complete a partial causal graph. We design a benchmark with varying difficulty levels with over 4000 queries. We show the strong ability of LLMs to hypothesize the backdoor variables between a cause and its effect. Unlike simple knowledge memorization of fixed associations, our task requires the LLM to reason according to the context of the entire graph 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Scientific discovery has been key to humankind's advances. It is a dynamic process revolving around inquiry and refinement. Scientists adhere to a process that involves formulating a hypothesis and then collecting pertinent data <ref type="bibr" target="#b61">(Wang et al., 2023)</ref>. They then draw inferences from these experiments, modify the hypothesis, formulate sub-questions, and repeat the process until the research question is answered <ref type="bibr" target="#b29">(Kıcıman et al., 2023)</ref>.</p><p>Central to scientific discovery is formulating hypotheses and identifying relevant variables that drive the underlying causal mechanisms of observed phenomena <ref type="bibr" target="#b8">(Bunge, 2017)</ref>. Randomized controlled trials are the gold standard for establishing causal relationships, but they are often in- feasible due to ethical, financial, or logistical constraints <ref type="bibr">(Nichol et al., 2010)</ref>. In such cases, researchers rely on observational data, where a key challenge lies not only in analyzing relationships but in determining which variables should be observed and included in the analysis, particularly confounders or mediators that influence causal mechanisms underlying the outcomes (Ananth and Schisterman, 2017; <ref type="bibr" target="#b20">Gupta et al., 2021)</ref>.</p><p>With the recent advancement of Large Language Models (LLMs), there has been a growing interest in using them for scientific discovery (AI4Science and Quantum, 2023; <ref type="bibr" target="#b35">Lu et al., 2024;</ref><ref type="bibr" target="#b10">Cory-Wright et al., 2024)</ref>. LLMs have demonstrated strong performance in internalizing knowledge <ref type="bibr" target="#b53">(Sun et al., 2024;</ref><ref type="bibr" target="#b66">Yu et al., 2024)</ref> and reasoning-based tasks <ref type="bibr" target="#b58">(Valmeekam et al., 2023;</ref><ref type="bibr" target="#b18">Guo et al., 2025)</ref>, including causal discovery, where they infer pairwise causal relationships based on variable semantics <ref type="bibr" target="#b29">(Kıcıman et al., 2023;</ref><ref type="bibr" target="#b34">Long et al., 2023;</ref><ref type="bibr" target="#b4">Ban et al., 2023;</ref><ref type="bibr">Vashishtha et al., 2023;</ref><ref type="bibr" target="#b11">Darvariu et al., 2024;</ref><ref type="bibr" target="#b7">Binkyte et al., 2025)</ref>.</p><p>Scientific reasoning is fundamentally context-driven; unlike simple factual retrieval, it requires adapting hypotheses based on new evidence and integrating knowledge across varying subpopulations. While recent work has explored the use of LLMs for causal discovery <ref type="bibr" target="#b29">(Kıcıman et al., 2023;</ref><ref type="bibr" target="#b34">Long et al., 2023;</ref><ref type="bibr" target="#b11">Darvariu et al., 2024;</ref><ref type="bibr" target="#b4">Ban et al., 2023;</ref><ref type="bibr">Vashishtha et al., 2023)</ref>, much of it assumes a fixed set of variables and focuses on identifying relationships among them. However, a critical and underexplored aspect is determining which variables should be considered in the first place. This demands flexible, context-sensitive reasoning to identify missing causal factors.</p><p>In our paper, we use the term reasoning operationally to describe the model's ability to generate hypotheses or identify variables that complete partial causal graphs. Our usage follows previous work by <ref type="bibr" target="#b29">Kıcıman et al. (2023)</ref> in causal discovery and LLM research, where "reasoning" often refers to generating plausible hypotheses or prioritizing potential candidates given partial structural information, rather than strict deductive logic.</p><p>To address this gap, we propose a novel task: given a partial causal graph with missing variables, the LLM is prompted to hypothesize what those variables might be, using the structure and known nodes as context. By systematically omitting different variables, we generate diverse test cases to evaluate the robustness of model reasoning. We further decompose the benchmark into subtasks, starting from baseline variable identification to more realistic, open-ended settings where multiple unobserved mediators exist between known treatments and outcomes.</p><p>Our task mirrors real-world scientific workflows, where identifying missing variables-especially confounders and mediators is essential for valid causal inference. This typically demands costly, interdisciplinary effort. LLMs, trained on diverse knowledge sources, offer a scalable alternative. For example, in a stroke drug study, an LLM might suggest socioeconomic status as an unmeasured confounder. While recent works advocate using LLMs as co-pilots for causal tasks <ref type="bibr" target="#b40">(Petersen et al., 2024;</ref><ref type="bibr" target="#b2">Alaa et al., 2024)</ref>, systematic evaluations are lacking. Our benchmark addresses this gap by assessing LLMs' ability to infer missing causal variables across domains.</p><p>Our main contributions are: 1) We propose and formalize the novel task of LLM-assisted causal variable inference. 2) We propose a benchmark for inferring missing variables across diverse domains of causal graphs. 3) We design experimental tasks with different difficulty levels and knowledge assumptions, such as open-world and closed-world settings, the number of missing variables, etc. 4) Our benchmark allows for both grounded evaluations and a reproducible framework to benchmark LLMs' capabilities in hypothesis generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>LLMs and Causality. Our work builds on the foundational framework of causality by <ref type="bibr" target="#b38">Pearl (2009)</ref>. Prior studies have explored extracting causal relationships from text <ref type="bibr" target="#b16">(Girju et al., 2002;</ref><ref type="bibr" target="#b21">Hassanzadeh et al., 2020;</ref><ref type="bibr">Tan et al., 2023;</ref><ref type="bibr" target="#b12">Dhawan et al., 2024)</ref> and using LLMs for causal reasoning <ref type="bibr" target="#b29">(Kıcıman et al., 2023)</ref>, including commonsense <ref type="bibr" target="#b14">(Frohberg and Binder, 2021;</ref><ref type="bibr" target="#b51">Singh et al., 2021)</ref> and temporal causality <ref type="bibr" target="#b69">(Zhang et al., 2020</ref><ref type="bibr" target="#b68">(Zhang et al., , 2022))</ref>. Recent efforts prompt LLMs with variable names to discover causal structures <ref type="bibr" target="#b29">(Kıcıman et al., 2023;</ref><ref type="bibr" target="#b34">Long et al., 2023;</ref><ref type="bibr" target="#b11">Darvariu et al., 2024;</ref><ref type="bibr" target="#b4">Ban et al., 2023;</ref><ref type="bibr">Vashishtha et al., 2023)</ref>. Others integrate LLMs with deep structural causal models <ref type="bibr" target="#b0">(Abdulaal et al., 2024;</ref><ref type="bibr" target="#b67">Yu et al., 2019)</ref>, or focus on graph formatting <ref type="bibr" target="#b50">(Sheth et al., 2024)</ref>, query design <ref type="bibr">(Jiralerspong et al., 2024)</ref>, and causal inference <ref type="bibr">(Jin et al., 2023)</ref>. In contrast to prior work, we use LLMs to infer missing variables before data collection and evaluation, leveraging their pre-trained knowledge for this novel hypothesizing task.</p><p>LLMs and Hypothesis Generation. Existing work tested hypothesis generation with LLMs in reasoning tasks or free-form scientific hypotheses from background knowledge provided in the context <ref type="bibr" target="#b15">(Gendron et al., 2023;</ref><ref type="bibr" target="#b44">Qi et al., 2023;</ref><ref type="bibr">Xu et al., 2023a,b;</ref><ref type="bibr" target="#b45">Qiu et al., 2024;</ref><ref type="bibr" target="#b35">Lu et al., 2024)</ref>. In contrast, we consider the structured task of causal hypothesis generation, where the ground-truth variables are known and can be used for evaluation.</p><p>Context-aware reasoning has been explored through prompt engineering <ref type="bibr" target="#b13">(Dutta et al., 2024;</ref><ref type="bibr" target="#b71">Zhou et al., 2023;</ref><ref type="bibr" target="#b46">Ranaldi and Zanzotto, 2023)</ref>, premise ordering manipulation <ref type="bibr" target="#b9">(Chen et al., 2024)</ref>, diagnostic analyses <ref type="bibr" target="#b42">(Prabhakar et al., 2024)</ref>, and compositional reasoning evaluations <ref type="bibr" target="#b43">(Press et al., 2022;</ref><ref type="bibr" target="#b48">Saparov et al., 2024)</ref>. Unlike premise-based or linguistic evaluations, our setup requires reasoning over causal graph topology, using contextual cues by varying assumptions.</p><p>A causal relationship can be modeled via a Directed Acyclic Graph (DAG). A causal DAG represents relationships between a set of N variables defined by V = {v 1 , ..., v N }. The variables are encoded in a graph G = (V, E) where E is a set of directed edges between the nodes ∈ V such that no cycle is formed. Mathematically, it can be expressed as:</p><formula xml:id="formula_0">G = (V, E), E = {e i,j | v i , v j ∈ V, i ̸ = j and v i → v j }</formula><p>Each edge e i,j denotes causal relationship and the influence from v i to v j , v i e i,j --→ v j . We define d(v) as the degree of a node v, representing the total number of edges connected to v. d in (v) is the in-degree, representing the number of incoming edges to v. d out (v) is the out-degree, representing the number of outgoing edges from v. Source has no incoming edges; d in (v) = 0. Sink has no outgoing edges. Sinks are d out (v) = 0. Treatment is characterized by nodes that are being intervened upon. Outcome is characterized by nodes that are observed for interventions from the treatments. Mediator has both incoming and outgoing edges (d in (v) &gt; 0 and d out (v) &gt; 0) as intermediaries in the pathways between treatment and outcome. Confounder influences both treatment and outcome, exhibiting edges directed towards the treatment and outcome nodes (d out (v) ≥ 2). Hence v is a confounder if it is a parent of both v i and v j . Collider has two edges meeting, and d in (v) &gt; 1. I.e., v is a collider if it is a child of both v i and v j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Inferring Causal Variables</head><p>Motivated by the challenge of discovering variables that block backdoor paths to ensure unbiased causal inference <ref type="bibr" target="#b17">(Glymour et al., 2019)</ref>, in this work, we leverage language models to infer missing variables in a causal DAG. We assume that a part of the graph is already known, and the aim is to find additional variables that can be incorporated into the existing DAG to enhance the underlying causal mechanism.</p><p>Formally, we assume a partially known causal DAG, G * = (V * , E), where V * ⊆ V. The objective is to identify the set of missing variables V * = V \ V missing thereby expanding G * to G. This implies that all causal relationships (edges) among variables in V * are known and correctly represented in G * ; i.e., E is fully specified. Here, "missing" variables are not latent or hidden by measurement error but known unknowns within the causal graph reflective of the LLM's perspective.</p><p>To systematically assess LLMs' ability to infer missing causal variables, we construct a multi-stage benchmark with increasing levels of complexity. We begin with a controlled setting, where the model is provided with a partial causal DAG and a set of multiple-choice options to identify missing variables. Then, the task becomes open-ended, where LLMs hypothesize missing variables, simulating an open-world paradigm. Additionally, as the task escalates, we introduce more complexity by omitting additional nodes, challenging the model to hypothesize multiple missing variables.</p><p>We evaluate the reasoning capability of LLMs through prompting. We represent the graph G * using a prompt template P LLM (•) which enables LLMs to parse causal relationships in the DAG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task 1: Out-of-Context Identification</head><p>Motivation. To assess whether LLMs can infer missing variables in causal graphs, we begin with a controlled multiple-choice setting that serves as a baseline. This task isolates the core challenge: identifying a single missing variable from a causal DAG. By restricting the search space to a fixed set of options, including the correct variable and out-of-context distractors, we evaluate whether the model can distinguish the variable that meaningfully completes the causal structure.</p><p>The partial DAG G * is created by removing one variable, denoted as v x , from the original DAG G. The role of the LLM is to select a variable from the multiple choices, MCQ vx , that can be used to complete the graph. The out-of-context distractors are unrelated to the causal domain of the given DAG, chosen to minimize any contextual overlap with the true missing variable. Let v *</p><p>x represent the variable selected by the LLM to complete G * .</p><formula xml:id="formula_1">v * x = P LLM (G * , MCQ vx ) ∀v x ∈ V 4.2 Task 2: In-Context Identification</formula><p>Motivation. In real-world domains like healthcare and finance, missing or unobserved variables often challenge causal inference <ref type="bibr" target="#b22">(Hughes et al., 2019;</ref><ref type="bibr" target="#b55">Tian and Pearl, 2012)</ref>. This task simulates such ambiguity by requiring LLMs to identify a relevant missing variable when presented with multiple plausible options, going beyond the baseline. Here, instead of removing one node from the ground truth DAG G, two nodes, v x 1 and v x 2 , are now removed to create the partial graph, G * .</p><formula xml:id="formula_2">G * = G \ {v x 1 , v x 2 } for v x 1 , v x 2 ∈ V</formula><p>The MCQA paradigm provides multiple choices, including the missing variables v x 1 and v x 2 . The task for the LLM here is to select the correct variable v x 1 only, given an in-context choice v x 2 and out-of-context choices. The in-context variables are plausible within the same causal graph, allowing the LLM to use DAG-defined context inference to distinguish the relevant from the irrelevant options. We ensure v x 1 and v x 2 are not directly connected i.e., neither is a parent of the other. Given a partial DAG G * = G \ v x 1 , . . . , v x M , the task (illustrated in Figure <ref type="figure" target="#fig_2">3b</ref>) involves generating a sequence of missing mediators M = v m 1 , v m 2 , ..., v m H that plausibly connect a treatment variable v t to an outcome variable v y .</p><formula xml:id="formula_3">v * x 1 = P LLM (G * , MCQ vx 1 ,vx 2 ) ∀ v x 1 , v x 2 ∈ V and v x 1 ̸ → v x 2 , v x 2 ̸ → v x 1 4.3</formula><p>At each iteration i, , the LLM is prompted with the current partial graph and returns a hypothesis for the next mediator. This process continues until all of the mediators are inferred.</p><formula xml:id="formula_4">v * m i = P LLM (G * ∪ {v * m 1 , ..., v * m i-1 }),</formula><p>for i = 1, ..., H. The sequence of mediators M = {v m 1 , v m 2 , ..., v m H } is chosen at random. To assess how mediator order affects performance, we draw on mediation analysis concepts <ref type="bibr" target="#b39">(Pearl, 2014)</ref>, specifically the Natural Direct Effect (NDE)-the treatment's effect not mediated by a variable-and the Natural Indirect Effect (NIE)-the portion mediated by it (see Appendix A.4). We propose the Mediation Influence Score (MIS) to quantify each mediator's impact between a treatment and outcome. Defined as the ratio of NIE to NDE, MIS is a scale-free, positive measure of a mediator's relative contribution:</p><formula xml:id="formula_5">MIS (v m i ) = NIE(v m i ) NDE(v m i ) for i = 1, ..., H.</formula><p>This metric quantifies the relative importance of the indirect effect (through the mediator) compared to the direct impact. Mediators are then ranked and prioritized based on their MIS scores, with higher scores indicating a stronger mediation effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation and Results</head><p>Graphs. We evaluate a variety of causal graphs spanning diverse domains. We use the semi-  synthetic DAGs from BNLearn repository -Cancer (Korb and Nicholson, 2010), Survey <ref type="bibr" target="#b49">(Scutari and Denis, 2021)</ref>, Asia <ref type="bibr" target="#b33">(Lauritzen and</ref><ref type="bibr">Spiegelhalter, 1988), Child (Spiegelhalter, 1992)</ref>, Insurance <ref type="bibr" target="#b6">(Binder et al., 1997), and</ref><ref type="bibr">Alarm (Beinlich et al., 1989)</ref>. We also evaluate our approach on a realistic Alzheimer's Disease graph <ref type="bibr" target="#b0">(Abdulaal et al., 2024)</ref> Models. We evaluate our setups across different open-source and closed models. The models we use are GPT-4o <ref type="bibr">(Hurst et al., 2024)</ref>, <ref type="bibr">GPT-4 (OpenAI, 2023)</ref>, LLama3-chat-8b <ref type="bibr" target="#b56">(Touvron et al., 2023</ref><ref type="bibr">), Mistral-7B-Instruct-v0.2 (Jiang et al., 2023)</ref>, <ref type="bibr">Mixtral-7B-Instruct-v0.1 (Jiang et al., 2024</ref><ref type="bibr">), Zephyr-7b-Beta (Tunstall et al., 2023)</ref> and Neuralchat-7b-v3-1 <ref type="bibr" target="#b24">(Intel, 2023)</ref>.</p><p>Prompt. We used the textual prompting strategy from <ref type="bibr" target="#b50">Sheth et al. (2024)</ref> after performing experiments on some of the proposed encoding methods (see Appendix B.10). Implementation details are in Appendix A and prompts in Appendix F. Our code will be available after anonymity period.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Task 1</head><p>Setup. The input to the LLM consists of a partial DAG G * , and multiple choices including the correct missing variable v x and several out-of-context distractors. This task includes 120 queries. We define accuracy to assess the LLM's v x prediction.</p><formula xml:id="formula_6">Accuracy = 1 N N i=1 1(v * x = v i x )</formula><p>Results. In Figure <ref type="figure" target="#fig_4">4a</ref>, we report the accuracy of different LLMs in identifying the missing variable. GPT-4, followed closely by Mixtral and GPT-4o, consistently performs well, achieving perfect accuracy on most of the graphs. Other models, including Mistral-7b, Llama-7b, Neural, and Zephyr-7b, have varying degrees of success. Insurance remains the most challenging graph, potentially due to the high number of edges present in the DAG. All models significantly outperform the random baseline. However, we conjecture that the high performance could be partially attributed to the simplicity of the task. The models might be using the context of the graph domain to exclude unrelated distractors rather than engaging in deeper causal reasoning among multiple plausible choices. To investigate this, we introduce an in-domain choice among the multiple choices in the next experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Task 2</head><p>Setup. This is a more challenging task where the partial graph has two missing nodes. In addition to out-of-context distractors and the ground-truth variable, v x 1 , the multiple-choice set includes the second missing variable v x 2 as an in-context distractor. This setup tests the model's ability to reason over indirect causal relations contextually to identify the correct variable. This task results in over 3800 queries. To evaluate performance, we use two metrics: Accuracy and False Node Accu-  racy (FNA). FNA captures how often the model incorrectly selects the in-context distractor instead:</p><formula xml:id="formula_7">FNA ↓= 1 N N i=1 1(v * x 1 = v x 2 )</formula><p>Results. In Figure <ref type="figure" target="#fig_4">4b</ref>, we report Accuracy and False Node Accuracy (FNA) across graphs. Accuracy reflects how often the correct missing variable is chosen, while FNA measures how often the model incorrectly selects the in-context distractor-another missing variable included to test deeper causal reasoning. Since there are 5 options, random accuracy is 0.2, and FNA under random guessing would be around 0.2 as well. GPT-4 and GPT-4o achieve high accuracy and low FNA, showing that they reliably distinguish the true missing node from both distractors and the in-context variable. GPT-4o slightly outperforms GPT-4 on several graphs. Open models like Mistral, Zephyr, and Mixtral show more variability, performing well on simpler graphs like Cancer but struggling on complex ones like Alarm. While most models exceed random chance, higher FNA in some cases highlights a tendency to confuse plausible but incorrect variables, emphasizing the difficulty of reasoning over multiple missing nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Task 3</head><p>Setup. In real-world settings, partial causal graphs provided by domain experts often lack ground truth and multiple choices. Hypotheses may vary depending on context, data, or domain knowledge. To simulate this, we prompt the LLM to generate. The LLM generates k = 5 suggestions for the missing node v x . This task has 120 queries. We compare suggestions to the ground truth, recognizing that real-world cases often lack a single correct answer.</p><p>Since traditional metrics may miss contextual nuances, we use two evaluations: semantic similarity and LLM-as-Judge (see Appendix B.4).</p><p>1. Semantic Similarity. We compute the cosine similarity between the embeddings of the predictions, v * x 1:5 , and the ground truth v x , averaging the highest similarity scores across all nodes v x ∈ V (see Appendix A.5 for details).</p><p>2. LLM-Judge. Inspired by <ref type="bibr">Zheng et al. (2023)</ref>, this two-step metric assesses contextual semantic similarity beyond exact matches. First, LLM ranks suggestions v * x 1:5 based on how well they fit the partial graph. Second, it rates the best match on a 1-10 scale. Scores are averaged across nodes for an overall measure (see Appendix A.6).</p><p>Results. We report models' performances using both semantic similarity and LLM-Judge metrics in Table <ref type="table" target="#tab_3">2</ref>. For brevity, we provided the variances in Appendix B.1. We provide a detailed analysis of each metric across different types of node variables (defined in Section 3). We evaluate sources, sinks, colliders, and mediators for each of the partial causal graphs. The results, fine-grained by node type, are given in Figure <ref type="figure" target="#fig_5">5</ref>, which shows each model's average performance across graphs with a detailed performance per graph in Figure <ref type="figure">8</ref>. GPT-4, GPT-4o and Mixtral generally achieve higher semantic similarity and LLM-as-Judge scores across most graphs (Figure <ref type="figure">8</ref>). We observe that semantic similarity is a stricter metric than LLM-as-judge since it cannot encode contextual information about the causal DAG (see example in Table <ref type="table" target="#tab_2">10</ref>). Despite different scales, both metrics seem to be fairly correlated. Figure <ref type="figure" target="#fig_5">5</ref>, shows that models display stronger performance for colliders and mediators In Figure <ref type="figure">6a</ref>, model performance improves with more suggestions (k). Figure <ref type="figure">6b</ref> shows that accuracy also correlates with node degree (d in + d out ), indicating that more context aids prediction. Overall, LLMs perform well on many nodes, especially mediators and colliders, making them promising tools for real-world causal discovery where treatments and outcomes are known. (b) LLM-as-Judge. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Hypothesizing Confounder</head><p>Backdoor paths are alternative causal pathways that confound the estimation of causal effects and introduce bias if not accounted for. Hence, hypothesizing and controlling for confounders is an important task in causal inference <ref type="bibr" target="#b41">(Pourhoseingholi et al., 2012)</ref>. We extract confounder subgraphs from <ref type="bibr" target="#b47">(Sachs et al., 2005)</ref>, Alarm, and Insurance graphs. From Table <ref type="table" target="#tab_6">3</ref> and Appendix D, we find  that while LLMs accurately hypothesize some confounders, models struggle with domain-specific graphs like SACHS. Larger models like GPT-4o don't necessarily always perform best, underscoring the need for diverse benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Task 4</head><p>Setup. We adopt an iterative approach for hypothesizing mediators, allowing the model to refine predictions step-by-step-unlike global prediction, which yields lower performance (Appendix B.6). This aligns with Chain-of-Thought <ref type="bibr" target="#b62">(Wei et al., 2022)</ref> reasoning and improves accuracy. There are more than 140 queries for this task, ranging from 1-10 missing mediators. For unordered evaluation, mediators are given in random order and scored via average semantic similarity. For ordered evaluation, we rank mediators using the Mediation Influence Score (MIS) and compare model performance when prompted in ascending vs. descending MIS order. We define a metric, ∆, to capture this difference. Positive ∆ values suggest that prompting the LLM based on the MIS metric leads to higher semantic similarity between the mediator hypotheses and the ground truth variables. In summary, we observe that LLMs can be effective in iteratively hypothesizing multiple mediators in a DAG, and if present, some domain knowledge about the significance of the mediator can boost the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Memorization</head><p>A concern in evaluating pretrained LLMs on knowledge-intensive tasks is contamination i.e., memorization of evaluation data from training. This is especially relevant for public datasets like those in the BNLearn repository, which may have appeared in training corpora.</p><p>To assess this, we tested whether models could recall the number and names of variables from each of the eight datasets in our benchmark. This included well-known BNLearn graphs (e.g., Asia, Child, Insurance, Alarm) and less common ones (e.g., Law, Alzheimer's). We prompted each model to report node counts and variable names, including explicit references to BNLearn for relevant datasets, to detect signs of memorization.</p><p>In Table <ref type="table">5</ref>, except GPT family models, which exhibited partial recall for some widely known BN-Learn datasets, we observe that full reconstruction</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Cancer Survey Asia Law Alz Child Insurance Alarm</p><formula xml:id="formula_8">Zephyr ✗ ✗ ✗ ✗ ✗ ✗ ✗ ✗ Mixtral ✗ ✗ 0.71 ✗ ✗ ✗ ✗ 0.13 Neural ✗ ✗ ✗ ✗ ✗ ✗ ✗ ✗ LLama ✗ ✗ ✓ ✗ ✗ ✗ ✗ ✗ Mistral ✓ ✗ ✗ ✗ ✗ ✗ ✗ ✗ GPT-4 ✓ ✓ ✓ ✗ 0.55 ✓ ✓ ✓ GPT-4o ✓ ✓ ✓ ✗ 0.45 ✓ ✓ ✓</formula><p>Table <ref type="table">5</ref>: Memorization analysis: Whether the model could correctly recall node information from the dataset (✓), failed to recall (✗), or proportion of nodes recalled.</p><p>of the graphs' details was rare. This recall was consistently absent for lesser-known datasets such as Law and Alzheimer's, which are less likely to have appeared during pretraining. While these findings cannot eliminate memorization with certainty, they suggest that it is not predominant for most models.</p><p>To further test GPT-4, we explicitly mentioned the graph provenance (e.g., "This graph is from BNLearn") during "Task 3", shown in Table <ref type="table" target="#tab_11">17</ref>. GPT-4's performance improved across most graphs. This suggests that its initial responses were not purely reciting these graphs but potentially based on broader parametric knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Discussion</head><p>The results show that LLMs effectively hypothesize missing variables, especially mediators, though performance varies with task complexity. Simple tasks, like identifying missing variables from controlled options, had high success rates.</p><p>Performance differences across domains may stem from biases in LLM training data, affecting parametric memory. For instance, confounder hypothesis quality varied across graphs, with domainspecific gaps lowering accuracy, like in the Sachs graph (Appendix D).</p><p>We explored fine-tuning and few-shot prompting to enhance performance, but small DAG sizes limited the graph size, yielding mixed results (Appendix C.1). While fine-tuning may help specialization, it can also reduce reliance on general parametric knowledge <ref type="bibr" target="#b65">(Yang et al., 2024)</ref>. Future work could explore domain-specific fine-tuning.</p><p>Though model training data is undisclosed, we used a recently released graph <ref type="bibr" target="#b0">(Abdulaal et al., 2024)</ref> that postdates cut-off dates (at the time of performing experiments). Our novel task and verbalization approach further reduce the risks of memorization. Table <ref type="table" target="#tab_3">2</ref> confirms LLMs generate novel hypotheses rather than retrieving memorized patterns, with no evidence of direct graph reconstruction. Our work relies on reasoning via parametric knowledge rather than explicit memorization.</p><p>Our setup assumes known edges among missing variables for controlled evaluation, which future work can extend. We envision this as a human-LLM collaboration under expert supervision, as LLMs cannot self-assess plausibility or confidence <ref type="bibr" target="#b72">(Zhou et al., 2024)</ref>. Future work could also refine filtering mechanisms and improve performance on source and sink nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Human Evaluation</head><p>To complement our automatic evaluation metrics, we conducted a small-scale human evaluation on three representative graphs (Cancer, Survey, and Asia). Two independent annotators (a CS PhD student and a CS PhD graduate) rated the quality of LLM-suggested variables. We then measured the agreement between human judgments, semantic similarity, and our LLM-judge using Spearman correlation. Table <ref type="table">6</ref> indicates strong correlations among human annotators and between human judgments and the automatic metrics. In particular, the LLM-judge shows high alignment with both annotators, suggesting that it serves as a reliable proxy for human evaluation. This supports the use of our automatic evaluation framework as a scalable approach for benchmarking causal reasoning tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Most causality research focuses on identifying relationships from observed data, while hypothesizing which variables to observe remains largely reliant on expert knowledge. We propose using LLMs as proxies for this step and introduce a novel task: hypothesizing missing variables in causal graphs. We formalize this with a benchmark that spans varying levels of difficulty and ground-truth knowledge. Our results highlight LLMs' strengths in inferring backdoor paths, including colliders, confounders, and mediators, which often lead to biased causal inference when unaccounted for. Our work LLMs can serve as useful tools for early-stage hypothesis generation, supporting scientists in formulating plausible causal variables before data collection. By evaluating models across different graph completeness, open-and closed-world settings, we highlight their potential and limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Limitations</head><p>While this work presents promising advancements in leveraging LLMs for hypothesizing missing variables in causal graphs, there are some limitations to consider. Our evaluation relies on established DAGs and comparisons with known ground truth, limiting assessment in scenarios without a defined baseline. Future work can include validation using human in loop evaluation. Future work can also integrate our work into the full causal discovery pipeline with statistical data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Ethics and Risk</head><p>Our work leverages LLMs for hypothesis generation in causal discovery but comes with ethical risks. Biases from training data may lead to skewed hypotheses, and over-reliance on AI without expert validation could result in misleading conclusions. While we design our task to minimize memorization, risks of data leakage remain. Additionally, LLM performance varies across domains, making errors in high-stakes fields like healthcare particularly concerning. To mitigate these risks, we emphasize human-AI collaboration, transparency in model limitations, and improved evaluation frameworks for reliability. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Acknowledgements</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Implementation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Datasets</head><p>We use 7 real-world based graphs. These graphs span different domain knowledge topics. These graphs have ground truth graphs along with their observational data. The simplest graph used is the cancer graph with 4 edges and 5 node variables. In addition to the semi-synthetic graphs from the BNLearn library, we also evaluate our approach on a realistic Alzheimer's Disease graph <ref type="bibr" target="#b0">(Abdulaal et al., 2024)</ref>, which was developed by five domain experts. Given that each expert created a different causal graph, the final causal DAG comprises only those edges that were agreed upon by consensus.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Reproducibility</head><p>For reproducibility, we used temperature 0 and top-p value as 1 across all of the models. We also mentioned the snapshot of the model used. We have also included the prompts and examples below. Our code will be released upon acceptance. The graphs are under CC BY-SA 3.0, which allows us to freely modify the graphs for benchmarking. Our benchmark will be released under the CC BY-SA License. GPT-4o, GPT-4 was accessed via API. The rest of the models were run on 1 A100 GPU. Since we used an off-the-shelf LLM, there was no training to be performed. Since many of the models were run by API, it is difficult to calculate the entire computation, however, all of the experiments for each model took ≈ 6 hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Controlled Variable Identification</head><p>For variable identification, we generate multiple choices that remain consistent across all missing nodes and all of the graphs. The words were randomly chosen to be far enough from the nodes. The options chosen were weather, book sales, and movie ratings. We wanted to make sure that the options were not from one specific domain, such that the LLM could do the process of elimination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Causal effect</head><p>Average Treatment Effect. Average Treatment Effect (ATE) quantifies the expected change in the outcome v y caused by the unit change of the treatment v t . ATE is a part of the causal do-calculus introduced by <ref type="bibr" target="#b38">(Pearl, 2009)</ref>. We consider binary causal DAGs, i.e., each variable can either take 0 or 1 as values.</p><p>ATE</p><formula xml:id="formula_9">= E[v y |do(v t = 1)] -E[v y |do(v t = 0)]</formula><p>where the do(•) operator, represents an intervention. The E[v y |do(v t = 1)] represents the expected value of the outcome variable v y when we intervene to set the treatment variable v t to 1 (i.e., apply the treatment), and E[v y |do(v t = 0)] represents the expected value of v y when we set v t to 0 (i.e., do not apply the treatment).</p><p>Mediation Analysis. Mediation analysis is implemented to quantify the effect of a treatment on the outcome via a third variable, the mediator. The total mediation effect can be decomposed into the Natural Direct Effect (NDE) and the Natural Indirect Effect (NIE). The Natural Direct Effect (NDE) is the effect of the treatment on the outcome variable when not mediated by the mediator variable. The Natural Indirect Effect (NIE) is the effect of the treatment variable on the outcome variable when mediated by the mediator variable.</p><formula xml:id="formula_10">NDE = E[v t=1 , v m=0 -v t=0 , v m=0 ]</formula><p>Here, NDE is calculated by comparing the expected outcome when the treatment variable is set to 1 and the mediator is fixed at the level it would take under the control treatment v t = 0, with the expected outcome when both the treatment and the mediator are set to the control level.</p><formula xml:id="formula_11">NIE = E[v t=0 , v m=1 -v t=0 , v m=0 ]</formula><p>Here, NIE is calculated by comparing the expected outcome when the treatment variable is set to 1 and the mediator is allowed to change as it would under the treatment, with the expected outcome when the treatment variable is set to 1 but the mediator is fixed at the control level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Semantic Similarity</head><p>Given the task of hypothesizing missing nodes in a partial graph G * in the absence of multiple-choices, we evaluate the semantic similarity between the model's predictions and the ground truth node variable.</p><p>We leverage an open model namely 'all-mpnet-base-v2' to transform the textual representations of the model's predictions and the ground truth into high-dimensional vector space embeddings. Post transforming textual representations into embeddings and normalizing them, we calculate the cosine similarity. Scores closer to 1 indicate a high semantic similarity, suggesting the model's predictions align well with the ground truth. This metric gives a score of similarity without the contextual knowledge of the causal graph. We perform our experiments to consider every node of the ground truth as a missing node iteratively. For all the suggestions for a node variable, we calculate the semantic similarity. The average similarity reported is the highest semantic similarity for each of the variable suggestions.</p><p>Algorithm 1 Evaluating Semantic Similarity for Hypothesized Missing Nodes for each prediction p in predictions do 9: </p><formula xml:id="formula_12">embedding GT ← Embed(v GT ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 LLM-as-Judge</head><p>To capture the domain knowledge of the expert that selects the most relevant causal variable, we use LLM-as-Judge as a proxy expert. This also allows for evaluation based on contextual DAG knowledge as well. Given the impressive results of GPT-4 in <ref type="bibr">(Zheng et al., 2023)</ref>, we use GPT-4 as a judge for all of the experiments.</p><p>Algorithm 2 Evaluating Model Suggestions with LLM as Judge Prompt LLM to rate suggestion on a scale of 1 to 10  Table <ref type="table" target="#tab_2">10</ref>: Example comparing the semantic similarity and LLM-as-Judge metrics. Dyspnea is a medical term for shortness of breath. In this example, the contextual information, beyond exact matching, is better captured by LLM-as-Judge.</p><p>Shortcomings of LLM-as-judge. LLM-as-judge uses GPT-4 as a judge model which could be biased towards some data. Since the training graphs are not public for this model, it would be hard to judge how these biases might affect the final score. Hence for robust evaluation we also evaluate using the semantic similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.7 Iteratively Hypothesizing in Open World</head><p>For each order, the algorithm prompts the LLM to generate mediator suggestions, selects the suggestion with the highest semantic similarity to the context, and iteratively updates the partial graph with these mediators. ∆, quantifies the impact of mediator ordering by comparing the average highest semantic similarity scores obtained from both descending and ascending orders. This methodical evaluation sheds light on how the sequence in which mediators are considered might affect the LLM's ability to generate contextually relevant and accurate predictions.</p><p>Algorithm 3 Random Order Mediator Hypothesis  </p><formula xml:id="formula_13">for each mediator v m i in M do 6: Calculate NIE(v m i ) and NDE(v m i ) 7: MIS(v m i ) ← NIE(vm i ) NDE(vm i ) 8: Append MIS(v m i ) to MISList</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Variances</head><p>For brevity we didnt add variance in the main text, the following results have variances: Table <ref type="table" target="#tab_3">12</ref>: Sim: semantic similarity for iteratively hypothesizing the mediator nodes when prompted with random order. ∆ measures the change in the prediction of each model according to the MIS. Figure <ref type="figure">6</ref>: L: Plot of semantic similarity with an increasing number of suggestions for GPT-4 on the Alarm graph. R: Plot of semantic similarity against the total number of incoming and outgoing edges for GPT-4 on the Alarm graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Breaking down the performance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Effect of context</head><p>We observed notable differences in the accuracy of LLM predictions for missing nodes within causal graphs when context was provided versus when it was absent. Specifically, the inclusion of contextual information about the causal graph significantly enhanced the LMs' ability to generate accurate and relevant predictions. In realistic settings, when this setup is being used by a scientist, they would provide the context of the task along with the partial graph. When context was not provided, the models often struggled to identify the most appropriate variables, leading to a decrease in prediction accuracy, especially for smaller models. Unsurprisingly, providing context was more important for smaller graphs than larger graphs. LLMs were able to understand the context of the graph via multiple other nodes in the graph for larger graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cancer</head><formula xml:id="formula_14">Survey Asia Insurance Alarm X ✓ X ✓ X ✓ X ✓ X ✓</formula><p>In-Context 0.75 1.00 0.67 1.00 0.68 0.88 0.85 0.90 0.96 0.96 Out-of-Context 0.00 0.25 0.33 0.33 0.53 0.61 0.58 0.58 0.60 0.57 Open world Hypothesis 0.39 0.41 0.40 0.39 0.63 0.66 0.49 0.50 0.44 0.46 Table <ref type="table" target="#tab_6">13</ref>: Model-Mixtral to evaluate the effect of context given in the prompt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Using explanations</head><p>While using LLMs for hypothesizing the missing nodes within the causal graph for the open world setting, an additional question is for the model to provide explanations for each of its predictions. This was motivated by the fact that incorporating a rationale behind each prediction might enhance the model's semantic similarity. We present the results in the Table below. We observe that evaluating semantic similarity with explanations leads to a decrease in performance as compared to the earlier setting where the language model returned phrases. This is because semantic similarity, as a metric, evaluates the closeness of the model's predictions to the ground truth in a high-dimensional vector space, focusing on the semantic content encapsulated within the embeddings. It is a metric that leaves little room for interpretative flexibility, focusing strictly on the degree of semantic congruence between the predicted and actual variables. The introduction of explanations, while enriching the model's outputs with contextual insights, did not translate into improved semantic alignment with the ground truth.  Ambiguous predictions which semantically represent the same variable. An important linguistic concern that could be missed by semantic similarity is an ambiguous hypothesis by the LLM that may have the same semantics, which again breaks the semantic similarity metric. This further motivates the LLM-judge metric, whose input is the context of the causal graph, the partial causal graph, the ground truth variable, and the model predictions. Given the rich context of the LLM-judge metric, we suspect it would be able to overcome the ambiguity. We prompted the model to justify its hypothesis variables using explanations. We observe that evaluating semantic similarity with explanations leads to a decrease in performance as compared to the earlier setting where the language model returned just phrases. In Table <ref type="table" target="#tab_17">14</ref>, we observed a drop in performance for semantic similarity. In contrast, we observe a similar or slight improvement in the LLM-judge metric when the explanation of the model hypothesis is given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 Chain of thought</head><p>Chain-of-Thought prompting has gained popularity due to its impressive performance in proving the quality of LLMs' output <ref type="bibr" target="#b30">(Kojima et al., 2022)</ref>, also in metadata-based causal reasoning <ref type="bibr">(Vashishtha et al., 2023)</ref>. We also incorporated COT prompting for our prompts. We perform ablation studies in Table <ref type="table" target="#tab_18">15</ref>. We observe that COT particularly improves the performance of the identification experiments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.6 Iterative mediator search vs all at once</head><p>For Task 4, we iteratively hypothesize the missing variables (mediators). Our choice was primarily driven by the complexity of Task 4, which involves predicting multiple missing mediators, ranging from 1 to 10. For a Task with 10 missing mediators, the model would have to predict 50 suggestions at once. We initially hypothesized that LLMs might struggle with making multiple predictions across different variables simultaneously. This was indeed reflected in our results and GPT-4 outputs from Table <ref type="table">X</ref>. The iterative approach allows the model's prediction to narrow the search space, which would not be possible in a non-iterative approach. This method is more aligned with the scientific discovery process, where hypotheses are often refined iteratively based on new findings. Furthermore, our approach simulates a human-in-the-loop scenario, where the most plausible answer is selected and used to guide the next prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Asia</head><p>Child Insurance Alarm</p><p>Non-iterative 0.42 +-0.07 0.33 +-0.06 0.45 +-0.09 0.54 +-0.05 Iterative 0.49 +-0.05 0.39 +-0.03 0.52 +-0.02 0.60 +-0.04</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.7 Results on Neuropathic graph</head><p>We added a new graph, the neuropathic pain graph <ref type="bibr" target="#b57">(Tu et al., 2019)</ref>      Answer: X = visited Asia.My thought process is as follows:The causal graph suggests that X causes tuberculosis, and tuberculosis is related to lung diseases. Visiting Asia is a possible explanation for why an individual may have been exposed to tuberculosis, as the disease is more prevalent in some Asian countries. Therefore, visited Asia is the most likely option for X. Your answer should be formatted as follows -Answer: X = choice. The choice must be one of the provided options, and it should be formatted exactly as it appears in the choices. Generating your own options is not allowed in this task.</p><p>Answer: Answer: X = visited Asia. My thought process is as follows:1. The graph shows that X causes tuberculosis, which suggests that X is a variable related to healthcare or medicine.</p><p>2. The graph also shows that bronchitis causes dyspnoea-laboured breathing, which further supports the idea that X is a variable related to healthcare or medicine. 3. The graph shows that individual has either tuberculosis or lung cancer causes y, which suggests that X could be a variable related to diagnosing or treating lung diseases. 4. The graph shows that smoking cigarettes causes lung cancer and bronchitis, which suggests that X could be a variable related to smoking or lung health. 5. Based on the above observations, it seems unlikely that X would be weather, book sales, or movie rating.6. Visited Asia is a variable that could potentially relate to healthcare or medicine, particularly if the patient has traveled to a region with a high prevalence of tuberculosis or other lung diseases.7. Therefore, based on the information provided in the graph, it seems most likely that X = visited Asia. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Assumptions</head><p>The causal sufficiency of G, by definition, implies that for every pair of variables within V, all common causes are also included within V. Extending this assumption to G * , we assume that the partial graph inherits causal sufficiency for its given that all edges among these variables are preserved as in G. This preservation ensures that the observed relationships within V * are not confounded by omitted common causes. Since the faithfulness of G ensures that the observed conditional independencies among variables in V are accurately reflected by the causal structure represented by E. By maintaining the same set of edges E in G * for the subset V * , we uphold the faithfulness assumption within the partial graph.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Scientific discovery iteratively generates hypotheses from assumptions using human expertise. We use LLMs as proxy experts to propose new hypotheses about missing variables in causal DAGs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Leveraging LLM to identify the missing variable for a causal DAG in the presence of out-of-context distractors (a), an in-context distractor along with out-of-context distractors (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Leveraging LLM to hypothesize the missing variable in a causal DAG in an open-world setting for one variable (a), in an iterative fashion for multiple missing mediators (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Accuracy of LLMs in identifying the missing causal variable from multiple choices with out-of-context distractors (a), and from both out-of-context and in-context distractors (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Task 3 Results. Visualizing each model's performance, averaged across the different graphs, for Sink, Source, Mediator, and Collider nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>1:</head><label></label><figDesc>Input: Partial graph G * , Ground truth node variables V GT , Language model LM = 'all-mpnet-base-v2' 2: Output: Average highest semantic similarity score 3: procedure SEMANTICSIMILARITY(G * , V GT , LM )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>1:</head><label></label><figDesc>Input: Partial graph G * , Ground truth node variables V GT , Predictions P , Language model LLM = GPT-4 2: Output: Average quality rating of model's suggestions 3: procedure LLMASJUDGE(G * , V GT , P , LLM) procedure 14: function GENERATESUGGESTIONS(G * , P , LLM) 15: return A set of suggestions for missing nodes based on P 16: end function 17: function SELECTBESTSUGGESTION(suggestions, v GT ,LLM) 18: Prompt LLM with G * , v GT , and suggestions 19: return LLM's choice of the best fitting suggestion 20: end function 21: function RATESUGGESTION(suggestion, LM ) 22:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>1:</head><label></label><figDesc>Input: Partial graph G * (where G * = G -H), Treatment v t , Outcome v y , Number of mediators H, Number of suggestions k 2: Output: Updated graph G * with selected mediators 3: procedure GENERATEMEDIATORSRANDOM(G * , v t , v y , H, k) 4: for i ← 1 to H do 5: suggestions ← Generate k suggestions for v m i using P LLM (G * ) Ordered Mediator Generation and Evaluation Based on MIS 1: Input: Partial graph G * , Treatment v t , Outcome v y , Set of potential mediators M , Number of suggestions k 2: Output: ∆ -measure of the influence of mediator ordering 3: procedure CALCULATEMIS(v t , v y , M ) 4: Initialize MISList as an empty list 5:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>procedure 12: procedure GENERATEMEDIATORSORDERED(G * , v t , v y , M, k) 13: MISList ← CALCULATEMIS(v t , v y , M)14: Sort M in descending order of MISList to get M desc 15: Sort M in ascending order of MISList to get M asc 16: averageDesc ← GENERATEANDEVALUATE(G * , M desc , k) 17: averageAsc ← GENERATEANDEVALUATE(G * , M asc , k) procedure 21: function GENERATEANDEVALUATE(G * , M order , k) 22: Initialize similarityScores as an empty list 23: for each mediator v m i in M order do 24:Perform the same steps as in the refined random order mediator generation 25:(Generate k suggestions, select the most similar, update G * )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: Detailed spider plots for Semantic similarity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure</head><label></label><figDesc>Figure 10: Alarm 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure</head><label></label><figDesc>Figure 12: Insurance 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>What could be the missing variable? Smoking Dyspnea Difficulty Chronic Bronchitis, Emphysema, Asthma, Pneumonia Chronic Obstructive Pulmonary Disease (a) Task 3 What could variable #1 be? Smoking Dyspnea Difficulty Chronic Bronchitis, Emphysema, Asthma, Pneumonia Chronic Obstructive Pulmonary Disease #2 #1</head><label></label><figDesc></figDesc><table><row><cell>(b) Task 4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>, developed by five domain experts and Law (VanderWeele and Staudt, 2011). See Appendix A.1 for further details. Datasets used in the benchmark.</figDesc><table><row><cell>Graph</cell><cell>V</cell><cell>E</cell><cell>Description</cell></row><row><cell>Cancer</cell><cell>5</cell><cell>4</cell><cell>Factors around lung cancer</cell></row><row><cell>Survey</cell><cell>6</cell><cell>6</cell><cell>Factors for choosing trans-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>portation</cell></row><row><cell>Asia</cell><cell>8</cell><cell>8</cell><cell>Factors affecting dysponea</cell></row><row><cell>Law</cell><cell>8</cell><cell cols="2">20 factors around legal system</cell></row><row><cell>Alzheimer</cell><cell>9</cell><cell cols="2">16 Factors around Alzheimer's</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Disease</cell></row><row><cell>Child</cell><cell cols="3">20 25 Lung related illness for a child</cell></row><row><cell>Insurance</cell><cell cols="3">27 52 Factors affecting car accident</cell></row><row><cell></cell><cell></cell><cell></cell><cell>insurance</cell></row><row><cell>Alarm</cell><cell cols="3">37 46 Patient monitoring system</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Zephyr 0.36 0.61 0.34 0.60 0.45 0.66 0.41 0.70 0.35 0.75 0.51 0.70 0.45 0.44 0.46 0.69 0.42 0.63 Mixtral 0.41 0.66 0.39 0.66 0.66 0.75 0.38 0.69 0.31 0.77 0.53 0.77 0.46 0.56 0.50 0.72 0.46 0.70 Neural 0.38 0.77 0.43 0.55 0.53 0.55 0.47 0.72 0.44 0.71 0.48 0.70 0.47 0.43 0.47 0.67 0.45 0.63 Llama 0.40 0.48 0.40 0.54 0.53 0.58 0.67 0.65 0.45 0.61 0.48 0.63 0.42 0.34 0.46 0.65 0.45 0.55 Task 3 Results. Average semantic similarity and LLM-as-Judge metrics to evaluate LLMs in hypothesizing the missing variable in a causal DAG.on average. This suggests that these models are better at reasoning about common causes and indirect causal relationships. Sinks are typically the nodes that represent the outcomes or effects of interventions (treatments) applied to other nodes. Source nodes represent the causes in a causal graph. Lower performance on these nodes indicates to reason about the potential causes and outcomes of the causal graphs is difficult.</figDesc><table><row><cell>Cancer</cell><cell>Survey</cell><cell>Asia</cell><cell>Law</cell><cell>Alzheimers Child</cell><cell>Insurance</cell><cell>Alarm</cell><cell>Avg</cell></row><row><cell cols="8">Mistral 0.33 0.67 0.44 0.65 0.60 0.73 0.49 0.67 0.34 0.76 0.48 0.68 0.46 0.47 0.47 0.71 0.44 0.67</cell></row><row><cell cols="8">GPT-4 0.49 0.90 0.51 0.67 0.66 0.76 0.55 0.78 0.47 0.98 0.36 0.53 0.52 0.56 0.49 0.75 0.50 0.73</cell></row><row><cell cols="8">GPT-4o 0.52 0.89 0.50 0.71 0.66 0.78 0.58 0.80 0.50 0.91 0.40 0.60 0.54 0.58 0.44 0.76 0.54 0.76</cell></row></table><note><p>Sim LLM-J Sim LLM-J Sim LLM-J Sim LLM-J Sim LLM-J Sim LLM-J Sim LLM-J Sim LLM-J Sim LLM-J</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Hypothesizing Confounders in Task 3.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Task 4 Results. Accuracy of iterative mediator prediction when prompted in random order. ∆ reflects the change in performance when mediators are ordered by their Mediation Influence Score (MIS).</figDesc><table><row><cell></cell><cell>Asia</cell><cell></cell><cell cols="2">Child</cell><cell cols="2">Insurance</cell><cell cols="2">Alarm</cell></row><row><cell></cell><cell>Sim</cell><cell>∆</cell><cell>Sim</cell><cell>∆</cell><cell>Sim</cell><cell>∆</cell><cell>Sim</cell><cell>∆</cell></row><row><cell>Zephyr</cell><cell cols="3">0.61 -0.02 0.54</cell><cell cols="2">0.17 0.47</cell><cell cols="2">0.19 0.51</cell><cell>0.20</cell></row><row><cell cols="2">Mixtral 0.87</cell><cell cols="2">0.01 0.50</cell><cell cols="2">0.18 0.48</cell><cell cols="2">0.15 0.52</cell><cell>0.13</cell></row><row><cell>Neural</cell><cell>0.65</cell><cell cols="2">0.04 0.48</cell><cell cols="2">0.21 0.42</cell><cell cols="2">0.16 0.46</cell><cell>0.12</cell></row><row><cell>Llama</cell><cell>0.80</cell><cell cols="4">0.07 0.49 -0.05 0.44</cell><cell cols="2">0.21 0.51</cell><cell>0.07</cell></row><row><cell>Mistral</cell><cell>0.33</cell><cell cols="2">0.02 0.50</cell><cell cols="2">0.12 0.48</cell><cell cols="2">0.13 0.47</cell><cell>0.11</cell></row><row><cell>GPT-4</cell><cell>0.49</cell><cell cols="2">0.04 0.39</cell><cell cols="2">0.16 0.52</cell><cell cols="3">0.14 0.60 -0.07</cell></row><row><cell cols="2">GPT-4o 0.55</cell><cell cols="2">0.00 0.48</cell><cell cols="2">0.10 0.51</cell><cell cols="2">0.08 0.62</cell><cell>0.01</cell></row><row><cell cols="9">Results. The results of this experiment are in Ta-</cell></row><row><cell cols="9">ble 4. Results with variances are provided in Ap-</cell></row><row><cell cols="9">pendix B.1. In this highly complex environment</cell></row><row><cell cols="9">with more than one node missing and with open-</cell></row><row><cell cols="9">world search space, LLMs can still maintain their</cell></row><row><cell cols="9">performance. Unlike the overall consistent per-</cell></row><row><cell cols="9">formance of GPT-4 across all graphs, other mod-</cell></row></table><note><p>els showed superior performance in Insurance and Alarm graphs only. As the complexity of the graph increases, we observe larger differences in hypothesizing the mediators according to the MIS order.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>This work was partially funded by ELSA -European Lighthouse on Secure and Safe AI funded by the European Union under grant agreement No. 101070617 and the German Federal Ministry of Education and Research (BMBF) under the grant AIgenCY (16KIS2012). Views and opinions expressed are however those of the authors only and do not necessarily reflect those of the European Union or European Commission. Neither the European Union nor the European Commission can be held responsible for them.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>graph description.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Examples of model suggestions from and the corresponding semantic similarity score for a missing node variable from each of the graphs.</figDesc><table><row><cell>LM )</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 9 :</head><label>9</label><figDesc>Examples of model suggestions from and the corresponding LLM-as-judge score for a missing node variable.</figDesc><table><row><cell>Ground Truth: Dyspnea laboured breathing</cell></row><row><cell>LLM Suggestion: Shortness of breath</cell></row><row><cell>Semantic similarity to GT: 0.57</cell></row><row><cell>LLM-as-Judge score: 9.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 :</head><label>11</label><figDesc>Average semantic similarity and LLM-as-Judge metrics to evaluate LLMs in hypothesizing the missing variable in a causal DAG.</figDesc><table><row><cell cols="2">Cancer</cell><cell cols="2">Survey</cell><cell></cell><cell cols="2">Asia</cell><cell></cell><cell cols="2">Alzheimers</cell><cell cols="2">Child</cell><cell></cell><cell cols="3">Insurance</cell><cell>Alarm</cell><cell>Avg</cell></row><row><cell cols="2">Sim LLM-J</cell><cell cols="2">Sim LLM-J</cell><cell></cell><cell cols="3">Sim LLM-J</cell><cell cols="2">Sim LLM-J</cell><cell cols="3">Sim LLM-J</cell><cell cols="3">Sim LLM-J</cell><cell>Sim LLM-J</cell><cell>Sim</cell><cell>LLM-J</cell></row><row><cell>Zephyr 0.36 ±0.04</cell><cell>0.61 ±0.06</cell><cell>0.34 ±0.07</cell><cell>0.60 ±0.05</cell><cell cols="2">0.45 ±0.05</cell><cell cols="2">0.66 ±0.04</cell><cell>0.35 ±0.03</cell><cell>0.75 ±0.03</cell><cell>0.51 ±0.02</cell><cell cols="2">0.70 ±0.04</cell><cell cols="2">0.45 ±0.04</cell><cell cols="2">0.44 ±0.05</cell><cell>0.46 ±0.03</cell><cell>0.69 ±0.02</cell><cell>0.42 ±0.04</cell><cell>0.63 ±0.04</cell></row><row><cell>Mixtral 0.41 ±0.03</cell><cell>0.66 ±0.04</cell><cell>0.39 ±0.05</cell><cell>0.66 ±0.06</cell><cell cols="2">0.66 ±0.02</cell><cell cols="2">0.75 ±0.03</cell><cell>0.31 ±0.04</cell><cell>0.77 ±0.02</cell><cell>0.53 ±0.03</cell><cell cols="2">0.77 ±0.02</cell><cell cols="2">0.46 ±0.03</cell><cell cols="2">0.56 ±0.04</cell><cell>0.50 ±0.03</cell><cell>0.72 ±0.06</cell><cell>0.46 ±0.03</cell><cell>0.70 ±0.05</cell></row><row><cell>Neural 0.38 ±0.02</cell><cell>0.77 ±0.05</cell><cell>0.43 ±0.02</cell><cell>0.55 ±0.03</cell><cell cols="2">0.53 ±0.03</cell><cell cols="2">0.55 ±0.04</cell><cell>0.44 ±0.05</cell><cell>0.71 ±0.03</cell><cell>0.48 ±0.04</cell><cell cols="2">0.70 ±0.03</cell><cell cols="2">0.47 ±0.04</cell><cell cols="2">0.43 ±0.05</cell><cell>0.47 ±0.02</cell><cell>0.67 ±0.03</cell><cell>0.45 ±0.03</cell><cell>0.63 ±0.04</cell></row><row><cell>Llama 0.40 ±0.03</cell><cell>0.48 ±0.05</cell><cell>0.40 ±0.04</cell><cell>0.54 ±0.05</cell><cell cols="2">0.53 ±0.03</cell><cell cols="2">0.58 ±0.06</cell><cell>0.45 ±0.05</cell><cell>0.61 ±0.03</cell><cell>0.48 ±0.04</cell><cell cols="2">0.63 ±0.03</cell><cell cols="2">0.42 ±0.01</cell><cell cols="2">0.34 ±0.05</cell><cell>0.46 ±0.02</cell><cell>0.65 ±0.03</cell><cell>0.45 ±0.03</cell><cell>0.55 ±0.04</cell></row><row><cell>Mistral 0.33 ±0.01</cell><cell>0.67 ±0.05</cell><cell>0.44 ±0.05</cell><cell>0.65 ±0.04</cell><cell cols="2">0.60 ±0.03</cell><cell cols="2">0.73 ±0.04</cell><cell>0.34 ±0.04</cell><cell>0.76 ±0.02</cell><cell>0.48 ±0.04</cell><cell cols="2">0.68 ±0.03</cell><cell cols="2">0.46 ±0.03</cell><cell cols="2">0.47 ±0.01</cell><cell>0.47 ±0.03</cell><cell>0.71 ±0.03</cell><cell>0.44 ±0.03</cell><cell>0.67 ±0.03</cell></row><row><cell>GPT-4 0.49 ±0.02</cell><cell>0.90 ±0.03</cell><cell>0.51 ±0.06</cell><cell>0.67 ±0.04</cell><cell cols="2">0.66 ±0.02</cell><cell cols="2">0.76 ±0.03</cell><cell>0.47 ±0.02</cell><cell>0.98 ±0.02</cell><cell>0.36 ±0.05</cell><cell cols="2">0.53 ±0.04</cell><cell cols="2">0.52 ±0.03</cell><cell cols="2">0.56 ±0.03</cell><cell>0.49 ±0.06</cell><cell>0.75 ±0.02</cell><cell>0.50 ±0.04</cell><cell>0.73 ±0.03</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Asia</cell><cell></cell><cell></cell><cell cols="2">Child</cell><cell cols="4">Insurance</cell><cell></cell><cell cols="2">Alarm</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Sim</cell><cell></cell><cell cols="2">∆</cell><cell></cell><cell>Sim</cell><cell>∆</cell><cell cols="2">Sim</cell><cell cols="2">∆</cell><cell cols="2">Sim</cell><cell>∆</cell></row><row><cell></cell><cell cols="4">Zephyr 0.61 ±0.03</cell><cell cols="2">-0.02 ±0.01</cell><cell cols="2">0.54 ±0.04</cell><cell>0.17 ±0.02</cell><cell cols="2">0.47 ±0.05</cell><cell cols="2">0.19 ±0.02</cell><cell cols="2">0.51 ±0.05</cell><cell>0.20 ±0.02</cell></row><row><cell></cell><cell cols="4">Mixtral 0.87 ±0.02</cell><cell cols="2">0.01 ±0.01</cell><cell cols="2">0.50 ±0.05</cell><cell>0.18 ±0.02</cell><cell cols="2">0.48 ±0.05</cell><cell cols="2">0.15 ±0.02</cell><cell cols="2">0.52 ±0.05</cell><cell>0.13 ±0.01</cell></row><row><cell></cell><cell cols="4">Neural 0.65 ±0.06</cell><cell cols="2">0.04 ±0.02</cell><cell cols="2">0.48 ±0.05</cell><cell>0.21 ±0.02</cell><cell cols="2">0.42 ±0.04</cell><cell cols="2">0.16 ±0.02</cell><cell cols="2">0.46 ±0.04</cell><cell>0.12 ±0.01</cell></row><row><cell></cell><cell cols="4">Llama 0.80 ±0.08</cell><cell cols="2">0.07 ±0.02</cell><cell cols="2">0.49 ±0.05</cell><cell>-0.05 ±0.01</cell><cell cols="2">0.44 ±0.06</cell><cell cols="2">0.21 ±0.02</cell><cell cols="2">0.51 ±0.05</cell><cell>0.07 ±0.01</cell></row><row><cell></cell><cell cols="4">Mistral 0.33 ±0.03</cell><cell cols="2">0.02 ±0.01</cell><cell cols="2">0.50 ±0.05</cell><cell>0.12 ±0.01</cell><cell cols="2">0.48 ±0.05</cell><cell cols="2">0.13 ±0.02</cell><cell cols="2">0.47 ±0.04</cell><cell>0.11 ±0.01</cell></row><row><cell></cell><cell cols="4">GPT-4 0.49 ±0.07</cell><cell cols="2">0.04 ±0.01</cell><cell cols="2">0.39 ±0.05</cell><cell>0.16 ±0.02</cell><cell cols="2">0.52 ±0.05</cell><cell cols="2">0.14 ±0.02</cell><cell cols="2">0.60 ±0.06</cell><cell>-0.07 ±0.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 14 :</head><label>14</label><figDesc> Evaluating the effect of explanations on different metrics from Task 3.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 15 :</head><label>15</label><figDesc>Model-Mixtral to evaluate the effect of COT given in the prompt.</figDesc><table><row><cell></cell><cell>Cancer</cell><cell>Survey</cell><cell>Asia</cell><cell>Insurance Alarm</cell></row><row><cell></cell><cell cols="4">X ✓ X ✓ X ✓ X ✓ X ✓</cell></row><row><cell>In-Context</cell><cell cols="4">1.00 1.00 0.83 1.00 0.75 0.88 0.74 0.90 0.91 0.96</cell></row><row><cell cols="5">Out-of-Context 0.50 0.25 0.18 0.33 0.57 0.61 0.56 0.58 0.54 0.57</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head></head><label></label><figDesc>, which is not part of common LLM training corpora as one needs to use a python script to download it. The graph consists of 221 nodes and 770 edges, but for feasibility, we selected a subset of the graph for evaluation. We ran experiments for Task 1, Task 2, and Task 3.</figDesc><table><row><cell cols="6">Model Task 1 Task 2 Result Task 2 FNA Task 3 Sim Task 3 LLM-J</cell></row><row><cell cols="2">Mistral 0.64</cell><cell>0.51</cell><cell>0.32</cell><cell>0.38</cell><cell>0.53</cell></row><row><cell cols="2">Mixtral 0.83</cell><cell>0.55</cell><cell>0.34</cell><cell>0.45</cell><cell>0.69</cell></row><row><cell>Llama</cell><cell>0.78</cell><cell>0.49</cell><cell>0.27</cell><cell>0.44</cell><cell>0.63</cell></row><row><cell cols="2">GPT-4 0.94</cell><cell>0.68</cell><cell>0.24</cell><cell>0.51</cell><cell>0.76</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 16 :</head><label>16</label><figDesc>Comparison of model performances across tasks on Neuropathic graph.</figDesc><table><row><cell cols="5">B.8 Fine grained model performance</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Collider</cell><cell>Source 0.1 0.2 0.3 0.4 0.5 0.6 Sink</cell><cell>Collider</cell><cell cols="2">Sink 0.1 0.2 0.3 0.4 0.5 0.6</cell><cell>Source</cell><cell>Collider</cell><cell cols="2">Sink</cell><cell>0.1 0.2 0.3 0.4 0.5</cell><cell>Source</cell><cell>Collider</cell><cell>Sink</cell><cell>0.2 0.4 0.6 0.8</cell><cell>Source Zephyr Mixtral Neural llama Mistral GPT 3.5 GPT 4</cell></row><row><cell></cell><cell>Mediator</cell><cell></cell><cell cols="2">Mediator</cell><cell></cell><cell></cell><cell cols="3">Mediator</cell><cell></cell><cell></cell><cell cols="2">Mediator</cell></row><row><cell></cell><cell>(a) Cancer</cell><cell></cell><cell cols="2">(b) Survey</cell><cell></cell><cell cols="4">(c) Alzheimers</cell><cell></cell><cell></cell><cell cols="2">(d) Asia</cell></row><row><cell></cell><cell></cell><cell>Sink</cell><cell></cell><cell></cell><cell></cell><cell>Sink</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sink</cell><cell></cell></row><row><cell></cell><cell>Collider</cell><cell cols="2">Source 0.1 0.2 0.3 0.4 0.5 0.6</cell><cell>Collider</cell><cell></cell><cell>0.1 0.2 0.3 0.4 0.5</cell><cell>Source</cell><cell cols="2">Collider</cell><cell></cell><cell>0.1 0.2 0.3 0.4 0.5 0.6</cell><cell>Source</cell></row><row><cell></cell><cell cols="2">Mediator</cell><cell></cell><cell></cell><cell cols="2">Mediator</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Mediator</cell><cell></cell></row><row><cell></cell><cell cols="2">(e) Child</cell><cell></cell><cell></cell><cell cols="2">(f) Insurance</cell><cell></cell><cell></cell><cell></cell><cell cols="2">(g) Alarm</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head></head><label></label><figDesc>F Prompt templateHello. You will be given a causal graph. The context of the graph[CONTEXT]. Please understand the causal relationships between the variables -[VERBALISED DAG].Prompt 1: Base prompt to describe the causal graph Hello. You will be given a causal graph. The context of the graph is hypothetical patient monitoring system in an intensive care unit (ICU). Please understand the causal relationships between the variables -&lt; anaphylaxis &gt; causes &lt; total peripheral resistance &gt;. &lt; arterial co2 &gt; causes &lt; expelled co2 &gt;. &lt; arterial co2 &gt; causes &lt; catecholamine &gt;. &lt; catecholamine &gt; causes &lt; heart rate &gt;. &lt; cardiac output &gt; causes &lt; blood pressure &gt;. &lt; disconnection &gt; causes &lt; breathing tube &gt;. &lt; error cauter &gt; causes &lt; heart rate displayed on ekg monitor &gt;. &lt; error cauter &gt; causes &lt; oxygen saturation &gt;. &lt; error low output &gt; causes &lt; heart rate blood pressure &gt;. &lt; high concentration of oxygen in the gas mixture &gt; causes &lt; pulmonary artery oxygen saturation &gt;. &lt; heart rate &gt; causes &lt; heart rate blood pressure &gt;. &lt; heart rate &gt; causes &lt; heart rate displayed on ekg monitor &gt;. &lt; heart rate &gt; causes &lt; oxygen saturation Prompt 2: An example of the base prompt for Alarm graph. Each relationship is enclosed in pointed brackets,&lt;&gt; followed by a full stop. Hello. You will be given a causal graph. The context of the graph is different aspects of a patient's health related to lung diseases. Please understand the causal relationships between the variables -&lt; x &gt; causes &lt; tuberculosis &gt;. &lt; bronchitis &gt; causes &lt; dyspnoea-laboured breathing &gt;. &lt; individual has either tuberculosis or lung cancer &gt; causes &lt; positive xray &gt;. &lt; individual has either tuberculosis or lung cancer &gt; causes &lt; dyspnoea-laboured breathing &gt;. &lt; lung cancer &gt; causes &lt; individual has either tuberculosis or lung cancer &gt;. &lt; smoking cigarettes &gt; causes &lt; lung cancer &gt;. &lt; smoking cigarettes &gt; causes &lt; bronchitis &gt;. &lt; tuberculosis &gt; causes &lt; individual has either tuberculosis or lung cancer &gt;.Based on your understanding and analytical skills, please identify what the variable X could most likely be from the given multiple choices. It's important to note that you MUST select an option from the provided choices, as one of them is the correct answer. The choices are: [ visited Asia; weather; book sales; movie rating ]. Please think step by step. Your answer should be formatted as follows -Answer: X = choice. The choice must be one of the provided options, and it should be formatted exactly as it appears in the choices. Generating your own options is not allowed in this task.</figDesc><table /><note><p><p>&gt;. &lt; heart rate &gt; causes &lt; cardiac output &gt;. &lt; hypovolemia &gt; causes &lt; left ventricular end-diastolic volume &gt;. &lt; hypovolemia &gt; causes &lt; stroke volume &gt;. &lt; insufficient anesthesia &gt; causes &lt; catecholamine &gt;. &lt; intubation &gt; causes &lt; lung ventilation &gt;. &lt; intubation &gt; causes &lt; minute volume &gt;. &lt; intubation &gt; causes &lt; alveolar ventilation &gt;. &lt; intubation &gt; causes &lt; shunt -normal and high &gt;. &lt; intubation &gt; causes &lt; breathing pressure &gt;. &lt; kinked chest tube &gt; causes &lt; lung ventilation &gt;. &lt; kinked chest tube &gt; causes &lt; breathing pressure &gt;. &lt; left ventricular end-diastolic volume &gt; causes &lt; central venous pressure &gt;. &lt; left ventricular end-diastolic volume &gt; causes &lt; pulmonary capillary wedge pressure &gt;. &lt; left ventricular failure &gt; causes &lt; previous medical history &gt;. &lt; left ventricular failure &gt; causes &lt; left ventricular end-diastolic volume &gt;. &lt; left ventricular failure &gt; causes &lt; stroke volume &gt;. &lt; the amount of time using a breathing machine &gt; causes &lt; the intensity level of a breathing machine &gt;. &lt; sudden blockage in the pulmonary arteries &gt; causes &lt; shunt -normal and high &gt;. &lt; sudden blockage in the pulmonary arteries &gt; causes &lt; pulmonary artery pressure &gt;. &lt; pulmonary artery oxygen saturation &gt; causes &lt; oxygen saturation &gt;. &lt; oxygen saturation &gt; causes &lt; catecholamine &gt;. &lt; shunt -normal and high &gt; causes &lt; oxygen saturation &gt;. &lt; stroke volume &gt; causes &lt; cardiac output &gt;. &lt; total peripheral resistance &gt; causes &lt; catecholamine &gt;. &lt; total peripheral resistance &gt; causes &lt; blood pressure &gt;. &lt; alveolar ventilation &gt; causes &lt; arterial co2 &gt;. &lt; alveolar ventilation &gt; causes &lt; pulmonary artery oxygen saturation &gt;. &lt; lung ventilation &gt; causes &lt; expelled co2 &gt;. &lt; lung ventilation &gt; causes &lt; minute volume &gt;. &lt; lung ventilation &gt; causes &lt; alveolar ventilation &gt;. &lt; the intensity level of a breathing machine &gt; causes &lt; breathing tube &gt;. &lt; breathing tube &gt; causes &lt; lung ventilation &gt;. &lt; breathing tube &gt; causes &lt; breathing pressure &gt;.</p>Prompt:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head></head><label></label><figDesc>Hello. You will be given a causal graph. The context of the graph is different aspects of a patient's health related to lung diseases Please understand the causal relationships between the variables -&lt; x &gt; causes &lt; tuberculosis &gt;. &lt; bronchitis &gt; causes &lt; dyspnoea-laboured breathing &gt;. &lt; individual has either tuberculosis or lung cancer &gt; causes &lt; y &gt;. &lt; individual has either tuberculosis or lung cancer &gt; causes &lt; dyspnoea-laboured breathing &gt;. &lt; lung cancer &gt; causes &lt; individual has either tuberculosis or lung cancer &gt;. &lt; smoking cigarettes &gt; causes &lt; lung cancer &gt;. &lt; smoking cigarettes &gt; causes &lt; bronchitis &gt;. &lt; tuberculosis &gt; causes &lt; individual has either tuberculosis or lung cancer &gt;. Based on your understanding and analytical skills, please identify what the variable X could most likely be from the given multiple choices. It's important to note that you MUST select an option from the provided choices, as one of them is the correct answer. The choices are: [ weather; book sales; movie rating; positive xray; visited Asia ]. Please think step by step.</figDesc><table /><note><p>Prompt 3: Out-of-context controlled variable identification, Ground truth variable: visited Asia Prompt:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head></head><label></label><figDesc>Prompt 4: In-context controlled variable identification, Ground truth variable: visited asia Prompt: Hello. You will be given a causal graph. The context of the graph is different aspects of a patient's health related to lung diseases. Please understand the causal relationships between the variables -&lt; x &gt; causes &lt; tuberculosis &gt;. &lt; bronchitis &gt; causes &lt; dyspnoea-laboured breathing &gt;. &lt; individual has either tuberculosis or lung cancer &gt; causes &lt; positive xray &gt;. &lt; individual has either tuberculosis or lung cancer &gt; causes &lt; dyspnoea-laboured breathing &gt;. &lt; lung cancer &gt; causes &lt; individual has either tuberculosis or lung cancer &gt;. &lt; smoking cigarettes &gt; causes &lt; lung cancer &gt;. &lt; smoking cigarettes &gt; causes &lt; bronchitis &gt;. &lt; tuberculosis &gt; causes &lt; individual has either tuberculosis or lung cancer &gt;. Using your causal knowledge, can you suggest what variable X most likely? Give 5 suggestions for what variable X could be. Give reason for your suggestions. Finally, return your answer (without reasoning) in the following format: &lt;Answer&gt; [first suggestion, second suggestion, third suggestion .. and so on] &lt;/Answer&gt; No explanations, no reasoning, just answers as a list as described earlier. For example, if the suggestions are A,B,C,D,E then -&lt;Answer&gt; [A, B, C, D, E] &lt;/Answer&gt; Answer: &lt;Answer&gt; [HIV/AIDS, Chronic respiratory conditions, Pneumonia, Exposure to asbestos, Silicosis] &lt;/Answer&gt; Reasons: 1. HIV/AIDS: It is known to weaken the immune system, making the individual more susceptible to infections like tuberculosis. 2. Chronic respiratory conditions: These can make an individual more susceptible to lung diseases like tuberculosis. 3. Pneumonia: It is a lung infection that can lead to serious conditions like tuberculosis if not treated properly. 4. Exposure to asbestos: Long-term exposure to asbestos can lead to lung diseases including lung cancer and tuberculosis. 5. Silicosis: It is a lung disease caused by inhalation of silica dust, leading to inflammation and scarring of the lung tissue, making the individual more susceptible to tuberculosis. Prompt 5: Hypothesizing missing variable in open world, Ground truth variable: Visited Asia Prompt: Hello. You will be given a causal graph. The context of the graph is different aspects of a patient's health related to lung diseases. Please understand the causal relationships between the variables -&lt; visited asia &gt; causes &lt; tuberculosis &gt;. &lt; bronchitis &gt; causes &lt; dyspnoealaboured breathing &gt;. &lt; individual has either tuberculosis or lung cancer &gt; causes &lt; positive xray &gt;. &lt; individual has either tuberculosis or lung cancer &gt; causes &lt; dyspnoea-laboured breathing &gt;. &lt; x &gt; causes &lt; individual has either tuberculosis or lung cancer &gt;. &lt; smoking cigarettes &gt; causes &lt; x &gt;. &lt; smoking cigarettes &gt; causes &lt; bronchitis &gt;. &lt; tuberculosis &gt; causes &lt; individual has either tuberculosis or lung cancer &gt;. Using your causal knowledge, can you suggest what variable X most likely? Give 5 suggestions for what variable X could be. Give reason for your suggestions. Finally, return your answer (without reasoning) in the following format: &lt;Answer&gt; [first suggestion, second suggestion, third suggestion .. and so on] &lt;/Answer&gt; No explanations, no reasoning, just answers as a list as described earlier. For example, if the suggestions are A,B,C,D,E then -&lt;Answer&gt; [A, B, C, D, E] &lt;/Answer&gt; Answer: &lt;Answer&gt; [Lung Cancer, Chronic Obstructive Pulmonary Disease, Emphysema, Pneumonia, Asthma] &lt;/Answer&gt; Reasons: 1. Lung Cancer: Smoking is a major cause of lung cancer and lung cancer can lead to tuberculosis or other lung diseases. 2. Chronic Obstructive Pulmonary Disease: Smoking is a leading cause of COPD and it can lead to other lung diseases including tuberculosis and lung cancer. 3. Emphysema: It is a type of COPD often caused by smoking and can lead to other lung diseases. 4. Pneumonia: Smoking increases the risk of pneumonia and pneumonia can lead to other lung diseases. 5. Asthma: Smoking can trigger asthma attacks and severe asthma can lead to other lung diseases.</figDesc><table /><note><p>Prompt 6: Hypothesizing missing variable in open world, Ground truth variable: Lung cancer</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Code available at https://github.com/ivaxi0s/ inferring-causal-variables</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The memorization column shows whether GPT-4 recalled structural details.</p><p>To test whether GPT-4's original performance was driven by the retrieval of memorized content, we reran the variable inference task with explicit prompts stating that the graphs were from the BNLearn repository.</p><p>We observed modest gains in similarity for well-known graphs (e.g., Asia, Alarm), indicating that GPT-4 can retrieve additional details when cued. However, the performance in the original setting, without such cues, was already strong, suggesting that the model was not merely retrieving memorized structures. Instead, its responses appear to reflect contextual reasoning and generalization beyond rote recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.10 Converting causal graph to prompt</head><p>We observe that different graph representations yield similar performance across tasks, with the most variation for Task 2 where we have 2 missing variables on Mistral and Mixtral models. C Finetuning and Few-shot prompting</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Finetuning</head><p>We aim to assess the LLM's causal reasoning via prompting. The following are the reasons why fine-tuning is not the most practical solution:</p><p>• Pretrained models come with a wealth of general knowledge, which we aim to leverage. Fine-tuning these models could potentially limit their ability to draw on this broad knowledge base. We aim to understand the utility of pretrained models, as fine-tuning large models like GPT-4 is not always feasible.</p><p>• The training graph is too small for fine-tuning. Despite considering a large 52-edged graph: Insurance, we would have just 27 datapoints or Alarm with 37 datapoint. Additionally:</p><p>1. Using the same graph as part of train and test would unfortunately lead to training data leakage.</p><p>2. If we consider different graphs for train and test, there would exist a domain shift in the two graphs and the model may be overfitted to the domain of the train graph.</p><p>However, to illustrate our hypothesis and alleviate the reviewer's concern, we performed Supervised Fine-Tuning using QLoRA on the Mistral-7b-Instruct model for hypothesizing in the open world task. The train set here is all of the graphs minus the respective graph it was tested on. We tested on Survey, Insurance and Alzheimers graphs. The model was trained to give one best-fit suggestion for the missing variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Insurance Survey Alzheimers</head><p>No fine-tuning 0.42 +-0.03 0.44 +-0.05 0.34 +-0.04 Fine-tuned 0.39 +-0.04 0.39 +-0.03 0.36 +-0.07 From the above results, it is evident that finetuning does not significantly improve over the prompting results. This is because during training the LLM gets biased towards the domains of training graphs which are contextually distant from the test domain, given the diversity of graphs chosen. One may think that training might help the LLM to understand the task, but from prompt-based model output, it was evident that the LLM can instruction-follow. In summary, we were able to extract the LLM knowledge via prompting and domain-specific fine-tuning could be closely looked at in the future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Fewshot prompting</head><p>Similar to fine-tuning, few-shot learning's success depends on balancing domain specificity and generality. To avoid test examples becoming part of the shots, we have to use different domains as examples. Given the complexity of the Alarm graph, we decided to use them as a prior. We performed experiments with 1-shot and 5-shots for the Mixtral 8x7b model. We would like to remind you that Alarm was a medical graph which means that providing more examples in a different domain might hinder the model performance. Drop in performance when changing domain for in-context learning has been discussed in <ref type="bibr" target="#b32">(Kwan et al., 2024)</ref> and <ref type="bibr" target="#b19">(Gupta et al., 2024)</ref>   </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Causal modelling agents: Causal graph discovery through synergising metadata-and data-driven reasoning</title>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Abdulaal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nina</forename><surname>Montana-Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiantian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayodeji</forename><surname>Ijishakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivana</forename><surname>Drobnjak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">C</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><surname>Alexander</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m">Microsoft Research AI4Science and Microsoft Azure Quantum. 2023. The impact of large language models on scientific discovery: a preliminary study using gpt-4. arXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Alaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachael</forename><forename type="middle">V</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Kıcıman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><forename type="middle">B</forename><surname>Balzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Van Der Laan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maya</forename><surname>Petersen</surname></persName>
		</author>
		<idno>arXiv</idno>
		<title level="m">Large language models as co-pilots for causal inference in medical studies</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Confounding, causality, and confusion: the role of intermediate variables in interpreting observational studies in obstetrics</title>
		<author>
			<persName><forename type="first">V</forename><surname>Cande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrique</forename><forename type="middle">F</forename><surname>Ananth</surname></persName>
		</author>
		<author>
			<persName><surname>Schisterman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American journal of obstetrics and gynecology</title>
		<imprint>
			<biblScope unit="volume">217</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="175" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">From query tools to causal architects: Harnessing large language models for advanced causal discovery from data</title>
		<author>
			<persName><forename type="first">Taiyu</forename><surname>Ban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyvzhou</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huanhuan</forename><surname>Chen</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The alarm monitoring system: A case study with two probabilistic inference techniques for belief networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ingo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henri</forename><forename type="middle">Jacques</forename><surname>Beinlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Suermondt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">F</forename><surname>Chavez</surname></persName>
		</author>
		<author>
			<persName><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AIME 89: Second European Conference on Artificial Intelligence in Medicine</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1989-08-29">1989. August 29th-31st 1989</date>
			<biblScope unit="page" from="247" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive probabilistic networks with hidden variables</title>
		<author>
			<persName><forename type="first">John</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keiji</forename><surname>Kanazawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="213" to="244" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Ruta</forename><surname>Binkyte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivaxi</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Havaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<idno>arXiv</idno>
		<title level="m">Causality is key to understand and balance multiple goals in trustworthy ml and foundation models</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Causality and modern science</title>
		<author>
			<persName><forename type="first">Mario</forename><surname>Bunge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Routledge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno>arXiv</idno>
		<title level="m">Premise order matters in reasoning with large language models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Evolving scientific discovery by unifying data and background knowledge with ai hilbert</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Cory-Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Cornelio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeeb</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bachir</forename><forename type="middle">El</forename><surname>Khadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lior</forename><surname>Horesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5922</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Large language models are effective priors for causal graph discovery</title>
		<author>
			<persName><forename type="first">Victor-Alexandru</forename><surname>Darvariu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Hailes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirco</forename><surname>Musolesi</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">End-to-end causal effect estimation from unstructured natural language data</title>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Dhawan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonardo</forename><surname>Cotta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Ullrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Rahul G Krishnan</surname></persName>
		</author>
		<author>
			<persName><surname>Maddison</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">How to think stepby-step: A mechanistic understanding of chain-ofthought reasoning</title>
		<author>
			<persName><forename type="first">Subhabrata</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joykirat</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanmoy</forename><surname>Chakraborty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Crass: A novel data set and benchmark to test counterfactual reasoning of large language models</title>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Frohberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Binder</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Large language models are not abstract reasoners</title>
		<author>
			<persName><forename type="first">Gaël</forename><surname>Gendron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Witbrock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gillian</forename><surname>Dobbie</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Text mining for causal relations</title>
		<author>
			<persName><forename type="first">Roxana</forename><surname>Girju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><forename type="middle">I</forename><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FLAIRS conference</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="360" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Review of causal discovery methods based on graphical models</title>
		<author>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in genetics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">524</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Dejian</forename><surname>Daya Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haowei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junxiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoyu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runxin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qihao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiyi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Bi</surname></persName>
		</author>
		<title level="m">Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Akash</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivaxi</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raina</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Gales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<idno>arXiv</idno>
		<title level="m">Llm task interference: An initial study on the impact of task-switch in conversational history</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Estimating treatment effects with observed confounders and mediators</title>
		<author>
			<persName><forename type="first">Shantanu</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Childers</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="982" to="991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Causal knowledge extraction through large-scale text mining</title>
		<author>
			<persName><forename type="first">Oktie</forename><surname>Hassanzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debarun</forename><surname>Bhattacharjya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Feblowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kavitha</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Perrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirin</forename><surname>Sohrabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="13610" to="13611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Accounting for missing data in statistical analyses: multiple imputation is not always the answer</title>
		<author>
			<persName><forename type="first">Rachael</forename><forename type="middle">A</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Heron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">Ac</forename><surname>Sterne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kate</forename><surname>Tilling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of epidemiology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1294" to="1304" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Hurst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><forename type="middle">P</forename><surname>Goucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akila</forename><surname>Ostrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Welihinda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><surname>Radford</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>et al. 2024. Gpt-4o system card. arXiv</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Intel neural-chat-7b model achieves top ranking on llm leaderboard!</title>
		<author>
			<persName><surname>Intel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Albert Q Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianna</forename><surname>Bressand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><surname>Saulnier</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>et al. 2023. Mistral 7b. arXiv</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Albert Q Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blanche</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Savary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><forename type="middle">Bou</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName><surname>Bressand</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>et al. 2024. Mixtral of experts. arXiv</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Zhijing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiarui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spencer</forename><surname>Poff</surname></persName>
		</author>
		<title level="m">Mrinmaya Sachan, Rada Mihalcea, Mona Diab, and Bernhard Schölkopf. 2023. Can large language models infer causation from correlation? arXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Yash More, Vedant Shah, and Yoshua Bengio. 2024. Efficient causal graph discovery using large language models</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Jiralerspong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyin</forename><surname>Chen</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Emre</forename><surname>Kıcıman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Ness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<title level="m">Causal reasoning and large language models: Opening a new frontier for causality</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><surname>Iwasawa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Kevin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><forename type="middle">E</forename><surname>Korb</surname></persName>
		</author>
		<author>
			<persName><surname>Nicholson</surname></persName>
		</author>
		<title level="m">Bayesian artificial intelligence</title>
		<imprint>
			<publisher>CRC press</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Mt-eval: A multiturn capabilities evaluation benchmark for large language models</title>
		<author>
			<persName><forename type="first">Wai-Chung</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingshan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liangyou</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>EMNLP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Local computations with probabilities on graphical structures and their application to expert systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Steffen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Lauritzen</surname></persName>
		</author>
		<author>
			<persName><surname>Spiegelhalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="194" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tibor</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Piché</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ser-Vicenow</forename><surname>Research</surname></persName>
		</author>
		<title level="m">Can large language models build causal graphs? arXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Chris</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">Tjarko</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
		<idno>arXiv</idno>
		<title level="m">The ai scientist: Towards fully automated open-ended scientific discovery</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">On behalf of the PO-LAR, et al. 2010. Challenging issues in randomised controlled trials</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ad Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Injury</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="20" to="S23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<title level="m">Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Causality</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Interpretation and identification of causal mediation</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological methods</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">459</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Artificial intelligence-based copilots to generate causal evidence</title>
		<author>
			<persName><forename type="first">Maya</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Alaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Kıcıman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Van Der Laan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">How to control confounding effects by statistical analysis</title>
		<author>
			<persName><forename type="first">Mohamad</forename><surname>Amin Pourhoseingholi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmad</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Baghestani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohsen</forename><surname>Vahedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Gastroenterology and hepatology from bed to bench</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">79</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deciphering the factors influencing the efficacy of chain-of-thought: Probability, memorization, and noisy reasoning</title>
		<author>
			<persName><forename type="first">Akshara</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Mccoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP Findings</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Measuring and narrowing the compositionality gap in language models</title>
		<author>
			<persName><forename type="first">Ofir</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muru</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP Findings</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Large language models are zero shot hypothesis proposers</title>
		<author>
			<persName><forename type="first">Biqing</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sihang</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhang-Ren Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Phenomenal yet puzzling: Testing inductive reasoning capabilities of language models with hypothesis refinement</title>
		<author>
			<persName><forename type="first">Linlu</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ximing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Sclar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentina</forename><surname>Pyatkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nouha</forename><surname>Dziri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Hans, are you clever? clever hans effect analysis of neural systems</title>
		<author>
			<persName><forename type="first">Leonardo</forename><surname>Ranaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Massimo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zanzotto</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SEM@ACL</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Causal protein-signaling networks derived from multiparameter single-cell data</title>
		<author>
			<persName><forename type="first">Karen</forename><surname>Sachs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Pe'er</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><forename type="middle">A</forename><surname>Lauffenburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garry</forename><forename type="middle">P</forename><surname>Nolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">308</biblScope>
			<biblScope unit="issue">5721</biblScope>
			<biblScope unit="page" from="523" to="529" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Testing the general deductive reasoning capacity of large language models using ood examples</title>
		<author>
			<persName><forename type="first">Abulhair</forename><surname>Saparov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">Yuanzhe</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishakh</forename><surname>Padmakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehran</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Najoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>NeurIPS</publisher>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Bayesian networks: with examples in R</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Scutari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Denis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Causalgraph2llm: Evaluating llms for causal queries</title>
		<author>
			<persName><forename type="first">Ivaxi</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bahare</forename><surname>Fatemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.15939</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Com2sense: A commonsense reasoning benchmark with complementary sentences</title>
		<author>
			<persName><forename type="first">Shikhar</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nuan</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pegah</forename><surname>Alipoormolabashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Te-Lin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning in probabilistic expert systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><surname>Spiegelhalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian statistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="447" to="465" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Head-to-tail: How knowledgeable are large language models (llms)? aka will llms replace knowledge graphs?</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwen</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 Conference of the North American Chapter</title>
		<meeting>the 2024 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Unicausal: Unified benchmark and repository for causal text mining</title>
		<author>
			<persName><forename type="first">Fiona</forename><surname>Anting Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">See-Kiong</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Big Data Analytics and Knowledge Discovery</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="248" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">On the testable implications of causal models with hidden variables</title>
		<author>
			<persName><forename type="first">Jin</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Azhar</surname></persName>
		</author>
		<idno>arXiv</idno>
		<title level="m">Llama: Open and efficient foundation language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Neuropathic pain diagnosis simulator for causal discovery algorithm evaluation</title>
		<author>
			<persName><forename type="first">Ruibo</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Bertilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hedvig</forename><surname>Kjellstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Lewis</forename><surname>Tunstall</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Edward</forename><surname>Beeching</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nathan</forename><surname>Lambert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nazneen</forename><surname>Rajani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Younes</forename><surname>Belkada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Shengyi</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Leandro</forename><surname>Von Werra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Clémentine</forename><surname>Fourrier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nathan</forename><surname>Habib</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
	<note>et al. 2023. Zephyr: Direct distillation of lm alignment. arXiv</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Planbench: An extensible benchmark for evaluating large language models on planning and reasoning about change</title>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Valmeekam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Marquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Olmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarath</forename><surname>Sreedharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subbarao</forename><surname>Kambhampati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="38975" to="38987" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Causal diagrams for empirical legal research: a methodology for identifying causation, avoiding bias and interpreting results</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tyler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Vanderweele</surname></persName>
		</author>
		<author>
			<persName><surname>Staudt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Law, Probability &amp; Risk</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="329" to="354" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">Aniket</forename><surname>Vashishtha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gowtham</forename><surname>Abbavaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saketh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><surname>Bachu</surname></persName>
		</author>
		<title level="m">Vineeth N Balasubramanian, and Amit Sharma. 2023. Causal inference using llm-guided discovery</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Scientific discovery in the age of artificial intelligence</title>
		<author>
			<persName><forename type="first">Hanchen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianfan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanqi</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kexin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Payal</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengchao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Van Katwyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreea</forename><surname>Deac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">620</biblScope>
			<biblScope unit="issue">7972</biblScope>
			<biblScope unit="page" from="47" to="60" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Fangzhi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qika</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianzhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<title level="m">Are large language models really good logical reasoners? a comprehensive evaluation from deductive, inductive and abductive views</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">Yudong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pashootan</forename><surname>Vaezipoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Sanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><forename type="middle">B</forename><surname>Khalil</surname></persName>
		</author>
		<title level="m">Llms and the abstraction and reasoning corpus: Successes, failures, and the importance of object-based representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Unveiling the generalization power of fine-tuned large language models</title>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yumeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL:HLT</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Kola: Carefully benchmarking world knowledge of large language models</title>
		<author>
			<persName><forename type="first">Jifan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaozhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shangqing</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shulin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zhang-Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanming</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Dag-gnn: Dag structure learning with graph neural networks</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7154" to="7163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Rock: Causal inference principles for reasoning about commonsense causality</title>
		<author>
			<persName><forename type="first">Jiayao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="26750" to="26771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<idno>arXiv</idno>
		<title level="m">Reasoning about goals, steps, and temporal ordering with wikihow</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Lin</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghao</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Li</surname></persName>
		</author>
		<idno>arXiv</idno>
		<title level="m">Eric Xing, et al. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Least-to-most prompting enables complex reasoning in large language models</title>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Relying on the unreliable: The impact of language models</title>
		<author>
			<persName><forename type="first">Kaitlyn</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jena</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>reluctance to express uncertainty. arXiv</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
