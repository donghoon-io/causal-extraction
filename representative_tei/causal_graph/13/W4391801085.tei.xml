<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Conditional Generative Models are Sufficient to Sample from Any Causal Effect Estimand</title>
				<funder ref="#_YhRgZXx">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_TuXFKdT">
					<orgName type="full">Amazon Research Award and Adobe Research</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-10-31">31 Oct 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Md</forename><forename type="middle">Musfiqur</forename><surname>Rahman</surname></persName>
							<email>rahman89@purdue.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Purdue University</orgName>
								<orgName type="institution" key="instit2">University of Texas at Austin</orgName>
								<orgName type="institution" key="instit3">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matt</forename><surname>Jordan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Purdue University</orgName>
								<orgName type="institution" key="instit2">University of Texas at Austin</orgName>
								<orgName type="institution" key="instit3">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Murat</forename><surname>Kocaoglu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Purdue University</orgName>
								<orgName type="institution" key="instit2">University of Texas at Austin</orgName>
								<orgName type="institution" key="instit3">Purdue University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Conditional Generative Models are Sufficient to Sample from Any Causal Effect Estimand</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-10-31">31 Oct 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2402.07419v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Causal inference from observational data plays critical role in many applications in trustworthy machine learning. While sound and complete algorithms exist to compute causal effects, many of them assume access to conditional likelihoods, which is difficult to estimate for high-dimensional (particularly image) data. Researchers have alleviated this issue by simulating causal relations with neural models. However, when we have high-dimensional variables in the causal graph along with some unobserved confounders, no existing work can effectively sample from the un/conditional interventional distributions. In this work, we show how to sample from any identifiable interventional distribution given an arbitrary causal graph through a sequence of push-forward computations of conditional generative models, such as diffusion models. Our proposed algorithm follows the recursive steps of the existing likelihood-based identification algorithms to train a set of feedforward models, and connect them in a specific way to sample from the desired distribution. We conduct experiments on a Colored MNIST dataset having both the treatment (X) and the target variables (Y ) as images and sample from P (y|do(x)). Our algorithm also enables us to conduct a causal analysis to evaluate spurious correlations among input features of generative models pre-trained on the CelebA dataset. Finally, we generate high-dimensional interventional samples from the MIMIC-CXR dataset involving text and image variables.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Causal inference has recently attracted significant attention in machine learning (ML) due to its application in fairness, invariant prediction, and explainability <ref type="bibr" target="#b58">[60,</ref><ref type="bibr" target="#b60">62,</ref><ref type="bibr" target="#b47">49]</ref>. Even though existing ML models show notable predictive performance by optimizing the likelihood of the training data, they are prone to failure when the covariate distribution changes in the test domain. Consider the medical scenario in Fig. <ref type="figure" target="#fig_1">1a</ref> with the causal order: Xray(X)→Diagnosis(S)→Report(R) representing the true data-generating mechanisms. Suppose a practitioner observes only X to make a high-level intermediate diagnosis S that contains sufficient information about the patient. The prescription report(R) is written only based on the diagnosis (thus X ̸ → R). Since data are collected from different hospitals locations (H), H acts as an unobserved common cause for both X and R, i.e., X ↔ R (ex: correlation between x-ray artifacts and report writing style). The task is "x-ray to report" generation. One might train an ML model to directly learn a mapping f : X → R, with maximum likelihood estimation (MLE) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10]</ref> mimicking the conditional distribution P (r|x). However, since H is an unobserved common cause between X and R; H has some influence on P (r|x) <ref type="bibr" target="#b8">[9]</ref>. Thus, if the model is deployed in a new location, its MLE-based prediction accuracy may drop since P (r|x) shifts in that location. On the other hand, if we can remove the location bias X ↔ R with an intervention on the x-ray variable (do(x)), the x-ray to report generation would be invariant to domain shifts. Thus, to obtain such generalization, we need to perform causal interventions in high-dimension.  Structural causal models (SCM) <ref type="bibr">[38]</ref> enable a data-driven approach to estimate interventional distributions <ref type="bibr" target="#b41">[43,</ref><ref type="bibr" target="#b29">30]</ref>. Given the qualitative causal relations, summarized in a causal graph, we now have a complete understanding of which causal effects/queries (ex: P (r|do(x))) can be uniquely identified from the observational distribution and which require further assumptions or experimental data <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b44">46,</ref><ref type="bibr" target="#b48">50]</ref>. More precisely, if all conditional probability tables are available, sound and complete identification algorithms <ref type="bibr" target="#b49">[51,</ref><ref type="bibr" target="#b44">46]</ref> can perform exact inference to estimate causal effects or <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b24">25]</ref> can sample from the interventional distribution, using a combination of marginalization and product operators applied to those conditional distributions. However, such approaches struggle to deal with high-dimensional variables. In Fig. <ref type="figure" target="#fig_1">1a</ref>, we could intervene on x-ray X and estimate its effect on the report R as, P (r|do(x)) = s P (s|x) x ′ P (x ′ )P (r|x ′ , s), i.e., as functions of the observational distribution (X, X ′ : independent instances of the same variable). However, the second and third terms in this expression require marginalization over the "X-ray" variable. Exact Bayesian inference methods used for calculating conditional distributions are infeasible for high-dimensional variables since marginalization over their non-parametric distributions is generally intractable <ref type="bibr" target="#b5">[6]</ref>.</p><p>Deep generative models with variational inference methods approximate the intractable marginalization and can sample from such high-dimensional distributions <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b45">47,</ref><ref type="bibr" target="#b13">14]</ref>. Recent works such as Xia et al. <ref type="bibr" target="#b57">[59]</ref>, Chao et al. <ref type="bibr" target="#b10">[11]</ref>, Rahman and Kocaoglu <ref type="bibr" target="#b38">[40]</ref> employ deep generative models to match joint distribution of the system by learning the conditional generation of each variable from its causal parents. Nonetheless, it is highly non-trivial for these works to mimic any arbitrary causal model with high-dimensional variables, specially when there are unobserved confounders in the (semi-Markovian) causal model. Consider the X ↔ R relation in Fig. <ref type="figure" target="#fig_1">1a</ref> where R and X are correlated through unobserved hospital location. To learn the joint distribution P (x, r), the above approaches need to synchronously train their generative models. For that purpose, Xia et al. <ref type="bibr" target="#b57">[59]</ref>, Rahman and Kocaoglu <ref type="bibr" target="#b38">[40]</ref> train two GAN networks concurrently by feeding the same prior noise. However, it is nontrivial to design a loss function for the joint distribution balancing multiple high-dimensional variables making it challenging for the discriminator to detect true/false sampled pairs. Thus, the high-dimensional intervention problem still requires a more effective approach.</p><p>In this paper, we propose a novel algorithm ID-GEN that can utilize any (conditional) generative models (such as GANs or diffusion models) to perform high-dimensional interventional sampling in the presence of latent confounders. For this purpose, we resort to the sound and complete identification algorithm <ref type="bibr" target="#b48">[50,</ref><ref type="bibr" target="#b44">46]</ref> and design our algorithm on top of its structure to sample from any identifiable causal query which may have an arbitrarily complex probabilistic expression (ex: Eq. 1). More precisely, given a causal graph, training data, and a causal query, our algorithm i) follows the recursive trace of the ID algorithm to factorize the query ii) trains a set of conditional models for each factor, iii) connects them to build a neural network called sampling network and generate interventional samples from this network. For example, to sample from P (r|do(x)) for the frontdoor graph in Fig. <ref type="figure" target="#fig_1">1</ref> (top), we i) utilize ID to obtain the factors: P (s|do(x)) and P (r|do(x, s)), ii) train conditional models {M S }, {M X ′ , M R } for the two factors (Fig. <ref type="figure" target="#fig_1">1b</ref>), iii) merge all models based on input-output (Fig. <ref type="figure" target="#fig_1">1c</ref>). Sampling according to this network's topological order would produce samples</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Identification algorithm (ID) and challenges with high-dimensional sampling</head><p>Shpitser and Pearl <ref type="bibr" target="#b44">[46]</ref> propose a recursive algorithm (Algorithm 6) for estimating an interventional distribution P x (y) given access to all probability tables. At any recursion level, it enters one of its four recursive steps: 2, 3, 4, 7 and three base case steps: 1, 5, 6 . Below, we discuss them in detail.</p><p>Step 1 occurs when the intervention set X is empty in P x (y). The effect of X = ∅ on Y is its marginal P (y) which is returned as output.</p><p>Step 2 checks if there exists any non-ancestor variable of Y in the intervention set X. Such variables in the graph do not have any causal effect on Y. Thus, it is safe to drop them. In Step 3, it searches for a set W in G, which does not effect Y assuming that X has already been intervened on. Thus, it can include W as an additional intervention set: X = X ∪ W. An intervention on W implies deleting its incoming edges, which simplifies the problem in the future.</p><p>Step 4 is the most important line and is executed when there are multiple c-components in the subgraph G \ X. It factorizes (decomposes) the problem of estimating P x (y) into estimating c-factors (subproblems) and performs recursive calls for each c-factor. Base case</p><p>Step 5 returns fail for non-identifiable queries. Base case Step 6 asserts that when X does not have a bi-directed edge with the rest of the nodes in S and S consists of a single c-component, intervening on X is equivalent to conditioning on X. Thus, ID can now solve P x (y) as s\y i|Vi∈S P (v i |v (i-1) π</p><p>) and return as output.</p><p>Step 7 occurs when the variables in X can be partitioned into two sets: one having bi-directed edges to other variables (S ′ ) in the graph and one (defined as X Z ) with no bi-directed edges to S ′ . In that case, evaluating P x (y) from P (V) is equivalent to first obtaining P ′ (V) := P x Z (V) and then evaluating P x\xz (Y ) from P ′ (V). Hence, P x Z (V) is first calculated as</p><formula xml:id="formula_0">{i|Vi∈S ′ } P (V i |V (i-1) π ∩ S ′ , v (i-1) π \ S ′</formula><p>) and then passed to the next recursive call for do(x \ x z ) to be applied. One major issue of ID is that it requires probability tables and thus cannot be applied for high-dimensional sampling. Suppose we naively design an algorithm that follows ID's recursive steps and trains a generative model for every factor it encounters and samples from it. This algorithm would not know which of these factors to learn and sample first, leading to a deadlock as shown in Ex C.1. ID-GEN solves such issue by avoiding direct sampling and building a sampling network. Definition 3.1 (Sampling network, H). A collection of feedforward models {M Vi } ∀i for a set of variables V = {V i } ∀i is said to form a sampling network, H, if the directed graph obtained by connecting each M Vi to M An(Vi) G via incoming edges according to some conditional distribution, is acyclic. Two sampling networks H i , H r can be merged into a larger network H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Recursive training of ID-GEN and interventional sampling</head><p>Similar to ID's recursive structure, ID-GEN has 7 steps (Algorithm 1). However, to deal with highdimensional variables, we call three new functions: i) Algorithm 2:ConditionalGMs(.) inside steps 1 and 6 where we train diffusion models or other conditional models to learn conditional distributions, ii) Algorithm 3:MergeNetwork(.) inside step 4 to merge the conditional models, and iii) Algorithm 4:Update(.) inside step 7 to train models that can apply part of the interventions and update the training dataset for next recursive calls. We initiate with ID-GEN (Y, X, G, D, X = ∅, Ĝ = G). Along with the given inputs Y, X, G, D, ID-GEN maintains two extra parameters X, Ĝ to keep track of the interventions performed. During the top-down phase, ID-GEN updates its parameters: by i) removing interventions from the intervention set X, and ii) updating the training dataset D, X and the causal graph G, Ĝ according to the interventions. At any level of recursion, an ID-GEN call returns a sampling network H (DAG of a set of trained models) trained on the dataset D to learn conditional distributions according to X, G, Ĝ. After the recursion ends, we can generate samples from P x (V), Y ⊆ V, by ancestral sampling on H. See a recursion tree in Appendix C.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Base Case:</head><p>Step 1: ID-GEN enters step 1 if the intervention X is empty. For X = ∅, we have, P x (y) = P (y) = v\y P (v) = v\y Vi∈V P (v i |v</p><formula xml:id="formula_1">(i-1) π</formula><p>) which is suitable for ancestral sampling. To train models that can collectively sample from this distribution, we call Algorithm 2:ConditionalGMs(.). Here, we train each model M Vi , ∀V i ∈ V using V (i-1) π , (i.e., variables that are located earlier in the topological order π) as inputs to match P (v i |v (i-1) π</p><p>). Note that X contains the values that were intervened in previous recursion levels and Ĝ is the graph at the current level that contains X with its incoming edges cut. Since we want our conditional models to generate samples consistent with the values of X, we consider the topological order of Ĝ while using V (i-1) π as inputs so that X are also fed as input while training. After training, we connect the trained models according to their input-outputs to build a sampling network H and return it (Alg 2:lines 1-6). Note that when all variables in Y are low dimensional, we can also learn a single model M to sample P (Y). However, for high-dimensional variables, matching such joint distributions is non-trivial <ref type="bibr" target="#b38">[40]</ref>.</p><p>Step 2 &amp; 3: We follow the same steps of the ID algorithm as discussed in Section 3.1.</p><formula xml:id="formula_2">X W 1 W 2 Y M W2 M X ′ M Y M W1 X W 1 W 2 Y M W2 M X ′ M Y M W1 do(x) Y Figure 2: ↔:Unobserved. Left blue samples from P x,w2 (w 1 , y) = P (w 1 |x) P (y|x, w 1 , w 2 ).</formula><p>Right blue samples from P x,w1 (w 2 ) = x ′ P (x ′ ) P (w 2 |x ′ , w 1 ). Joint network samples from P x (y).</p><p>Step 4 and Merge sampling Networks: Our goal is to train models that can sample from P x (y) which unfortunately is not straightforward. This step allows us to decompose our problem into sub-problems and we can train models to sample from the c-factors of P x (y)'s factorization. The next challenge is to connect these models consistently to sample from P x (y). More precisely, if we remove X from G and the graph splits into multiple c-components (variables in each component connected with ↔) (Alg 1:line 11), we can apply c-component factorization (Lemma D.7, <ref type="bibr" target="#b49">[51]</ref>) to factorize P x (y) as v\(y∪x) P v\s1 (s 1 ) . . . P v\sn (s n ) where each {S k } k is the c-factor corresponding to each c-component. To obtain trained models for each of these c-factors, we perform the next recursive calls: ID-GEN (Y = S i , X = V \ S i , G, D, X, Ĝ). When these recursive calls return a sampling network H i for each P v\si (s i ), we can wire them based on their input-output to build a single sampling network H. According to Theorem D.21 and D.22, H now can sample from P x (y).</p><p>We call Algorithm 3: MergeNetwork(.) to connect all sampling networks {H i } ∀i . Here, each H i is a set of trained conditional models {M Vj } j connected to each other as a DAG. If a sampling network H i contains an empty node M Vj = ∅ without any conditional model and some other sampling network H r generates this variable V j with its node M V k , i.e., V j = V k , then we combine M Vj and M V k into the same node to build a connection between H i and H r (lines 3-6). Intuitively, due to the c-factorization at this step, the variables intervened in one sampling network might be generated from models in another network. We connect two networks to continue the ancestral sampling sequence. Fig. <ref type="figure" target="#fig_9">2</ref> shows an example of this step where P x (y) is factorized into c-factors as P x (y) = w1,w2 P x,w1 (w 2 )P x,w2 (w 1 , y). For the c-component {W 1 , Y }, ID-GEN first obtains P x,w2 (w 1 , y) = P (w 1 |x)P (y|x, w 1 , w 2 ), and trains conditional models M W1 and M Y for these conditional distributions. Similarly, for {W 2 }, we have P x,w1 (w 2 ) = x ′ P (x ′ )P (w 2 |x ′ , w 1 ) and we train M X ′ and M W2 . Finally, we merge these networks based on inputs-outputs to build a single sampling network and perform ancestral sampling on it to sample from P x (y), ∀x.</p><p>Base Case: Step 5: We follow the step 5 of the ID algorithm as discussed in Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Base Case:</head><p>Step 6: We enter Step 6 if G \ X is a single c-component S, and X is located outside the c-component. This situation allows us to replace the intervention on X by conditioning on</p><formula xml:id="formula_3">X: P x (y) = s\y Vi∈S P (v i |v (i-1) π</formula><p>). This step is similar to step 1, except that now we have a non-empty intervention set, i.e., X ̸ = ∅. Here, we consider the topological order of Ĝ and V (i-1) π contains both X and X. We call Algorithm 2:ConditionalGMs(.) which trains multiple conditional models to learn the above distribution. More precisely, we utilize classifier-free diffusion guidance for conditional training of each M Vi by taking the gradient step on ∇ θ ||ϵ θ (z i λ , v</p><formula xml:id="formula_4">(i-1) π ) -ϵ|| 2 .</formula><p>Here, z i λ is the noisy version of V i at time step λ during the forward process and v (i-1) π is the condition (see Background). Finally, we connect the input-output of these diffusion models according to the topological order to build a sampling network and return it as output. Note that for any specific conditional distribution, if we have access to a pre-trained models that can sample from it, we can directly plug it in the network instead of training it from scratch (motivated from <ref type="bibr" target="#b38">[40]</ref>).</p><p>Step 7: Here, ID-GEN partitions X into two sets: one is applied in the current step to update the training dataset and other parameters, and the other is kept for future steps. It performs this step if i) G \ X is a single c-component S and ii) S is a sub-graph of a larger c-component S ′ in the whole graph G, i.e, (S = C(G \ X)) ⊂ (S ′ ∈ C(G)). For example, in Fig. <ref type="figure">3</ref>, for P w1,w2,x (y), we have</p><formula xml:id="formula_5">S = G \ {W 1 , W 2 , X} = {Y }, S ′ = {W 1 , X, Y }.</formula><p>In this step, we call Algorithm 4: Update(.)</p><formula xml:id="formula_6">Algorithm 1 ID-GEN (Y, X, G, D, X, Ĝ)</formula><p>1: Input: target Y, to be intervened X, intervened variables at step 7s X, causal graph G without X, causal graph Ĝ with X having no parents, training data D[ Ĝ] sampled from observed distribution P (V).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2:</head><p>Output: A sampling network of trained models.</p><formula xml:id="formula_7">3: if X = ∅ then {Step 1} 4: Return ConditionalGMs(Y,X = ∅,G,D, X, Ĝ) 5: if V \ An(Y)G ̸ = ∅ then {Step 2} 6: Return ID-GEN(Y, X ∩ An(Y)G, G An(Y) , X, ĜAn(Y) , D ′ = D[An(Y)G] ) 7: Let W = (V \ X) \ An(Y)G X {Step 3} 8: if W ̸ = ∅ then 9: Return ID-GEN(Y, X = X ∪ W, G, X, Ĝ, D) 10: if C(G \ X) = {S1, . . . , S k } then {Step 4} 11: for each Si ∈ C(G \ X) = {S1, . . . , S k } do 12: Hi=ID-GEN(Si, X = V \ Si, G, X, Ĝ, D) 13: Return MergeNetwork({Hi} ∀i ) 14: if C(G \ X) = {S} then 15: if C(G) = {G} then {Step 5} 16: throw FAIL 17: if S ∈ C(G) then {Step 6} 18: Return ConditionalGMs(S, X, G, D, X, Ĝ) 19: if (∃S ′ ) such that S ⊂ S ′ ∈ C(G) then {S7} 20: Return ID-GEN(Update(S ′ ,X,G,D, X, Ĝ))</formula><p>Algorithm 2 ConditionalGMs(Y,X,G,D, X, Ĝ) MV j = MV k 7: Return H = {Hi} ∀i {All Hi are connected.} Algorithm 4 Update(S ′ , X, G, D, X, Ĝ) Note that given access to probability tables, the ID can use any specific value X Z = x z to calculate P xz (v) to get the correct estimation of P x (y) (Verma constraint <ref type="bibr" target="#b52">[54,</ref><ref type="bibr" target="#b44">46]</ref>). In our case, if we use a specific value x z to sample the training dataset D ′ ∼ P xz (v), the models trained on this dataset in subsequent recursive steps will also depend on x z . However, during ancestral sampling in the returned network, a different value X Z = x ′ z might come from other c-components (ex: M Y (W 2 , .) in Fig. <ref type="figure">3</ref>). Thus, to make our trained models suitable for any values, we pick X Z from a uniform distribution or from P (X Z ) and generate D ′ accordingly. We save X Z in X, its values in D[ X, S ′ ] and in Ĝ{S ′ , X} with incoming edges removed, to be considered during training in the next recursive calls. Whenever ID-GEN visits Step 7 again, X will be applied along with the new X Z . Finally, a recursive call is performed with these updated parameters (line 4) which will return a network trained on dataset D ′ ∼ P xz (v). It can sample from P x∩S ′ (y) and equivalently from the original P x (y).</p><formula xml:id="formula_8">1: for each Vi ∈ {X ∪ X} do 2: Add node (Vi, ∅) to H {Initialized H = ∅} 3: for each Vi ∈ Y in the topological order π Ĝ do 4: Let MV i be a model trained on D[Vi, V (i-1) π ] such that MV i (V (i-1) π ) ∼ P (vi|v (i-1) π ) 5: Add node (Vi, MV i ) to H 6: Add edge Vj → Vi to H for all Vj ∈ V (i-1) π 7: Return H.</formula><formula xml:id="formula_9">1: XZ = X \ S ′ 2: H = ConditionalGMs(S ′ , XZ , G, D, X, Ĝ) 3: D ′ ∼ H(XZ , X); X = X ∪ X Z 4: Return Y, X ∩ S ′ , G S ′ , D ′ [ X, S ′ ], X,</formula><p>Algorithm simulation: We apply ID-GEN to sample from P w1 (y) for the causal graph G in Fig. <ref type="figure">3</ref>. Since G \ {W 1 } has three c-components {W 2 }, {X}, {Y }, we first call (i) step 4 of ID-GEN. P w1 (y) is factorized as: x,w2 P w1,x,y (w 2 ) P w1,w2,y (x) P w1,w2,x (y). Thus, step 4 will return the sampling networks {H W2 , H X , H Y } that can sample from each of these factors. Here, we focus only on H Y . ID-GEN reaches (ii) step 7 for the query: P w1,w2,x (y) since we have S = G \ {W 1 , W 2 , X} = {Y }, S ′ = {W 1 , X, Y } and S ⊂ S ′ . Here, sampling from P x,w1,w2 (y) in G, with observational training dataset is equivalent to sampling from P x,w1 (y) in Ĝ = G W2 with do(W 2 ) interventional data. With W 2 ∼ P (w 2 ), we generate D ′ ∼ P w2 (v) by calling step 6 (base case). We pass D ′ as the dataset parameter for the next recursive call. This step implies that if the recursive call returns a network that is trained on D ′ ∼ P w2 (v) and can sample from P x,w1 (y) , it can also be used to sample</p><formula xml:id="formula_10">W1 W2 X Y (i) Step 4 W1 X Y (iii) Step 2 W 1 W 2 X Y (ii) Step 7 G : X Y Ĝ : W 2 X Y (iv) Step 6 MW 2 W1 MX M W ′ 1 MY W2 X U nif [W2] MW 2 do(W1 = w1) MX M W ′ 1 MY</formula><p>Figure <ref type="figure">3</ref>: (Left: top-down) P w1 (y) is factorized into P w1,x,y (w 2 ), P w1,w2,y (x) and P w1,w2,x (y) (Step 4). Steps 7, 2, 6 is shown for P w1,w2,x (y) only. (Right: bottom-up) we combine the sampling networks of each c-factor. For any do(W 1 = w 1 ), we use H to get samples from P w1 (y).</p><p>from P w1,w2,x (y). Next, since W 1 / ∈ An(Y ) G , at (iii) step 2, we drop W 1 from all parameters before the next recursive call. We are at the base case (iv) step 6 with Ĝ : W 2 → X → Y . Thus, we train a conditional model M Y (W 2 , X) on D ′ [W 2 , X, Y ] that can sample from P (y|w 2 , x). This would be returned as H Y at step 4 (Fig. <ref type="figure">3</ref>:green). Similarly, we can obtain sampling network H W2 and H X to sample from P w1,x,y (w 2 ) = P (w 2 |w 1 ) and P w1,w2,y (x) = w ′ 1 P (x|w ′ 1 , w 2 )P (w ′ 1 ) (Fig. <ref type="figure">3</ref>:blue). We connect these networks and perform ancestral sampling with fixed w 1 for do(W 1 = w 1 ).</p><p>(Un)conditional sampling and complexity: ID-GEN returns a sampling network H when recursion ends. For unconditional query P x (y), we fix X = x in H and perform ancestral sampling to generate joint samples. We pick the Y values in these joint samples (equivalent to marginalization in ID) and report as interventional samples. For a conditional query P x (y|z), ID-GEN uses the sampling network to first generate samples D[X, Z, Y] ∼ P x (y, z) and then train a new conditional model M Y (X, Z) on D to sample from Y ∼ P x (y|z) (Alg.5:IDC-GEN). The sampling network has O(|An(Y) G |) number of models and requires O(|An(Y) G |) time to sample from it. Please, see our complexity details in Appendix C.5, Appendix C.6. Theorem 3.2. Under Assumptions: i) the SCM is semi-Markovian, ii) we have access to the ADMG, iii) P (V) is strictly positive and iv) trained generative models sample from correct distributions, ID-GEN and IDC-GEN are sound and complete to sample from any identifiable P x (y) and P x (y|z).</p><p>Note that although existing work can sample from (low-dimensional) distributions, Theorem 3.2, makes ID-GEN, to our knowledge, the first method to use only feed-forward models to provably sample from identifiable high-dimensional interventional distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>To illustrate ID-GEN's capabilities with high-dimensional image and text variables, we evaluate it on semi-synthetic: Colored MNIST and real-world: CelebA and MIMIC-CXR datasets. We provide additional details in Appendix F. Codes are available at github.com/musfiqshohan/idgen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">ID-GEN performance on napkin-MNIST dataset and baseline comparison</head><p>Setup: We consider a semi-synthetic Colored-MNIST dataset for the napkin graph <ref type="bibr" target="#b37">[39]</ref> in Fig. <ref type="figure" target="#fig_2">4</ref> with image variables W 1 , X, Y and paired discrete variable W 2 . Here, X and Y inherit the same digit value as image W 1 which is propagated through discrete W 2 .d ∈ [0 -9]. X is either red or green which is also inherited from W 1 through discrete W 2 .c, i.e., W 1 .color : {r, g, b, y, m, cy} → W 2 .c : {0, 1} → X.color : {r, g}. Unobserved U color makes W 1 and Y correlated with the same color, and unobserved U thickness makes W 1 and X correlated with the same thickness. Even though image X (takes r and g) is a direct ancestor of image Y (takes all 6 colors), Y only inherits the digit property from X but correlates the color property with image W 1 . This color correlation between W 1 and Y is created by Ucolor. All mechanisms include 10% noise. Our target is to sample from P x (y).</p><p>Training and evaluation: We follow ID-GEN steps: <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b5">6]</ref>. Step 3 implies P x (y) = P x,w1,w2 (y), i.e., intervention set ={X, W 1 , W 2 }. Step 7 suggests to generate do(W 2 ) interventional dataset D ′ [W 1 , W 2 , X, Y ] ∼ P w2 (w 1 , x, y) = P (w 1 )P (x, y|w 1 , w 2 ). To obtain D ′ , we i) sample W 1 ∼ P (w 1 ), and ii) train a conditional diffusion model to sampling from P (x, y|w 1 , w 2 ) with arbitrary W 2 values. Next, Step 2 drops non-ancestor W 1 and Step 6 trains a diffusion model M Y (x, w 2 ) on the new dataset D ′ to sample from P ′ (y|x, w 2 ). M Y (x, w 2 ) is returned as output that can sample from P x (y),∀w 2 . We compare our performance with three baselines: i) a classifier-free diffusion  model that samples from the (Cond)itional distribution P (y|x), ii) the DCM algorithm <ref type="bibr" target="#b10">[11]</ref> that uses diffusion models to samples from P x (y) but without confounders, and iii) the NCM algorithm <ref type="bibr" target="#b56">[58]</ref> that uses GANs and considers confounders. We performed do(x) intervention with two images, i) digit 3 and ii) digit 5, both colored red. In Fig. <ref type="figure" target="#fig_2">4</ref>, we show interventional samples for each method alongside their FID scores representing the image quality (lower:better). The (Cond) model (row 1, 5), DCM (row 2, 6) and our algorithm (row 5, 8) all generate good quality images of digit 3 and digit 5 with a specific color. However, the NCM algorithm (row 3, 7) generates images with blended colors (such as green + red). We observe that ID-GEN achieves the lowest FID scores (25.66 and 22.67), showing the ability to generate high-quality images consistent with the dataset. Whereas, Cond and DCM generate almost the same structure for all digits lacking variety, which explains their high FID. Note that do(x) removes the color bias between X and Y along the backdoor path. Thus, interventional samples should show all colors with uniform probability. Since Cond and DCM can not deal with confounders they show bias towards R, G, B colors of Y for red X. ID-GEN removes such bias and balances different colors (Fig. <ref type="figure" target="#fig_2">4</ref>). For a more rigorous evaluation, we use the effectiveness metric proposed in <ref type="bibr" target="#b33">[34]</ref> and employ a classifier to map all generated images to discrete analogues (Digit, Color, T hickness) and compute exact likelihoods. We compare them with our ground truth P (Y.color|do(x)) (uniform) and display these results for the color attribute in Fig. <ref type="figure" target="#fig_2">4</ref>(right). We emulate the interventional distribution more closely with a low total variation distance: 0.25 compared to the baselines Cond (0.54) and DCM (0.58). We skip classifying colors of NCM as they are blended.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluating</head><p>CelebA image translation models with ID-GEN  Setup: We apply ID-GEN to evaluate multidomain image translation of some existing generative models (ex: Male to Female domain translation). We examine whether they apply causal changes in (facial) attributes or add unnecessary changes due to the spurious correlations among different attributes they picked up in the training data. Our application is motivated by Goyal et al. <ref type="bibr" target="#b14">[15]</ref>, who generate counterfactual images to explain a pre-trained classifier while we examine pre-trained image generative models. We employ two generative models that are trained on CelebA dataset <ref type="bibr" target="#b28">[29]</ref>: i) StarGAN <ref type="bibr" target="#b11">[12]</ref> and ii) EGSDE <ref type="bibr" target="#b62">[64]</ref> (an approach that utilizes energyguided stochastic differential equations). We assume the graph in Fig. <ref type="figure" target="#fig_3">5</ref> where the original image I 1 causes its own attributes Male and Young. We consider an unobserved confounder between them, as in the dataset, men are more likely to be old (correlation coeff=0.42, <ref type="bibr" target="#b42">[44]</ref>) and a classifier might have some bias toward predicting young-male images as oldmale. These attributes along with the original image are used to generate a translated image I 2 . Next, P 1 and P 2 are 40 CelebA attributes of I 1 and I 2 . A is the difference between P 1 , P 2 , i.e., the additional attributes (ex: makeup) that gets added to I 2 but are absent in I 1 during translation. We estimate P Male=0 (A), i.e., the causal effect of changing the domain from Male to Female on the appearance of a new attribute. We connect these models to build the sampling network in Fig. <ref type="figure" target="#fig_3">5</ref>. We can now perform ancestral sampling in the network with Male = 0 and generate samples of I 2 . Next, we use a classifier to obtain 40 attributes of I 1 and I 2 as P 1 and P 2 . Finally, we obtain the added attributes, A by comparing P 1 and P 2 and report the proportion as the estimate of P Male=0 (A). Similarly, we also estimate the conditional query, P Male=0 (A|Y ), using StarGAN with Y = 1 fixed.</p><formula xml:id="formula_11">I 1 P 1 I 2 P 2 A M ale Y oung(Y ) MI 2 MY MI 1 M ale = 0 I2 W e a ri</formula><p>In Fig. <ref type="figure" target="#fig_3">5</ref>, we show top 9 most appeared attributes. We observe that EGSDE introduces both causal (ex: WearingLipstick to 82%, HeavyMakeup to 69.28% of all images) and non-causal attributes (ex:Attractive to 37.61% and Young to 24.76%) with high probability. The model might assign high-probability to non-causal attributes because they were spuriously correlated in the CelebA training dataset (ex: sex and age). On the other hand, StarGAN and conditional StarGAN introduce new attributes with a low probability (≤ 30%) even if they are causal which is also not preferred. These evaluations enabled by ID-GEN help us to understand the fairness or bias in the prediction of image translation models. Finally, for the conditional query P Male=0 (A|Y ), StarGAN translates 54.68% of all images as Young, Female which is consistent. In Appendix F.3, we discuss how baselines deal poorly with these queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Invariant prediction with foundation models for chest X-ray generation</head><p>Setup: In this section, we demonstrate ID-GEN's utility to intervene with a text variable and generate images from the corresponding interventional distribution. Due to the lack of high-quality, annotated medical imaging datasets, the task of generating X-ray images (X) from the prescription reports (R) is recently being investigated. Consider the report-to-Xray generation task shown in Fig. <ref type="figure" target="#fig_4">6</ref>. The shown causal graph is designed based on the MIMIC-CXR dataset <ref type="bibr" target="#b23">[24]</ref> (see Appendix F.4 for details). Existing works <ref type="bibr" target="#b9">[10]</ref> solve this task by using vision-language foundation models to directly generate CXR images conditioned on text prompts (or report): P (X|R)(Fig. <ref type="figure" target="#fig_4">6 left</ref>). These models can generate images satisfying the prompt attributes (ex: effusion). However, they ignore the status of other attributes caused by prompt attributes (effusion→atelectasis) that might implicitly contribute to generate the image. Moreover, these models are trained on multiple datasets collected from different locations, which could introduce different types of bias <ref type="bibr" target="#b8">[9]</ref>. For example, in many scenarios, patients with severe pneumonia are transferred to a different hospital and receives critical reports. Thus, there exists a potential confounding bias between report (R) writing style and pneumonia prevalence (N ) in a specific location (H) i.e. R ← H → N . The direct R → X prediction of the above mentioned conditional models might absorb the backdoor bias: R ← H → N → ... → X and get affected if P (R, N ) shifts in a new location. We aim to make the image generation task of such models, interpretable and invariant in the test domain. Therefore, we consider the same input (report variable) and output (X-ray image) as such these models. For this purpose, ID-GEN performs do(R) intervention to remove the backdoor bias and infer attributes from the interventional distribution. Now these attributes are used to generate the final images (motivated by <ref type="bibr" target="#b46">[48,</ref><ref type="bibr" target="#b26">27]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and Evaluation:</head><p>We indicate attribute extraction with outgoing edges from report R and image generation with incoming edges to X-ray X. We assume pneumonia infection N affects other attributes. For our target query P R (N, E, A, L, X), ID-GEN first visits step 4 and factorizes it as P R (N, E, A, L, X) = P (N )P R,N (E)P R,N,E (A)P R,N,E,A (L)P E,A,L (X). ID-GEN goes to step 6 for each, converts them to conditional distributions and trains corresponding models or use pre-trained ones for M N , M E , M A , M L , M X . We utilize an LLM labeler <ref type="bibr" target="#b15">[16]</ref> that can only extract attributes E, A, L from the report R (thus R ̸ → N ). If R explicitly mentions E, A, L then the models M E , M A , M L output 1. Otherwise, they probabilistically infer their output conditioned on parent attributes in the causal graph. The models we train are able to converge to their conditional distribution with a low total variation distance (≈ 0.05). We utilize a stable diffusion-based model <ref type="bibr" target="#b9">[10]</ref> as M X to sample X ∼ P E,A,L (X). After ID-GEN connects all models, we intervene with a prompt, infer all attributes along with their empirical distribution and generate corresponding X-rays. In Fig. <ref type="figure" target="#fig_4">6</ref> (right), we show our results for the prompt intervention do(R =left pleural fluid persists). For better visualization, we also condition on N = 0 and N = 1 separately. First, the LLM labeler extracts effusion (E = 1) from the prompt. Next, ancestral sampling with E = 1 in the sampling network provides us with the top 3 most probable attribute combination (N = 0/1, E = 1, A, L) and their corresponding images. In Fig. <ref type="figure" target="#fig_4">6</ref>, we provide (i) a healthy image, (ii) image generated by baseline <ref type="bibr" target="#b9">[10]</ref>, and (iii)-(v) images generated with ID-GEN and their attributes with empirical probabilities. ID-GEN makes these predictions interpretable while facilitating them to be invariant with domain shifts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>Shalit et al. <ref type="bibr" target="#b41">[43]</ref>, Louizos et al. <ref type="bibr" target="#b29">[30]</ref>, Zhang et al. <ref type="bibr" target="#b61">[63]</ref>, Vo et al. <ref type="bibr" target="#b53">[55]</ref> propose novel approaches to solve the causal effect estimation problem using variational autoencoders. Their proposed solution and theoretical guarantees are tailored for specific causal graphs containing treatment, effect, and covariates (or observed proxy variables), where they can apply the backdoor adjustment formula. Sanchez and Tsaftaris <ref type="bibr" target="#b40">[42]</ref> employ DDPMs <ref type="bibr" target="#b21">[22]</ref> to generate high-dimensional interventional samples, but only for bivariate models. Kocaoglu et al. <ref type="bibr" target="#b25">[26]</ref> perform adversarial training on a collection of conditional generative models following the topological order to sample from interventional distributions. Pawlowski et al. <ref type="bibr" target="#b34">[35]</ref> employ a conditional normalizing flow-based approach to offer high-dimensional interventional sampling as part of their solution. Chao et al. <ref type="bibr" target="#b10">[11]</ref> designs diffusionbased causal models for arbitrary causal graphs with classifier-free guidance <ref type="bibr" target="#b20">[21]</ref>. However, these works have limited applications due to their strong assumption of no latent confounders in the system. Xia et al. <ref type="bibr" target="#b56">[58]</ref> propose a similar training process as Kocaoglu et al. <ref type="bibr" target="#b25">[26]</ref> in the presence of hidden confounders. They show explicit connections with the Causal Hierarchy Theorem <ref type="bibr" target="#b2">[3]</ref> and formalize the identification problem with neural models. However, it is difficult to match an arbitrary highdimensional distribution, and their joint GAN training approach may suffer from convergence issues. Rahman and Kocaoglu <ref type="bibr" target="#b38">[40]</ref> utilizes a modular algorithm to relax the joint training restriction for specific structures, but might face the convergence issue when the number of high-dimensional variables increases. Note that these methods are not suitable for efficient conditional sampling. Jung et al. <ref type="bibr" target="#b24">[25]</ref> convert the expression returned by identification algorithm <ref type="bibr" target="#b49">[51]</ref> into a form where it can be computed through a re-weighting function to allow sample-efficient estimation. Similarly Bhattacharyya et al. <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> utilize bounded number of samples from the observational distribution to construct an interventional sampler. However, computing these reweighting functions/conditional distributions from data is still highly nontrivial with high-dimensional variables. Zečević et al. <ref type="bibr" target="#b59">[61]</ref> models each probabilistic term in the expression obtained for P (y|do(x)) with (i)SPNs. However, they require access to the interventional data and do not address identification from only observations. Wang and Kwiatkowska <ref type="bibr" target="#b54">[56]</ref> design a novel probabilistic circuit architecture to encode the target causal query and estimate causal effects but do not offer high-dimensional sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We propose a sound and complete algorithm to sample from conditional or unconditional highdimensional interventional distributions. Our approach is able to leverage the state-of-the-art conditional generative models by showing that any identifiable causal effect estimand can be sampled from efficiently, only via feed-forward models. In future, we aim to relax our assumption on access to the ADMG and adapt our algorithm to deal with soft interventions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Limitations and future work</head><p>In this section, we list some future directions of our work. i) We assume that we have access to the fully specified causal graph (ADMG) and the causal model is semi-MarkoviaN. Although these are common assumptions in causal inference, we aim to extend our algorithm for structures with more uncertainty (ex: PAGs). ii) In certain cases, the identification algorithm acts on particular variables, yet the expression for the causal effect does not depend on these variables. However, given that our sample size is limited, distinct values of these variables could affect the accuracy of the causal effect <ref type="bibr" target="#b18">[19]</ref>. Since our algorithm follows the same recursive trace as the identification algorithm, it might suffer from the same problem. In addition, some model training might be unnecessarily performed due to this issue. To avoid this scenario, the pruning algorithm proposed in <ref type="bibr" target="#b51">[53]</ref> might be merged with us to reduce the redundant cost of model training. iii) Since we target a specific causal query, if the query is substantially changed (causal effect on new variables), we might have to re-train some models. iv) For causal effect estimation in high-dimension, we follow the ID algorithm <ref type="bibr" target="#b43">[45]</ref> to consider a hard intervention do(X = x) i.e., fixing a specific value of the intervened variable, and assume that the rest of the conditional distribution stays unchanged. An interesting future direction would be to consider imperfect/soft intervention where the underlying mechanism of intervention changes instead of being fixed to a specific value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Broader impact</head><p>During the last few years, researchers have proposed many deep learning-based approaches to learn the unknown structural causal model from available data and employ the learned model to estimate the causal effect or sample from the high-dimensional interventional distribution. However, all these methods propose solutions tailored to specific neural architectures. As a result, when better generative models appear (such as diffusion models), existing methods lack the flexibility to utilize them, and thus we are in need of a new causal sampling method to get benefits of the new architecture. ID-GEN proposes a generic method that is independent of any model architecture and can generate high-dimensional interventional samples with any model architecture (GANs, VAE, Normalizing flow, diffusion models, etc.) as long as that model has the ability to generate conditional samples. Thus, our algorithm would allow the causal community to always use the latest generative model for high-dimensional causal sampling-based applications.</p><p>On a different note, the ability to sample from interventional distributions may enhance deepgenerative models to obtain fake data, which can be exploited similarly to fake image generation. Since our algorithm considers causal relations among different variables, it has the ability to generate comparatively sensible and realistic fake images. Fake images can be a source of distress or might influence public actions and opinion. Thus, careful deployment of should be considered for deep causal generative models and the same procedures to detect fake image should be taken.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C ID-GEN additional discussion</head><p>In this section, we provide more details about our algorithm ID-GEN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Sampling from any interventional distribution with ID-GEN</head><p>Here we provide the full form of the causal query P (v|do(r)) for the graph in Figure <ref type="figure" target="#fig_6">7</ref>. Each term is expressed in terms of observational distribution. Note that it is nonintuitive and nontrivial for existing algorithms to sample from this complicated expression. Our algorithm ID-GEN solves this problem by training a specific set of models in a recursive manner and building a sampling network combining them. Finally, ID-GEN uses this network to sample from the following interventional distribution.</p><formula xml:id="formula_12">P (v|do(r)) = P (w 2 , w 3 |do(r))P (w 4 |do(w 3 ))P (w 1 |do(v \ {w 1 , x}))P (x|do(v \ {x})) = P (w 2 , w 3 |r) * P (w 4 |w 3 ) * r ′ P (w 1 |r ′ , w 2 , w 3 , w 4 )P (r ′ |w 3 , w 4 ) * r ′ P (w 1 , x|r ′ , w 2 , w 3 , w 4 )P (r ′ |w 3 , w 4 ) r ′ P (w 1 |r ′ , w 2 , w 3 , w 4 )P (r ′ |w 3 , w 4 )<label>(1)</label></formula><p>Symptoms (W 2 )  </p><formula xml:id="formula_13">Aging (W 3 ) Past illness (W 4 ) Xray Scan (X) Prescription Report (R) Detection &amp; Diagnosis (W 1 ) F a m il y H is to ry (F ) H o s p it a l L o c a ti o n (H ) (a) ML model failure scenario M W3 M W2 do(R = r) P (w 2 , w 3 |do(r)) M W4 P (w 4 |do(w 3 )) M X P (x|do(v \ {x, r})) M W1 P (w 1 |do(w 2 , w 3 , w 4 )) W 3 W 3 W 2 W 3 W 4 W 2 W 4 W 3 W 1 (b) Train and build sampling network. M W3 M W2 do(R = r) M W4 M X M W1 X W 3 W 3 W 2 W 2 W 4 W 1 W 4 W 3 (c)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Cyclic dependency dealt with ID-GEN</head><formula xml:id="formula_14">X W 1 W 2 Y MW 2 MX′ MY MW 1 X W1 W2 Y MW 2 MX′ MY MW 1 do(x) Y Figure 8: ↔:Confounding. M W1 , M Y sample from P x,w2 (w 1 , y) = P (w 1 |x) P (y|x, w 1 , w 2 ). M X ′ , M W2 sample from P x,w1 (w 2 ) = x ′ P (x ′ ) P (w 2 |x ′ , w 1 ). Joint network samples from P x (y).</formula><p>Example C.1 (Cyclic dependency). For the graph in Fig. <ref type="figure">8</ref>, P x (y) does not fit any familiar criterion such as backdoor or front door. ID algorithm factorizes P x (y) into c-factors at its step 4, as P x (y) = w1,w2 P x,w1 (w 2 )P x,w2 (w 1 , y) and estimates each of them recursively. Suppose we naively design an algorithm that follow ID step-by-step and trains a generative model and sample from every factor it encounters. This algorithm would not know which of these factors to learn and sample first with the generative models. To sample W 2 ∼ P x,w1 (w 2 ) we need W 1 as input, which has to be sampled from P x,w2 (w 1 , y). But to sample {W 1 , Y } ∼ P x,w2 (w 1 , y), we need W 2 as input which has to be sampled from P x,w1 (w 2 ). Therefore, no order helps to sample all W 1 , W 2 , Y consistently.</p><p>ID-GEN follows ID's recursive trace to reach at the factorization: P x (y) = w1,w2 P x,w1 (w 2 )P x,w2 (w 1 , y) but solves the deadlock issue by avoiding direct sampling from them. Rather, it first trains the required models for c-components {W 1 , Y }, {W 2 } individually, considering all possible input values, and then connects them to perform sampling. Thus, ID-GEN first obtains P x,w2 (w 1 , y) = P (w 1 |x)P (y|x, w 1 , w 2 ), and trains a conditional model for each of the conditional distributions (Fig. <ref type="figure">8</ref> left-blue). Similarly, for P x,w1 (w 2 ) = x ′ P (x ′ )P (w 2 |x ′ , w 1 ), we train models for each conditional distribution (right-blue). Note that X and X ′ are sampled from the same P (x) but considered as different variables. Thus, we train M X ′ to sample from P (x ′ ) which is different from intervention do(X). Finally, we merge these networks trained for each c-component to build a single sampling network and can perform ancestral sampling on this network to sample from P x (y), ∀x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Related works</head><p>In Figure <ref type="figure">9</ref>, we show a visual comparison among different implementations of existing works. Researchers have proposed deep neural networks for causal inference problems <ref type="bibr" target="#b41">[43,</ref><ref type="bibr" target="#b29">30]</ref> and neural causal methods Xia et al. <ref type="bibr" target="#b56">[58]</ref>, Kocaoglu et al. <ref type="bibr" target="#b25">[26]</ref> to deal with high-dimensional data. However, the proposed approaches are not applicable to any general query due to the restrictions they employ or their algorithmic design. For example, some approaches perform well only for low-dimensional discrete and continuous data (group 2 in Figure <ref type="figure">9</ref>: <ref type="bibr" target="#b56">[58,</ref><ref type="bibr" target="#b0">1]</ref>) while some propose modular training to partially deal with high-dimensional variables (group 3: <ref type="bibr" target="#b38">[40]</ref>). Other works with better generative Figure <ref type="figure">9</ref>: Suppose we aim to sample from P (m|do(v)), with M (MRI) as high-dimensional. Group 1 includes algorithms (ex: ID) that depend on likelihood estimation such as P (m|v, a, b). Group 2 algorithms with GAN architectures have issues with GAN convergence while Group 3 improves convergence with modularization but both struggle to match the joint distribution. Group 4 utilizes normalizing flow, diffusion models, etc but cannot deal with confounders. Groups 2-4 only do unconditional interventions or costly rejection sampling. Finally, our method can employ classifierfree diffusion models to sample from P (m|do(v)) or conditional P (m|a, do(v)). The causal graph is adapted from Ribeiro et al. <ref type="bibr" target="#b39">[41]</ref>.</p><p>performance depend on a strong structural assumption: no latent variable in the causal graph (group 4: Kocaoglu et al. <ref type="bibr" target="#b25">[26]</ref>, Pawlowski et al. <ref type="bibr" target="#b34">[35]</ref>, Chao et al. <ref type="bibr" target="#b10">[11]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 ID-GEN recursion tree example</head><p>In Figure <ref type="figure" target="#fig_8">10</ref>, we show a possible recursive route of ID-GEN for a causal query P (y|do(x)). At any recursion level, we check condition for 7 steps (S1-S7) and enter into one step based on the satisfied conditions. The red edges indicate the top-down phase, and the green edges indicate the bottomup phase. The rectangular gray boxes (ConditionalGMs(.), MergeNetwork(.), Update(.)) represent the functions that allow ID-GEN to sample from the high-dimensional interventional distribution. P v\s1 (s 1 )P v\s2 (s 2 ) are obtained after performing c-factorization at step 4. We also indicate the recursive route with increasing indices. We hope that this figure helps the readers understand the recursion route in a better way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 IDC-GEN: conditional interventional sampling</head><p>Existing works that use causal graph-based feedforward models <ref type="bibr" target="#b57">[59,</ref><ref type="bibr" target="#b38">40]</ref> need to update the posterior of Z's upstream variables which is not efficiently feasible in their architecture. We, given a causal query P x (y|z), sample from this conditional interventional query by calling Algorithm 5: IDC-GEN. This function finds the maximal set α ⊂ Z such that we can apply do-calculus rule-2 and move α from conditioning set Z and add it to intervention set X. Precisely, P x (y|z) = P x∪α (y|z \ α) = Px∪α(y,z\α) Px∪α(z\α) . Next, Algorithm 1: ID-GEN (.) is called to obtain the sampling network that can sample from the interventional joint distribution P x∪α (y, z \ α). We use the sampling network to generate samples D[X ∪ α, Y, Z \ α]. We train a new conditional model M Y on D that takes Z \ α, X ∪ α as input and samples Y ∼ P x∪α (y, z \ α) i.e, Y ∼ P x (y|z).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.6 ID-GEN computational complexity</head><p>Bhattacharyya et al. <ref type="bibr" target="#b4">[5]</ref> in their work discusses the sample complexity and time complexity of Shpitser and Pearl <ref type="bibr" target="#b44">[46]</ref>'s ID algorithm. Since our algorithm ID-GEN is build upon the recursive structure of ID, we follow their approach to determine the computational complexity of our algorithm. Suppose, in step 4 ID-GEN factorizes P x (y) as v\(y∪x) P v\s1 (s 1 ) . . . P v\s l (s l ) . . . P v\sn (s n ) where each S i is the c-factor of each c-component C i . Let the number of variables located in each c-component be k. Suppose, the intervention X can be partitioned into multiple c-components and the c-components can be arranged in a way such that X = ∪ l i=1 X i and X i ⊆ C i , i.e., all interventions are located in the first l c-components. Following <ref type="bibr" target="#b4">[5]</ref>, we define two sets For |C &gt;l | = n -l, c-components that do not contain any X, ID-GEN will either go to step1 or step 6. In the base cases, they will train k models for each c-components. Thus, the number of models trained for these c-components will be O((n -l)k).</p><formula xml:id="formula_15">C &gt;l = ∪ i&gt;l C i and C ≤l = ∪ i≤l C i .</formula><p>For the first |C ≤l | = l, c-components, we assume that each c-component contains intervention subset X i of size X . Then the size of the remaining c-component is k -X . For each P v\si (s i ), ID-GEN will eventually reach the base cases: Step 1 or 6 and will train k -X models. Now, consider recursive steps. We assume that, in the worst case, X i will reduce one at a time, by visiting step 7 and step 2 alternately. Thus, ID-GEN will visit step 7, O((X /2 -1)) times (except base case). Whenever ID-GEN visits step 7, it will apply a subset of the intervention X i and atmost k models will be trained to sample the updated training dataset. Thus, till the base case, the total number of models trained in step 7s will be O(k(X /2 -1)). If we consider the whole recursive route for each c-component </p><formula xml:id="formula_16">C i ∈ C ≤l , we will train O(k(X /2 -1)) + O((k -X )) = O(kX /</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.7 ID-GEN for Non-Markovian Causal Models</head><p>We assumed the underlying true causal model to be semi-Markovian in our paper. This is not a limitation as <ref type="bibr" target="#b50">[52]</ref> showed that causal models with arbitrary latent variables can always be converted into semi-Markovian causal models i.e., models in which latent variables have no parent and only two children, while preserving the same independence relations between the observed variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Theoretical analysis</head><p>Here we provide formal proofs for all theoretical claims made in the main paper, along with accompanying definitions and lemmas. Definition D.1. A conditional generative model for a random variable X ∈ V relative to the distribution P (v) is a function M X : Pa X → |X| such that M X (pa X ) ∼ P (x|pa X ), ∀pa ∈ Pa, where Pa is a subset of observed variables in V . Definition D.2 (Recursive call). For a function f (), when a subprocedure with the same name is called within f () itself, we define it as a recursive call. At Steps 2, 3, 4, 7 of Algorithm 1:ID-GEN, the sub-procdedure ID-GEN(.) with updated parameters are recursive calls, but the sub-procedure ConditionalGMs(.), Update(.) are not recursive calls.</p><p>Here, we restate the assumptions that are mentioned in the main paper. Assumption D.3. The causal model is semi-Markovian.</p><p>Assumption D.4. We have access to the true acyclic-directed mixed graph (ADMG) induced by the causal model. Assumption D.5. Each conditional generative model trained by ID-GEN correctly samples from the corresponding conditional distribution. Assumption D.6. The observational joint distribution is strictly positive and Markov relative to the causal graph. Lemma D.7 (c-component factorization <ref type="bibr" target="#b49">[51]</ref>). Let M be an SCM that entails the causal graph G and P x (y) be the interventional distribution for arbitrary variables X and Y . Let C(G \ X) = {S 1 , . . . , S n }. Then we have P x (y) = v\(y∪x) P v\s1 (s 1 )P v\s2 (s 2 ) . . . P v\sn (s n ).</p><p>Definition D.8. We say that a sampling network H is valid for an interventional distribution P x (y) if the following conditions hold:</p><p>• Every node V ∈ H has an associated conditional generative model M V (.) except the variables in X.</p><p>• If the values X = x are specified in H, then the samples of Y obtained after dropping H \ {X ∪ Y} from all generated samples are equivalent to samples from P x (Y).</p><p>Proposition D.9. The ConditionalGMs(.) (S ′ , X Z , G, D, X, Ĝ) called inside Update(.), returns D[X Z , S ′ ] ∼ P X Z (S ′ ).</p><p>Proof. Suppose that our goal is to generate samples from P X Z (Y = S ′ ). S ′ is a single c-component and the intervention set X = X Z located outside of S ′ . This is the entering condition for step 6 of the ID-GEN algorithm. Thus, we can directly apply it as Algorithm 2: ConditionalGMs(.), instead of another recursive ID-GEN (Y = S ′ , X = X Z , G, D, X, Ĝ) call.</p><p>Proposition D.10. At any recursion level of Algorithm 1: ID-GEN (Y, X, G, D, X, Ĝ) and Algorithm 6: ID(Y, X, P, G) , the execution step is determined by the values of the set of observed variables Y, the set of intervened variables X and the causal graph G, at that recursion level.</p><p>Proof. To enter in steps <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref> of ID-GEN and steps <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref> of ID, specific graphical conditions are checked, which depend only on the values of the parameters Y, X and G. If that graphical condition is satisfied, both algorithms enter in their corresponding steps. Thus, the execution step of each algorithm at any recursive level is determined by only Y, X and G. Proof. Suppose, both algorithms start with an input causal query P x (y) for a given graph G. For this query, the parameters Y, X, G of ID(Y, X, P, G) and ID-GEN (Y, X, X′ , D, G) represent the same objects: the set of observed variables Y, the set of intervened variables X and the causal graph G. According to Proposition D.10, Algorithm 1: ID-GEN and Algorithm 6: ID only check these 3 parameters to enter into any steps and decide the next recursive step. Thus, we use proof by induction based on these 3 parameters to prove our statement.</p><p>Induction base case (recursion level R = 0): Both algorithms start with the same input causal query P x (y) in G, i.e., the same parameter set Y, X, G. We show that at recursion level R = 0, ID-GEN enters step i if and only if ID enters step i for any i ∈ <ref type="bibr" target="#b6">[7]</ref>.</p><p>Step 1: Both ID and ID-GEN check if the intervention set X is empty and go to step 1. Thus, ID-GEN enters step 1 iff ID enters step 1.</p><p>Step 2: If the condition for step 1 is not satisfied, then both ID and ID-GEN check if there exist any non-ancestor variables of Y: V \ An(Y) G in the graph to enter in their corresponding step 2. Thus, with the same Y and G, ID-GEN enters step 2 iff ID enters step 2.</p><p>Step 3: If conditions for Steps <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref> are not satisfied, both ID and ID-GEN check if W is an empty set for W = (V \ X) \ An(Y) G X to enter in their corresponding step 3. Since both algorithms have the same Y, X and G, ID-GEN enters step 3 iff ID enters step 3.</p><p>Step 4: If conditions for Steps <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref> are not satisfied, both ID and ID-GEN check if they can partition the variables set C(G \ X) into k (multiple) c-components. Since these condition checks depend on X and G and both have the same input X and G, ID-GEN enters step 4 iff ID enters step 4.</p><p>Step 5: If conditions for Steps <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref> are not satisfied, both algorithms check if C(G \ X) = {S} and C(G) = {G} to enter their corresponding step 5. Since both have the same X and G, ID-GEN enters step 5 iff ID enters step 5.</p><p>Step 6: If the conditions of Steps <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref> are not satisfied, ID and ID-GEN check if C(G \ X) = {S} and S ∈ C(G), to enter their corresponding step 6. Since both have the same X and G, ID-GEN enters step 6 iff ID enters step 6.</p><p>Step 7: If conditions for Steps <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref> are not satisfied, both ID and ID-GEN check if C(G \ X) = {S} and (∃S ′ ) such that S ⊂ S ′ ∈ C(G) to enter their corresponding step 7. Since both have the same X and G, both will satisfy this condition and enter this step. Thus, ID-GEN enters step 7 iff ID enters step 7.</p><p>Induction Hypothesis: We assume that for recursion levels R = 1, . . . , r, ID-GEN and ID follow the same steps at each recursion level and maintain the same values for the parameter set Y, X and G.</p><p>Inductive steps: Both algorithms have the same set of parameters Y, X, G and they are at the same step i at the current recursion level R = r. As inductive step, we show that with the same values of the parameter set Y, X and G at recursion level R = r, ID-GEN and ID will visit the same step at recursion level R = r + 1.</p><p>Step 1:</p><p>Step 1 is a base case of both algorithms. After entering into step 1 with X = ∅, ID estimates v\y P (v) and ends the recursion. ID-GEN also ends the recursion after training a set of conditional models M Vi (V</p><formula xml:id="formula_17">(i-1) π ) ∼ P (v i |v (i-1) π</formula><p>). Thus, ID-GEN goes to the same step at recursion level R = r + 1 iff ID goes to the same step which in this case is Return.</p><p>Step 2: At step 2, both ID-GEN and ID update their intervention set X as X ∩ An(Y) G and the causal graph G as G An(Y) . The same values of the parameters X, Y and G will lead both algorithms to the same step at the recursion level R = r + 1. Thus, at recursion level R = r + 1, ID-GEN visits step i iff ID visits step i, ∀i ∈ <ref type="bibr" target="#b6">[7]</ref>.</p><p>Step 3: At step 3, both algorithms only update the intervention set parameter X as X = X ∪ W and perform the next recursive call. Since they leave for the next recursive call with the same set of parameters, at recursion level R = r + 1, ID-GEN visits step i iff ID visits step i, ∀i ∈ <ref type="bibr" target="#b6">[7]</ref>.</p><p>Step 4: At step 4, both ID-GEN and ID partition the variables set C(G \ X) into k (multiple) c-components. Then they perform a recursive call for each c-component with parameter Y = S i and X = V \ S i . For each of these k recursive calls, both algorithms use the same values for the parameter set Y, X and G. Thus, at recursion level R = r + 1, ID-GEN visits step i iff ID visits step i, ∀i ∈ <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inductive step:</head><p>The set of parameters {G ID-GEN , X, Ĝ} of ID-GEN and the graph parameter G of ID are only updated at step 2 and step 7 for the next recursive calls. Thus, we prove the claim for these two steps separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>At step 2:</head><p>In both ID and ID-GEN algorithms, we remove the non-ancestor variables V \ An(Y ) from the graph. For ID, G r+1 ID = G r ID (An(Y)). For the ID-GEN algorithm, we obtain G r+1</p><p>ID-GEN = G r ID-GEN (An(Y)). Thus, G r+1 ID = G r+1 ID-GEN . In ID-GEN, we also update Ĝr+1 as Ĝr+1 = Ĝr (An(Y)). Since removing non-ancestor does not affect the intervened variables X anyway, the same relation between G r+1 ID and Ĝr+1 is maintained, i.e., G r+1 ID = Ĝr+1 \ X. At step 7: Both ID and ID-GEN finds X Z = X \ S ′ and apply do(X Z ) as intervention. Also, in ID-GEN, Xr+1 is set to Xr ∪ X Z .</p><p>For ID-GEN:</p><formula xml:id="formula_18">Since X Z is intervened on, G r for ID-GEN is updated as G r+1 = G r X Z</formula><p>and Ĝr is updated as Ĝr+1 = Ĝr X Z . Now, X Z has all incoming edges are cut off in G r+1 and does not have any parents. As a result, removing X Z from G r+1 is valid. Thus, we obtain</p><formula xml:id="formula_19">G r+1 = G r+1 \ X Z = G r X Z \ X Z = G r S ′ .</formula><p>However, for the other graph parameter, we keep Ĝr+1 = Ĝr X Z as it is, since we would follow this structure in the base cases and consider X Z while training the conditional models. Note that, in Ĝr the intervened variables Xr (before recursion level r) had already incoming edges removed. Thus, after Xr being updated as Xr+1 = Xr ∪ X Z , we can write Ĝr+1 = Ĝr X Z</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>= Ĝr</head><p>Xr+1 . Since by inductive assumption, G r = Ĝr \ Xr , thus</p><formula xml:id="formula_20">G r+1 = Ĝr+1 \ { Xr ∪ X Z } = Ĝr+1 \ { Xr+1 }<label>(2)</label></formula><p>For ID:</p><p>ID algorithm updates its parameters G as G r+1 = G r S ′ = G r \ X Z . Since ID-GEN and ID have the same graph parameter at recursion level r, i.e, G r ID = G r ID-GEN and they updated the parameter in the same way, G r+1 ID = G r+1 ID-GEN holds true. Since G r+1 ID-GEN = Ĝr+1 \ { Xr+1 } according to Equation 2, we also obtain G r+1 ID = Ĝr+1 \ { Xr+1 }. Therefore, the lemma holds for any recursion level R.</p><p>Lemma D.14. Let P (.) be the input observational distribution to the ID algorithm and D ∼ P (.) be the input observational dataset to the ID-GEN algorithm. Suppose, X is the set of variables that are intervened at step 7 of both the ID and ID-GEN algorithm from recursion level R = 0 to R = r. Consider recursive calls ID( * , P ID (v)) and ID-GEN( * , D, * , X, Ĝ) at recursion level R = r. Then P ID = P x(v) and D[ X, V] ∼ P x(x, v).</p><p>Proof. According to Lemma D.11, ID and ID-GEN follow the same recursive trace. Thus, at any recursion level, both algorithms will stay at step i ∈ <ref type="bibr" target="#b6">[7]</ref>.</p><p>Base case: At recursion level R = 0, ID starts with the observational distribution P and ID-GEN starts with the observational training dataset D ∼ P . At R = 0, X = ∅ since no variables have yet been intervened on. Thus, for ID algorithm P ID = P ∅ (V ) holds. For ID-GEN, D[∅, V] ∼ P ∅ (∅, V) holds. Thus, the claim is true for R = 0.</p><p>Induction hypothesis: Let the set of variables intervened at step 7s from the recursion level R = 0 to R = r, be Xr . At R = r, let the distribution parameter of the ID algorithm be P r ID = P xr (v). Let the dataset parameter of the ID-GEN algorithm be sampled from P xr (x r , v), i.e, D r ∼ P xr (x r , v).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inductive step:</head><p>The distribution parameter P of ID and the dataset parameter D of ID-GEN only change at step 2 and step 7 for the next recursive calls. Thus, we prove the claim for these two steps separately.</p><p>At step 2: At step 2 of both ID and ID-GEN algorithms, there is no change in X, i.e., no additional variables are intervened to change the distribution P or the dataset D.</p><p>Since ID algorithm is sound it returns correct output for the query P (y). We prove the soundness of ID-GEN step 1 by showing that the sampling network ID-GEN returns, is valid for the output of the ID algorithm.</p><p>ID algorithm is sound and factorizes P ID (v) with respect to the graph G as below.</p><formula xml:id="formula_21">P ID (v) = vi∈V P (v i |v (i-1) π G )</formula><p>And obtains P ID (y) by: P ID (y) = v\y vi∈V</p><formula xml:id="formula_22">P (v i |v (i-1) π G )<label>(3)</label></formula><p>Let D[ X, V] ∼ P ID-GEN (x, v) = P (x, v), ∀(x, v). For fixed X = x, P ID-GEN (v|x) can be factorized with respect to G and Ĝ as following:</p><formula xml:id="formula_23">P ID-GEN (v|x) = vi∈V P (v i |v (i-1) π G , x) = vi∈V P (v i |v (i-1) π Ĝ )</formula><p>[Changed the graph from G to Ĝ since X ∈ Ĝ and only affects the descendants of X.]</p><p>And P ID-GEN (y|x) can be obtained by:</p><formula xml:id="formula_24">P ID-GEN (y|x) = v\y vi∈V P (v i |v (i-1) π Ĝ )<label>(4)</label></formula><p>Since for fixed X = x, P ID (v) = P ID-GEN (v|x) according to Lemma D.15. Thus, the corresponding conditional distributions in Equation 3 and 4 are equal, i.e, P ID (v i |v</p><formula xml:id="formula_25">(i-1) π G ) = P ID-GEN (v i |v (i-1)</formula><p>π Ĝ ), ∀{i|V i ∈ V}. Therefore, P ID (y) and P ID-GEN (y|x) having the same factorization and the corresponding conditional distributions being equal implies that P ID (y) = P ID-GEN (y|x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Now, based on Assumption D.5, ID-GEN learns to sample from each conditional distribution</head><formula xml:id="formula_26">P ID-GEN (v i |v (i-1) π , v (i-1)</formula><p>π Ĝ ) of the product in Equation <ref type="formula" target="#formula_24">4</ref>, by training a conditional model M Vi on samples from the dataset D[ X, V] ∼ P (x, v).</p><p>For each V i , we add a node containing V i and its associated conditional generative model M Vi to a sampling network. This produces a sampling network H that is a DAG, where each variable V i ∈ V has a sampling mechanism. By factorization and Assumption D.5, ancestral sampling from this sampling graph produces samples from P ID-GEN (v|x). We can drop values of V \ Y to obtain the samples from P ID-GEN (y|x). Since P ID (v) = P ID-GEN (v|x), both factorized in the same manner and M Vi learned conditional distribution of ID-GEN's factorization, the sampling network returned by ID-GEN, will correctly sample from the distribution P ID (y) returned by the ID algorithm for fixed X = x. Thus, the sampling network returned by ID-GEN is valid for P (y).</p><p>Lemma D.18. ID-GEN Base case (step 6): Let, at any recursion level of ID-GEN, the input dataset D[ X, V] is sampled from a specific joint distribution P ( X, V), i.e., D[ X, V] ∼ P ( X, V) where X is the set of intervened variables at step 7s. Given an identifiable interventional query P x (y) over a causal graph G = (V, E), suppose ID-GEN (Y, X, G, D, X, Ĝ) immediately enters step 6 and returns H. Then H is a valid sampling network for P x (y) with fixed consistent X = x.</p><p>Proof. By Lemma D.11, both ID-GEN (Y, X, G, D, X, Ĝ) and ID(Y, X, P, G) enter the same base case step 6. By the condition of step 6, G \ X has only one c-component {S}, where S ∈ C(G).</p><p>Let P (v) be the current distribution of the ID algorithm after performing a series of marginalizations in step 2 and intervention in step 7 on the input observational distribution. Let D[ X, V] ∼ P ′ (x, v) be the dataset parameter of ID-GEN algorithm that went through the same transformations as the ID algorithm in the sample space. X is the set of interventions that are applied on the dataset at step 7s. According to Lemma D.15 for fixed values of X = x, P (v) = P ′ (v|x) holds true at any recursion level.</p><p>Since ID algorithm is sound it returns correct output for the query P x (y). We prove the soundness of ID-GEN step 6 by showing that the sampling network ID-GEN returns, is valid for the output of the ID algorithm.</p><p>With the joint distribution P (v), the soundness of ID implies that</p><formula xml:id="formula_27">P x (y) = S\Y {i|Vi∈S} P (v i |v (i-1) π G )<label>(5)</label></formula><p>where π G is a topological ordering for G.</p><p>With the joint distribution P ′ (v|x), ID-GEN can factorize P ′ x (y|x) in the same manner:</p><formula xml:id="formula_28">P ′ x (y|x) = S\Y {i|Vi∈S} P ′ (v i |v (i-1) π G , x) = S\Y {i|Vi∈S} P ′ (v i |v (i-1) π Ĝ )</formula><p>[Changed the graph from G to Ĝ since X ∈ Ĝ and only affects the descendants of X.]</p><p>Since P (v) = P ′ (v|x), the corresponding conditional distributions in Equation 5 and 6 are equal, i.e, P (v i |v</p><formula xml:id="formula_30">(i-1) π G ) = P ′ (v i |v (i-1)</formula><p>π Ĝ ), ∀{i|V i ∈ S}. Therefore, P x (y) and P ′ x (y|x) having the same factorization and the corresponding conditional distributions being equal implies that P x (y) = P ′</p><p>x (y|x). ID-GEN operates in this case by training, from joint samples D[ X, V ], a model to correctly sample each P ′ (v i | v (i-1) π Ĝ ) term, i.e., we learn a conditional generative model M Vi (V</p><formula xml:id="formula_31">(i-1) π Ĝ ) which produces samples from P ′ (v i | v (i-1)</formula><p>π Ĝ ), which we can do according to Assumption D.5. Then we construct a sampling network H by creating a node V i with a sampling mechanism M Vi for each V i ∈ S. We add</p><formula xml:id="formula_32">edges from V j → V i for each V j ∈ V (i-1) π Ĝ</formula><p>. Since every vertex in Ĝ is either in S or in X ∪ X, every edge either connects to a previously constructed node or a variable in X ∪ X. Since we already have fixed values for X = x, when we specify values for X and sample according to topological order π Ĝ, this sampling graph provides samples from the distribution {i|Vi∈S} P ′ (v i |v (i-1) π Ĝ ), i.e. P ′</p><p>x (s|x). Since, as shown earlier, P ′</p><p>x (s|x) = P x (s), samples from the sampling network H is consistent with P x (s) as well. We obtain samples from P x (y) by dropping the values of S \ Y from the samples obtained from P x (s). We assert the remaining conditions to show that this sampling network is correct for P x (y): certainly this graph is a DAG and every v ∈ S has a conditional generative model in H. By the conditions to enter step 6, Ĝ = S ∪ X ∪ X and S ∩ {X ∪ X} = ∅. Then every node in H is either in S or is in X ∪ X: hence the only nodes without sampling mechanisms are those in X ∪ X as desired. Therefore, when X is fixed as x, H is a valid sampling network for P x (y).</p><p>Proposition D. <ref type="bibr" target="#b18">19</ref>. At any level of the recurison, the graph parameters G and Ĝ in ID-GEN (Y, X, G, D, X, Ĝ) have the same topological order excluding X.</p><p>Proof. Let π G be the topological order of G and π Ĝ be the topological order of Ĝ. At the beginning of the algorithm G = Ĝ. Thus, π G = π Ĝ. According to the lemma D.13, at any level of recursion,</p><formula xml:id="formula_33">G ID = G ID-GEN and G ID = Ĝ \ X. Thus, we have G = G ID-GEN = G ID = Ĝ \ X. Therefore, π G = π Ĝ\ X.</formula><p>Lemma D.20. Let H be a sampling network produced by ID-GEN from an identifiable query P x (y) over a graph G. If G has the topological ordering π, then every edge in the sampling graph of H adheres to the ordering π.</p><p>Proof. We consider two factors: which edges are added, and with respect to which graphs. Since the only base cases ID-GEN enters are steps 1 and 6, the only edges added are consistent with the topological ordering π for the graph that was supplied as an argument to these base case calls. The only graph modifications occur in steps 2 and 7, and these yield subgraphs of G. Thus the original topological ordering π for graph G is a valid topological ordering for each restriction of G. Therefore any edge added to H is consistent with the global topological ordering Π.</p><p>Lemma D.21. Let H be a sampling network for random variables {V 1 , V 2 , . . . V n } formed by a collection of conditional generative models M Vi relative to P (v) for all V i . Then the tuple (V 1 , V 2 . . . V n ) obtained by sequentially evaluating each conditional generative model relative to the topological order of the sampling graph is a sample from the joint distribution</p><formula xml:id="formula_34">Π i P i (v i |pa i ).</formula><p>Proof. Without loss of generality, let (V 1 , V 2 , . . . , V N ) be a total order that is consistent with the topological ordering over the nodes in G. To attain a sample from the joint distribution, sample each V i in order. When sampling V j , each V i for all i &lt; j is already sampled, which is a superset of P a j (the inputs to M Vj ) by definition of topological orderings. Thus, all inputs to every conditional generative model M Vj are available during sampling. Since each V j is conditionally independent of V i ̸ ∈ P a j , the joint distribution factorizes as given in the claim.</p><p>Theorem D.22. ID-GEN Soundness: Let P x (y) be an identifiable query given the causal graph G = (V, E) and that we have access to joint samples D ∼ P (v). Then the sampling network returned by ID-GEN (Y, X, G, D, X, Ĝ) correctly samples from P x (y) under Assumption D.5.</p><p>Proof sketch: Suppose that P x (y) is the input causal query and Assumptions D.3, D.4, D.5, D.6 hold. The soundness of ID-GEN implies that if the trained conditional models converge to (near) optimality, ID-GEN returns the correct samples from P x (y). For each step of the ID algorithm that deals with probabilities of discrete variables, multiple actions are performed in the corresponding step of ID-GEN to correctly train conditional models to sample from the corresponding distributions. ID-GEN merges these conditional models according to the topological order of G, to build the final sampling network H. Therefore, according to structural induction, when we intervened on X and provided from ID step 7 as</p><formula xml:id="formula_35">P x (y) = ID(Y, X ∩ S ′ , P ′ , G S ′ )</formula><p>where</p><formula xml:id="formula_36">P ′ := {i|Vi∈S ′ } P (V i |V (i-1) π ∩ S ′ , v (i-1) π \ S ′ ).</formula><p>Examining ID algorithm more closely, if we enter step 7 during ID, the interventional set X is partitioned into two components: X ∩ S ′ and X Z := X \ S ′ . From Lemmas 33 and 37 of Shpitser and Pearl <ref type="bibr" target="#b44">[46]</ref>, in the event we enter step 7, P x (y) is equivalent to P ′ x∩S ′ (y) where P ′ (v) = P x Z (v). ID estimates P x Z (v) with a similar computation as the step 6 base case.</p><p>To sample correctly in ID-GEN, we consider two cases. i) X = ∅: When ID-GEN visits step 7 for the first time, we have X = ∅. In that case, we first update our dataset D[V] ∼ P (v) to samples from D ′ ∼ P x Z (v), and then we recurse on the query P ′ x∩S ′ (y) over the graph G S ′ . Also, X Z is outside the c-component S ′ . Therefore we generate a dataset from D ′ ∼ P x Z (S ′ ) via running directly the ConditionalGMs(.) of the ID-GEN algorithm, Algorithm 2: ConditionalGMs(S ′ , X Z , G, D, X, Ĝ). This is attainable via the inductive assumption and Lemma D.12. The only divergence from ID during the generation of D ′ is that ID presumes pre-specified fixed values for X Z , where we train a sampling mechanism that is agnostic a priori to the specific choice of X Z . To sidestep this issue, we generate a dataset with all possible values of X Z and be sure to record the values of</p><formula xml:id="formula_37">X Z in the dataset D ′ [X Z , S ′ ].</formula><p>ii) X ̸ = ∅: When ID-GEN has visited step 7 already once and thus X ̸ = ∅. We consider X along with X Z when generating D ′ this time. More precisely, we update our dataset D[ X, V] ∼ P (x, v) to samples from D ′ ∼ P x Z ∪x (x z , x, v). Rest of the steps follow similarly as the above case. We record the new X Z in X and carry them in D ′ [ X, S ′ ] and Ĝ.</p><p>Next, we need to map the recursive call ID(Y, X ∩ S ′ , P ′ , G) to ID-GEN. ID-GEN sends the same parameters Y, X ∩ S ′ and G as ID. Now, equivalent to passing the distribution P ′ of ID, we pass the dataset D[ X, S ′ ] sampled from this distribution, including the intervened values for X used to obtain this dataset. According to Lemma D.15, this dataset is sampled from P ′ if we fix to a specific value X = x. Finally, ID algorithm uses specific value of X Z and then ignores those variables from X and G for rest of the recursion. On the other hand, ID-GEN saves X Z in X as X = X ∪ X Z and keeps X connected to Ĝ with incoming edges cut, i.e., G S ′ , X for the next recursive calls since ID-GEN utilizes X and the topological order in Ĝ at the base cases (step 1 and 6). By the inductive assumption, we can generate a correct sampling network from the call ID-GEN(Y, X \ X Z , G S ′ , D[ X, S], X, Ĝ{S ′ , X} ), and hence the returned sampling graph is correct for P x (y).</p><p>Since we have shown that every recursion of ID-GEN ultimately terminates in a base case, that all the base cases provide correct sampling graphs, and that correct sampling graphs can be constructed in each step assuming the recursive calls are correct, we conclude that ID-GEN returns the correct sampling graph for P x (y).</p><p>Theorem D.23. ID-GEN is complete.</p><p>Proof. Suppose we are given a causal query P x (y) as input to sample from. We prove that if ID-GEN fails, then the query P x (y) is non identifiable, implying that it is not possible to train conditional models on observational data and correctly sample from the interventional distribution P x (y).</p><p>If ID-GEN reaches step 5, it returns FAIL. According to the lemma D.11, ID reaches at step 5 if and only if ID-GEN reaches at step 5. Step 5 is also the FAIL case of the ID algorithm. Since ID is complete and returns FAIL at Step 5, the query P x (y) is not identifiable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Conditional interventional sampling</head><p>Conditional sampling: Given a conditional causal query P x (y|z), we sample from this conditional interventional query by calling Algorithm 5: IDC-GEN. This function finds the maximal set α ⊂ Z such that we can apply rule-2 and move α from conditioning set Z and add it to intervention set X. Precisely, P x (y|z) = P x∪α (y|z \ α) = Px∪α(y,z\α) Px∪α(z\α) . Next, Algorithm 1: ID-GEN(.) is called to obtain the sampling network that can sample from the interventional joint distribution P x∪α (y, z \ α). We use the sampling network to generate samples D ′ through feed-forward. A new conditional model M Y is trained on D ′ that takes Z \ α and X ∪ α as input and outputs Y . Finally, we generate new samples with M Y by feeding input values such that Y ∼ P x∪α (y, z \ α) i.e, Y ∼ P x (y|z).</p><p>Theorem E.1 (Shpitser and Pearl <ref type="bibr" target="#b44">[46]</ref>). For any G and any conditional effect P X (Y |W ) there exists a unique maximal set</p><formula xml:id="formula_38">Z = {Z ∈ W |P X (Y |W ) = P X,Z (Y |W \ Z)} such that rule 2 applies to Z in G for P X (Y |W ). In other words, P X (Y |W ) = P X,Z (Y |W \ Z).</formula><p>Theorem E.2 (Shpitser and Pearl <ref type="bibr" target="#b44">[46]</ref>). Let P X (Y |W ) be such that every</p><formula xml:id="formula_39">W ∈ W has a back-door path to Y in G \ X given W \ {W }. Then P X (Y |W ) is identifiable in G if and only if P X (Y, W ) is identifiable in G.</formula><p>Theorem E.3. IDC-GEN Soundness: Let P X (Y |Z) be an identifiable query given the causal graph G = (V, E) and that we have access to joint samples D ∼ P (v). Then the sampling network returned by IDC-GEN (Y, X, Z, D, G) correctly samples from P X (Y |Z) under Assumptions D.3, D.4, D.5, D.6.</p><p>Proof. The IDC algorithm is sound and complete based on Theorem E.1 and Theorem E.2. For sampling from the conditional interventional query, we follow the same steps as the IDC algorithm in Algorithm 5: IDC-GEN and call the sound and complete Algorithm 1:ID-GEN as sub-procedure. Therefore, IDC-GEN is sound and complete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Experimental details F.1 Training details and compute</head><p>We performed some of our experiments on a machine with an RTX-3090 GPU. We also performed some training on 2 A100 GPU's which took roughly 9 hours for 1000 epochs. Training for baseline NCM took more than 50 hours to complete 1000 epochs. The baseline DCM took around 10 hours. When variables were low-dimensional discrete, it was quite fast and took 10-20 minutes to finish all training and get convergence. We discuss more specifics about each experiment in their individual sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1.1 Reproducibility</head><p>For reproducibility purposes, we provide our anonimized source codes with instructions. Besides, we provided explanations of each experiment along with model settings and hyperparameters. We provide the code to generate the Colored MNIST dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Napkin-MNIST dataset</head><p>Data Generation: First we consider a synthetic dataset imbued over the napkin graph. We consider variables W 1 , W 2 , X, Y , where W 1 , X, Y are images derived from MNIST and W 2 is a paired discrete variable. We introduce latent confounders C, T , denoting color and thickness, where C can be any of {red, greed, blue, yellow, magenta, cyan}, and T can be any of {thin, regular, thick}. Data generation proceeds as follows: first we sample latent C, T from the uniform distribution. We color and reweight a random digit from MNIST to form W 1 . W 2 only keeps the digit value in {0 . . . 9} of W 1 and a restriction of its color: if the color of W 1 is red, green, or blue, W 2 's color value is 0, and it is 1 otherwise. X then picks a random MNIST image of the same digit as W 2 's digit value (0-9), is colored according to W 2 's color value (0-1), and is reweighted according to the latent T . Then Y is the same original MNIST image as X, with the same thickness but colored according to the latent C. Further, for every edge in the graph, we include a random noising process: with Further, because this distribution is only supported over discrete variables, exact likelihoods can be computed for any conditional query. This is much more easily done programmatically, however, and we provide code in the attached codebase to do just that. We will claim without proof that in the case of thicknesses and digits, P Y (X) = P (Y |X). However in the case of colors, P Y (X) ̸ = P (Y |X). Hence we consider this case in the evaluations in the experiments section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2.2 Data generation procedure: high-dimensional case</head><p>The high-dimensional case follows the discrete case of the Napkin-MNIST dataset, with a few key changes. Namely, W 1 , X, and Y are MNIST images that have been colored and thickened. We explicitly outline these changes:</p><p>• W 1 : A random MNIST image of the provided digit is used, then colored and thickened accordingly (noisy from latents).</p><p>• W 2 : This is a discrete variable, only encoding the (noised) digit and (noised) restricted color of W 1 .</p><p>• X: This is a random MNIST image of the (noised) digit obtained from W 2 , then colored with the (noised) restricted color from W 2 and thickened according to the (noised) latent thickness.</p><p>• Y : This is the same base image of X, unless the noising procedure calls for a change in digit, then a random MNIST image of the specified image is used. The (noisy) color is obtained from the latent distribution, and the (noisy) thickness is obtained from X.</p><p>To color the images, we convert each 1-channel MNIST image into a 3-channel MNIST image, and populate the necessary channels to generate these colors. Note that in RGB images: if only the RG channels are active, the image is yellow; if only the RB channels are active, the image is magenta; if only the BG channels are active, the image is cyan. To thicken the images, we use the MorphoMNIST Castro et al. <ref type="bibr" target="#b7">[8]</ref> package <ref type="foot" target="#foot_0">2</ref> . Operationally, we generate a base dataset for our experiments of size equivalent to the original MNIST dataset. That is, the training set has a size of 60K, and the test set has a size of 10K. Because we have access to the latents during the data generation procedure, we are able to train classifiers for each variable to identify their digit, color and thickness. We use a simple convolutional network architecture for each of these cases and achieve accuracy upwards of 95% in each case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2.3 Diffusion training details</head><p>We train two diffusion models during our sampling procedure, and we discuss each of them in turn.</p><p>To train a model to sample from P ( X, Y |W 1 , W 2 ), we train a single diffusion model over the joint (X, Y ) distribution, i.e., 6 channels. We train a standard UNet architecture where we follow the conditioning scheme of classifier-free guidance. That is, we insert at every layer an embedding of the W 1 (image) and W 2 (2-dimensional discrete variable). To embed the W 1 image, we use the base of a 2-layer convolutional neural network for MNIST images, and to embed the W 1 we use a standard one-hot embedding for each of the variables. All three embeddings are concatenated and mixed through a 2-layer fully connected network to reach a final embedding dimension of 64. Batch sizes of 256 are used everywhere. Training is performed for 1000 epochs, which takes roughly 9 hours on 2 A100 GPU's. Sampling is performed using DDIM over 100 timesteps, with a conditioning weight of w = 1 (true conditional sampling) and noise σ = 0.3.</p><p>To train a model to sample Y from the generated dataset (W 2 , X, Y ), we follow an identical scheme. An option is to train a single diffusion model for each choice of W 2 in our synthetic dataset, however, we argue our schema still produces correct samples because: 1) W 2 can be arbitrarily chosen, and thus should not affect Y , 2) we argue that the model fidelity benefits from weight sharing across multiple choices of W 2 , 3) the model is only ever called with a specified value of W 2 so we always condition on this W 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2.4 Extra evaluations</head><p>As such, our evaluations include verifying the quality of the trained component neural networks and, in the case of MNIST, a surrogate ground truth for a discrete version of the dataset. In each experiment, for conditional sampling with high-dimensional data, we train diffusion models using classifier-free guidance <ref type="bibr" target="#b20">[21]</ref>. For conditional sampling of categorical data, we train a classifier using cross-entropy loss. In addition to the evaluations presented in the main paper, we can further perform evaluations on the component models necessary to sample P X (Y ).</p><formula xml:id="formula_40">P (X, Y |W 1 , W 2 ):</formula><p>We can evaluate the model approximating samples from P (X, Y |W 1 , W 2 ) on a deeper level than just visual inspection as provided in the main paper. In particular, assuming access to good classifiers that can predict the digit, color, and thickness of an MNIST image, we can compare properties of the generated images with respect to the ground truth in the discrete case. For example, assuming we have hyperparameter of random noise equal to p, we can compute the following quantities analytically on the discrete dataset as:</p><formula xml:id="formula_41">• P [X d = W 2d ] = 1 -p + p 10 • P [X. c = W 2c ] = 1 -p + p 10 • P [X t = W 1t ] = (1 -p + p 3 ) 2 + p 3 2 * 2 • P [Y d = X d ] = 1 -p + p 10 • P [Y c = W 1c ] = (1 -p + p 6 ) 2 + big( p 6 2 * 5 • P [Y t = X t ] = 1 -p + p 3</formula><p>where V d , V c , V t refer to the digit, color, and thickness attributes respectively. These calculations follow from two formulas. In a discrete distribution with support S and |S| = K:</p><formula xml:id="formula_42">• P [η p (z, S) = z] = 1 -p + p K • P [η p (z, S) = η p (z, S)] = (1 -p + p K ) 2 + p K 2 * (K -1)</formula><p>where in the second equation, it is assumed that η p (•, •) are two independent noising procedures.</p><p>Then to evaluate, we can 1) consider a large corpus of joint data, 2) run each of W 1 , X, Y through a classifier for digit, color, and thickness, 3) evaluate the empirical estimate of each desired probability. We present these results for the synthetic dataset D synth sampled from the diffusion model approximating P (X, Y |W 1 , W 2 ), a dataset D orig generated according to the data generation procedure, and P true the true analytical probabilities. These results are displayed in the Table <ref type="table" target="#tab_4">1</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2.5 MNIST baseline comparison</head><p>Here we provide some additional information about the baseline comparison we showed in Section 4.1.</p><p>Although the implementation of the baseline methods is different, we considered the performance of each method after running them for 300 epochs (until good image quality is obtained). The NCM algorithm took around 50 hours to complete while our algorithm took approximately 16 hours to complete. We observe the probabilities in Table <ref type="table">2</ref>.</p><p>In the generated samples from the conditional model, the color of digit image X and digit image Y are correlated due to confounding through backdoor paths. For example, for a digit image X with color as red, Y takes a value from [Red, Green, Blue] with high probability. Thus, the conditional model does not have the ability to generate interventional samples. On the other hand, our algorithm generates samples from the interventional distribution P (y|do(x)) and the generated samples choose different colors:[Red, Green, Blue, Yellow, Magenta, Cyan] with almost the same probability. Therefore, our algorithm shows superior performance compared to baselines and illustrates the high-dimensional interventional sampling capability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3 CelebA experiment</head><p>Here we provide some additional information about the CelebA image to image translation experiment we showed in Section 4.2. We used a pre-trained classifier from this repository: <ref type="url" target="https://github">https://github</ref>.  <ref type="table" target="#tab_5">3</ref> shows, 29.16% of the total images are translated as a young person.   Baselines: Existing algorithms such as Xia et al. <ref type="bibr" target="#b57">[59]</ref>, Chao et al. <ref type="bibr" target="#b10">[11]</ref> do not utilize the causal effect expression of P (A|do(Male = 0)), rather they train neural models for each variable in the causal graphs which will be costly in this scenario. Even if they utilize pre-trained models, they have to train models for the remaining variables to match the whole joint and perform sampling-based methods to evaluate P (A|Young = 1, do(Male = 0)). Note that the ground truth if our considered attributes are causally related with an image of a Female is unknown. We assume that they are causal in the CelebA dataset based on expert knowledge <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3.1 Conditional image generation</head><p>In Figure <ref type="figure" target="#fig_1">19</ref>, we show images generated from conditional interventional distribution. Below we shortly describe the reasoning for our causal graph assumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nodes and Edges:</head><p>• Prompt/Report (R) is variable that represents textual input. In CXR datasets such as MIMIC-CXR, it is generally doctor written text report indicating the existence of different attributes.</p><p>In our experiment, we consider it as an input prompt feed by some user who is interested to understand how the prompt affects other attributes and the CXR image generation. We assume that the LLM labeler can extract effusion (E) and atelectasis (A). Thus, we consider R → E and R → A.</p><p>• Pneumonia(N ) is an infection that inflames the air sacs in one or both lungs <ref type="bibr" target="#b30">[31]</ref>.</p><p>• Pleural effusion (E) happens when fluid builds up in the space between the lung and the chest wall. This can occur for reasons such as pneumonia or complications from heart, liver, or kidney disease. Pleural effusion also involves fluid in the lung area. It is common in patients who develop pneumonia. At least 40-60% of patients with bacterial pneumonia will develop a pleural effusion of varying severity. Thus, we consider N → E .</p><p>• Atelectasis (A) is one of the most common breathing complications after surgery. Here, complication is a medical problem that occurs during a disease, or after a procedure or treatment <ref type="bibr" target="#b12">[13]</ref>. External pulmonary compression by pleural fluid or air (i.e, pleural effusion, pneumothorax, etc.) may cause atelectasis <ref type="bibr" target="#b32">[33]</ref>. Thus, we consider the edge E → A. Also, various types of pneumonia, which is a lung infection, can cause atelectasis <ref type="bibr" target="#b31">[32]</ref>. Therefore, we consider the edge N → A.</p><p>• Lung opacity (L) is a lack of transparency, i.e., an opaque or non-transparent area on an x-ray/radiograph. <ref type="bibr" target="#b17">[18]</ref>. We consider pneumonia, effusion and atelectasis to be causes for lung opacity. Thus we consider edges N → L, E → L, A → L.</p><p>• Xray Image (X) represents different attributes such as atelectasis, effusion and lung opacity in visible radiography form. Thus, we consider edges E → X, A → X, L → X.</p><p>• N ↔ R represents the presence of a hidden confounder between pneumonia and the input prompt/report. We followed <ref type="bibr" target="#b8">[9]</ref> to consider the hospital location as the unobserved variable from where the chest x-ray datasets where collected. They discuss that when we merge/mix different datasets and train models on that different types of biases are introduced. For example, in many scenarios, most patients are screened in certain health services and highly suspicious patients are derived to a different area. Another example of introducing bias is, when we aim to increase the number of controls or cases, we expand the dataset with samples coming from significantly different origins and labeled with unbalanced class identifiers. Since we utilized foundation models such as <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b9">10]</ref> which are trained in multiple chest radiograph datasets, they are prone to above kind of bias. In some cases, to discriminate between cases and controls, these models might depend on the origins/location based details rather than finding actual features related to the disease. Thus, we consider that hospital locations have some effect on the text report on which the models were trained on and also how likely people were affected by pneumonia infection in those areas. Therefore, we consider the presence of a confounder between the text report (R) and pneumonia (N ).</p><p>Note that all our results are based on the MIMIC-CXR dataset and our assumption on the causal graph. Thus, our results should not be used to make medical inferences without an expert opinion. In the real world, the domain-specific causal graph might change. Our algorithm can be applied on the domain specific causal graph and the dataset to obtain correct results.</p><p>F.5 Covid X-Ray dataset F.5.1 Data preprocessing Note that a full pipeline of data preparation is contained in cxray/prep_cxray_dataset.sh in the provided codebase. We start by downloading the corpus approximately 30K Covid X-Ray images <ref type="foot" target="#foot_1">3</ref> . Then we download Covid-19 labels and Pneumonia labels <ref type="foot" target="#foot_2">4</ref> and attach labels to each image. Then we convert each image to black-white one-channel images and rescale each to a size of (128 × 128) pixels. Finally, a random split of the 30K images is performed: keeping 20K to be used during training, and 10K to be used as validation images. Note that the labels come with a set of 400 test images, but 400 images is too small to be an effective test set (say for FID computations). We will be explicit about where we use each data set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.5.2 Diffusion training details</head><p>We train a diffusion model to approximate P (X|C). To do this, we use a standard UNet and classifierfree guidance scheme. We train for 100K training steps over the 20K-sized training set, using a batch size of 16. This takes roughly 10 hours on a single A100. The same classifier-free guidance parameters are used as in the NapkinMNIST diffusion training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.5.3 Calibrated classifier training details</head><p>To train a classifier to sample from P (N |C, X), we note that our inputs are a (1, 128, 128) image and a binary variable. Our architecture is as follows: we create an embedding of X by modifying the final linear layer of a ResNet18 to have output dimension 64 (vs 1000), and modify the input channels to be 1. We create an embedding for N by using a standard embedding layer for binary variables, with embedding dimension 64. These embeddings are then concatenated and pushed through 3 fully connected layers with ReLU nonlinearities and dimension 128. A final fully-connected layer with 2 outputs is used to generate logits.</p><p>Training follows a standard supervised learning setup using cross entropy loss. We train for 100 epochs using a batch size of 256 and a standard warmup to decaying learning rate (see code for full details).</p><p>We note the deep literature suggesting that even though classifiers seek to learn P (N |X, C), neural networks trained using cross entropy loss do not actually do a very good job of estimating this distribution. Training attains an accuracy of 91.2% on the test set. Calibrated classification seeks to solve this problem by modifying the network in a way such that it more accurately reflects this distribution. We follow the standard approach using temperature scaling of the logits, where a temperature is learned over the validation set, using LBFGS with a learning rate of 0.0001 and a maximum of 10K iterations. This does not affect the test accuracy at all, but drastically improves the ECE and MCE reliability metrics. See Guo et al. <ref type="bibr" target="#b16">[17]</ref> for a further discussion of temperature scaling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.6 Covid X-Ray dataset</head><p>Data generation: Next we apply our algorithm to a real dataset using chest X-rays on COVID-19 patients. Specifically, we download a collection of chest X-rays (X) where each image has binary labels for the presence/absence of COVID-19 (C), and pneumonia (N) <ref type="bibr" target="#b55">[57]</ref> 5 . We imbue the causal samples versus a held-out validation set of 10K X-ray images. When samples are generated with C taken from the training distribution, we attain an FID score of 16.17. We then evaluate the conditional generation by comparing class-separated FID evaluations and display these results in Table <ref type="table">4</ref> (left). The classifier estimating P (n|x, c) has an accuracy of 91.9% over validation set. We note that we apply temperature scaling <ref type="bibr" target="#b16">[17]</ref> to calibrate our classifier, where the temperature parameter is trained over a random half of the validation set. Temperature scaling does not change the accuracy, but it does vastly improve the reliability metrics; see Appendix.</p><p>Finally we evaluate the query of interest P c (n). Since we cannot evaluate the ground truth, we consider our evaluated P c (n) versus an ablated version where we replace the diffusion sampling mechanism with P (x|c), where we randomly select an X-ray image from the held-out validation set. We also consider the query P c (n) if there were no latent confounders in the graph, in which case, the interventional query P c (n) is equal to P (n|c). We display the results in Table <ref type="table">4</ref> (right). if C(G) = {G} then {Step:5} 14:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Pseudo-codes</head><p>Return FAIL(G, G ∩ S) 15:</p><p>if S ∈ C(G) then {Step:6} 16:</p><p>Return s\y {i|V i ∈S} P (vi|v i-1 π ) 17:</p><p>if ∃S ′ s.t. S ⊂ S ′ ∈ C(G) then {Step:7} 18:</p><p>Return ID(y, x ∩ S ′ , P = {i|V i ∈S ′ } P (Vi|V • Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. • The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. • The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. • If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">Safeguards</head><p>Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Our paper does not pose such risks. Guidelines:</p><p>• The answer NA means that the paper poses no such risks.</p><p>• Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. • Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. • We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. 12. Licenses for existing assets Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We properly cited papers of all models, datasets we used. Guidelines:</p><p>• The answer NA means that the paper does not use existing assets.</p><p>• The authors should cite the original paper that produced the code package or dataset.</p><p>• The authors should state which version of the asset is used and, if possible, include a URL. • The name of the license (e.g., CC-BY 4.0) should be included for each asset.</p><p>• For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. • If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>PP</head><label></label><figDesc>(r|do(x)) = s P (s|do(x))P (r|do(x, s))Hospital Location (H) M S X P (s|do(x)) = P (s|x) M R M X ′ P (r|do(x, s)) = x ′ P (x ′ )P (r|x ′ , s) s P (s|x) x ′ P (x ′ )P (r|x ′ , s) (i|do(v)) =a,b P (a, b)P (i|do(v, a, b)) S e x ( S ) (a) ML model failure scenario M AB P (a, b) M I P (i|do(v, a, b)) = P (i|v, a, b) P (a, b)P (i|v, a, b) do(V = v) [A, B] (c) Merge and sample ancestrally.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (Top: x-ray to report generation task) (a) do(X = x) removes the X ↔ R bias and makes the generation of R domain invariant. P (r|do(x)) is factorized into c-factors and (b) conditional models ({M V k } k ) are trained for each factor (shown as boxes). (c) The intervened value X = x is propagated through the merged network and samples from the P (r|do(x)) are generated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: (Left:) Causal graph with color and thickness as unobserved. (Center:) FID scores (lower the better) of each algorithm and images generated from them. (Right:) Likelihood calculated from the P x (y) images generated by each algorithm. We closely reflect the true P x (y) with low TVD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: i) Graph and sampling network for P M ale (I 2 ). ii) For both causal and non-causal attributes, EGSDE shows high correlation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Left: Baseline vs our causal graph. Right: images for specific prompt w/ and w/o pneumonia. Inferred attributes are shown with their likelihood. Blue indicates changes compared to healthy.</figDesc><graphic coords="9,243.89,126.42,257.38,69.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Merge and sample P (y|do(x)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: do(R = r) removes the R ↔ X bias and makes prediction of X domain invariant. ID-GEN factorizes P (v|do(r)) into four factors and trains conditional models ({M Vi } i ) for each (blue shades). The intervened value R = r is propagated through the merged network to generate all other variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: ID-GEN Recursion Tree Example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>2 )</head><label>2</label><figDesc>number of models. For all c-components in C ≤l , we will train O(lkX /2) number of models. Finally, if we consider all c-components, we will train in total O((n -l)k + lkX /2) models. If the cost of training a diffusion model to learn a specific conditional distribution is O(T ), then the total training cost is O(T (n -l)k + T lkX /2). Note that, when there exists no confounders, we have k = 1 and the trining cost is O(T (n -l) + T l) = O(T n). Here |An(Y) G | = n. Existing algorithms train |V| number of models for a causal graph of V variables. Thus, their training cost is O(T |V|).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Lemma D. 11 .</head><label>11</label><figDesc>(Recursive trace) At any recursion level R, recursive call ID-GEN (Y, X, D, G, X, Ĝ) enters Step i if and only if recursive call ID(Y, X, P, G) enters Step i, for any i ∈<ref type="bibr" target="#b6">[7]</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: Joint samples from the Napkin-MNIST dataset: Samples from the Napkin-MNIST dataset are visualized as columns above. The first row indicates the latent variable color, the second row indicates the latent variable thickness, and the row labeled W 2 is a discrete variable holding a (color, digit), where digit is represented as the number of dots. Notice that the noising process sometimes causes information to not be passed to children.</figDesc><graphic coords="32,186.60,72.00,277.32,103.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Table 2 :Figure 16 :</head><label>216</label><figDesc>Figure 16: Samples from P (I 2 |do(M ale = 0). Row 1: original I 1 , Row 2: translated I 2 by StarGAN and Row3: translated I 2 by EGSDE.</figDesc><graphic coords="34,167.40,144.16,277.21,99.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Multi-domain image translation by EGSDE. Images in rows 1 and 3 are the original images (male domain) and images in rows 2 and 4 are translated images (female domain). Table3shows, 29.16% of the total images are translated as a young person.</figDesc><graphic coords="35,127.80,137.26,356.39,64.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Performance comparison of multi-domain image translation between StarGAN and EGSDE.</figDesc><graphic coords="35,147.60,450.59,316.80,93.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 19 :Figure 20 :</head><label>1920</label><figDesc>Figure 19: Samples from P (I 2 |Y oung = 1, do(M ale = 0)) generated by StarGAN. Models Distribution Matched TVD ↓ M N P (N ) 0.0595 M E P (E|N, R) 0.0512 M A P (A|N, E, R) 0.0451 M L P (L|N, E, A) 0.042 M X P (X|N, E, A, L) Pretrained Figure 20: CXR conditional models in the sampling network.</figDesc><graphic coords="36,137.70,245.25,336.60,60.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>F. 4 F. 4 . 1</head><label>441</label><figDesc>Explaining foundation model output for chest X-ray generation Causal graph</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 21 :</head><label>21</label><figDesc>Figure 21: Two prompts, their CXR images, and inferred attributes with the likelihood to appear. Blue regions indicate changes compared to the healthy X-ray.</figDesc><graphic coords="38,108.00,180.26,396.00,99.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Algorithm 5 1 : 8 := ∅ 9 : 1 : 2 :</head><label>518912</label><figDesc>IDC-GEN (Y, X, Z, D, G) Input: target Y , intervention X , conditioning set Z. training data D, G. 2: Output: A DAG of trained model to sample from P X (Y|Z).3: if ∃α ∈ Z such that (Y ⊥ ⊥ α|X, Z \ {α})G X,α then 4: return IDC-GEN (Y, X ∪ {α}, Z \ {α}, D, G) 5: else 6: H1= ID-GEN (Y ∪ Z, X, D, X = ∅, Ĝ = G) 7: D ′ ∼ H1(X) H2 Add node (X, ∅) and (Z, ∅) to H2 10:Let MY be a model trained on {Y, X, Z} ∼ D ′ such that MY (X, Z)∼ P ′ (Y |X, Z) i.e., MY (X, Z) ∼ PX (Y |Z) 11:Add node (Y, MY ) to H2 12:Add edge X → Y and Z → Y to H2 13: return H2Algorithm 6 ID(y, x, P, G) Input: y, x value assignments , distribution P , G. Output: Expression for Px(y) in terms of P or Fail(F, F ′ ).3: if x = ∅ then {Step:1} 4: Return v\y P (v) 5: if V \ An(Y)G ̸ = ∅ then {Step:2} 6: Return ID(y, x ∩ An(Y)G, V\An(Y) G P, G An(Y) ) 7: Let W = (V \ X) \ An(Y)G X {Step:3} 8: if W ̸ = ∅ then 9:Return ID(y, x ∪ w, P, G) 10: if C(G \ X) = {S1, . . . , S k } then {Step:4} 11:Return v\(y∪x) i ID(si, v \ si, P, G) 12: if C(G \ X) = {S} then 13:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>(i- 1 1 : 2 :</head><label>112</label><figDesc>) π ∩ S ′ , v (i-1) π \ S ′ ), G S ′ )Algorithm 7 IDC(Y, X, Z, P, G) Input: x, y, z value assignments, P a probability distribution, G a causal diagram (an I-map of P ). Output: Expression for PX (Y |Z) in terms of P or Fail(F, F').3:if ∃α ∈ Z such that (Y ⊥ ⊥ α|X, Z \ {α})G X,α then 4:return IDC(Y, X ∪ {α}, Z \ {α}, D, G) 5: else 6:let P ′ = ID(y ∪ z, x, P, G) 7:return P ′ / y P ′</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Ĝ{S ′ , X} which utilizes the larger c-component S ′ to partition the intervention set X into one set contained within S ′ , i.e., X ∩ S ′ , and another set not contained in S ′ , i.e., X Z = X \ S ′ . Evaluating P x (y) from P (v) is equivalent to evaluating P x∩s ′ (y) from P ′ (v) where P ′ (v) := P xz (v) is the joint distribution. Hence, we first perform do(X Z ) to update the dataset as D ′ . Next, we shift our goal of sampling from P x (y) in G with training dataset D ∼ P (V) to sampling from P x∩s ′ (y) in Ĝ{S ′ , X} with training data D ′ ∼ P xz (v) in the next recursive calls. To generate dataset D ′ ∼ P xz (v), we call ConditionalGMs(.) and use the returned network to sample D ′ (lines 2-3).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Evaluations on the Napkin-MNIST generated dataset. V.d, V.c, V.t refer to the digit, color and thickness respectively of variable V . The first column is with respect to samples generated from diffusion model P (X, Y | W 1 , W 2 ), Image Data is the dataset used to train P , Discrete Data is the empirical distribution according to a discrete Napkin-MNIST, and the ground truth is analytically computed. Ideally all values should be equal across a row. While our synthetic dataset generated from P is not a perfect representation, it is quite close in all attributes except thickness. This is because the classifier for thickness has some inherent error in it, as evidenced by the mismatch between the base data and ground truth in the thickness rows.P (Y, X | W 1 , W 2 ) Image Data Discrete Data Ground Truth</figDesc><table><row><cell>P [X.d = W 2 .d]</cell><cell>0.931</cell><cell>0.895</cell><cell>0.909</cell><cell>0.910</cell></row><row><cell>P [X.c = W 2 .c]</cell><cell>0.964</cell><cell>0.950</cell><cell>0.950</cell><cell>0.950</cell></row><row><cell>P [X.t = W 1 .t]</cell><cell>0.683</cell><cell>0.776</cell><cell>0.879</cell><cell>0.873</cell></row><row><cell>P [Y.d = X.d]</cell><cell>0.927</cell><cell>0.895</cell><cell>0.909</cell><cell>0.910</cell></row><row><cell>P [Y.c = W 1 .c]</cell><cell>0.847</cell><cell>0.841</cell><cell>0.841</cell><cell>0.842</cell></row><row><cell>P [Y.t = X.t]</cell><cell>0.830</cell><cell>0.851</cell><cell>0.933</cell><cell>0.933</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Additional attributes added (in percentage) in the translated images.</figDesc><table><row><cell cols="6">WearingLipstick HeavyMakeup ArchedEyebrows OvalFace Attractive Young</cell></row><row><cell>Added Attribute (%) 87.5</cell><cell>79.16</cell><cell>66.66</cell><cell>54.16</cell><cell>37.5</cell><cell>29.16</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://github.com/dccastro/Morpho-MNIST/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://www.kaggle.com/datasets/andyczhao/covidx-cxr2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://github.com/giocoal/CXR-ACGAN-chest-xray-generator-covid19-pneumonia</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Labels are from https://github.com/giocoal/CXR-ACGAN-chest-xray-generator-covid19-pneumonia/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments and Disclosure of Funding</head><p>This research has been supported in part by <rs type="funder">NSF</rs> <rs type="grantNumber">CAREER 2239375</rs>, <rs type="grantNumber">IIS 2348717</rs>, <rs type="funder">Amazon Research Award and Adobe Research</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_YhRgZXx">
					<idno type="grant-number">CAREER 2239375</idno>
				</org>
				<org type="funding" xml:id="_TuXFKdT">
					<idno type="grant-number">IIS 2348717</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Step 5: Step 5 is a base case for both algorithms, and if both algorithms are at step 5, they return FAIL. This step represents the non-identifiability case. Thus, ID-GEN goes to the same step at recursion level R = r + 1 iff ID goes to the same step, which in this case is Return.</p><p>Step 6: Step 6 is a base case for both algorithms. ID calculates the product of a set of conditional distributions P (v i |v i-1 π ) and returns it. While ID-GEN trains conditional models M Vi (V (i-1) π</p><p>) to learn those conditional distributions, ID-GEN returns a sampling network after connecting these models. Both algorithms end the recursion here and return different objects but that will not affect their future trace. Thus, ID-GEN goes to the same step at recursion level R = r + 1 iff ID goes to the same step which in this case is Return.</p><p>Step 7: ID algorithm at step 7, updates its distribution parameter P with P xz (S ′ ). On the other hand, ID-GEN generates do(X Z ) interventional samples. Both algorithms update their parameters set Y, X and G in the same way as Y = Y, X = X ∩ S ′ (or X \ X Z since X ∩ S ′ = X \ X Z ) and G = G S ′ . Since they leave for the next recursive call with the same set of parameters Y, X, G, at recursion level R = r + 1, ID-GEN visits step i iff ID visits step i, ∀i ∈ <ref type="bibr" target="#b6">[7]</ref>.</p><p>Therefore, we have proved by induction that ID-GEN (Y, X, G, D, X, Ĝ) enters Step i if and only if ID(Y, X, P, G) enters Step i, for any i ∈ <ref type="bibr" target="#b6">[7]</ref> for any recursion level R.</p><p>Lemma D.12. Termination: Let P x (Y) be a query for causal graph G = (V, E) and D ∼ P (V). Then the recursions induced by ID-GEN (Y, X, G, D, X, Ĝ) terminate in either step 1, 5, or 6.</p><p>Proof. The result follows directly from Lemma D.11: Consider any causal query P x (Y). Since ID is complete, the query -whether it is identifiable or not -terminates in one of the steps 1, 5, or 6. By Lemma D.11, ID-GEN follows the same steps as ID, and hence also terminates in one of these steps.</p><p>Lemma D. <ref type="bibr" target="#b12">13</ref>. Consider the recursive calls ID( * , G ID ) and ID-GEN( * , G ID-GEN , X, Ĝ) at any level of the recursion. Then G ID = G ID-GEN and G ID = Ĝ \ X.</p><p>Proof. According to Lemma D.11, ID and ID-GEN follow the same recursive trace. Thus, at any recursion level, both algorithms will stay at step i ∈ <ref type="bibr" target="#b6">[7]</ref>.</p><p>Base case: At recursion level R = 0, both ID and ID-GEN start with the same input causal graph G. Thus, G ID = G ID-GEN = Ĝ = G. Also at R = 0, the set of intervened variables X = ∅. Thus, G ID = Ĝ \ ∅ = G holds.</p><p>Induction hypothesis: At any recursion level R = r, let G r ID be the graph parameter of the ID algorithm and {G r ID-GEN , Xr , Ĝr } be the parameters for the ID-GEN algorithm. We assume that G r ID = G r ID-GEN and G r ID = Ĝr \ Xr .</p><p>At this step, we marginalize over V \ An(Y). Since X ⊂ An(Y) Ĝ, marginalizing non-ancestors out does not impact X. Thus,</p><p>. This holds true since we can marginalize over V \ An(Y) G in the joint interventional distribution.</p><p>In the ID-GEN algorithm, we drop the values of variables</p><p>At step 7: At step 7, both ID and ID-GEN algorithm intervened on variable set X Z where X Z = X \ S ′ . Thus, at level R = r + 1, we have Xr+1 = Xr ∪ X Z . Note that at this step, S ′ = V \ X Z .</p><p>ID algorithm updates its current distribution parameter P r ID by intervening on X Z . Thus, at level</p><p>Thus the claim holds for ID algorithm at level R = r + 1.</p><p>In the ID-GEN algorithm, we generate an interventional dataset</p><p>Thus, the claim holds true for ID-GEN at the recursion level R = r + 1.</p><p>Therefore, P (.) being the input distribution for ID and D ∼ P (.) being the input dataset for ID-GEN, we proved by induction that P ID = P x(v) and D[ X, V] ∼ P x(x, v) at any recursion level.</p><p>Proof. At any level R = r of the recursion , we have G ID = G ID-GEN and G ID = Ĝ \ X according to Lemma D.13 and P ID = P x(v) and D[ X, V] ∼ P x(x, v) according to Lemma D.14 where P (v) is the input observational distribution.</p><p>Let D[ X, V] ∼ P x(x, v) = P ID-GEN (x, v), ∀x. Now, since in Ĝ we have already intervened on X, for fixed X = x, we have P x(x, v) = P x(x) * P x(v|x) = P x(v|x), thus V will be sampled from P ID-GEN (v|x) for fixed consistent X = x.</p><p>On the other hand, in the ID algorithm, at any recursion level, P ID (v) = P x(v) for fixed consistent X = x and G ID = Ĝ \ X.</p><p>Since according to Lemma D.14, P ID = P x(v) and D[ X, V] ∼ P x(x, v) at any recursion level, i.e., starting from the same P (V), the same set of interventions are performed in the same manner in both algorithms; thus for fixed X = x, we obtain P ID (v) = P ID-GEN (v|x) . Lemma D. <ref type="bibr" target="#b15">16</ref>. If a non-identifiable query is passed to it, ID-GEN will return FAIL.</p><p>Proof. Suppose ID-GEN is given a non-identifiable query as input. Since the ID algorithm is complete, if ID is given this query, it will reach its step 5 and return FAIL. According to the lemma D.11, ID-GEN follows the same trace and the same sequence of steps as ID for a fixed input. Since for the non-identifiable query ID reaches step 5, ID-GEN will also reach step 5 and return FAIL.</p><p>Lemma D.17. ID-GEN Base case (step 1):</p><p>Let, at any recursion level of ID-GEN, the input dataset D[ X, V] is sampled from a specific joint distribution P ( X, V), i.e., D[ X, V] ∼ P ( X, V) where X is the set of intervened variables at step 7s. Given a target interventional query P (y) over a causal graph G = (V, E), suppose ID-GEN  Proof. Since the intervention set X is empty, we are at the base case step 1 of ID-GEN. Suppose that for the same query, the ID algorithm reaches step 1. Let P ID (v) be the current distribution of the ID algorithm after performing a series of marginalizations in step 2 and intervention in step 7 on the input observational distribution. D[ X, V] is the dataset parameter of ID-GEN algorithm that went through the same transformations as the ID algorithm in the sample space according to Lemma D. <ref type="bibr" target="#b14">15</ref> Proof. We proceed by structural induction. We start from the base cases, i.e., the steps that do not call ID-GEN again. ID-GEN only has three base cases: step 1 is the case when no variables are being intervened upon and is covered by Lemma D.17; step 6 is the other base case and is covered by Lemma D.18; step 5 is the non-identifiable case and since we assumed that P x (y) is identifiable, we can skip ID-GEN's step 5.</p><p>The structure of our proof is as follows. By the assumption that P x (y) is identifiable and due to Lemma D.12, its recursions must terminate in steps 1 or 6. Since we have already proven correctness for these cases, we use these as base cases for a structural induction. We prove that if ID-GEN enters any of step 2, 3, 4 or 7, under the inductive assumption that we have correct sampling network for the recursive calls, we can produce a correct overall sampling network. The general flavor of these inductive steps adheres to the following recipe: i) determine the corresponding recursive call that ID algorithm makes; ii) argue that we can generate the correct dataset to be analogous to the distribution that ID uses in the recursion; iii) rely on the inductive assumption that the generated DAG from ID-GEN's recursion is correct.</p><p>We consider each recursive case separately. We start with step 2. Suppose ID-GEN (Y, X, G, D, X, Ĝ) enters step 2, then according to Lemma D.11, ID(Y, X, P, G) enters step 2 as well. Hence the correct distribution to sample from is provided by ID step 2:</p><p>Now, according to Lemma D.15, at the current step, the dataset D of ID-GEN is sampled from a distribution P ′ (v|x) such that for fixed values of X = x, P (v) = P ′ (v|x) holds true. Following our recipe, we need to update the dataset D such that it is sampled from V \An(Y</p><p>We do this by dropping all non-ancestor variables of Y (in the graph G) from the dataset D, thereby attaining samples from the joint distribution V\An(Y) G P (v). Since Ĝ is used at the base case, we update it as ĜAn(Y) , the same as G An(Y) to propagate the correct graph at the next step. Therefore, we can generate the sampling network from ID-GEN(Y,</p><p>) by the inductive assumption and simply return it.</p><p>Next, we consider step 3. Suppose ID-GEN (Y, X, G, D, X, Ĝ) enters step 3. Then by Lemma D.11, ID(Y, X, P, G) enters step 3, and the correct distribution to sample from is provided from ID step 3 as</p><p>where ID-GEN Termination Figure <ref type="figure">14</ref>: Flow Chart of Proofs correct for P X∪W (Y) by the inductive assumption. Thus, the returned sampling network by ID-GEN can sample from P x (y). While we do need to specify a sampling mechanism for W to satisfy our definition of a valid sampling network, this can be chosen arbitrarily, say W ∼ P (w) or uniform the distribution.</p><p>Next we consider step 4. Suppose ID-GEN (Y, X, G, D, X, Ĝ) enters step 4. Then by Lemma D.11, ID(Y, X, P, G) enters step 4 and the correct distribution to sample from is provided from ID step 4 as:</p><p>where S i are the c-components of G \ X, i.e., elements of C(G \ X). By the inductive assumption, we can sample from each term in the product with the sampling network returned by ID-GEN(S i , X = V \ S i , G, D, X, Ĝ). However, recall the output of ID-GEN: ID-GEN returns a 'headless' (no conditional models for X) sampling network as follows:</p><p>ID-GEN (Y, X, G, D, X, Ĝ) returns a sampling network, i.e., a collection of conditional generative models where for each variable in G and every variable except those in X have a specified conditional generative model. To sample from this sampling network, values for X must first be specified. In the step 4 case, the values v \ s i need to be provided to sample values for S i , and similarly for i ̸ = j, values v \ s j are needed to sample values for S j . Since S i ⊆ (V \ S j ) and S j ⊆ (V \ S i ), it might lead to cycles (as shown in Example C.1) if we attempt to generate samples for each c-components sequentially. Thus, it does not suffice to sample from each c-component sequentially or separately.</p><p>Note that, H i is the correct sampling network corresponding to ID-GEN(S i , X = V\S i , G, D, X, Ĝ) by definition, for each node V i ∈ S i , V i has a conditional generative model in H i . By Lemma D.20, each edge in H i adheres to the topological ordering π G (at the current level). Hence, if we apply MergeNetwork(.) to construct a graph H from {H i } i , it will also adhere to the original topological ordering π G . Thus, H is a DAG.</p><p>Since every node V i in G \ X has a conditional generative model in some H i , the only nodes in combined H without conditional generative models are those in X. Finally, since each node in H samples the correct conditional distribution by the inductive assumption, H samples from the product distribution P x (y) corretly. The sum v\(y∪x) can be safely ignored now and can be applied later since the sample values of the marginalized variables (v \ (y ∪ x)) can be dropped from the joint at the end of the algorithm to attain samples values of the remaining variables. Hence H is correct for P x (y).</p><p>Step 5 can never happen by the assumption that P x (y) is identifiable, and step 6 has already been covered as a base case. The only step remaining is step 7.</p><p>Lemma D.11 says, ID-GEN (Y, X, G, D, X, Ĝ) enters step 7 by the same conditions ID(Y, X, P, G) enters step 7. Then by assumption, C(G \ X) = {S} and there exists a confounding component S ′ ∈ C(G) such that S ⊂ S ′ . The correct distribution to sample from is probability 0.1, the information passed along is chosen in a uniformly random manner from the valid range.</p><p>Here we describe the data-generation procedure, and training setup for the Napkin-MNIST experiment in full detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2.1 Data generation procedure: discrete case</head><p>As a warm-up, we outline the generation for the Napkin-MNIST dataset in a low-dimensional setting. When we consider in the next section the high-dimensional case, we simply replace some of these discrete variables with MNIST images which can be mapped back into this low-dimensional case.</p><p>We start by enumerating the joint distribution and the support of each marginal variable. First lets define the sets • COLORS := {red, green, blue, yellow, magenta, cyan}.</p><p>• RG_COLORS := {red, green}.</p><p>• THICKNESSES := {thin, regular, thick}.</p><p>• DIGITS := {0, . . . , 9}.</p><p>And then the definitions and support of each of the variables in our distribution:</p><p>Now we describe the full data generation procedure. A key hyperparameter is a noise-probability p. This defines the probability that any variable flips to a uniform probability. To ease notation, we define the function η p (v, S) defined as Where U (S) means a uniformly random choice of S. Then our data generation procedure follows the following steps:</p><p>It is easy to verify that this describes the Napkin graph, as each only Color, Thickness are latent and each variable only depends on its parents in the SCM.</p><p>Secondly, observe that this structural causal model is separable with respect to digits, colors, and thicknesses. Since each digit only depends on parent digits, each color only depends on parent colors, and each thickness depends only on parent thicknesses, these can all be considered separately. Component Models: Applying ID-GEN to this graph requires access to two conditional distributions: P (x|c) and P (n|x, c). Since X is a high-dimensional image, we train a conditional diffusion model to approximate the former. Since N is a binary variable, we train a classifier that accepts X, C and returns a Bernoulli distribution for N . The generated sampling network operates by sampling an X given the interventional C, and then sampling an auxiliary C ′ ∼ P (c ′ ) and feeding X, C ′ to the classifier for P (n|x, c), finally sampling from this distribution.</p><p>Evaluation: Again we do not have access to the ground truth. Instead, we focus on the evaluation of each component model, and we also perform an ablation on our diffusion model. We first evaluate the image quality of the diffusion model approximating P (x|c). We evaluate the FID of generated Guidelines:</p><p>• The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. • The authors are encouraged to create a separate "Limitations" section in their paper.</p><p>• The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. • The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. • The authors should reflect on the factors that influence the performance of the approach.</p><p>For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. • The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. • If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. • While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Theory Assumptions and Proofs</head><p>Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: <ref type="bibr">[Yes]</ref> Justification: We provide all our theoretical claims and their proofs in Appendix D. Guidelines:</p><p>• The answer NA means that the paper does not include theoretical results.</p><p>• All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced. • All assumptions should be clearly stated or referenced in the statement of any theorems.</p><p>• The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. • Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. • Theorems and Lemmas that the proof relies upon should be properly referenced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Result Reproducibility</head><p>Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer:[Yes] Justification: We discuss reproducibility in Appendix F.1.1. Guidelines:</p><p>• The answer NA means that the paper does not include experiments.</p><p>• If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. • If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. • Depending on the contribution, reproducibility can be accomplished in various ways.</p><p>For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. • While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility.</p><p>In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Open access to data and code</head><p>Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?</p><p>Answer: <ref type="bibr">[Yes]</ref> Justification: We provide our source code as supplementary material and also as a github repo.</p><p>Guidelines:</p><p>• The answer NA means that paper does not include experiments requiring code. • Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental Setting/Details</head><p>Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?</p><p>Answer: <ref type="bibr">[Yes]</ref> Justification: We provide the experimental details in Appendix F.</p><p>Guidelines:</p><p>• The answer NA means that the paper does not include experiments.</p><p>• The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. • The full details can be provided either with the code, in appendix, or as supplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experiment Statistical Significance</head><p>Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?</p><p>Answer: <ref type="bibr">[Yes]</ref> Justification: We provided appropriate information about the statistical significance of the MIMIC-CXR experiment in Section 4.3. We did not provide such evaluations for the Colored-MNIST or CelebA datasets, as we obtained consistent results in multiple runs. We plan to run our algorithm on larger datasets and will include error bars in those experiments.</p><p>Guidelines:</p><p>• The answer NA means that the paper does not include experiments.</p><p>• The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. • The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).</p><p>• The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) • The assumptions made should be given (e.g., Normally distributed errors). • It should be clear whether the error bar is the standard deviation or the standard error of the mean. • It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. • For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). • If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Experiments Compute Resources</head><p>Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?</p><p>Answer: [Yes] Justification: We discuss about the computing resources for each experiment in Appendix F.1.</p><p>Guidelines:</p><p>• The answer NA means that the paper does not include experiments.</p><p>• The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. • The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. • The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Code Of Ethics</head><p>Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics <ref type="url" target="https://neurips.cc/public/EthicsGuidelines">https://neurips.cc/public/EthicsGuidelines</ref>?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: [Yes]</head><p>Justification: Yes, our research in the paper conform, in every respect, with the NeurIPS Code of Ethics Guidelines:</p><p>• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.</p><p>• If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. • The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Broader Impacts</head><p>Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?</p><p>Answer: [Yes] Justification: We discuss the broader impact of our work in Appendix B.</p><p>Guidelines:</p><p>• The answer NA means that there is no societal impact of the work performed.</p><p>• If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.</p><p>• For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. • If this information is not available online, the authors are encouraged to reach out to the asset's creators. • We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. • For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Partial identification of treatment effects with implicit generative models</title>
		<author>
			<persName><forename type="first">Balazadeh</forename><surname>Vahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasilis</forename><surname>Meresht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul G</forename><surname>Syrgkanis</surname></persName>
		</author>
		<author>
			<persName><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22816" to="22829" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Causal inference by surrogate experiments: z-identifiability</title>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On pearl&apos;s hierarchy and the foundations of causal inference</title>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">D</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duligur</forename><surname>Ibeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Icard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Probabilistic and causal inference: the works of judea pearl</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="507" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning and sampling of atomic interventions from observations</title>
		<author>
			<persName><forename type="first">Arnab</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sutanu</forename><surname>Gayen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saravanan</forename><surname>Kandasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashwin</forename><surname>Maran</surname></persName>
		</author>
		<author>
			<persName><surname>Vinodchandran</surname></persName>
		</author>
		<author>
			<persName><surname>Variyam</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="842" to="853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient interventional distribution learning in the pac framework</title>
		<author>
			<persName><forename type="first">Arnab</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sutanu</forename><surname>Gayen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saravanan</forename><surname>Kandasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Raval</surname></persName>
		</author>
		<author>
			<persName><surname>Vinodchandran</surname></persName>
		</author>
		<author>
			<persName><surname>Variyam</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="7531" to="7549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer google schola</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="645" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Making the most of text semantics to improve biomedical vision-language processing</title>
		<author>
			<persName><forename type="first">Benedikt</forename><surname>Boecking</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naoto</forename><surname>Usuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruthi</forename><surname>Bannur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Schwaighofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Hyland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Wetscherek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><surname>Alvarez-Valle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Morphomnist: quantitative assessment and diagnostics for representation learning</title>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Daniel C Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ender</forename><surname>Kainz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">178</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bias analysis on public x-ray image datasets of pneumonia and covid-19 patients</title>
		<author>
			<persName><forename type="first">Omar</forename><surname>Del</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tejo</forename><surname>Catalá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ismael</forename><forename type="middle">Salvador</forename><surname>Igual</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Javier Pérez-Benito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Millán Escrivá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vicent</forename><surname>Ortiz Castelló</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Llobet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan-Carlos</forename><surname>Perez-Cortes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ieee Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="42370" to="42383" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Chambon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Bluethgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Benoit</forename><surname>Delbrouck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rogier</forename><surname>Van Der Sluijs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Małgorzata</forename><surname>Połacin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Manuel Zambrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanishq</forename><surname>Chaves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivanshu</forename><surname>Mathew Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Curtis</forename><forename type="middle">P</forename><surname>Purohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshay</forename><surname>Langlotz</surname></persName>
		</author>
		<author>
			<persName><surname>Chaudhari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.12737</idno>
		<title level="m">Roentgen: Vision-language foundation model for chest x-ray generation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Blöbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiva</forename><surname>Prasad Kasiviswanathan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.00860</idno>
		<title level="m">Interventional and counterfactual inference with diffusion models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Stargan: Unified generative adversarial networks for multi-domain image-to-image translation</title>
		<author>
			<persName><forename type="first">Yunjey</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minje</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Munyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cleveland</forename><surname>Clinic</surname></persName>
		</author>
		<author>
			<persName><surname>Atelectasis</surname></persName>
		</author>
		<ptr target="https://my.clevelandclinic.org/health/diseases/17699-atelectasis" />
		<imprint>
			<date type="published" when="2024-05-12">May 12, 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Diffusion models in vision: A survey</title>
		<author>
			<persName><surname>Florinel-Alin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Croitoru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Hondru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tudor</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Explaining classifiers with causal concept effect (cace)</title>
		<author>
			<persName><forename type="first">Yash</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.07165</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Jawook</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han-Cheol</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiho</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kihyun</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eun</forename><forename type="middle">Kyoung</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byungseok</forename><surname>Roh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.11505</idno>
		<title level="m">Chex-gpt: Harnessing large language models for enhanced chest x-ray report labeling</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">On calibration of modern neural networks</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Lung opacity: Symptoms, causes, diagnosis, and treatment</title>
		<author>
			<persName><surname>Healthline</surname></persName>
		</author>
		<ptr target="https://www.healthline.com/health/lung-opacity" />
		<imprint>
			<date type="published" when="2024-05-12">May 12, 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Estimation of causal effects with small data in the presence of trapdoor variables</title>
		<author>
			<persName><forename type="first">Jouni</forename><surname>Helske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santtu</forename><surname>Tikka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juha</forename><surname>Karvanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series A: Statistics in Society</title>
		<imprint>
			<biblScope unit="volume">184</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1030" to="1051" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Classifier-free diffusion guidance</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.12598</idno>
		<title level="m">Classifier-free diffusion guidance</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Identifiability in causal bayesian networks: A sound and complete algorithm</title>
		<author>
			<persName><forename type="first">Yimin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Valtorta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national conference on artificial intelligence</title>
		<meeting>the national conference on artificial intelligence<address><addrLine>Menlo Park, CA; Cambridge, MA; London</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press; MIT Press</publisher>
			<date type="published" when="1999">1999. 2006</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">1149</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mimic-cxr, a de-identified publicly available database of chest radiographs with free-text reports</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Alistair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">J</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathaniel</forename><forename type="middle">R</forename><surname>Berkowitz</surname></persName>
		</author>
		<author>
			<persName><surname>Greenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Ying</forename><surname>Matthew P Lungren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><forename type="middle">G</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><surname>Horng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">317</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning causal effects via weighted empirical risk minimization</title>
		<author>
			<persName><forename type="first">Yonghan</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="12697" to="12709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Causalgan: Learning causal implicit generative models with adversarial training</title>
		<author>
			<persName><forename type="first">Murat</forename><surname>Kocaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriram</forename><surname>Vishwanath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Finding invariant predictors efficiently via causal structure</title>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Musfiqur Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murat</forename><surname>Kocaoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1196" to="1206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">General identifiability with arbitrary surrogate experiments</title>
		<author>
			<persName><forename type="first">Sanghack</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">D</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in artificial intelligence</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="389" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015-12">December 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Causal effect inference with deep latent-variable models</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<ptr target="https://www.mayoclinic.org/diseases-conditions/pneumonia/symptoms-causes/syc-20354204" />
		<title level="m">Mayo Clinic. Pneumonia -symptoms and causes</title>
		<imprint>
			<date type="published" when="2024-05-12">May 12, 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<ptr target="https://www.mayoclinic.org/diseases-conditions/atelectasis/symptoms-causes/syc-20369684" />
		<title level="m">Atelectasis -symptoms and causes</title>
		<imprint>
			<date type="published" when="2024-05-12">May 12, 2024</date>
		</imprint>
		<respStmt>
			<orgName>Mayo Clinic Staff</orgName>
		</respStmt>
	</monogr>
	<note>text=Various%20types%20of%20pneumonia%2C%20which,of%20a%20lung%20to% 20collapse</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName><surname>Medscape</surname></persName>
		</author>
		<author>
			<persName><surname>Hyponatremia</surname></persName>
		</author>
		<ptr target="https://emedicine.medscape.com/article/296468-overview?form=fpf" />
		<imprint>
			<date type="published" when="2024-05-12">May 12, 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Measuring axiomatic soundness of counterfactual image models</title>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><forename type="middle">De</forename><surname>Sousa Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">C</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.01274</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep structural causal models for tractable counterfactual inference</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel Coelho De</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="857" to="869" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Causality: models, reasoning, and inference</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Causal diagrams for empirical research</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">The book of why: the new science of cause and effect. Basic books</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Mackenzie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Modular learning of deep causal generative models for high-dimensional causal inference</title>
		<author>
			<persName><forename type="first">Md</forename><surname>Musfiqur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahman</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Murat</forename><surname>Kocaoglu</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=bOhzU7NpTB" />
	</analytic>
	<monogr>
		<title level="m">Forty-first International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">High fidelity image counterfactuals with probabilistic causal models</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sousa</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.15764</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Diffusion causal models for counterfactual estimation</title>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sotirios</forename><forename type="middle">A</forename><surname>Tsaftaris</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.10166</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Estimating individual treatment effect: generalization bounds and algorithms</title>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Fredrik D Johansson</surname></persName>
		</author>
		<author>
			<persName><surname>Sontag</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3076" to="3085" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Interpreting the latent space of gans for semantic face editing</title>
		<author>
			<persName><forename type="first">Yujun</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinjin</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9243" to="9252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Identification of joint interventional distributions in recursive semi-Markovian causal models</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Shpitser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Complete identification methods for the causal hierarchy</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Shpitser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1941" to="1979" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenlin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02502</idno>
		<title level="m">Denoising diffusion implicit models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Preventing failures due to dataset shift: Learning predictive models that transport</title>
		<author>
			<persName><forename type="first">Adarsh</forename><surname>Subbaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Schulam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suchi</forename><surname>Saria</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3118" to="3127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Evaluating model robustness and stability to dataset shift</title>
		<author>
			<persName><forename type="first">Adarsh</forename><surname>Subbaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suchi</forename><surname>Saria</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2611" to="2619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Studies in causal reasoning and learning</title>
		<author>
			<persName><forename type="first">Jin</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>University of California, Los Angeles</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">A general identification condition for causal effects</title>
		<author>
			<persName><forename type="first">Jin</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">On the identification of causal effects</title>
		<author>
			<persName><forename type="first">Jin</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; L</forename></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Lab</surname></persName>
		</author>
		<idno>R-290</idno>
		<ptr target="https://ftp.cs.ucla.edu/pub/stat_ser/R290-L.pdf" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Enhancing identification of causal effects by pruning</title>
		<author>
			<persName><forename type="first">Santtu</forename><surname>Tikka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juha</forename><surname>Karvanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">194</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Equivalence and synthesis of causal models. Probabilistic and Causal Inference</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<ptr target="https://api.semanticscholar.org/CorpusID" />
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page">27807863</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">An adaptive kernel approach to federated learning of heterogeneous causal effects</title>
		<author>
			<persName><forename type="first">Thanh Vinh</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnab</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Young</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tze-Yun</forename><surname>Leong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24459" to="24473" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Compositional probabilistic and causal inference using tractable circuit models</title>
		<author>
			<persName><forename type="first">Benjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Kwiatkowska</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="9488" to="9498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Covid-net: a tailored deep convolutional neural network design for detection of covid-19 cases from chest x-ray images</title>
		<author>
			<persName><forename type="first">Linda</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhong</forename><surname>Qiu Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Wong</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-020-76550-z</idno>
		<ptr target="https://doi.org/10.1038/s41598-020-76550-z" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<idno type="ISSN">2045-2322</idno>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">19549</biblScope>
			<date type="published" when="2020-11">Nov 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The causal-neural connection: Expressiveness, learnability, and inference</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Zhan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="10823" to="10836" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Neural causal models for counterfactual identification and estimation</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Muyuan Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=vouQcZS8KfW" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Vision paper: causal inference for interpretable and robust machine learning in mobility analysis</title>
		<author>
			<persName><forename type="first">Yanan</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natasa</forename><surname>Tagasovska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Perez-Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Raubal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Advances in Geographic Information Systems</title>
		<meeting>the 30th International Conference on Advances in Geographic Information Systems</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Interventional sum-product networks: Causal inference with tractable probabilistic models</title>
		<author>
			<persName><forename type="first">Matej</forename><surname>Zečević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Dhami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Athresh</forename><surname>Karanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriraam</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="15019" to="15031" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A causal view on robustness of neural networks</title>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingzhen</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="289" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Treatment effect estimation with disentangled latent factors</title>
		<author>
			<persName><forename type="first">Weijia</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiuyong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="10923" to="10930" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongxuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.06635</idno>
		<title level="m">Egsde: Unpaired image-to-image translation via energy-guided stochastic differential equations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
