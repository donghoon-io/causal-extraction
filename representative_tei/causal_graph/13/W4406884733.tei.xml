<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ARE TRANSFORMERS ABLE TO REASON BY CON-NECTING SEPARATED KNOWLEDGE IN TRAINING DATA?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-10-11">11 Oct 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yutong</forename><surname>Yin</surname></persName>
							<email>yutongyin2028@u.northwestern.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Northwestern University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhaoran</forename><surname>Wang</surname></persName>
							<email>zhaoranwang@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Northwestern University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ARE TRANSFORMERS ABLE TO REASON BY CON-NECTING SEPARATED KNOWLEDGE IN TRAINING DATA?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-10-11">11 Oct 2025</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2501.15857v8[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Humans exhibit remarkable compositional reasoning by integrating knowledge from various sources. For example, if someone learns ( B = f(A) ) from one source and ( C = g(B) ) from another, they can deduce ( C=g(B)=g(f(A)) ) even without encountering ( ABC ) together, showcasing the generalization ability of human intelligence. In this paper, we introduce a synthetic learning task, "FTCT" (Fragmented at Training, Chained at Testing), to validate the potential of Transformers in replicating this skill and interpret its inner mechanism 1 . During training, data consist of separated knowledge fragments from an overall causal graph. In testing, Transformers must combine these fragments to infer complete causal traces. Our findings demonstrate that few-shot Chain-of-Thought prompting enables Transformers to perform compositional reasoning on FTCT by revealing correct combinations of fragments, even if such combinations were absent in training data. Furthermore, the emergence of compositional reasoning ability is strongly correlated with model complexity and training-testing data similarity. We propose, both theoretically and empirically, that Transformers learn an underlying generalizable program from training, enabling effective compositional reasoning during testing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Humans exhibit a generalized reasoning ability that integrates knowledge from diverse sources. For example, if one learns ( B = f(A) ) from one source and ( C = g(B) ) from another, they can deduce ( C = g(B)=g(f(A)) ) without direct exposure to ( ABC ). We formally define this capability as compositional reasoning-the skill to integrate discrete pieces of knowledge from multiple sources to form coherent reasoning, even in the absence of explicit examples connecting these pieces during learning. This ability is a manifestation of systematic compositionality-understanding and generating an infinite number of expressions by combining a finite set of known components and rules <ref type="bibr" target="#b19">(Fodor &amp; Pylyshyn, 1988;</ref><ref type="bibr" target="#b11">Chomsky, 2002)</ref>. Transformer-based large language models demonstrate signs of compositional reasoning by producing comprehensive content that includes elements not likely to co-occur within the training data, suggesting the emergence of general intelligence <ref type="bibr" target="#b48">(Press et al., 2023;</ref><ref type="bibr" target="#b75">Zhou et al., 2023;</ref><ref type="bibr" target="#b9">Bubeck et al., 2023;</ref><ref type="bibr">Li et al., 2024a)</ref>. However, the complexity and ambiguity of their natural language training and testing data make it hard to scientifically validate the compositional reasoning ability and explore the underlying mechanisms. This paper validates the potential of Transformers in doing compositional reasoning on synthetic dataset and investigates the inner mechanisms eliciting such ability. Specifically, we address three key questions: 1) When are Transformers able to perform compositional reasoning by connecting fragmented knowledge in training data? 2) How do different training factors impact the emergence of this ability? 3) What internal mechanisms enable Transformers to develop this ability?</p><p>We first introduce the "FTCT" (Fragmented at Training, Chained at Testing) dataset, on which we investigate the performance of Transformers to address these questions. This dataset simulates knowledge relationships through graph-like causal structures, where vertices represent knowledge points and edges represent the relationships between their values. Multi-step reasoning paths are represented by chains consisting of connected vertices with values calculated by edges between them. their Bayesian networks, additionally inserting contextual noise and complicating value relationships. While they focus on locality structure's impact on CoT efficacy, we investigate how various training factors influence compositional reasoning emergence and conduct an in-depth analysis of the mechanisms within Transformer structures that elicit such capability.</p><p>In-context learning. In-context learning (ICL) <ref type="bibr" target="#b8">(Brown et al., 2020;</ref><ref type="bibr" target="#b20">Garg et al., 2022;</ref><ref type="bibr" target="#b43">Min et al., 2022;</ref><ref type="bibr" target="#b54">Shi et al., 2024)</ref> enables language models to perform various tasks by interpreting examples within the provided prompt, without needing explicit tuning. This capability allows Transformers trained on our FTCT to emulate the order of vertices in few-shot examples. Several theoretical studies <ref type="bibr" target="#b65">(Xie et al., 2022;</ref><ref type="bibr" target="#b37">Li et al., 2023;</ref><ref type="bibr">Wang et al., 2024b;</ref><ref type="bibr" target="#b23">Hahn &amp; Goyal, 2023;</ref><ref type="bibr" target="#b63">Wies et al., 2024;</ref><ref type="bibr">Zhang et al., 2023b)</ref> treat ICL as implicit Bayesian inference. Another set of works <ref type="bibr" target="#b14">(Dai et al., 2023;</ref><ref type="bibr" target="#b57">Von Oswald et al., 2023;</ref><ref type="bibr" target="#b3">Akyurek et al., 2023;</ref><ref type="bibr" target="#b2">Ahn et al., 2024)</ref> argue that ICL functions similarly to gradient descent from a function approximation perspective. Notably, a mechanism within Transformers, known as "induction heads" <ref type="bibr" target="#b17">(Elhage et al., 2021;</ref><ref type="bibr" target="#b46">Olsson et al., 2022;</ref><ref type="bibr" target="#b6">Bietti et al., 2024)</ref>, is identified as the direct cause of ICL capabilities (detailed explanation is in Section 6.1). We demonstrate that induction heads exist in Transformers trained on FTCT, enabling the model to replicate the order of vertices from few-shot examples through ICL.</p><p>Compositional generalization. Compositional generalization refers to machine learning models' ability to solve new problems by integrating known components from training data <ref type="bibr" target="#b33">(Lake &amp; Baroni, 2018;</ref><ref type="bibr" target="#b29">Keysers et al., 2020;</ref><ref type="bibr" target="#b31">Kim &amp; Linzen, 2020;</ref><ref type="bibr" target="#b26">Hupkes et al., 2020)</ref>. Prior works have validated the potential of Transformers in compositional tasks where answers are directly output without intermediate reasoning steps <ref type="bibr" target="#b26">(Hupkes et al., 2020;</ref><ref type="bibr" target="#b5">Arora &amp; Goyal, 2023;</ref><ref type="bibr" target="#b69">Yu et al., 2024;</ref><ref type="bibr" target="#b66">Xu et al., 2024;</ref><ref type="bibr" target="#b56">Treutlein et al., 2024)</ref>. In contrast, our FTCT dataset with deep causal structure allows exploration of explicit reasoning's impact on compositional generalization. While some empirical studies have shown that step-by-step reasoning enhances large language models' compositional abilities on real-world tasks <ref type="bibr" target="#b48">(Press et al., 2023;</ref><ref type="bibr" target="#b75">Zhou et al., 2023;</ref><ref type="bibr" target="#b30">Khot et al., 2023)</ref>, the complexity of natural language corpora used by them complicates the scientific validation, which can be done credibly by our synthetic data. Recent studies have explored Transformers' generalized reasoning on various controllable synthetic tasks <ref type="bibr" target="#b52">(Ramesh et al., 2023;</ref><ref type="bibr" target="#b4">Allen-Zhu &amp; Li, 2023;</ref><ref type="bibr" target="#b68">Ye et al., 2024)</ref>. In contrast, our FTCT task not only ensures controlled experimentation but also introduces measures of trainingtesting data similarity and establishes a distinct parent-child causal relationship, facilitating analysis of the underlying mechanisms in terms of data distribution and model structure. Although some studies have highlighted Transformers' shortcomings in achieving compositional generalization due to structural constraints <ref type="bibr" target="#b15">(Dziri et al., 2024;</ref><ref type="bibr" target="#b47">Peng et al., 2024)</ref> or misleading statistical features <ref type="bibr">(Zhang et al., 2023a)</ref>, our findings reveal that few-shot CoT prompting elicits compositional generalization in sequential reasoning tasks, indicating the importance of data structure and prompting skills.</p><p>Transformer expressivity. Transformers are highly expressive, capable of approximating universal sequence-to-sequence functions <ref type="bibr" target="#b71">(Yun et al., 2020)</ref>, Turing machines <ref type="bibr" target="#b50">(Pérez et al., 2019;</ref><ref type="bibr">Wei et al., 2022a)</ref>, and even full computers <ref type="bibr" target="#b21">(Giannou et al., 2023)</ref>. They can replicate algorithms for in-context learning <ref type="bibr" target="#b14">(Dai et al., 2023;</ref><ref type="bibr" target="#b57">Von Oswald et al., 2023;</ref><ref type="bibr" target="#b3">Akyurek et al., 2023;</ref><ref type="bibr" target="#b2">Ahn et al., 2024)</ref>, stepby-step reasoning <ref type="bibr">(Li et al., 2024b;</ref><ref type="bibr" target="#b18">Feng et al., 2024)</ref>, and causal graph inference <ref type="bibr" target="#b44">(Nichani et al., 2024;</ref><ref type="bibr" target="#b16">Edelman et al., 2024;</ref><ref type="bibr" target="#b41">Makkuva et al., 2024;</ref><ref type="bibr" target="#b6">Bietti et al., 2024)</ref>. Leveraging these insights, we construct a Transformer that efficiently minimizes both training and testing loss on FTCT. Recent studies have also demonstrated that specific architectural features of Transformers critically enhance the generalization capabilities of language models <ref type="bibr" target="#b4">(Allen-Zhu &amp; Li, 2023;</ref><ref type="bibr" target="#b27">Jin et al., 2025)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FRAGMENTED AT TRAINING, CHAINED AT TESTING</head><p>We introduce the structure of FTCT dataset and corresponding training and testing loss, illustrating the reason why it measures the model's compositional reasoning ability. Figure <ref type="figure" target="#fig_6">1</ref> demonstrates the data generation procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">CAUSAL STRCTURE</head><p>We represent knowledge relationships with a directed graph G = (V, E), where knowledge points are simulated by vertices V, a subset of the alphabet V all := {A, B, . . . , Z, a, b, . . . , z}. Each vertex v in V has a value q(v) from its associated set VALS(v) ⊂ Z. Relationships between knowledge points In the end, the "Downstream Processing" adapts sequences into natural language-like sentences for intuitive reasoning format.</p><p>are represented by the edges set E. Each edge e := (v 1 , v 2 ) ∈ E defines the relationship between the parent vertex v 1 and the child vertex v 2 by the operation op(e), satisfying q(v 2 ) = op(e) • q(v 1 ).</p><p>We assume that op(e) only represents addition or subtraction operation like +a or -b. Multi-step reasoning paths are represented by the chains</p><formula xml:id="formula_0">T (G) := {[v 1 , v 2 , . . . , v n ] | n ∈ N, (v i , v i+1 ) ∈ E}.</formula><p>The depth of G, denoted as N , is the length of the longest chain in T (G). The "Causal Structure" in Figure <ref type="figure" target="#fig_6">1</ref> illustrates a causal structure with depth N = 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">DATA GENERATION</head><p>Step 1.1. Fragmented at Training: To simulate disconnected knowledge, training data excludes the longest chain in T (G) and instead includes shorter child chains with length M &lt; N , interspersed with M ′ noise vertices from V all -V. Child chains vertices are merged with noise vertices, preserving their order. Child chain vertices receive values based on their edge operations, while noise vertices get random values. The final vertex-value sequence is formatted as seq</p><formula xml:id="formula_1">:= [v 1 , q 1 , . . . , v m , q m ],</formula><p>where m = M + M ′ . As shown in "Fragmented at Training" in Figure <ref type="figure" target="#fig_6">1</ref>, the training data includes sequences like <ref type="bibr">[A, 100, Z, 3, B, 101, H, 1]</ref>, where [A, B] is a child chain from T (G) with values following the "+1" operation, and [Z, H] are sampled from V all -V with randomly assigned values.</p><p>Step 1.2. Chained at testing: To test models' compositional reasoning ability, the testing data consists of longest chains (length N ) from T (G) without noise, formulating the sequence seq :=</p><formula xml:id="formula_2">[v 1 , q 1 , . . . , v N , q N ], where (v 1 , . . . , v N ) ∈ T (G).</formula><p>Refer to "Chained at Testing" in Figure <ref type="figure" target="#fig_6">1</ref>.</p><p>Step 2. Few-shot learning: For both training and testing datasets, multiple sequences with the same vertices order are concatenated into few-shot document, which is formatted as ) , \n, . . . , \n, seq (k) ], where seq</p><formula xml:id="formula_3">doc k := [seq (1</formula><formula xml:id="formula_4">(i) := [v 1 , q (i) 1 , . . . , v L , q<label>(i)</label></formula><p>L ] where L is the sequence length which can be either m or N , and k is the shots number ranging from 0 to K. The k-shot input and label are formatted as</p><formula xml:id="formula_5">inp k := doc k + [v 1 , q (k+1) 1 ], lab k := [v 2 , q (k+1) 2 , . . . , v L , q (k+1) L ].</formula><p>The model should generate lab k autoregressively from inp k . Especially, the zero-shot input inp 0 requires reasoning without any preceding examples. See "Few-Shot Examples" in Figure <ref type="figure" target="#fig_6">1</ref>.</p><p>Step 3. Downstream processing: This process adapts sequences into natural language-like sentences by adding punctuation, contextual details, and stating the reasoning goal upfront. As illus-trated in "Downstream Processing" in Figure <ref type="figure" target="#fig_6">1</ref>, a few-shot document like <ref type="bibr">[A, 110, Z, 1, B, 111, H, 5, \n, A, 102, Z, 4, B, 103, H, 9]</ref> transforms into the sentence "H=?: ... A=110, ... Z=1, ... B=111, ... H=5 \n H=?: ... A=102, For brevity, we define D train as the distribution of inputs and labels generated by Step 1.1, 2, 3, and D test as the distribution of inputs and labels generated by Step 1.2, 2, 3. The detailed data generation with specific sampling methods is in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">TRAINING AND TESTING LOSS</head><p>Training loss: For any input and label sampled from D train , we train the language model to autoregressively generate label given input. With the length of label lab k defined as d k , the training loss is formatted as</p><formula xml:id="formula_6">L train := -E lab, inp∼Dtrain K-1 k=0 d k -1 t=1 log P model lab k t+1 | inp k + lab k 1:t .</formula><p>Testing loss: For any input and label sampled from D test , given the input, we test how well a language model can generate sentence having the same vertex-value pairs as the label. Specifically, We define a decoding function dec( lab) := lab = [v 2 , q 2 , . . . , v N , q N ] to decode the vertexvalue information from the processed label. Given the input, the sentence generated by the model is defined as model( inp). We measure model's testing loss with k-shot prompt by  <ref type="figure" target="#fig_6">1</ref>, this is tested by prompting models with sentences like "... A=100, ... B=". The model is considered to output accurate values if and only if it outputs "101" as the next token.</p><formula xml:id="formula_7">L k test := -E inp k , lab k ∼Dtest 1 {dec(model( inp k ))=dec( lab k )} .<label>(1)</label></formula><p>We trained 3-layer 3-head GPT-2-like Transformers (details in Appendix H) on FTCT training set with varying graph depths and child chain lengths. Figure <ref type="figure" target="#fig_2">2</ref> (left) shows the testing performance for Transformers trained on graph depths N = 5, 10, 15, with k-shot CoT prompting (k from 0 to 4). Different curve colors represent different child chain lengths M = 2, 3, 4, 6. Our conclusions are:</p><p>Few-shot CoT enables compositional reasoning by revealing correct vertices order. Whole chain accuracy is low with zero-shot prompts but increases sharply with more shots. At zero-shot, values accuracy is optimal while vertices accuracy is near zero. This indicates that few-shot CoT prompts enhance models' compositional reasoning by revealing the correct vertices order. Notably, such order has not appeared in the training data. The ability to understand and imitate the OOD vertices order stems from Transformers' in-context learning via induction heads <ref type="bibr">(Section 5,</ref><ref type="bibr">6)</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">THE SIMILARITY BETWEEN TRAINING AND TESTING DATA DETERMINES THE EMGERGENCE OF COMPOSITIONAL REASONING</head><p>For each FTCT task, we measure the similarity between training and testing data by the relative knowledge ratio λ := M/N , where M is the child chain lengths and N is the causal graph depth. We find that compositional reasoning emerges as λ increases. Figure <ref type="figure" target="#fig_2">2</ref> (right) illustrates the relationship between λ and model's compositional reasoning ability. For each λ, the compositional reasoning ability is measured by the optimal few-shot testing performance of Transformers trained on tasks whose relative knowledge ratio is λ. A phase transition occurs: compositional reasoning remains weak when λ &lt; 0.3 and distinctly emerges when λ ≥ 0.3. In essence, a larger λ makes few-shot CoT prompts more similar to training data, thereby enhancing testing performance. However, the fact that testing accuracy approaches one with λ = 0.3-a ratio significantly smaller than 1-underscores the non-triviality of our results.</p><p>Experiments on larger models like GPT-2-small (12 layers 12 heads) and GPT-2-large (36 layers 20 heads) show the same pattern (Appendix K), demonstrating the generalizability of our conclusions. and child chain length upper bound M = 3. "Params" stands for numbers of parameters of different models; "Training" column includes three criteria described in Section 4.3 measuring the indistribution performance;"Testing" column includes three criteria described in Section 4.1 measuring the compositional reasoning performance. We only show the performance of models prompted by CoT with the optimal shots number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MULTI-LAYER ATTENTION MECHANISM ENABLES COMPOSITIONAL REASONING</head><p>We show that compared with other simpler structures, multi-layer Transformers excel at imitating vertices order from few-shot examples and deducing correct values with preceding reasoning paths, leading to outstanding compositional reasoning ability. In addition to compositional reasoning metrics (Section 4.1), we introduce the following criteria to evaluate in-distribution performance: We assess the performance of various models on the FTCT task with a causal structure depth of 5 and a child chain length of 3. Models include Transformers (TF) of various layers and heads, and multi-layer perceptrons (MLPs) of different depths (details in Appendix H). Table <ref type="table" target="#tab_2">1</ref> summarizes the results. For brevity, we only show the performance of models prompted by CoT with the optimal shots number.</p><p>Depth of Transformer enables the imitation of vertices. Table <ref type="table" target="#tab_2">1</ref> indicates that Transformers with at least 2 layers and 2 heads achieve optimal in-distribution and compositional reasoning performance. As complexity decreases, performance deteriorates, notably with a significant drop in the vertices accuracy, both training and testing, while values accuracy remains optimal. Such phenomenon indicates that depth in Transformers is crucial for imitating vertices order in few-shot examples, hence enhancing compositional reasoning. This is because induction heads for in-context learning are less likely in single-layer Transformers (Section 6).</p><p>Attention mechanism enables the deduction of sparse values information. For MLPs with appropriate window sizes (details in Appendix H.2), both the training and testing values accuracy remain low. Conversely, even the simplest Transformer (1 layer, 1 head) achieves nearly optimal values accuracy, suggesting that MLPs struggle to capture sparse value information in noisy contexts as effectively as Transformers. Interestingly, MLPs perform well in generating vertices order during testing but not during training, possibly due to the extra noise vertices in the training data, suggesting a different knowledge memorization approach that warrants further study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">TRANSFORMER DOES COMPOSITIONAL REASONING VIA THE UNDERLYING PROGRAM</head><p>As discussed in Section 4.3, the multi-layer attention mechanism of Transformers is crucial for compositional reasoning. However, how Transformers achieve this ability through training remains unclear. In this section, we explain this mystery by showing the capability of Transformer in learning an underlying program that minimizes both training and testing loss. In Section 6 we provide empirical evidence of this underlying program in the Transformer's hidden states. We focus on the few-shot testing loss {L k test } K-1 k=1 and a modified training loss accounting only for shots number k ≥ 1, which is defined as</p><formula xml:id="formula_8">L train := -E lab, inp∼Dtrain K-1 k=1 d k -1 t=1 log P model lab k t+1 | inp k + lab k 1:t .</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">UNDERLYING PROGRAM</head><p>We construct a text-generating program which provably achieves optimal performance on both training and testing data. Key components are summarized here, with an algorithm (Algorithm 1) in the Appendix. Given any input sentence z 1:T that contains at least 1-shot example, the program executes the following two parts iteratively:</p><p>In-context learning: If the last token z T is a comma ",", z T -3 must be a vertex v i . The program identifies all v i in the previous few-shot examples and attends to their next vertex v i+1 , returning v i+1 's contextual tokens.</p><p>Parent retrieving: If the last token z T is an equation token "=", z T -1 must be a vertex v j . The program retrieves the parent of v j from the preceding context. If v j belongs to the child chain from T (G) and has a parent v j1 with value q j1 in the preceding context, the program returns q j = op(v j1 , v j ) • q j1 with probability one. Otherwise, it returns value q j randomly sampled from v i 's value set VALS(v i ).</p><p>For example, in the testing sentence shown in Figure <ref type="figure" target="#fig_6">1</ref>, given the input "C=?: . . . A=100, . . . B=101, . . . C=103 \n C=?: . . . A=105," , the program, through in-context learning, attends to "B" in the preceding example and outputs its contextual information as the next token. The program continues generating tokens using other minor parts from Algorithm 1 until the output "C=?: . . . A=100, . . . B=101, . . . C=103 \n C=?: . . . A=105, . . . , B=" .</p><p>The program then retrieves "A" as the parent of "B" by parent retrieving part, returning the value 106 = 105 + 1. The Following lemmas show that the underlying program minimizes both the few-shot training loss and few-shot testing loss.   </p><formula xml:id="formula_9">" . . . v i = q i , . . . v i+1 = q i+1 , . . . \n . . . v i = q ′ i , "</formula><p>The head in the shallower layer copies the information of v i and v i+1 to ",". The head in the deeper layer attends "," along with the information of v i+1 to ",", making the model to output the contextual information of v i+1 .</p><p>To empirically demonstrate this pattern, we trained a 3-layer, 3-head Transformer on the FTCT task with a causal structure depth of 13 and a child chain length of 6, generating attention heatmaps for each layer. Complete heatmap plots are available in Appendix M, and an abbreviated version is shown in Table <ref type="table" target="#tab_3">2</ref> which displays the average attention weights of heads in different layers for their respective tokens. For each comma in the black frame, the distribution of its attention weights to preceding tokens is shown using colored boxes-the brighter the color, the more attention paid. In Layer 1, each comma attends to its previous two vertices, recording their information in its hidden state. In Layer 2, each comma uses this information to identify the preceding comma whose vertex is next to be output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">ATTENTION ASSIGNMENT</head><p>By linear probing <ref type="bibr" target="#b24">(Hewitt &amp; Manning, 2019;</ref><ref type="bibr" target="#b12">Clark et al., 2019;</ref><ref type="bibr" target="#b4">Allen-Zhu &amp; Li, 2023)</ref>, we empirically show that the parent retrieving is facilitated by proper attention assignment-focusing on the value of parent vertex while ignoring others.</p><p>For each sentence sampled from either the training or testing data, we identify the equation token "=", where its corresponding vertex has a parent in the preceding context. Specifically, we examine input formatted as: " . . . v j1 = q j1 , . . . v j = " where v j1 is the parent of v j . We construct the probing dataset by each time picking a position i &lt; j (including j 1 ), replacing q i with randomly sampled q ′ i , and recording the Transformer's hidden state for this modified sentence. We train a linear function (details in Appendix H.3) to predict q ′ i from the hidden states. If the Transformer attends to q i , the linear function should predict q ′ i with high accuracy. If not, the accuracy should be low.</p><p>Table <ref type="table" target="#tab_4">3</ref> shows the results for 3-layer, 3-head Transformers trained on multiple FTCT tasks. For sentences sampled from training or testing data, linked to prompts with shot numbers 0-4, the probing accuracy of predicting replaced values is tested. The results demonstrate that for both training and testing data, the probing function achieves high accuracy in predicting parents' replaced values, while showing low accuracy for other positions. This indicates that Transformers successfully retrieve parent vertices within fragmented knowledge, ignoring irrelevant information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>Our research validates the potential of Transformers in doing compositional reasoning on synthetic data and investigates the inner mechanism eliciting such ability. We demonstrate that few-shot CoT prompting enables Transformers to perform compositional reasoning by providing the information of correct order of knowledge points. We also find that compositional reasoning ability emerges when the training-testing data similarity and the model complexity are above certain thresholds. We further show that Transformers develop compositional reasoning by learning an underlying program during training, which minimizes both training and testing loss. This program leverages in-context learning and parent retrieving mechanisms, facilitated by induction heads and attention assignment.</p><p>Through experiments on synthetic data, we demonstrate the potential of Transformers to develop generalized reasoning skills, indicating that the impressive performance of contemporary large language models extends beyond mere memorization of vast data. While our conclusions may not directly apply to real-world models trained on extensive natural language datasets, we believe that our analysis offers valuable insights into the training processes and understanding of today's large language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A CONCURRENT AND CLOSELY-RELATED WORKS</head><p>Other patterns of compositionality &amp; generalization. Grokking results show composition and comparison often emerge only after a phase transition, with the mechanism (not just the mapping) determining OOD behavior <ref type="bibr">(Wang et al., 2024a)</ref>. Rule-extrapolation stresses truly OOD generalization by violating a learned rule template at test time; outcomes hinge on model/optimization choices, revealing how easily surface cues can mimic rules <ref type="bibr" target="#b42">(Mészáros et al., 2024)</ref>. Directional-asymmetry ("reversal curse") work shows that failures often reflect training-distribution directionality rather than a blanket lack of systematicity <ref type="bibr" target="#b40">(Lin et al., 2024)</ref>. A complementary thread asks when optimization even finds a compositional mechanism: initialization scale can push the same task toward factorized reasoning vs. memorization-style solutions <ref type="bibr" target="#b74">(Zhang et al., 2024)</ref>. Recent work also asks whether mechanistic signals can predict OOD behavior directly, linking interpretability readouts to unseen-data performance <ref type="bibr" target="#b36">(Li et al., 2025)</ref>.</p><p>Multi-hop reasoning. Most recent studies probe latent (implicit) multi-hop: models chain facts in a single forward pass without textually emitting steps; success depends on when hops are computed and how signals route under distractors. Controlled two-hop probes on LLMs map when latent two-step computation appears-and where it collapses <ref type="bibr" target="#b67">(Yang et al., 2024)</ref>. Mechanistic analyses expose "hop-timing" failures and sequential-attention-style routing that stabilizes only after training dynamics shift <ref type="bibr" target="#b7">(Biran et al., 2024)</ref>. Reverse-engineering a 3-layer transformer on two-hop reveals the abrupt transition from random guessing to perfect accuracy and the underlying sequential query mechanism; similar dynamics surface in larger LLMs <ref type="bibr" target="#b22">(Guo et al., 2025)</ref>. Architectural/analysis work like Back Attention further enhances latent multi-hop by enabling lower layers to re-use higher-layer states <ref type="bibr" target="#b70">(Yu et al., 2025)</ref>. Related disentanglement results show step-wise concept composition and low-dimensional subspaces for continuous latents-bridging multi-hop probes with causal-interp style findings <ref type="bibr" target="#b25">(Hong et al., 2025)</ref>.</p><p>A smaller but important slice shows that explicit CoT or intermediate supervision boosts stability and sample-efficiency-matching our result that exposing the hop order/vertex order in-context unlocks compositional ability. Capacity analyses argue latent two-hop often forces the model to "learn each fact twice," whereas two-hop with CoT avoids that burden <ref type="bibr" target="#b28">(Johnston &amp; Belrose, 2025)</ref>. Under the coverage lens, CoT improves data efficiency inside the coverage boundary but still struggles when multiple computational paths compete <ref type="bibr" target="#b10">(Chang et al., 2025)</ref>. } K,B k=1,b=1 from D test . The empirical testing loss with k-shot prompt is</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B EMPIRICAL LOSS</head><formula xml:id="formula_10">L k test := - 1 B B b=1 1 {dec(model( inp k,b ))=dec( lab k,b )} .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C DETAILED DATA GENERATION</head><p>Step 0. Causal structure: The dataset is based on directed graph structures G = (V, E), where V is a subset of the alphabet vocabulary V all := {A, B, . . . , Z, a, b, . . . , z}. Each vertex v ∈ V all has a value q(v) from its set VALS(v) ⊂ Z. For any edge e := (v 1 , v 2 ) ∈ E, v 1 is the parent and v 2 is the child. Each edge e maps VALS(v 1 ) to VALS(v 2 ) via op(e) : VALS(v 1 ) → VALS(v 2 ), satisfying q(v 2 ) = op(e) • q(v 1 ). We assume op(e) represents operations like (+a) or (-b). The set of chains T (G) :</p><formula xml:id="formula_11">= {[v 1 , v 2 , . . . , v n ] | n ∈ N, (v i , v i+1 ) ∈ E} represents sequences of connected vertices.</formula><p>The depth of G, denoted as N , is the length of the longest chain in T (G).</p><p>Step 1.1. Fragmented at Training: The training data consists of child chains sampled from T (G) with length M &lt; N as well as M ′ noise vertices sampled from V all -V. Child chains are merged with noise vertices while maintaining their relative order. Within the merged sequence, vertices belonging to the child chains are assigned values following their defined operations, while noise vertices are given random values. Suppose the child chain is</p><formula xml:id="formula_12">s 1 := [u 1 , • • • , u M ] ∈ T (G) and the sequence of noise vertices is s 2 := [u ′ 1 , • • • , u ′ M ′ ]. The merged sequence is [v 1 , • • • , v m ], where m = M + M ′ , [v i1 , • • • , v i M ] = s 1 and [v j1 , • • • , v j M ′ ] = s 2 . We then sample [q 1 , • • • , q m ]</formula><p>as the corresponding values of vertices. For [q i1 , • • • , q i M ] that corresponds to s 1 , it follows the operators over the chain, where</p><formula xml:id="formula_13">q i1 ∼ Uniform(VALS(u 1 )) and q i h = op((u h-1 , u h )) • q i h-1 for h = 2, • • • , M.</formula><p>For [q j1 , • • • , q j M ′ ] that corresponds to s 2 , they are just random noise so we have</p><formula xml:id="formula_14">q j h ∼ Uniform(VALS(u ′ h )) for h = 1, • • • , M ′ .</formula><p>The final sequence of vertex-value pairs is formatted as seq := [v 1 , q 1 , . . . , v m , q m ], where m = M + M ′ .</p><p>Step 1.2. Chained at testing: In contrast to the training dataset, the testing data consists of complete chains of length N from T (G) without noise vertices, formulating the sequence</p><formula xml:id="formula_15">seq := [v 1 , q 1 , . . . , v N , q N ], where (v 1 , . . . , v N ) ∈ T (G), q 1 ∼ Uniform(VALS(v 1 )) and q i = op((v i-1 , v i )) • q i-1 for i = 2, • • • , N</formula><p>Step 2. Few-shot learning: For both training and testing datasets, multiple sequences with the same vertices order are concatenated into few-shot document, which is formatted as ) , \n, . . . , \n, seq (k) ], where seq (i) := [v 1 , q</p><formula xml:id="formula_16">doc k := [seq (1</formula><formula xml:id="formula_17">(i) 1 , . . . , v L , q (i) L ].</formula><p>Here L is the number of vertex-value pairs that can be either m or N , and k is the shot numbers, ranging from 0 to K. The k-shot input and label are formatted as</p><formula xml:id="formula_18">inp k := doc k + [v 1 , q (k+1) 1 ], lab k := [v 2 , q (k+1) 2 , . . . , v L , q (k+1) L ].</formula><p>Given the input inp k , the model is expected to autoregressively generate the label lab k by referring to the k-shot examples in doc k . Especially, the zero-shot input inp 0 requires reasoning without any preceding examples.</p><p>Step 3. Downside processing: In order to make sentences resemble natural language, we apply the following modifications: First, insert equation token o eq between each vertex v i and value q i . Second, insert comma token o cm between each value q i and next vertex v i+1 . Third, insert contextual tokens [c(v i ) 1 , . . . , c(v i ) li ] before each vertex v i . Lastly, define the question token o qu and insert [v L , o eq , o qu ] to the beginning of the sequence, indicating the final goal to be reasoned. For each sequence seq = [v 1 , q 1 , . . . , v L , q L ], the processed form of it is like</p><formula xml:id="formula_19">seq := [v L , o eq , o qu , c(v 1 ) 1 , . . . , c(v 1 ) l1 , v 1 , o eq , q 1 , o cm , . . . , o cm , c(v L ) 1 , . . . , c(v L ) l L , v L , o eq , q L ].</formula><p>Similarly, with the processed document defined as doc k := { seq (i) } k i=1 , the processed input and label are formatted as</p><formula xml:id="formula_20">inp k := doc k + [v L , o eq , o qu , c(v 1 ) (k+1) 1 , . . . , c(v 1 ) (k+1) l1 , v 1 , o eq , q (k+1) 1 , o cm ] lab k := [c(v 2 ) (k+1) 1 , . . . , c(v 2 ) (k+1) l2 , v 2 , o eq , q (k+1) 2 , o cm , . . . , o cm , c(v L ) (k+1) 1 , . . . , c(v L ) (k+1) l L , v L , o eq , q (k+1) L ]</formula><p>The contextual tokens are sampled in the following way: For each vertex v ∈ V all , we maintain its context token set CONT(v). For any</p><formula xml:id="formula_21">v 1 ̸ = v 2 , we regulate CONT(v 1 ) ∩ CONT(v 2 ) = ∅. For each vertex v i in the sequence, its contextual tokens c(v i ) 1 , • • • c(v i ) li are sampled from CONT(v i ) without replacement, with l i following the uniform distribution Uniform([|CONT(v i )|]).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D CONCRETE EXAMPLES OF SENTENCES IN FTCT</head><p>We provide concrete examples of sentences in the FTCT, using the causal structure illustrated in Figure <ref type="figure" target="#fig_6">1</ref>. Each vertex in V all is associated with its own set of contextual tokens, represented as follows:</p><p>A: {"intern", "accomplishment", "whistle", "subsystem", "Rewards", "patents", "ARCH" } B: {"correl", "register", "044", "ask", "latex", "Coins", "google" } C: {"ü", "exc", "increasing", "REAM", "she", "-.", "operated"} Z: {"Influ", "interf", "Ideally", "Pad", "adders", "confusion", "XP"} H: {"Higher", "fren", "romptu", "smoke", "shake", "Frank", "treasure"} v: {"ACH", "Catalyst", "pens", "emer", "4000", " Cars", "easiest"} For any sentence z 1:T , its last token z T must be one of the tokens {o cm , c(v j ) k , v j , o eq , q j }. Then we discuss the distribution of the next token in D train when z T is any one of them.</p><p>Algorithm 1 Generalized Reasoning</p><formula xml:id="formula_22">1: Input: Causal graph G = (V, E), all vertices V all , input sentence z 1:T , shot number f ≥ 1. 2: if z T = o cm then 3:</formula><p>That means z T -3 must be a vertex v i . There are f vertices v i in the previous sentence. Find all v i in the previous sentence and pay attention to there next vertex v i+1 , deduce the contextual information CONT(v i+1 ), return Uniform(CONT(v i+1 )).</p><formula xml:id="formula_23">4: else if z T = c(v j ) k then 5: That means z T -k+1:T = [c(v j ) 1 , • • • , c(v j ) k ]. Pay attention to them and return Uniform(CONT(v j ) + {v j } -{c(v j ) k ′ } k k ′ =1 ) 6: else if z T = v j then 7:</formula><p>return distribution P (•) where P (o eq ) = 1. 8: else if z T = o eq then 9:</p><p>Pay attention to its corresponding vertex</p><formula xml:id="formula_24">v j = z T -1 . 10: if v j ∈ V then 11:</formula><p>If v j is the first vertex from V that appears in the sentence, then return Uniform(VALS(v j )). Otherwise, search in previous tokens and pay attention to the nearest v j1 , q f j1 that v j1 ∈ V. Such a v j1 must be the parent of v j . Then return distribution P (•) where P (op(v j1 , v j ) • q j1 ) = 1.</p><p>12: else 13:</p><p>Return Uniform(VALS(v j )).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14:</head><p>end if 15: else if z T = q j then 16:</p><p>Return distribution P (•) where P (o cm ) = 1 17: end if</p><formula xml:id="formula_25">• When z T = o cm ,</formula><p>that means z T -3 must be a vertex v i and the next token will be one of the contextual tokens of v i+1 . To determine which specific vertex v i+1 is, we can refer to previous examples to find what is the next vertex after every v i . After determining v i+1 , in D train , the next token follows the distribution of c</p><formula xml:id="formula_26">(v i+1 ) 1 . Because c(v i+1 ) 1 , • • • , c(v i+1 ) li+1 are sampled from CONT(v i+1 ) without replacement, so c(v i+1 ) 1 ∼ Uniform(CONT(v i+1 )), deducing P train (• | z 1:T ) = Uniform(CONT(v i+1 )). • When z T = c(v j ) h , the previous h -1 tokens must be c(v j ) 1 , • • • c(v j ) h-1 . Because l j is sampled from Uniform(1, |CONT(v j )|), then we have P (l j = • | l j ≥ h) ∼ Uniform(h, |CONT(v j )|). So with probability 1/(|CONT(v j )| -h + 1) the next token is v j , with probability (|CONT(v j )| -h)/(|CONT(v j )| -h + 1) the next token is sampled from Uniform(CONT(v j ) -{c(v j ) 1 , • • • , c(v j ) h }).</formula><p>Combining them together, we have that</p><formula xml:id="formula_27">P train (• | z 1:T ) = Uniform(CONT(v j ) {v j } -{c(v j ) 1 , • • • , c(v j ) h }).</formula><p>• When z T = v j , the next token is o eq , deducing P train (o eq | z 1:T ) = 1.</p><p>• When z T = o eq , z T -1 must be a vertex v j and the next token must be a value q j . If v j ∈ V all -V, then q j is sampled from Uniform(VALS(v j )), deducing P train (• | z 1:T ) = Uniform(VALS(v j )). If v j ∈ V and v j is not the first vertex from V in this sentence, there must exist v j1 ∈ V which is the parent of v j previously. In this situation, q j = op(v j1 , v j )• q j1 with probability one, deducing</p><formula xml:id="formula_28">P train (op(v j1 , v j ) • q j1 | z 1:T ) = 1. Otherwise, if v j</formula><p>is the first vertex from V in this sentence, then q j is sampled from Uniform(VALS(v j )), deducing P train (• | z 1:T ) = Uniform(VALS(v j )).</p><p>• When z = q j , the next token must be o cm , deducing P train (o cm | z 1:T ) = 1.</p><p>In any situation, P prog (• | z 1:T ) always equals to P train (• | z 1:T ).</p><p>e ⊤ 1 e 1 = 1 and e ⊤ 1 e 2 = 0. Then for any token z t at the tth position of the input sentence z 1:T , its embedding is</p><formula xml:id="formula_29">W E (z t , t) := (W ⊤ tok (z t ) + p ⊤ t + W ⊤ comp (z t , t) d1 , 0, • • • , 0 4d1 ) ⊤</formula><p>where the last 4d 1 dimensional zero vector is for writing in additional information. For simplicity, we denote x t := W E (z t , t) ∈ R d where d = 5d 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 ATTENTION MECHANISM</head><p>For an L-layers H-heads Transformer, it has the set</p><formula xml:id="formula_30">{(W l,h Q , W l,h K , W l,h V )} L,H l=1,h=1</formula><p>as its query, key, value matrices, where |A|+d2) and bias W B ∈ R |A|+d2 to map the hidden state to the logits for output tokens. Here d 2 is an extra dimension for information writing in of MLP, whose specific value will be given in section G.3. For each embedded input sentence x 1:T , it goes through the following attention mechanism:</p><formula xml:id="formula_31">W l,h Q , W l,h K , W l,h V ∈ R d×d . It also has output matrices W O1 ∈ R (|A|+d2)×d , W O2 ∈ R |A|×(</formula><formula xml:id="formula_32">x (0) 1:T ← x 1:T x (l) t ← x (l-1) t + H h=1 W l,h V x (l-1) 1:t softmax x (l-1) 1:t ⊤ W l,h K ⊤ W l,h Q x (l-1) t := x (l-1) t + H h=1 attn (l,h) x (l-1) 1:t , for t = 1, • • • , T , l = 1, • • • , L x out t ← W O2 relu W O1 x (L) t + W B := MLP(x (L) t ), for t = 1, • • • , T Define the parameter vector θ := {(W l,h Q , W l,h K , W l,h V )} L,H l=1,h=1 {W O1 , W O2 , W B }.</formula><p>Given any input sentence z 1:T , the output probability of the Transformer with parameter θ is a distribution over the indices set of all tokens A:</p><formula xml:id="formula_33">P θ (• | z 1:T ) := softmax(x out T ).</formula><p>Here we assume that the temperature of every softmax layer here tends to infinity, meaning that softmax(x) = Uniform(arg max(x)).</p><p>At test time, the Transformer does greedy decoding, which outputs the token with the largest probability every time. Denoting the decoded sentence output by the Transformer as model θ (z</p><formula xml:id="formula_34">1:T ) := z ′ 1,T1 , it follows z ′ 1 = arg max P θ (• | z 1:T ), z ′ i = arg max P θ (• | [z 1:T , z ′ 1:i ]) for i = 2, • • • T 1 . G PROOF OF LEMMA 5.3 G.1 FIRST LAYER</formula><p>We directly give the construction. We set W l,h K = I d for all l, h, letting W l,h Q plays the role of both key and query. Moreover, we set T max as the maximum length of all possible input sentences.</p><p>• If z T = o cm /o dlm , it will be caught by the first two items in W 1,1 Q and attend to its corresponding vertex z T -3 = v j-1 . The value matrix W 1,1 V maps the value vector of each vertex v ∈ V all to (0 d1 , W tok (v) ⊤ , 0 3d1 ) ⊤ . Hence, we have that attn 1,1 (x 1:T ) = (0 d1 , W tok (v j-1 ) ⊤ , 0 3d1 ) ⊤ .</p><p>• If z T ∈ V all , it will be caught by the third item in W 1,1 Q , attending to the equation token o eq . The value matrix W 1,1 V maps the value vector of each o eq in the sentence to (0 d1 , W tok (o eq ) ⊤ , 0 3d1 ) ⊤ . Hence, we have that attn 1,1 (x 1:T ) = (0 d1 , W tok (o eq ) ⊤ , 0 3d1 ) ⊤ .</p><p>• If z T is other type of token, it will be caught by the last item in W 1,1 Q , attending to the question mark o qu . The value matrix W 1,1 V maps o qu to zero vector (0 5d1 ) ⊤ . Hence, we have that attn 1,1 (x 1:T ) = (0 5d1 ) ⊤ .</p><p>Then we analyze attn 1,2 (x 1:T ):</p><formula xml:id="formula_35">• If z T = c(v j ) l , it will be caught by the first item in W 1,2</formula><p>Q , attending to the previous contextual tokens that are also generated by v j including itself:</p><formula xml:id="formula_36">{c(v j ) l ′ } l l ′ =1 . The value ma- trix W 1,1 V maps every contextual token c to (0 3d1 , W tok (c) ⊤ , 0 d1 ) ⊤ . Hence, we have that attn 1,2 (x 1:T ) = (0 3d1 , 1 l l l ′ =1 W tok (c(v j ) l ′ ) ⊤ , 0 d1 ) ⊤ .</formula><p>• If z T = o cm /o dlm , it will be caught by the second item in W 1,2 Q , attending to all the previous tokens that are also vertices except for the nearest one v j-1 = z T -3 . Each token is multiplied by a weight t 2 , the nearer the token is to z T , the higher the weight will be. Hence, as the temperature of the softmax goes to infinity, z T attends to the second nearest vertex to it, which is denoted by v j-2 . The value matrix W 1,2 V maps the value vector of each vertex v ∈ V all to (0 2d1 , W tok (v) ⊤ , 0 2d1 ) ⊤ . Hence, we have that attn 1,2 (x</p><formula xml:id="formula_37">1:T ) = (0 2d1 , W tok (v j-2 ) ⊤ , 0 2d1 ) ⊤ .</formula><p>• If z T is other type of token, it will be caught by the last item in W 1,2 Q , attending to the question mark o qu . The value matrix W 1,2 V maps o qu to zero vector (0 5d1 ) ⊤ . Hence, we have that attn 1,2 (x 1:T ) = (0 5d1 ) ⊤ .</p><p>The hidden states generated by attn 1,3 and attn 1,4 can be calculated following the same routine. Finally we can summarize that for any input sequence z 1:T and its embedding x 1:T , we have</p><formula xml:id="formula_38">x (1) T = x T + 4 h=1 attn 1,h (x 1:T ) =                1.(W E (z T , T ) ⊤ , W tok (v j-1 ) ⊤ , W tok (v j-2 ) ⊤ , 0 2d1 ) ⊤ , if z T = o cm /o dlm and z T -3 = v j-1</formula><p>If j = 2, then v j-2 is the last vertex of the sentence, otherwise it is the vertex before v j-1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.(W</head><formula xml:id="formula_39">E (z T , T ) ⊤ , 0 2d1 , 1 l l l ′ =1 W tok (c(v j ) l ′ ) ⊤ , 0 d1 ) ⊤ , if z T = c(v j ) l 3.(W E (z T , T ) ⊤ , 0 2d1 , W tok (o eq ) ⊤ , 0 d1 ) ⊤ , if z T = v j 4.(W E (z T , T ) ⊤ , W comp (v j , T -1) ⊤ , 0 2d1 , W tok (v j ) ⊤ ) ⊤ , if z T = o eq and z T -1 = v j 5.(W E (z T , T ) ⊤ , 0 d1 , W comp (v j , T -2) ⊤ , 0 2d1 ) ⊤ , if z T = q j and z T -2 = v j .</formula><p>• If z T is other type of token, it will be caught by the last item in W 2,1 Q , attending to the question mark o qu . The value matrix W 2,1 V maps o qu to zero vector (0 5d1 ) ⊤ . Hence, we have that attn 2,1 (x (1)</p><formula xml:id="formula_40">1:T ) = (0 5d1 ) ⊤ .</formula><p>Then we analyze attn 2,2 (x 1:T ):</p><p>• If z T = o eq , it will be caught by the first item in W 2,2 Q . Denote the corresponding vertex of z T as v j = z T -1 . If v j ∈ V all -V, then it attends to the question mark o qu , being same as the second situation. If v j ∈ V, it attends to the nearest delimiter o dlm or the nearest value q j1 whose corresponding vertex v j1 ∈ V. If the nearest is o dlm , that means v j has no parent in the sentence, we have that attn 2,2 (x (1)</p><formula xml:id="formula_41">1:T ) = (0 4d1 , √ 2W tok (o dlm ) ⊤ ) ⊤ .</formula><p>If the nearest is q j1 , that means v j has a parent v j1 in the sentence, we have that attn 2,2 (x (1)</p><formula xml:id="formula_42">1:T ) = (0 4d1 , W tok (v j1 ) ⊤ + W tok (q j1 ) ⊤ ) ⊤ .</formula><p>• If z T is other type of token, it will be caught by the last item in W 2,1 Q , attending to the question mark o qu . The value matrix W 2,1 V maps o qu to zero vector (0 5d1 ) ⊤ . Hence, we have that attn 2,1 (x</p><formula xml:id="formula_43">(1) 1:T ) = (0 5d1 ) ⊤ .</formula><p>To summarize, we have that</p><formula xml:id="formula_44">x (2) T = x (1) T + 2 h=1 attn (2,h) x (1) 1:T =                      1.(W E (o cm , T ) ⊤ , W tok (v j-1 ) ⊤ , W tok (v j-2 ) ⊤ , W tok (v j ) ⊤ , 0 d1 ) ⊤ , if z T = o cm and z T -3 = v j-1 2.(W E (c(v j ) l , T ) ⊤ , 0 2d1 , 1 l l l ′ =1 W tok (c(v j ) l ′ ) ⊤ , 0 d1 ) ⊤ , if z T = c(v j ) l 3.(W E (v j , T ) ⊤ , 0 2d1 , W tok (o eq ) ⊤ , 0 d1 ) ⊤ , if z T = v j 4.1.(W E (o eq , T ) ⊤ , W comp (v j , T -1) ⊤ , 0 2d1 , W tok (v j ) ⊤ + √ 2W tok (o dlm ) ⊤ ) ⊤ if z T = o eq and z T -1 = v j has no parent in the sentence 4.2.(W E (o eq , T ) ⊤ , W comp (v j , T -1) ⊤ , 0 2d1 , W tok (v j ) ⊤ + W tok (v j1 ) ⊤ + W tok (q j1 ) ⊤ ) ⊤ if z T = o eq and v j1 is the parent of z T -1 = v j 5.(W E (q j , T ) ⊤ , 0 d1 , W comp (v j , T -2) ⊤ , W tok (q j ) ⊤ , 0 d1 ) ⊤ , if z T = q j G.3 OUTPUT LAYER</formula><p>The output layer is a two-layer MLP whose input dimension is 5d 1 , hidden dimension is |A| + d 2 and output dimension is |A|. Here the extra dimension d 2 is for mapping elements in the set</p><formula xml:id="formula_45">B := V   (v1,v2)∈E q1∈VALS(v1) {(v 1 , v 2 , q 1 )}   , so d 2 = |B|.</formula><p>For simplicity of the notation, we here introduce shorthands of several |A|-dimensional vectors. There is an one-one mapping from the set of all tokens A to their indices <ref type="bibr">[|A|]</ref>. Specifically, each token a ∈ A has its unique index idx(a) ∈ <ref type="bibr">[|A|]</ref>. Let e (i) be an |A|-dimensional vector where a 1 at position i and 0 at other positions. With a slight misuse of the notation, we define e(a) := e (idx(a)) for all a ∈ A. For any subset A ′ ⊂ A, we denote the uniform logit on it as e uni (A ′ ) := a∈A ′ e(a). For the extra set B, we define g (i) be a |B|-dimensional vector where a 1 at position i and 0 at other positions. Similarly, we can define g(b) := g idx(b) for all b ∈ B.</p><p>Denoting the set of vertices in V which does not have parents as V init , we can define the output matrices as</p><formula xml:id="formula_46">W O1 = v∈Vall (e uni (CONT(v)) ⊤ , 0 d2 ) ⊤ (0 3d1 , W tok (v) ⊤ , 0 d1 ) 1.z T =o cm + v∈Vall c∈CONT(v) (e uni (CONT(v)) ⊤ + e(v) ⊤ -e(c) ⊤ , 0 d2 ) ⊤ (0 3d1 , W tok (c) ⊤ , 0 d1 ) 2.z T =c(vj ) l + (e(o eq ) ⊤ , 0 d2 ) ⊤ (0 3d1 , W tok (o eq ), 0 d1 ) 3.z T ∈V + (v1,v2)∈E q1∈VALS(v1) (0 |A| , g((v 1 , v 2 , q 1 )) ⊤ ) ⊤ (0 4d1 , W tok (v 2 ) ⊤ + W tok (v 1 ) ⊤ + W tok (q 1 ) ⊤ ) 4.z T =o eq + v∈V (0 |A| , g(v) ⊤ ) ⊤ (0 4d1 , W tok (v) ⊤ + √ 2W tok (o dlm ) ⊤ ) 5.z T =o eq + v∈Vall-V (e uni (VALS(v)) ⊤ , 0 d2 ) ⊤ (0 4d1 , W tok (v) ⊤ ) 6.z T =o eq + q∈ v∈V all VALS(v) (e(o cm ) ⊤ , 0 d2 ) ⊤ (0 3d1 , W tok (q) ⊤ , 0 d1 ) 7.z T =qj W B = (0 |A| , -2 d2 ) W O2 = v∈Vall   e(v)(e(v) ⊤ , 0 d2 ) + c∈CONT(v) e(c) ⊤ (e(c) ⊤ , 0 d2 )   + e(o eq )(e(o eq ) ⊤ , 0 d2 ) + (v1,v2)∈E q1∈VALS(v1) e(op(v 1 , v 2 ) • q 1 )(0 |A| , g((v 1 , v 2 , q 1 )) ⊤ ) + v∈V e uni (VALS(v))(0 |A| , g(v) ⊤ ) + q∈ v∈V all VALS(v)</formula><p>e(q)(e(q) ⊤ , 0 d2 ) + e(o cm )(e(o cm ) ⊤ , 0 d2 )</p><p>Here we only explain the procedure of deriving MLP(x</p><p>T ) when z T = o eq , the other situations are straightforward. Denoting v j = z T -1 as its corresponding vertex, we have that • If v j ∈ V all -V, it will be caught by item 6 in W O1 . It is then easy to show that MLP(x (2) T ) = e uni (VALS(v j )).</p><p>• If v j ∈ V but has no parents in previous sentence, it will be caught by item 4, 5 in W O1 .</p><p>We can calculate that</p><formula xml:id="formula_48">W O1 x</formula><p>(2)</p><formula xml:id="formula_49">T = 3(0 |A| , g(v j ) ⊤ ) ⊤ + b∈B-{vj } µ b (0 |A| , g(b) ⊤ ) ⊤ , where µ b ≤ 2.</formula><p>That means all other g(b) will be filtered by the relu except for g(v j ). Specifically we have that relu(W O1 x</p><p>(2)</p><p>T + W B ) = 3(0 |A| , g(v j ) ⊤ ) ⊤ . Then it will be caught by the 4th item in W O2 , resulting in MLP( <ref type="formula">x</ref>(2) T ) = e uni (VALS(v j )).</p><p>• If v j ∈ V and has a parent v j1 , it will be caught by item 4, 5 in W O1 . We can calculate that</p><formula xml:id="formula_50">W O1 x (2) T = 3(0 |A| , g((v j1 , v j , q j1 )) ⊤ ) ⊤ + b∈B-{(vj 1 ,vj ,qj 1 )} µ b (0 |A| , g(b) ⊤ ) ⊤ , where µ b ≤ 2.</formula><p>Then we have relu(W O1 x</p><p>(2) T + W B ) = 3(0 |A| , g((v j1 , v j , q j1 )) ⊤ ) ⊤ . It will be caught by the 3rd item in W O2 , resulting in MLP( <ref type="formula">x</ref>(2) T ) = e(op(v j1 , v j ) • q j1 ).</p><p>In summary, we have that</p><formula xml:id="formula_51">MLP(x (2) T ) =                  1.e uni (CONT(v j )), if z T = o cm and z T -3 = v j-1 2.(e uni (CONT(v j )) + e(v j ) -1 l l l ′ =1 e(c(v j ) l ′ )), if z T = c(v j ) l 3.e(o eq ), if z T = v j 4.1.e(op(v j1 , v j ) • q j1 ), if z T = o eq and v j = z T -1 has a parent v j1 in previous sentence 4.2.e uni (VALS(v j )), if z T = o eq and v j = z T -1 ∈ V but has no parents in previous sentence 4.3.e uni (VALS(v j )), if z T = o eq and v j ∈ V all -V 5.e(o cm ), if z T = q j</formula><p>As the temperature of the softmax goes to infinity, we have that</p><formula xml:id="formula_52">softmax MLP(x (2) T ) ≈                  1.Uniform(CONT(v j )), if z T = o cm and z T -3 = v j-1 2.Uniform(CONT(V j ) + {v j } -{c(v j ) l ′ } l l ′ =1 ), if z T = c(v j ) l 3.P (•) where P (o eq ) = 1, if z T = v j 4.1.P (•) where P (op(v j1 , v j ) • q j1 ) = 1, if z T = o eq and v j = z T -1 has a parent v j1 in previous sentence 4.2.Uniform(VALS(v j )), if z T = o eq and v j = z T -1 ∈ V but has no parents in previous sentence 4.3.Uniform(VALS(v j )), if z T = o eq and v j ∈ V all -V 5.P (•) where P (o cm ) = 1, if z T = q j .</formula><p>That is exactly the same distribution given by algorithm 1. Depending on how high the temperature of the softmax layer is, the Transformer structure can approximate algorithm 1 with arbitrary preciseness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H IMPLEMENTATION DETAILS</head><p>H.1 TRANSFORMER Our Transformer model is based on the GPT-2 architecture as implemented by Hugging Face <ref type="bibr" target="#b64">(Wolf et al., 2020;</ref><ref type="bibr" target="#b51">Radford et al., 2019)</ref>. We tested various combinations of layers and heads, as detailed in Section 4. The model features 720-dimensional embeddings and a context window of 2048 tokens. During encoding, we generate token indices directly and feed them into the model, adhering to the mapping provided by GPT2Tokenizer for both encoding and decoding. The AdamW optimizer is employed with a learning rate of 5e-5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.2 MLP FOR LEARNING FTCT</head><p>Given that a 1-shot CoT prompt suffices for optimal model performance and excessive input length may degrade training efficiency and accuracy, we use sliding windows to cap input length. We experimented with window sizes of 150, 200, and 300 tokens, selecting the size with the best performance. Each sentence is represented by the concatenation of the one-hot encodings of its tokens, where each token is represented in a 503-dimensional space. Thus, with a window size of 300, the input dimension approximates 1e5. We evaluated MLPs with varying layer numbers and a hidden size of 1000 dimensions, as described in Section 4.3. The MLP output dimension matches the 50257 tokens of GPT2Tokenizer, with unused tokens assigned near-zero weights. For MLP we also use the AdamW optimizer with the learning rate 5e-5. world scenarios where the training corpus is typically affected by noise, while users offer highquality, noise-free prompts during testing. To demonstrate the robustness of our conclusion, we evaluate the performance of Transformers on testing data that is also blurred by noisy tokens. The key to constructing this noisy testing dataset is merging the longest chain in T (G) with randomly sampled noisy tokens from V all -V, while ensuring that (1) the order of the vertices in the chain is preserved and (2) the last vertex of the chain remain as the last vertex in the merged sequence. For the causal structure depicted in Figure <ref type="figure" target="#fig_6">1</ref>, such a merged sequence might look like <ref type="bibr">[F, 9, A, 100, K, 6, B, 101, H, 1, C, 103]</ref> where [A, B, C] is the longest chain in T (G) and [F, K, H] are noise randomly sampled from V all -V. After downstream processing, such sequnce is transformed to the input "C=?: ... F=9, ... A=100," and label "... K=6, ... B=101, ... H=1, ... C=103". To assess compositional reasoning performance on this dataset, we modify our evaluation criteria to focus only on the accuracy of non-noisy vertices in the set of knowledge points V:</p><p>Whole chain accuracy: Measures if the model correctly predicts all vertices belonging to the set of knowledge points V and their values along the reasoning chain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J LEAST VISITED TIMES OF ALL ADJACENT VERTICES AND THEIR VALUES</head><p>We define the set of all adjacent vertices and their values as S(G) := {(v i , q i , v i+1 , q i+1 ) | v i , v i+1 ∈ V, (v i , v i+1 ) ∈ E, q i ∈ VALS(v i ), q i+1 = op(v i , v i+1 )•q i }.</p><p>Only when each element in S(G) has been visited for enough times in the training data, can we ensure that the poor compositional reasoning ability of models trained on certain FTCT tasks is not  (as noted in Figure <ref type="figure" target="#fig_8">4b</ref> of <ref type="bibr" target="#b20">(Garg et al., 2022) and</ref><ref type="bibr">Figures 7, 10 of (Xie et al., 2022)</ref>). Although systematic explanations are limited, it is not uncommon for performance to drop when the number of shots surpasses a particular threshold. <ref type="bibr" target="#b1">(Agarwal et al., 2024)</ref> notably demonstrates that the optimal shot count for peak performance is often less than the maximum a model can manage, indicating that performance does not always increase monotonically with additional shots.</p><p>We propose that performance decreases when the number of shots exceeds one because additional CoT examples increase the dissimilarity between training and testing data, thereby degrading performance. To explain this, we begin by analyzing the difference between one-shot examples in testing and training data. In testing, one-shot examples typically consist of the longest chains of length N , whereas in training, they are child chains of length M &lt; N , with the primary difference being the N -M missing vertices. As the number of shots increases, each shot introduces more instances of these missing vertices, compounding the disparity between training and testing prompts. This growing difference complicates the model's ability to recognize patterns in the testing data, thus impairing performance.</p><p>In our setup, a single shot during testing already provides ample information about the vertex order needed for generating correct answers. For a k-shot testing example, the additional k -1 shots do not add valuable information and only exacerbate the divergence between training and testing data. Consequently, we observe that testing performance peaks at 1-shot and diminishes thereafter, aligning with our expectations.</p><p>When the differences between training and testing data are limited, we observe the expected pattern of in-context learning, where performance improves with more shots and does not decline after reaching its peak. From all FTCT tasks with various depth and child chain length combinations shown in Figure <ref type="figure">3</ref>, we select settings where performance decreases when shot numbers exceed one. These settings include "depth=8, child chain length=3," "depth=10, child chain length=3," "depth=13, child chain length=4," and "depth=15, child chain length=4." Instead of testing models' performance on the longest chains equal to their depth, we assess performance on causal chains with lengths varying from the child chain length to the depth. For instance, for models trained on an FTCT task with depth=8 and child chain length=3, we measure performance on chains with lengths 3, 4, 5, 6, and 8. The results in Figure <ref type="figure" target="#fig_12">10</ref> show that for tasks where test lengths are close to child chain lengths, few-shot performance does not decrease. Notably, zero-shot performance increases as test lengths near the child chain length. As the gap between child chain and test lengths widens, the performance decrease after one shot becomes evident. a test input formatted as "C=?: ... A=100, ... C=103 \n C=?: ... A=102," with the test label being "... C=105". For causal structures with greater depth, we define the retaining ratio ρ as the ratio of the count of remaining vertices to the causal structure's depth. This ratio reflects the degree of incompleteness in the reasoning path. For example, if the longest chain in the causal structure is [A, B, C, F, G, I] and ρ is set to 0.5, then the number of remaining vertices is 6 * 0.5 = 3. Since we only remove intermediate vertices, potential final sequences include [A, F, I] or [A, C, I], among others. Our evaluation criteria remain the same as the original (Section 4.1), but now both testing inputs and labels comprise incomplete reasoning paths. Given that Transformers trained on FTCT cannot generate incomplete reasoning paths autonomously in a zero-shot setting, we assess performance with 1 to 4 shots, each containing examples of incomplete reasoning paths.</p><p>Figure <ref type="figure" target="#fig_6">13</ref> illustrates the testing performance with retaining ratios of 0.3, 0.5, and 0.8. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>.." indicating tokens' context. The processed input and label are denoted as inp k and lab k .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Transformer outputs correct values with OOD reasoning paths. High testing values accuracy shows Transformers' robust performance in deducing correct values with the OOD compositional reasoning paths. Such an ability ensures models to iteratively output correct values of the vertices generated by few-shot CoT, leading to correct reasoning paths. This ability stems from Transformers' parent retrieving mechanism brought by proper attention assignment (Section 5, 6). An adequate number of shots is necessary. Performance improvements plateau or decline after one-shot examples, possibly due to increased dissimilarity between training and testing data with more CoT examples. A detailed discussion is in Appendix L.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Left: Zero and few-shot testing performance of Transformers trained on FTCT with various causal depths and child chain lengths. Right: Relationship between the relative knowledge ratio and model's compositional reasoning ability. Each row shows testing performance under a specific criterion: The 1st row indicates whole chain accuracy (correct prediction of all vertices and values), the 2nd row shows testing vertices accuracy (correct order of vertices), and the 3rd row shows testing values accuracy (correct values of vertices with correct preceding reasoning paths).</figDesc><graphic coords="6,391.20,314.65,110.87,152.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Validation loss: Tracks the validation loss during training. Training vertices accuracy: Assesses how well the model imitates the vertices order from the few-shot examples sampled from D train . Training values accuracy: Measures if the model outputs correct values of vertices from child chains, given preceding reasoning paths sampled from D train .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Lemma 5.1. For any sentence z 1:T := inp k + lab k 1:t , where input inp k and label lab k are sampled from D train with k ≥ 1, and t is an arbitrary position within the label, denote the distribution output by the program as P prog (• | z 1:T ). We have that P prog (• | z 1:T ) = P train (• | z 1:T ). Hence, P prog minimizes the few-shot training loss L train (eq. (2)) . Lemma 5.2. For any input inp k and label lab k sampled from D test with k ≥ 1, denoting the sentence generated by the program as prog( inp k ), we have dec(prog( inp k )) = dec( lab k ). Hence, prog(•) minimizes the few-shot testing loss {L k test } K-1 k=1 (eq. (1)). Lemma 5.1 and 5.2 show that, despite the different distributions of fragmented training data and chained testing data, their next-token distributions given few-shot examples can be represented by a common program. As demonstrated in Sections 5.2 and 6, the Transformer learns this common latent structure through training, achieving the compositional reasoniong ability.5.2 TRANSFORMER IS EXPRESSIVE ENOUGH TO SIMULATE THE UNDERLYING PROGRAMWe prove that Transformer is expressive enough to simulate the underlying program by explicitly constructing a 2 layers Transformer. Representing the model parameters by θ, we state Lemma 5.3. There exists a 2 layer Transformer with parameters θ * that approximates Algorithm 1 with arbitrarily small error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>... E = 138 , ... A = 141 , ... o = 135 , ... i = 130 , ... D = 138 , ... \n ... E = 125 , Layer 1 ... ... E = 138 , ... A = 141 , ... ... E = 125 , Layer 2 ... ... A = 141 , ... o = 135 , ... i = 130 , ... D = 138 , ... \n ... E = 125 , ... A = 128 , Layer 1 ... ... E = 138 , ... A = 141 , ... o = 135 , ... ... E = 125 , ... A = 128 , Layer 2 ... ... o = 135 , ... i = 130 , ... D = 138 , ... \n ... E = 125 , ... A = 128 , ... o = 122 , Layer 1 ... ... E = 138 , ... A = 141 , ... o = 135 , ... i = 130 , ... ... E = 125 , ... A = 128 , ... o = 122 , Layer 2 ... ... i = 130 , ... D = 138 , ... \n ... E = 125 , ... A = 128 , ... o = 122 , ... i = 117 , Layer 1 ... ... A = 141 , ... o = 135 , ... i = 130 , ... D = 138 , ... E = 125 , ... A = 128 , ... o = 122 , ... i = 117 ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>B. 1</head><label>1</label><figDesc>EMPIRICAL TRAINING LOSS With B samples in total, at each sample step b we sample { inp from D train . With the length of label lab k,b defined as d k,b , the empirical training loss is formatted as L train :=in total, at each sample step b we sample { inp</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>In this representation, [A, B, C] are knowledge points from V, and[Z, H, v]  are random noise from V all -V. The contextual tokens carry no semantic meaning, and the contextual token sets for different vertices do not overlap. The 3-shot training input containing [A, B] is like "B=?: confusion Pad interf Ideallyadders XPZ=6, accomplishmentintern subsystemARCH Rewards patentsA=120,romptuH=8,044 Coins google correl latexB=123 B=?: confusion Pad Ideally XPZ=7, accomplishment patents subsystem RewardsARCHA=122, treasureFrankH=3, googleregister044 CoinsaskB=125 B=?: Pad Influ interfZ=5,". Its corresponding label is "accomplishment subsystem whistle RewardsARCHinternA=147,smokeH=6, latexregister googleB=150". The 3-shot training input containing [B, C] is like "C=?: correl044 latexregisterB=126, 4000v=6,increasingoperatedREAMC=135 C=?: Coins correlaskB=108, pens Catalystv=6, exc-.increasingC=117 C=?: correl Coins googleregisterB=144,". Its corresponding label is "Carsemerv=5,-. excoperatedC=153". The 3-shot testing input is like "C=?: accomplishment patents Rewards subsystemA=134, Coins correlB=137,-.REAM exc sheC=146 C=?: subsystem patents RewardsA=103, latex google correlB=106,REAM exc sheC=115 C=?description of the generalized text generating program is shown in Algorithm 1 E.2 PROOF OF LEMMA 5.1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Testing performance of Transformers trained on FTCT where the testing data are blurred by noisy tokens. The performance is evaluated by all four criteria in Section I.2.</figDesc><graphic coords="29,108.00,81.86,435.59,217.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Final value accuracy: Measures if the model outputs the correct value of the last vertex in V within the sentence. Testing vertices accuracy: Measures if the model correctly outputs all vertices in dec( lab k ) which belong to V. Testing values accuracy: Measures if the model outputs correct values of intermediate vertices that belongs to V, given correct preceding reasoning paths from D test . Figures 4 and 5 display the compositional reasoning capacity of Transformers trained on FTCT with testing data blurred by noisy tokens. The results align with those from tests without noise, indicating the robustness of our conclusions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Zero and few-shot testing performance of GPT2 large trained on FTCT with various causal depths and child chain lengths.</figDesc><graphic coords="32,108.00,81.86,435.59,217.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: The relationship between the relative knowledge ratio and the compositional reasoning ability of GPT2 large.</figDesc><graphic coords="32,207.00,346.14,198.00,247.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Performance of Transformers in reasoning causal chains with varying lengths.</figDesc><graphic coords="33,108.00,474.03,435.59,217.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="28,108.00,178.69,435.59,217.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="31,108.00,116.90,435.59,217.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="36,108.00,91.60,395.97,197.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="36,108.00,290.58,395.97,197.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="36,108.00,489.56,395.97,197.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Overview of the FTCT Data Generation Process. The generation begins with the introduction of "Causal Structure", representing the relationships of knowledge points. The "Fragmented at Training" stage shows how shorter child chains with noise vertices are formed to simulate incomplete knowledge during training. The "Chained at Testing" stage presents the longest chains used in testing to assess compositional reasoning ability. The "Few-Shot Examples" part demonstrates the concatenation of multiple sequences for both training and testing to enable few-shot learning.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>A</cell><cell>B</cell><cell>Z</cell><cell>H</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>A, 100, Z, 3, B, 101, H, 1</cell><cell>H=?: ... A=100, ... Z=3, ... B=101, ... H=1</cell></row><row><cell>+3 -1 D</cell><cell>A</cell><cell>+1 +2 B</cell><cell cols="4">A A, 100, Z, 3, B, 101, H, 1 Z B H</cell><cell>A, 110, Z, 1, B, 111, H, 5 ... ... ... ... A, 102, Z, 4, B, 103, H, 9 ... ... ... ...</cell><cell>H=?: ... A=110, ... Z=1, ... B=111, ... H=5 ... ... ... ... H=?: ... A=102, ... Z=4, ... B=103, ... H=9 ... ... ... ...</cell></row><row><cell>E</cell><cell></cell><cell>C</cell><cell></cell><cell>+1</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>A, 100, B, 101, C, 103</cell><cell>C=?: ... A=100, ... B=101, ... C=103</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">A, 100, B, 101, C,103 A B C</cell><cell>A, 105, B, 106, C, 108 ... ... ... A, 102, B, 103, C, 105 ... ... ...</cell><cell>C=?: ... A=105, ... B=106, ... C=108 ... ... ... C=?: ... A=102, ... B=103, ... C=105 ... ... ...</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>+1</cell><cell></cell><cell>+2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Lorem ipsum</cell></row><row><cell cols="2">Figure 1:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Measures if the model outputs correct values of intermediate vertices,given correct preceding reasoning paths sampled from D test . For the causal structure in Figure</figDesc><table><row><cell cols="5">Transformers trained on D train have not seen the complete chains in D test from either the reasoning</cell></row><row><cell cols="5">paths or the few-shot examples. As a result, the fact that they still achieve low testing loss indicates</cell></row><row><cell cols="5">the emergence of the compositional reasoning ability. The empirical version of training and testing</cell></row><row><cell cols="3">loss are in Appendix B.</cell><cell></cell></row><row><cell cols="3">4 EMPIRICAL FINDINGS</cell><cell></cell></row><row><cell cols="5">4.1 FEW-SHOT COT PROMPTING ENABLES COMPOSITIONAL REASONING</cell></row><row><cell cols="5">Our empirical findings highlight the essential role of few-shot CoT prompts in enabling compo-</cell></row><row><cell cols="5">sitional reasoning in Transformers during testing. We evaluate model's compositional reasoning</cell></row><row><cell cols="3">ability using the following criterion: 2</cell><cell></cell></row><row><cell cols="5">Whole chain accuracy: Measures if the model's generation contains all vertices and values along</cell></row><row><cell cols="3">the reasoning chain in a correct order. For ( inp k</cell><cell>, lab</cell><cell>k</cell><cell>) sampled from D test , it measures whether</cell></row><row><cell>dec(model( inp</cell><cell>k</cell><cell cols="3">)) contains all elements from dec( lab k</cell><cell>) in a correct order.</cell></row><row><cell cols="5">Further, we decompose the compositional reasoning ability into two sublevel abilities-the ability</cell></row><row><cell cols="5">of generating correct vertices order and the ability of deducing correct values given preceding paths,</cell></row><row><cell cols="3">which are evaluated respectively by these criteria:</cell><cell></cell></row><row><cell cols="5">Testing vertices accuracy: Measures if the model correctly outputs all vertices in dec( lab</cell><cell>k</cell><cell>).</cell></row><row><cell cols="3">Testing values accuracy:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Performance of different models trained on FTCT task with causal structure depth N = 5</figDesc><table><row><cell cols="2">Model</cell><cell>Params</cell><cell></cell><cell>Training</cell><cell></cell><cell></cell><cell>Testing</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">Valid loss Vertices acc Values acc Vertices acc Values acc Whole acc</cell></row><row><cell></cell><cell>3L3H</cell><cell>54M</cell><cell>1.446</cell><cell>1.000</cell><cell>1.000</cell><cell>0.996</cell><cell>1.000</cell><cell>0.996</cell></row><row><cell></cell><cell>2L2H</cell><cell>48M</cell><cell>1.433</cell><cell>1.000</cell><cell>1.000</cell><cell>1.000</cell><cell>1.000</cell><cell>1.000</cell></row><row><cell>TF</cell><cell>2L1H</cell><cell>48M</cell><cell>1.436</cell><cell>0.870</cell><cell>1.000</cell><cell>0.768</cell><cell>1.000</cell><cell>0.766</cell></row><row><cell></cell><cell>1L2H</cell><cell>42M</cell><cell>1.559</cell><cell>0.138</cell><cell>0.994</cell><cell>0.776</cell><cell>1.000</cell><cell>0.776</cell></row><row><cell></cell><cell>1L1H</cell><cell>42M</cell><cell>1.624</cell><cell>0.025</cell><cell>0.974</cell><cell>0.026</cell><cell>1.000</cell><cell>0.022</cell></row><row><cell>MLP</cell><cell>4L</cell><cell>145M</cell><cell>3.464</cell><cell>0.063</cell><cell>0.104</cell><cell>0.484</cell><cell>0.290</cell><cell>0.002</cell></row><row><cell></cell><cell>2L</cell><cell>143M</cell><cell>2.147</cell><cell>0.065</cell><cell>0.146</cell><cell>0.850</cell><cell>0.346</cell><cell>0.022</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Attention weights of induction heads on the sentence sampled from test dataset.</figDesc><table><row><cell>Data</cell><cell></cell><cell cols="2">0-shot prompt</cell><cell cols="2">1-shot prompt</cell><cell cols="2">2-shot prompt</cell><cell cols="2">3-shot prompt</cell><cell cols="2">4-shot prompt</cell></row><row><cell></cell><cell></cell><cell cols="10">Parent Others Parent Others Parent Others Parent Others Parent Others</cell></row><row><cell cols="2">Depth 5 train</cell><cell>78.6</cell><cell>11.6</cell><cell>79.3</cell><cell>10.3</cell><cell>81.9</cell><cell>9.3</cell><cell>80.8</cell><cell>9.5</cell><cell>77.9</cell><cell>10.2</cell></row><row><cell>Child 3</cell><cell>test</cell><cell>78.3</cell><cell>4.3</cell><cell>77.1</cell><cell>4.5</cell><cell>78.8</cell><cell>4.5</cell><cell>79.8</cell><cell>4.1</cell><cell>77.8</cell><cell>4.5</cell></row><row><cell cols="2">Depth 10 train</cell><cell>77.6</cell><cell>10.3</cell><cell>80.8</cell><cell>10.0</cell><cell>79.3</cell><cell>9.7</cell><cell>78.3</cell><cell>9.5</cell><cell>80.5</cell><cell>9.4</cell></row><row><cell>Child 4</cell><cell>test</cell><cell>81.5</cell><cell>3.1</cell><cell>79.3</cell><cell>2.6</cell><cell>78.4</cell><cell>2.7</cell><cell>78.8</cell><cell>2.5</cell><cell>74.6</cell><cell>2.5</cell></row><row><cell cols="2">Depth 15 train</cell><cell>80.6</cell><cell>8.8</cell><cell>83.8</cell><cell>9.4</cell><cell>80.6</cell><cell>10.0</cell><cell>81.8</cell><cell>10.9</cell><cell>79.7</cell><cell>9.6</cell></row><row><cell>Child 5</cell><cell>test</cell><cell>78.2</cell><cell>2.4</cell><cell>80.3</cell><cell>2.4</cell><cell>78.8</cell><cell>2.1</cell><cell>76.9</cell><cell>2.9</cell><cell>73.9</cell><cell>2.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>(approximately) minimizes both the training and testing loss is that it simulates the underlying program common to both training and testing data. It is noteworthy that the theorem only establishes the existence of such program-simulating θ * . However, empirical evidence in Section 6 demonstrates that the hidden states of Transformers trained in practice exhibit patterns corresponding to the underlying program. recognizes [B] and retrieves its context from [A], guiding the model to output [B] as the next token. In our task, we discovered similar induction heads operating in a slightly different manner. Given an input sentence formatted as (for clarity, we highlight comma tokens at different positions with boxes and different colors):</figDesc><table><row><cell>6 EMPIRICAL EVIDENCE OF THE UNDERLYING PROGRAM</cell></row><row><cell>We present empirical evidence showing that Transformers are simulating the underlying program</cell></row><row><cell>through two mechanisms-induction head and attention assignment, which respectively facilitate</cell></row><row><cell>the in-context learning and parent retrieving.</cell></row><row><cell>6.1 INDUCTION HEADS</cell></row></table><note><p><p><p><p><p><p><p>Probing accuracy in predicting the replaced values of different vertices. "Parent" column records the accuracy in predicting values of parent vertices while "Others" column records the accuracy in predicting values of non-parent vertices.</p>The ability of a 2-layer Transformer to simulate the underlying program aligns with the empirically observed performance in Table</p>1</p>. By expressing the training and testing loss as functions of the model parameters θ, we summarize Lemmas 5.1, 5.2, and 5.3 into the following theorem. Theorem 5.4. There exists a Transformer model parameterized by θ * that satisfies L train (θ * ) -min θ L train (θ) &lt; ϵ, where ϵ is an arbitrarily small value, L k test (θ * ) = 0, where k = 2, . . . , K.</p>Theorem 5.4 shows that the parameters θ * approximate the minimizers of the few-shot training loss, indicating they can be learned from fragmented knowledge. Additionally, θ * minimizes the few-shot testing loss, reflecting strong compositional reasoning ability. The reason why θ * By plotting Transformer's attention heat map, we provide empirical evidence showing the existence of induction heads that enables in-context learning. As described in previous works</p><ref type="bibr" target="#b17">(Elhage et al., 2021;</ref><ref type="bibr" target="#b46">Olsson et al., 2022)</ref></p>, induction heads are two heads of the Transformer in different layers that collaborate to copy patterns. For example, with input sentences like ". . . [A][B]. . . [A]", the first head in a shallow layer copies information from the first [A] to [B], while the second head in a deeper layer</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>The results indicate that Transformers trained on FTCT exhibit limited proficiency in reasoning with incomplete intermediate steps. This limitation is likely due to training dataset bias, where adjacent vertices consistently appear consecutively in training sequences. Nonetheless, this performance shortcoming does not compromise our main findings, which demonstrate the Transformers' compositional reasoning capabilities, because the testing data invariably contain longer causal chains than the training data, regardless of whether the demonstrated reasoning path is complete or not.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>We also assessed final value accuracy (Appendix I.1), which considers the model correct if it outputs the correct value of the last vertex. Models' performance under such metric mirrors that of whole chain accuracy, underscoring the necessity of proper reasoning paths for correct final answers.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>In practice, the orthonormality can be approximated by randomly mapping embeddings to highdimensional Gaussian vectors with low variance<ref type="bibr" target="#b6">(Bietti et al., 2024)</ref>.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>seq = [v L , o eq , o qu , c(v 1 ) 1 , . . . , c(v 1 ) l1 , v 1 , o eq , q 1 , o cm , . . . , o cm , c(v L ) 1 , . . . , c(v L ) l L , v L , o eq , q L ] doc k = [ seq (1) , \n, . . . , \n, seq (k) ]</p><p>, . . . , c(v 1 ) (k+1) l1</p><p>, v 1 , o eq , q</p><p>, v 2 , o eq , q (k+1) 2</p><p>, o cm , . . . , o cm , c(v L )</p><p>After decoding, we have dec( lab</p><p>]. According to the program, we have</p><p>In this situation, the greedy decoding will randomly sample a c(v 2 ) k 1 uniformly and concatenate it to the end of inp k , then we have that</p><p>). It will keep sampling elements from CONT(v 2 ) until it samples the vertex v 2 . Suppose that it samples r k 2 times until it samples v 2 . Then we have that</p><p>Following such routine, the greedy decoding on algorithm 1 we finally sample prog( inp</p><p>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>So we have dec(prog( inp</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F TRANSFORMER ARCHITECTURE</head><p>Here we construct a simplified Transformer architecture that is convenient for theoretical analysis. Denote the set A as the set of all possible tokens that may appear in our task. Given any input sentence z 1:T ∈ A T , it is processed by the following structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1 EMBEDDINGS</head><p>Token Embeddings. The token embedding W tok : A → R dtok is a mapping that maps each possible token z ∈ A to a d tok dimensional real vector W tok (z).</p><p>Positional Embeddings. For each z t that is the tth token of the sentence, it has a d p dimensional positional embedding p t ∈ R dp .</p><p>Comprehensive Embeddings. The comprehensive embedding W comp : A × [T max ] → R dcomp is a mapping that maps both the token information z and the positional information t to a d comp dimensional vectore W comp (z, t).</p><p>To simplify the analysis, we unify the dimensions of different embeddings as</p><p>Then we regulate that any two different embeddings are orthonormal 3 , which means that for all e 1 , e 2 ∈ {W tok (z)} z∈A {p t } t∈[Tmax] {W comp (z, t)} z∈A,t∈ <ref type="bibr">[Tmax]</ref> and e 1 ̸ = e 2 , we have that Referring to <ref type="bibr" target="#b6">(Bietti et al., 2024)</ref>, we construct {W 1,h Q } 4 h=1 as associative memory:</p><p>Using the above keys and values to calculate the hidden states directly is a little bit abstract. As a result, we explain the intuition of our construction taking attn 1,1 and attn 1,2 as examples. For any input sequence z 1:T and its embedding x 1:T , we first analyze attn 1,1 (x 1:T ):</p><p>First is the queries:</p><p>Then is the values:</p><p>For any input sequence z 1:T and its embedding x 1:T , we first analyze attn 2,1 (x 1:T ):</p><p>• If z T = q j , it will be caught by the first item in W 2,1 Q , attending to itself. The value matrix W 2,1 V maps each q to the vector (0 3d1 , W tok (q) ⊤ , 0 d1 ). Hence, we have that attn 2,1 (x</p><p>o dlm , it will be caught by the second item in W 2,1 Q . It attends to a previous token z T1 whose value is equal to z T (which means it is also a comma or delimiter). Denote v j-1 = z T -3 as the corresponding vertex of z T , what is special is that z T1-3 = v j . That means that z T1 is the comma (or delimiter) of the next token of v j in a previous shot. The reason why z T can attend to z T1 is because of their hidden states:</p><p>T1 ) 2d1+1:3d1 , which is caught by the second item in W 2,1 Q . Such a mechanism is known as induction head <ref type="bibr" target="#b21">Giannou et al. (2023)</ref>; Olsson et al. ( <ref type="formula">2022</ref>); <ref type="bibr" target="#b6">Bietti et al. (2024)</ref>. The value matrix W 2,1 V maps each o cm /o dlm to (0 3d1 , W tok (v j-1 ) ⊤ , 0 d1 ) ⊤ , where v j-1 is its corresponding vertex. Hence, we have that attn 2,1 (x</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.3 LINEAR FUNCTION FOR PROBING</head><p>For the probing task, we use a single-layer linear neural network without activation, effectively functioning as a matrix. The input size corresponds to the Transformer's 720-dimensional embeddings, and the output size matches the 50257 tokens of GPT2Tokenizer. We trained 3-layer, 3-head GPT-2-like Transformers on the FTCT training set with varying graph depths (N ) and maximum child chain lengths (M ). We test the performance of Transformers trained on FTCT tasks with N = 5, 8, 10, 13, 15 and M = 2, 3, 4, 5, 6. For each (M, N ) pair, we change the causal structures for 5 times, calculating the average and standard deviation of the testing performance of Transformers trained on them, recording the results in Figure <ref type="figure">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I TESTING PERFORMANCE CURVES</head><p>From Figure <ref type="figure">3</ref> we observe that the curves of the final value accuracy mirrors the curves of whole chain accuracy, underscoring the necessity of proper reasoning paths for correct final answers I.2 TESTING PERFORMANCE WITH NOISY TOKENS In the main text, we configured the training data to consist of child chains blurred by noisy tokens, while the testing data comprised the longest chains without such noise. This setup simulates real-  due to the insufficient data. For any training dataset D, we define t D (v i , q i , v i+1 , q i+1 ) as the times the tuple (v i , q i , v i+1 , q i+1 ) is visited by the data in D. We define the least visited times of D as</p><p>The least visited times measure the degree of how well the S(G) is visited by D. We demonstrate the least visited times of all our training data in Table <ref type="table">4</ref>. The results suggest that all necessary knowledge parts are covered sufficiently by our training dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K PERFORMANCE OF LARGER TRANSFORMER MODELS</head><p>To assess the generalizability of our findings to more complex and sizable architectures, we trained GPT2-small (12 layers, 12 heads, 117M parameters) and GPT2-large (36 layers, 20 heads, 774M parameters) on FTCT tasks with varying causal depths and child chain lengths. We discovered that the diversity of training data used for smaller models was insufficient to leverage the larger models' generalized in-context learning ability. Consequently, we introduced auxiliary data to facilitate this capability. Specifically, the auxiliary data comprises few-shot examples with vertices and values randomly sampled from V all and Z, respectively. The testing performances of GPT2-small and GPT2-large are depicted in Figures <ref type="figure">6</ref> and<ref type="figure">8</ref>, with the performance's relationship to relative knowledge ratio illustrated in Figures <ref type="figure">7</ref> and<ref type="figure">9</ref>. We continue to observe that compositional reasoning ability emerges with increased shot numbers and relative knowledge ratios. However, the performance of these larger models is less stable compared to smaller ones, which may be attributed to overfitting.    </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Josh</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lama</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilge</forename><surname>Akkaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florencia</forename><surname>Leoni Aleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janko</forename><surname>Altenschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Altman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<title level="m">Shyamal Anadkat, et al. Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Many-shot in-context learning</title>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avi</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Rosias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankesh</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaheer</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Azade</forename><surname>Nova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="76930" to="76966" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Transformers learn to implement preconditioned gradient descent for in-context learning</title>
		<author>
			<persName><forename type="first">Kwangjun</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hadi</forename><surname>Daneshmand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suvrit</forename><surname>Sra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">What learning algorithm is in-context learning? investigations with linear models</title>
		<author>
			<persName><forename type="first">Ekin</forename><surname>Akyurek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>id=0g0X4H8yN4I</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Physics of language models: Part 1, context-free grammar</title>
		<author>
			<persName><forename type="first">Zeyuan</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Zhu</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13673</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A theory for emergence of complex skills in language models</title>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.15936</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Birth of a transformer: A memory viewpoint</title>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Bietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivien</forename><surname>Cabannes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diane</forename><surname>Bouchacourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herve</forename><surname>Jegou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Hopping too late: Exploring the limitations of large language models on multi-hop queries</title>
		<author>
			<persName><forename type="first">Eden</forename><surname>Biran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniela</forename><surname>Gottesman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sohee</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mor</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2406.12775</idno>
		<idno>CoRR, abs/2406.12775</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2406.12775" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronen</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ece</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Tat Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Lundberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.12712</idno>
		<title level="m">Sparks of artificial general intelligence: Early experiments with gpt-4</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Hoyeon</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinho</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanseul</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sohee</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miyoung</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeonbin</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seungpil</forename><surname>Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dohaeng</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youbin</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2505.20278</idno>
		<title level="m">The coverage principle: A framework for understanding compositional generalization</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Syntactic structures</title>
		<author>
			<persName><forename type="first">Noam</forename><surname>Chomsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Mouton de Gruyter</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">What does bert look at? an analysis of bert&apos;s attention</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">276</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Training verifiers to solve math word problems</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Why can gpt learn in-context? language models secretly perform gradient descent as meta-optimizers</title>
		<author>
			<persName><forename type="first">Damai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaru</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="4005" to="4019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Faith and fate: Limits of transformers on compositionality</title>
		<author>
			<persName><forename type="first">Nouha</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ximing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Sclar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorraine</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><surname>Le Bras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The evolution of statistical induction heads: In-context learning markov chains</title>
		<author>
			<persName><forename type="first">Ezra</forename><surname>Edelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Tsilivis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Edelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Malach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surbhi</forename><surname>Goel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="64273" to="64311" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A mathematical framework for transformer circuits</title>
		<author>
			<persName><forename type="first">Nelson</forename><surname>Elhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Conerly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transformer Circuits Thread</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Towards revealing the mystery behind chain of thought: a theoretical perspective</title>
		<author>
			<persName><forename type="first">Guhao</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bohang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntian</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haotian</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Connectionism and cognitive architecture: A critical analysis</title>
		<author>
			<persName><forename type="first">Jerry</forename><forename type="middle">A</forename><surname>Fodor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zenon</forename><forename type="middle">W</forename><surname>Pylyshyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="3" to="71" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">What can transformers learn in-context? a case study of simple function classes</title>
		<author>
			<persName><forename type="first">Shivam</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="30583" to="30598" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Looped transformers as programmable computers</title>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Giannou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashank</forename><surname>Rajput</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jy-Yong</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kangwook</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Papailiopoulos</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="11398" to="11442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanlin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiantao</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Russell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.13913</idno>
		<title level="m">How do llms perform two-hop reasoning in context? arXiv preprint</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navin</forename><surname>Goyal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.07971</idno>
		<title level="m">A theory of emergent in-context learning as implicit structure induction</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A structural probe for finding syntax in word representations</title>
		<author>
			<persName><forename type="first">John</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4129" to="4138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Latent concept disentanglement in transformer-based language models</title>
		<author>
			<persName><forename type="first">Guan Zhe</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhavya</forename><surname>Vasudeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vatsal</forename><surname>Sharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyrus</forename><surname>Rashtchian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prabhakar</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rina</forename><surname>Panigrahy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2506.16975</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Compositionality decomposed: How do neural networks generalise</title>
		<author>
			<persName><forename type="first">Dieuwke</forename><surname>Hupkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Verna</forename><surname>Dankers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathijs</forename><surname>Mul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="757" to="795" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Massive values in self-attention modules are the key to contextual knowledge understanding</title>
		<author>
			<persName><forename type="first">Mingyu</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wujiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruixiang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengnan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zirui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.01563</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Examining two hop reasoning through information content scaling</title>
		<author>
			<persName><forename type="first">David</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nora</forename><surname>Belrose</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.03490</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Measuring compositional generalization: A comprehensive method on realistic data</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hylke</forename><surname>Buisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Furrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergii</forename><surname>Kashubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikola</forename><surname>Momchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danila</forename><surname>Sinopalnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Stafiniak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tibor</forename><surname>Tihon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Tsarkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Van Zee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SygcCnNKwr" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Decomposed prompting: A modular approach for solving complex tasks</title>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harsh</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Finlayson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=_nGgzQjzaRy" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Cogs: A compositional generalization challenge based on semantic interpretation</title>
		<author>
			<persName><forename type="first">Najoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Linzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 conference on empirical methods in natural language processing</title>
		<meeting>the 2020 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9087" to="9105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><surname>Iwasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22199" to="22213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks</title>
		<author>
			<persName><forename type="first">Brenden</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2873" to="2882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Teaching arithmetic to small transformers</title>
		<author>
			<persName><forename type="first">Nayoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartik</forename><surname>Sreenivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kangwook</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Papailiopoulos</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=dsUB4bst9S" />
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Infibench: Evaluating the question-answering capabilities of code large language models</title>
		<author>
			<persName><forename type="first">Linyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijie</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenwen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yibo</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyue</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanghan</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=E8EAeyTxOy" />
	</analytic>
	<monogr>
		<title level="m">The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2024a</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Jenny</forename><surname>Victoria R Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naomi</forename><surname>Alvarez-Melis</surname></persName>
		</author>
		<author>
			<persName><surname>Saphra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2507.06445</idno>
		<title level="m">Can interpretation predict behavior on unseen data? arXiv preprint</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Transformers as algorithms: Generalization and stability in in-context learning</title>
		<author>
			<persName><forename type="first">Yingcong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammed</forename><surname>Emrullah Ildiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Papailiopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samet</forename><surname>Oymak</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="19565" to="19594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Dissecting chain-of-thought: Compositionality through in-context filtering and learning. Advances in Neural Information Processing Systems</title>
		<author>
			<persName><forename type="first">Yingcong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartik</forename><surname>Sreenivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Giannou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Papailiopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samet</forename><surname>Oymak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Chain of thought empowers transformers to solve inherently serial problems</title>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=3EWTEy9MTM" />
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Delving into the reversal curse: How far can large language models generalize?</title>
		<author>
			<persName><forename type="first">Zhengkai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binbin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieping</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="30686" to="30726" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Attention with markov: A framework for principled analysis of transformers via markov chains</title>
		<author>
			<persName><forename type="first">Ashok</forename><surname>Vardhan Makkuva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Bondaschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adway</forename><surname>Girish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alliot</forename><surname>Nagle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeji</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gastpar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.04161</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Rule extrapolation in language modeling: A study of compositional generalization on ood prompts</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Mészáros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Szilvia</forename><surname>Ujváry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrik</forename><surname>Reizinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ferenc</forename><surname>Huszár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="34870" to="34899" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Rethinking the role of demonstrations: What makes in-context learning work?</title>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinxi</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.emnlp-main.759</idno>
		<ptr target="https://aclanthology.org/2022.emnlp-main.759/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</editor>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-12">December 2022</date>
			<biblScope unit="page" from="11048" to="11064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">How transformers learn causal structure with gradient descent</title>
		<author>
			<persName><forename type="first">Eshaan</forename><surname>Nichani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Damian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="38018" to="38070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Johan Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.00114</idno>
		<title level="m">Show your work: Scratchpads for intermediate computation with language models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nelson</forename><surname>Elhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nova</forename><surname>Dassarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.11895</idno>
		<title level="m">-context learning and induction heads</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">On limitations of the transformer architecture</title>
		<author>
			<persName><forename type="first">Binghui</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srini</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Papadimitriou</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=KidynPuLNW" />
	</analytic>
	<monogr>
		<title level="m">First Conference on Language Modeling</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Measuring and narrowing the compositionality gap in language models</title>
		<author>
			<persName><forename type="first">Ofir</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muru</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="5687" to="5711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Why think step by step? reasoning emerges from the locality of experience</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Prystawski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">On the turing completeness of modern neural network architectures</title>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Marinković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Barceló</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HyGBdo0qFm" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">How capable can a transformer become? a study on synthetic, interpretable tasks</title>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikail</forename><surname>Khona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hidenori</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekdeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lubana</forename></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=KIhFggzePM" />
	</analytic>
	<monogr>
		<title level="m">R0-FoMo:Robustness of Few-shot and Zero-shot Learning in Large Foundation Models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Mathematical discoveries from program search with large language models</title>
		<author>
			<persName><forename type="first">Bernardino</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammadamin</forename><surname>Barekatain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Novikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matej</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M Pawan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emilien</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco Jr</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><forename type="middle">S</forename><surname>Ellenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Fawzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">625</biblScope>
			<biblScope unit="issue">7995</biblScope>
			<biblScope unit="page" from="468" to="475" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Why larger language models do in-context learning differently?</title>
		<author>
			<persName><forename type="first">Zhenmei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoyan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=WOa96EG26M" />
	</analytic>
	<monogr>
		<title level="m">Forty-first International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Challenging bigbench tasks and whether chain-of-thought can solve them</title>
		<author>
			<persName><forename type="first">Mirac</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.findings-acl.824</idno>
		<ptr target="https://doi.org/10.18653/v1/2023.findings-acl.824" />
	</analytic>
	<monogr>
		<title level="m">ACL (Findings)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="13003" to="13051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Connecting the dots: Llms can infer and verbalize latent structure from disparate training data</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Treutlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dami</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Betley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cem</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><forename type="middle">B</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Owain</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="140667" to="140730" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Transformers learn in-context by gradient descent</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Von</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oswald</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Eyvind</forename><surname>Niklasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ettore</forename><surname>Randazzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">João</forename><surname>Sacramento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Mordvintsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Vladymyrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="35151" to="35174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Grokking of implicit reasoning in transformers: A mechanistic journey to the edge of generalization</title>
		<author>
			<persName><forename type="first">Boshi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="95238" to="95265" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Large language models are latent variable models: Explaining and finding good demonstrations for incontext learning</title>
		<author>
			<persName><forename type="first">Xinyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanrong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Saxon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Statistically meaningful approximation: a case study on approximating turing machines with transformers</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yining</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="12071" to="12083" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Emergent abilities of large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=yzkSU5zdwD" />
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<idno type="ISSN">2835-8856</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Survey Certification</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The learnability of in-context learning</title>
		<author>
			<persName><forename type="first">Noam</forename><surname>Wies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amnon</forename><surname>Shashua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations</title>
		<meeting>the 2020 conference on empirical methods in natural language processing: system demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">An explanation of in-context learning as implicit bayesian inference</title>
		<author>
			<persName><forename type="first">Sang</forename><surname>Michael Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditi</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=RdJVFCHjUMI" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Do large language models have compositional ability? an investigation into limitations and scalability</title>
		<author>
			<persName><forename type="first">Zhuoyan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenmei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=iI1CzEhEMU" />
	</analytic>
	<monogr>
		<title level="m">First Conference on Language Modeling</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">Sohee</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nora</forename><surname>Kassner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mor</forename><surname>Geva</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2411.16679</idno>
		<title level="m">Do large language models perform latent multi-hop reasoning without exploiting shortcuts? arXiv preprint</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Physics of language models: Part 2.1, grade-school math and the hidden reasoning process</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zicheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyuan</forename><surname>Allen-Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirteenth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">SKILL-MIX: a flexible and expandable family of evaluations for AI models</title>
		<author>
			<persName><forename type="first">Dingli</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simran</forename><surname>Kaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arushi</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonah</forename><surname>Brown-Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Jf5gplvglq" />
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Back attention: Understanding and enhancing multi-hop reasoning in large language models</title>
		<author>
			<persName><forename type="first">Zeping</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.10835</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Are transformers universal approximators of sequence-to-sequence functions</title>
		<author>
			<persName><forename type="first">Chulhee</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinadh</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankit</forename><surname>Singh Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sashank</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=ByxRM0Ntvr" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">On the paradox of learning to reason from data</title>
		<author>
			<persName><forename type="first">Honghua</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liunian</forename><surname>Harold Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Van Den Broeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">What and how does in-context learning learn? bayesian model averaging, parameterization, and generalization</title>
		<author>
			<persName><forename type="first">Yufeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengzhuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoran</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoran</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.19420</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Initialization is critical to whether transformers fit composite functions by reasoning or memorizing</title>
		<author>
			<persName><forename type="first">Zhongwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengxiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi-Qin</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="14093" to="14126" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Least-to-most prompting enables complex reasoning in large language models</title>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName><surname>Chi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=WZH7099tgfM" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Teaching algorithmic reasoning via in-context learning</title>
		<author>
			<persName><forename type="first">Hattie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Azade</forename><surname>Nova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Behnam</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanie</forename><surname>Sedghi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09066</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
