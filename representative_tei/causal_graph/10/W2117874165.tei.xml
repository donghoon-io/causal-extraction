<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Bootstrap Method for Identifying and Evaluating a Structural Vector Autoregression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2006-03-28">28 March 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kevin</forename><forename type="middle">D</forename><surname>Hoover</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Economics</orgName>
								<orgName type="institution">Koç University</orgName>
								<address>
									<postCode>34450</postCode>
									<settlement>Sariyer Turkey</settlement>
									<region>Istanbul</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">‡Department of Economics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>One Shields Avenue</addrLine>
									<postCode>95616-8578</postCode>
									<settlement>Davis</settlement>
									<region>California</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><forename type="middle">J</forename><surname>Perez</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Economics</orgName>
								<orgName type="institution">Koç University</orgName>
								<address>
									<postCode>34450</postCode>
									<settlement>Sariyer Turkey</settlement>
									<region>Istanbul</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">‡Department of Economics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>One Shields Avenue</addrLine>
									<postCode>95616-8578</postCode>
									<settlement>Davis</settlement>
									<region>California</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Selva</forename><surname>Demiralp</surname></persName>
							<email>sdemiralp@ku.edu.tr</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Economics</orgName>
								<orgName type="institution">Koç University</orgName>
								<address>
									<postCode>34450</postCode>
									<settlement>Sariyer Turkey</settlement>
									<region>Istanbul</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">‡Department of Economics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>One Shields Avenue</addrLine>
									<postCode>95616-8578</postCode>
									<settlement>Davis</settlement>
									<region>California</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Davis Selva Demiralp</orgName>
								<orgName type="institution" key="instit1">University of California</orgName>
								<orgName type="institution" key="instit2">Koç University</orgName>
								<orgName type="institution" key="instit3">California State University</orgName>
								<address>
									<settlement>Sacramento</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Economics One Shields Avenue Davis</orgName>
								<address>
									<postCode>95616 (530 752-0741</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">†Department of Economics</orgName>
								<orgName type="institution">California State University</orgName>
								<address>
									<addrLine>6000 J. Street</addrLine>
									<postCode>95819-6082</postCode>
									<settlement>Sacramento Sacramento</settlement>
									<region>California</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">We thank Katarina Juselius</orgName>
								<orgName type="institution" key="instit1">Søren Johansen</orgName>
								<orgName type="institution" key="instit2">David Hendry</orgName>
								<orgName type="institution" key="instit3">University of Copenhagen</orgName>
								<orgName type="institution" key="instit4">Oxford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Bootstrap Method for Identifying and Evaluating a Structural Vector Autoregression</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-03-28">28 March 2006</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>vector autoregression (VAR)</term>
					<term>structural vector autoregression (SVAR)</term>
					<term>causality</term>
					<term>causal order</term>
					<term>Choleski order</term>
					<term>causal search algorithms</term>
					<term>graph-theoretic methods JEL Codes: C30</term>
					<term>C32</term>
					<term>C51 Demiralp</term>
					<term>Hoover</term>
					<term>and Perez</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph-theoretic methods of causal search based in the ideas of <ref type="bibr" target="#b16">Pearl (2000)</ref>, <ref type="bibr" target="#b19">Spirtes, Glymour, and Scheines (2000)</ref>, and others have been applied by a number of researchers to economic data, particularly by <ref type="bibr" target="#b20">Swanson and Granger (1997)</ref> to the problem of finding a data-based contemporaneous causal order for the structural autoregression (SVAR), rather than, as is typically done, assuming a weakly justified Choleski order. <ref type="bibr" target="#b9">Demiralp and Hoover (2003)</ref> provided Monte Carlo evidence that such methods were effective, provided that signal strengths were sufficiently high. Unfortunately, in applications to actual data, such Monte Carlo simulations are of limited value, since the causal structure of the true data-generating process is necessarily unknown. In this paper, we present a bootstrap procedure that can be applied to actual data (i.e., without knowledge of the true causal structure). We show with an applied example and a simulation study that the procedure is an effective tool for assessing our confidence in causal orders identified by graph-theoretic search procedures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>"Bootstrap Methods for the SVAR" 28 March 2006 3 allows one to assess the reliability of a data-based identification scheme for arbitrary structures. We show that this technique allows us, in cases in which we do not know the true underlying structure, to present simulation evidence that closely mimics Monte Carlo simulations for which we know the underlying structure ex hypothesi. It therefore allows us to give reasonable assessments of the reliability of data-based, graph-theoretic identifications of SVARs.</p><p>The SVAR can be written as:</p><p>(1)</p><formula xml:id="formula_0">t t t L E Y A Y A + = -1 0 ) ( ,</formula><p>where Y t is an N × 1 vector of contemporaneous variables, A 0 is an N × N matrix with ones on the main diagonal and possibly non-zero off-diagonal elements; A(L) is a polynomial in the lag operator, L; and E t is an N × 1 vector of error terms with E = [E t ],</p><p>t = 1, 2, . . . , T and the covariance matrix Σ = E(EE´) diagonal. The individual error terms (shocks) can be assigned unequivocally to particular equations because Σ is diagonal. The matrix A 0 defines the causal interrelationships among the contemporaneous variables.</p><p>Premultiplying equation ( <ref type="formula">1</ref>) by 1 0 -A yields the reduced-form or vector autoregression (VAR):</p><p>(2)</p><formula xml:id="formula_1">t t t t t L L U Y B E A Y A A Y + = + = - - - - 1 1 0 1 1 0 ) ( ) (</formula><p>, "Bootstrap Methods for the SVAR" 28 March 2006 4 with U = [U t ], t = 1, 2, . . . , T. While equation ( <ref type="formula">2</ref>) is easily estimated, the covariance matrix, Λ = E(UU′) in general will not be diagonal, so that it will be impossible to evaluate the effects of shocks to particular variables. The identification problem reduces to this: if we know A 0 , then it is easy to recover equation (1) from our estimates of (2); but how do we know A 0 ?</p><p>Identification schemes typically start with the property that Σ, the covariance matrix of E t , is diagonal. True identification would permit us to transform equation ( <ref type="formula">2</ref>) into (1) and recover the diagonal Σ. There are a large number of N × N matrices, P i such that the covariance matrix ) )' ( (</p><formula xml:id="formula_2">1 1 U P U P Ω - - = i i E</formula><p>is diagonal. Let P = {P i } be the set of all such orthogonalizing transformations. Each element of P can be thought of as a potential candidate for A 0 . Most commonly economists have based their choices of P i on highly informal arguments appealing to general plausibility or weak theoretical considerations. Typically, although not uniformly (see, for instance, <ref type="bibr" target="#b2">Bernanke and Mihov 1998)</ref>, they have restricted themselves to just-identified, lower-triangular matrices. These are based on the Choleski decompositions of the covariance matrix of U.</p><p>There are, in general, n! such matrices, each corresponding to one Wold-or recursive causal ordering of the variables in Y.</p><p>We too restrict ourselves to recursive orderings, but widen the class of possible matrices to include the over-identified -that is, to matrices that may have zeroes among the off-diagonal elements of P i . Graph-theoretic search algorithms work according to the following general plan: the true A 0 induces a set of conditional independence relations among the elements of U t . The algorithm thoroughly tests for conditional independence relations among the estimated t U ˆ. It then selects the class of P i -perhaps unique -that is consistent with those independence relations.</p><p>The Monte Carlo simulations of <ref type="bibr" target="#b9">Demiralp and Hoover (2003)</ref> generate data from a variety of known specifications of SVARs like equation ( <ref type="formula">1</ref>) and then address the question of how successfully A 0 can be recovered from estimates of VARs like equation</p><p>(2). The problem for empirical analysts is to evaluate the reliability of such identifications when A 0 and, indeed, the entire specification of the SVAR is unknown.</p><p>We employ a bootstrap strategy. Starting with the original data, we estimate the VAR (equation ( <ref type="formula">2</ref>)) and retain the residuals ] [ ˆt U U =</p><p>, t = 1, 2, . . . , T. In order to maintain the contemporaneous correlations among the variables, we resample the residuals by columns from U ˆ. The resampled residuals are used in conjunction with the coefficient estimates of equation ( <ref type="formula">2</ref>) to generate simulated data. A large number of simulated data sets are created. For each one, we run the search algorithm, record the results, and compute summary statistics.</p><p>Graph-theoretic, causal search algorithms are increasingly used in biological sciences, physical sciences, and social sciences, other than economics. And while there are by now a number of applications within economics, the ideas behind graph-theoretic search algorithms are not well known among economists. Consequently, we begin with a review of the basic ideas behind the algorithms. Both the search algorithm and the bootstrap procedure that we propose to evaluate our confidence in the outcome of the search are best understood in a concrete example. We, therefore, illustrate both with the same data set used in <ref type="bibr" target="#b20">Swanson and Granger (1997)</ref>. The central question of this study is, how reliable is this bootstrap procedure? We conclude with a simulation study that addresses that question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Causal Search Algorithm</head><p>To keep things simple, assume that the variables are a cross-section with an interesting causal structure, but no time-series structure. The most fundamental notion is that causally related variables are connected by edges. On the one hand, if the direction of causal influence is ambiguous the edge is shown as a line or undirected edge. On the other hand, if it is determinate, then an arrow head indicates the causal direction, and the edge is referred to as directed. Sprites, Glymour, <ref type="bibr" target="#b19">Scheines (2000)</ref> and <ref type="bibr" target="#b16">Pearl (2000)</ref> show how the mathematics of graph theory relates a graphical representation of causal relations to implications for the probability distributions of the variables.</p><p>Suppose that A → B → C (that is, A causes B causes C). A and C would be probabilistically dependent; but, conditional on B, they would be independent. Causal search algorithms use a statistical measure of independence, commonly a measure of conditional correlation, to check systematically the patterns of conditional independence and dependence and to work backwards to the class of admissible causal structures. <ref type="foot" target="#foot_1">3</ref> We employ the SGS algorithm of <ref type="bibr">Spirtes et al. (2000, pp. 82-83)</ref>. The SGS algorithm is a close relative of the PC algorithm <ref type="bibr">(Spirtes et al. 2000, pp. 84-85 )</ref>. <ref type="bibr" target="#b9">Demiralp and Hoover (2003)</ref>  </p><formula xml:id="formula_3">A → B → C.</formula><p>6. If there is a pair of variables, A and B connected both by an undirected edge and a directed path, starting at A, through one or more other variables to B (i.e., a path in which the arrows all orient in a chain), then orient the undirected edge as</p><formula xml:id="formula_4">A → B.</formula><p>Steps 1-4 are statistical; the next two steps are logical.</p><p>Step 5 follows logically, because orienting the undirected edge in the other direction would turn the pattern into an unshielded collider, which would have already been identified in Step 4.</p><p>Step 6 follows because orienting the undirected edge in the other direction would, contrary to assumption, render the graph cyclical.</p><p>variables against every set of variables of the right number for that round, whether or not they were connected to the test pair in the previous round. The SGS algorithm may detect conditional independence better in the presence of nonlinearities, but its computational complexity rises exponentially even when the true underlying graph is sparsely connected. Comparison of our results in section 4, especially Figures <ref type="figure">6</ref> and<ref type="figure" target="#fig_3">7</ref>, with those of <ref type="bibr" target="#b9">Hoover and Demiralp (2003)</ref> confirm that the two algorithms generate similar results for small numbers of variables.</p><p>"Bootstrap Methods for the SVAR" 28 March 2006 9</p><p>The SGS algorithm can be illustrated with the example in Figure <ref type="figure">1</ref>. Panel A shows the graph of the data-generating process. It determines just what the tests should find, small-sample problems to one side. The graph corresponds to a particular</p><formula xml:id="formula_5">matrix ⎥ ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎢ ⎣ ⎡ = 1 0 0 1 0 0 1 0 0 0 0 1 0 ZY ZW YX YW a a a a A</formula><p>, where the variables are ordered WXYZ, the rows correspond to effects and the columns to causes, and the a ij to the non-zero elements.</p><p>Step 1 starts with panel B in which each variable is connected to every other variable by an undirected edge.</p><p>Step 2 eliminates edge 1, because W and X are 3. An Application of the Bootstrap Procedure <ref type="bibr" target="#b20">Swanson and Granger's (1997)</ref> essential contribution was to realize that identification of the SVAR depends only on the contemporaneous correlations among variables and that the VAR itself filters out the lagged dynamics so that the residuals of a well specified VAR (the t U ˆ in an estimated version of equation ( <ref type="formula">2</ref>)) capture the relevant contemporaneous characteristics of the original variables. Each element of t U ˆcan be thought of as a filtered variable purged of its time-series properties. A graph-theoretic search algorithm can then be applied to attempt to recover the causal order among these filtered variables.</p><p>In one case, <ref type="bibr">Swanson and Granger (1997, pp. 362-363)</ref> applied this filtering method and a causal search algorithm to updated quarterly data previously investigated by <ref type="bibr" target="#b14">King et al. (1991)</ref>. But what confidence should anyone place in the identification selected by the algorithm? We use the bootstrap procedure to evaluate the selected identification.</p><p>Appendix B reports the details of the bootstrap procedure. Here we provide only a sketch.</p><p>We start with the VAR that is used to identify the causal order. A bootstrap realization is created by using the estimated coefficients from this VAR as well as its matrix of residuals ( U ˆ) resampled by columns with replacement,. For each bootstrap realization, a new VAR is estimated and the matrix of its residuals ( U ~) is retained as the time series of the filtered variables. These are then fed into the SGS search algorithm and the results are recorded. We construct a large number of bootstrap realizations and record the outcomes of the search.</p><p>The bootstrap results are displayed in two ways. columns each refer to possible orientations of the edge and report each as a percentage of the total number of realizations in which some edge was found.</p><p>An undirected edge (⎯) implies that the algorithm cannot select a unique causal direction, so that ceteris paribus the selected graph identifies an equivalence class with one member with the edge directed one way and the other with the edge reversed.</p><p>A bidirectional edge (↔) appears to violate the assumption of acylicality. The algorithm sometimes may select a bidirectional edge nonetheless, because it orients edges based on triples of variables, rather than on the whole graph. Inconsistencies can arise for three reasons. First, they may be artifacts of small samples. Second and more interestingly, practitioners of graph-theoretic methods have seen them as evidence of omitted latent variables in otherwise acyclical graphs (see <ref type="bibr">Scheines et al. 1994, pp. 90)</ref>.</p><p>Third, economists naturally may interpret them as evidence of simultaneous causality. This is an especially attractive option if we are willing to maintain the assumption of causal sufficiency -that is, that there are no important omitted variables.</p><p>The results give strong support for the skeleton identified in Figure <ref type="figure">2</ref>. That skeleton omits two edges and the bootstrap typically omits those edges as well: between I and M in 94 percent of the realizations and between M and Y in 100 percent of the realizations. The highest number of omissions for any of the edges in the selected skeleton is 16 percent, and two edges are never omitted.</p><p>The data are repackaged in Figure <ref type="figure">2</ref> to provide easy-to-grasp summary statistics.</p><p>Each edge is associated with a triple Exists/Directed/Net Direction. The first number, Exists, is the percentage of realizations in which an edge is found (i.e., it is the complement of the No Edge value). The second, Directed, indicates the percentage of existing edges for which there is a definite direction -that is, the sum of the three columns headed "→" and "←" and "↔" divided by (1-No Edge). Finally, Net Direction indicates the difference between unidirectional edges going from earlier to later ordered variables and those going from later to earlier as a percentage of the directed edges -that is, the difference between the columns headed "→" and "←" divided by the sum of the same two columns. The order of variables is that in the left-hand column of Table <ref type="table" target="#tab_4">1</ref>, shown in Figure <ref type="figure">2</ref> as the clockwise arrangement of the variables starting from the upper left corner (C). A negative number, therefore indicates an edge directed from a higher to a lower ordered variable -for example, from Y to I.</p><p>To illustrate, consider the edge between C and M, which the SGS algorithm identified it as C ← M (we adopt the convention of always writing the lower ordered variable on the left). Its statistics, 87/75/-100, indicate that it is selected by the bootstrap procedure in 87 percent of the realizations, found to have a definite direction in 75 percent of the realizations in which it is selected, and is 100 percentage points more</p><formula xml:id="formula_6">frequently oriented C ← M than C → M.</formula><p>Overall, the bootstrap provides support for the orientation of the edges, as well as for the skeleton. Both the Directed and Net Direction statistics correspond to the orientation of the identified edges. Two edges require further comment. First, the edge between I and Y is directed in the bootstrap only 40 percent of the times that it is selected, although when it is directed it is oriented as in the identified graph (I ← Y) by 95 points more than the reverse. While this orientation would appear to be only weakly supported, notice that reversing the orientation, holding all other edges fixed, would violate the maintained hypothesis that the graph is acyclical by introducing a loop: I → Y→ C → I.</p><p>"Bootstrap Methods for the SVAR" 28 March 2006 14 Second, the search algorithm directs the edge between C and I in 67 percent of the cases in which it is selected, but with only a 19 point advantage for the selected direction (C → I) over the reverse. This is confirmed in Table <ref type="table" target="#tab_4">1</ref> which shows a fairly even division between the edge being undirected and it taking each of the unidirectional orientations. However, given the high level of confidence in the orientation of C ← Y and C ← M edges, directing the edge as C ← I would not be attractive. It would imply that C was an unshielded collider that had not been identified. C is found to be an unshielded collider in only 20 percent of the realizations. Thus, despite the two edges the directions of which are individually more weakly identified edges, the bootstrap procedure, viewed as a whole, provides moderately strong support for the graph identified in Figure <ref type="figure">2</ref>.</p><p>Figure <ref type="figure">3</ref> demonstrates why it matters which order is selected. In the four-variable system, there are sixteen impulse-response functions. We display three that illustrate the range of variation. Each panel displays one of these impulse-response functions for each of the three identification schemes:</p><formula xml:id="formula_7">1. A Choleski ordering M, C, I, Y, corresponding to ⎥ ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎢ ⎣ ⎡ = 1 0 1 0 0 1 0 0 0 1 0 YI YC YM IC IM CM a a a a a a A ;</formula><p>2. <ref type="bibr" target="#b20">Swanson and Granger's (1997)</ref> </p><formula xml:id="formula_8">causal chain M → C → I → Y, corresponding to ⎥ ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎢ ⎣ ⎡ = 1 0 0 0 1 0 0 0 1 0 0 0 1 0 YI IC CM a a a A ;</formula><p>3. the order selected by the SGS algorithm (Figure <ref type="figure">2</ref>), corresponding to</p><formula xml:id="formula_9">⎥ ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎢ ⎣ ⎡ = 1 0 0 0 1 0 0 1 0 0 0 1 0 IY IC CY CM a a a a A .</formula><p>In each panel, the impulse-response functions for the Choleski ordering and Choleski orders are in fact very close to those for the SGS-selected order. This similarity points to the usefulness of causal search algorithms in choosing among just-identified causal orders that could not be distinguished on, for example, a likelihood criterion alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">How Well Does the Bootstrap Indicate the Uncertainty of Causal Search?</head><p>Now that we have seen how to apply the bootstrap procedure, we need to ask whether its guidance is reliable. We know from Monte Carlo simulations that the performance of the causal search algorithm depends on the signal-to-noise ratios of the causal linkages in the true data-generating process. Monte Carlo simulations are based on the specification of an artificial "true" data-generating process. In practice, of course, we do not know the true data-generating process. Our assessment of reliability is guided by the following idea: the bootstrap procedure is reliable if it gives us guidance that would mimic that of a Monte Carlo simulation, if we somehow had access to the truth.</p><p>We begin our assessment of the bootstrap procedure with a known SVAR. We evaluate the performance of SGS search algorithm in a Monte Carlo simulation. This simulation then becomes the standard against which we judge the success of the bootstrap procedure. Since the bootstrap is a solution to an essentially statistical problem, we evaluate its success with respect to the four statistical steps of the SGS algorithmnamely, how well it does at identifying the skeleton and unshielded colliders of the graph of the true SVAR. The bootstrap procedure would work ideally if it reproduced the results of the Monte Carlo simulation.</p><p>Appendix C reports the details of the design of the simulation experiments. Here we provide only a sketch.</p><p>1. We start with two graphs and the A 0 matrix of their associated SVARs. Model 1 (Figure <ref type="figure">4</ref>) represents three unshielded colliders: y 4 on three different paths -y 1 y 4 y 2 , y 1 y 4 y 3 , and y 2 y 4 y 3 . Model 2 (Figure <ref type="figure">5</ref>) is an elaboration of Model 1:</p><p>the edge added between y 1 and y 2 acts as a shield, so that y 4 on path y 1 y 4 y 2 is no longer an unshielded collider. The additional edge 5 adds another unshielded collider, while the additional edge 6 does not. Model 2, therefore, also has three unshielded colliders: y 4 on paths y 1 y 4 y 3 and y 2 y 4 y 3 ; and y 2 on y 1 y 2 y 5 . And since edge 6 can be reversed without changing the skeleton or the unshielded colliders, the best that the SGS algorithm could do is to find an undirected edge between y 3 and y 6 .</p><p>We also consider two further models. Model 3 (not shown) is identical to</p><p>Model 1 except that it reverses edge 3. This reduces the number of unshielded colliders to just one: y 4 on the path y 1 y 4 y 3 . Similarly, Model 4 (not shown) is identical to Model 2 except that it reverses edge 4. There are now only two unshielded colliders: y 2 on y 1 y 2 y 5 and y 3 on y 4 y 3 y 6 . The algorithm cannot identify the direction of edge 2.</p><p>2. The SVARs corresponding to Models 1-4 are used to create simulated sets of pseudo-real-world data. Each realization constructs a time-series of 500 observations based on the assignment of a different set of random values to the non-zero off-diagonal coefficients (the ij α ) of the A 0 matrix. The coefficients are drawn uniformly from an interval that ensures that the ex ante t-statistics, which provide a measure of the signal-to-noise ratio, are bound between 0 and about 10.</p><p>3. We then estimate a VAR like equation (2) for each realization of the pseudo-realworld data, retain the residuals, and treat them as filtered variables that form the input to the SGS search algorithm. The output of the search is then recorded and compared to the known graph of the model. These comparisons are reported as the outcomes of the Monte Carlo simulations. These simulations are the standard against which the bootstrap procedure is judged.</p><p>4. We apply the bootstrap procedure, constructing a large number of bootstrap realizations, for each realization of the pseudo-real-world data and record the outcomes.</p><p>The key statistical decision in the SGS algorithm starts from the null hypothesis that a conditional correlation equals zero. Rejection of the null implies, in steps 1-3, that an edge is not removed from the graph and, in step 4, that an unshielded collider is</p><p>identified. An error of commission (falsely including an edge or falsely identifying an unshielded collider) is, therefore, an example of type I error, and the rate of type I error corresponds to the size of the procedure. Analogously, an error of omission (falsely omitting an edge or failing to identify an unshielded collider) is an example of type II error, and the complement of the rate of type II error corresponds to the power the procedure.</p><p>Figure <ref type="figure">6</ref> reports the size and power for identification of the skeleton of Model 1 for both the Monte Carlo and the bootstrap procedure. The horizontal axis reports the signal-to-noise ratio of the parameterization of the A 0 matrix measured as the mean exante t-statistic for the edges in Figure <ref type="figure">4</ref>.</p><p>The critical values of the tests of conditional correlation for the Monte Carlo simulations are set at 10 percent. Notice that, when signal-to-noise ratios are very low, the size of the procedure is also approximately 10 percent; but, when signal-to-noise ratios are very high, the size of the procedure falls by about half to 6 percent. This is consistent with the results of Monte Carlo experiments on the PC algorithm reported by <ref type="bibr" target="#b9">Demiralp and Hoover (2003)</ref>. Figure <ref type="figure" target="#fig_3">7</ref> reports results for size and power for the unshielded colliders in Model 1. The pattern is similar to that in Figure <ref type="figure">6</ref>, though at high signal strengths, type I error falls to nearly zero.</p><p>Preliminary experimentation on Model 1 showed that using a 10-percent critical value for the tests of conditional correlation in the SGS algorithm applied to the bootstrap resulted in a size of the procedure systematically higher than that for the Monte Carlo simulations. Experimentation demonstrated that by reducing the critical value to 2.5 percent it was possible to match the size of the Monte Carlo procedure extremely well as</p><p>shown in Figure <ref type="figure">6</ref>. The comparative size reported in Figure <ref type="figure">6</ref> does not, therefore, represent an independent test of the quality of the bootstrap procedure. However, the same adjustment to the critical value is applied to Model 2-4 with no further modelspecific calibration. Table <ref type="table">2</ref> shows that the match between the size of the Monte Carlo and bootstrap procedures is very close for both the skeletons and the unshielded colliders (look at the errors of commission, ignoring Model 2A, which is discussed below).</p><p>Turning to errors of omission, Figure <ref type="figure">6</ref> shows that the power of the bootstrap procedure to identify the skeleton of Model 1 is uniformly lower than that of the Monte Carlo. The power of both the Monte Carlo and the bootstrap increase as signal-to-noise ratios increase. The mean difference between the two curves is 8.6 percentage points. The power of the search algorithm to identify unshielded colliders correctly as indicated by the Monte Carlo is very low when signal strengths are low, but rises to 85 percent when they are high. The bootstrap procedure also shows this rising pattern, but remains systematically less powerful than the Monte Carlo with a mean difference between the two curves of 11.3 percentage points.</p><p>All four models show similar patterns of type I and type II errors. The main question that we want to answer is how well the bootstrap algorithm mimics the results that we would find in a Monte Carlo study, were we lucky enough to know the true structure. We have already seen that the bootstrap algorithm with the adjustment to the critical value mimics type I error closely, but differs on type II error to a non-trivial degree. Table <ref type="table">2</ref> presents the differences between the bootstrap algorithm and the Monte Carlo for all four models. The pattern of differences for Models 2, 3, and 4 are similar to those for Model 1.</p><p>To investigate the effect of the critical value adjustment somewhat further, we also compare the Monte Carlo to the bootstrap algorithm for Model 2 with the critical value in the bootstrap set to 10 percent (rather than the adjusted 2.5 percent). The results (shown in Table <ref type="table">2</ref> as Model 2A) nearly reverse the pattern with the adjusted critical value. Now the bootstrap matches the Monte Carlo on errors of omission for the skeleton very closely, but differs by 9.2 percentage points (on average over different signal strengths) on errors of commission. The pattern is much the same with respect to unshielded colliders. These patterns are reflective of the usual tradeoff between size and power. They show that we can calibrate the bootstrap to either extreme, and possibly through an intermediate setting of the critical value in the bootstrap might choose some more desirable compromise in matching the Monte Carlo properties on one or other type of error.</p><p>We conclude from these simulation experiments that the bootstrap procedure provides a reasonable method for assessing the reliability of causal structures identified by the SGS algorithm. With an adjustment to the critical value in the tests of conditional correlation, size can be controlled with reasonable precision. Power is systematically lower than Monte Carlo simulations indicate. This implies that the bootstrap procedure will suggest the omission of a causal linkage or fail to direct it too frequently -although the mean errors appear moderate. To look at this result more positively, if the bootstrap confirms a causal linkage, that confirmation is unlikely to be spurious: the bootstrap method should lead to few false positives. <ref type="bibr" target="#b9">Demiralp and Hoover (2003)</ref> showed that the graph-theoretic PC algorithm was very successful in finding the skeleton and somewhat successful in directing the edges of the causal graph corresponding to the contemporaneous causal order of structural vector autoregressions. These findings held out the promise that data-based methods might replace the ad hoc and largely unconvincing a priori arguments that VAR analysts have typically used to choose the causal order of the SVAR. Unfortunately, while it was possible to show good results for particular structures, it was not clear how one could assess the reliability of a causal ordering chosen by a search algorithm in the typical cases in which, unlike Monte Carlo experiments, we do not have the true order to hand to serve as a standard of comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">The Utility of Graph-theoretic Algorithms</head><p>In this paper, we have proposed a bootstrap procedure that allows the investigator to assess the performance of the SGS algorithm (a close relative of the PC algorithm) using only information readily to hand -that is, the data themselves. Using data from <ref type="bibr" target="#b20">Swanson and Granger (1997)</ref>, we showed that this bootstrap procedure was an effective tool. And, by comparing the results of the bootstrap procedure to those of Monte Carlo experiments on known models, we were able to show that the bootstrap sufficiently well mimics the Monte Carlo that it can provide useful guidance on the reliability of inference using graph-theoretic algorithms to determine the causal order of SVARs.</p><p>1. Start with an estimate of the reduced-form using the notation of section 1 with the addition that a "hat" (^) indicates an estimated value:</p><p>(B.1)</p><formula xml:id="formula_10">t t t L U Y B Y ) ( ˆ1 + = - . Let ] [ ˆt U U =</formula><p>, where U ˆis an N × T matrix with columns t U ˆ.</p><p>2. Let k = 1, 2, . . . K be the bootstrap realization, and j = 1, 2, . . . J, where J &gt; &gt; T, be the pseudo-time period. (In the simulations in this paper, T = 500, and J = 1,500.) Construct a set of bootstrap pseudo-observations recursively, starting with the initial condition</p><formula xml:id="formula_11">= 0 ~k Y 0, with (B.2) BS kj BS j k BS kj L U Y B Y + = -) 1 ( ) ( ˆ, where each BS kj U is a scaling factor, V L T L T - - -</formula><p>times one of the columns of U ˆ drawn randomly with replacement, where L is the order of the lags of the VAR and V = N + 1 (i.e., the number of variables in each equation of the VAR including the constant). The scaling factor corrects for losses in degrees of freedom in estimating the residuals from the VAR. Define the pseudo-data set as</p><formula xml:id="formula_12">] [ ] [ ~BS ki kt k Y Y Y = =</formula><p>to be the last T of the J columns of recursive pseudoobservations. That is, the observations for t = 1, 2, . . . T correspond to those for i = J -T + 1, J -T + 2, . . . J -1, J. (The long "startup period" is meant to eliminate dependence on the initial condition.) 3. For each k, run the casual search algorithm on the residuals ( k U ~) from a reduced form VAR of k Y ~ and record the graph. (In this paper, we use the SGS algorithm, although the PC algorithm or other algorithms could be used.)</p><p>4. For each possible edge between variables (elements of Y ) record the number of times it appears a) missing (no edge); b) undirected (⎯); c) directed from lower to a higher ordered variable(←); d) directed from a higher to a lower order variable (→); and e) bidirectional (↔).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C. Design of the Simulation Experiments</head><p>1. We evaluate four SVAR models with contemporaneous causal orders described in section 4 of the main text. Evaluations are made with respect to the reference graph as described in point 5 below.</p><p>2. We start with a set of artificially generated data constructed by Monte Carlo methods as follows:</p><p>a) A set of contemporaneous parameterizations is indexed p = 1, 2, . . . P; and, for each parameterization, a set of Monte Carlo realizations is indexed m = 1, 2, . . . M, so that there are PM total realizations. (For all models, P is set to 200; and, for Models 1 and 3, M is set to 200, yielding 40,000 realizations; while, for Models 2 and 4, M is set to 100, yielding 20,000 realizations.</p><p>b) The data for each Monte Carlo realization are generated recursively. For each realization, let j = 1, 2, . . . J, indicate time, start with the initial condition MC 0 Y = 0, and construct subsequent observations according to</p><formula xml:id="formula_13">(B.2) pmj p MC j pm p MC pmj E A AY A Y 1 0 ) 1 ( 1 0 - - - + = .</formula><p>where:</p><p>i) Each model includes 1 lag of each variable, and A is a fixed N × N matrix of coefficients on the lagged variables, for which all diagonal elements are set to 0.25 and all off-diagonal elements are set to 0.05.</p><p>ii) 0 pm A = [a pmgh ] is an N × N (g = 1, 2, . . . , N; h = 1, 2, . . . , N) matrix of contemporaneous coefficients with ones on the main diagonal, and zeroes placed to correspond to the causal orders for each model in point 1 above. (The number of bootstrap realizations for each Monte Carlo realization is set to K = 100, so that, for Models 1 and 3, the total number of bootstrap realizations is 4,000,000 (=PMK = 200 × 200 × 100) and, for Models 2 and 4, 2,000,000 (=PMK = 200 × 100 × 100). The relatively small number of bootstrap realizations per Monte Carlo realization is needed to keep the computing time manageable.) The results provide a measure of how closely the bootstrap conforms to the Monte Carlo in particular cases. 5. To assess outcomes in points 3 and 4 above, the graphs identified by the SGS algorithm applied to simulated data are compared edge by edge to the graphs that are used to generate the data (see point 1 and point 2 above). Because of Pearl's observational equivalence theorem (see section 2), an ideally functioning search algorithm working with infinite data will not be able to orient some edges.</p><p>Comparisons are not made to the true graph that generates the data, but to a reference graph that represents the equivalence class (that is, to the graph that leaves edges unoriented if, in the true graph, they can be reversed without changing the number or location of the unshielded colliders). Results are assessed according to success at the statistical identification of the skeleton and the unshielded colliders. There are three possible outcomes: i. correct: an edge or unshielded collider is identified as absent when it is absent in the reference graph or identified as present when it is present in the reference graph; ii. omitted: an edge or unshielded collider that is present in the reference graph is identified as absent; iii. committed: an edge or unshielded collider that is absent in the reference graph is identified as present.</p><p>Results are reported as rates taking the number of possible realizations of a particular outcome as the base. For example, in Model 2 (Figure <ref type="figure">5</ref>), there are six edges out of a total of fifteen possible between six variables. The base for computing the rate of omissions is, therefore, six per search. In contrast, the base for the rate of commissions is nine -that is, the number of possible edges that are in fact missing in the reference graph.  Net Direction = difference between edges directed low-to-high (→) and high-to-low (←), where higher variables are the more clockwise starting in the upper left corner (at C), as a percentage of the directed edges. Circled variables are found as unshielded colliders on paths, and with rates (percentage of replications) as indicated in boxed notes. Any unshielded collider found in fewer than 1 percent of replications is omitted. Data may differ from values computed from  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>unconditionally uncorrelated in the true graph. Step 3 eliminates edge 5 (X and Z are uncorrelated conditional on Y). Step 4 orients edges 2 and 3 toward Y (W and X are correlated conditional on Y -i.e., Y is an unshielded collider on WYX). Step 5 orients edge 6 towards Z. Step 6 orients edge 4 toward Z. The algorithm is able to recover the true graph. Not every true graph can be recovered uniquely. A graph and a probability distribution are faithful when the independence relationships in the graph stand in one-toone correspondence with those implied by the probability distribution. The skeleton of a graph is the pattern of its causal linkages ignoring their direction. The observational equivalence theorem (Pearl 2000, p. 19, Theorem 1.2.8) states that any probability distribution that can be faithfully represented by an acyclical graph, can equally well be represented by another acyclical graph with the same skeleton and the same unshielded colliders. A graph identical to panel A of Figure 1 except that edge 6 was reversed would not be observationally equivalent to panel A because it would add an unshielded collider "Bootstrap Methods for the SVAR" 28 March 2006 10 (Y on XYZ). A graph that reversed edge 4 would be observationally equivalent to the graph in panel A because it would have the same skeleton and neither add nor subtract unshielded colliders. While the graph with edge 4 reversed illustrates the observational equivalence theorem, Step 6 of the algorithm rules it out, since it possesses a cycle (W → Y → Z → W), which violates the antecedent of the observational equivalence theorem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Swanson and Granger's VAR used 8 lags of the logarithms of real per capita consumption expenditures (C), real per capita gross private domestic fixed investment (I), per capita real balances (M), and real per capita private gross domestic product (Y) for the period 1949:1-1990:2. Swanson and Granger's algorithm restricted attention to linear chains in which each variable was allowed at most one direct cause (e.g., A → B → C → D would be admissible, but A → B ← C → D would not). With this restriction their algorithm considered only measures of first-order (i.e., unconditional) independence, which they implemented using tests of correlation between two variables conditional on a third, ignoring unshielded colliders. They identified the skeleton of the graph as M ⎯ C⎯ I ⎯ Y. Appealing to the extra-statistical assumption that at least one of M, C, or I should cause Y in the current period, they oriented the edges as M → C→ I → Y.Demiralp and Hoover (2003, pp. 762-763)  applied the PC algorithm to similar data for the period 1949:1-2002:4 and identified the structure shown as the heavy black lines in Figure2. (Sources and construction of these data are described in Appendix A.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Swanson and Granger's causal chain are similar, while those for the SGS-selected order are quite distinct. In panel A, the impulse-response function of M for a shock to C for the SGS-selected order is positive at all horizons and globally increasing, while those for the other two orders are negative. While the impulse-responses in the other two panels do not display such a qualitative contrast, they are nonetheless quantitatively distinct. All three impulse-responses of Y to M in panel B show a similar pattern, but the impulse response corresponding to the order chosen by the SGS algorithm lies well below the other two, especially for the first half of the forecast period. The quantitative gap is even larger and shows less tendency to converge over time with the impulse responses of Y to a shock to Y. And where the impulse responses for both Swanson and Granger's and the Choleski order start positive and then turn negative, the impulse response for the order chosen by the SGS algorithm never becomes negative at all.The close similarity of impulse-response functions for the Choleski order and Swanson and Granger's causal chain is not too surprising as the causal chain (in contrast to the SGS-selected order) is an overidentifying restriction on that particular Choleski order. The SGS-selected order is, however, an overidentifying restriction of two other Choleski orders: M, Y, C, I and Y, M, C, I. The impulse-response functions for these two</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7</head><label>7</label><figDesc>Figure7shows that for Model 1, when signal-to-noise ratios are low, both the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 4 Model 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>investigated the PC algorithm using Monte Carlo methods.</figDesc><table><row><cell>Stage 2. Statistical Orientation of Edges</cell></row><row><cell>4. For each conditionally uncorrelated pair of variables (i.e., ones without a direct</cell></row><row><cell>edge) that are connected through a third variable, test whether they become</cell></row><row><cell>correlated conditional on that third variable. If so, the third variable is an</cell></row><row><cell>unshielded collider. Orient the edges as pointing into the unshielded collider.</cell></row><row><cell>Stage 3. Logical Orientation of Edges</cell></row><row><cell>5. If there are any pairs A and C that are not directly connected but are indirectly</cell></row><row><cell>The connected A → B ⎯ C, then orient the second edge toward C, so that the triple is</cell></row><row><cell>SGS algorithm proceeds in three stages:</cell></row><row><cell>Stage 1. Elimination of Edges</cell></row><row><cell>1. Start with a graph in which each variable is assumed to be connected by an</cell></row><row><cell>undirected causal edge.</cell></row><row><cell>2. Test for the unconditional correlation of each pair of variables, eliminating the</cell></row><row><cell>edge in the graph whenever the absence of correlation cannot be rejected.</cell></row><row><cell>3. Test for the correlation of each pair of variables conditional on a third variable,</cell></row><row><cell>again eliminating the edge if correlation is absent. Continue testing pairs</cell></row><row><cell>conditional on pairs, triples, quadruples, and so on until the graph is pared down</cell></row><row><cell>as far as the data permit. 4</cell></row></table><note><p>The SGS algorithm assumes that graphs are acylical (what VAR analysts typically refer to as "recursive") -that is, there are no loops in causal chains such that an effect feeds back onto a direct or indirect cause. Acyclicality rules out simultaneous equations.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>edges are present or absent and, if present, how they are oriented. Results are assessed by comparison to the known reference graph, as described in point 5 below. The resulting PM realizations in the current study, correspond to the Monte Carlo simulations reported in<ref type="bibr" target="#b9">Demiralp and Hoover (2003)</ref> for the PC algorithm. The results provide a practical measure of how well the SGS algorithm does in discovering the true causal order underlying the data.4. For each Monte Carlo realization run the bootstrap procedure described in AppendixB using m Y ( as the input; and, for each bootstrap realization (k), record: a. the ex ante t-statistics for each edge; b. whether edges are present or absent; c. if edges are present, how they are oriented; and d. the unshielded colliders. Results are assessed by comparison to the known graph (see point 1 above), as described in point 5 below.</figDesc><table><row><cell cols="12">oversampling in the range that produces average ex ante t-statistics</cell></row><row><cell cols="12">between 0 and 1. (See subpoint v below on the evaluation of ex ante t-</cell></row><row><cell cols="2">statistics.)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>iii) pmj E ~</cell><cell cols="11">= [E pmnj ] is an N-element column vector with each element drawn</cell></row><row><cell cols="12">randomly from an independent normal distributions with mean 0 and</cell></row><row><cell cols="2">variance 1.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="12">iv) To determine the ex ante t-statistics: 1. each model is simulated 1000</cell></row><row><cell cols="12">times according to subpoint i with randomly drawn contemporaneous</cell></row><row><cell cols="12">coefficients, estimated, and the coefficient values (β) and the</cell></row><row><cell cols="12">corresponding t-statistics recorded; 2. a regression equation is estimated t = ϕ + μβ + error is estimated; 3. in the simulation experiments, the ex</cell></row><row><cell cols="11">ante t-statistic for any coefficient is given as</cell><cell>t</cell><cell>=</cell><cell>β μ ϕ +</cell><cell>, where the hats</cell></row><row><cell cols="11">("^") indicate estimated or predicted values.</cell></row><row><cell cols="2">Define the pseudo-data set as</cell><cell cols="2">pm Y (</cell><cell>=</cell><cell>[</cell><cell>pmt Y (</cell><cell>]</cell><cell>=</cell><cell>[</cell><cell cols="2">MC pmi Y</cell><cell>]</cell><cell>, t = 1, 2, . . . 500, to be the</cell></row><row><cell cols="2">The non-zero elements of</cell><cell>A</cell><cell>pm</cell><cell>0</cell><cell cols="7">are drawn randomly from a range that</cell></row><row><cell cols="12">yields ex ante t-statistics between 0 and 10 (averaging over all edges), with</cell></row></table><note><p><p>last 500 of the J columns of recursive pseudo-observations, where J &gt;&gt; 500. That is, the observations for t = 1, 2, . . . 500 correspond to those for i = J -499, J -498, . . . J -1, J. (As with the bootstrap method in Appendix B, the long "startup period" is meant to eliminate dependence on the initial condition.) 3. For each Monte Carlo realization, run the SGS algorithm on the residuals from a reduced form VAR of pm Y ( and record: a. the ex ante t-statistics for each edge and b.</p>whether</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 Bootstrap Evaluation of the SGS-selected Causal Order for the King et al. Data Set SGS-selected Causal Order Edge Identification (percent of bootstrap realizations) Edge direction</head><label>1</label><figDesc>Notes: Entries in bold type correspond to the SGS-selected direction.See text (section 2) for a description of the SGS search algorithm and Appendix B for a description of the bootstrap procedure. See Appendix A for data definitions and sources.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>⎯</cell><cell>←</cell><cell>no edge</cell><cell>→</cell><cell>↔</cell></row><row><cell>C C C</cell><cell>→ ← ←</cell><cell>I M Y</cell><cell>28 22 32</cell><cell>23 65 67</cell><cell>16 13 0</cell><cell>33 0 1</cell><cell>0 0 0</cell></row><row><cell>I</cell><cell>no edge</cell><cell>M</cell><cell>0</cell><cell>6</cell><cell>94</cell><cell>0</cell><cell>0</cell></row><row><cell>I</cell><cell>←</cell><cell>Y</cell><cell>61</cell><cell>39</cell><cell>0</cell><cell>1</cell><cell>0</cell></row><row><cell>M</cell><cell>no edge</cell><cell>Y</cell><cell>0</cell><cell>0</cell><cell>100</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Table 1 due to rounding error.</figDesc><table><row><cell>MCY: 64</cell><cell>MIY: 6</cell></row><row><cell>ICM: 20</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>This and the next five paragraphs are based closely on<ref type="bibr" target="#b13">Hoover (2005)</ref>, pp. 71-74.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>Absence of conditional correlation is a necessary, but not sufficient, condition for statistical independence.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>This step distinguishes the SGS algorithm(Spirtes et al. 2000, pp. 82-83)  from the more commonly used PC algorithm<ref type="bibr" target="#b19">(Spirtes et al. 2000</ref>, pp. 84-85, Pearl 2000, pp. 49-51, Cooper 1999, p. 45, figure 22,  Demiralp and Hoover 2003, pp. 766-767). The PC algorithm tests independence between two variables that had been connected by an edge in the previous round conditional only on variables that were themselves adjacent to one of the two variables in the previous round. The SGS algorithm tests the pair of</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>This appendix is drawn verbatim from<ref type="bibr" target="#b9">Demiralp and Hoover (2003)</ref>, Appendix B.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_4"><p>August</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2005" xml:id="foot_5"><p>Demiralp, Hoover, and Perez    "Bootstrap Methods for the SVAR"</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. The Data 5</head><p>All the raw series, except M1, are from the U.S. National Income and Product Accounts and were downloaded from the Haver Analytics United States Economic Statistics database. Except where noted, they are seasonally adjusted, stated in billions of constant <ref type="bibr">1996 dollars, and cover 1947:1-2002:4</ref>. Haver codes are in bold type. Personal Consumption Expenditure = CH; Gross Private Domestic Fixed Investment = FH; M1 monetary aggregate (MN) for 1947:1-1958:4 = M1 monetary aggregate from Board of <ref type="bibr">Governors (1976)</ref>, Table <ref type="table">1</ref>.1, pp. 17-18, column 2 ("Money Stock: Total") × 0.   </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Modeling corn exports and exchange rates with directed graphs and statistical loss functions</title>
		<author>
			<persName><forename type="first">Derya</forename><forename type="middle">G</forename><surname>Akleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><forename type="middle">M</forename><surname>Bessler</surname></persName>
		</author>
		<author>
			<persName><surname>Burton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computation, Causation, and Discovery</title>
		<editor>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gregory</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</editor>
		<meeting><address><addrLine>Menlo Park; Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>CA and MIT Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="497" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Export-led Growth and the Japanese Economy: Evidence from VAR and Directed Acyclical Graphs</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Awokuse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Economics Letters</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="849" to="858" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Measuring Monetary Policy</title>
		<author>
			<persName><forename type="first">Ben</forename><forename type="middle">S</forename><surname>Bernanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illian</forename><surname>Mihov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="869" to="902" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Economic Development: Evidence from Directed Acyclical Graphs</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Bessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Loper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manchester School</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="457" to="476" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Money and prices: U.S. data 1869-1914 (a study with directed graphs)</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Bessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongpyo</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Economics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="427" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The Dynamic Effects of Aggregate Demand and Supply Disturbances</title>
		<author>
			<persName><forename type="first">Olivier</forename><forename type="middle">J</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Quah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="655" to="673" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Banking and Monetary Statistics: 1941-1970, Board of Governors of the Federal Reserve System</title>
		<imprint>
			<date type="published" when="1976">1976</date>
			<pubPlace>Washington, D.C</pubPlace>
		</imprint>
	</monogr>
	<note>Board of Governors of the Federal Reserve System</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An overview of the representation and discovery of causal relationships using Bayesian networks</title>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computation, Causation, and Discovery</title>
		<editor>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gregory</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</editor>
		<meeting><address><addrLine>Menlo Park; Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>CA and MIT Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="3" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The structure of monetary policy and transmission mechanism</title>
		<author>
			<persName><forename type="first">Selva</forename><surname>Demiralp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Department of Economics, University of California, Davis</orgName>
		</respStmt>
	</monogr>
	<note>unpublished Ph.D dissertation</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Searching for the Causal Structure of a Vector Autoregression</title>
		<author>
			<persName><forename type="first">Selva</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">D</forename><surname>Hoover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oxford Bulletin of Economics and Statistics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="745" to="767" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>supplement</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Integration and Causality in International Freight Markets: Modeling with Error Correction and Directed Acyclical Graphs</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Haigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Nomikos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Bessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Southern Economic Journal</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="162" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">D</forename><surname>Hoover</surname></persName>
		</author>
		<title level="m">Causality in Macroeconomics</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Some Causal Lessons from Macroeconomics</title>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">D</forename><surname>Hoover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="121" to="125" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automatic Inference of the Contemporaneous Causal Order of a System of Equations</title>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">D</forename><surname>Hoover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometric Theory</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="77" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Stochastic Trends and Economic Fluctuations</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">G</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">H</forename><surname>Plosser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">W</forename><surname>Stock</surname></persName>
		</author>
		<author>
			<persName><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="819" to="840" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Causality: models, reasoning, and inference: a review of Judea Pearl&apos;s Causality</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">F</forename><surname>Leroy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Methodology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="100" to="103" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<title level="m">Causality: Models, Reasoning, and Inference</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Richard</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
		<title level="m">Tetrad II: Tools for Causal Modeling: User&apos;s Manual</title>
		<meeting><address><addrLine>Mahwah, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A new approach to causality and economic growth</title>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">M</forename><surname>Sheffrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><surname>Triest</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>University of California, Davis</orgName>
		</respStmt>
	</monogr>
	<note>unpublished typescript</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Causation, Prediction, and Search, 2 nd edition</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Scheines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Impulse response functions based on a causal approach to residual orthogonalization in vector autoregressions</title>
		<author>
			<persName><forename type="first">Norman</forename><forename type="middle">R</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clive</forename><forename type="middle">W J</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="357" to="367" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The International Price Transmission in Stock Index Futures Markets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Bessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Economic Inquiry</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="370" to="386" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
