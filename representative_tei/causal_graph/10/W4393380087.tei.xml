<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Causal Structural Learning from Time Series: A Convex Optimization Approach</title>
				<funder ref="#_E7WKmnS #_ERUCxbP">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_X8E35NV #_XxGFraw #_YFcQ9Zu">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-04-15">15 Apr 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Song</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Systems Engineering</orgName>
								<orgName type="institution" key="instit1">Stewart School of Industrial</orgName>
								<orgName type="institution" key="instit2">Georgia Institute of Technology</orgName>
								<address>
									<postCode>30332</postCode>
									<settlement>Atlanta</settlement>
									<region>Georgia</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yao</forename><surname>Xie</surname></persName>
							<email>&lt;yao.xie@isye.gatech.edu&gt;.</email>
							<affiliation key="aff0">
								<orgName type="department">Systems Engineering</orgName>
								<orgName type="institution" key="instit1">Stewart School of Industrial</orgName>
								<orgName type="institution" key="instit2">Georgia Institute of Technology</orgName>
								<address>
									<postCode>30332</postCode>
									<settlement>Atlanta</settlement>
									<region>Georgia</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Systems Engineering</orgName>
								<orgName type="institution" key="instit1">Stewart School of Industrial</orgName>
								<orgName type="institution" key="instit2">Georgia Institute of Technology</orgName>
								<address>
									<postCode>30332</postCode>
									<settlement>Atlanta</settlement>
									<region>Georgia</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">H</forename><surname>Milton</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Systems Engineering</orgName>
								<orgName type="institution" key="instit1">Stewart School of Industrial</orgName>
								<orgName type="institution" key="instit2">Georgia Institute of Technology</orgName>
								<address>
									<postCode>30332</postCode>
									<settlement>Atlanta</settlement>
									<region>Georgia</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Causal Structural Learning from Time Series: A Convex Optimization Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-04-15">15 Apr 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2301.11336v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Structural learning, which aims to learn directed acyclic graphs (DAGs) from observational data, is foundational to causal reasoning and scientific discovery. Recent advancements formulate structural learning into a continuous optimization problem; however, DAG learning remains a highly non-convex problem, and there has not been much work on leveraging well-developed convex optimization techniques for causal structural learning. We fill this gap by proposing a data-adaptive linear approach for causal structural learning from time series data, which can be conveniently cast into a convex optimization problem using a recently developed monotone operator variational inequality (VI) formulation. Furthermore, we establish non-asymptotic recovery guarantee of the VI-based approach and show the superior performance of our proposed method on structure recovery over existing methods via extensive numerical experiments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Causal discovery, which aims to capture the interactions among events of interest using directed acyclic graphs (or Bayesian networks), is a crucial part of scientific discovery <ref type="bibr">[Pearl, 2009]</ref> and has drawn much attention recently. With advanced data acquisition techniques, we usually observe time series data in many modern applications, posing both opportunities to learn a dynamic Bayesian network and challenges in finding an efficient approach for learning a directed acyclic graph (DAG) from serially correlated data <ref type="bibr">[Pamfil et al., 2020]</ref>.</p><p>However, learning DAGs from observational data, i.e., the structural learning problem, is NP-hard due to the combinatorial acyclicity constraint <ref type="bibr" target="#b0">[Chickering et al., 2004]</ref>, motivating many research efforts in finding efficient approaches for learning DAGs. Recently, Zheng et al.</p><p>[2018] proposed a continuous differentiable characterization of DAG, which formulates the DAG learning problem into a constrained continuous optimization problem; they applied augmented Lagrangian method to transfer constraint into penalty and achieved efficient DAG learning. Later on, <ref type="bibr" target="#b11">Ng et al. [2020]</ref> proposed to treat the non-convex DAG characterization as penalty and proved asymptotic recovery guarantee for linear Gaussian models.</p><p>On the other hand, recently much work has been done on causal discovery from time series; notable contributions include Fourier-transform based time series approach for continuoustime Hawkes process models <ref type="bibr" target="#b1">[Etesami et al., 2016]</ref>. However, existing works have been mostly focusing on Granger causality, which has been deemed less useful due to the lack of DAG structure in the estimated causal graph. To fix this issue, <ref type="bibr">Pamfil et al. [2020]</ref> leveraged the continuous DAG characterization as the constraint in structural vector autoregressive models for Granger causal discovery and solved the constrained optimization problem via augmented Lagrangian method as <ref type="bibr">Zheng et al. [2018]</ref> did. Despite those recent advancements, DAG learning remains a non-convex problem. Thus, how to leverage the well-developed convex optimization techniques to learn a DAG largely remains an open problem.</p><p>In this work, we present a generalized linear model (GLM) based approach for causal discovery from time series data, while seeking the DAG structure via a novel data-adaptive linear regularizer. Furthermore, we cast the DAG structural learning problem into a convex optimization program by a monotone operator variational inequality (VI) formulation. The convex formulation enables us to establish non-asymptotic performance guarantee for a wide range of non-linear link functions via recent advances in VI-based signal recovery <ref type="bibr">[Juditsky and</ref><ref type="bibr">Nemirovski, 2019, Juditsky et al., 2020</ref>]. We provide extensive numerical experiments to show the competitive performance of the proposed method and observe that our approach achieves more performance gain in the presence of limited data (see Figure <ref type="figure">1</ref> for illustration).</p><p>Literature. Efficient structural learning of a DAG is the heart of scientific discovery in many fields, e.g., biology <ref type="bibr" target="#b13">[Sachs et al., 2005]</ref>, genetics <ref type="bibr" target="#b19">[Zhang et al., 2013]</ref>, and so on. In particular, in causal reasoning, structural causal model based causal discovery methods oftentimes boil down to maximizing a score function within the DAG family <ref type="bibr" target="#b3">[Glymour et al., 2019]</ref>. There is rich literature in DAG learning: <ref type="bibr" target="#b18">Yuan et al. [2019]</ref> proposed to use indicator function to enumerate and eliminate all possible directed cycles; to efficiently solve such problem, they used truncate 1 -function as a continuous surrogate of indicator function and proposed to use alternating direction method of multipliers to numerically solve it. <ref type="bibr" target="#b10">Manzour et al. [2021]</ref> transferred indicators into binary variables and leveraged mixed integer programming to solve it. There are also dynamic programming based approaches, e.g., <ref type="bibr" target="#b9">Loh and Bühlmann [2014]</ref>, but they are not scalable in high dimensions unless coupled sparse structure, e.g., A * Lasso <ref type="bibr" target="#b16">[Xiang and Kim, 2013]</ref>. Another line of research follows the continuous DAG characterization by <ref type="bibr">Zheng et al. [2018]</ref>; in addition to aforementioned developments, notable extensions along this direction includes a discrete backpropagation method, exploration of low-rank structure <ref type="bibr" target="#b2">[Fang et al., 2020]</ref> and neural DAG learning <ref type="bibr" target="#b17">[Yu et al., 2019</ref><ref type="bibr" target="#b6">, Ke et al., 2019</ref><ref type="bibr" target="#b8">, Lachapelle et al., 2019]</ref>. We refer readers to <ref type="bibr" target="#b14">Scanagatta et al. [2019]</ref>, <ref type="bibr" target="#b7">Kitson et al. [2021]</ref>, Vowels et al. <ref type="bibr">[2022]</ref> for systematic surveys on structural learning and causal discovery.</p><p>Figure <ref type="figure">1</ref>: Visualization of estimated graphs, where the size of the node is proportional to the background intensity and the width of the edge is proportional to the exciting coefficient magnitude. We consider a graph with d 1 = 10 nodes and time horizon T = 500; the data is generated via our GLM with exponential link. We compare various types of regularization (specified on top of each panel). The Structural Hamming Distances between the estimated graph and the ground truth are 39 (no regularization), 7 (proposed), 21 <ref type="bibr">(DAG regularization [Zheng et al., 2018</ref><ref type="bibr" target="#b11">, Ng et al., 2020]</ref>), 25 ( 1 regularization) and 12 (adaptive 1 regularization <ref type="bibr">[Zou, 2006]</ref>), respectively. Our proposed data-adaptive linear regularization achieves the best graph structure recovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem set-up</head><p>Consider observing d 1 binary time series over time horizon T , among which there exist lagged mutual-exciting effects and such effects have a finite memory depth τ ≥ 1. To be precise, consider we are given history {y (i) t : t = 1 -τ . . . , 0} and observe {y (i) t : t = 1 . . . , T } for i ∈ {1, . . . , d 1 }, where y (i) t = 1 means type-i event occurs at time t and zero otherwise. In the following, we will refer to those events as node variables and our goal is to recover the mutual-excitation graph over those d 1 nodes.</p><p>We adopt the discrete-time Bernoulli process <ref type="bibr" target="#b4">[Juditsky et al., 2020]</ref> and model the probability of i-th event's occurrence at time step t ∈ {1, . . . , T } via the following generalized linear model:</p><formula xml:id="formula_0">P y (i) t = 1|H t-1 = g ν i + d 1 j=1 τ k=1 α ijk y (j) t-k ,<label>(1)</label></formula><p>where H t denotes all history observations up to time t. Here, ν i ≥ 0 reflects the deterministic background intensity, and α ijk ≥ 0 represents the magnitude of triggering effect from the j-th node variable to the i-th node variable at time lag k. Link function g : R → [0, 1] can be non-linear, such as sigmoid link function g(x) = 1/(1 + e -x ) on domain x ∈ R and g(x) = 1 -e -x on domain x ∈ [0, ∞); also, it can be linear g(x) = x on domain x ∈ [0, 1],</p><p>which reduces our GLM to the simple linear model.</p><p>For brevity, we use w t-τ :t-1 to denote the observations from time t -τ to t -1 and θ i ∈ R d</p><p>(where d = 1 + τ d 1 denotes the dimensionality) to denote the problem parameter:</p><formula xml:id="formula_1">w t-τ :t-1 = 1, y<label>(1)</label></formula><p>t-1 , . . . , y</p><p>t-τ , . . . , y</p><formula xml:id="formula_3">(d 1 )</formula><p>t-1 , . . . , y</p><formula xml:id="formula_4">(d 1 ) t-τ T , θ i = (ν i , α i11 , . . . , α i1τ , . . . , α id 1 1 , . . . , α id 1 τ ) T ,</formula><p>where superscript T denotes vector/matrix transpose. Parameter θ i summarizes the influence from all nodes to node i. Now, we can rewrite (1) into the following compact form:</p><formula xml:id="formula_5">P y (i) t = 1 w t-τ :t-1 = g w T t-τ :t-1 θ i , θ i ∈ Θ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_6">Θ ⊂ R d + = [0, ∞) d</formula><p>is the feasible region and depends on the link function. For example, when g is linear function, i.e., g(x) = x, the feasible region is</p><formula xml:id="formula_7">Θ = {θ ∈ R d + : 0 ≤ w T t-τ :t-1 θ ≤ 1, t = 1, . . . , T }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Decoupled estimation with Variational Inequality</head><p>In this section, we introduce a recently developed technique <ref type="bibr">[Juditsky and</ref><ref type="bibr">Nemirovski, 2019, Juditsky et al., 2020]</ref> to estimate the parameters of the GLM by solving stochastic monotone variational inequality. For i ∈ {1, . . . , d 1 }. we assume the feasible region Θ is convex and compact and use the weak solution to the following variational inequality as the estimator θi</p><p>(which we will refer to as VI estimator):</p><p>find θi ∈ Θ :</p><formula xml:id="formula_8">F (i) T (θ i ), θ i -θi ≥ 0, ∀θ i ∈ Θ, VI[F (i) T , Θ]</formula><p>where • represents the standard inner product in Euclidean space and</p><formula xml:id="formula_9">F (i)</formula><p>T (θ i ) is the empirical vector field and defined as:</p><formula xml:id="formula_10">F (i) T (θ i ) = 1 T T t=1 w t-τ :t-1 g w T t-τ :t-1 θ i -y (i) t .<label>(3)</label></formula><p>As we can see, the statistical inference for each node can be decoupled and therefore we can perform the computation in parallel and simplify the analysis.</p><p>The intuition behind this method is straightforward. Let us consider the global counterpart of the above vector field, whose root is the unknown ground truth θ i ,</p><formula xml:id="formula_11">F (i) (θ i ) = E (w,y (i) ) w g (w T θ i ) -y (i) = E (w,y (i) ) [w (g (w T θ i ) -g (w T θ i ))] .</formula><p>Although we cannot access this global counterpart, by solving the empirical one VI[F (i)</p><p>T , Θ] we could approximate the ground truth very well. We will show how well this approximation can be by generalizing the parameter recovery guarantee in <ref type="bibr" target="#b4">Juditsky et al. [2020]</ref> to handle general non-linear link functions in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Method</head><p>As illustrated in Figure <ref type="figure">1</ref>, it is difficult to recover the true graph structure in the presence of limited data. However, with prior knowledge on the potential graph structure, such as the directed acyclic graph structure, we can use regularization to encourage such structure and improve the recovery accuracy. Here, we will present our proposed data-adaptive linear regularization to encourage the DAG structure and show how to leverage such constraint (or rather, penalty) in the VI estimator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data-adaptive linear cycle elimination regularization</head><p>Consider the graphs induced by the estimated adjacency matrices</p><formula xml:id="formula_12">Â = (α ij ) ∈ R d 1 ×d 1 , ∈ {1, . . . , τ }, using estimator VI[F (i) T , Θ].</formula><p>To return a DAG, cycles in those estimated graphs are undesirable and should be removed.</p><p>First, let us formally define cycles: for positive integer L ≥ 2, if there exist ∈ {1, . . . , τ } and mutually different indices i 1 , . . . , i L ∈ {1, . . . , d 1 } such that</p><formula xml:id="formula_13">αi 1 i L &gt; 0, αi k+1 i k &gt; 0, k ∈ {1, . . . , L -1},</formula><p>then we say there exists a length-L (directed) cycle in the directed graphs induced by Â 's. In particular, for L = 1 case, we say there is a length-1 cycle (or lagged self-exciting component)</p><formula xml:id="formula_14">if there exist ∈ {1, . . . , τ } and index i ∈ {1, . . . , d 1 } such that αii &gt; 0.</formula><p>To remove those cycles, we consider all possible length-1, 2 and 3 cycles in those estimated graphs, whose indices are denoted as follows: for all ∈ {1, . . . , τ },</p><formula xml:id="formula_15">I 1, = i : αii &gt; 0 , I 2, = (i, j) : i = j, αij , αji &gt; 0 , I 3, = (i, j, k) : i, j, k mutually different, αij , αjk , αki &gt; 0 .</formula><p>Intuitively, in each length-2 (or 3) cycle of those estimated graphs, the edge with the least weight could be caused by noisy observation, meaning that we should remove such edge to eliminate the corresponding cycle. To do so, we impose the following data-adaptive linear cycle elimination constraints, aiming to shrink the weight of those "least important edges" in the cycle: for all ∈ {1, . . . , τ },</p><formula xml:id="formula_16">α ij + α ji ≤ δ 2, (i, j), (i, j) ∈ I 2, , α ij + α jk + α ki ≤ δ 3, (i, j, k), (i, j, k) ∈ I 3, ,<label>(4)</label></formula><p>where the adaptive constraint strength parameters are</p><formula xml:id="formula_17">δ 2, (i, j) = αij + αji -min{α ij , αji }, δ 3, (i, j, k) = αij + αjk + αki -min{α ij , αjk , αki }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Joint VI estimator with penalty</head><p>Different from the decoupled learning approach in Section 2.2, parameters θ 1 , . . . , θ d 1 should be estimated jointly in order to account for the desired DAG structure. We concatenate the parameter and response vectors into matrices as follows:</p><formula xml:id="formula_18">θ = (θ 1 , . . . , θ d 1 ) ∈ R d×d 1 , Y = (Y (1) 1:T , . . . , Y (d 1 ) 1:T ) ∈ R T ×d 1 ,</formula><p>where</p><formula xml:id="formula_19">Y (i) 1:T = (y (i) 1 , . . . , y (i) T ) T .</formula><p>The feasible region of the concatenated parameter Θ is then defined as follows:</p><formula xml:id="formula_20">Θ = {θ = (θ 1 , . . . , θ d 1 ) : θ i ∈ Θ, i = 1, . . . , d 1 }.</formula><p>One natural idea to incorporate the data-adaptive linear constraints ( <ref type="formula" target="#formula_16">4</ref>) is to add them into the feasible region Θ, which will not change the convexity of this region. However, as we typically treat the empirical vector field as the gradient filed and perform projected gradient descent (PGD) to numerically solve for the VI estimator in practice <ref type="bibr" target="#b5">[Juditsky and Nemirovski, 2019]</ref>, adding more constraints to feasible region will make the projection harder to implement; one can see a special case on how to use PGD to solve for VI estimator in Appendix B.</p><p>Alternatively, we propose to transfer those constraints into penalty and add the derivative of the penalty term to the vector field. To be precise, we propose an data-adaptive linear penalized VI estimator, which is the weak solution to the following Variational Inequality:</p><formula xml:id="formula_21">find θ ∈ Θ : vec(F AL T (θ)), vec(θ -θ) ≥ 0, ∀θ ∈ Θ,</formula><p>where vec(A) is the vector of columns of A stacked one under the other. The data-adaptive linear penalized vector filed F AL T (θ) is defined as follows:</p><formula xml:id="formula_22">F AL T (θ) =F T (θ) + λ τ =1 i∈I 1, e f i, ,d e T i,d 1 αii + i ∈I 1, e f i, ,d e T i,d 1 Λ (5) + (i,j)∈I 2, e f j, ,d e T i,d 1 + e f i, ,d e T j,d 1 δ 2, (i, j) + (i,j,k)∈I 3, e f j, ,d e T i,d 1 + e f k, ,d e T j,d 1 + e f i, ,d e T k,d 1 δ 3, (i, j, k) ,</formula><p>where the "concatenated empirical vector field" F T (θ) is</p><formula xml:id="formula_23">F T (θ) = (F<label>(1)</label></formula><p>T (θ 1 ), . . . , F</p><formula xml:id="formula_24">(d 1 ) T (θ d 1 )) ∈ R d×d 1 ,<label>(6)</label></formula><p>and the empirical vector field</p><formula xml:id="formula_25">F (i) T (θ i ) is defined in (3).</formula><p>We denote e i,d ∈ R d to be the standard basis vector with its i-th element being one and define f j, = 1 + (j -1)τ + , which gives us</p><formula xml:id="formula_26">e T f j, ,d θe i,d 1 = α ij , ∇ θ (e T f j, ,d θe i,d 1 ) = e f j, ,d e T i,d 1 .</formula><p>Remark 1 (Interpretation of the penalized vector filed). In the above penalized vector filed, the penalties at the end of the first line and the beginning of the second are very similar to adaptive Lasso <ref type="bibr">[Zou, 2006]</ref>, aiming to remove all lagged self-exiting components.</p><p>Intuitively, the smaller the adaptive constraint strength parameters are, the stronger penalties should be applied, which is why those adaptive constraint strength parameters appear in the denominators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Selection of hyperparameter</head><p>Hyperparameters λ and Λ are tunable and control the penalty strength. In practice, hyperparameter Λ is usually set to be a small number, such as 10 -3 , to ensure there will not exist self-exciting components, whereas λ is selected based on the continuous DAG characterization <ref type="bibr">[Zheng et al., 2018]</ref>. To be precise, let us consider the τ = 1 special case in the illustrative example in Figure <ref type="figure">1</ref>, and use A = (α ij ) to denote A 1 = (α ij1 ) for brevity.</p><p>The DAG characterization of a graph induced by adjacency matrix A is:</p><formula xml:id="formula_27">h(A) = tr(e A ) -d,<label>(7)</label></formula><p>where tr(e A ) is the trace of matrix exponential of A. For A ∈ R d 1 ×d 1 + , we have h(A) ≥ 0 and h(A) = 0 if and only if the directed graph induced by adjacency matrix A is a DAG.</p><p>Therefore, h(A) can measure the "DAG-ness" of A. We study how the performances vary with respect to (w.r.t.) hyperparameter λ in Figure <ref type="figure">2</ref>; the performance evaluation metrics are: (i) matrix F -norm of the mutual-exciting matrix estimation error (A err.), (ii) the 2 norm of the background intensity estimation error (ν err.), (iii) "DAG-ness" of estimated adjacency matrix h(A), and (iv) Structural Hamming Distance between the estimated adjacency matrix and the ground truth.</p><p>From Figure <ref type="figure">2</ref>, we can observe that the λ which minimizes the A err. (marked with a dot) typically does not give the best structural recovery (i.e., the smallest SHD); A err. cannot be used to select hyperparameter anyways since its calculation requires knowledge on the ground truth. Fortunately, we observe that the SHD converges (to its near optimal value) almost the same time when the "DAG-ness" measure h(A) converges to zero. Therefore, we propose to select λ as the smallest one which satisfies that h(A) ≤ thres., where thres. is again user-specified. Later in our numerical experiments, we will show how hyperparameter thres. controls the balance between structural recovery (SHD) and weight recovery (A err.).</p><p>Figure <ref type="figure">2</ref>: Illustration of the hyperparameter selection. We plot the trajectories of four performance metrics w.r.t. hyperparameter λ for the example in Figure <ref type="figure">1</ref>. In our numerical simulation, λ is selected to be the smallest one which satisfies h(A) ≤ 10 -8 . The selected λ is marked with a star; in addition, we mark the λ which minimizes A err. with a dot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Theoretical Analysis</head><p>Here, we extend the non-asymptotic recovery guarantee of VI[F</p><p>T , Θ] for linear link function case in <ref type="bibr" target="#b4">Juditsky et al. [2020]</ref> to general non-linear link function case by imposing the following assumption:</p><p>Assumption 1. The link function g(•) is continuous and monotone, and the vector field</p><formula xml:id="formula_29">G(θ) = E w [wg(w T θ)</formula><p>] is well defined (and therefore monotone along with g). Moreover, g is differentiable and has uniformly bounded first order derivative</p><formula xml:id="formula_30">m g ≤ |g | ≤ M g for 0 &lt; m g ≤ M g .</formula><p>The non-asymptotic upper bound on estimation error θi -θ i 2 , where θ i is the unknown ground truth, is given by: Theorem 1. Under Assumption 1, for i ∈ {1, . . . , d 1 } and any ε ∈ (0, 1), with probability at least 1 -ε, the 2 estimation error of VI[F (i) T , Θ] can be upper bounded as follows:</p><formula xml:id="formula_31">θi -θ i 2 ≤ 1 m g λ 1 d log(2d/ε) T ,</formula><p>where λ 1 is the smallest eigenvalue of W 1:T = T t=1 w t-τ :t-1 w T t-τ :t-1 /T .</p><p>As pointed out in <ref type="bibr" target="#b4">Juditsky et al. [2020]</ref>, W 1:T ∈ R d×d will be full rank when T is sufficiently large, i.e., with high probability, λ 1 will be a positive constant. The complete proof of the above theorem can be found in Appendix A. One pitfall of the theoretical analysis is the lack of guarantee for the proposed data-adaptive linear regularizer and we leave this part for future discussion. In the following, we will use numerical experiments to show the good performance of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Numerical Experiments</head><p>In this section, we provide more numerical experiments to show the effectiveness of our proposed method. We will 1) show its competitive performance under various settings and 2) study the effect regularization strength hyperparameter. In our numerical simulation, we consider τ = 1 case for simplicity and choose SHD (for structural recovery) and A err. (for weight recovery) as the primary performance metrics. We report the mean and standard deviation of those metrics over 200 independent trials. Complete details, such as random DAG generation, can be found in Appendix C.</p><p>Let us begin with presenting benchmark methods. The idea of transferring constraint into penalty by adding the penalty's derivative to the vector filed opens up possibilities to consider various type of DAG-inducing penalties when using the VI estimator, e.g., the continuous DAG penalty Zheng et al. <ref type="bibr">[2018]</ref> and the adaptive Lasso Zou <ref type="bibr">[2006]</ref>. As mentioned earlier, we use A = (α ij ) to denote A 1 = (α ij1 ) for brevity; in addition, we denote J = (0</p><formula xml:id="formula_32">d 1 , I d 1 ) ∈ R d 1 ×d</formula><p>such that we have Jθ = A T .</p><p>Continuous DAG regularization. The DAG characterization (7) has the following closed-from derivative:</p><formula xml:id="formula_33">∇h(A) = e A T .</formula><p>Inspired by <ref type="bibr" target="#b11">Ng et al. [2020]</ref> who treated the DAG characterization directly as a penalty, we take advantage of the differentiability of the DAG penalty and add its derivative to the concatenated field F T (θ) (6), which will later be treated as the gradient field when we use PGD to solve for the estimator. More precisely, the DAG-penalized vector field F DAG T (•) is defined as follows:</p><formula xml:id="formula_34">F DAG T (θ) = F T (θ) + λJ T ∇h(Jθ) = F T (θ) + λJ T e A .</formula><p>1 regularization. We adopt the 1 penalty as another benchmark method, which will encourage a sparse structure on the adjacency matrix A and in turn eliminates cycles. To be precise, the 1 penalized vector filed is defined as follows:</p><formula xml:id="formula_35">F 1 T (θ) = F T (θ) + λJ T ∇(|Jθ| 1 ),<label>(8)</label></formula><p>where | • | 1 is the summation of all entries' absolute values.</p><p>Adaptive Lasso. As a variant of 1 regularization, adaptive 1 regularization, or adaptive Lasso Zou <ref type="bibr">[2006]</ref>, replaces λ|α ij | with λ αij |α ij | in (8). In addition, for αij = 0 case, we use a simple remedy by adding penalty term λ Λ |α ij | as in ( <ref type="formula">5</ref>) to restrict α ij to be zero. As shown in Figure <ref type="figure">1</ref>, our proposed data-adaptive linear approach has superior performance compared with the aforementioned DAG-inducing penalties. We will give more numerical evidence to support this in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment 1</head><p>First, we show the superior performance of our proposed method under settings (d 1 , T ) ∈ {(10, 500), (20, 1000), (300, 1500)}; results are reported in Figure <ref type="figure" target="#fig_0">3</ref>. We observe that our proposed method achieves the best structural recovery among all methods, especially in higher dimensions. Besides, 1 regularization does well in weight recovery but poorly in structural recovery. As a comparison, our proposed method achieves comparable weight recovery accuracy with 1 regularization but much better structural recovery accuracy. On the contrary, DAG regularization is completely dominated by our proposed method, potential due to the non-convexity incurred by the DAG characterization (7); adaptive 1 regularization achieves improved structural recovery accuracy compared with 1 regularization, but is again dominated by our proposed method in most cases. As a sanity check, we observe the A err.'s are all on the same scale for different dimension cases -this is because we normalize each row of A to sum to one to make sure it stays within the feasible region for linear link function case. independent trials for various types of regularization. Hyperparameter λ is selected to be the smallest one which satisfies h(A) ≤ 10 -4 . For each regularization, the closer it is to the origin, the better it is. We can observe that our proposed data-adaptive linear regularization performs the best (especially in higher dimensional case).</p><p>For completeness, we also report the ν err. and the "DAG-ness" measure h(A) in Table <ref type="table">1</ref> in Appendix C. Those results do not only further validate our aforementioned observations, but also show 1 regularization does the best in returning a DAG (even better than DAG regularization) but cannot return an accurate graph structure. This agrees with our illustration in Figure <ref type="figure">1</ref> -it does very well in encouraging sparse structure, but may shrink some important edges' weights to zeros.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiment 2</head><p>We now study the effect of the hyperparameter thres. introduced in Section 3.2. We plot the SHD and A err. in Figure <ref type="figure">4</ref> for the exponential link function case; for completeness, we report the result for linear link function in Figure <ref type="figure" target="#fig_2">5</ref> in Appendix C. From both figures, we can observe that: (i) On one hand, smaller thres. does give better SHD. (ii) On the other hand, A err. exhibits a U-shape property w.r.t. thres., which agrees with the U-shape curves for both A err. and ν err. w.r.t. λ in Figure <ref type="figure">2</ref> and suggests that there could exist one optimal hyperparameter in outputting the smallest A err.; however, it is an open problem on how to select it to minimize A err. -one possible approach is through the norm of empirical vector field, since it is treated as the gradient field in PGD. Nevertheless, we mainly focus on the structural recovery (i.e., SHD), and it is safe to choose a sufficient small thres. (e.g., thres. = 10 -4 ) in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we go beyond the continuous but non-convex optimization approach for structural learning Zheng et al. <ref type="bibr">[2018]</ref> and formulate the DAG learning problem as a general convex optimization problem. Our theoretical analysis for the VI estimator extends the recovery guarantee in <ref type="bibr" target="#b4">Juditsky et al. [2020]</ref> to the general non-linear monotone ink function cases and our numerical experiments show our method's superior performance over existing methods in structural learning, opening up possibility for future work to adopt this method in a wide range of applications.</p><p>Figure <ref type="figure">4</ref>: Effect of hyperparameter. We consider the VI estimator with exponential link function. Regularization strength hyperparameter λ is selected to be the smallest one which satisfies that h(A) is smaller than a given threshold (thres.). We plot the mean (dot) and standard deviation (error bar) of A err. and SHD over 200 independent trials for different choices of this threshold. We can observe that smaller thres. typically leads to better SHD. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional Technical Details</head><p>We begin with defining an auxiliary vector field</p><formula xml:id="formula_36">F (i) T (θ i ) = 1 T T t=1 w t-τ :t-1 (g(w T t-τ :t-1 θ i ) -g(w T t-τ :t-1 θ i )),</formula><p>where θ i is the unknown ground truth. This vector field has a nice property that its unique root/weak solution to corresponding VI is θ i , whereas the VI estimator θi is the root of</p><formula xml:id="formula_37">F (i)</formula><p>T (θ i ). Next, we bound the difference between θi and θ i by bounding the difference between the empirical vector field</p><formula xml:id="formula_38">F (i)</formula><p>T (θ i ) and the auxiliary vector field</p><formula xml:id="formula_39">F (i) T (θ i ), i.e.,</formula><formula xml:id="formula_40">∆ (i) = F (i) T (θ i ) - F (i) T (θ i ) = F (i) T (θ i ).</formula><p>Proposition 1. Under Assumption 1, for any ε ∈ (0, 1), with probability at least 1 -ε, for i ∈ {1, . . . , d 1 }, ∆ (i) can be bounded as follows:</p><formula xml:id="formula_41">∆ (i) ∞ ≤ log(2d/ε)/T .<label>(9)</label></formula><p>Moreover, this implies</p><formula xml:id="formula_42">∆ (i) 2 ≤ N log(2d/ε)/T .<label>(10)</label></formula><p>Proof. Denote random vector</p><formula xml:id="formula_43">ξ t = w t-τ :t-1 g w T t-τ :t-1 θ i -y (i) t .</formula><p>We can re-write</p><formula xml:id="formula_44">∆ (i) = T t=1 ξ t /T. Define σ-field F t = σ(W t ), and F 0 ⊂ F 1 ⊂ • • • F T form a filtration. We can show E[ξ t |F t-1 ] = 0, Var(ξ t |F t-1 ) = g w T t-τ :t-1 θ i 1 -g w T t-τ :t-1 θ i ≤ 1/4.</formula><p>This means ξ t , t ∈ {1, . . . , T }, is a Martingale Difference Sequence. Moreover, its infinity norm is upper bounded by one almost surly since it only consists of binary elements. Therefore, Azuma's inequality gives us:</p><formula xml:id="formula_45">P |∆ (i) k | &gt; u ≤ 2 exp - T u 2 2 , k = 1, . . . , d, ∀ u &gt; 0,</formula><p>where</p><formula xml:id="formula_46">∆ (i)</formula><p>k is the k-th entry of vector ∆ (i) . By union bound,</p><formula xml:id="formula_47">P |∆ (i) k | &gt; u, k = 1, . . . , d ≤ 2d exp - T u 2 2 , ∀ u &gt; 0.</formula><p>By setting the RHS of above inequality to ε and solving for u, we prove (9). Besides, since ∆ 2 ≤ √ d ∆ ∞ holds for any vector ∆ ∈ R d , we can easily prove (10) using ( <ref type="formula" target="#formula_41">9</ref>).</p><p>The proof of Proposition 1 leverages the concentration property of martingales. By this proposition, we can now prove the non-asymptotic estimation error bound as follows:</p><p>Proof of Theorem 1. Under Assumption 1, the vector field</p><formula xml:id="formula_48">F (i) T (θ i ) is monotone modulus m g λ 1 ,</formula><p>where λ 1 is the smallest eigenvalue of W 1:T = T t=1 w t-τ :t-1 w T t-τ :t-1 /T . This can be proved as follows:</p><formula xml:id="formula_49">F (i) T (θ) -F (i) T (θ ) T (θ -θ ) = 1 T T t=1 w T t-τ :t-1 (θ -θ ) g w T t-τ :t-1 θ -g w T t-τ :t-1 θ ≥ m g 1 T T t=1 w T t-τ :t-1 (θ -θ ) 2 2 = m g (θ -θ ) T 1 T T t=1 w t-τ :t-1 w T t-τ :t-1 (θ -θ ) ≥ m g λ 1 θ -θ 2 2 .</formula><p>In particular, we have:</p><formula xml:id="formula_50">F (i) T ( θi ) -F (i) T (θ i ) T ( θi -θ i ) ≥ m g λ 1 θi -θ i 2 2 .</formula><p>Notice that our weak solution θi is also a strong solution to the VI since the empirical vector field is continuous, which gives us</p><formula xml:id="formula_51">F (i) T ( θi ) T ( θi -θ i ) ≤ 0.</formula><p>By triangle inequality, we also have</p><formula xml:id="formula_52">-F (i) T (θ i ) T ( θi -θ i ) = -∆ T i ( θi -θ i ) ≤ ∆ i 2 θi -θ i 2 .</formula><p>Together with (10) in Proposition 1, we complete the proof.</p><p>Identifiablility of our proposed estimator. In addition, we can show the uniqueness, or rather, the identifiablility of the VI estimator VI[F (i) T , Θ], which comes from the nice property of the underlying vector field. To be precise, in the proof of the above theorem, we have shown the vector field F (i) T (θ i ) is monotone modulus m g λ 1 under Assumption 1. Then, the following lemma tells us that our proposed estimator is unique:</p><p>Lemma 1 (Lemma 3.1 <ref type="bibr" target="#b5">Juditsky and Nemirovski [2019]</ref>). Let Θ be a convex compact set and H be a monotone vector field on Θ with monotonicity modulus κ &gt; 0, i.e.,</p><formula xml:id="formula_53">∀ z, z ∈ Θ, [H(z) -H(z )] T (z -z ) ≥ κ z -z 2 2 .</formula><p>Then, the weak solution z to VI[H, Θ] exists and is unique. It satisfies:</p><formula xml:id="formula_54">H(z) T (z -z) ≥ κ z -z 2 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B A Special Example</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Decoupled estimation</head><p>We consider a special case where g(x) = x. To make sure the model (2) indeed returns a meaningful probability, we require the parameter θ i to take value in Θ = {θ i ∈ R d + : 0 ≤ w T t-τ :t-1 θ i ≤ 1, t = 1, . . . , T }. In this special case, the empirical vector field (3) becomes</p><formula xml:id="formula_55">F (i) T (θ i ) = 1 T T t=1 w t-τ :t-1 w T t-τ :t-1 θ i - 1 T T t=1 w t-τ :t-1 y (i) t = W 1:T θ i - 1 T T t=1 w t-τ :t-1 y (i) t ,</formula><p>where we denote</p><formula xml:id="formula_56">w 1:T = (w 1-τ :0 , . . . , w T -τ :T -1 ) ∈ R d×T , W 1:T = 1 T w 1:T w T 1:T = 1 T T t=1 w t-τ :t-1 w T t-τ :t-1 ∈ R d×d .<label>(11)</label></formula><p>Most importantly, this vector field is indeed the gradient field of the least square objective, meaning that the weak solution to the corresponding VI is the following LS estimator <ref type="bibr" target="#b4">Juditsky et al. [2020]</ref>: min</p><formula xml:id="formula_57">θ i 1 2T w T 1:T θ i -Y (i) 1:T 2 2 , subject to θ i ≥ 0 T , 1 T -w T 1:T θ i ≥ 0 T ,<label>(12)</label></formula><p>where</p><formula xml:id="formula_58">Y (i) 1:T = (y (i) 1 , . . . , y<label>(i)</label></formula><p>T ) T , 0 T and 1 T are the column vectors of all zeros and ones in R T , respectively, and • p denotes the vector p norm.</p><p>Note that the equivalence between our proposed estimatorand LS estimator will only hold for linear link function, since the gradient field of LS objective with general link function is:</p><formula xml:id="formula_59">1 T T t=1 w t-τ :t-1 g w T t-τ :t-1 θ i g w T t-τ :t-1 θ i -y (i) t</formula><p>.</p><p>One approach to solve ( <ref type="formula" target="#formula_57">12</ref>) is to leverage the well-developed optimization tools, such as</p><p>Mosek ApS <ref type="bibr">[2019]</ref>. An alternative approach is through projected gradient descent, where the empirical vector field (3) is treated as the gradient. To be precise, we introduce dual variables η 1 = (η 1,1 , . . . , η 1,T ) T , η 2 = (η 2,1 , . . . , η 2,d ) T and the Lagrangian is as follows:</p><formula xml:id="formula_60">L(θ i , η 1 , η 2 ) = 1 2T w T 1:T θ i -Y (i) 1:T 2 2 + η T 1 (w T 1:T θ i -1 T ) -η T 2 θ i .</formula><p>The Lagrangian dual function is min θ i L(θ i , η 1 , η 2 ). As we can see, the Lagrangian above is convex w.r.t. θ i . By setting the derivative of L(θ i , η 1 , η 2 ) w.r.t. θ i to zero, we have</p><formula xml:id="formula_61">θi = 1 T W -1 1:T w 1:T Y (i) 1:T /T -η 1 + η 2 ,</formula><p>which minimizes the Lagrangian dual function. As pointed out in <ref type="bibr" target="#b4">Juditsky et al. [2020]</ref>,</p><p>W 1:T ∈ R d×d will be full rank with high probability when T is sufficiently large, and therefore W -1 1:T exists. By plugging θi into the Lagrangian dual function min θ i L(θ i , η 1 , η 2 ), we give the dual problem as follows: max</p><formula xml:id="formula_62">η 1 ,η 2 L( θi , η 1 , η 2 ), subject to η 1 , η 2 ≥ 0 T .</formula><p>As we can see, this dual problem can be easily solved by PGD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Joint estimation</head><p>Now let us consider the joint estimation, where the vector field F T (θ) (6) can be expressed as follows:</p><formula xml:id="formula_63">F T (θ) = 1 T w 1:T w T 1:T θ - 1 T w 1:T Y = W 1:T θ - 1 T w 1:T Y,</formula><p>where w 1:T ∈ R d×T is defined in 11. Similar to the example in decoupled estimation, the above vector field is the gradient field of the least square objective, and our proposed estimator boils down to LS estimator, which solves the following penalized optimization problem:</p><formula xml:id="formula_64">min θ∈ Θ 1 2T w T 1:T θ -Y 2 F + λ τ =1 i∈I 1, e T f i, ,d θe i,d 1 αii + i ∈I 1, e T f i, ,d θe i,d 1 Λ + (i,j)∈I 2, e T f j, ,d θe i,d 1 + e T f i, ,d θe j,d 1 δ 2, (i, j) + (i,j,k)∈I 3, e T f j, ,d θe i,d 1 + e T f k, ,d θe j,d 1 + e T f i, ,d θe k,d 1 δ 3, (i, j, k) ,<label>(13)</label></formula><p>where • F is the matrix F -norm. Therefore, (13) can be solved efficiently using PGD, where at each iteration the update rule is as follows:</p><formula xml:id="formula_65">θ ← θ -ηF AL T ( θ),</formula><p>where η is the step size/learning rate hyperparameter and F AL T (•) is the penalized empirical field (5). Since the prediction of the i-th event at time t is determined by the estimated probability w T t-τ :t-1 θ i and a cut-off/threshold selected using the validation dataset, we can further relax the constraint w T 1:T θ i ≤ 1 T and treat it as "score" instead of probability. Therefore, after the above update in each iteration, the projection onto the (relaxed) feasible region can be simply done by replacing all negative entries in θ with zeros.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Additional Numerical Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Additional experimental details</head><p>We first randomly generate ν and A using standard uniform distribution. Next, to make sure A stays in the feasible region Θ for the linear function case, we normalize each row to make sure it sums up to one. To be precise, we just update each entry in the row by dividing it with the row summation. To make sure A is DAG, we (i) first "sparse-ify" it by setting all entries smaller than the 95% percentile to zeros and (ii) next minimize the DAG characterization h(A) using vanilla gradient descent (learning rate is 0.5 and we consider in total 5000 iterations). The reason of applying (i) is the highly non-convex optimization in (ii) -if we do not input a highly sparse graph, then we cannot shrink the DAG characterization to exactly zero with high probability. As for PGD approach to solve for VI estimator, we use 5 × 10 -3 as the initial learning rate and decrease it by half every 2000 iterations (in total there are 6000 iterations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Additional experimental results</head><p>Due to space consideration, we report the results that do not give new insights and only serve for completeness purpose here. In particular, we report all four aforementioned metrics for Experiment 1 in Table <ref type="table">1</ref>, and plot the results for linear link function for Experiment 2 in Figure <ref type="figure" target="#fig_2">5</ref>; please see the interpretation of those results in Section 5. Table <ref type="table">1</ref>: Comparison of the mean (and standard deviation) of various performance metrics over 200 trials for different types of regularization. We report the matrix F -norm of the selfand mutual-exciting matrix estimation error (A err.), the 2 norm of the background intensity estimation error (ν err.), the "DAG-ness" measured by h(A) and the Structural Hamming Distance (SHD).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linear Link.</head><p>Dimension d 1 = 10, Time Horizon T = 500. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regularization</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparison among different types of regularization in DAG recovery. We plot the mean (dot) and standard deviation (error bar) of matrix F -norm of the self-and mutualexciting matrix estimation error (A err.) and Structural Hamming Distance (SHD) over 200independent trials for various types of regularization. Hyperparameter λ is selected to be the smallest one which satisfies h(A) ≤ 10 -4 . For each regularization, the closer it is to the origin, the better it is. We can observe that our proposed data-adaptive linear regularization performs the best (especially in higher dimensional case).</figDesc><graphic coords="12,116.85,92.82,374.41,492.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Xun Zheng, Bryon Aragam, Pradeep K Ravikumar, and Eric P Xing. Dags with no tears: Continuous optimization for structure learning. Advances in Neural Information Processing Systems, 31, 2018. Hui Zou. The adaptive lasso and its oracle properties. Journal of the American statistical association, 101(476):1418-1429, 2006.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Effect of hyperparameter (continued). We consider the VI estimator with linear link function for completeness in this figure. We can observe similar patterns with Figure 4.</figDesc><graphic coords="23,72.00,317.00,468.00,242.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="3,113.77,261.06,380.91,287.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="9,116.85,135.33,374.40,270.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="14,116.85,117.65,374.41,472.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>A err. 0.3379 (0.0988) 0.2347 (0.0698) 0.3214 (0.1009) 0.2172 (0.0674) 0.2246 (0.0872) ν err. 0.0970 (0.0307) 0.0661 (0.0213) 0.0822 (0.0266) 0.0636 (0.0208) 0.0584 (0.0170) h(A) 0.0311 (0.0163) 0.0002 (0.0011) 0.0053 (0.0041) 0.0000 (0.0000) 0.0000 (0.0000) Dimension d 1 = 20, Time Horizon T = 1000. A err. 0.3764 (0.0737) 0.2035 (0.0348) 0.3382 (0.0783) 0.1820 (0.0357) 0.1819 (0.0401) ν err. 0.1729 (0.0329) 0.0969 (0.0253) 0.1403 (0.0259) 0.0834 (0.0225) 0.0735 (0.0170) h(A) 0.0573 (0.0132) 0.0000 (0.0000) 0.0086 (0.0012) 0.0000 (0.0000) 0.0000 (0.0000) SHD 183.28 (10.70) 32.99 (8.65) 139.79 (8.19) 123.64 (14.34) 91.24 (15.07) Dimension d 1 = 30, Time Horizon T = 1500. .4116 (0.0448) 0.1782 (0.0239) 0.3549 (0.0491) 0.1676 (0.0213) 0.1727 (0.0226) ν err. 0.2486 (0.0334) 0.1104 (0.0210) 0.1995 (0.0262) 0.1013 (0.0187) 0.0987 (0.0190) h(A) 0.0774 (0.0113) 0.0000 (0.0000) 0.0089 (0.0011) 0.0000 (0.0000) 0.0000 (0.0000) A err. 0.4495 (0.1457) 0.2797 (0.0914) 0.4233 (0.1452) 0.2417 (0.0620) 0.2925 (0.1167) ν err. 0.1061 (0.0336) 0.0720 (0.0225) 0.0889 (0.0285) 0.0666 (0.0208) 0.0644 (0.0196) h(A) 0.0439 (0.0243) 0.0001 (0.0006) 0.0046 (0.0039) 0.0000 (0.0000) 0.0000 (0.0000) Dimension d 1 = 20, Time Horizon T = 1000. Dimension d 1 = 30, Time Horizon T = 1500. .5048 (0.0507) 0.1841 (0.0225) 0.4277 (0.0559) 0.1738 (0.0205) 0.1888 (0.0250) ν err. 0.2743 (0.0361) 0.1090 (0.0170) 0.2148 (0.0274) 0.1022 (0.0168) 0.1032 (0.0162) h(A) 0.1090 (0.0151) 0.0000 (0.0000) 0.0089 (0.0010) 0.0000 (0.0000) 0.0000 (0.0000) SHD 414.17 (13.44) 73.75 (10.52) 294.5 (11.44) 277.14 (19.12) 198.52 (26.61)</figDesc><table><row><cell></cell><cell>None</cell><cell>Proposed</cell><cell>DAG</cell><cell>1</cell><cell>Ada. 1</cell></row><row><cell>SHD</cell><cell>44.3 (5.24)</cell><cell>12.74 (4.73)</cell><cell>32.7 (6.34)</cell><cell>31.77 (5.48)</cell><cell>26.22 (6.32)</cell></row><row><cell>Regularization</cell><cell>None</cell><cell>Proposed</cell><cell>DAG</cell><cell>1</cell><cell>Ada. 1</cell></row><row><cell>Regularization</cell><cell>None</cell><cell>Proposed</cell><cell>DAG</cell><cell></cell><cell></cell></row><row><cell>SHD</cell><cell>411.81 (12.18)</cell><cell>73.43 (11.03)</cell><cell>306.52 (11.69)</cell><cell>277.25 (19.99)</cell><cell>199.15 (26.89)</cell></row><row><cell></cell><cell></cell><cell cols="2">Exponential Link.</cell><cell></cell><cell></cell></row><row><cell>Regularization</cell><cell>None</cell><cell>Proposed</cell><cell>DAG</cell><cell>1</cell><cell>Ada. 1</cell></row><row><cell>SHD</cell><cell>43.75 (5.00)</cell><cell>12.96 (5.11)</cell><cell>30.77 (5.71)</cell><cell>31.66 (5.28)</cell><cell>24.7 (6.44)</cell></row><row><cell>Regularization</cell><cell>None</cell><cell>Proposed</cell><cell>DAG</cell><cell>1</cell><cell>Ada. 1</cell></row><row><cell>A err.</cell><cell cols="5">0.4731 (0.0844) 0.2118 (0.0360) 0.4206 (0.0911) 0.1898 (0.0310) 0.2136 (0.0496)</cell></row><row><cell>ν err.</cell><cell cols="5">0.1897 (0.0385) 0.0948 (0.0201) 0.1511 (0.0298) 0.0840 (0.0187) 0.0813 (0.0174)</cell></row><row><cell>h(A)</cell><cell cols="5">0.0799 (0.0191) 0.0002 (0.0011) 0.0087 (0.001) 0.0000 (0.0000) 0.0000 (0.0000)</cell></row><row><cell>SHD</cell><cell>183.83 (10.18)</cell><cell>34.59 (10.79)</cell><cell>134.53 (7.80)</cell><cell>125.7 (12.75)</cell><cell>90.8 (17.29)</cell></row><row><cell>Regularization</cell><cell>None</cell><cell>Proposed</cell><cell>DAG</cell><cell></cell><cell></cell></row></table><note><p>1 Ada. 1 A err. 0Dimension d 1 = 10, Time Horizon T = 500. 1 Ada. 1 A err. 0</p></note></figure>
		</body>
		<back>

			<div type="funding">
<div><p>This work is partially supported by an <rs type="funder">NSF</rs> <rs type="grantNumber">CAREER CCF-1650913</rs>, and <rs type="funder">NSF</rs> <rs type="grantNumber">DMS-2134037</rs>, <rs type="grantNumber">CMMI-2015787</rs>, <rs type="grantNumber">DMS-1938106</rs>, and <rs type="grantNumber">DMS-1830210</rs>.  </p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_E7WKmnS">
					<idno type="grant-number">CAREER CCF-1650913</idno>
				</org>
				<org type="funding" xml:id="_ERUCxbP">
					<idno type="grant-number">DMS-2134037</idno>
				</org>
				<org type="funding" xml:id="_X8E35NV">
					<idno type="grant-number">CMMI-2015787</idno>
				</org>
				<org type="funding" xml:id="_XxGFraw">
					<idno type="grant-number">DMS-1938106</idno>
				</org>
				<org type="funding" xml:id="_YFcQ9Zu">
					<idno type="grant-number">DMS-1830210</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Large-sample learning of bayesian networks is np-hard</title>
		<author>
			<persName><forename type="first">Max</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1287" to="1330" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning network of multivariate hawkes processes: a time series approach</title>
		<author>
			<persName><forename type="first">Jalal</forename><surname>Etesami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Negar</forename><surname>Kiyavash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kushagra</forename><surname>Singhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Thirty-Second Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="162" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Low rank directed acyclic graphs and causal structure learning</title>
		<author>
			<persName><forename type="first">Zhuangyan</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiji</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangbo</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.05691</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Review of causal discovery methods based on graphical models</title>
		<author>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in genetics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">524</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Convex parameter recovery for interacting marked processes</title>
		<author>
			<persName><forename type="first">Anatoli</forename><surname>Juditsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arkadi</forename><surname>Nemirovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liyan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Information Theory</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Signal recovery by stochastic optimization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Anatoli</surname></persName>
		</author>
		<author>
			<persName><surname>Juditsky</surname></persName>
		</author>
		<author>
			<persName><surname>Nemirovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation and Remote Control</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1878" to="1893" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Nan</forename><surname>Rosemary Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olexa</forename><surname>Bilaniuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><surname>Mozer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01075</idno>
		<title level="m">Chris Pal, and Yoshua Bengio. Learning neural causal models from unknown interventions</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Anthony</forename><forename type="middle">C</forename><surname>Neville K Kitson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhigao</forename><surname>Constantinou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kiattikun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Chobtham</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.11415</idno>
		<title level="m">A survey of bayesian network structure learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gradientbased neural dag learning</title>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Brouillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">High-dimensional learning of linear causal networks via inverse covariance estimation</title>
		<author>
			<persName><forename type="first">Po-Ling</forename><surname>Loh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3065" to="3105" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Integer programming for learning directed acyclic graphs from continuous data</title>
		<author>
			<persName><forename type="first">Simge</forename><surname>Hasan Manzour</surname></persName>
		</author>
		<author>
			<persName><surname>Küçükyavuz</surname></persName>
		</author>
		<author>
			<persName><surname>Hao-Hsiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Shojaie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="73" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On the role of sparsity and dag constraints for learning linear dags</title>
		<author>
			<persName><forename type="first">Ignavier</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amiremad</forename><surname>Ghassami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="17943" to="17954" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynotears: Structure learning from time-series data</title>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<editor>
			<persName><forename type="first">Roxana</forename><surname>Pamfil</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nisara</forename><surname>Sriwattanaworachai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Shaan</forename><surname>Desai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Philip</forename><surname>Pilgerstorfer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Konstantinos</forename><surname>Georgatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paul</forename><surname>Beaumont</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bryon</forename><surname>Aragam</surname></persName>
		</editor>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1595" to="1605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Causal protein-signaling networks derived from multiparameter single-cell data</title>
		<author>
			<persName><forename type="first">Karen</forename><surname>Sachs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Pe'er</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><forename type="middle">A</forename><surname>Lauffenburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garry</forename><forename type="middle">P</forename><surname>Nolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">308</biblScope>
			<biblScope unit="issue">5721</biblScope>
			<biblScope unit="page" from="523" to="529" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A survey on bayesian network structure learning from data</title>
		<author>
			<persName><forename type="first">Mauro</forename><surname>Scanagatta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Salmerón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Stella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progress in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="425" to="439" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">D&apos;ya like dags? a survey on structure learning and causal discovery</title>
		<author>
			<persName><forename type="first">J</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Necati</forename><surname>Vowels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Cihan Camgoz</surname></persName>
		</author>
		<author>
			<persName><surname>Bowden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A* lasso for learning a sparse bayesian network structure for continuous variables</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyoung</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dag-gnn: Dag structure learning with graph neural networks</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7154" to="7163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Constrained likelihood for reconstructing a directed acyclic gaussian graph</title>
		<author>
			<persName><forename type="first">Yiping</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zizhuo</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="125" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Integrated systems approach identifies genetic nodes and networks in late-onset alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Gaiteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liviu-Gabriel</forename><surname>Bodea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Mcelwee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Podtelezhnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunsheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Dobrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="707" to="720" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
