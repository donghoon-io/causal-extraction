<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning</title>
				<funder ref="#_QvQrSY3">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
				<funder ref="#_7BJT3tN">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder>
					<orgName type="full">Youth Innovation Promotion Association CAS</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-03-22">22 Mar 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhitao</forename><surname>He</surname></persName>
							<email>zhitao.he@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">The Laboratory of Cognition and Decision Intelligence for Complex Systems</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pengfei</forename><surname>Cao</surname></persName>
							<email>pengfei.cao@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">The Laboratory of Cognition and Decision Intelligence for Complex Systems</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhuoran</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">The Laboratory of Cognition and Decision Intelligence for Complex Systems</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yubo</forename><surname>Chen</surname></persName>
							<email>yubo.chen@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">The Laboratory of Cognition and Decision Intelligence for Complex Systems</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
							<email>kliu@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">The Laboratory of Cognition and Decision Intelligence for Complex Systems</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Shanghai Artificial Intelligence Laboratory</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">Ant Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mengshu</forename><surname>Sun</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">Ant Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
							<email>jzhao@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">The Laboratory of Cognition and Decision Intelligence for Complex Systems</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-03-22">22 Mar 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2403.02893v2[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>zero-shot cross-lingual</term>
					<term>document-level</term>
					<term>event causality identification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Event Causality Identification (ECI) refers to the detection of causal relations between events in texts. However, most existing studies focus on sentence-level ECI with high-resource languages, leaving more challenging document-level ECI (DECI) with low-resource languages under-explored. In this paper, we propose a Heterogeneous Graph Interaction Model with Multi-granularity Contrastive Transfer Learning (GIMC) for zero-shot cross-lingual document-level ECI. Specifically, we introduce a heterogeneous graph interaction network to model the long-distance dependencies between events that are scattered over a document. Then, to improve cross-lingual transferability of causal knowledge learned from the source language, we propose a multi-granularity contrastive transfer learning module to align the causal representations across languages. Extensive experiments show our framework outperforms the previous state-of-the-art model by 9.4% and 8.2% of average F1 score on monolingual and multilingual scenarios respectively. Notably, in the multilingual scenario, our zero-shot framework even exceeds GPT-3.5 with few-shot learning by 24.3% in overall performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Event Causality Identification (ECI) is an important task in natural language processing (NLP), which can facilitate various applications, including explainable question answering <ref type="bibr">(Yang et al., 2018b)</ref>, intelligent search <ref type="bibr" target="#b36">(Rudnik et al., 2019)</ref> and complex reasoning <ref type="bibr" target="#b14">(Dalvi et al., 2021)</ref>. Most previous methods <ref type="bibr" target="#b22">(Kadowaki et al., 2019;</ref><ref type="bibr">Liu et al., 2020a;</ref><ref type="bibr" target="#b49">Zuo et al., 2021;</ref><ref type="bibr" target="#b5">Cao et al., 2021)</ref> focus on sentence-level with English corpora. Nevertheless, a substantial number of causal relations are expressed by multiple sentences. For instance, there are approximately 68.7% of causal relationships in English corpora <ref type="bibr" target="#b7">(Caselli and Vossen, 2017)</ref> are attributed to intersentence event pairs. Hence, identifying causality of events at the document-level is necessary, which gains increasing attention recently <ref type="bibr" target="#b41">(Tran Phu and Nguyen, 2021;</ref><ref type="bibr" target="#b18">Fan et al., 2022;</ref><ref type="bibr" target="#b1">Boxi Cao et al., 2024;</ref><ref type="bibr" target="#b9">Chen et al., 2022)</ref>.</p><p>However, training an ECI model typically relies on a large amount of data, especially for document-level, which makes it hard to adapt to low-resource languages. While pre-trained language models have exhibited remarkable capabilities across various tasks <ref type="bibr">(Brown et al.,</ref>   <ref type="bibr" target="#b11">Chowdhery et al., 2022;</ref><ref type="bibr" target="#b42">Wang et al., 2023;</ref><ref type="bibr" target="#b40">Tan et al., 2023;</ref><ref type="bibr" target="#b24">Liang Zhang et al., 2023)</ref>, they still struggle in multilingual setting, as evidenced in recent studies <ref type="bibr" target="#b8">(Chang et al., 2023;</ref><ref type="bibr" target="#b21">Huang et al., 2023;</ref><ref type="bibr">Zhang et al., 2023)</ref>. Even the powerful ChatGPT exhibits quite limited performance in multilingual relation prediction task, with an average accuracy of only 37%. Particularly for low-resource languages, the model performs even worse, such as achieving only a 6.3% accuracy in Urdu <ref type="bibr" target="#b23">(Lai et al., 2023)</ref>. Moreover, low-resource languages face a critical shortage of training data, making it challenging to enhance the document-level ECI performance of language models. Therefore, in this paper we focus on zero-shot cross-lingual document-level ECI, aiming to efficiently transfer the causality knowledge from the source languages to any other languages (e.g. low-resource/less-studied languages) under limited language resources. As shown in Figure <ref type="figure">1</ref>, the model is trained with the annotated data in source language and directly applied to target language. While significant efforts have been made for monolingual setting <ref type="bibr" target="#b41">(Tran Phu and Nguyen, 2021;</ref><ref type="bibr" target="#b9">Chen et al., 2022)</ref>, two critical challenges arise when we apply monolingual ECI to zero-shot crosslingual document-level setting:</p><p>(1) Language-agnostic causal knowledge alignment. Each language has its own characteristics. The multilingual ECI models, trained in source language, inevitably tend to learn language-specific knowledge rather than pure language-agnostic knowledge (i.e., causal knowledge). Thus, the trained ECI model may only perform well in source language. For example, different languages have distinct distributions of distance between causal events. According to statistics, the majority distance between causal events in English corpora is 40 words, whereas in Turkish, it is 33 words, and in Danish, it is 23 words. Furthermore, based on our error analysis of vanilla pre-trained langugae model, when we employ model trained on English to test on Danish, more than half (53%) of the false positive causal events are separated by more than 23 words, which means the ECI model trained in English corpora tend to predict a causal relation between two events that are far away, leading negatively impact on the prediction in Danish.</p><p>(2) Causal events scattering. As shown in Figure <ref type="figure" target="#fig_2">2</ref>(a), the intra-sentence causality between "crashed" and "died" can be easily predicted. By contrast, event "crashed" and "killing" are located in sentence 1 and 5 respectively, the long distance and the interference of irrelevant events such as "Beirut barracks bombings" and "pursuing militants" make it difficult to directly model the long-distance dependencies between mentioned events. Fortunately, as shown in Figure <ref type="figure" target="#fig_2">2</ref>(b), we can efficiently obtain the informative phrases (i.e., the underlined "military helicopter" and "soldier") related to scattered causal events "crashed" and "killing" by processing dependency structure with heuristic rules. We find that these informative phrases are similar and can serve as intermediate bridges for connecting the two events, which indicates the importance of informative phrases in modeling long-distance dependencies between events.   Events are colored and we underline the informative phrases related to colored events. Red lines and gray lines indicate the causal relations and arguments of events, respectively.</p><p>To tackle the aforementioned challenges, we propose a Heterogeneous Graph Interaction Model with Multi-granularity Contrastive Transfer Learning (GIMC). Specifically, we introduce a Multigranularity Contrastive Transfer Learning Module to align causal representations across languages for transferring language-agnostic causal knowledge in statement and aspect levels. Meanwhile, we design a Heterogeneous Graph Interaction network with informative phrase nodes, sentence nodes, statement nodes, event pair nodes to model the long-distance dependencies between events. Extensive experiments show that our zeroshot framework outperforms previous models and even exceeds GPT-3.5 with zero/few-shot prompt.</p><p>We summarize the contributions as follows:</p><p>• We propose a novel heterogeneous graph interaction model with multi-granularity contrastive transfer learning (GIMC) to simultaneously address document-level and zero-shot cross-lingual event causality identification.</p><p>• We introduce a multi-granularity contrastive learning module to facilitate the cross-lingual transfer of language-agnostic causal knowledge, and construct a heterogeneous graph interaction network with four kinds of semantically rich nodes to model long-distance dependencies between events.</p><p>• Extensive experiments on the widely used multilingual ECI dataset show the effectiveness of our proposed model. F1 scores are improved by an average of 9.4% and 8.2% in monolingual and multilingual scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head><p>Figure <ref type="figure" target="#fig_5">4</ref> shows the architecture of GIMC which consists of a heterogeneous graph interaction network (left) and a multi-granularity contrastive transfer learning module on graph (right). We first encode the document using multilingual pre-trained language model, then construct the heterogeneous graph interaction network with four types of nodes. Finally, we leverage statement-level and aspectlevel casual pattern contrastive learning to facilitate the cross-lingual transfer of causal knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Informative Phrase Extraction</head><p>Given a sentence s = {w j } |s| j=1 ∈ D, we use the multilingual NLP toolkit Trankit <ref type="bibr">(Nguyen et al., 2021)</ref>, which has an overall performance of about 93% across different languages in sentence parsing, to obtain the dependency tree as shown in <ref type="bibr">Figure 3(a)</ref>. Previous studies only exploit the nodes in dependency tree as language-independent information to enhance ECI systems <ref type="bibr" target="#b19">(Gao et al., 2019;</ref><ref type="bibr" target="#b41">Tran Phu and Nguyen, 2021)</ref> and overlook the rich semantics of dependency relations.</p><p>Thus, based on the semantics of the dependency relations <ref type="bibr" target="#b16">(De Marneffe and Manning, 2008;</ref><ref type="bibr" target="#b15">De Marneffe et al., 2014;</ref><ref type="bibr" target="#b37">Schuster and Manning, 2016)</ref>, we further process the dependency structure with heuristic rules to obtain a simplified dependency tree with informative phrases, as shown in Figure <ref type="figure" target="#fig_3">3</ref>(b). We first analyze all dependency relations and their subtypes 1 , retaining 19 semantically rich and indicative dependency relations, e.g., nsubj (nominal subject), obj (object), obl (oblique nominal). In this way, we extract the informative phrases and the corresponding dependency relations that indicates the relevant arguments of the events of interest (e.g., the subject (nsubj) of the event "crashed" is "two French military helicopters"). The complete list of dependency relations is in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Heterogeneous Graph Interaction Network</head><p>We build a heterogeneous graph interaction network G which contains informative phrase nodes, sentence nodes, statement nodes and event pair nodes. After inserting special tags "&lt;t&gt;" and "&lt;/t&gt;" at the start and end of all events to mark the event positions, we transform each word w i ∈ D into the embedding x i using pre-trained language model.  For each informative phrase node p which needs to incorporate its role information r p , we initialize its embedding by h</p><formula xml:id="formula_0">(0) p = Mean({x j } j∈p ) + Emb(r p ).</formula><p>For each sentence node s, we initialize its embedding h (0) s = Mean({x j } j∈s ). We define statement as a sentence containing two events to adapt to cross-sentence cases, such as the sentence 1 where the event "crashed" and the event "died" are located, or a concatenation of two sentences to include event pairs that across sentences, such as event "crashed" in sentence 1 and event "killing" in sentence 5. We initialize statement node embedding h (0) st = Mean({x j } j∈st ). For event pair (i, j) with their representation (e i , e j ), following <ref type="bibr" target="#b9">Chen et al. (2022)</ref>, we initialize v (0) i,j = W v [e i ||e j ] , W v are trainable parameters and || denotes concatenation.</p><p>To capture the interactions among these nodes, we introduce six types of edges: Phrase-Phrase Edge (P-P) The P-P edges are derived from the dependency structure. Informative phrase nodes are connected to each other by the dependency relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence-Phrase Edge (S-P)</head><p>The phrase node is connected to its sentence node. The S-P edges enable to model the local contextual information of a phrase in its corresponding sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phrase-Events Edge (P-E)</head><p>The informative phrase containing an event mention can be seen as a more complete expression of the event. We model this information via the P-E edge. Sentence-Events Edge (S-E) If there are sentences containing any events of the current event pair, the event pair node is connected to the nodes of those sentences. We model the local context information of events with S-E edges.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement-Events Edge (St-E)</head><p>We connect the event node and its statement node. The St-E edge is expected to model the process of transfer the causality in statement to event pair to avoid the model from overfitting the causality in event pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Events-Events Edge (E-E)</head><p>There is an E-E edge between two event pair nodes only if the two corresponding event pairs share at least one event. E-E edge can promote the effective transmission of the causal information in event pairs. After construct heterogeneous graph, we apply Graph Attention Networks v2 (GATv2) <ref type="bibr" target="#b2">(Brody et al., 2022)</ref> to model the global interactions. For each edge (j, i), the scoring function f : R d × R d → R indicates the importance of the features of the neighbor j ∈ N i to the node i:</p><formula xml:id="formula_1">f (hi, hj) = a ⊤ LeakyReLU(W • [hi||hj])<label>(1)</label></formula><p>where W is denoted as</p><formula xml:id="formula_2">[W l ||W r ], W l ∈ R d ′ ×d , W r ∈ R d ′ ×d , a ∈ R d ′</formula><p>are trainable parameters. h i and h j are the representations of node i and j respectively. Then the attention function is defined:</p><formula xml:id="formula_3">αij = exp(f (hi, hj)) j ′ ∈N i exp(f (hi, h ′ j ))<label>(2)</label></formula><p>Then, we compute a weighted average of the transformed features of the neighbor nodes as the new representation of node i, using the normalized attention scores:</p><formula xml:id="formula_4">h ′ i = j∈N i αijWrhj<label>(3)</label></formula><p>We employ K separate attention heads and concatenate their outputs as the output of node i:</p><formula xml:id="formula_5">h ′ i = Wo K k=1 h ′k i (4)</formula><p>where W o are trainable parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Multi-granularity Contrastive Learning Module</head><p>Inspired by sentence-level ECI studies <ref type="bibr">(Liu et al., 2020a;</ref><ref type="bibr" target="#b49">Zuo et al., 2021)</ref>, which leverage the context-specific causal patterns of statements, for example, we can leverage the causal pattern "The [EVENT] generates [EVENT] ..." to identify the causation between traffic congestion and environmental pollution in a new statement "The traffic congestion generates environmental pollution and economic loss". We generalize the causal pattern to the multilingual space, using contrastive learning to explicitly align causal representations across language. As shown in Figure <ref type="figure" target="#fig_5">4</ref>, our contrastive transfer learning module consists of two part: 1) statement-level causal pattern contrastive learning to align statement causal representation across languages, 2) aspect-level causal pattern contrastive learning to align the representation between finegrained causal patterns and statement. We select appropriate positive and negative samples for anchor statement:</p><p>Positive Samples Given each anchor causal statement, we follow <ref type="bibr" target="#b35">Qin et al. (2020)</ref> to use MUSE bilingual dictionaries to generate multilingual codeswitched statements as the positive samples. Unlike <ref type="bibr" target="#b35">Qin et al. (2020)</ref> which randomly replace a word at a time, we operate on phrases in statements. Specifically, given a phrase, we first randomly select a bilingual dictionary (e.g., en-da). Then, we switch each word in the phrase one by one using that bilingual dictionary, which is intuitively expected to maintain more complete semantic information. Taking the informative phrase in Figure <ref type="figure" target="#fig_3">3</ref> as example, "two French military helicopters" da -→ "to franske militaer helikoptere". Negative Samples To make the negative examples more discriminative, we select non-causal statements within the same document as negative examples that do not have any text overlap with anchor statement. Furthermore, as we expect the model to focus on transfering across languages, we generate multilingual negative examples by codeswitching to augment the list of negative samples. <ref type="bibr">As Zuo et al. (2021)</ref> learn contextspecific causal patterns from causal statements, we propose a statement-level causal pattern contrastive learning loss to explicitly align causal representations of anchor statement with the generated positive sample. Formally, this is formulated as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Statement-level causal pattern contrastive learning</head><formula xml:id="formula_6">LS = - n j=1 log s(hCLS, h j CLS + ) s(hCLS, h j CLS + ) + K-1 k=0 s(hCLS, h k CLS -)</formula><p>where s(•) denotes dot product, n is the number of corresponding positive samples, K is the number of negative samples. h CLS is the embedding of CLS token, which serves as the initial state of statement and contains context-specific causal patterns.</p><p>2) Aspect-level causal pattern contrastive learning Many previous studies <ref type="bibr" target="#b5">(Cao et al., 2021;</ref><ref type="bibr" target="#b9">Chen et al., 2022)</ref> focus on exploring the causality of event pairs. Recently, <ref type="bibr">Liu et al. (2020a)</ref> exploits event-agnostic, context-specific patterns which achieve promising performance. Thus, we categorize causal patterns into two aspects: event pair and event-agnostic context. Using the mentioned statement "The traffic congestion generates environmental pollution and economic loss" as an example, one of its causal patterns is the event pair aspect that "traffic congestion" and "environmental pollution", another causal pattern is the event-agnostic context aspect "The [EVENT] generates [EVENT] ..." Specifically, we split each statement into event pair and event-masked context, and get representations of these two types of aspects after encoding by multilingual pre-trained language model. We further introduce the aspectlevel causal pattern contrastive learning loss:</p><formula xml:id="formula_7">LAspE = - n j=1 log s(hCLS, h j AspE + ) s(hCLS, h j AspE + ) + K-1 k=0 s(hCLS, h k AspE -) LAspC = - n j=1 log s(hCLS, h j AspC + ) s(hCLS, h j AspC + ) + K-1 k=0 s(hCLS, h k AspC -)</formula><p>We consider contrastive learning loss from both event pair aspect (L AspE ) and event-agnostic context aspect (L AspC ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Training</head><p>We concatenate event pair node representation v ei,j , statement node representation h CLS . For training, we adopt cross entropy as loss function:</p><formula xml:id="formula_8">pe i ,e j = softmax(Wp[ve i,j ||hCLS])<label>(5)</label></formula><p>LC =e i ,e j ∈Es ye i ,e j log(pe i ,e j )</p><p>where p ei,ej is the predicted probability of causality between events e i and e j . E s is the set of events, y ei,ej is a one-hot vector representing the gold label between e i and e j . We sum the losses as follows:</p><formula xml:id="formula_10">L all = L C + L S + L AspE + L AspC (7)</formula><p>In our implementations, we employ the base versions of the language-specific pre-trained language models (PLMs) and the multilingual PLMs. The learning rate is initialized as 1e-3 with a linear decay. We use the AdamW algorithm <ref type="bibr" target="#b27">(Loshchilov and Hutter, 2017)</ref> to optimize model parameters. The batch size is set to 1, the number of GATv2 layers is 3. The number of training epochs is 60. Each experiment is conducted on NVIDIA GeForce RTX 3090 GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset</head><p>As the cross-lingual DECI is under-explored, the dataset we build upon is currently the only largescale multi-lingual ECI dataset Lai et al. ( <ref type="formula">2022</ref>) that employs a consistent annotation standard. It comprises as many as 3591 documents of five typologically diverse languages, i.e., English, Danish, Spanish, Turkish, and Urdu, the details are shown in Table <ref type="table" target="#tab_2">1</ref>. This dataset is not only larger but also more challenging, as a majority of events are 10 to 50 words away from each other in documents and there are clear divergences between the distance distributions of causal events over languages (we list the majority distance of causal events below). Table <ref type="table">2</ref>: Monolingual performance on MECI dataset. We report the results using language-specific PLMs ("*"), XLMR and mBERT as the backbone respectively. AVG is the average F1 score for five languages. Table <ref type="table">3</ref>: Zero-shot cross-lingual document-level ECI performance with English as the source language. We report the average (AVG) and fluctuation (∆) of F1 score under the different multilingual PLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Experimental Settings</head><p>We utilize the base versions of all PLMs and evaluate our model in the following settings: Monolingual learning setting The training and test data are in same language. We use language specific PLMs, i.e., BotXO2<ref type="foot" target="#foot_0">foot_0</ref> for Danish, BERT <ref type="bibr" target="#b17">(Devlin et al., 2019)</ref> for English, BETO <ref type="bibr" target="#b4">(Canete et al., 2020)</ref> for Spanish, BERTurk <ref type="bibr" target="#b38">(Schweter, 2020)</ref> for Turkish, and UrduHack<ref type="foot" target="#foot_1">foot_1</ref> for Urdu.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multilingual learning setting</head><p>The ECI models are trained in source language and directly tested in target language. We utilize the multilingual PLMs, i.e., mBERT <ref type="bibr" target="#b17">(Devlin et al., 2019)</ref> or XLMR <ref type="bibr" target="#b13">(Conneau et al., 2020)</ref> as the backbone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Baselines</head><p>We compare our method with the vanilla PLM, LLM and three strong monolingual baselines (we replace their backbones with multilingual PLM):</p><p>(1) PLM By leveraging the embeddings h i , h j of two events, the overall representation vector is formed</p><formula xml:id="formula_11">h i,j = [h i , h j , h i -h j , h i * h j ] for ECI.</formula><p>(2) Know <ref type="bibr">Liu et al. (2020a)</ref> retrieves external knowledge from knowledge base and eventagnostic, context-specific patterns to enrich the representations of events for causality identification.</p><p>(3) RichGCN Tran Phu and Nguyen (2021) implement several interaction graphs, by learning a linear combination of the adjacency matrices of these graphs to get a final graph and uses graph convolutional network (GCN) to capture capture relevant context information.</p><p>(4) ERGO <ref type="bibr" target="#b9">Chen et al. (2022)</ref> define a pair of events as a node and build a complete event relational graph to capture the causation transitivity among event pairs via a graph transformer.</p><p>(5) GPT-3.5 We use gpt-3.5-turbo with zero-shot / few-shot learning on this complex multilingual task. The prompt is shown in Figure <ref type="figure">5</ref> and languagespecific prompts can be found in Appendix B. Table <ref type="table">4</ref>: The Performance in low-resource settings. We separately report the cross-lingual performance with low-source language Danish, Spanish, Turkish, and Urdu as source language.</p><p>Task Description: Answer the causal relationship between event mentions from the given passage. The relation has to be of the type: "CauseEffect" means that the former event is the cause of the latter event,"EffectCause" means that the former event is the effect of the latter event,"NoRel" means that the two events have no causal relationship.</p><p>Here are an example: Passage: One of the &lt;T0&gt; surviving &lt;T0&gt; passengers , an eight -year -old in 1978 , was &lt;T1&gt; awarded &lt;T1&gt; US $ 900,000 in &lt;T2&gt; damages &lt;T2&gt; from the airline by a Portland jury in 1984… Filling the relations: {"T0-T1": "&lt;One of the above mentioned relations&gt;", "T1-T0": "&lt;One of the above mentioned relations&gt;", "T2-T1": "&lt;One of the above mentioned relations&gt;", … } Filled relations: {"T0-T1": "CauseEffect","T1-T0": "EffectCause", "T2-T1": "CauseEffect", … } Note: &lt;T&gt;event&lt;T&gt; marks the position of event mention in passage, with T as the code name of the event mention. Fills these following relations and returns the filled json file. Passage: {passage} Filling the relation: {relation_to_fill} Filled relations:</p><p>Figure <ref type="figure">5</ref>: Few-shot prompt for English. We set language specific prompts for different source languages. The passage and relations are truncated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Main Results (1) The Performance in Monolingual Setting</head><p>The results is illustrated in Table <ref type="table">2</ref>, in this monolingual setting, we observe that our model GIMC (base version), which removes contrastive learning module, achieves the best performance across all languages, and outperforms RichGCN across all settings with an average improvement of 9.4% in F1 score. It is worth noting that we test the effectiveness of our method with different PLMs as the backbone. The significant improvement of our method over the vanilla PLM (18.8%) suggests that the success of our model can be attributed to the effectiveness of our method rather than the backbone. These baselines without well-designed cross-lingual module, rely almost on multilingual backbones, perform poorly when transferring to other languages. However our model can cope well with all language settings, even for Danish (an average increase of 16.4% compared with RichGCN).</p><p>(2) The Performance in High-Resource Setting As shown in Table <ref type="table">3</ref>, the entire GIMC performs surprisingly well on all languages. Comparing with the results of the baseline RichGCN with mBERT, GIMC pushes the average F1 score from 41.8% to 52.1% and effectively reduces performance fluctuations (i.e., ∆) during transfer to other languages. Note that the performance of RichGCN with mBERT drops significantly for three target languages Danish (by 25.1%), Spanish (by 25.7%), and Urdu (by 12.9%), we observed the same trend in our experiments with GPT-3.5, demonstrating that despite extensive training on high-resource language English, LLM fails to achieve plug-and-play functionality when faced with complex cross-lingual tasks, which is consistent with Lai et al. ( <ref type="formula">2023</ref>).</p><p>(3) The Performance in Low-Resource Setting Since English as high-resource language may benefit more from PLMs than other languages, we further conduct experiments with low-resource lan- guage as source language. We utilize mBERT as our backbone due to its superior performance in the above experiments. As shown in Table <ref type="table">4</ref>, GIMC improves average performance and fluctuation in all language settings and achieves double first in monolingual performance (by 64.7%) and crosslingual transfer performance (by 56.6%) on Turkish.</p><p>Contrarily, the GPT-3.5 performs unsatisfactorily (with an average performance 24.9% lower than GIMC). Moreover, The drop of RichGCN for Urdu → Turkish is smaller compared to ours. It suggests that the baseline might be sensitive to certain specific languages, whereas our model demonstrates consistently strong performance across all settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Effects of Heterogeneous Graph Interaction Network</head><p>To investigate the effectiveness of our graph interaction network, we conduct the ablation studies as shown in Table <ref type="table">5</ref>, the F1 score would decreases 1.3% ~3.8% without the top five types of edges.</p><p>Besides, removing the E-E edge causes an significant drop by 4.2%, which is consistent with "preserving transitivity of causation" <ref type="bibr" target="#b32">(Paul et al., 2013;</ref><ref type="bibr" target="#b9">Chen et al., 2022)</ref>, each edge represents a possible causal pattern transitivity between the event pair. Despite a slight decrease in performance when using other information aggregation methods such as GCN, our method is still competitive. Ablation experiments demonstrates that our graph interaction network helps improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Effects of Cross-lingual Contrastive Transfer Learning Module</head><p>As depicted in the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Cross-lingual Transfer Effect of Different Languages</head><p>We plot the performance of zero-shot cross-lingual transfer using different languages as source language in Figure <ref type="figure" target="#fig_6">6</ref>. GIMC achieves best crosslingual performance on Turkish, due to more data and possibly greater linguistic transferability. The large gap between the performance of model on Spanish in monolingual setting and cross-lingual setting leads to its high fluctuation. The drop on Danish much smaller than on other languages, e.g. da-en, which is partly attribute to the effectiveness of our cross-language module, and partly may because of the features of the language such as language families (both Danish and English belong to the Germanic language family). Due to its distinct morphology and syntax compared to the other four languages, Urdu exhibits below-average performance, warranting further attention in future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Work Event Causality Identification</head><p>Most event causality identification (ECI) methods focus on sentence-level, and the corresponding datasets are mainly English corpora. <ref type="bibr">Liu et al. (2020a)</ref> proposes a mention masking generalization mechanism to learn event-agnostic, context-specific pat-terns. <ref type="bibr" target="#b49">Zuo et al. (2021)</ref> designs a self-supervised framework to learn context-specific causal patterns from causal statements. However, these sentencelevel models fail to predict the causality expressed by multiple sentences. So <ref type="bibr" target="#b19">Gao et al. (2019)</ref> leverages Integer Linear Programming (ILP) to model document-level structures for ECI. Tran Phu and Nguyen (2021) constructs several document-level interaction graphs and uses GCN to capture relevant context information. <ref type="bibr" target="#b9">Chen et al. (2022)</ref> proposes a concise graph network with event pairs as nodes to model the transitivity of causation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-lingual Transfer Learning</head><p>Recently, cross-lingual contextualized embeddings have achieved promising results. e.g., mBERT <ref type="bibr" target="#b17">(Devlin et al., 2019)</ref>, XLMR <ref type="bibr" target="#b13">(Conneau et al., 2020)</ref>. Further studies also consider aligning representations between source and target languages during finetuning. <ref type="bibr">Liu et al. (2020b)</ref> proposes task-related parallel word pairs to generate code-switching sentences for learning the interlingual semantics across languages. <ref type="bibr" target="#b35">Qin et al. (2020)</ref> leverage a data augmentation framework to generate multi-lingual codeswitching data to fine-tune mBERT. <ref type="bibr" target="#b34">Qin et al. (2022)</ref> proposes a global-local contrastive learning framework for cross-lingual spoken language understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose Heterogeneous Graph Interaction Model with Multi-granularity Contrastive Transfer Learning (GIMC) to simultaneously address document-level and zero-shot cross-lingual ECI. We design a multi-granularity contrastive transfer learning module to align causal representations across language. We construct a heterogeneous graph interaction network to model long-distance dependencies between events. Experiments on Multilingual dataset show the effectiveness of our method in both monolingual and multilingual scenarios. Despite extensive training on high-resource language English, GPT-3.5 with few-shot prompts fails to achieve plug-and-play functionality in crosslingual task, it appears more practical to develop smaller task-specific models for complex multilingual problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Limitations</head><p>This paper are towards the task of zero-shot crosslingual document-level event causality identification. This work has certain limitations. Firstly, due to lack of dataset, we only conduct experiments on MECI, which is the largest multilingual event causality identification dataset by far, however, the dataset only contain five languages across diverse typologies. It would be beneficial to test the effectiveness of our method on other low-resource language in the future. Secondly, limited by computation resources, our experiments only employ the language-specific PLMs as previous work and the base versions of multilingual PLMs, mBERT and XLMR. Different pre-trained language model as encoder could produce different results. Thirdly, constrained by the high computational cost of API calls, we only conducted analysis on GPT-3.5 with few-shot prompts, thus unable to provide comparisons with other popular LLMs such as <ref type="bibr">GPT-4 (OpenAI, 2023)</ref>. Furthermore, while we crafted task-specific prompts for GPT-3.5, it could be intriguing to explore additional prompts for testing purposes. We expect future research to encompass a broader range of languages and models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dependency Relations</head><p>The table 7 lists the 19 dependency relations we used in this paper. The upper part of the table follows the main organizing principles of the UD taxonomy such that rows correspond to functional categories in relation to the head while columns correspond to structural categories of the dependent. The lower part of the table lists relations that are not dependency relations in the narrow sense.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiment Details of GPT-3.5 B.1. Prompts</head><p>In the monolingual setting, we employ a zero-shot prompt as illustrated in Figure <ref type="figure" target="#fig_8">8</ref>. We provide a task description and specify the required output format. In the multilingual setting, we have designed five different language-specific few-shot prompts. In each prompt, we provide a document and 13 event pairs, where the events mentioned in the document are marked with special symbols (i.e., &lt;T&gt;). Among the 13 event pairs, 8 are causal event pairs, and 5 are unrelated event pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Analysis</head><p>Models were queried through the OpenAI API between December 2022 and May 2023. We illustrate the multilingual performance of GPT-3.5 in Figure <ref type="figure">7</ref>. It can be observed that GPT-3.5 performs the best in English and the worst in Urdu. This indicates that GPT-3.5 has insufficient understanding of languages other than English, especially lowresource language. Moreover, even in the case of high-resource language English, the overall performance of GPT-3.5 is below 30%. In addition to the possibility of imperfect prompt design, this outcome is highly likely to be attributed to the complexity of the task and the differences between languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Description:</head><p>Answer the causal relationship between event mentions from the given passage. The relation has to be of the type: "CauseEffect" means that the former event is the cause of the latter event,"EffectCause" means that the former event is the effect of the latter event,"NoRel" means that the two events have no causal relationship.</p><p>Note: &lt;T&gt;event&lt;T&gt; marks the position of event mention in passage, with T as the code name of the event mention. Your output must only be the relation of the two given event mentions. Fills these following relations and returns the filled json file. Do not add any redundant information except filled json file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Passage: {passage}</head><p>Filling the relation: {relation_to_fill} Filled relations: Task Description: Answer the causal relationship between event mentions from the given passage. The relation has to be of the type: "CauseEffect" means that the former event is the cause of the latter event,"EffectCause" means that the former event is the effect of the latter event,"NoRel" means that the two events have no causal relationship.</p><p>Here are an example: Passage: One of the &lt;T0&gt; surviving &lt;T0&gt; passengers , an eight -year -old in 1978 , was &lt;T1&gt; awarded &lt;T1&gt; US $ 900,000 in &lt;T2&gt; damages &lt;T2&gt; from the airline by a Portland jury in 1984 . She was &lt;T3&gt; injured &lt;T3&gt; and both of her parents were &lt;T4&gt; killed &lt;T4&gt; . &lt;T5&gt; Published &lt;T5&gt; in February 2018 , _ Crash Course _ by Julie Whipple &lt;T7&gt; focuses &lt;T7&gt; on the &lt;T8&gt; events &lt;T8&gt; of the night of the &lt;T9&gt; crash &lt;T9&gt; , the &lt;T10&gt; investigation &lt;T10&gt; , and aftermath of the &lt;T11&gt; crash &lt;T11&gt; . -The events of &lt;T13&gt; Flight &lt;T13&gt; 173 were &lt;T14&gt; featured &lt;T14&gt; in " Focused on Failure " , a season -12 ( 2012 ) episode of the Canadian TV series _ Mayday _ ( called _ Air Emergency _ in the US and _ Air Crash Investigation _ in the UK and elsewhere around the world ) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filling the relations:</head><p>{"T0-T1": "&lt;One of the above mentioned relations&gt;", "T1-T0": "&lt;One of the above mentioned relations&gt;", "T2-T1": "&lt;One of the above mentioned relations&gt;","T1-T2": "&lt;One of the above mentioned relations&gt;", "T13-T14": "&lt;One of the above mentioned relations&gt;","T14-T13": "&lt;One of the above mentioned relations&gt;","T5-T7": "&lt;One of the above mentioned relations&gt;","T7-T5": "&lt;One of the above mentioned relations&gt;","T0-T10": "&lt;One of the above mentioned relations&gt;","T1-T7": "&lt;One of the above mentioned relations&gt;","T11-T1": "&lt;One of the above mentioned relations&gt;","T11-T9": "&lt;One of the above mentioned relations&gt;","T13-T18": "&lt;One of the above mentioned relations&gt;"} Filled relations: {"T0-T1": "CauseEffect","T1-T0": "EffectCause", "T2-T1": "CauseEffect","T1-T2": "EffectCause","T13-T14":"CauseEffect","T14-T13":"EffectCause","T5-T7": "CauseEffect","T7-T5": "EffectCause","T0-T10": "NoRel","T1-T7": "NoRel","T11-T1": "NoRel","T11-T9": "NoRel","T13-T18": "NoRel"} Note: &lt;T&gt;event&lt;T&gt; marks the position of event mention in passage, with T as the code name of the event mention. Your output must only be the relation of the two given event mentions. Fills these following relations and returns the filled json file. Do not add any redundant information except filled json file. Passage: {passage} Filling the relation: {relation_to_fill} Filled relations: Besvar å rsagssammenhaengen mellem begivenhedsomtaler fra den givne passage. Relationen skal vaere af typen: "CauseEffect" betyder, at den førstnaevnte haendelse er å rsagen til den sidstnaevnte haendelse,"EffectCause" betyder, at den førstnaevnte haendelse er virkningen af den sidstnaevnte haendelse,"NoRel" betyder, at de to haendelser har ingen å rsagssammenhaeng.</p><p>Here are an example: Passage: Det nordamerikanske luftrum holdt &lt;T0&gt; lukket &lt;T0&gt; i flere dage efter &lt;T1&gt; angrebene &lt;T1&gt; , hvilket førte til en &lt;T2&gt; nedskaering &lt;T2&gt; pånaesten 20 % i lufttrafikkens kapacitet . Som følge af tvillingetå rnenes &lt;T12&gt; kollaps &lt;T12&gt; blev mere end 2.500 forurenende stoffer , herunder kendte kraeftfremkaldende stoffer , &lt;T11&gt; spredt &lt;T11&gt; ud over Manhattan . Dette har &lt;T3&gt; ført &lt;T3&gt; til invaliderende &lt;T4&gt; sygdomme &lt;T4&gt; blandt redningsarbejderne . For eksempel &lt;T5&gt; døde &lt;T5&gt; NYPD-officeren Frank Macrìaf lungekraeft , der havde &lt;T13&gt; bredt sig i &lt;T13&gt; hele hans krop , den 3. september 2007 ; hans familie har &lt;T6&gt; taget &lt;T6&gt; hans &lt;T7&gt; kraeftsygdom &lt;T7&gt; som et resultat af den lange arbejdstid , som han har &lt;T8&gt; haft &lt;T8&gt; påstedet . &lt;T9&gt; Effekter &lt;T9&gt; på helbredet &lt;T10&gt; udvidede &lt;T10&gt; sig ligeledes til nogle beboere , studerende og kontorarbejdere i Lower Manhattan samt i naerheden af Chinatown .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filling the relations:</head><p>{"T1-T2": "&lt;En af de ovennaevnte relationer&gt;", "T2-T1": "&lt;En af de ovennaevnte relationer&gt;", "T1-T0": "&lt;En af de ovennaevnte relationer&gt; ","T0-T1": "&lt;En af de ovennaevnte relationer&gt;", "T12-T11": "&lt;En af de ovennaevnte relationer&gt;","T11-T12": "&lt;En af de ovennaevnte relationer &gt;","T11-T3": "&lt;En af de ovennaevnte relationer&gt;","T3-T11": "&lt;En af de ovennaevnte relationer&gt;","T0-T13": "&lt;En af de ovenfor naevnte relations&gt;","T0-T3": "&lt;En af de ovennaevnte relationer&gt;","T0-T9": "&lt;En af de ovennaevnte relationer&gt;","T1-T13": "&lt;En af ovenstå ende naevnte relationer&gt;","T1-T3": "&lt;En af de ovennaevnte relationer&gt;"} Filled relations: {'T1-T2': 'CauseEffect', 'T2-T1': 'EffectCause', 'T1-T0': 'CauseEffect', 'T0-T1': 'EffectCause', 'T12-T11': 'CauseEffect', 'T11-T12': 'EffectCause', 'T11-T3': 'CauseEffect', 'T3-T11': 'EffectCause','T0-T13': 'NoRel', 'T0-T3': 'NoRel', 'T0-T9': 'NoRel', 'T1-T13': 'NoRel', 'T1-T3': 'NoRel'} Note: &lt;T&gt;haendelse&lt;T&gt; markerer positionen for haendelsesomtale i passage, med T som kodenavn påhaendelsesomtalen. Dit output måkun vaere relationen mellem de to givne begivenhedsomtaler. Udfylder disse følgende relationer og returnerer den udfyldte json-fil. Tilføj ikke nogen overflødig information undtagen udfyldt json-fil. Passage: {passage} Filling the relation: {relation_to_fill} Filled relations: Responda la relación causal entre las menciones de eventos del pasaje dado. La relación tiene que ser del tipo: "CauseEffect" significa que el primer evento es la causa del último evento, "EffectCause" significa que el primer evento es el efecto del último evento, "NoRel" significa que los dos eventos tienen sin relación de causalidad.</p><p>Here are an example: Passage: El VUELO 821 DE AEROFLOT , &lt;T0&gt; operado &lt;T0&gt; por la aerolí nea Aeroflot-Nord , se &lt;T1&gt; estrelló&lt;T1&gt; el durante su &lt;T2&gt; aproximación &lt;T2&gt; al aeropuerto Bolshoe Savino de la ciudad de Perm , Rusia . Este &lt;T11&gt; desastre &lt;T11&gt; aé reo provocóel &lt;T4&gt; cambio &lt;T4&gt; de marca de Aeroflot-Nord en Nordavia , efectivo el 1 de diciembre de 2009 . Todos los 83 pasajeros y 5 miembros de la tripulación &lt;T5&gt; fallecieron &lt;T5&gt; . La aeronave , un Boeing 737 con &lt;T6&gt; registro &lt;T6&gt; VP-BKO , &lt;T7&gt; despegó &lt;T7&gt; del aeropuerto de Moscú-Sheremetyevo con destino a la ciudad de Perm , al pie de los montes Urales . La causa principal del &lt;T8&gt; accidente &lt;T8&gt; fue que ambos pilotos habí an &lt;T9&gt; perdido &lt;T9&gt; la orientación espacial debido a su &lt;T10&gt; inexperiencia &lt;T10&gt; con el tipo de indicador de actitud occidental en el avión .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filling the relations:</head><p>{'T11-T4': '&lt;Una de las relaciones mencionadas anteriormente&gt;', 'T4-T11': '&lt; Una de las relaciones mencionadas anteriormente&gt;', 'T1-T5': '&lt; Una de las relaciones mencionadas anteriormente&gt;', 'T5-T1': '&lt; Una de las relaciones mencionadas anteriormente&gt;', 'T9-T8': '&lt; Una de las relaciones mencionadas anteriormente&gt;', 'T8-T9': '&lt; Una de las relaciones mencionadas anteriormente&gt;', 'T10-T9': '&lt; Una de las relaciones mencionadas anteriormente&gt;', 'T9-T10': '&lt; Una de las relaciones mencionadas anteriormente&gt;', 'T0-T2': '&lt; Una de las relaciones mencionadas anteriormente&gt;', 'T0-T5': '&lt; Una de las relaciones mencionadas anteriormente&gt;', 'T0-T7': '&lt; Una de las relaciones mencionadas anteriormente&gt;', 'T0-T9': '&lt; Una de las relaciones mencionadas anteriormente&gt;', 'T1-T2': '&lt; Una de las relaciones mencionadas anteriormente&gt;'} Filled relations: {'T11-T4': 'CauseEffect', 'T4-T11': 'EffectCause', 'T1-T5': 'CauseEffect', 'T5-T1': 'EffectCause', 'T9-T8': 'CauseEffect', 'T8-T9': 'EffectCause', 'T10-T9': 'CauseEffect', 'T9-T10': 'EffectCause', 'T0-T2': 'NoRel', 'T0-T5': 'NoRel', 'T0-T7': 'NoRel', 'T0-T9': 'NoRel', 'T1-T2': 'NoRel'} Note: &lt;T&gt;event&lt;T&gt; marca la posición de la mención del evento en el pasaje, con T como el nombre en clave de la mención del evento. Su salida solo debe ser la relación de las dos menciones de eventos dadas. Rellena las siguientes relaciones y devuelve el archivo json relleno. No agregue ninguna información redundante, excepto el archivo json lleno. Passage: {passage} Filling the relation: {relation_to_fill} Filled relations: Verilen pasajdaki olaylar arasındaki nedensel ilişkiyi yanıtlayın. İlişki şu türden olmalıdır: "CauseEffect", önceki olayın sonraki olayın nedeni olduğu anlamına gelir, "EffectCause", önceki olayın sonraki olayın etkisi olduğu anlamına gelir, "NoRel", iki olayın olduğu anlamına gelir nedensel ilişki yok.</p><p>Here are an example: Passage: Muhalefetteki Ata Meken Sosyalist Partisi milletvekili Ömürbek Tekebayev kargo enkazında Rusç a ve Kırgızca etiket basılı ürünler bulunduğunu ve bu ürünlerin açıkça Kırgızistan pazarına yönelik olduğunu &lt;T0&gt; söyledi &lt;T0&gt; . Ayrıca &lt;T1&gt; katıldığı &lt;T1&gt; bir parlamento toplantısında bir Türkiye şirketinden mektup aldığını ; uç akta Bişkek'e gelmeden direkt olarak İstanbul'a gitmesine yetecek yakıtın bulunduğunu ve uçağın , kargoların Bişkek'te &lt;T2&gt; boşaltılması &lt;T2&gt; iç in &lt;T12&gt; geldiğini &lt;T12&gt; ve hükûmetin doğruları &lt;T13&gt; sakladığını &lt;T3&gt; &lt;T13&gt; söyledi &lt;T3&gt; . Havalimanı gümrüğünün kargodan haberi olmadığı iç in bazı haberler kargonun kaç ak olabileceğini &lt;T4&gt; yazdı &lt;T4&gt; . 27 Ocak'ta nakliye firması Global Link Logistics , Hong Kong'dan gelen bir ACT Airlines uçağının Manas Havalimanı'na &lt;T17&gt; varmasını &lt;T18&gt; &lt;T17&gt; beklediğini &lt;T5&gt; &lt;T18&gt; açıkladı &lt;T5&gt; . Tekebayev bunun ardından havalimanında &lt;T19&gt; kaçakçılık &lt;T19&gt; veya &lt;T20&gt; yolsuzluk &lt;T20&gt; yapılıyor olabileceğini &lt;T7&gt; söyledi &lt;T7&gt; .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filling the relations:</head><p>{"T2-T12": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T12-T2": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T13-T3": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T3-T13": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T1-T5": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T5-T1": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T1-T7": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T7-T1": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T0-T12": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T0-T17": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T0-T18": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T0-T4": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;","T1-T13": "&lt;Yukarıda belirtilen ilişkilerden biri&gt;"} Filled relations: {"T2-T12": "CauseEffect", "T12-T2": "EffectCause", "T13-T3": "CauseEffect","T3-T13": "EffectCause","T1-T5": "CauseEffect","T5-T1": "EffectCause","T1-T7": "CauseEffect","T7-T1": "EffectCause","T0-T12": "NoRel","T0-T17": "NoRel","T0-T18": "NoRel","T0-T4": "NoRel","T1-T13": "NoRel"} Note: &lt;T&gt;event&lt;T&gt;, geçişte olay bahsinin konumunu, olay bahsinin kod adı olarak T ile işaretler. Çıktınız yalnızca verilen iki olay bahsinin ilişkisi olmalıdır. Aşağıdaki ilişkileri doldurur ve doldurulmuş json dosyasını döndürür. Doldurulmuş json dosyası dışında herhangi bir gereksiz bilgi eklemeyin. Passage: {passage} Filling the relation: {relation_to_fill} Filled relations: </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: Zero-shot cross-lingual document-level event causality identification. Data is non-parallel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: We show event-relevant sentences.Events are colored and we underline the informative phrases related to colored events. Red lines and gray lines indicate the causal relations and arguments of events, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example of informative phrase extraction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>On 25 November 2019, two French military helicopters crashed in northern Mali, 13 soldiers on board ...[2] It was the deadliest ... [3] A French Eurocopter Tiger ... [4] The helicopters were ... [5] ... two military helicopters lost contact, killing all soldiers on board.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Overview of our proposed heterogeneous graph interaction network with multi-granularity contrastive transfer learning (GIMC) for zero-shot cross-lingual document-level ECI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Average F1 score (AVG) and fluctuation (∆) of GIMC with different source language.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure 7: Average F1 score(AVG) and fluctuation(∆) of GPT-3.5 with different language specific prompt.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Zero-shot prompt for GPT-3.5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: English few-shot prompt</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Danish few-shot prompt</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Spanish few-shot prompt</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Turkish few-shot prompt</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>On 25 November 2019, two French military helicopters crashed in northern Mali, 13 soldiers on board died in the accident. [2] It was the deadliest incident involving the French military since the 1983 Beirut barracks bombings. [3] A French Eurocopter Tiger attack helicopter collided with ... [4] The helicopters were in the midst of pursuing militants ... [5] For unknown reasons, two military helicopters lost contact, killing all soldiers on board.</figDesc><table><row><cell>[1]</cell><cell></cell></row><row><cell>crashed</cell><cell>killing</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>b) Dependency tree with informative phrase Sentence: On</head><label></label><figDesc>25 November 2019, two French military helicopters crashed in northern Mali, 13 soldiers on board died in the accident.</figDesc><table><row><cell></cell><cell cols="2">crashed</cell><cell></cell><cell></cell><cell cols="2">paratexis</cell><cell>died</cell></row><row><cell></cell><cell>obl</cell><cell>nsubj</cell><cell></cell><cell>obl</cell><cell></cell><cell>nsubj</cell><cell>obl</cell></row><row><cell></cell><cell>November</cell><cell cols="3">helicopters</cell><cell>Mali</cell><cell>soldiers accident</cell></row><row><cell>case</cell><cell cols="3">nummod nummod nummod amod</cell><cell cols="3">amod case</cell><cell>amod</cell><cell>13 nummod nomd board</cell><cell>in the case det</cell></row><row><cell cols="2">On 25 2019</cell><cell cols="4">two French military</cell><cell>in northern</cell><cell>on case</cell></row><row><cell></cell><cell></cell><cell cols="5">(a) Dependency tree</cell></row><row><cell></cell><cell cols="2">crashed</cell><cell></cell><cell></cell><cell cols="2">paratexis</cell><cell>died</cell><cell>obl</cell></row><row><cell></cell><cell>obl</cell><cell></cell><cell>obl</cell><cell></cell><cell></cell></row><row><cell cols="3">On 25 November 2019</cell><cell cols="4">nsubj in northern Mali</cell><cell>nsubj</cell><cell>in the accident</cell></row><row><cell></cell><cell cols="6">two French military helicopters</cell><cell>13 soldiers on board</cell></row><row><cell cols="2">(</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1 https://universaldependencies.org/u/dep/</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>index.html</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics for the MECI dataset.</figDesc><table><row><cell>Language</cell><cell>Document</cell><cell>Relation</cell><cell>Event</cell><cell>Distance</cell></row><row><cell>Danish</cell><cell>519</cell><cell>1377</cell><cell>6909</cell><cell>22</cell></row><row><cell>English</cell><cell>438</cell><cell>2050</cell><cell>8732</cell><cell>40</cell></row><row><cell>Spanish</cell><cell>746</cell><cell>1312</cell><cell>11839</cell><cell>39</cell></row><row><cell>Turkish</cell><cell>1357</cell><cell>5337</cell><cell>14179</cell><cell>33</cell></row><row><cell>Urdu</cell><cell>531</cell><cell>979</cell><cell>4975</cell><cell>23</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Performance of GIMC on ablation study for cross-lingual contrastive transfer learning module.</figDesc><table><row><cell>Model</cell><cell cols="5">English Danish Spanish Turkish Urdu AVG</cell><cell>∆</cell></row><row><cell>GIMC</cell><cell>59.6</cell><cell>48.0</cell><cell>53.9</cell><cell>50.3</cell><cell>48.8 52.1</cell><cell>9.4</cell></row><row><cell>GIMC(GCN)</cell><cell>58.6</cell><cell>47.5</cell><cell>50.4</cell><cell>47.1</cell><cell cols="2">48.3 50.4 10.2</cell></row><row><cell>-P-P</cell><cell>57.3</cell><cell>43.2</cell><cell>49.2</cell><cell>46.6</cell><cell cols="2">45.4 48.3 11.2</cell></row><row><cell>-S-P</cell><cell>58.3</cell><cell>46.4</cell><cell>53.0</cell><cell>49.2</cell><cell>46.3 50.6</cell><cell>9.6</cell></row><row><cell>-P-E</cell><cell>58.8</cell><cell>47.5</cell><cell>52.2</cell><cell>48.3</cell><cell cols="2">47.2 50.8 10.0</cell></row><row><cell>-S-E</cell><cell>57.9</cell><cell>45.5</cell><cell>51.5</cell><cell>46.1</cell><cell cols="2">47.6 49.7 10.2</cell></row><row><cell>-St-E</cell><cell>58.9</cell><cell>48.4</cell><cell>51.2</cell><cell>47.5</cell><cell cols="2">46.1 50.4 10.6</cell></row><row><cell>-E-E</cell><cell>57.5</cell><cell>43.3</cell><cell>47.6</cell><cell>45.7</cell><cell cols="2">45.5 47.9 12.0</cell></row><row><cell cols="7">Table 5: The ablation experiments of GIMC's het-</cell></row><row><cell cols="7">erogeneous graph interaction network. We directly</cell></row><row><cell cols="7">report the F1 scores (%) in the zero-shot cross-</cell></row><row><cell cols="7">lingual setting using English as source language.</cell></row><row><cell>Model</cell><cell cols="5">English Danish Spanish Turkish Urdu AVG</cell><cell>∆</cell></row><row><cell>GIMC</cell><cell>59.6</cell><cell>48.0</cell><cell>53.9</cell><cell>50.3</cell><cell>48.8 52.1</cell><cell>9.4</cell></row><row><cell>GIMCword</cell><cell>61.2</cell><cell>47.2</cell><cell>51.6</cell><cell>50.6</cell><cell cols="2">48.3 51.8 11.8</cell></row><row><cell>GIMC(base)</cell><cell>58.8</cell><cell>44.2</cell><cell>49.7</cell><cell>46.8</cell><cell cols="2">47.6 49.4 11.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>, the overall performance</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Nominals Clauses Modifier words Core arguments</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>nsubj</cell><cell></cell><cell></cell></row><row><cell></cell><cell>nsubj:pass obj</cell><cell>csubj</cell><cell></cell></row><row><cell></cell><cell>iobj</cell><cell></cell><cell></cell></row><row><cell></cell><cell>obl</cell><cell></cell><cell></cell></row><row><cell></cell><cell>obl:loc</cell><cell></cell><cell></cell></row><row><cell>Non-core dependents</cell><cell>obl:tmod</cell><cell>advcl</cell><cell>advmod</cell></row><row><cell></cell><cell>obl:npmod</cell><cell></cell><cell></cell></row><row><cell></cell><cell>dislocated</cell><cell></cell><cell></cell></row><row><cell>Nominal dependents</cell><cell>appos</cell><cell>acl acl:relcl</cell><cell></cell></row><row><cell>Coordination</cell><cell cols="2">Loose</cell><cell>Other</cell></row><row><cell>conj</cell><cell cols="2">list parataxis</cell><cell>root</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Dependencies with rich semantics that we reserved in this paper</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://huggingface.co/Maltehb/ danish-bert-botxo</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://github.com/urduhack/urduhack</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7.">Acknowledgements</head><p>This work is supported by the <rs type="funder">National Key Research and Development Program of China</rs> (No. <rs type="grantNumber">2022ZD0160503</rs>), the <rs type="funder">National Natural Science Foundation of China</rs> (No. <rs type="grantNumber">62176257</rs> ). This work is also supported by the <rs type="funder">Youth Innovation Promotion Association CAS</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_QvQrSY3">
					<idno type="grant-number">2022ZD0160503</idno>
				</org>
				<org type="funding" xml:id="_7BJT3tN">
					<idno type="grant-number">62176257</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Description:</head><p>Here are an example: Filling the relations:</p><p>{"T0-T4":</p><p>, "T4-T0":</p><p>, "T7-T10":</p><p>, "T1-T5":</p><p>Filled relations: {"T0-T4": "CauseEffect","T4-T0": "EffectCause", "T0-T5": "CauseEffect", "T5-T0": "EffectCause", "T7-T6": "CauseEffect","T6-T7": "EffectCause","T10-T7": "CauseEffect","T7-T10": "EffectCause","T0-T1": "NoRel","T0-T3": "NoRel","T1-T3": "NoRel","T1-T5": "NoRel","T1-T6": "NoRel"}  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Using a bigram event model to predict causal potential</title>
		<author>
			<persName><forename type="first">Bibliographical</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Beamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roxana</forename><surname>Girju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Text Processing and Computational Linguistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="430" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The life cycle of knowledge in big language models: A survey</title>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boxi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11633-023-1416-x</idno>
	</analytic>
	<monogr>
		<title level="j">Machine Intelligence Research</title>
		<imprint>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">How attentive are graph attention networks</title>
		<author>
			<persName><forename type="first">Shaked</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Yahav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Spanish pre-trained bert model and evaluation data</title>
		<author>
			<persName><forename type="first">José</forename><surname>Canete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Chaperon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Fuentes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jou-Hui</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hojin</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pml</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2020</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Peng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Knowledge-enriched event causality identification via latent structure induction networks</title>
		<idno type="DOI">10.18653/v1/2021.acl-long.376</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4862" to="4872" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The event storyline corpus: A new benchmark for causal and temporal relation extraction</title>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piek</forename><surname>Vossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Events and Stories in the News Workshop</title>
		<meeting>the Events and Stories in the News Workshop</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="77" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jindong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaijie</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yidong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.03109</idno>
		<title level="m">A survey on evaluation of large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ERGO: Event relational graph transformer for document-level event causality identification</title>
		<author>
			<persName><forename type="first">Meiqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunquan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mukai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Computational Linguistics</title>
		<meeting>the 29th International Conference on Computational Linguistics<address><addrLine>Gyeongju, Republic of Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2118" to="2128" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">CHEER: Centrality-aware highorder event reasoning network for documentlevel event causality identification</title>
		<author>
			<persName><forename type="first">Meiqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.acl-long.604</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="10804" to="10816" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<title level="m">Palm: Scaling language modeling with pathways</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Eventnarrative: A large-scale event-centric dataset for knowledge graph-to-text generation</title>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Colas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daisy</forename><forename type="middle">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.00276</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartikay</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.747</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Explaining answers with entailment trees</title>
		<author>
			<persName><forename type="first">Bhavana</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengnan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leighanna</forename><surname>Pipatanangkura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.585</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7358" to="7370" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Universal stanford dependencies: A cross-linguistic typology</title>
		<author>
			<persName><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Silveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katri</forename><surname>Haverinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="4585" to="4592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The stanford typed dependencies representation</title>
		<author>
			<persName><forename type="first">Marie-Catherine</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marneffe</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Coling 2008: proceedings of the workshop on cross-framework and crossdomain parser evaluation</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Towards event-level causal relation identification</title>
		<author>
			<persName><forename type="first">Chuang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daoxing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Libo</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1828" to="1833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Modeling document-level causal structures for event causal relation identification</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kumar Choubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1179</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1808" to="1817" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semantic structure enhanced event causality identification</title>
		<author>
			<persName><forename type="first">Zhilei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saiping</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.acl-long.610</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="10901" to="10913" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Not all languages are created equal in llms: Improving multilingual capability by cross-lingual-thought prompting</title>
		<author>
			<persName><forename type="first">Haoyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.07004</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Event causality recognition exploiting multiple annotators&apos; judgments and background knowledge</title>
		<author>
			<persName><forename type="first">Kazuma</forename><surname>Kadowaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kentaro</forename><surname>Torisawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong-Hoon</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Kloetzer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1590</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5816" to="5822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Dac</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nghia Trung</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Pouran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Veyseh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trung</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien Huu</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.05613</idno>
		<title level="m">Chatgpt beyond english: Towards a comprehensive evaluation of large language models in multilingual learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multimodal pretraining from monolingual to multilingual</title>
		<author>
			<persName><forename type="first">Ludan</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anwen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Jin</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11633-022-1414-4</idno>
	</analytic>
	<monogr>
		<title level="j">Machine Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="220" to="232" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Knowledge enhanced event causality identification with mention masking generalizations</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2020/499</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20</title>
		<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3608" to="3614" />
		</imprint>
	</monogr>
	<note>International Joint Conferences on Artificial Intelligence Organization. Main track</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Attentioninformed mixed-language training for zero-shot cross-lingual task-oriented dialogue systems</title>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaojiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8433" to="8440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<title level="m">Decoupled weight decay regularization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Extracting temporal and causal relations between events</title>
		<author>
			<persName><forename type="first">Paramita</forename><surname>Mirza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2014 Student Research Workshop</title>
		<meeting>the ACL 2014 Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="10" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Trankit: A light-weight transformer-based toolkit for multilingual natural language processing</title>
		<author>
			<persName><forename type="first">Minh</forename><surname>Van Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dac</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Pouran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien Huu</forename><surname>Veyseh</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-demos.10</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="80" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<title level="m">Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<title level="m">Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Laurie</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ned</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">Jonathan</forename><surname>Hall</surname></persName>
		</author>
		<title level="m">Causation: A user&apos;s guide</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Enhancing event causality identification with event causal label and event pair interaction graph</title>
		<author>
			<persName><forename type="first">Ruili</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suge</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianxing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Liao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.findings-acl.655</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<meeting><address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="10314" to="10322" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Gl-clef: A global-local contrastive learning framework for cross-lingual spoken language understanding</title>
		<author>
			<persName><forename type="first">Libo</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qixin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.08325</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Cosda-ml: Multi-lingual codeswitching data augmentation for zero-shot crosslingual nlp</title>
		<author>
			<persName><forename type="first">Libo</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minheng</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2020/533</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20</title>
		<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3853" to="3860" />
		</imprint>
	</monogr>
	<note>International Joint Conferences on Artificial Intelligence Organization. Main track</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Searching news articles using an event knowledge graph leveraged by wikidata</title>
		<author>
			<persName><forename type="first">Charlotte</forename><surname>Rudnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Ehrhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Ferret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Teyssou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raphaël</forename><surname>Troncy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion proceedings of the 2019 world wide web conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1232" to="1239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Enhanced english universal dependencies: An improved representation for natural language understanding tasks</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2371" to="2378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Berturk -bert models for turkish</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Schweter</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3770924</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An open multilingual graph of general knowledge</title>
		<author>
			<persName><forename type="first">J</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C Conceptnet</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016-12">2016. December 2016</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="4444" to="4451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dehai</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongrui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guilin</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.07992</idno>
		<title level="m">Evaluation of chatgpt as a question answering system for answering complex questions</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Graph convolutional networks for event causality identification with rich document-level structures</title>
		<author>
			<persName><forename type="first">Minh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phu</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Thien</forename><surname>Huu Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.273</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3480" to="3490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Jiaan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunlong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhixu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.14229</idno>
		<title level="m">Crosslingual summarization via chatgpt</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">HotpotQA: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1259</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.09600</idno>
		<title level="m">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Discriminative reasoning with sparse event representation for documentlevel event-event relation extraction</title>
		<author>
			<persName><forename type="first">Changsen</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He-Yan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonggang</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="16222" to="16234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Yew Ken Chia, and Lidong Bing. 2023. M3exam: A multilingual, multimodal, multilevel benchmark for examining large language models</title>
		<author>
			<persName><forename type="first">Wenxuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharifah</forename><surname>Mahani Aljunied</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.05179</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Document-level event causality identification via graph inference mechanism</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fazhi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yafeng</forename><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2021.01.078</idno>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">561</biblScope>
			<biblScope unit="page" from="115" to="129" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Augmentation, retrieval, generation: Event sequence prediction with a threestage sequence-to-sequence approach</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiexin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojian</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuxia</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Computational Linguistics</title>
		<meeting>the 29th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1865" to="1874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Improving event causality identification via selfsupervised representation learning on external causal statement</title>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuguang</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.190</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2162" to="2172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">MECI: A multilingual dataset for event causality identification</title>
		<author>
			<persName><forename type="first">Language</forename><surname>Resource</surname></persName>
		</author>
		<author>
			<persName><forename type="first">References</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dac</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Pouran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Veyseh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh</forename><surname>Van Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien Huu</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Computational Linguistics</title>
		<meeting>the 29th International Conference on Computational Linguistics<address><addrLine>Gyeongju, Republic of Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2346" to="2356" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
