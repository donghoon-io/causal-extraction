<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Teaching Transformers Causal Reasoning through Axiomatic Training</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-04-15">15 Apr 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Aniket</forename><surname>Vashishtha</surname></persName>
							<email>&lt;aniketv2@illinois.edu&gt;</email>
						</author>
						<author>
							<persName><forename type="first">Abhinav</forename><surname>Kumar</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">UIUC</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Atharva</forename><surname>Pandey</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">CISPA Helmholtz Center for Information Security</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<country>USA Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Abbavaram</forename><surname>Gowtham Reddy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kabir</forename><surname>Ahuja</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Washing- ton</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vineeth</forename><forename type="middle">N</forename><surname>Balasubramanian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Amit</forename><surname>Sharma</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">CISPA Helmholtz Center for Information Security</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<country>USA Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Teaching Transformers Causal Reasoning through Axiomatic Training</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-04-15">15 Apr 2025</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2407.07612v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Preprint. Under Review</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For text-based AI systems to interact in the real world, causal reasoning is an essential skill. Since active interventions are costly, we study to what extent a system can learn causal reasoning from symbolic demonstrations of causal axioms. Specifically, we present an axiomatic training method where the system learns from multiple demonstrations of a causal axiom (or rule), rather than incorporating the axiom as an inductive bias or inferring it from data values. A key question is whether the system would learn to generalize from the axiom demonstrations to more complex scenarios. Our results, based on applying axiomatic training to learn the transitivity axiom and d-separation rule, indicate that such generalization is possible. To avoid data contamination issues, we start with a 67 million parameter transformer model and train it from scratch. On both tasks, we find that a model trained on linear causal chains (along with some noisy variations) can generalize well to complex graphs, including longer causal chains, causal chains with reversed order, and graphs with branching. To handle diverse text inputs, the same method is extended to finetune language models. Finetuning Llama-3.1 8B model on our axiomatic data leads to significant gains on causal benchmarks such as Corr2Cause and CLEAR, in some cases providing state-of-theart performance surpassing GPT-4.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Causal reasoning can be defined as a set of reasoning procedures consistent with pre-defined axioms or rules that are specific to causality <ref type="bibr" target="#b11">(Galles &amp; Pearl, 1997)</ref>. For instance, under stable causal models, the transitivity axiom ("if A causes B and B causes C, then A causes C") helps answer questions of cause and effect between pairs of variables in a system. Similarly, the d-separation rule connects independence of variables and their causal graph structure, and forms the basis of many graph discovery and effect identification algorithms. Given a causal task and data observations from a system, axioms or rules are typically incorporated as inductive biases in a machine learning (ML) algorithm, through regularization, model architecture, or the choice of variables for a particular analysis. Depending on the kind of available data-observational, interventional, or counterfactual-Pearl's ladder of causation <ref type="bibr" target="#b4">(Bareinboim et al., 2022)</ref> defines the kinds of causal reasoning that is possible.</p><p>As axioms are the building blocks of causality, we study whether it is possible to directly learn the axioms or rules using ML models. That is, rather than learning from data that is the result of axioms obeyed by a data-generating process, what if a model can learn an axiom (and thus causal reasoning) directly from symbolic demonstrations of the axiom? This question gains relevance as language models make it possible to learn over symbolic data expressed in natural language. In fact, recent studies have evaluated causal reasoning capabilities of large language models (LLMs) by encoding causal reasoning problems in natural language <ref type="bibr" target="#b19">(Kıcıman et al., 2023;</ref><ref type="bibr">Jin et al., 2024a;</ref><ref type="bibr">b)</ref>. Our goal is to study whether directly teaching the axioms can be a viable way to improve causal reasoning of language models. Specifically, we propose a new way to learn causal reasoning through axiomatic training. We posit that causal axioms or rules can be expressed as the following symbolic tuple, ⟨premise, hypothesis, result⟩ where hypothesis refers to a causal claim and premise refers to any relevant information to decide whether the claim is true or not (conclusion). The conclusion could simply be "Yes" or "No". For example, consider the task of inferring causal relationships from correlational statements in the Corr2Cause dataset <ref type="bibr">(Jin et al., 2024b)</ref>, which we empirically study in this paper. The premise can be statements about statistical (in)dependence: "Premise: T causes T1. T2 causes T. T2 causes t. T2 causes T3. t causes T. t causes T1. t causes T3"; the hypothesis can be a question about cause-and-effect, "Are T3 and T d-separated given t, T 2?"; and the conclusion would be "Yes". This tuple is a demonstration of the d-separation rule <ref type="bibr">(Pearl, 2009b)</ref> (see Section 3 for definition). Based on this template, our key insight is that a large number of synthetic tuples can be generated, e.g., by changing the variable names, changing the number of variables, changing the order, and so on. The question is: if a model is trained on such data, would it learn to apply the axiom to new, more complex scenarios?</p><p>To answer this question, we consider a setup where a model is trained on axiomatic demonstrations over simple chainlike graphs of size 3-6 nodes and evaluated on more complex graphs, including longer chain-like graphs of size 7-15, graphs with branching, longer variable names, and edge direction perturbations. To avoid any contamination concerns with the pre-training data of an existing language model, we first train a transformer model from scratch. For both transitivity and d-separation, we find that a model trained on axiomatic demonstrations learns to apply the axiom multiple times to answer questions over more complex graphs. Diversity in the training data matters. For transitivity, a model trained only on simple directed chains generalizes to longer length chains, but is unable to generalize to graphs with branching or edge direction perturbations. In comparison, a model trained on a combined dataset of simple chains and chains with some edges randomly reversed, generalizes well across all kinds of evaluation scenarios. In particular, for d-separation, our 67 million parameter model outperforms billion-scale models such as GPT-4 under both zero-shot and multi-shot settings. Extending the findings on positional embedding for length generalization in NLP tasks <ref type="bibr" target="#b18">(Kazemnejad et al., 2023;</ref><ref type="bibr" target="#b6">Bhattamishra et al., 2020;</ref><ref type="bibr" target="#b13">Haviv et al., 2022)</ref>, we find that rotary position embedding works the best for causal generalization.</p><p>Next, we study whether the same axiomatic training dataset can also help to improve causal reasoning of pretrained large language models. We fine-tune Llama-3.1-8B-Instruct model over axiomatic datasets for transitivity and dseparation. We evaluate on two benchmarks: CLEAR <ref type="bibr">(Chen et al., 2024b)</ref>, that includes a test set for measuring dseparation capabilities; and Corr2Cause <ref type="bibr">(Jin et al., 2024b)</ref> on inferring causal structure from correlational statements. Note that our model is not trained on any of these datasets. We find significant gains due to axiomatic fine-tuning: in CLEAR, the accuracy on d-separation increases from 30 to 70 % on Yes/No task, and goes from 33 to 50% on Multi-Choice Questions. On Corr2Cause, the F1 score improves significantly, increasing 2x compared to the baseline and outperforms GPT-4 (F1=0.29) by 8 p.p thus highlighting the impact of axiomatic training on complex real world datasets for causal reasoning.</p><p>Our work provides a new paradigm of teaching models causal reasoning through symbolic demonstrations of axioms or rules, which we call axiomatic training. Such symbolic data can be cheaply generated for multiple axioms and added to the finetuning data of language models. More generally, our results contribute to the literature on causal learning from passive data <ref type="bibr" target="#b20">(Lampinen et al., 2023)</ref>, showing a general way to learn causal reasoning with passive demonstrations. Our code repository can be accessed at: <ref type="url" target="https://github.com/AniketVashishtha/CausalAxioms">https://github.com/AniketVashishtha/ CausalAxioms</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>LLMs for Knowledge-Driven Causal Reasoning: Recent developments in Large Language Models (LLMs) have highlighted their potential for knowledge-driven causal discovery. Unlike traditional methods which focus on statistical patterns or correlations, LLMs utilize knowledge acquired through their pretraining to reason about and identify causal structures based on metadata of variables <ref type="bibr" target="#b19">(Kıcıman et al., 2023;</ref><ref type="bibr" target="#b3">Ban et al., 2023;</ref><ref type="bibr" target="#b22">Long et al., 2023;</ref><ref type="bibr" target="#b36">Willig et al., 2022;</ref><ref type="bibr" target="#b34">Vashishtha et al., 2023)</ref>. However, possibility of memorization of existing benchmarks in the pretraining of these LLMs has been a major criticism. As a result, recent work <ref type="bibr" target="#b37">(Zečević et al., 2023)</ref> argues that LLMs are not actually performing causal reasoning, but simply learning correlations about causal facts. In addition, there are critical failure modes of using LLMs for causal discovery due to hallucinations or not obeying the acyclic constraint when generating graph edges <ref type="bibr" target="#b34">(Vashishtha et al., 2023)</ref>. To evaluate causal reasoning capabilities of LLMs, <ref type="bibr">(Jin et al., 2024b)</ref> and <ref type="bibr">(Jin et al., 2024a)</ref> propose formal causal inference evaluation benchmarks to infer direct and indirect causal relationships, and highlight the failure of LLMs in performing accurate causal reasoning.</p><p>Impact of Positional Encoding on Generalization: Length generalization capabilities of transformers has been studied in the past to better understand their different failure modes across various settings <ref type="bibr" target="#b14">(Hupkes et al., 2020;</ref><ref type="bibr" target="#b38">Zhang et al., 2023;</ref><ref type="bibr" target="#b10">Furrer et al., 2021)</ref>. Previous work <ref type="bibr" target="#b18">(Kazemnejad et al., 2023;</ref><ref type="bibr" target="#b6">Bhattamishra et al., 2020;</ref><ref type="bibr" target="#b13">Haviv et al., 2022;</ref><ref type="bibr" target="#b31">Shen et al., 2023)</ref> emphasizes the impact of positional encoding in length generalization capability of transformers. To understand how transformers can be optimized for learning through axiomatic training and generalizing to unseen larger causal structures, we also examine different types of positional encoding such as no positional encoding (PE), Learnable PEs <ref type="bibr" target="#b28">(Radford et al., 2018)</ref> and Sinusoidal PEs <ref type="bibr" target="#b35">(Vaswani et al., 2023)</ref>.</p><p>Synthetic data generation for teaching transformers reasoning: Synthetic data generation has been explored for optimising model training for reasoning. For example, <ref type="bibr" target="#b21">(Li et al., 2023;</ref><ref type="bibr" target="#b12">Gunasekar et al., 2023)</ref> use LLM-generated synthetic text for training Phi-1 and Phi-1.5 models and show impressive performance for reasoning-based tasks. <ref type="bibr" target="#b33">(Trinh et al., 2024)</ref> introduce a novel neuro-symbolic framework to pre-train a transformer model for Olympiad-level math problems. <ref type="bibr" target="#b23">(Morishita et al., 2024)</ref> construct synthetic training data to improve language models' performance on logical reasoning tasks. Building on this stream of work, we apply synthetic data generation for teaching causal reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries: Causal Axioms and Rules</head><p>Instead of performing causal reasoning using observational or interventional data, we study whether it is possible to learn general rules of causality directly from symbolic axioms. There has been fundamental work from <ref type="bibr" target="#b11">Galles &amp; Pearl (1997)</ref> where they axiomatize causal relevance (or equivalently irrelevance). They show that for a given stable probabilistic causal model (defined below), there exists a finite set of axioms that are completely characterized by axioms of path interception in corresponding directed graphs. Additionally, causal inference in practice depends on a few key rules, such as d-separation and do-calculus rules. Learning these rules can have a tangible impact on practical causal tasks such as graph discovery and effect inference. While we call the method axiomatic training, we consider learning both causal axioms and rules. Throughout this work, we assume no unobserved confounders.</p><p>Notation. We denote a random variable with an uppercase letter (e.g., X, Y, Z) and use lowercase letters (e.g., x, y, z) to denote the values taken by the corresponding random variable, written as X = x, Y = y, Z = z. We represent the probability of a random variable X i as P(X i ). Let G(X, E) be a directed acyclic graph (DAG) consisting of a set of variables X = {X 1 , . . . , X n } and a set of directed edges</p><formula xml:id="formula_0">E among variables in X. Let pa(X i ) = {X k |X k → X i }, de(X i ) = {X k |X k ← • • • ← X i }, ch(X i ) = {X k |X i → X k } denote</formula><p>the set of parents, descendants and children of X i respectively. Given two nodes X i , X j we call a third node X k as a collider if both X i and X j are parents of X k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Axioms of Causality: Transitivity</head><p>Definition 3.1 (Causal Irrelevance, adapted from Defn. 7 in <ref type="bibr" target="#b11">(Galles &amp; Pearl, 1997)</ref>). X is probabilistically causally irrelevant to Y given Z, written (X ↛ Y |Z) iff: P(y|z, do(X) = x) = P(y|z, do(X) = x ′ ), ∀x, x ′ , y, z i.e., once we hold Z fixed at z, intervening on X will not change the probability of Y.</p><p>Next, we restate the stability assumption for a causal model from <ref type="bibr" target="#b11">(Galles &amp; Pearl, 1997</ref>) that gives a richer set of finite axiomatization for probabilistic causal irrelevance. Assumption 3.2 (Stability, Definition 9 in <ref type="bibr" target="#b11">(Galles &amp; Pearl, 1997)</ref>). Let M be a causal model. Then an irrelevance (X ↛ Y |Z) in M is stable if it is shared by all possible probability distribution over M. The causal model M is stable if all of the irrelevances in M are stable.</p><p>Under the stability assumption (see Assumption 3.2), <ref type="bibr" target="#b11">Galles &amp; Pearl (1997)</ref> states six axioms that completely characterize causal irrelevance (Definition 3.1) via axioms of path interception in the directed graphs. An axiom of causal irrelevance is of the form (given in conjunctive normal form):</p><formula xml:id="formula_1">s t (X s,t i ↛ X s,t j |X s,t k ) =⇒ l n (X l,n i ↛ X l,n j |X l,n k )</formula><p>where ∧ is "logical and", ∨ is "logical or" and for a given (s, t) or (l, n) pair, X i , X j , X k are disjoint subsets of observed variables X. In the above causal irrelevance statement, if the antecedent is true, the consequent is also true.</p><p>Transitivity Axiom. We illustrate our axiomatic training procedure through the transitivity axiom. Following the stability assumption above, we consider the class of interventional distributions in which the transitivity causal irrelevance axiom holds <ref type="bibr">(Sadeghi &amp; Soo, 2024)</ref>. Formally, for a stable probabilistic causal model ( §3), given variables X, Y , Z in the system, the transitivity axiom is:</p><formula xml:id="formula_2">(X ↛ Y |Z) =⇒ (A ↛ Y |Z) ∨ (X ↛ A|Z) ∀A / ∈ X ∪ Z ∪ Y</formula><p>which can be simplified using the contrapositive.</p><formula xml:id="formula_3">∃A / ∈ X ∪ Y ∪ Z s.t. (X → A|Z) ∧ (A → Y |Z) P :premise =⇒ (X → Y |Z) H:hypothesis<label>(1)</label></formula><p>We call the LHS as Premise and the RHS as Hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">d-separation rule</head><p>The d-separation rule connects causal graph structure with conditional independence in P(X).</p><p>Definition 3.3 (Definition 1.2.3 in <ref type="bibr">Pearl (2009a)</ref>). Given a DAG G(X, E), two sets of random variables X i and X j are said to be d-separated by a third set X z if all the paths between X i and X j in G are blocked by X z . A path p between X i and X j is said to be blocked by a set of nodes X z iff 1) p contains a fork (i.e., • ← A → •) or a chain (i.e.,</p><p>• → A → •) such that the middle node A is in X z , or 2) p contains a collider (• → A ← • ) such that the middle node A is not in X z and no descendant of A is in X z .</p><p>Given P(X) is Markov with respect to G, if two sets of random variable X i and X j are d-separated by X z , then they are conditionally independent of each other given X z .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Axiomatic Training for Transformers</head><p>Given an axiom, our key idea is to generate thousands of synthetic symbolic expressions that can be used to train a transformer on how to use the axiom. The trained model is then evaluated on whether it can apply these axioms to new causal structures that were not available in the training set.</p><p>Below we describe how we generate the training data and the model architecture details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Training Data: Diversity is key</head><p>As mentioned above, an axiom consists of a tuple, ⟨premise, hypothesis, conclusion⟩. Based on the specific axiom, we can map a hypothesis given the premise to its correct label ('Yes' or 'No'). To create a training dataset, we randomly sample a causal DAG G and enumerate N random tuples of {(P, H, L)} N where P is the premise, H is the hypothesis and L is the label (Yes/No). The premise describes the edges of the graph and is expressed in natural language, e.g., "X causes Y. Z causes Y.". Given a premise P based on the causal graph's edges, if the hypothesis can be derived by applying the specified axiom (once or multiple times), then label L is Yes; otherwise, No. For example, for the transitivity axiom, suppose the underlying true causal graph of a system is a chain, X 1 → X 2 → X 3 . Then, the premise will be X 1 → X 2 ∧ X 2 → X 3 . A corresponding hypothesis for the transitivity axiom could be X 1 → X 3 will have label Yes whereas another hypothesis X 3 → X 1 will have label No. The former would create a training data instance with the following text, "X1 causes X2. X2 causes X3. Does X1 cause X3? Yes.". Note that the axiom can be inductively applied multiple times to generate more complex training tuples. Another possible hypothesis for the d-separation rule could be "Are X 1 and X 2 d-separated given {X 3 }?" and the label will be No.</p><p>We train the model on data from simple causal graphs such as sequential chains with 3-6 nodes and evaluate its performance on more complex graphs 1. To enhance generalization, we introduce structured perturbations in the training data across three axes: node names, causal structure types, and the number of nodes in the causal graph.</p><p>1. Node names: Each node in the graph is represented by an alphanumeric name comprising 1-3 characters. The length of a name and the specific characters are randomly selected during data generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Causal Graph Topology:</head><p>We consider two main types of causal graphs in the training set.</p><p>(a) Sequential: All causal edges are directed forward, thus forming a typical chain DAG, e.g. X → Y → Z.</p><p>(b) Random Flipping: Given a chain of sequential nodes, we randomly reverse some edges eg. X → Y ← Z. This can be expressed simply through natural language like: "X causes Y. Z causes Y.". This introduces forks and colliders that help add complexity to model training, thus aiding generalization across a larger space of graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Number of nodes in graph:</head><p>To facilitate the generalization of transformers over graphs of different sizes we incorporate chains of varying lengths, ranging from 3 to 6 nodes in our training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Tokenization, Training Loss &amp; Architecture</head><p>We train the transformer model from scratch to ensure that the model has not seen such axioms in the pertaining step and thus requires a true correct understanding of axioms to perform well. Later we also tested on a pre-trained model fine-tuned on our dataset.</p><p>Tokenization. Since the training dataset follows a specific structure, we develop a custom tokenizer. Alphanumeric node names are tokenized at a character level, while special terms such as 'causes', 'Does', 'cause', 'Yes', and 'No' are tokenized at the word level. Such an approach avoids out-ofvocabulary (OOV) tokens at test time since the alphanumeric node names in the test set can be different than those in the training set. Following this approach, the vocabulary size of our transformer model is 69.</p><p>Loss function. Given a dataset, the loss function is defined based on the ground truth label for each tuple, represented as E (P,H,L)∼Ptrain -log P(L|P, H). A preliminary analysis indicated promising results with this loss formulation compared to next token prediction loss.</p><p>Positional Encoding. In addition to the training data and loss function, recent work <ref type="bibr" target="#b18">(Kazemnejad et al., 2023)</ref> has shown that the choice of positional encoding is important for generalizing a transformer to longer or complex inputs. Therefore, we experiment with different positional encoding to understand their impact on generalization in causal tasks: learnable (LPE) <ref type="bibr" target="#b28">(Radford et al., 2018)</ref>, sinusoidal (SPE) <ref type="bibr" target="#b35">(Vaswani et al., 2023)</ref>, rotary (RoPE) position encodings <ref type="bibr" target="#b32">(Su et al., 2023)</ref>, and no positional encoding (NoPE) <ref type="bibr" target="#b18">(Kazemnejad et al., 2023;</ref><ref type="bibr" target="#b13">Haviv et al., 2022)</ref>. See Appendix E for details.</p><p>Finetuning. Apart from training a transformer from scratch, we also fine-tune a pre-trained language model (Llama-3.1-8b-Instruct (gra, 2024)) on our axiomatic training data.  The trained model is evaluated on significantly more complex structures: bigger causal chains with &gt;6 nodes, general branched networks with higher average in-degree and out-degree, complete reversals, longer sequences, shuffled natural language statements of sequences and longer node names</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluation setup: Assessing Axiomatic Learning in Transformers</head><p>We consider two types of evaluation: 1) on synthetic datasets where we directly test the models on axioms and, 2) on existing benchmarks corresponding to different high-level causal tasks where we expect the axioms to be helpful.</p><p>Synthetic evaluation. To evaluate if a trained model has learned the correct understanding of an axiom instead of shortcuts or correlation-based features, designing an out-ofdistribution (OOD) evaluation set is important. We evaluate our model on multiple types of complex graphs that are unseen during training.</p><p>1. Length: Evaluating whether our model accurately infers causal relationships for chain graphs (both sequential and ones with random flipping) longer than those in the training set. Specifically, we train the model on chains with size 3-6 and evaluate on chains of size 7-15. 2. Node Name Shift: Testing the model's performance on longer node names, from 1-3 characters used in the training set to 8-10 characters. This is motivated by <ref type="bibr">(Jin et al., 2024b)</ref> who show how change in node names results in generalization failure on causal tasks for language models. 3. Order of Chains: a) Completely reversed chains: This evaluation is inspired by the reversal curse <ref type="bibr">(Berglund et al., 2024)</ref> that revealed generalization failure of LLMs in answering questions in reversed sequences despite knowing the answers in the original order. We evaluate our model on completely reversed chains, a structure that was not in the training data. A completely reversed chain will be of the form X ← Y ← Z, written in natural language as: "Y causes X. Z causes Y.", where X, Y, Z are replaced by random alphanumeric names. b) Shuffling of Sequences: Here we shuffle the order of causal edges presented in each training row to add complexity and break sequential order. 4. Branching Factor: One of the most complex evaluation setups, with DAGs containing multiple branches, colliders, and forks. Let the branching factor be defined as the ratio between a number of edges and a number of nodes. Thus, the branching factor for the training set is ≤ 1. Then, we create a different evaluation set with multiple densely branched networks constructed using the Erdös-Rényi model, with different branching factors.</p><p>Benchmark evaluation. To test whether such simple axiomatic training is helpful in more complex scenarios, we evaluate our models on existing causal reasoning benchmarks, Corr2Cause <ref type="bibr">(Jin et al., 2024b)</ref> and CLEAR <ref type="bibr">(Chen et al., 2024b)</ref>. Models trained from scratch on axiomatic instances with limited vocabulary and capability cannot be tested on diverse datasets (due to out-of-vocabulary issues). Therefore we use finetuned language models on these datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Axiomatic Training For Transitivity Axiom</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Training and Evaluation Datasets</head><p>In all our experiments, we consider an empty conditioning set Z for simplicity.</p><p>Training Datasets. The training data consists of sequential chains of lengths from <ref type="bibr">[3,</ref><ref type="bibr">6]</ref>. In addition to sequential chains, random flipping of edges is done with 0.5 probability. See Appendix F for details on these hyperparameters.</p><p>Our training data consists of 175k axiom demonstrations. We use three versions of training data to evaluate the impact of different data perturbations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Baselines Using Existing LLMs</head><p>Given recent work on how LLMs can be leveraged for causal reasoning <ref type="bibr" target="#b19">(Kıcıman et al., 2023;</ref><ref type="bibr" target="#b34">Vashishtha et al., 2023;</ref><ref type="bibr" target="#b3">Ban et al., 2023)</ref>, we include language models such as GPT-4 (gpt-4-32k) (ope, 2024), Gemini (gemini-pro) (gem, 2024) and Phi-3 (Phi-3-mini-128k-instruct) (abd, 2024) as baselines. Note that each of these models is significantly larger than our model and known to perform well on reasoning tasks, with the smallest baseline model Phi-3 having 3.8 billion parameters <ref type="bibr" target="#b21">(Li et al., 2023)</ref>.</p><p>Zero Shot Setting To evaluate the baseline models, we follow a simple zero-shot prompting strategy. For each tuple, we provide the natural language expression of the causal graph (Premise) followed by the question (Hypothesis) and prompt the LM to answer it in either 'Yes' or 'No' (Label).</p><p>Here is an example prompt: "EX causes T. T causes 9. 9 causes W. W causes 7. 7 causes M. M causes a. Does EX cause T? Answer in 'Yes' or 'No' only". See Table ?? contains examples of prompts used.</p><p>Multi Shot Setting (In-context-learning). Since these LLMs might not have seen such tasks before, we include some examples along with their true label in the prompt and then we add the evaluation example in the end. This ensures LLMs can do in-context learning and thus a fair comparison against our model that is trained explicitly on the axiomatic dataset. We present few-shot instances from our training set that includes sequential causal chains, along with a few examples with random flipping of edges. Appendix B.1 contains the multishot prompt used for querying baseline LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Results: Generalization to Complex Causal Scenarios</head><p>We since it includes example that are different from training dataset in terms of size and complexity of causal graph. Table 1 summarizes the results for this dataset. While GPT-4 performs best, models trained with RoPE position encodings still achieve strong results, surpassing Gemini Pro and Phi-3 in both zero-shot and multi-shot settings for majority of node lengths.</p><p>A similar trend is seen for completely reversed sequences (Table <ref type="table" target="#tab_6">A3</ref>). This task presents extreme out-of-distribution data, as the training data contains left-to-right edges, while the test data has only right-to-left edges. TS2 (NoPE) consistently outperforms Gemini-Pro and Phi-3, and remains competitive with GPT-4 (zero shot). In particular, its accuracy (0.94 for chains of length 6) is substantially higher than Gemini Pro and Phi-3 (0.71 and 0.75 respectively).</p><p>Branched Causal Graphs. Even though our models are trained on simpler graphs like sequential and randomflipping, we want to test our models on structurally harder graphs not considered in MultiEval SLR . To do so, we introduce general Erdos-Renyi graphs as the causal sequences while the training data contains only linear chains. We vary the branching factor of the graph as defined in Sec 4.3 between 1.4 and 2 for all our experiments on graphs with different numbers of nodes. Table <ref type="table" target="#tab_3">2</ref> summarizes the results of this experiment. While GPT-4 achieves the highest accuracy as graph sizes increase, our TS1 (RoPE) and TS2  (RoPE) model outperforms Gemini Pro (branching factor 1.4) in for graphs with size 5 and 8 under zero-shot settings. On graphs with 12 nodes and a 1.4 branching factor, TS2 (RoPE) achieves 68% accuracy, far better than random (50%), despite training only on graphs with branching factors ≤ 1. Although LLMs excel in multi-shot settings, our model's performance is comparable even on more complicated causal graphs than the ones they were trained on.</p><p>Further Ablations. We run further ablations to understand the generalization behavior of our models. In particular, we experiment with generalization to unseen node names (Appendix Table <ref type="table" target="#tab_4">A5</ref>), generalization to unseen lengths for graphs with linear chains and random flipping of edges (Appendix Table <ref type="table" target="#tab_7">A4</ref>), and generalization to graphs with branching factor of 2 (A6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Axiomatic Training for D-Separation Rule</head><p>Similar to the transitivity axiom, we now train our model on instances on of d-separation rule from multiple causal graphs and different premise, hypothesis pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Training Dataset and Setup</head><p>We follow a similar strategy to generate the training dataset as we did for the transitivity axioms. The training dataset Table <ref type="table">3</ref>: Evaluation on CLEAR dataset <ref type="bibr">(Chen et al., 2024b)</ref> We finetune the LMs on our d-separation dataset and evaluate on the CLEAR dataset in a zero-shot setting.</p><p>We observe a significant increase in performance compared to the baseline, which highlights the efficacy of axiomatic training. For discussion refer Sec 7.1.</p><p>consists of graphs with lengths from [3, 6] with branching factor in range [0.6, 0.8] and uses the same premises from the TS2 training set as we did for transitivity axiom (see Sec 5.1). Given a premise, we create the hypotheses as follows: First, select all pairs of nodes in the graphs (x 1 , x 2 ), then select the conditioning set C from the remaining sets of nodes of size up to 5 nodes at a time. The ground truth labels denote whether x 1 and x 2 are d-separated given conditioning set C for the given causal graph in the premise. From this exhaustive set of hypotheses, we randomly subsample 175k examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Evaluation</head><p>Building on the success of axiomatic training for the transitivity axiom, we extend our approach to d-separation by introducing structurally more complex scenarios, such as branching and longer chains with random flipping. Unlike transitivity, which primarily involves reasoning over linear chains, d-separation is inherently more challenging due to its dependence on various structural patterns, including colliders, chains, and forks.</p><p>We evaluate the trained 67M model on two evaluation settings: longer sequences with random flipping (refer Table <ref type="table" target="#tab_8">A7</ref>) and branching (refer Table <ref type="table">4</ref>), to cover a range of structural variations. Overall, model trained with RoPE emerges as the best performer, with NoPE based model following as close second. While GPT-4 struggles to perform better than random baselines in both settings, our models trained from scratch perform much better than random baseline, and the performance goes down as size increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Evaluating on complex tasks with axiomatic finetuning</head><p>We trained Llama-3.1-8B-Instruct using supervised finetuning on the same axiomatic training data, where the model  <ref type="bibr">(Jin et al., 2024b)</ref>. We finetune the LMs on our transitivity and d-separation dataset and evaluate the Corr2Cause dataset in a zero-shot setting. We observe a significant increase in performance compared to the baseline, which highlights the efficacy of axiomatic training. For discussion refer Sec 7.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Evaluation on Corr2Cause Dataset</head><p>Jin et al. (2024c) proposed a more complex dataset to evaluate models on different causal tasks. Each data instance in the benchmark includes correlational relationships described in natural language for graphs with 3 to 6 nodes; the goal is to infer the truth value of a hypothesis. The hypothesis consists of six different kinds of graphical relationships between pairs of variables: Parent, Ancestor, Child, Descendant, Collider, and Confounder. This task is significantly harder than applying a single axiom. First, one needs to infer the causal graph from the correlation statements. This requires knowledge of d-separation statements and Markov condition Appendix D.1. Then, one needs to use the transitivity axiom to identify the direct effect and indirect effect to identify the children, ancestors, colliders, and confounders in the causal graph.</p><p>Comparison with Baselines: Our results highlight the Llama-3-8b-Instruct Base model's poor performance on this task, while axiomatic fine-tuning enables it to handle the complexity effectively. Fine-tuning on transitivity and dseparation improved performance, despite their simplicity. Notably, transitivity fine-tuning led to the largest gains, even surpassing GPT-4, likely due to its direct relevance in inferring graph relationships. This demonstrates the potential of our minimalist training setup to tackle complex, languagebased causal reasoning tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Discussion and Conclusion</head><p>In this paper, we provide a general framework, axiomatic training, to add axioms and simple rules of causality as inductive prior in the ML models, which can then further help in downstream causal discovery and causal inference tasks. We demonstrate their usefulness by training/finetuning models using our axiomatic training framework on two simple rules -transitivity and d-separation rules. We also discuss various modelling choices and how they effect the learning and generalization of causal axioms. We ob-serve that a transformer model trained from scratch on a large axiomatic dataset can learn to apply axioms effectively. On causal tasks like graph traversal via transitivity and inferring causal relationships from correlation, small 67M transformers generalize well to unseen complex graphs, often outperforming models like GPT-4, Phi-3, and Gemini Pro. We then demonstrate the usefulness of adding these rules as inductive prior to downstream tasks on two downstream datasets -CLEAR and Corr2Cause. We observe that fine-tuning LLMs using axiomatic training help perform better on these dataset in the zero-shot setting, i.e., having never seen examples from these datasets. Fine-tuning on dseparation and transitivity-based axiomatic instances led to performance improvements. The model fine-tuned on transitivity exhibited the highest performance gain on templates like Parent, where distinguishing direct and indirect relationships is crucial. Similarly, fine-tuning on d-separation instances resulted in performance improvements on templates like idenrifying collider, where identifying colliders is key. Since the Child template contains no "No" labels, its reported F1 score is 0.</p><p>Generalization to Logical Reasoning. While our axiomatic training approach focuses on causal reasoning, it can be applied to any formal system such as deductive logical reasoning. Recent work <ref type="bibr" target="#b30">(Saparov et al., 2023)</ref> highlights LLMs' deterioration in performance as reasoning depth increases. Given the similarity between our setup and such tasks, it would be interesting to explore if axiomatic training can improve deductive reasoning in LMs.</p><p>Implications for Training Language Models. GPT-4 demonstrates impressive generalization on the causal tasks we evaluated. We hypothesize that axiomatic training may explain GPT-4's ability to reason over causal graphs, as (noisy) demonstrations of the underlying axioms could be present in its web-scale training data. Meanwhile, models like Gemini Pro and Phi-3 struggle with zero-shot reasoning for causal tasks, such as handling completely reversed chains, suggesting room for improvement. Incorporating causal axiom demonstrations as a part of language models' pretraining (or finetuning data) could help improve the reasoning of these models so that small language models like Phi-3 can achieve GPT4-like accuracy on causal tasks. Incorporating axiomatic inductive biases could aid the language model's reasoning abilities for the desired task. For instance, <ref type="bibr" target="#b25">(Papadimitriou &amp; Jurafsky, 2023)</ref> propose pretraining language models on synthetic formal languages to incorporate inductive biases to improve performance in learning grammatically diverse languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact Statement</head><p>This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here. accuracy, indicating that the axiomatically-trained TS2 (NoPE) model can generalize its reasoning to causal chains much longer than 6 even though it was trained only on chains up to length 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query</head><p>Node Name Shift: For models trained on TS2 dataset, we also evaluate generalization to changes in variable names (Figure <ref type="figure" target="#fig_1">2</ref>). We find that TS2 (NoPE) is robust to node name changes and retains its high accuracy as new, longer names are introduced. It also retains its generalizability to longer sequences with new node names, performing similarly to GPT-4.</p><p>Summary: Across all evaluation setups, our axiomatically trained model TS2 (NoPE) performs significantly better than random baselines even as chain lengths are increased beyond its training data. In particular, even though our model was not trained on fully reversed chains, it performs at par with the significantly larger GPT-4 model, while easily outperforming other billion scale models even under multi-shot settings. For other tasks, it often outperforms or matches the accuracy of billion-scale models like Gemini Pro and Phi-3. These results indicate that a model trained axiomatically can learn to reason about more complex causal structures from demonstrations of simple causal sequences. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Positional Encodings and their Role in Generalization</head><p>Positional Encoding (PE) play a crucial role of providing information about the absolute and relative position of tokens in a sequence <ref type="bibr" target="#b35">(Vaswani et al., 2023)</ref>. <ref type="bibr" target="#b35">(Vaswani et al., 2023)</ref> propose an absolute positional encoding strategy using periodic functions (e.g., sinusoidal or cosine) to initialize these encodings. Absolute positional encoding provides definite values for all positions across any sequence length. However, studies <ref type="bibr" target="#b24">(Ontañón et al., 2022;</ref><ref type="bibr" target="#b9">Csordás et al., 2021)</ref> show absolute positional encoding fails in length generalization tasks for transformers. In the learnable APE variant <ref type="bibr" target="#b28">(Radford et al., 2018)</ref>, each positional embedding is randomly initialized and trained with the model. This approach falters with sequences longer than those seen in training, as the new positional embeddings remain untrained and randomized. Interestingly, recent findings <ref type="bibr" target="#b18">(Kazemnejad et al., 2023;</ref><ref type="bibr" target="#b13">Haviv et al., 2022)</ref> indicate that removal of PEs in auto-regressive models can improve model's length generalization capabilities, wherein the attention mechanism during auto-regressive decoding is sufficient to encode positional information. We also experiment with Rotary Position Encodings <ref type="bibr" target="#b32">(Su et al., 2023)</ref>, which have shown superior length generalization. We use θ = 10000.0 for the base period of RoPE embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Formalising training and Evaluation Setup</head><p>Let f dim represent the maximum value for a given perturbation dimension dim, along which we construct train and evaluation sets for our axiomatic framework. For each dimension, we choose a threshold τ dim ∈ L, such that f dim &lt; τ dim forms our training set and f dim ≥ τ dim forms the evaluation set. So, f dim ∈ {f len , f branch , f nodelen , f revf actor , f shuf f le } where:</p><p>• f len = max ∀i (len(V i )), gives the maximum number of nodes across all causal sequences. τ len for length is set at 6, with f len ∈ [3, 6].</p><p>• f branch = max ∀i (|X i |/|V i |) gives the maximum branching factor in a dataset, with τ branch = 0.8 (for 6 node linear sequences). For sequences in the train set, the branching factor ranges from 0.6 to 0.8 for 3 to 6 length sequences.</p><p>• Let l i,j be the length of the name of the node X i,j , then l i,j = (len(X i,j )).Therefore, the maximum length of node names across all nodes in all causal sequences can be represented as: f nodenamelen = max 1≤i≤n, 1≤j≤m l i,j . We set τ nodelen for train set as 3, with f nodelen ∈ [1, 3].</p><p>• Given any causal sequence X i and a function N , where N (X i,j , X i,j+1 ) returns natural language representation of a directed edge between j and j + 1 node in the causal chain X i . f shuf f le = ∩ ∀i,j Perm(N (X i,j , X i,j+1 )), where N (X i,j , X i,j+1 ) represents deviation from original sequential order of natural language sentences to represent X i .</p><p>• Given a causal sequence X i and let R(X i , f revf actor ) be an operation on the causal chain that flips the direction of every edge in the sequence with probability f revf actor . In the training set, there is a directed edge between every sequential pair of nodes X i,j , X i,j+1 with f revf actor = 0 (for linear sequence, X i,j → X i,j+1 ) or 0.5 (for sequence with random flipping, X i,j → X i,j+1 or X i,j ← X i,j+1 ) In the evaluation set f revf actor = 1 i.e., all sequences for reversal evaluation setup are completely reversed unlike in train set where no sequence is present where all edges are completely reversed.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Results of Dsep on CLEAR dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Results on Corr2Cause dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Implementation Details</head><p>We used a learning rate of 1e-4 with linear scheduling and 3% warmup ratio, training for 4102 max steps on axiomatic instance samples with sequences of maximum length 4096 tokens. We employed mixed precision (bfloat16) training with flash attention for efficiency. After training, the LoRA weights were merged with the base model for inference. We used Huggingface (wol, 2020) for implementation. The fine-tuning used LoRA with rank 64, alpha 16, and dropout 0.1. Training was performed on 3 GPUs using DeepSpeed Stage 3 with a total batch size of 128 (16 samples per GPU with gradient accumulation). 1 A40 and 1 A100 GPUs were used for training the transformer model from scratch for all Positional encodings based experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Evaluating structural generalization of transformers through axiomatic training. We train a transformer on two simple causal structures: chains and chains with random flipping of some edges. All training instances consist of 3-6 nodes.The trained model is evaluated on significantly more complex structures: bigger causal chains with &gt;6 nodes, general branched networks with higher average in-degree and out-degree, complete reversals, longer sequences, shuffled natural language statements of sequences and longer node names</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Evaluating generalization on causal sequences (without random flipping) with longer node names (than the ones used in sequences in train set). TS-2 training set with no positional encoding leads to the best performance. Refer table A5 for complete results.</figDesc><graphic coords="7,307.44,222.96,240.56,80.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Generalizing to longer unseen causal sequences (&gt;6 nodes) with random flipping on TS2 and OCC (with NoPE) train sets. OCC-trained models struggle due to limited edge-level variability, while TS2 NoPE consistently performs well. Refer table A4 for complete results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure A1 :</head><label>A1</label><figDesc>Figure A1: Example instance of Multiple Choice (MC) question type from (Chen et al., 2024b) dataset describing dseparation rule problem defined with a different hypothesis type and semantic structure then the one our models are finetuned on.</figDesc><graphic coords="19,55.44,222.13,485.99,258.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure A2 :</head><label>A2</label><figDesc>Figure A2: Model Comparison: F1 Score across Templates, finetuning on dsep and transitivity based axiomatic instances lead to performance improvement. Model finetuned on transitivity sees the highest jump for templates like Parent, where identifying direct-indirect relations is important. Finetuning on D-separation instances see a jump in performances for templates like has_collider, where identifying a collider is important. Since child template has 0 'No' labels, the F1 score reported is 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure A3 :</head><label>A3</label><figDesc>Figure A3: Comparison of Model Performance across Different Relationship Templates. Accuracy plots show consistent trends, with model finetuned on transitivity consistently outperforming base models, on templates where direct-indirect relationship identification is required. Finetuning on D-separation instances see a performance jump over the base instruct model, for templates identifying colliders and confounders.</figDesc><graphic coords="20,55.44,67.06,485.99,258.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Evaluation Datasets. In addition to the evaluation sets described earlier (length generalization, node name shift, order of chains, and branching), we add another evaluation set that is a combination of three shifts.</figDesc><table><row><cell>graphs with only sequential chains (see causal graph</cell></row><row><cell>topology in Sec 4.1 for details).</cell></row><row><cell>2. Training Setup 1 (TS1): This setup comprises of 73k ex-</cell></row><row><cell>amples where the underlying graphs has random flipping</cell></row><row><cell>and 101k causal graphs where the underlying graphs has</cell></row><row><cell>sequential chains. Since flipping is done randomly across</cell></row><row><cell>all consecutive pairs of nodes in the given chain, some</cell></row><row><cell>complete reversals are also formed. In this training set,</cell></row><row><cell>around 12k completely reversed chains are present.</cell></row><row><cell>3. Training Setup 2 (TS2): This setup comprises more sim-</cell></row><row><cell>ple sequential chains (132k), while we decrease chains</cell></row><row><cell>with random flipping (42k) to keep the overall size</cell></row><row><cell>around 175k to see the effect of adding examples with</cell></row><row><cell>complicated graphs on model's performance.</cell></row><row><cell>MultiEval SLR (Shuffling + Random Flipping + Length</cell></row><row><cell>Sequence): This setup involves evaluation on 3 levels of</cell></row><row><cell>complexities together: shuffling of sentence for representing</cell></row><row><cell>the sequences, each sequence having random flipping, and</cell></row><row><cell>some sequences having longer length than sequences in</cell></row><row><cell>training set (upto 9).</cell></row><row><cell>5.2. Implementation Details: Architecture and Training</cell></row><row><cell>Procedure and Positional Encoding</cell></row><row><cell>We train a decoder-based 67 million parameter model based</cell></row><row><cell>on GPT-2's architecture. The model has 12 attention lay-</cell></row><row><cell>ers, 8 attention heads and 512 embedding dimensions.</cell></row><row><cell>The model is trained from scratch on each of our train-</cell></row><row><cell>ing datasets. All models are trained for 100 epochs using</cell></row><row><cell>the AdamW optimizer with 1e-4 learning rate. We use three</cell></row><row><cell>variant of positional encoding when training the transformer:</cell></row></table><note><p>1. Only Causal Chains (OCC): This set comprises of SPE: Sinusoidal Positional Encoding (PE), LPE: Learnable PE, RoPE: Rotary PE, NoPE: without any PE.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Evaluation on MultiEval SLR dataset. Accuracy of axiomatically trained models with another baseline on the most complicated setups. For OCC we only report performance with RoPE encodings, which is the best performing setup for this dataset. See Sec 5.4 for details. Bold numbers denote the highest value on a test set, while the underlined ones denote the second best.</figDesc><table><row><cell>Model/Nodes</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell></row><row><cell>Baselines (Zero Shot)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GPT-4</cell><cell>0.99</cell><cell>0.97</cell><cell>0.89</cell><cell>0.85</cell><cell>0.95</cell><cell>0.90</cell><cell>0.90</cell></row><row><cell>Gemini Pro</cell><cell>0.75</cell><cell>0.73</cell><cell>0.72</cell><cell>0.76</cell><cell>0.71</cell><cell>0.68</cell><cell>0.74</cell></row><row><cell>Phi-3</cell><cell>0.88</cell><cell>0.86</cell><cell>0.82</cell><cell>0.79</cell><cell>0.76</cell><cell>0.73</cell><cell>0.79</cell></row><row><cell>Baselines (Multi Shot)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GPT-4</cell><cell>1.00</cell><cell>0.99</cell><cell>0.97</cell><cell>0.95</cell><cell>0.94</cell><cell>0.90</cell><cell>0.92</cell></row><row><cell>Gemini Pro</cell><cell>0.95</cell><cell>0.85</cell><cell>0.83</cell><cell>0.79</cell><cell>0.79</cell><cell>0.73</cell><cell>0.75</cell></row><row><cell>Phi-3</cell><cell>0.88</cell><cell>0.83</cell><cell>0.82</cell><cell>0.80</cell><cell>0.83</cell><cell>0.76</cell><cell>0.78</cell></row><row><cell>Axiomatic Training</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TS1 w NoPE</cell><cell>1.00</cell><cell>0.93</cell><cell>0.85</cell><cell>0.83</cell><cell>0.78</cell><cell>0.73</cell><cell>0.73</cell></row><row><cell>TS1 w LPE</cell><cell>1.00</cell><cell>0.93</cell><cell>0.87</cell><cell>0.83</cell><cell>0.79</cell><cell>0.74</cell><cell>0.73</cell></row><row><cell>TS1 w SPE</cell><cell>0.99</cell><cell>0.92</cell><cell>0.85</cell><cell>0.81</cell><cell>0.76</cell><cell>0.74</cell><cell>0.61</cell></row><row><cell>TS1 w RoPE</cell><cell>1.0</cell><cell>0.93</cell><cell>0.87</cell><cell>0.85</cell><cell>0.81</cell><cell>0.78</cell><cell>0.76</cell></row><row><cell>TS2 w NoPE</cell><cell>0.99</cell><cell>0.93</cell><cell>0.86</cell><cell>0.82</cell><cell>0.79</cell><cell>0.74</cell><cell>0.73</cell></row><row><cell>TS2 w LPE</cell><cell>1.00</cell><cell>0.92</cell><cell>0.85</cell><cell>0.83</cell><cell>0.77</cell><cell>0.74</cell><cell>0.71</cell></row><row><cell>TS2 w SPE</cell><cell>0.99</cell><cell>0.94</cell><cell>0.86</cell><cell>0.81</cell><cell>0.76</cell><cell>0.72</cell><cell>0.64</cell></row><row><cell>TS2 w RoPE</cell><cell>1.0</cell><cell>0.95</cell><cell>0.89</cell><cell>0.86</cell><cell>0.82</cell><cell>0.79</cell><cell>0.76</cell></row><row><cell>OCC w RoPE</cell><cell>0.78</cell><cell>0.71</cell><cell>0.64</cell><cell>0.65</cell><cell>0.63</cell><cell>0.61</cell><cell>0.61</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Evaluation</figDesc><table><row><cell>train our model using axiomatic training on different</cell></row><row><cell>kinds of datasets, TS1, TS2, and OCC, with different po-</cell></row><row><cell>sitional encoding (NoPE, LPE, and SPE) as described in</cell></row><row><cell>Sec 5.1. Results on all evaluation settings are in Appendix</cell></row><row><cell>Tables A3, A4 and A5.</cell></row></table><note><p>MultiEval SLR Dataset. We evaluate our models and other baselines on the challenging MultiEval SLR dataset with branching factor 1.4. Accuracy of axiomatically trained models with LM baselines on the causal graphs with branching factor 1.4. See Sec 5.4 for details.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Evaluation on the Corr2Cause Task from</figDesc><table><row><cell cols="3">Branching (Bfactor = 1.4)</cell><cell></cell><cell></cell></row><row><cell>Models</cell><cell>5</cell><cell>8</cell><cell>10</cell><cell>12</cell></row><row><cell>Baselines</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GPT-4</cell><cell cols="2">0.53 0.544</cell><cell>0.62</cell><cell>0.52</cell></row><row><cell>Finetuned Results</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Llama-3-8b-Instruct</cell><cell cols="4">0.474 0.490 0.470 0.482</cell></row><row><cell>Finetuned Llama</cell><cell cols="4">0.796 0.738 0.718 0.670</cell></row><row><cell>Models with different PEs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SPE</cell><cell>0.67</cell><cell>0.59</cell><cell>0.56</cell><cell>0.55</cell></row><row><cell>LPE</cell><cell>0.67</cell><cell>0.61</cell><cell>0.57</cell><cell>0.56</cell></row><row><cell>NoPE</cell><cell>0.63</cell><cell>0.58</cell><cell>0.53</cell><cell>0.53</cell></row><row><cell>RoPE</cell><cell>0.70</cell><cell>0.58</cell><cell>0.54</cell><cell>0.52</cell></row><row><cell cols="5">Table 4: We evaluate the effectiveness of axiomatic train-</cell></row><row><cell cols="5">ing for d-separation under two training paradigms: training</cell></row><row><cell cols="5">a model from scratch and fine-tuning a pretrained Llama</cell></row><row><cell cols="5">model. Our training setup consists of linear sequential</cell></row><row><cell cols="5">causal chains, along with some variations where edges</cell></row><row><cell cols="5">are randomly flipped. However, we assess model perfor-</cell></row><row><cell cols="5">mance on significantly more complex causal graphs featur-</cell></row><row><cell cols="5">ing branching structures and additional nodes, similar to our</cell></row><row><cell cols="5">transitivity analysis. The base Llama Instruct model (prior</cell></row><row><cell cols="5">to fine-tuning) performs on par with random baselines. In</cell></row><row><cell cols="5">contrast, the fine-tuned model demonstrates a substantial</cell></row><row><cell cols="5">improvement, particularly on branched networks. Unlike</cell></row><row><cell cols="5">our transitivity analysis where GPT-4 significantly outper-</cell></row><row><cell cols="5">formed all other models, GPT-4 struggles in this setting,</cell></row><row><cell cols="5">performing no better than the random baseline. Our exper-</cell></row><row><cell cols="5">iments with a decoder-based model trained from scratch</cell></row><row><cell cols="4">show superior performance compared to baselines.</cell><cell></cell></row><row><cell cols="5">takes causal graph premises and hypotheses (for transitivity</cell></row><row><cell cols="5">or d-separation) as inputs and predicts 'Yes'/'No' as output</cell></row><row><cell cols="2">labels. Refer I for more details.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">7.1. Evaluation on CLEAR Benchmark</cell><cell></cell><cell></cell></row><row><cell cols="5">Chen et al. (2024a) introduced CLEAR, a comprehensive</cell></row><row><cell cols="5">benchmark assessing LLMs' causal reasoning across 20</cell></row><row><cell cols="5">tasks, including backdoor adjustment, d-separation and oth-</cell></row><row><cell cols="5">ers. It features diverse question types beyond Yes/No, al-</cell></row><row><cell cols="5">lowing for evaluation on more complex tasks. We test our</cell></row><row><cell cols="5">model, fine-tuned on axiomatic d-separation instances, in</cell></row><row><cell cols="5">a zero-shot setting on CLEAR's Yes/No (YN) and Multi-</cell></row><row><cell cols="5">Choice (MC) questions. Despite training on YN labels,</cell></row><row><cell cols="5">our model outperformed GPT-4 on MC tasks. Fine-tuning</cell></row><row><cell cols="5">on axiomatic instances of d-separation yielded a 20% im-</cell></row><row><cell cols="5">provement over the base model, surpassing GPT-4, while</cell></row><row><cell cols="5">model showed improvement for YN task as well. Despite</cell></row><row><cell cols="5">differences in semantic structure and wordings of finetuning</cell></row><row><cell cols="5">and evaluation instances, our model, exhibited a significant</cell></row><row><cell cols="5">performance gain over the base model. The substantial</cell></row><row><cell cols="5">zero-shot gains across diverse tasks, semanmtic structure</cell></row><row><cell cols="5">and question types, outperforming larger models like GPT-</cell></row><row><cell cols="5">4, suggest that the model effectively applies d-separation</cell></row><row><cell cols="5">rather than relying on spurious associations. Refer Table 3</cell></row><row><cell>for results.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table A2 :</head><label>A2</label><figDesc>Table with examples of d-separation data instances of different causal structural networks used for training and evaluating models. We have instances with null and non empty conditioning set for d-separation in our train and evaluation set.</figDesc><table><row><cell>Type</cell><cell>Data Instance Example</cell><cell>Structure Type</cell><cell>Network Size</cell></row><row><cell>(Train/</cell><cell>(Premise-Hypothesis-Label)</cell><cell></cell><cell>(number of nodes)</cell></row><row><cell>Eval)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>D-Separation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Train</cell><cell>1c1 causes kT. kT causes t4d. t4d causes zW. zW</cell><cell>Short Linear</cell><cell>6</cell></row><row><cell></cell><cell>causes Z4P. Z4P causes pij. Are zW and pij d-separated</cell><cell>Sequence with Non</cell><cell></cell></row><row><cell></cell><cell>given {t4d, kT, Z4P}?: Yes</cell><cell>Empty</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Conditioning Set</cell><cell></cell></row><row><cell>Train</cell><cell>nL causes A. A causes xx. xx causes 5Cg. Are xx and</cell><cell>Short Linear</cell><cell>4</cell></row><row><cell></cell><cell>nL d-separated?: No</cell><cell>Sequence with</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Empty</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Conditioning Set</cell><cell></cell></row><row><cell>Train</cell><cell>ZWn causes P9. u causes P9. B causes u. NS causes B.</cell><cell>Short Sequence</cell><cell>5</cell></row><row><cell></cell><cell>Are P9 and u d-separated given {B}?: No</cell><cell>with Empty</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Conditioning Set</cell><cell></cell></row><row><cell>Train</cell><cell>ZWn causes P9. u causes P9. B causes u. NS causes B.</cell><cell>Short Sequence</cell><cell>5</cell></row><row><cell></cell><cell>Are P9 and u d-separated given {B, ZWn}?: No</cell><cell>with Empty</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Conditioning Set</cell><cell></cell></row><row><cell>Eval</cell><cell>FZg causes l. FZg causes Y. Y causes vEU. a causes</cell><cell>Long Sequence</cell><cell>10</cell></row><row><cell></cell><cell>vEU. f5 causes a. f5 causes R. R causes O. 2WJ causes</cell><cell>with Random</cell><cell></cell></row><row><cell></cell><cell>O. 2WJ causes TDA. TDA causes 9d. Are 2WJ and 9d</cell><cell>Flipping</cell><cell></cell></row><row><cell></cell><cell>d-separated given {FZg}?</cell><cell></cell><cell></cell></row><row><cell>Eval</cell><cell>t causes a. t causes OP. t causes wT. faG causes t. faG</cell><cell>Branching</cell><cell>12</cell></row><row><cell></cell><cell>causes Z. pK causes OP. pK causes 0K3. pK causes</cell><cell></cell><cell></cell></row><row><cell></cell><cell>yUa. 0K3 causes a. 0K3 causes OP. 0K3 causes wT. Z</cell><cell></cell><cell></cell></row><row><cell></cell><cell>causes yUa. rY6 causes faG. rY6 causes wT. Are t and</cell><cell></cell><cell></cell></row><row><cell></cell><cell>yUa d-separated given {faG}?: Yes</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table A3 :</head><label>A3</label><figDesc>Following(Berglund et al., 2024), we evaluate models on inferring cause-and-effect from fully reversed sequences absent in training data. Models trained on OCC perform worse, highlighting the importance of edge-level perturbations for generalization. Accuracy metric is reported, with random baseline = 0.5. Best performance is bolded, while second best is underlined.</figDesc><table><row><cell>C. Results and Analysis</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell><cell>12</cell><cell>13</cell><cell>14</cell><cell>15</cell></row><row><cell></cell><cell cols="9">FS RF FS RF FS RF FS RF FS RF FS RF FS RF FS RF FS RF</cell></row><row><cell>Baselines</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Single Shot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GPT-4</cell><cell cols="9">0.95 0.98 0.97 0.93 0.87 0.94 0.91 0.87 0.90 0.95 0.92 0.92 0.85 0.93 0.93 0.93 0.89 0.86</cell></row><row><cell>Gem-Pro</cell><cell cols="9">0.63 0.73 0.69 0.74 0.64 0.75 0.65 0.81 0.72 0.78 0.60 0.80 0.59 0.68 0.67 0.64 0.61 0.66</cell></row><row><cell>Phi-3</cell><cell cols="9">0.81 0.85 0.96 0.85 0.85 0.85 0.87 0.89 0.90 0.86 0.84 0.85 0.91 0.84 0.90 0.80 0.78 0.85</cell></row><row><cell>Multi Shot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GPT-4</cell><cell cols="9">0.97 0.99 0.93 0.99 0.92 0.96 0.88 0.94 0.89 0.97 0.89 0.93 0.88 0.95 0.93 0.94 0.86 0.94</cell></row><row><cell>Gem-Pro</cell><cell cols="9">0.80 0.82 0.81 0.79 0.78 0.81 0.67 0.79 0.73 0.82 0.74 0.83 0.67 0.78 0.72 0.78 0.68 0.78</cell></row><row><cell>Phi-3</cell><cell cols="9">0.83 0.92 0.89 0.88 0.75 0.86 0.66 0.87 0.80 0.90 0.80 0.85 0.79 0.82 0.71 0.81 0.72 0.82</cell></row><row><cell>Axiomatic Training</cell><cell cols="2">Model</cell><cell></cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell></cell><cell></cell></row><row><cell>TS1 w NoPE TS1 w LPE</cell><cell cols="9">0.99 0.96 0.97 0.95 0.86 0.92 0.78 0.87 0.77 0.90 0.76 0.82 0.77 0.82 0.75 0.83 0.70 0.76 Baselines 0.98 0.96 0.89 0.94 0.81 0.91 0.61 0.86 0.64 0.87 0.64 0.79 0.60 0.80 0.59 0.81 0.57 0.73</cell></row><row><cell>TS1 w SPE TS1 w RoPE</cell><cell cols="9">0.99 0.91 0.88 0.92 0.73 0.77 0.62 0.69 0.63 0.65 0.69 0.60 0.62 0.62 0.59 0.58 0.63 0.58 Zero Shot 0.99 0.96 0.97 0.95 0.89 0.90 0.82 0.84 0.81 0.84 0.86 0.76 0.76 0.81 0.82 0.70 0.78 0.75</cell></row><row><cell>TS2 w NoPE</cell><cell cols="9">GPT-4 0.98 0.93 0.93 0.92 0.82 0.88 0.74 0.84 0.70 0.85 0.70 0.80 0.71 0.76 0.71 0.77 0.66 0.73 0.97 0.99 0.98 0.92</cell></row><row><cell>TS2 w LPE TS2 w SPE TS2 w RoPE</cell><cell cols="9">Gemini Pro 0.99 0.95 0.96 0.94 0.86 0.90 0.72 0.86 0.69 0.85 0.80 0.78 0.73 0.78 0.75 0.80 0.68 0.77 0.61 0.59 0.66 0.62 Phi-3 0.97 0.92 0.91 0.92 0.76 0.85 0.58 0.72 0.60 0.66 0.61 0.56 0.60 0.56 0.58 0.56 0.56 0.59 0.80 0.69 0.73 0.69 0.99 0.97 0.98 0.96 0.90 0.89 0.85 0.87 0.84 0.82 0.87 0.74 0.78 0.80 0.86 0.69 0.78 0.71</cell></row><row><cell>OCC w NoPE OCC w RoPE</cell><cell cols="9">0.99 0.61 0.98 0.62 0.89 0.62 0.90 0.57 0.90 0.57 0.93 0.52 0.87 0.55 0.93 0.50 0.87 0.53 Multi Shot 0.96 0.65 0.98 0.71 0.84 0.68 0.84 0.64 0.80 0.65 0.88 0.56 0.76 0.60 0.84 0.60 0.79 0.55</cell></row><row><cell></cell><cell cols="2">GPT-4</cell><cell></cell><cell cols="4">1.00 1.00 1.00 0.99</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Gemini Pro</cell><cell></cell><cell cols="4">0.95 0.87 0.77 0.71</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Phi-3</cell><cell></cell><cell></cell><cell cols="4">0.93 0.89 0.75 0.75</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Axiomatic Training</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">TS1 w NoPE</cell><cell></cell><cell cols="4">0.99 0.97 0.90 0.91</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">TS1 w LPE</cell><cell></cell><cell cols="4">0.99 0.98 0.95 0.93</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">TS1 w SPE</cell><cell></cell><cell cols="4">1.00 0.98 0.95 0.96</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">TS1 w RoPE</cell><cell></cell><cell cols="4">0.97 0.97 0.96 0.98</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">TS2 w NoPE</cell><cell></cell><cell cols="4">0.98 0.96 0.90 0.91</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">TS2 w LPE</cell><cell></cell><cell cols="4">0.99 0.97 0.92 0.96</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">TS2 w SPE</cell><cell></cell><cell cols="4">0.99 0.97 0.93 0.94</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">TS2 w RoPE</cell><cell></cell><cell cols="4">0.99 0.98 0.97 0.98</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">OCC w NoPE</cell><cell></cell><cell cols="4">0.41 0.24 0.18 0.13</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">OCC w RoPE</cell><cell></cell><cell cols="4">0.59 0.26 0.22 0.20</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table A4 :</head><label>A4</label><figDesc>Accuracy of different models on Transitivity axioms. In this table, we show the accuracy of different models on the transitivity axioms. The rows shows different models considered for comparison. The top rows denote the performance of baseline models with different prompting strategies i.e. single shot and multi-shot prompt (see Sec 5.3 for details). The models listed after axiomatic training shows the performance of transformer models trained from scratch on our axiomatic dataset. TS1 and TS2 denote pretraining data setups 1 and 2 as described in Sec 5.1 and different modifiers are: SPE: Sinusoidal Positional Encoding (PE), LPE: Learnable PE, w/o PE: No PE, RoPE: Rotary Position Embedding. For axiomatic training, the model remains the same across all setups (67 Million parameters based). The training dataset contain graphs of size 3-6 however the models are tested on graphs of size 7-15 (as mentioned in different columns). FS denotes the graphs that only contain chains that are oriented in forward direction and RF contains the graphs that also includes random flipping (see Sec 4.1 for details) same as training set.</figDesc><table><row><cell>Model</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell></row><row><cell>Baselines</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Single Shot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GPT-4</cell><cell cols="7">1.00 1.00 1.00 1.00 1.00 1.00 1.00</cell></row><row><cell>Gemini Pro</cell><cell cols="7">0.96 0.94 0.86 0.81 0.76 0.73 0.71</cell></row><row><cell>Phi-3</cell><cell cols="7">0.99 0.98 0.95 0.94 0.96 0.95 0.93</cell></row><row><cell>Multi Shot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GPT-4</cell><cell cols="7">1.00 1.00 0.98 0.98 0.98 0.98 0.97</cell></row><row><cell>Gemini Pro</cell><cell cols="7">1.00 1.00 0.91 0.90 0.86 0.88 0.84</cell></row><row><cell>Phi-3</cell><cell cols="7">0.93 0.89 0.89 0.84 0.82 0.77 0.79</cell></row><row><cell>Axiomatic Training</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TS1 w NoPE</cell><cell cols="7">1.00 1.00 1.00 0.99 0.98 0.92 0.88</cell></row><row><cell>TS1 w LPE</cell><cell cols="7">1.00 1.00 0.99 0.97 0.92 0.83 0.74</cell></row><row><cell>TS1 w SPE</cell><cell cols="7">0.76 0.61 0.58 0.57 0.54 0.50 0.54</cell></row><row><cell>TS1 w RoPE</cell><cell cols="7">0.65 0.56 0.56 0.49 0.45 0.49 0.50</cell></row><row><cell>TS2 w NoPE</cell><cell cols="7">1.00 0.99 0.92 0.84 0.76 0.71 0.69</cell></row><row><cell>TS2 w LPE</cell><cell cols="7">1.00 0.99 0.96 0.90 0.86 0.76 0.74</cell></row><row><cell>TS2 w SPE</cell><cell cols="7">0.82 0.66 0.60 0.58 0.57 0.55 0.53</cell></row><row><cell>TS2 w RoPE</cell><cell cols="7">0.51 0.48 0.48 0.50 0.46 0.46 0.48</cell></row><row><cell>OCC w NoPE</cell><cell cols="7">1.00 0.99 0.98 0.96 0.96 0.91 0.93</cell></row><row><cell>OCC w RoPE</cell><cell cols="7">0.90 0.77 0.67 0.64 0.65 0.59 0.62</cell></row></table><note><p>s Table A5: Results on node name length generalization. TS1 and TS2 denote Training Data setup 1 and 2 from Section 4 ??. OCC is the third data setup comprising of sequential causal chains. SPE: Sinusoidal PE, LPE: Learnable PE, w/o PE: No PE, RoPE: Rotary Position Embedding. Model remains the same across all setups (67 Million parameter based). For longer node names, NoPE performs best on sequential linear setup. Accuracy metric is used.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table A7 :</head><label>A7</label><figDesc>Performance on DSEP of longer chains with random flipping</figDesc><table><row><cell>Models</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell><cell>12</cell><cell>13</cell><cell>14</cell></row><row><cell>GPT-4</cell><cell>0.57</cell><cell>0.64</cell><cell>0.52</cell><cell cols="5">0.50 0.53 0.52 0.51 0.50</cell></row><row><cell>Llama-3-8b-Instruct</cell><cell>0.51</cell><cell>0.50</cell><cell>0.54</cell><cell cols="5">0.51 0.48 0.51 0.53 0.51</cell></row><row><cell cols="9">Llama-3-8b-Instruct-Finetuned 0.952 0.948 0.954 0.850 0.87 0.88 0.73 0.66</cell></row><row><cell cols="3">Models with different PEs trained from scratch</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SPE</cell><cell>0.93</cell><cell>0.95</cell><cell>0.97</cell><cell cols="5">0.95 0.71 0.61 0.80 0.44</cell></row><row><cell>LPE</cell><cell>0.96</cell><cell>0.93</cell><cell>0.99</cell><cell cols="5">0.92 0.68 0.71 0.62 0.47</cell></row><row><cell>NoPE</cell><cell>0.89</cell><cell>0.93</cell><cell>0.85</cell><cell cols="5">0.94 0.68 0.65 0.60 0.5</cell></row><row><cell>RoPE</cell><cell>0.96</cell><cell>0.91</cell><cell>0.96</cell><cell cols="5">0.92 0.70 0.69 0.54 0.58</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Transitivity Axioms</head><p>Length Generalization: Table <ref type="table">A4</ref> shows the accuracy of different models when evaluated on larger causal chains that were not seen during training. Among the baseline pre-trained LMs, GPT-4 obtains the highest accuracy on both sequential and randomly flipped chains for the multi-shot setting. It is remarkable that our TS2 (NoPE) model obtains competitive performance to the trillion-scale GPT-4 model. In particular, for chains of size 7-12, TS2 (NoPE) obtains higher or comparable accuracy than GPT-4 on both sequential and randomly flipped chains. Similar trends are observed for chains of size 7-13 when compared to GPT-4 in the zero-shot setting. Our model's accuracy decreases for chains of length 14-15 (0.85 for sequential chains and 0.78 for randomly flipped chains) but is still significantly higher than that of LMs like Gemini-Pro and Phi-3. Although in-context examples in multi-shot setting improve the performance of baseline LLMs, TS2 (NoPE) still outperforms both Gemini Pro and Phi-3 in the multi-shot setting. Note that a random prediction would yield a 50%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Additional Results: Role of Data Diversity and Positional Encoding</head><p>Importance of Data Perturbations. We find that diversity of the sequences in train data plays an important role. Model trained on only causal chains (OCC) generalize to longer chains (Table <ref type="table">A4</ref>) but not to other DAG structures (see Figure <ref type="figure">3</ref> for edge flip, Table <ref type="table">2</ref> for branching). Models trained on TS1 or TS2 generalize across all scenarios, including random flip, order permutations, and branching; thus highlighting the impact of incorporating variability at the edge level through random flipping. However, across tasks, we find that TS2 yields higher accuracy than TS1, even as TS1 has more variations due to random flipping. This suggests that while perturbations aid structural generalization, excessive perturbations can hinder it (in particular, random flipping may decrease the length of available causal paths during training).</p><p>Role of Positional Encodings. When comparing models based on positional encoding, we find that models without positional encoding generalize well to both longer chains (up to length 15) and unseen complex graph structures, despite being trained only on linear chains with 3-6 nodes. Models with SPE and LPE perform well on longer chains but struggle with longer node names, even in smaller graphs (Figure <ref type="figure">2</ref>), highlighting their sensitivity to minor perturbations. SPE also underperforms in branching and order-based settings like shuffling and reversal. Learnable PE works up to 9-length chains but drops afterward. Overall, our results extend earlier work on the utility of NoPE <ref type="bibr" target="#b18">(Kazemnejad et al., 2023;</ref><ref type="bibr" target="#b13">Haviv et al., 2022)</ref> to the task of understanding causal sequences and generalizing to both longer length and complex structure at test time. Interestingly, all PEs perform well in randomly flipped sequences, likely due to the short effective path lengths caused by the 0.5 probability of forward-directed edges. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multi-Shot Prompt</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Preliminaries and Notations</head><p>Causal Models Let M = (X, U , F) be a causal model defined over a set of endogenous variables X, exogenous variables U and the causal relationship between then defined by set of structural equations F <ref type="bibr" target="#b11">(Galles &amp; Pearl, 1997)</ref>. Let G be the causal graph associated with the causal model M where the nodes V in G correspond to the variables in M and an edge V i → V j between any two nodes V i , V j denote the causal relationship between them. The causal relationship of node X i is characterized by the functional relationship f i ∈ F s.t., x i = f i (pa i , u i ). Here pa i are the parent of the node X i is the corresponding causal graph G and u i ⊆ U are set of exogenous variables influencing the exogenous variable X i .</p><p>In our work, we assume that there are no hidden confounders so we have one exogenous variable corresponding to every endogenous variable i.e. u i = u i . Each exogenous variable has an associated probability distribution which quantifies the uncertainty in the system i.e. u i ∼ P(u i ). Thus the joint distribution of the exogenous variable is given by P(U ). Since any endogenous variable is a deterministic function of other endogenous and exogenous variables the probability distribution corresponding to the endogenous variable is the push-forward of the exogenous variable i.e P(X) ≜ P # (U ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1. Definitions</head><p>Following the formal definitions provided by <ref type="bibr">(Jin et al., 2024b)</ref>, we explain the following terminologies:</p><p>Markov Property In a directed acyclic graph (DAG) G, the Markov property asserts that each node X i is conditionally independent of its non-descendants given its parents. This can be written as X i ⊥ ⊥ NonDe(X i ) | Pa(X i ), where NonDe(X i ) represents the set of non-descendants of X i , excluding the node itself, and Pa(X i ) denotes its parents. Leveraging the Markov property, the joint distribution over all the nodes can be factorized as:</p><p>Markov Equivalence Class Two directed acyclic graphs (DAGs) are considered Markov equivalent if they induce the same joint distribution P (X). The collection of DAGs that are Markov equivalent is referred to as a Markov equivalence class (MEC). Causal graphs within the same MEC can be easily recognized as they share the same skeleton (i.e., undirected edges) and V-structures (i.e., configurations of the form A → B ← C, where A and C are not directly connected).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">References Transformers: State-of-the-art natural language processing</title>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<editor>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Schlangen</surname></persName>
		</editor>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-10">October 2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Gemini: A family of highly capable multimodal models, 2024. The llama 3 herd of models</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
	<note>Phi-3 technical report: A highly capable language model locally on your phone</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">From query tools to causal architects: Harnessing large language models for advanced causal discovery from data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.16902</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">On pearl&apos;s hierarchy and the foundations of causal inference (1st edition)</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ibeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Icard</surname></persName>
		</author>
		<editor>Geffner, H., Dechter, R., and Halpern, J.</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>ACM Books</publisher>
			<biblScope unit="page" from="507" to="556" />
		</imprint>
	</monogr>
	<note>Probabilistic and Causal Inference: the Works of Judea Pearl</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The reversal curse: Llms trained on &quot;a is b&quot; fail to learn &quot;b is a</title>
		<author>
			<persName><forename type="first">L</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balesni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Stickland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Korbak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Evans</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On the ability and limitations of transformers to recognize formal languages</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattamishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CLEAR: Can language models really understand causal graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2024.findings-emnlp.363</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2024</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Al-Onaizan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y.-N</forename><surname>Chen</surname></persName>
		</editor>
		<meeting><address><addrLine>Miami, Florida, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2024-11">November 2024</date>
			<biblScope unit="page" from="6247" to="6265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Clear: Can language models really understand causal graphs?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The devil is in the detail: Simple tricks improve systematic generalization of transformers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Csordás</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Irie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.49</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">M.-F</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Specia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Yih</surname></persName>
		</editor>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">November 2021</date>
			<biblScope unit="page" from="619" to="634" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Compositional generalization in semantic parsing: Pre-training vs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Furrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Zee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schärli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>specialized architectures</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Axioms of causal relevance. Artificial Intelligence</title>
		<author>
			<persName><forename type="first">D</forename><surname>Galles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0004-3702(97)00047-7.Rele-vance</idno>
		<ptr target="https://doi.org/10.1016/S0004-3702(97)00047-7.Rele-vance" />
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Gunasekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aneja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C T</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Giorno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gopi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Javaheripi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kauffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>De Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Saarikivi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Behl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Kalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Textbooks are all you need</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Transformer language models without positional encodings still learn positional information</title>
		<author>
			<persName><forename type="first">A</forename><surname>Haviv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Izsak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-emnlp.99</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2022</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Kozareva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</editor>
		<meeting><address><addrLine>Abu Dhabi, United Arab Emirates, De</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1382" to="1390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Compositionality decomposed: how do neural networks generalise?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hupkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dankers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bruni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Assessing causal reasoning in language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Leeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gresele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kamal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Blin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Adauto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><surname>Cladder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Can large language models infer causation from correlation?</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Can large language models infer causation from correlation?</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The impact of positional encoding on length generalization in transformers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kazemnejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Padhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Natesan Ramamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Oh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Globerson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="24892" to="24928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Kıcıman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.00050</idno>
		<title level="m">Causal reasoning and large language models: Opening a new frontier for causality</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Passive learning of active causal strategies in agents and language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Oh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Globerson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1283" to="1297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Giorno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gunasekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<title level="m">Textbooks are all you need ii: phi-1.5 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Causal discovery with language models as imperfect experts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Piché</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zantedeschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Drouin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2023 Workshop on Structured Probabilistic Inference &amp; Generative Modeling</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Enhancing reasoning capabilities of llms via principled synthetic logic corpus</title>
		<author>
			<persName><forename type="first">T</forename><surname>Morishita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Morio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sogawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2411.12498</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Making transformers solve compositional tasks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ontañón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Cvicek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fisher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Injecting structural hints: Using language models to study inductive biases in language learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Causality: Models, Reasoning and Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Causality: Models, Reasoning and Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Axiomatization of interventional probability distributions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Soo</surname></persName>
		</author>
		<idno type="DOI">10.1093/biomet/asae043</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<idno type="ISSN">1464-3510</idno>
		<imprint>
			<biblScope unit="page" from="8" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Testing the general deductive reasoning capacity of large language models using ood examples</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saparov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Padmakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Positional description matters for transformers arithmetic</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Roformer: Enhanced transformer with rotary position embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Murtadha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Solving olympiad geometry without human demonstrations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Luong</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-023-06747-5</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">625</biblScope>
			<biblScope unit="issue">7995</biblScope>
			<biblScope unit="page" from="476" to="482" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Causal inference using llm-guided discovery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vashishtha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bachu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Attention is all you need</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Probing for correlations of causal facts: Large language models and causality</title>
		<author>
			<persName><forename type="first">M</forename><surname>Willig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zečević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Dhami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Causal parrots: Large language models may talk causality but are not causal</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zečević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Willig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Dhami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Unveiling transformers with lego: a synthetic reasoning task</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Backurs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gunasekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wagner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Given a DAG (directed acyclic graph) with nodes</title>
		<author>
			<persName><forename type="first">; C</forename><surname>Premise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName><forename type="first">C-&gt;v</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P-&gt;v</forename></persName>
		</author>
		<author>
			<persName><forename type="first">C-&gt;z</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Z-&gt;p</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Z-&gt;v</forename><surname>Hypothesis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Which of the following nodesets can d-separate node C and node P? A. {&apos;Z</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
