<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DyC-STG: Dynamic Causal Spatio-Temporal Graph Network for Real-time Data Credibility Analysis in IoT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-09-08">8 Sep 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Guanjie</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Boyi</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peihan</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Feiyi</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinkui</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mengying</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuiguang</forename><surname>Deng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DyC-STG: Dynamic Causal Spatio-Temporal Graph Network for Real-time Data Credibility Analysis in IoT</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-09-08">8 Sep 2025</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2509.06483v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The wide spreading of Internet of Things (IoT) sensors generates vast spatio-temporal data streams, but ensuring data credibility is a critical yet unsolved challenge for applications like smart homes. While spatio-temporal graph (STG) models are a leading paradigm for such data, they often fall short in dynamic, human-centric environments due to two fundamental limitations: (1) their reliance on static graph topologies, which fail to capture physical, event-driven dynamics, and (2) their tendency to confuse spurious correlations with true causality, undermining robustness in human-centric environments. To address these gaps, we propose the Dynamic Causal Spatio-Temporal Graph Network (DyC-STG), a novel framework designed for real-time data credibility analysis in IoT. Our framework features two synergistic contributions: an event-driven dynamic graph module that adapts the graph topology in real-time to reflect physical state changes, and a causal reasoning module to distill causally-aware representations by strictly enforcing temporal precedence. To facilitate the research in this domain we release two new real-world datasets. Comprehensive experiments show that DyC-STG establishes a new state-of-the-art, outperforming the strongest baselines by 1.4 percentage points and achieving an F1-Score of up to 0.930.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The rise of large models and agents is driving the Internet of Things (IoT) towards a new era of advanced autonomous intelligence, which in turn places unprecedented demands on the quality of its underlying data <ref type="bibr" target="#b10">(Guo et al. 2024;</ref><ref type="bibr" target="#b1">Aouedi et al. 2024</ref>). In the smart home scenario, this deep integration of Artificial Intelligence (AI) and IoT is transforming living spaces into vast and complex sensing networks <ref type="bibr" target="#b11">(Huda et al. 2024)</ref>. The high-dimensional, multivariate time-series data streams continuously generated by these networks form the very backbone of advanced automated services, such as intelligent energy management <ref type="bibr" target="#b24">(Nikpour et al. 2025)</ref>, proactive security <ref type="bibr" target="#b28">(Rehman et al. 2024)</ref>, and personalized scene recommendations <ref type="bibr">(Xiao et al. 2023)</ref>.</p><p>However, the performance and reliability of all such intelligent services hinge entirely upon the credibility of the data that drives them. Consequently, the issue of data credibility-that is, whether the data accurately reflects the true state of the physical world-has become a core bottleneck impeding the advancement of intelligent systems toward greater autonomy and reliability. While Spatio-Temporal Graph Neural Networks (STGNNs) have achieved tremendous success in modeling such dependencies, particularly in structured data scenarios like traffic flow forecasting <ref type="bibr" target="#b15">(Ju et al. 2024;</ref><ref type="bibr" target="#b17">Kong, Guo, and Liu 2024)</ref>, their direct application to the smart home context reveals two fundamental limitations stemming from the unique dynamic and eventdriven nature of the environment: 1. Static Assumption of Spatial Dependencies: The majority of existing methods rely on a pre-defined, static graph topology to capture spatial correlations <ref type="bibr" target="#b31">(Tang et al. 2023;</ref><ref type="bibr" target="#b26">Pazho et al. 2023)</ref>. In a smart home, however, the physical relationships between sensors are dynamic. For instance, opening or closing a window fundamentally alters the correlation strength between indoor and outdoor temperature sensors. Even models that employ adaptive adjacency matrices <ref type="bibr" target="#b3">(Chen et al. 2023;</ref><ref type="bibr" target="#b30">Sun et al. 2025</ref>) often learn graph structures that evolve too slowly to capture the abrupt topological changes triggered by discrete events. This assumption of a static or slowly-changing graph fundamentally limits the model's capacity to represent real-world physical dynamics. 2. Causal Confusion in Temporal Dependencies: In the complex environment of a smart home, a single human activity can trigger simultaneous changes across multiple sensors, creating inter-dependencies between variables in multivariate time series. While existing deep learning models are good at capturing these co-occurrence patterns, they often struggle to distinguish true causal chains from spurious correlations <ref type="bibr" target="#b8">(Gong et al. 2024)</ref>. This "correlation-causation confusion" is a critical flaw; a model that learns a spurious link between, for instance, a coffee machine and a toaster (which are often used together in the morning) may fail when only one is used. This disregard for the underlying causal mechanisms compromises the model's robustness, making it liable to misinterpret valid but less common sequences of events as anomalies.</p><p>Recent efforts have begun to tackle these issues from separate angles. To capture dynamic spatial dependencies, existing research <ref type="bibr" target="#b7">(Geng et al. 2024;</ref><ref type="bibr" target="#b21">Liu and Zhang 2024)</ref> have moved beyond static graphs by learning topologies that evolve based on data correlations. On the temporal front, another line of work <ref type="bibr" target="#b6">(Fu, Pan, and Zhang 2024;</ref><ref type="bibr" target="#b8">Gong et al. 2024</ref>) has focused on explicit causal discovery, attempting to first learn a causal graph from data and then use it as a prior to guide the model's predictions. However, the dynamic graph models learn abstract correlations that are frequently ungrounded from the discrete, physical events that truly govern the environment. Meanwhile, approaches based on explicit causal discovery often rely on strong statistical assumptions and decouple the causal learning from the end-to-end representation learning process. A critical gap thus persists: the lack of a unified framework that marries physically-grounded, event-driven dynamic graphs with robust causal reasoning embedded within the architecture.</p><p>To address these challenges and bridge this gap, this paper proposes a novel framework named the Dynamic Causal Spatio-Temporal Graph Network (DyC-STG), designed as an end-to-end solution with deep reasoning capabilities for assessing data credibility in smart homes. Specifically, we design an event-driven dynamic graph construction module that dynamically reconstructs the graph topology based on the state of control nodes, thereby precisely capturing dynamic spatial dependencies. Furthermore, we introduce a causality-enhanced Transformer module <ref type="bibr">(Wang et al. 2024b;</ref><ref type="bibr" target="#b0">Aky√ºrek et al. 2024;</ref><ref type="bibr" target="#b23">Nichani, Damian, and Lee 2024)</ref> that fundamentally redefines the mechanism's temporal receptive field. Unlike a global, bidirectional field that captures all correlations, our approach imposes a causal structure where the receptive field for each time step is strictly confined to its historical context. This forces the model to learn directional, cause-and-effect relationships rather than mere temporal cooccurrence.</p><p>The main contributions are summarized as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Works</head><p>Ensuring the credibility of massive Internet of Things (IoT) data is fundamental for advanced applications <ref type="bibr" target="#b25">(Paramesha, Rane, and Rane 2024)</ref>. Early statistical and machine learning methods for data quality assessment <ref type="bibr" target="#b31">(Tang et al. 2023;</ref><ref type="bibr" target="#b26">Pazho et al. 2023</ref>) are often inadequate for dynamic environments because they fail to model complex spatio-temporal dependencies.</p><p>Spatio-Temporal Graph Models for IoT Data. Spatio-Temporal Graph Neural Networks (STGNNs) have rapidly evolved to capture these dependencies <ref type="bibr" target="#b13">(Jin et al. 2023)</ref>. Firstgeneration models like DCRNN <ref type="bibr" target="#b19">(Li et al. 2017)</ref>, STGCN <ref type="bibr" target="#b39">(Yu, Yin, and Zhu 2017)</ref>, STFGNN <ref type="bibr" target="#b18">(Li and Zhu 2021)</ref>, and STGNCDE <ref type="bibr" target="#b5">(Choi et al. 2022</ref>) fused graph convolutions with sequence models but were limited by static graph structures, a bottleneck for adapting to physical events in smart homes <ref type="bibr" target="#b38">(Xie et al. 2023;</ref><ref type="bibr" target="#b17">Kong, Guo, and Liu 2024)</ref>. Second-generation models such as GWNet, MT-GNN, and AGCRN <ref type="bibr" target="#b32">(Tian and Chan 2021;</ref><ref type="bibr" target="#b36">Wu et al. 2020;</ref><ref type="bibr" target="#b40">Zheng et al. 2023</ref>) introduced adaptive graphs, yet these learned topologies remain fixed post-training, lacking realtime responsiveness.Third-generation models shifted to attention and Transformers, with works like ST-MambaSync <ref type="bibr" target="#b29">(Shao et al. 2025)</ref>, QA-STGACN <ref type="bibr" target="#b27">(Qiu et al. 2024)</ref>, STFT <ref type="bibr">(Wang et al. 2024b</ref>), SSL-STMFormer <ref type="bibr" target="#b20">(Li et al. 2025)</ref>, and PDFormer <ref type="bibr" target="#b12">(Jiang et al. 2023</ref>) dynamically weighting spatio-temporal dependencies. Their core limitation, however, is a tendency to capture all correlations, failing to distinguish true causal drivers from spurious associations. This "correlation-causation confusion" critically undermines robustness in aperiodic, human-driven scenarios.</p><p>Causal Reasoning in Time-Series Analysis. Distinguishing causality from correlation is central to model robustness in time-series analysis. Traditional methods like Granger causality tests are hampered by linearity and stationarity assumptions <ref type="bibr" target="#b8">(Gong et al. 2024;</ref><ref type="bibr" target="#b16">Kapoor et al. 2024)</ref>. While some deep learning works learn explicit causal graphs <ref type="bibr" target="#b14">(Jing et al. 2024;</ref><ref type="bibr">Zhang and Wu 2024)</ref> or perform complex counterfactual reasoning <ref type="bibr">(Wang et al. 2024a;</ref><ref type="bibr" target="#b33">Verma et al. 2024)</ref>, they are often too computationally prohibitive for efficient inference. A more pragmatic approach is enforcing causal- The architecture adopts a cascaded design that decouples spatial and temporal modeling. First, spatial information is aggregated independently at each time step via a stack of GAT layers, which operate on a dynamic graph structure derived from the physical environment. Subsequently, the resulting spatially-aware features are fed into parallel branches for deep temporal modeling and causal reasoning. Finally, a gating mechanism intelligently fuses these two representations before a prediction head generates the final output. ity through architectural design, such as using masking mechanisms to prevent information leakage from the future, thereby respecting the temporal arrow of causality <ref type="bibr" target="#b4">(Chen et al. 2024)</ref>.</p><p>Our DyC-STG framework is engineered to bridge these gaps. It integrates an event-driven dynamic graph for realtime physical adaptation with a causal Transformer that uses strict masking to enforce temporal causality. This novel fusion of Dynamic Physical Perception and Causal Logic Distillation offers a new paradigm to address the data credibility challenge in complex IoT systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology</head><p>This section details the technical architecture of our proposed DyC-STG. We begin by formalizing the problem and then elaborate on the four core modules of our framework which is shown in Figure <ref type="figure" target="#fig_1">2:</ref> (1) Dynamic Graph Construction; (2) Spatial Dependency Modeling; (3) Temporal Feature Extraction and Causal Refinement; (4) the Gated Fusion and Output Layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem Formulation</head><p>The primary objective of this work is to assess the credibility of data streams originating from a dynamically evolving smart home sensor network. We formally model the network's topological structure at any given time step as a timevarying graph G t = (V, E t ), where V is the set of N sensor nodes (i.e., |V| = N ), and E t is the time-varying edge set representing their connectivity.</p><p>Formally, the model has two primary inputs: (1) a multivariate time series tensor X ‚àà R B√óT √óN √óDin , where B is the batch size, T is the length of the historical window, and D in is the dimension of raw and engineered features for each sensor at each time step; and (2) a sequence of adjacency matrices A = {A 1 , A 2 , . . . , A T } that represents the evolving graph topology.</p><p>The goal is to learn a mapping function f that takes the historical spatio-temporal features and the dynamic graph structure to predict the credibility of each data point:</p><formula xml:id="formula_0">f : (X, A) ‚Üí Y (1)</formula><p>The model outputs a credibility tensor Y ‚àà R B√óT √óN √ó1 , where each element Y b,t,n represents the predicted probability that a sensor reading is trustworthy. This score is converted to a binary decision D b,t,n by applying a threshold Œ∂ ‚àà (0, 1):</p><formula xml:id="formula_1">D b,t,n = Trustworthy if Y b,t,n &gt; Œ∂ Untrustworthy if Y b,t,n ‚â§ Œ∂ (2)</formula><p>To ensure robustness against class imbalance, the threshold Œ∂ is not fixed but is empirically calibrated by maximizing the F1-Score on the validation set.</p><p>The final decision D is a critical trigger for system-level actions. A determination of "Untrustworthy" can initiate data quarantining and imputation, generate alerts for human verification, or signal the need for proactive hardware maintenance. This mechanism ensures that high-level autonomous services are shielded from corrupted data, thus preserving the integrity and reliability of the entire IoT ecosystem.  = 1), a modulation function activates latent pathways to produce the effective adjacency matrix A t+‚àÜt (right). In this visualization, colored blocks represent dense intra-group connections (blue: temperature, orange: humidity, red: light), while gray blocks represent inter-group connections, which are dynamically activated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dynamic Graph Construction</head><p>A critical limitation of conventional spatio-temporal models is the assumption of a static graph, which fails to capture how discrete physical events alter the nature of sensor correlations. Our work posits that spatial dependencies are not static but are, in fact, conditional upon the dynamic state of the physical environment.</p><p>To encode this physical prior into our model, we introduce the Dynamic Graph Construction module as shown in Figure <ref type="figure" target="#fig_2">3</ref>. This module generates a time-varying topology by modulating a latent static graph based on real-time environmental state changes, unfolding in a two-stage process for each time step t:</p><p>1. Latent Static Topology. We first define a base adjacency matrix, A Base ‚àà R N √óN . This matrix represents the latent, time-invariant topology of the network, encoding all potential interaction pathways based on physical proximity or functional coupling.</p><p>2. State-Driven Structural Modulation. We identify a subset of sensors as structural control nodes V c ‚äÇ V, corresponding to physical entities whose state changes causally govern the connectivity between spaces (e.g., doors, windows). At each time step t, the state s t c of a control node c ‚àà V c acts as a gating mechanism. The edge between an affected sensor pair (i, j) is dynamically modulated to form the effective adjacency matrix A t :</p><formula xml:id="formula_2">A t ij = f mod (s t c ) ‚Ä¢ A Base (i, j)<label>(3</label></formula><p>) where f mod is a deterministic modulation function. For binary controls, we use an identity map (f mod (s) = s), which translates the physical state into a topological switch that either permits or severs the interaction path. This localized, rule-based modulation allows for elegant handling of complex scenarios with multiple, independent control events.</p><p>This mechanism yields a sequence of adjacency matrices, A = {A 1 , A 2 , . . . , A T }, where each A t offers a physicallygrounded and context-aware snapshot of the network's true connectivity. This provides the downstream spatio-temporal layers with a far more realistic foundation for reasoning about dynamic events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial Dependency Modeling</head><p>Our spatial dependency module consists of L stacked Graph Attention Network (GAT) layers designed to learn complex topological dependencies. To enable efficient computation, the input tensor H (0) ‚àà R B√óT √óN √óDModel is reshaped to treat the time dimension as an extension of the batch, allowing T independent graph snapshots to be processed in parallel.</p><p>Within each GAT layer, node features are updated by aggregating information from their neighbors, guided by our dynamically constructed graph A t as shown in Figure <ref type="figure" target="#fig_3">4</ref>. The core of this process is a masked attention mechanism. First, attention coefficients e ij,t between nodes i and j are calculated using a shared linear transformation W and a LeakyReLU-based scoring function. To ensure the GAT adheres strictly to the time-varying topology, we apply a mask derived from A t . This mask sets the attention scores for all non-adjacent nodes to -‚àû, effectively restricting information flow to only the edges present in the current graph snapshot.</p><p>These masked scores are then normalized row-wise using the Softmax function to produce the final attention weights Œ± ij,t . The updated node representations for layer l are computed via a weighted aggregation of the transformed neighbor features:</p><formula xml:id="formula_3">H (l) t = œÉ Ô£´ Ô£≠ j‚ààNi(t)‚à™{i} Œ± ij,t H (l-1) j,t W Ô£∂ Ô£∏ (4)</formula><p>where N i (t) is the set of neighbors of node i at time t according to A t , and œÉ is a non-linear activation function.</p><p>After passing through L such layers, the module outputs the spatially-aware feature tensor H spatial . Each feature vector within this tensor is no longer an isolated sensor reading but a deep contextual summary, dynamically integrating information from its relevant multi-hop neighborhood at that specific moment. The standard Transformer computes attention bidirectionally, capturing strong correlations between co-occurring events. In contrast, our Causal Reasoning module applies a causal mask, enforcing a unidirectional information flow, allowing the model to distinguish preceding events as more likely causes, thus moving beyond spurious correlations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Temporal Feature Extraction</head><p>The spatially-aware feature tensor H spatial serves as the input to the temporal feature extraction module. The core of this module is architected as a multi-layer, multi-head bidirectional Transformer encoder. As shown in Figure <ref type="figure" target="#fig_4">5</ref>, a key strategy is to logically treat the input tensor H spatial as a batch of B √ó N independent time series, each of length T .</p><p>For each of these sequences, (h (n,1) , h (n,2) , . . . , h (n,T ) ), the encoder computes bidirectional self-attention along the temporal dimension to capture its dynamics. Under this attention mechanism, each time step t generates a Query vector, which is used to score its compatibility against the Key vectors of all other time steps within the sequence. This enables the model to construct a global attention map, allowing it to effectively capture long-range temporal dependencies and identify complex patterns.</p><p>The module's final output is a deeply-fused feature tensor, which we term the Spatio-Temporal Representation, denoted as H st ‚àà R B√óT √óN √óDmodel . At this stage, each feature vector h st,n,t encapsulates the state of sensor n at time t, enriched with both its own holistic temporal context across the entire window and the comprehensive spatial context from its neighbors at all corresponding time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Causal Context Refinement</head><p>Although the bidirectional representation H st is rich, it captures all correlations indiscriminately, including noncausal temporal co-occurrences. To address this, our Causal Context Refinement Module fundamentally redefines the model's temporal receptive field as shown in Figure <ref type="figure" target="#fig_4">5</ref>.</p><p>Unlike a global, bidirectional field that accesses both past and future data, our approach imposes a strict causal structure. This is implemented via a multi-head self-attention mechanism governed by a causal mask. This mask strictly confines the receptive field for each time step t to its historical context-that is, to information from steps 1, . . . , t. This design enforces an autoregressive process, as formalized below:</p><formula xml:id="formula_4">H Causal = MaskedSelfAttention(H st )<label>(5)</label></formula><p>By constraining the information flow in this manner, the module forces the model to learn directional, cause-andeffect relationships rather than mere statistical associations. The resulting output, H Causal ‚àà R B√óT √óN √óDModel , is a representation firmly grounded in the arrow of time, making it inherently more robust against spurious correlations and providing a sounder basis for trustworthy predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gated Fusion and Output Layer</head><p>At this stage, we introduce a Gated Fusion Mechanism to intelligently integrate H st and H Causal . A gate vector G is generated by first concatenating both feature tensors and then passing them through a linear layer followed by a Sigmoid activation function:</p><formula xml:id="formula_5">G = œÉ(W g [H (L) ‚à•H Causal ] + b g ) (6)</formula><p>where œÉ is the Sigmoid function and ‚à• denotes the concatenation operation. Each element in the gate G is a value within the range (0, 1) that dynamically arbitrates between the two feature sources. The final fused representation, H fused , is then computed as a weighted sum, modulated by the gate G:</p><formula xml:id="formula_6">H fused = G ‚äô H (L) + (1 -G) ‚äô H Causal (7)</formula><p>Finally, H fused is passed through a two-layer feed-forward network, which serves as the prediction head, followed by a final Sigmoid function to produce the credibility score tensor, and the tensor is converted into a final classification by the thresholding mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment Datasets</head><p>This study utilizes two large-scale, real-world datasets, SHSD92 and SHSD104, collected within a dedicated smart home testbed. The experimental environment is equipped with 31 heterogeneous sensors-comprising 8 temperature, 8 humidity, 8 light, and 7 door sensors-which feature varying native sampling rates and are deployed according to the floor plan shown in Figure <ref type="figure" target="#fig_1">2</ref>. Each dataset is collected over a one-month period, resulting in 2.5 GB of data in CSV format that captures a diverse range of human activity patterns such as cooking, bathing, and appliance use, with SHSD104 designed to present more complex scenarios.</p><p>To establish a reliable ground truth, we employ a semiautomated process that combines manual annotation of observed hardware failures with the controlled injection of realistic anomalies (e.g., sensor drift and spikes). This process results in an overall anomaly ratio of approximately 15%. Furthermore, more than 500 controlled dynamic events are precisely logged to provide the ground truth for validating our dynamic graph mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines</head><p>We compare DyC-STG with 12 state-of-the-art (SOTA) baselines, carefully selected to represent the primary paradigms in spatio-temporal modeling. To ensure a comprehensive evaluation, we include: (1) Graph Neural Network-based models (DCRNN, STGCN, GWNET, MT-GNN, STFGNN, STGNCDE <ref type="bibr" target="#b19">(Li et al. 2017;</ref><ref type="bibr" target="#b39">Yu, Yin, and Zhu 2017;</ref><ref type="bibr" target="#b18">Li and Zhu 2021;</ref><ref type="bibr" target="#b5">Choi et al. 2022;</ref><ref type="bibr" target="#b32">Tian and Chan 2021;</ref><ref type="bibr" target="#b36">Wu et al. 2020</ref>)), which are foundational for capturing structured dependencies; (2) Self-attention-based models (STTN, GMAN, ASTGCN, STJGCN <ref type="bibr" target="#b22">(Ma, Zhao, and Hou 2024;</ref><ref type="bibr" target="#b41">Zheng et al. 2020;</ref><ref type="bibr" target="#b9">Guo et al. 2019;</ref><ref type="bibr" target="#b2">Bai et al. 2020</ref>)), which leverage Transformer architectures; and (3) Dynamic Graph models (AGCRN, PDFormer <ref type="bibr" target="#b40">(Zheng et al. 2023;</ref><ref type="bibr" target="#b12">Jiang et al. 2023</ref>)), which models evolving spatial correlations explicitly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment settings</head><p>Dataset Processing. We first employ a Savitzky-Golay filter to smooth the raw sensor signals and mitigate highfrequency noise. All time series are then uniformly downsampled to 0.5 Hz for temporal alignment. We use a slidingwindow approach to generate samples, where each sample consists of a 150-step (5-minute) historical context. The window slides in 15 steps. Crucially, our task is to leverage this 5-minute spatio-temporal context to assess the credibility of every data point within the same window, rather than forecasting future values. Finally, the generated samples are chronologically divided into training, validation, and testing sets with a ratio 70% / 15% / 15%. Model Settings. All models were trained for 100 epochs on an NVIDIA RTX 4060 GPU (16GB) using PyTorch 2.2.1. We employed the AdamW optimizer with an initial learning rate of 0.001, a weight decay of 0.0001, a batch size of 32, and a Cosine Annealing scheduler for dynamic learning rate adjustment.</p><p>To address the inherent class imbalance, we utilized a Focal Loss function with parameters Œ± = 0.75 and Œ≥ = 2.0. For our DyC-STG architecture, the optimal hyperparameters (d model = 128, 4 attention heads) were determined through a grid search evaluated on the validation set. Baseline models adopted the hyperparameter settings from their original publications, with only their output layers adapted for our classification task.</p><p>Evaluation Metrics. We assess model performance using four standard classification metrics: Precision, Recall, F1-Score, and AUC (Area Under the Receiver Operating Characteristic Curve). The F1-Score offers a balanced measure between Precision and Recall. AUC provides a comprehensive evaluation of the model's ability to distinguish between classes across all possible thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance Comparison</head><p>The overall performance of our proposed DyC-STG model against all baselines on the SHSD92 and SHSD104 datasets is presented in Table <ref type="table" target="#tab_2">1</ref>. The results unequivocally demonstrate the superiority of our framework across all evaluation metrics on both datasets. The results in Table <ref type="table" target="#tab_2">1</ref> demonstrate that DyC-STG significantly outperforms all baselines, establishing a new state-of-the-art with an F1-Score of 0.9297 and an AUC of 0.9886 on SHSD92. This success is part of a clear trend where dynamic graph models (including PDFormer, AGCRN) substantially outperform static methods, validating our core hypothesis on the necessity of modeling dynamic dependencies. Furthermore, DyC-STG exhibits superior robustness on the more challenging SHSD104 dataset, where its F1-Score drops by a mere 1.2% compared to a 5.4% decline for classic models like STGCN, highlighting its strong generalization capabilities.</p><p>DyC-STG's advantage, particularly over other dynamic models like PDFormer, stems from its unique architecture. The event-driven dynamic graph provides a more principled model of physical state changes, while the causal reasoning module disambiguates true cause-and-effect from mere correlation. This combination enables a more fundamental and robust understanding of the underlying system dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study</head><p>Analysis of Model Components. To validate the contribution of each component within DyC-STG, we conducted a comprehensive ablation study, with the results presented in Table <ref type="table" target="#tab_3">2</ref>. The findings confirm that all modules are integral to the model's success, as the removal of any single one leads to a significant degradation in performance. The key insights are as follows: Causal Reasoning: This module proves to be the most critical component. Its removal incurs the most substantial performance drop, with the F1-Score on SHSD92 plummeting by 10.4%. This starkly demonstrates the necessity of refining spatio-temporal features to enforce temporal causality and filter out spurious correlations. Dynamic Graph: The dynamic graph mechanism is essential. Replacing our event-driven dynamic graph with a static one results in a significant 4.87% decrease in F1-Score, which quantitatively validates our core hypothesis on the importance of adapting the graph structure to physical events. Transformer Encoder: The Transformer is vital for modeling temporal context. Its removal causes an 8.3% drop in F1-Score, highlighting the importance of the architecture for capturing complex, long-range temporal dependencies. Graph Attention (GAT): Finally, omitting the GAT layers also diminishes performance. This validates our choice of an anisotropic spatial aggregation mechanism, which allows  The results across both datasets consistently reveal a nonlinear relationship between model depth and efficacy. A distinct "sweet spot" emerges at a moderate depth, with the (G l =2, T l =2) configuration achieving the optimal F1-Score of 0.9297 on the SHSD92 dataset. Shallower archi-tectures (i.e., G l =1 or T l =1) suffer from significant performance degradation, likely due to insufficient capacity to capture complex spatio-temporal dependencies. Conversely, increasing the depth beyond two layers (e.g., to G l =3, T l =3) leads to diminishing returns or even a slight performance decline. This is likely attributable to challenges such as oversmoothing in deeper GAT layers and increased optimization difficulty in deeper Transformers. This analysis empirically validates our choice of a 2+2 layer architecture, as it strikes an optimal balance between model capacity and performance, avoiding both underfitting and the adverse effects of excessive depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we introduce DyC-STG, a novel framework designed to overcome the limitations of existing models in assessing IoT data credibility. By integrating an eventdriven dynamic graph with a causality-enhanced Transformer, DyC-STG adapts to physical state changes while distinguishing causal drivers from spurious correlations. DyC-STG achieves state-of-the-art performance on two real-world smart home datasets. Ablation studies empirically validate our central hypothesis: both the dynamic graph adaptation and the causal reasoning module are critical to its superior performance. Future work will focus on enhancing the framework's autonomy by automatically learning</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of the core challenges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: The Overall Architecture of the DyC-STG. The architecture adopts a cascaded design that decouples spatial and temporal modeling. First, spatial information is aggregated independently at each time step via a stack of GAT layers, which operate on a dynamic graph structure derived from the physical environment. Subsequently, the resulting spatially-aware features are fed into parallel branches for deep temporal modeling and causal reasoning. Finally, a gating mechanism intelligently fuses these two representations before a prediction head generates the final output.</figDesc><graphic coords="3,66.98,158.26,148.26,90.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of the Dynamic Graph Construction mechanism. The process begins with a static base graph, A Base (left), which represents the latent physical topology. Upon a state change in a control node (e.g., a door opening, s t+‚àÜt c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The dynamic Graph Attention mechanism. Attention weights are computed only over the active edges defined by the dynamic graph topology at a given time step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Comparison of information flow in the standard bidirectional Transformer (left) and Causal Reasoning module (right).The standard Transformer computes attention bidirectionally, capturing strong correlations between co-occurring events. In contrast, our Causal Reasoning module applies a causal mask, enforcing a unidirectional information flow, allowing the model to distinguish preceding events as more likely causes, thus moving beyond spurious correlations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Evaluation results of the impact of the of model layers of GAT and Transformer encoder. The yellow/white spot indicates the best/second-best result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Adjacency Matrix ùë® ùë©ùíÇùíîùíÜ at time t Adjacency Matrix ùë® ùíï+‚àÜùíï at time t+Œît</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Quantitative comparison of DyC-STG against state-of-the-art baselines on the data credibility assessment task. Bold and underlined values indicate the best and second-best results, respectively.</figDesc><table><row><cell>Model</cell><cell cols="2">Model Variant</cell><cell></cell><cell cols="2">SHSD92</cell><cell></cell><cell></cell><cell cols="2">SHSD104</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Precision Recall F1-Score</cell><cell>AUC</cell><cell cols="3">Precision Recall F1-Score</cell><cell>AUC</cell></row><row><cell>DCRNN</cell><cell cols="2">DConv+GRU</cell><cell>0.8615</cell><cell>0.8321</cell><cell>0.8466</cell><cell>0.9588</cell><cell>0.8251</cell><cell>0.7835</cell><cell>0.8038</cell><cell>0.9255</cell></row><row><cell>STGCN</cell><cell cols="2">GCN+TCN</cell><cell>0.8559</cell><cell>0.8294</cell><cell>0.8424</cell><cell>0.9543</cell><cell>0.8176</cell><cell>0.7769</cell><cell>0.7967</cell><cell>0.9212</cell></row><row><cell>GWNet</cell><cell cols="2">Graph+TCN</cell><cell>0.9152</cell><cell>0.8718</cell><cell>0.8929</cell><cell>0.9785</cell><cell>0.8813</cell><cell>0.8351</cell><cell>0.8576</cell><cell>0.9593</cell></row><row><cell>MTGNN</cell><cell cols="2">Graph+GCN</cell><cell>0.9031</cell><cell>0.8665</cell><cell>0.8844</cell><cell>0.9743</cell><cell>0.8655</cell><cell>0.8288</cell><cell>0.8467</cell><cell>0.9519</cell></row><row><cell>STFGNN</cell><cell cols="2">TFusion+GNN</cell><cell>0.8995</cell><cell>0.8501</cell><cell>0.8741</cell><cell>0.9702</cell><cell>0.8596</cell><cell>0.8105</cell><cell>0.8343</cell><cell>0.9471</cell></row><row><cell cols="3">STGNCDE GCN+CDE</cell><cell>0.9088</cell><cell>0.8473</cell><cell>0.8770</cell><cell>0.9731</cell><cell>0.8724</cell><cell>0.8152</cell><cell>0.8428</cell><cell>0.9524</cell></row><row><cell>STTN</cell><cell cols="2">ST-Trans</cell><cell>0.9105</cell><cell>0.8699</cell><cell>0.8897</cell><cell>0.9769</cell><cell>0.8858</cell><cell>0.8395</cell><cell>0.8620</cell><cell>0.9601</cell></row><row><cell>GMAN</cell><cell cols="2">ST-Attn</cell><cell>0.9026</cell><cell>0.8753</cell><cell>0.8887</cell><cell>0.9754</cell><cell>0.8715</cell><cell>0.8411</cell><cell>0.8560</cell><cell>0.9567</cell></row><row><cell>ASTGCN</cell><cell cols="2">Attn+GCN+GRU</cell><cell>0.8749</cell><cell>0.8402</cell><cell>0.8572</cell><cell>0.9634</cell><cell>0.8392</cell><cell>0.7955</cell><cell>0.8167</cell><cell>0.9318</cell></row><row><cell>AGCRN</cell><cell cols="2">GCN+GRU</cell><cell>0.9599</cell><cell>0.8217</cell><cell>0.8856</cell><cell>0.9835</cell><cell>0.9387</cell><cell>0.8021</cell><cell>0.8651</cell><cell>0.9712</cell></row><row><cell>STJGCJ</cell><cell cols="2">Graph+Attn</cell><cell>0.8813</cell><cell>0.8564</cell><cell>0.8687</cell><cell>0.9677</cell><cell>0.8488</cell><cell>0.8117</cell><cell>0.8298</cell><cell>0.9396</cell></row><row><cell>PDFormer</cell><cell cols="2">Graph+Trans</cell><cell>0.9288</cell><cell>0.9021</cell><cell>0.9153</cell><cell>0.9819</cell><cell>0.9075</cell><cell>0.8996</cell><cell>0.9035</cell><cell>0.9684</cell></row><row><cell>DyC-STG</cell><cell cols="2">GAT+Trans</cell><cell>0.9597</cell><cell>0.9015</cell><cell>0.9297</cell><cell>0.9886</cell><cell>0.9485</cell><cell>0.8912</cell><cell>0.9189</cell><cell>0.9823</cell></row><row><cell>Dynamic Graph</cell><cell>GAT</cell><cell>Transformer encoder</cell><cell>Causal Reasoning</cell><cell cols="7">SHSD92 Precision Recall F1-Score AUC Precision Recall F1-Score AUC SHSD104</cell></row><row><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell cols="7">0.9597 0.9015 0.9297 0.9886 0.9485 0.8912 0.9189 0.9823</cell></row><row><cell>√ó</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell cols="7">0.9046 0.8585 0.8810 0.9717 0.9088 0.8415 0.8739 0.9665</cell></row><row><cell>‚úì</cell><cell>√ó</cell><cell>‚úì</cell><cell>‚úì</cell><cell cols="7">0.9557 0.8520 0.9009 0.9769 0.9521 0.8577 0.9024 0.9748</cell></row><row><cell>‚úì</cell><cell>‚úì</cell><cell>√ó</cell><cell>‚úì</cell><cell cols="7">0.9373 0.7721 0.8467 0.9559 0.9405 0.7823 0.8546 0.9585</cell></row><row><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>√ó</cell><cell cols="7">0.8583 0.7955 0.8257 0.9534 0.8421 0.8066 0.8239 0.9521</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Ablation study of model components on the SHSD92 and SHSD104 datasets. Bold value indicates the best result.</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Incontext language learning: architectures and algorithms</title>
		<author>
			<persName><forename type="first">E</forename><surname>Aky√ºrek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st International Conference on Machine Learning</title>
		<meeting>the 41st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="787" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A survey on intelligent Internet of Things: Applications, security, privacy, and future directions</title>
		<author>
			<persName><forename type="first">O</forename><surname>Aouedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sacco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Piamrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Marchetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-V</forename><surname>Pham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>IEEE communications surveys &amp; tutorials</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adaptive graph convolutional recurrent network for traffic forecasting</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="17804" to="17815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-scale adaptive graph neural network for multivariate time series forecasting</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="10748" to="10761" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using causal inference to avoid fallouts in data-driven parametric analysis: A case study in the architecture, engineering, and construction industry</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Saluz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schiavon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Geyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Developments in the Built Environment</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">100296</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graph neural controlled differential equations for traffic forecasting</title>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="6367" to="6374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A causal-temporal graphic convolutional network (CT-GCN) approach for TBM load prediction in tunnel excavation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">238</biblScope>
			<biblScope unit="page">121977</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">STGAFormer: Spatial-temporal gated attention transformer based graph neural network for traffic flow forecasting</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page">102228</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Causal discovery from temporal data: An overview and new perspectives</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Attention based spatial-temporal graph convolutional networks for traffic flow forecasting</title>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="922" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Large Language Model Based Multi-agents: A Survey of Progress and Challenges</title>
		<author>
			<persName><forename type="first">T</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wiest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Experts and intelligent systems for smart homes&apos; Transformation to Sustainable Smart Cities: A comprehensive review</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">U</forename><surname>Huda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Adnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Naeem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">238</biblScope>
			<biblScope unit="page">122380</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pdformer: Propagation delay-aware dynamic long-range transformer for traffic flow prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="4365" to="4373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph neural networks for predictive learning in urban computing: A survey</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="5388" to="5408" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Causalityaware spatiotemporal graph neural networks for spatiotemporal time series imputation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 33rd ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1027" to="1037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cool: a conjoint perspective on spatio-temporal graph neural network for traffic forecasting</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page">102341</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Latent diffusion for neural spiking data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Macke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="118119" to="118154" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Spatio-temporal pivotal graph neural networks for traffic flow forecasting</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="8627" to="8635" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Spatial-temporal fusion graph neural networks for traffic flow forecasting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4189" to="4196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.01926</idno>
		<title level="m">Diffusion convolutional recurrent neural network: Data-driven traffic forecasting</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">SSL-STMFormer Self-Supervised Learning Spatio-Temporal Entanglement Transformer for Traffic Flow Prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2025">2025</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="12130" to="12138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Spatial-temporal dynamic graph convolutional network with interactive learning for traffic forecasting</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="7645" to="7660" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Spatial-temporal transformer networks for traffic flow forecasting using a pretrained language model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page">5502</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">How transformers learn causal structure with gradient descent</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nichani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Damian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st International Conference on Machine Learning</title>
		<meeting>the 41st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="38018" to="38070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Intelligent energy management with iot framework in smart cities using intelligent analysis: An application of machine learning methods for complex networks and systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nikpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Yousefi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jafarzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Danesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shomali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Lonbar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">235</biblScope>
			<biblScope unit="page">104089</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Big data analytics, artificial intelligence, machine learning, internet of things, and blockchain for enhanced business intelligence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Paramesha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning, Internet of Things, and Blockchain for Enhanced Business Intelligence</title>
		<imprint>
			<date type="published" when="2024-06-06">2024. June 6, 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A survey of graph-based deep learning for anomaly detection in distributed systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Pazho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Noghre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Purkayastha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vempati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tabkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Integrating query data for enhanced traffic forecasting: A Spatio-Temporal Graph Attention Convolution Network approach with delay modeling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">301</biblScope>
			<biblScope unit="page">112315</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Proactive defense mechanism: Enhancing IoT security through diversity-based moving target defense and cyber deception</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Rehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Security</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page">103685</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ST-MambaSync: Complement the power of Mamba and Transformer fusion for less computational cost in spatialtemporal traffic forecasting</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page">102872</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Scalable and adaptive graph neural networks with self-label-enhanced training</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="page">111210</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gadbench: Revisiting and benchmarking supervised graph anomaly detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="29628" to="29653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Spatial-temporal attention wavenet: A deep learning framework for traffic prediction considering spatial-temporal dependencies</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Intelligent Transport Systems</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="549" to="561" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Counterfactual explanations and algorithmic recourses for machine learning: A review</title>
		<author>
			<persName><forename type="first">S</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Boonsanong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dickerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">2024a. Counterfactual explanations for deep learning-based traffic forecasting</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perez-Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raubal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.00456</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Klimenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Spatiotemporal Fusion Transformer for large-scale traffic forecasting. Information Fusion</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page">102293</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Connecting the dots: Multivariate time series forecasting with graph neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery &amp; data mining</title>
		<meeting>the 26th ACM SIGKDD international conference on knowledge discovery &amp; data mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="753" to="763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">2023. I know your intent: Graphenhanced intent-aware user device interaction prediction via contrastive learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Spatio-temporal dynamic graph relation learning for urban metro flow prediction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="9973" to="9984" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04875</idno>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">242</biblScope>
			<biblScope unit="page">122827</biblScope>
			<date type="published" when="2017">2017. 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Graph neural network-based bearing fault diagnosis using Granger causality test</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Spatio-temporal joint graph convolutional networks for traffic forecasting</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="372" to="385" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Gman: A graph multi-attention network for traffic prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1234" to="1241" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
