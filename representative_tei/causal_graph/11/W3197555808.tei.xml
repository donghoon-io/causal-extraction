<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bounds on the Feedback Capacity of the (d, ∞)-RLL Input-Constrained Binary Erasure Channel</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">V</forename><forename type="middle">Arvind</forename><surname>Rameshwar</surname></persName>
							<email>vrameshwar@iisc.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Communication Engineering</orgName>
								<orgName type="institution">Indian Institute of Science</orgName>
								<address>
									<settlement>Bengaluru</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Navin</forename><surname>Kashyap</surname></persName>
							<email>nkashyap@iisc.ac.in</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Communication Engineering</orgName>
								<orgName type="institution">Indian Institute of Science</orgName>
								<address>
									<settlement>Bengaluru</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bounds on the Feedback Capacity of the (d, ∞)-RLL Input-Constrained Binary Erasure Channel</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper considers the input-constrained binary erasure channel (BEC) with causal, noiseless feedback. The channel input sequence respects the (d, ∞)-runlength limited (RLL) constraint, i.e., any pair of successive 1s must be separated by at least d 0s. We derive upper and lower bounds on the feedback capacity of this channel, for all d ≥ 1, given by: max</p><p>, where the function</p><p>dδ+ 1 1-, with ∈ [0, 1] denoting the channel erasure probability, and h b (•) being the binary entropy function. We note that our bounds are tight for the case when d = 1 (see Sabag et al. (2016)), and, in addition, we demonstrate that for the case when d = 2, the feedback capacity is equal to the capacity with noncausal knowledge of erasures, for ∈ [0, 1 -1 2 log(3/2) ]. For d &gt; 1, our bounds differ from the non-causal capacities (which serve as upper bounds on the feedback capacity) derived in Peled et al. (2019) in only the domains of maximization. The approach in this paper follows Sabag et al. (2017), by deriving single-letter bounds on the feedback capacity, based on output distributions supported on a finite Q-graph, which is a directed graph with edges labelled by output symbols.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Memoryless channels were introduced by Shannon <ref type="bibr" target="#b0">[1]</ref> as models for communication links, and have, since then, been the object of much research activity in information theory. The capacity of a memoryless channel has an elegant, single-letter expression, C = sup P (x) I(X; Y ), and this expression is computable for a wide range of channels (see <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>). Furthermore, it was shown by Shannon <ref type="bibr" target="#b3">[4]</ref> that causal, noiseless feedback of the outputs does not increase the capacity of memoryless channels.</p><p>The case of discrete channels with memory (or discrete finitestate channels or FSCs) is quite different. For the purposes of this discussion, we restrict our attention to discrete memoryless channels with input constraints, which are specific instances of FSCs, and which find application in magnetic and optical recording systems <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. Figure <ref type="figure" target="#fig_0">1</ref> shows a generic discrete memoryless channel input constraints, with causal, noiseless feedback present. In this work, we shall focus on the binary erasure channel (or BEC) (shown in Figure <ref type="figure" target="#fig_2">3</ref>), the inputs of which are constrained to obey the (d, ∞)-runlength limited (RLL) input constraint <ref type="foot" target="#foot_0">1</ref> , which mandates that there needs to be at</p><p>The work of N. Kashyap was supported in part by MATRICS grant MTR/2017/000368 from the Science and Engineering Research Board (SERB), Govt. of India. The work of V. A. Rameshwar was supported by a Qualcomm Innovation Fellowship, India. The authors would like to thank O. Sabag for having shared the code for the numerical computation of the upper bounds. least d 0s between any pair of successive 1s. As was shown in the works <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, and <ref type="bibr" target="#b8">[9]</ref>, the capacities of the (1, ∞)-RLL inputconstrained binary erasure and binary symmetric channels are strictly larger than their respective non-feedback capacities, for at least some values of the channel parameters. Hence, Shannon's argument does not apply to DMCs with constrained inputs, and special tools are required to determine the feedback capacities of such channels.</p><p>In the context of the BEC with input constraints, the feedback capacities of the (1, ∞)and the (0, k)-RLL input constraints (for k ≥ 1) were computed in the works <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b9">[10]</ref>, respectively. Both of these works use the capacity of the BEC with noncausal knowledge of erasures as an upper bound on the feedback capacity, and put down an explicit coding scheme, whose rate is a lower bound on the feedback capacity, and demonstrate that the upper and lower bounds match. Interestingly, this gives rise to the fact that the non-causal capacities of the BEC with the (1, ∞)and the (0, k)-RLL input constraints are equal to the respective feedback capacities. Moreover, it was shown in <ref type="bibr" target="#b9">[10]</ref> that the feedback capacity of the (2, ∞)-RLL input-constrained BEC is less than the corresponding non-causal capacity, when the channel parameter, , is equal to 0.5. The proof involved deriving an upper bound on the feedback capacity, and proving that the upper bound is strictly less than the non-causal capacity at = 0.5. In this paper, we show that for the (2, ∞)-RLL inputconstrained BEC, the feedback capacity is in fact equal to the non-causal capacity for ∈ [0, 1 -</p><formula xml:id="formula_0">1 2 log(3/2)</formula><p>]. This result is a by-product of the main theorem in our paper, which presents an analytical lower bound on the feedback capacity of the (d, ∞)-RLL input-constrained BEC, for all d greater than or equal to 1. For the case when d = 1, our lower bound is tight for all values of <ref type="bibr" target="#b6">[7]</ref>, and for d = 2, our lower bound is numerically close to an upper bound derived using techniques in <ref type="bibr" target="#b10">[11]</ref>, for larger than 1 -1 2 log(3/2) , too. Our lower bounds are single-parameter optimization problems, and differ from the expression for the non-causal capacity (established for the (d, ∞)-RLL input-constrained BEC in <ref type="bibr" target="#b9">[10]</ref>) in only the domain of maximization.</p><p>Our techniques involve the use of the single-letter bounding techniques of Sabag et al. in <ref type="bibr" target="#b11">[12]</ref>, and we come up with a specific Q-graph (or a Q-context mapping) and a choice of a specific "BCJR-invariant" input distribution, which gives rise to an achievable rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. NOTATION AND PRELIMINARIES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Notation</head><p>In what follows, random variables will be denoted by capital letters, and their realizations by lower-case letters, e.g., X and x, respectively. Calligraphic letters, e.g., X, denote sets. We use the notation [n] to denote the set, {1, 2, . . . , n}, of integers, and the notation [a : b], for a &lt; b, to denote the set of integers {a, a + 1, . . . , b}. The notations X N and x N denote the random vector (X 1 , . . . , X N ) and the realization (x 1 , . . . , x N ), respectively. We define e n i to be the vector (e 0 , e 1 , . . . , e n ), of length n + 1, with e i = 1, and e j = 0, for j = i. Further, P (x), P (y) and P (y|x) are used to denote the probabilities P X (x), P Y (y) and P Y |X (y|x), respectively. As is usual, the notations H(X) and I(X; Y ) stand for the entropy of the random variable X, and the mutual information between the random variables X and Y , respectively, and h b (p) is the binary entropy function, for p ∈ [0, 1]. Finally, for a real number α ∈ [0, 1], we define ᾱ = 1 -α. All logarithms are taken to the base 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Problem Definition</head><p>The communication setting of an input-constrained memoryless channel with feedback is shown in Figure <ref type="figure" target="#fig_0">1</ref>. A message M is drawn uniformly from the set {1, 2, . . . , 2 nR }, and is made available to the encoder. The encoder, at time i, also has access to noiseless feedback in the form of the outputs, y i-1 , from the decoder, and produces a binary input symbol x i ∈ {0, 1}, as a function of the specific instance of the message, m, and the previous outputs, y i-1 . The encoder is constrained in that the sequence of input symbols x 1 x 2 x 3 . . . must satisfy the (d, ∞)-RLL input constraint, a deterministic presentation of which is shown in Figure <ref type="figure" target="#fig_1">2</ref>. We set the channel state alphabet, S, to be {0, 1, . . . , d}. Furthermore, the channel is memoryless in the sense that</p><formula xml:id="formula_1">P (y i |x i , y i-1 ) = P (y i |x i ), ∀i.</formula><p>Our focus is on the binary erasure channel, or the BEC, shown in Figure <ref type="figure" target="#fig_2">3</ref>. Here, the input alphabet, X = {0, 1}, while the output alphabet is Y = {0, ?, 1}, where ? denotes an erasure. Let ∈ [0, 1] be the erasure probability of the channel.</p><p>Definition II.1. An (n, 2 nR , (d, ∞)) feedback code for an inputconstrained channel is defined by a set of encoding functions:</p><formula xml:id="formula_2">f i : {1, . . . , 2 nR } × Y i-1 → X, i ∈ [n],</formula><p>which satisfy f i (m, y i-1 ) = 0, if f (i-j) + (m, y (i-j-1) + ) = 1 (where x + is equal to max{x, 0}), for some j ∈ [d], and for all (m, y i-1 ) , and a decoding function:</p><formula xml:id="formula_3">Ψ : Y n → {1, . . . , 2 nR }.</formula><p>The average probability of error for a code is defined as</p><formula xml:id="formula_4">P (n) e = P (M = Ψ(Y n )). A rate R is said to be (d, ∞)- achievable if there exists a sequence of (n, 2 nR , (d, ∞)) codes, such that lim n→∞ P (n) e = 0. The capacity, C fb (d,∞) ( )</formula><p>, is defined to be the supremum over all (d, ∞)-achievable rates, and is a function of the erasure probability, .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Q-graphs and (S, Q)-graphs</head><p>We now recall the definitions of the Q-graph and the (S, Q)graph introduced in <ref type="bibr" target="#b11">[12]</ref>.</p><p>Definition II.2. A Q-graph is a finite irreducible labelled directed graph on a vertex set Q, with the property that each q ∈ Q has at most |Y| outgoing edges, each labelled by a unique y ∈ Y.</p><p>Thus, there exists a function Φ : Q × Y → Q, such that Φ(q, y) = q iff there is an edge q y -→ q in the Q-graph. We arbitrarily label one vertex of the Q-graph as q 0 . For any positive integer n, there is a one-to-one correspondence between sequences in (y 1 , y 2 , . . . , y n ) ∈ Y n and directed paths in the Qgraph starting from q 0 : q</p><formula xml:id="formula_5">0 y1 -→ q 1 y2 -→ • • • yn -→ q n . Figure 4 depicts an example of a Q-graph.</formula><p>Definition II.3. Given an input-constrained DMC specified by {P (y|x)} and the states of the presentation of the input constraint of which obey s t = f (s t-1 , x t ), and a Q-graph with vertex set Q, the (S, Q)-graph is defined to be a directed graph on the vertex set S × Q, with edges (s, q) (x,y) ---→ (s , q ) if and only if P (y|x) &gt; 0, s = f (s, x), and q = Φ(q, y). Now, given an input distribution {P (x|s, q)} defined for each (s, q) in the (S, Q)-graph, we have a Markov chain on S × Q, where the transition probability associated with any edge (x, y) emanating from (s, q) ∈ S × Q is P (y|x)P (x|s, q). Let G({P (x|s, q)}) be the subgraph remaining after discarding edges of zero probability. We then define</p><formula xml:id="formula_6">Ω {P (x|s, q)} : G({P (x|s, q)}) has a single closed communicating class .</formula><p>Given an irreducible Q-graph, an input distribution {P (x|s, q)} ∈ Ω is said to be aperiodic, if the corresponding graph, G({P (x|s, q)}), is aperiodic. For such distributions, the Markov chain on S × Q has a unique stationary distribution π(s, q). An aperiodic input is said to be BCJR-invariant, if its state probability vector, (π(S = s|Q = q) : s ∈ S), satisfies</p><formula xml:id="formula_7">π(S = s + |Q = Φ(q, y)) = B s + ((π(s|q) : s ∈ S) , y),</formula><p>for all s, q ∈ S × Q, and y ∈ Y, where the function</p><formula xml:id="formula_8">B s : ∆(|S| -1) × Y → [0, 1] is shown in equation (1), with B s + ((γ q (s) : s ∈ S) , y) =</formula><p>x,s 1{s + = f (x, s)}γ q (s)P (x|s, q)P (y|x)</p><p>x ,s γ q (s )P (x |s , q)P (y|x )</p><p>.</p><p>(1)  |S| i=1 u i = 1}. Note that (γ q (s) : s ∈ S) is an arbitrary element of ∆(|S| -1) that is associated with node q of the Q-graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Bounds on Feedback Capacity</head><p>We shall make use of the following single-letter bounds on feedback capacity (specialized to input-constrained DMCs) of <ref type="bibr" target="#b11">[12]</ref>. The theorem below provides a lower bound on C fb DM C by considering input distributions that are BCJR-invariant.</p><p>Theorem II.1 ( <ref type="bibr" target="#b11">[12]</ref>, Theorem 3). The feedback capacity, C fb DM C , of input-constrained DMCs is lower bounded as</p><formula xml:id="formula_9">C fb DM C ≥ I(X; Y |Q),</formula><p>for all aperiodic input distributions, {P (x|s, q)} ∈ Ω, which are BCJR-invariant. The random variables X, Y, S, Q are associated with the time invariant system, with their joint distribution given by P (x, s, y, q) = π(s, q)P (x|s, q)P (y|x), where π(s, q) is the stationary distribution of the (S, Q)-graph.</p><p>The next theorem, which is a specialization of Theorem 2 of <ref type="bibr" target="#b11">[12]</ref>, provides a single-letter upper bound on C fb DMC , when the presentation of the input constraint is assumed to be irreducible: for all irreducible Q-graphs with q 0 such that (s 0 , q 0 ) lies in an aperiodic closed communicating class.</p><p>Remark. We implictly assume that the encoder and the decoder know the initial channel state, s 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. MAIN RESULTS</head><p>The following theorem states our main result concerning the capacity of the (d, ∞)-RLL input-constrained BEC with feedback. We shall make use of the function, R(δ), defined for δ ∈ [0, 1], which is given by</p><formula xml:id="formula_10">R(δ) = h b (δ) dδ + 1 1- .</formula><p>Theorem III.1. The feedback capacity of the (d, ∞)-RLL inputconstrained BEC, for &gt; 0, is lower bounded as follows:</p><formula xml:id="formula_11">C fb (d,∞) ( ) ≥ max δ∈[0, 1 d+1 ]</formula><p>R(δ).</p><p>Remark. At = 0, the capacities with and without feedback are identical, and are given by C(0) = max</p><formula xml:id="formula_12">δ∈[0,1] h b (δ)</formula><p>dδ+1 . Remark. The capacity of the (d, ∞)-RLL input-constrained BEC with non-causal knowledge of erasures, which serves as an upper bound on the feedback capacity, is given by [10, <ref type="bibr">Lemma 7]</ref>:</p><formula xml:id="formula_13">C nc (d,∞) ( ) = max δ∈[0, 1 2 ] R(δ).</formula><p>By standard calculus arguments, it holds that R(•) is concave, and, hence, has a unique maximum in [0, 1]. Indeed, since R (0 + ) &gt; 0 and R 1 2 &lt; 0, the unique maximum must lie in the interval [0, 1  2 ], where R (•) denotes the derivative of R(•). Note that the difference between the lower bound in Theorem III.1 and the non-causal capacity expression is only in the domain of maximization.</p><p>Theorem III.1 follows from the construction of a family of Qgraphs, indexed by d, and the identification of a BCJR-invariant input distribution. The construction of the Q-graphs and the input distribution is the subject of Section IV. Theorem III.1, whose proof is provided in Section VIII, then follows from Theorem II.1 by evaluating the conditional mutual information, I(X; Y |Q), using the BCJR-invariant distribution identified.</p><p>Theorem III.1 implies the following corollaries:</p><formula xml:id="formula_14">Corollary III.1. 1) For ≤ 1-1 2 log(<label>3</label></formula><p>2 ) , the feedback capacity of the (2, ∞)-RLL input-constrained BEC is equal to the non-causal capacity, and is given by:</p><formula xml:id="formula_15">C fb (2,∞) ( ) = C nc (2,∞) ( ) = max δ∈[0, 1 2 ]</formula><p>R(δ).</p><p>Further, for &gt; 1 -1 2 log( <ref type="formula" target="#formula_14">3</ref>2 ) , the feedback capacity is lower bounded as:</p><formula xml:id="formula_16">C fb (2,∞) ( ) ≥ R 1 3<label>.</label></formula><p>2) For d ≥ 3, and for &gt; 0, the feedback capacity of the (d, ∞)-RLL input-constrained BEC is lower bounded as:</p><formula xml:id="formula_17">C fb (d,∞) ( ) ≥ R 1 d + 1 .</formula><p>Moreover, the non-causal capacity is strictly larger than the lower bound, in this case. The proofs of the corollaries are relegated to Appendix B.</p><p>Figure <ref type="figure" target="#fig_4">5</ref> shows a plot of our lower bounds, for different values of d. We note that for d = 1, our lower bound is tight <ref type="bibr" target="#b6">[7]</ref>. However, for d ≥ 3, our lower bounds are not tight in the neighbourhood of = 0.</p><p>The following result provides an upper bound on the feedback capacity of the (d, ∞)-RLL input-constrained BEC, by considering a specific family of Q-graphs, each graph in which has d + 1 nodes, and invoking Theorem II.2.</p><p>Proposition III.1. The feedback capacity of the (d, ∞)-RLL input-constrained BEC is upper bounded as:</p><formula xml:id="formula_18">C fb (d,∞) ( ) ≤ max δ∈[0, 1 1+d ] R(δ).<label>(2)</label></formula><p>Further, for values of larger than , where satisfies</p><formula xml:id="formula_19">(d ) ( 1 1-+d) = (1 + d ) d ,</formula><p>the upper bound in (2) is less than the non-causal capacity.</p><p>The proof of Proposition III.1 is provided in Section IX. Figures <ref type="figure" target="#fig_9">6</ref> and<ref type="figure" target="#fig_10">7</ref> show, for d = 2 and d = 3, respectively, comparisons of the bounds in Theorem III.1 and Proposition III.1 with the non-causal capacity, and numerical evaluations of an upper bound obtained using Theorem II.2, by employing the same Q-graphs that were used for our lower bounds. The numerical upper bounds were computed by casting the upper bound in Theorem II.2 as a convex programming problem, as was discussed in <ref type="bibr" target="#b10">[11]</ref>. It is clear from the plots that the upper bound in Proposition III.1 is tighter than the non-causal capacity upper bound, for values of larger than -for example, for d = 2, ≈ 0.6960, and for d = 3, ≈ 0.5850. Futher, for d = 2, we note that the upper and lower bounds are equal for ∈ [0, 1 -  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONSTRUCTION OF Q-GRAPH AND INPUT DISTRIBUTION</head><p>We shall henceforth consider X = {0, 1}, Y = {0, ?, 1}, and S = {0, 1, . . . , d} to be the input, output and state alphabets, respectively, for the (d, ∞)-RLL input constrained BEC.</p><p>In this section, we shall construct a family of Q-graphs, indexed by the value of d, and identify a BCJR-invariant input distribution on the (S, Q)-graph corresponding to each Q-graph in the family.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Construction of Q-graphs</head><p>With each value of d corresponding to the (d, ∞)-RLL inputconstrained BEC, we associate a Q-graph, G d) , and a labelling function L (d) : E (d) → {0, ?, 1}.</p><formula xml:id="formula_20">(d) Q = (V (d) , E (d) , L (d) ), with vertex set V (d) , edge multi-set E (</formula><p>We write</p><formula xml:id="formula_21">V (d) = V (d) DB ∪ {Q 0 , Q 1 , . . . , Q d-1 }, where V (d) DB is constructed as follows. Each vertex in V (d)</formula><p>DB is uniquely identified by a d-tuple over {0, ?}, i.e., each vertex in V (d) DB can alternatively be written as q = (w q 0 , w q 1 , . . . , w q d-1 ), where w q i ∈ {0, ?}, for i ∈ {0, 1, . . . , d -1}. In what follows, we shall suppress the superscript q, as it will be clear from the context. Note that there are 2 d vertices in V We shall now construct the edge multi-set, E (d) . Firstly, for vertices in V Further, for any edge e = ((w 0 , w 1 . . . , w d-1 ), (w, w 0 , w 2 , . . . , w d-2 )), we define the labelling function</p><formula xml:id="formula_22">L (d) DB : E (d) DB → {0, ?} such that L (d)</formula><p>DB (e) = w. The edge set, E (d) , is constructed by adding to the set</p><formula xml:id="formula_23">E (d) DB , the edges (q, Q 0 ), for q ∈ V (d)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DB , and, corresponding to each</head><formula xml:id="formula_24">Q i , i ∈ [0 : d -1], two edges, e Qi 1 and e Qi 2 , from Q i to Q i+1 . Note that the Q-graph, G (d)</formula><p>Q , has parallel edges, which are precisely the edges from</p><formula xml:id="formula_25">Q i to Q i+1 , for i ∈ [0 : d -1].</formula><p>Finally, the labelling function, L (d) : E (d) → {0, ?, 1} is defined as:</p><formula xml:id="formula_26">L (d) (e) =            L (d) DB (e), if e ∈ E (d) DB , 1, if e = (q, Q 0 ) for q ∈ V (d) DB , 0, if e = e Qi 1 for some i ∈ [0 : d -1], ?, if e = e Qi 2 for some i ∈ [0 : d -1].<label>(3)</label></formula><p>Remark. The subscript "DB" refers to the fact that the subgraph G</p><formula xml:id="formula_27">(d) DB = (V (d) DB , E (d) DB , L (d) DB ), of G (d)</formula><p>Q , is a de Bruijn graph of order d, on {0, ?} symbols.</p><p>We note that G</p><formula xml:id="formula_28">(d) Q satsifies the properties of a Q-graph detailed out in Section II-C. The Q-graphs, G<label>(1)</label></formula><formula xml:id="formula_29">Q and G (2)</formula><p>Q are shown in Figures <ref type="figure">8a</ref> and<ref type="figure">8b</ref>, respectively.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark. The nodes</head><formula xml:id="formula_30">Q 0 , Q 1 , . . . , Q d of G (d)</formula><p>Q can be interpreted as follows. Let us define, for a fixed output sequence, y t , the length-(d+1) belief vector z t := (P (S t = s t |y t ) : s t ∈ S). Note that the vector, z t , which is an element of ∆(d), is precisely the state vector of the dynamic programming (DP) formulation of the feedback capacity problem <ref type="bibr" target="#b12">[13]</ref>. The node Q i corresponds to the DP state z t = e d i , for i ∈ [0 : d]. This, in turn, has the interpretation that the nodes Q 0 , . . . , Q d represent the belief vectors when the decoder knows the channel state exactly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Construction of a BCJR-invariant input distribution</head><formula xml:id="formula_31">Given the Q-graph, G (d) Q , for the (d, ∞)-RLL input constrained BEC, we shall call its corresponding (S, Q) graph, G (d)</formula><p>SQ , which is constructed following the description in definition II.3, with the presentation of channel states given in figure <ref type="figure" target="#fig_1">2</ref>.</p><p>In this subsection, we shall construct a BCJR-invariant input distribution, P (x|s, v) : x ∈ X : (s, v) ∈ S × V (d) . In tandem, we will also identify the conditional distribution, (π(s|v) : s ∈ S), for each v ∈ V (d) , where π(s|v</p><formula xml:id="formula_32">) = π(s,v) π(v) , with π(s, v) : s ∈ S, v ∈ V (d) denoting the stationary distribution on the nodes of G (d) SQ . Note that π(v) = s∈S π(s, v).</formula><p>Since our input distribution, P (•|s, v) : s ∈ S, v ∈ V (d) , must respect the (d, ∞) input constraint, we need that P (1|s, v) = 0, for s ∈ {0, 1, . . . , d-1}, and we hence need only specify P (1|d, v), for each v ∈ V (d) , to completely determine the input distribution.</p><p>To this end, we first associate with every node v ∈ V (d) , a probability vector, θ v := (θ v (s) : s ∈ S), of length d + 1. As we shall see, the vector θ v is a proxy for (π(s|v) : s ∈ S) for a suitably defined input distribution.</p><p>We set θ Qi = e d i , for i ∈ [0 : d]. Further, in compliance with the (d, ∞)-RLL input constraint, we set a Qi := P (1|d,</p><formula xml:id="formula_33">Q i ) = 0, for i = d. Let us pick a Q d := P (1|d, Q d ), such that a Q d ≤ 1</formula><p>d+1 . The reason for the restriction of a Q d to the interval [0, 1 d+1 ] will be made clear in Lemma V. We shall, for conciseness of notation, represent a Q d as a.</p><p>Now, for q = (w 0 , w 1 , . . . , w d-1 ) ∈ V (d) DB , we define an accompanying vector β = (β 0 , β 1 , . . . , β d-1 ), with β s := |{i ∈ [0 : s -1] : w i = 0}|. In words, β s is the number of 0s that appear strictly to the left of position s in the d-tuple corresponding to q. We then define θ q as follows:</p><formula xml:id="formula_34">For 0 ≤ s ≤ d -1, θ q (s) = 0, w s = 0, a (1-a) βs , w s = ?,<label>(4)</label></formula><p>and</p><formula xml:id="formula_35">θ q (d) = 1 - d-1</formula><p>s=0 θ q (s). It is clear from our definition that Lemma VII. It holds that θ(s, v) = π(s, v), for all s ∈ S and v ∈ V (d) .</p><p>Proof. Fix an s + ∈ S, and a v + ∈ V (d) . Now, s,v,x,y θ(s, v)P (x|s, v)P (y|x)1{s</p><formula xml:id="formula_36">+ = f (x, s)}1{v + = Φ(v, y)} = v,y π(v)1{v + = Φ(v, y)}</formula><p>x,s θ v (s)P (x|s, v)P (y|x)×</p><formula xml:id="formula_37">1{s + = f (x, s)} (a) = θ v + (s + ) v,y π(v)P (y|v)1{v + = Φ(v, y)} = θ v + (s + )π(v + ) = θ(s + , v + ),</formula><p>where (a) follows from Lemma VI, since θ v + (s + )P (y|q) =</p><p>x,s θ v (s)P (x|s, v)P (y|x)1{s + = f (x, s)}. Since this holds for all (s + , v + ) ∈ S × Y, it follows that θ(s + , v + ) = π(s + , v + ).</p><p>The lemma above implies that θ v = π(•|v), and using Lemma VI, we can conclude that P is BCJR-invariant.</p><p>Remark. It can be shown that for a fixed value of a, there is a unique BCJR-invariant input distribution on G (d) SQ . In particular, this means that for a fixed value of a, the probability P (Y = 1|q) = a , for all q ∈ V (d) DB .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. PROOF OF THEOREM III.1</head><p>Proof. We shall evaluate I(X; Y |Q), for the (d, ∞)-RLL inputconstrained BEC, using the BCJR-invariant input distribution P defined in subsection IV-B, and the Q-graph, G</p><p>Q . Now,</p><formula xml:id="formula_39">I(X; Y |Q) (a) = H(Y |Q) -h b ( ) (b) = ¯ v∈V (d) π(v)h b (P (X = 1|v)) + h b ( ) -h b ( ) (c) = ¯ q∈V (d) DB π(q)h b (P (X = 1|q))</formula><p>where (a) follows from the fact that Now, we note that for any q ∈ V (d) DB , P (X = 1|q) = π(d|q)a q , and since from Lemma VII we have that π(s|q) = θ q (s), for all s ∈ S, it follows that P (X = 1|q) = a. Hence, we get that</p><formula xml:id="formula_40">H(Y |X, Q) = H(Y |X) = h b ( ),</formula><formula xml:id="formula_41">I(X; Y |Q) = ¯ h b (a) q∈V (d) DB π(q).<label>(10)</label></formula><p>Further, from the fact that π is the stationary distribution on the nodes of G</p><formula xml:id="formula_42">(d) Q , 1 = q∈V (d) DB π(q) + d-1 i=0 π(Q i ) = q∈V (d) DB π(q) + dπ(Q 0 ) = (1 + da¯ ) q∈V (d) DB π(q),<label>(11)</label></formula><p>where the penultimate equality holds since π(Q</p><formula xml:id="formula_43">0 ) = π(Q i ), for all i ∈ [d -1]. The last equality follows from the observation that π(Q 0 ) = q∈V (d) DB π(q)P (Y = 1|q) = ¯ a q∈V (d)</formula><p>DB π(q). Hence, from equations ( <ref type="formula" target="#formula_42">11</ref>) and <ref type="bibr" target="#b9">(10)</ref>, we obtain that</p><formula xml:id="formula_44">I(X; Y |Q) = h b (a) da+ 1 1-</formula><p>, and taking a maximum over all a ∈ [0, </p><formula xml:id="formula_45">: i ∈ [0 : d -1]} ∪ {(s, Qd ) : s ∈ [0 : d]} of nodes.</formula><p>Further, since the inputs are constrained, it holds that P (X = 1|S = s, Q = q) = 0, for all (s, q) = (d, Qd ), with (s, q) in the closed class. Therefore, the matrix of conditional input distributions, [P (x|s, q)], can be parameterized by a single parameter, p := P (X = 1|S = d, Q = Qd ).</p><p>A simple computation then reveals that the stationary distribution of nodes in the closed communicating class obey:</p><formula xml:id="formula_46">π(s, Qs ) = p¯ 1 + dp , s ∈ [0 : d -1], π(s, Qd ) = p 1 + dp , s ∈ [0 : d -1], π(d, Qd ) = 1 1 + dp .</formula><p>Further, it holds that the conditional probability,   , is equal to 0. Further, from the proof of Corollaries III.1 in Appendix B, we observe that R (δ) is strictly decreasing in δ, for δ ∈ [0, 1]. Hence, it follows that for &gt; , the derivative, R</p><formula xml:id="formula_47">P (Y = 1| Qd ) = P (Y = 1, X = 1, S = d| Qd ) = p¯ π(d, Qd )</formula><formula xml:id="formula_48">1 1+d</formula><p>&gt; 0, with R (0 + ) &gt; 0.</p><p>Therefore, the non-causal capacity, which is a maximum over [0, 1] of R(δ), is strictly larger than the upper bound in Proposition III.1, for &gt; .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X. CONCLUSIONS AND FUTURE WORK</head><p>In this work, new lower bounds on the feedback capacities of the (d, ∞)-RLL input-constrained binary erasure channels were derived. The main idea was the construction of a family of Qgraphs and identifying a BCJR-invariant distribution for each graph in the family, and finally using the single-letter lower bounding methods in <ref type="bibr" target="#b11">[12]</ref> to obtain achievable rates. The rates derived were shown to be equal to the feedback capacities, for d = 1, and for a certain range of the channel parameter, , when d = 2. Further, numerical evaluations indicate that the lower bounds are close to the single-letter upper bounds (from <ref type="bibr" target="#b11">[12]</ref>) derived using the same family of Q-graphs, for d = 2, 3, 4, for all values of .</p><p>Extensions of this work could look at deriving analytical expressions for upper bounds for all values of d, using our Q-graph family, and comparing them with our lower bounds. Further, we intend analyzing the structure of the optimal input distribution, derived from the dynamic programming formulation of the feedback capacity problem, which will help identify the structure of the optimal Q-graph.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: System model of an input-constrained DMC with causal, noiseless feedback.</figDesc><graphic coords="1,314.32,198.60,255.74,84.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: A deterministic presentation of the (d, ∞)-RLL input constraint. The nodes of the presentation represent the channel states and the labels on the edges represent inputs.</figDesc><graphic coords="3,72.01,43.19,195.60,67.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: The binary erasure channel.</figDesc><graphic coords="3,123.26,167.00,93.10,63.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fig. 4: A Q-graph where each node represents the last channel output, where Y = {0, 1}. The labels on the edges represent outputs.</figDesc><graphic coords="3,71.25,647.58,197.14,62.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Plots of our lower bounds for d = 1, 2, 3, 4.</figDesc><graphic coords="4,119.52,43.19,372.96,157.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1 2 log( 3 / 2 )</head><label>132</label><figDesc>], and are numerically close in value, for &gt; 1 -</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>us denote by Q d , the vertex (0, 0, . . . , 0) ∈ V (d) DB .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>DB = {e : e = ((w 0 , w 1 . . . , w d-1 ), (w, w 0 , w 1 , . . . , w d-2 )) , for (w 0 , . . . , w d-1 ), (w, w 0 , . . . , w d-2 ) ∈ V (d) DB }.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Plot comparing bounds for the (2, ∞)-RLL input-constrained BEC.</figDesc><graphic coords="5,119.52,43.19,372.96,163.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: Plot comparing bounds for the (3, ∞)-RLL input-constrained BEC.</figDesc><graphic coords="5,119.52,238.82,372.96,163.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>and (b) follows from the fact that P (Y =?|v) = , for all v ∈ V (d) , with P (Y = 1|v) = ¯ P (X = 1|v). We additionally use the identity that H(ac, āc, c) = h b (c) + ch b (a), for all a, c ∈ [0, 1]. Finally, (c) holds since P (X = 1|Q i ) = 0, for i ∈ [0 : d -1].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Theorem II.2, it holds that C fb (d,∞) ≤ sup P (x|s,q)∈Ω I(X; Y |Q) = sup P (x|s,q)∈Ω H(Y |Q) -h b ( )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 9 :</head><label>9</label><figDesc>Fig. 9: The Q-graph, Ĝ(d) Q . The labels on the edges denote outputs.</figDesc><graphic coords="8,119.52,43.19,372.97,95.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>where, in (a), we have used the identity that H(ac, āc, c) = h b (c) + ch b (a), for all a, c ∈ [0, 1], and (b) follows by changing the variable used in the maximization to δ := p 1+dp . Now, we note that if satisfies the equation(d ) ( 1 1-+d) = (1 + d ) d ,then, the derivative evaluated at 1 1+d , R 1 1+d</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1 d+1 ], we get the required result. IX. PROOF OF PROPOSITION III.1 Proof. We shall compute the upper bound expression in theorem II.2 by considering the family of Q-graphs, J := {</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Ĝ(d) Q : d ∈ N},</cell></row><row><cell cols="2">where</cell><cell cols="2">Ĝ(d) Q is shown in figure 9 for some fixed d. Let</cell><cell>Ĝ(d) SQ denote</cell></row><row><cell cols="3">the (S, Q)-graph corresponding to</cell><cell>Ĝ(d) Q .</cell></row><row><cell></cell><cell cols="3">It can be shown that the single closed communicating class</cell></row><row><cell>in</cell><cell cols="2">Ĝ(d)</cell></row></table><note><p>SQ is precisely the collection {(i, Qi )</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The (d, ∞)-RLL constraint is a special case of the (d, k)-RLL constraint on binary sequences, which requires that the length of any run of consecutive 0s is at least d and at most k.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Q . The parallel edges defined are here represented as a single edge with the label (0, ?), according to <ref type="bibr" target="#b2">(3)</ref>.</p><p>where Q d = (0, 0, . . . , 0) ∈ V (d) DB . Finally, for q ∈ V (d) DB , we let a q := P (1|d, q) = a θq(d) , where a was defined earlier. Note that in order for a q to be a valid probability, it must lie in the interval [0, 1], a sufficient condition for which is provided by Lemma V below.</p><p>DB . The proof of this lemma is taken up in Appendix A.</p><p>Remark. Note that this procedure determines the vector a v : v ∈ V (d) , thereby specifying the entire input distribution P (•|s, v) : s ∈ S, v ∈ V (d) . Moreover, our input distribution is aperiodic if a &lt; 1 and = 1, as then there exists a self-loop of positive probability, ā¯ , from the node</p><p>SQ . From our choice of the interval, [0, 1 d+1 ], in which a lies, we see that a indeed satisfies the condition that a &lt; 1, and we assume, further, that = 1, as the feedback capacity at = 1 is well-known to be C fb (1) = 0.</p><p>Before we set out to prove that the aperiodic input distribution P is indeed BCJR-invariant, we note that for all s ∈ S and v ∈ V (d) , the value B s (θ v , y) (where the function B s : ∆(d) × Y → ∆(d) was defined in equation ( <ref type="formula">1</ref>)) can be computed explicitly for the (d, ∞)-RLL input constrained BEC with the input distribution P . For 0 ≤ s ≤ d -1, and for q ∈ V (d) DB , the following set of equations holds true:</p><p>with</p><p>for y ∈ {0, ?}. We now note that the following lemma holds:</p><p>for every (s</p><p>DB , and let v = Q i , for some i ∈ [0 : d -1]. Then, it follows from equation ( <ref type="formula">8</ref>) that</p><p>for y ∈ {0, ?}. Equation ( <ref type="formula">9</ref>) then follows by noting that</p><p>DB , when y = 1, we see from equation ( <ref type="formula">7</ref>) that</p><p>Since Φ(v, 1) = Q 0 , it follows that equation ( <ref type="formula">9</ref>) holds. Now, consider q = (w 0 , w 1 , . . . , w d-1 ) ∈ V</p><p>DB . Then, from our construction of V (d) DB , it holds that Φ(q, 0) = (0, w 0 , w 1 , . . . , w d-1 )) =: q + 0 , and Φ(q, ?) = (?, w 0 , w 1 , . . . , w d-1 ) =: q + ? . From equations (4), ( <ref type="formula">5</ref>) and from (6), we see that (B s (θ q , 0) : s ∈ S) = θ q + 0 and (B s (θ q , ?) : s ∈ S) = θ q + ? . Thus, equation <ref type="bibr" target="#b8">(9)</ref> holds in this case too. Now, let us define the joint distribution, θ(s, v) := θ v (s)π(v), where π(v) : v ∈ V (d) is the stationary distribution on the nodes of G (d) Q induced by P . The proof that the aperiodic input distribution, P , is BCJR-invariant, will follow from Lemma VI and the following lemma: APPENDIX A In this section, we shall prove Lemma V.</p><p>Proof. Consider a node q = (w 0 , . . . , w d-1 ) ∈ V (d) DB with accompanying vector β. From equation ( <ref type="formula">4</ref>) , we obtain that</p><p>Let us define by n 0 , the number of times a 0 occurs in the dtuple representation of q, i.e., n 0 := |{s : w s = 0}|. Likewise, we define n ? := |{s : w s = ?}|. Now, the following sequence of inequalities holds:</p><p>where the last equality holds since a ∈ [0, 1 d+1 ], and, hence,</p><p>where the last inequality follows from the fact that the function</p><p>Hence, for a ∈ [0, 1 d+1 ], we have that</p><p>and, therefore, a q = a θq(d) ∈ [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B</head><p>We shall now prove the Corollaries III.1.</p><p>Proof. We first note that the derivative, R (•), is given by</p><p>where we write 1 1-as k. We note that R (δ) is strictly decreasing in δ.</p><p>1) It is easy to see that when</p><p>, or, equivalently, iff ≤ 1 -1 2 log( <ref type="formula">3</ref>2 ) . As was noted in the remark following theorem III.1, R (0 + ) &gt; 0, and, hence, we have that for ≤ 1 -1 2 log( <ref type="formula">3</ref>2 ) , the unique maximum of R(•), over [0, 1], occurs in the interval [0, 1  3 ].</p><p>In other words, for</p><p>which, in turn, means that R (δ) &gt; 0, for δ ∈ [0, 1  3 ]. Hence, since R(δ) is strictly increasing for δ ∈ [0, 1  3 ], it follows that</p><p>2) As in the previous part, we note that R Moreover, since R ( 1 d+1 ) &gt; 0 as well, the non-causal capacity, which is the maximum of R(δ) over δ ∈ [0, 1], is strictly greater than R 1 d+1 .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Syst. Tech. J</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="379" to="423" />
			<date type="published" when="1948-07">July 1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Computation of channel capacity and rate-distortion functions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Blahut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="460" to="473" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An algorithm for computing the capacity of arbitrary discrete memoryless channels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="20" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The zero error capacity of a noisy channel</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="8" to="19" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An introduction to coding for constrained systems</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Siegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture notes</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Codes for digital recorders</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A S</forename><surname>Immink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2260" to="2299" />
			<date type="published" when="1998-10">Oct. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The feedback capacity of the binary erasure channel with a no-consecutive-ones input constraint</title>
		<author>
			<persName><forename type="first">O</forename><surname>Sabag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Permuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kashyap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="22" />
			<date type="published" when="2016-01">Jan. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Asymptotics of input-constrained erasure channel capacity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="148" to="162" />
			<date type="published" when="2018-01">Jan. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Feedback capacity and coding for the BIBO channel with a no-repeated-ones input constraint</title>
		<author>
			<persName><forename type="first">O</forename><surname>Sabag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Permuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kashyap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="4940" to="4961" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Feedback capacity and coding for the (0, k)-RLL input-constrained BEC</title>
		<author>
			<persName><forename type="first">O</forename><surname>Peled</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sabag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Permuter</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIT.2019.2903252</idno>
		<ptr target="https://doi.org/10.1109/TIT.2019.2903252" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="4097" to="4114" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Graph-based encoders and their performance for finite-state channels with feedback</title>
		<author>
			<persName><forename type="first">O</forename><surname>Sabag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huleihel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Permuter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2106" to="2117" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A single-letter upper bound on the feedback capacity of unifilar finite-state channels</title>
		<author>
			<persName><forename type="first">O</forename><surname>Sabag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Permuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1392" to="1409" />
			<date type="published" when="2017-03">March 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Capacity of the trapdoor channel with feedback</title>
		<author>
			<persName><forename type="first">H</forename><surname>Permuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cuff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weissman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3150" to="3165" />
			<date type="published" when="2008-07">July 2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
