<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">XInsight: eXplainable Data Analysis Through The Lens of Causality</title>
				<funder ref="#_BVh7CQQ">
					<orgName type="full">RGC RMGS</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-05-30">30 May 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Pingchuan</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hong</forename><surname>Kong</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Rui</forename><surname>Ding</surname></persName>
							<email>juding@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Microsoft</forename><surname>Research</surname></persName>
						</author>
						<author>
							<persName><forename type="first">China</forename><forename type="middle">Shuai</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shi</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName><forename type="first">China</forename><forename type="middle">Dongmei</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<settlement>Kowloon Hong Kong SAR</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">Shuai Wang</orgName>
								<orgName type="institution" key="instit2">Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Kowloon Hong Kong SAR</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country>China;</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">XInsight: eXplainable Data Analysis Through The Lens of Causality</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-05-30">30 May 2023</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3589301</idno>
					<idno type="arXiv">arXiv:2207.12718v4[cs.DB]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS Concepts:</term>
					<term>Information systems â†’ Data analytics</term>
					<term>Data management systems</term>
					<term>â€¢ Mathematics of computing â†’ Bayesian networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In light of the growing popularity of Exploratory Data Analysis (EDA), understanding the underlying causes of the knowledge acquired by EDA is crucial. However, it remains under-researched. This study promotes a transparent and explicable perspective on data analysis, called eXplainable Data Analysis (XDA). For this reason, we present XInsight, a general framework for XDA. XInsight provides data analysis with qualitative and quantitative explanations of causal and non-causal semantics. This way, it will significantly improve human understanding and confidence in the outcomes of data analysis, facilitating accurate data interpretation and decision making in the real world. XInsight is a three-module, end-to-end pipeline designed to extract causal graphs, translate causal primitives into XDA semantics, and quantify the quantitative contribution of each explanation to a data fact. XInsight uses a set of design concepts and optimizations to address the inherent difficulties associated with integrating causality into XDA. Experiments on synthetic and real-world datasets as well as a user study demonstrate the highly promising capabilities of XInsight.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Exploratory data analysis (EDA) is key to acquiring insight from data and facilitating analysis towards decision making <ref type="bibr" target="#b36">[38,</ref><ref type="bibr" target="#b27">28]</ref>. With the advent of the digital age, the information explosion phenomenon <ref type="bibr" target="#b7">[8]</ref> makes it difficult for users to justify and rely on knowledge and conclusions from EDA. To ease the cognitive process, data explanations are proposed to deliberate data facts (e.g., query outcomes) and enhance user comprehension <ref type="bibr" target="#b16">[17]</ref>. In this paper, we term such a process as eXplainable Data Analysis (XDA), which advances data analysis by providing users with effective explanations. By suggesting and justifying choices to alter outcomes, XDA helps users comprehend and trust phenomena emerging from data; as a result, it facilitates real-world decision making.</p><p>Explanations can be categorized as either causal or non-causal <ref type="bibr" target="#b21">[22]</ref>. Causal explanations seek causal factors to explain an outcome. Fig. <ref type="figure" target="#fig_2">1</ref> depicts a hypothetical lung cancer dataset. Here, a patient's location (indicating regional tobacco control policy) and amount of stress have an impact on whether they would smoke. Then, smoking influences lung cancer's severity. The degree of severity further affects whether they would undergo surgery and the five-year survival rate. Here, smoking explains why a patient has high lung cancer severity (see Fig. <ref type="figure" target="#fig_2">1(f)</ref>). In contrast, a non-causal explanation shows the results merely by statistical correlations. For example, surgery "explains" (more precisely, is relevant to) lung cancer severity (see Fig. <ref type="figure" target="#fig_2">1(g)</ref>). Despite being helpful, this is not a causal explanation <ref type="bibr" target="#b42">[45]</ref>.</p><p>Existing data explanation tools (e.g., Tableau's Explain Data <ref type="bibr" target="#b12">[13]</ref> in industry, Scorpion <ref type="bibr" target="#b51">[54]</ref> and DIFF <ref type="bibr" target="#b0">[1]</ref> in academia) often provide non-causal explanations <ref type="bibr" target="#b16">[17]</ref>. Although valuable for data analysis, they may mislead users who want causal explanations. A well-known confusion, as noted in <ref type="bibr" target="#b22">[23]</ref>, is that Tableau's Explain Data reports that Massachusetts' low teenage pregnancy rate may explain this state's high ACT Math score. Such explanations are questionable. In comparison, causal explanations play a central role in human cognition <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b37">39]</ref>. They enable users to make counterfactual thinking and actionable decisions. For instance, quitting smoking reduces lung cancer severity whereas cancelling surgery does not.</p><p>for which Fig. <ref type="figure" target="#fig_2">1</ref>(f) and (g) illustrate two explanations provided by XInsight. Each explanation is flagged as either a "causal" or "non-causal" explanation, and is composed of both qualitative and quantitative sub-explanations.</p><p>Example 1.2: An explanation (Fig. <ref type="figure" target="#fig_2">1(f)</ref>) deems "Smoking" to be a qualitative causal factor of lung cancer severity and highlights "Smoking=Yes" and its responsibility as a quantitative subexplanation.</p><p>XInsight includes three modules, XLearner, XTranslator, and XPlainer to gradually form explanations. XLearner first automatically discovers a causal graph G from data (Fig. <ref type="figure" target="#fig_2">1(c)</ref>). Then, given a Why Query (Fig. <ref type="figure" target="#fig_2">1(b</ref>)) with the target (i.e., the measure "Lung Cancer") and the context (i.e., the breakdown dimension "Location"), XTranslator enumerates each remaining variable on G and decides if it is causal or non-causal to the target under the context. Fig. <ref type="figure" target="#fig_2">1(d)</ref> shows causal variables (i.e., those that can potentially provide causal explanations) in green and non-causal variables (i.e., those that can potentially provide non-causal explanations) in purple. Last, XPlainer quantifies how well each variable answers Why Query by searching possible predicates on the variables that are the most responsible, as shown in Fig. <ref type="figure" target="#fig_2">1(e)</ref>. Despite the promising capability of XInsight, concretizing each module is challenging. We brief the challenges and our solutions in the following.</p><p>XLearner. Most real-world datasets are collected irrespective of causal sufficiency <ref type="bibr" target="#b40">[43]</ref>. In other words, not all causally relevant variables are available in the dataset. Furthermore, real-world datasets often contain deterministic relations in the form of Functional Dependency (FD), especially when they have materialized from relational databases. These FDs may violate the faithfulness assumption <ref type="bibr" target="#b11">[12]</ref>, which is crucial for many causal discovery algorithms. To address these challenges, we establish a theory to propose an FD-induced graph G FD . XLearner uses G FD to select a subset of variables for standard causal discovery where the selected variables do not trigger faithfulness violations induced by FDs. It adopts FCI <ref type="bibr" target="#b54">[57]</ref> to address causal insufficiency and synergistically combine the result of FCI with the causal relations entailed by G FD .</p><p>XTranslator. The translation from causal primitives (the structural relations in the causal graph) into XDA semantics (e.g., whether a variable provides causal explanations) is under-explored. Given a Why Query (with a target and a context), it is unclear how to determine if a variable ğ‘‹ can explain the target given the context, and, moreover, if ğ‘‹ provides causal or non-causal explanations. XTranslator characterizes various causal primitives (e.g., m-separation, ancestor/descendant relations) from a causal graph and provides a taxonomy to translate them into XDA semantics.</p><p>XPlainer. DB causality is primarily designed for data provenance, which usually provides tuples as explanations. Contrarily, we note that predicate-level explanations shall be more desirable for XDA scenarios. Moreover, computing the responsibility of explanations with DB causality is NP-complete in general <ref type="bibr" target="#b32">[33]</ref>. XPlainer adapts DB causality to XDA by using predicate-level explanations with the conciseness consideration and also significantly reduces the computing cost with theoretical guarantees. In summary, we make the following contributions:</p><p>â€¢ We propose XInsight, a unified and causality-based framework for XDA. XInsight features adequate (by distinguishing causal from non-causal) and comprehensive (with qualitative and quantitative) explanations. â€¢ XInsight consists of three modules, XLearner, XTranslator and XPlainer, each of which is meticulously designed to address technical challenges and deliver efficient analysis. XLearner learns the causal graph from causally insufficient data in the presence of FD-induced faithfulness violations, XTranslator translates causal primitives into XDA semantics, and XPlainer efficiently provides quantitative explanations via an adaptation of DB causality to meet the needs of XDA scenarios.</p><p>â€¢ Empirically, we conduct thorough experiments on public data, production data, and synthetic data via quantitative experiments and human evaluations. The results are very encouraging.</p><p>Open Source and Real-world Adoption. We release our code at <ref type="bibr">[36]</ref>. XPlainer has been integrated into Microsoft Power BI to explain increase/decrease in data <ref type="bibr" target="#b35">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Model and Query</head><p>Multi-Dimensional Data. Let ğ· {ğ‘‹ 1 , â€¢ â€¢ â€¢ , ğ‘‹ ğ‘› } represents multi-dimensional data comprising ğ‘› attributes. In XInsight, we assume that records of ğ· are drawn independently from an identical distribution without selection biases (i.e, i.i.d. assumption) such that each attribute is a (random) variable. Here, selection bias is a preferential selection of units in data analysis <ref type="bibr" target="#b4">[5]</ref>. A variable is either categorical or numerical. In accordance with previous works <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b10">11]</ref>, we denote a categorical variable as dimension and a numerical variable as measure. Multi-dimensional data is commonly represented as a spreadsheet in our context. For relational data, we anticipate taking a materialized provenance table <ref type="bibr" target="#b23">[24]</ref> as input. Aggregation and Discretization on Measure. Given a measure ğ‘€, users may perform aggregation operations (such as SUM and AVG in SQL) over a set of realizations of ğ‘€. In some cases, measures are processed in the form of a dimension (e.g., use measures for explanations), which necessitates discretization. It transforms numerical values into several discrete bins that form a categorical variable. Filter. In this paper, filter is the basic unit of data operations. Given a multi-dimensional data ğ· and a dimension ğ‘‹ , a filter ğ‘ ğ‘– = {ğ‘‹ = ğ‘¥ ğ‘– } (e.g., "Smoking=Yes") implies an equality assertion to ğ‘‹ such that the value of ğ‘‹ shall equal ğ‘¥ ğ‘– . Predicate. The disjunction of filters applied on the same dimension is a predicate. Given the dimension ğ‘‹ , the predicate</p><formula xml:id="formula_0">ğ‘ƒ (ğ‘¥ 1 , â€¢ â€¢ â€¢ , ğ‘¥ ğ‘˜ ) is a set containment assertion {ğ‘‹ = ğ‘¥ 1 âˆ¨ â€¢ â€¢ â€¢ âˆ¨ ğ‘‹ = ğ‘¥ ğ‘˜ } â‰¡ {ğ‘ 1 , â€¢ â€¢ â€¢ , ğ‘ ğ‘˜ }.</formula><p>On a discretized measure, a predicate is an assertion on ranges. A filter is a special case of a predicate. For clarity, we represent a general predicate with a capital ğ‘ƒ and a filter with a lower-case ğ‘. Subspace. A subspace is a conjunction of filters on disjointed dimensions. Given multi-dimensional data ğ·, a subspace corresponds to a subset of rows satisfying the conditions of all filters. If two subspaces only differ in one filter, they are regarded as siblings. The term Context refers to the variables of two sibling subspaces, where the background variables are the variables with the shared filters and the foreground variables are the variables with the different filters. In the following example, we provide a simple instantiation.</p><p>Example 2.1: Consider the preceding dataset in Fig. <ref type="figure" target="#fig_2">1(a)</ref>. ğ‘  = {Location = A âˆ§ Lung Cancer = Severe} represents the subspace denoting all patients in "Location=A" with severe lung cancer. All patients in "Location=A" with severe lung cancer and all patients in "Location=B" with severe lung cancer form a pair of sibling subspaces. Here, "Location" is the foreground variable and "Lung Cancer" is the background variable. Selection. We use the following notation to represent the selection procedure over multi-dimensional data ğ·. The subset of data after the selection operation is defined as ğ· ğ‘ ğ‘– , ğ· ğ‘ƒ , or ğ· ğ‘  , where ğ‘ ğ‘– is a filter, ğ‘ƒ is a predicate, and ğ‘  is a subspace. We define ğ· -ğ· â€² as the rows remaining in ğ· after removing those from ğ· â€² . Why Query and Explanation. As illustrated in Fig. <ref type="figure" target="#fig_2">1</ref>(b), the user would issue a Why Query to XInsight for explanation. We formally define Why Query as follows. Definition 2.1 (Why Query). Given a multi-dimensional data ğ·, a user launches aggregate query ğ‘ğ‘”ğ‘”() on a target measure ğ‘€ under two sibling subspaces ğ‘  1 , ğ‘  2 . Why Query is defined as Î” ğ‘  1 ,ğ‘  2 ,ğ‘€,ğ‘ğ‘”ğ‘” (ğ·) = ğ‘ğ‘”ğ‘” ğ‘€ (ğ· ğ‘  1 ) -ğ‘ğ‘”ğ‘” ğ‘€ (ğ· ğ‘  2 ). For brevity, we use Î”(ğ·) as the shorthand of Î” ğ‘  1 ,ğ‘  2 ,ğ‘€,ğ‘ğ‘”ğ‘” (ğ·). W.l.o.g., we assume Î” is always non-negative.</p><p>Example 2.2: As shown in Fig. <ref type="figure" target="#fig_2">1</ref>(b), we concretize the Why Query Î” with the AVG aggregate on the target "Lung Cancer" over two sibling subspaces ğ‘  1 = {Location = A}, ğ‘  2 = {Location = B}, denoting the difference in average lung cancer severity in "A" and "B".</p><p>Indeed, explaining the difference between two aggregate queries is one prevalent data analysis task. Identifying the cause in data difference constitutes the basis of many data explanation applications, such as outlier explanation and data debugging <ref type="bibr" target="#b16">[17]</ref>. In accordance with prior works <ref type="bibr" target="#b51">[54,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b16">17]</ref>, we concretize the problem of XDA by concentrating on the explanation of data difference. The following form is used to provide explanations in response to Why Query. Definition 2.2 (Explanation). Given a Why Query, an explanation is represented by the following triplet explanation âŸ¨type, predicate, responsibilityâŸ©</p><p>where type âˆˆ {causal, non-causal} denotes whether the explanation is causal or non-causal, the predicate is the content of the explanation, and responsibility, and a score ranging from 0 to 1 quantifies the extent to which the explanation explains the given Why Query.</p><p>Example 2.3: Fig. <ref type="figure" target="#fig_2">1</ref>(e) lists several explanations to the Why Query. Fig. <ref type="figure" target="#fig_2">1</ref>(f)-(g) visualize two of them. Fig. <ref type="figure" target="#fig_2">1</ref>(f), as a causal explanation, depicts that "Smoking=Yes" causes the lung cancer severity difference in Location A and B with a responsibility of 0.77.</p><p>Single-vs. Multi-Dimensional Explanation. For conciseness and clarity, we anticipate that each explanation reflects one aspect contributing to the outcome when explaining the Why Query. We recommend adopting a single-dimensional explanation in XInsight due to its unambiguous causal semantics, although it is feasible to extend an explanation as multi-dimensional using the Cartesian product. The joint causal semantics of several variables, however, could be obscure. Furthermore, multiple single-dimensional explanations (e.g., Fig. <ref type="figure" target="#fig_2">1</ref>(e)) suffice to represent a multi-dimensional case.</p><p>Functional Dependency (FD). Functional dependency relations are common in multi-dimensional data. In a relational database, among the attributes, there may exist primary keys and foreign keys. Therefore, after materialization, the resulting multi-dimensional data may have functional dependencies. A functional dependency between ğ‘‹ and ğ‘Œ is represented by ğ‘‹ FD --â†’ ğ‘Œ . FD, as a deterministic relation among two variables, deems a form of reliable knowledge. This research focuses on one-to-one and one-to-many FDs. We present a simple exemplary dataset that contains FDs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FD</head><p>--â†’ ğ‘‹ ğ‘— }. We assume G FD to be acyclic. Cycles in G FD imply redundant attributes; in such cases, we retain only one of them to ensure acyclicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Causal Discovery with Latent Variables</head><p>This section presents terminology essential to causal discovery with latent variables, such as the representation of causal graphs under causal insufficiency and typical assumptions in causal discovery. Causal Sufficiency. Causal discovery aims to learn the causal relations from the observational data. Most causal discovery algorithms assume a sufficient observation of the underlying data generating process <ref type="bibr" target="#b48">[51]</ref>. Formally, a set of variables ğ‘¿ is said to be causally sufficient if there is no hidden variable ğ‘ âˆ‰ ğ‘¿ that is causing more than one variable in ğ‘¿ . In other words, it assumes that latent confounders -the shared causes among two or multiple variables -do not exist. However, the process used to acquire real-world data does not provide such guarantees, thereby often yielding causally insufficient observations. Hence, the causal discovery procedure is compromised by the spurious association between two variables sharing a latent confounder. We present an example below. Example 2.5: Consider the hypothetical causal graph in Fig. <ref type="figure" target="#fig_1">2</ref>(a) where the socioeconomic status (ğ‘ ) simultaneously causes teenage pregnancy (ğ‘‹ ) and their ACT math scores (ğ‘Œ ). The socioeconomic status, however, does not appear in the dataset. This absence yields an insufficient observation (the left-side causal graph in Fig. <ref type="figure" target="#fig_1">2(b</ref>)), which further results in a spurious association [41] of teenage pregnancy and ACT math scores (the bidirected edge in Fig. <ref type="figure" target="#fig_1">2(b)</ref>). Hence, popular directed acyclic graphs are not expressive enough to represent these subtle relations. This necessitates the Maximum Ancestral Graph <ref type="bibr" target="#b48">[51]</ref>, which is introduced shortly.</p><p>Notation and Terminology. Recall that we assume the dataset is i.i.d. with potential latent confounders and does not contain selection bias. Maximal Ancestral Graph (MAG) forms the standard representation of causal graphs in this setting. We now introduce important concepts of graphical models and properties of MAG.</p><p>A directed mixed graph G is a graphical model that contains nodes ğ‘¿ and two types of edges, including directed (â†’) and bidirected (â†”). There is at most one edge between any two nodes. For each directed edge ğ‘‹ â†’ ğ‘Œ , ğ‘‹ is a parent of ğ‘Œ and ğ‘Œ is a child of ğ‘‹ . ğ‘‹ and ğ‘Œ are adjacent if there is an edge (either directed or bidirected) between them. A path P is a sequence of distinct nodes (ğ‘‹ 1 , . . . , ğ‘‹ ğ‘˜ ) where ğ‘‹ ğ‘– and ğ‘‹ ğ‘–+1 are adjacent in G for all 1 â‰¤ ğ‘– &lt; ğ‘˜. A path P = (ğ‘‹ 1 , . . . , ğ‘‹ ğ‘˜ ) is directed if ğ‘‹ ğ‘– is a parent of ğ‘‹ ğ‘–+1 for all 1 â‰¤ ğ‘– &lt; ğ‘˜. ğ‘‹ is an ancestor of ğ‘Œ if there exists a directed path from ğ‘‹ to ğ‘Œ and ğ‘Œ is a descendant of ğ‘‹ accordingly. Given a path (ğ‘‹ 1 , . . . , ğ‘‹ ğ‘˜ ), a non-endpoint node ğ‘‹ ğ‘– is a collider if there are arrowheads pointing to ğ‘‹ ğ‘– from both ğ‘‹ ğ‘– -1 and ğ‘‹ ğ‘–+1 . Below, we list all possible cases of a collider. A path (ğ‘‹,ğ‘Š 1 , â€¢ â€¢ â€¢ ,ğ‘Š ğ‘˜ , ğ‘Œ ) is said to be blocked by ğ‘ âŠ† ğ‘¿ \ {ğ‘‹, ğ‘Œ } if there exists a node ğ‘Š ğ‘– âˆˆ {ğ‘Š 1 , â€¢ â€¢ â€¢ ,ğ‘Š ğ‘˜ } such that a) ğ‘Š ğ‘– is not a collider but a member of ğ‘ , or b) ğ‘Š ğ‘– is a collider but not an ancestor of any nodes of ğ‘ . We now introduce m-separation and MAG. Definition 2.3 (m-separation <ref type="bibr" target="#b54">[57]</ref>). ğ‘‹, ğ‘Œ are m-separated by ğ‘ (denoted by ğ‘‹ â«« G ğ‘Œ | ğ‘ ) if all paths between ğ‘‹, ğ‘Œ are blocked by ğ‘ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 2.6:</head><formula xml:id="formula_2">Given (ğ‘‹ ğ‘– -1 , ğ‘‹ ğ‘– , ğ‘‹ ğ‘–+1 ), ğ‘‹ ğ‘– is a collider if and only if a) ğ‘‹ ğ‘– -1 â†’ ğ‘‹ ğ‘– â† ğ‘‹ ğ‘–+1 , or b) ğ‘‹ ğ‘– -1 â†” ğ‘‹ ğ‘– â† ğ‘‹ ğ‘–+1 , or c) ğ‘‹ ğ‘– -1 â†’ ğ‘‹ ğ‘– â†” ğ‘‹ ğ‘–+1 , or d) ğ‘‹ ğ‘– -1 â†” ğ‘‹ ğ‘– â†” ğ‘‹ ğ‘–+1 . In</formula><p>Example 2.7: Consider the causal graph in Fig. <ref type="figure" target="#fig_2">1(c</ref>) where "Smoking" blocks the only path between "Location" and "Lung Cancer". Hence, "Smoking" m-separates "Location" and "Lung Cancer" (denoted by Lung Cancerâ«« G Location | Smoking). Definition 2.4 (Maximal Ancestral Graph <ref type="bibr" target="#b54">[57]</ref>). A directed mixed graph is called a MAG if a) it contains no directed cycles or almost directed cycles and b) for each pair of non-adjacent nodes, there exists a set of nodes that m-separates them. A directed cycle refers to the case where ğ‘‹ â†’ ğ‘Œ â†’ â€¢ â€¢ â€¢ â†’ ğ‘‹ and an almost directed cycle refers to the case where</p><formula xml:id="formula_3">ğ‘‹ â†’ ğ‘Œ â†’ â€¢ â€¢ â€¢ â†’ ğ‘ â†” ğ‘‹ .</formula><p>Then, the Global Markov Property (GMP) is developed to provide a probabilistic interpretation of m-separation. Definition 2.5 (Global Markov Property <ref type="bibr" target="#b48">[51]</ref>).</p><formula xml:id="formula_4">ğ‘‹ â«« G ğ‘Œ | ğ‘ â‡’ ğ‘‹ â«« ğ‘Œ | ğ‘</formula><p>(2) As aforementioned, m-separation indicates that all paths between ğ‘‹ and ğ‘Œ are "blocked" by ğ‘ . Hence, it is intuitive that, if ğ‘‹ and ğ‘Œ are m-separated, their statistical correlation is also "blocked" by ğ‘ . The term conditional independence (i.e., ğ‘‹ â«« ğ‘Œ | ğ‘ ) depicts this absence of statistical correlation. Statistically, ğ‘‹ â«« ğ‘Œ | ğ‘ implies that ğ‘ƒ (ğ‘‹, ğ‘Œ | ğ‘ ) = ğ‘ƒ (ğ‘‹ | ğ‘ )ğ‘ƒ (ğ‘Œ | ğ‘ ), which can be empirically examined using statistical hypothesis tests (e.g., ğœ’ 2 tests).</p><p>Example 2.8: Consider the dataset in Fig. <ref type="figure" target="#fig_2">1(a)</ref>. According to GMP, the m-separation in Ex. 2.7 implies that, for the dataset in Fig. <ref type="figure" target="#fig_2">1</ref>(a), "Location" and "Lung Cancer" are conditionally independent given "Smoking, " in a statistical sense.</p><p>With GMP, we can deduce statistical conditional independence in data from m-separations. Note that only data is available when performing causal discovery. Hence, we need to invert GMP and establish a connection from data distribution to the graphical structure. Faithfulness assumption establishes such connection. Definition 2.6 (Faithfulness <ref type="bibr" target="#b48">[51]</ref>).</p><formula xml:id="formula_5">ğ‘‹ â«« ğ‘Œ | ğ‘ â‡’ ğ‘‹ â«« G ğ‘Œ | ğ‘<label>(3)</label></formula><p>According to faithfulness, if we observe that two variables are conditionally independent by a set of variables in data, then they are m-separated by the same set of variables on the causal graph. Faithfulness and GMP together establish the equivalence between conditional independence and m-separation and they form the key to causal discovery. In addition, we define skeleton as follows.</p><p>Definition 2.7 (Skeleton). The skeleton S of a MAG G is the undirected graph obtained by removing all arrowheads from G.</p><p>Constraint-based Causal Discovery. Constraint-based approaches are the standard solution to causal discovery. With the faithfulness assumption, these methods exploit the conditional independence derived from data and gradually establish a MAG G. G is consistent with all mseparations entailed by conditional independence. However, there may exist multiple MAGs that are equally consistent with the m-separations and not distinguishable, which is called Markov equivalence class, denoted by <ref type="bibr">[G]</ref>. It is worth noting that these feasible MAGs share the same skeleton while differing in direction on certain edges. These MAGs are therefore summarized into a compact representation called Partial Ancestral Graph (PAG) with some undetermined edge endpoints. Example 2.9: Location â€¢â†’ Smoking in Fig. <ref type="figure" target="#fig_2">1 (c</ref>) implies that "Location" is a cause of "Smoking" or they share a latent confounder.</p><p>We clarify that the FCI algorithm <ref type="bibr" target="#b48">[51]</ref>, as a typical constraint-based approach, consists of two phases. The skeleton of [G] is first learned by assuming faithfulness (i.e., the FCI-SL phase of the FCI algorithm). Then, the undirected edges are subsequently oriented according to a set of orientation rules (i.e., the FCI-Orient phase of the FCI algorithm). Finally, the PAG is returned; see full details of the FCI algorithm in Supplementary Material. However, soon we will show that the faithfulness assumption can be violated by FD relations. In this paper, we focus on establishing a theory and proposing a solution to tackle this unique challenge that arises in data analysis scenarios. That is, our XLearner calibrates the FCI algorithm to correctly handling FDs (see details in Sec. 3.1). XInsight delivers a unified framework for XDA with three modules. The workflow of XInsight is shown in Fig. <ref type="figure" target="#fig_3">3</ref>. First, given a multi-dimensional data ğ·, XLearner pre-learns a causal graph G from data in the offline phase (blue-annotated in Fig. <ref type="figure" target="#fig_3">3</ref>). Then, in the online phase (red-annotated in Fig. <ref type="figure" target="#fig_3">3</ref>), upon receiving a Why Query, XTranslator identifies variables that have the potential to give either causal or non-causal explanations based on the causal primitives in G. Finally, XPlainer examines each identified variable with potential and decides the optimal explanation for the given Why Query. After applying XPlainer to all variables with potential, XInsight yields a set of explanations (with qualitative sub-explanations and quantitative sub-explanations). By decoupling XInsight into an offline phase and an online phase, heavy-weight computations are performed beforehand, and only light-weight computations are needed in the online phase, allowing for a rapid response to a user's query. In the following, we elaborate on the design of each module. Due to page limits, we present proofs and theoretical discussion in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">XINSIGHT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">XLearner</head><p>XLearner aims to learn a causal graph G from multi-dimensional data ğ· in the presence of latent confounders. The primary obstacle is that learning the skeleton of G requires the faithfulness assumption (see Sec. 2.2), which may be violated by FDs in ğ·. Below, we show how contradictory causal structures can be induced when being agnostic to FDs.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alg.</head><p>Orientation FD-induced Faithfulness Violation Causal Insufficiency PC</p><formula xml:id="formula_6">[51] âœ“ âœ— âœ— FCI [57] âœ“ âœ— âœ“ REAL [12] âœ— âœ“ âœ— XLearner âœ“ âœ“ âœ“</formula><p>As aforementioned in Sec. 2, the violations of causal sufficiency and faithfulness (induced by FDs) are common in the data analysis scenarios. However, they are addressed separately in the literature, as reviewed in Table <ref type="table" target="#tab_1">2</ref>. XLearner focuses on addressing both challenges simultaneously. Fig. <ref type="figure">4(c)-(d)</ref> show the skeleton and orientation by XLearner, which are compliant with intuition. Overall, XLearner tackles the problem in three stages. We outline the workflow of XLearner in Alg. 1 and present an example. Then, we elaborate on the design of XLearner.</p><p>Algorithm 1: XLearner procedure. </p><formula xml:id="formula_7">Input: Multi-dimensional Data ğ·, FD-induced graph G FD Output: FD-augmented PAG ğº 1 //</formula><formula xml:id="formula_8">14 foreach (ğ‘‹ FD --â†’ ğ‘Œ ) âˆˆ G FD .ğ¸ do 15 if ğ‘‹, ğ‘Œ is adjacent in S then orient ğ‘‹ â†’ ğ‘Œ on G 2 ; 16 end 17 generate G concatenating G 1 and G 2 ; 18 return G;</formula><p>Example 3.2: Consider the FD-induced graph G FD shown in Fig. <ref type="figure" target="#fig_5">5</ref>. In the first stage, XLearner uses G FD to identify variables (e.g., ğ‘‹ 1 and ğ‘ in Fig. <ref type="figure" target="#fig_5">5</ref>) that may trigger faithfulness violations. Then, the skeleton S 2 is built upon a harmonious assumption instead of faithfulness over ğ‘‹ 1 and ğ‘ . In the second stage, the FCI algorithm (skeleton learning and orientation) is only conducted over variables that comply with the faithfulness assumption. Hence, the skeleton S 1 and the PAG G 1 are identified accordingly. In the third stage, we orient S 2 to generate an FD-augmented PAG G 2 . By concatenating G 1 and G 2 , the resultant (FD-augmented) PAG G is obtained.</p><p>Comparison with FCI. Comparing with the FCI algorithm <ref type="bibr" target="#b48">[51,</ref><ref type="bibr" target="#b54">57]</ref>, XLearner for the first time reconciles functional dependency (FD) and the faithfulness assumption for causally insufficient data within the harmonious skeleton framework. In that sense, it can learn causal graphs from real-world data adequately. As validated in Sec. 4.3, XLearner learns more accurate causal graphs than the FCI algorithm. Second, it uses FDs to provide a more complete orientation to the underlying causal graph. Hence, compared to the FCI algorithm, it leverages the knowledge from FDs to enforce a more precise causal graph with less undetermined edges. In sum, we deem that XLearner enhances the FCI algorithm from the theoretical perspective, and also addresses obstacles in the real-life adoption of the FCI algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Skeleton</head><p>Learning with FD (lines 1-9 of Alg. 1). Ding et al. point out that in the presence of FD relations, faithfulness assumption can be violated thus we can at most obtain a harmonious skeleton <ref type="bibr" target="#b11">[12]</ref>. However, the original theory of harmonious skeletons is established under causal sufficiency. Here, we further generalize the harmonious skeleton for causally insufficient systems: Definition 3.1 (Harmonious Skeleton). A skeleton S is said to be harmonious w.r.t. a joint probability distribution ğ‘ƒ if 1) there exists a MAG G sharing the same adjacencies of S, 2) ğ‘ƒ satisfies GMP to G, and 3) any subgraph of S does not satisfy the previous two conditions. Def. 3.1 entails three properties of S. First, since there exists a MAG G on top of the skeleton S, there exists a set of nodes that m-separates any non-adjacent nodes. Second, if two nodes (e.g., ğ‘‹, ğ‘Œ ) are m-separated by ğ‘ , then ğ‘‹ â«« ğ‘Œ | ğ‘ . These two conditions imply that ğ‘‹ and ğ‘Œ are non-adjacent in S, if and only if there exists a set of nodes ğ‘ such that ğ‘‹ â«« ğ‘Œ | ğ‘ . The last condition implies the minimality of S, which is commonly assumed <ref type="bibr" target="#b40">[43]</ref>. When two graphs G, G â€² are equally compatible with the data, we would prefer the simpler one. We now show the construction of S, which begins with a basic case and generalizes to arbitrary structures. Theorem 3.1. Let ğ‘ be a sink node (i.e., all edges of ğ‘ are oriented to ğ‘ ) in G FD . S = S 1 âˆª S 2 is a harmonious skeleton if 1) ğ‘† 1 is a harmonious skeleton over ğ‘¿ \ ğ‘ and S 2 contains only one edge ğ‘‹ ğ‘– -ğ‘ where ğ‘‹ ğ‘– can be any node connected to ğ‘ in G FD .</p><p>Example 3.3: Fig. <ref type="figure" target="#fig_5">5</ref> presents an example of Thm. 3.1. Connecting the sink node ğ‘ with one of its parents ğ‘‹ 1 in the G FD yields a skeleton S 2 . If we can learn a harmonious skeleton S 1 on the remaining nodes (ğ‘‹ 1 , â€¢ â€¢ â€¢ , ğ‘‹ ğ‘› ), Thm. 3.1 ensures that concatenating S 1 , S 2 produces a harmonious skeleton over all variables.</p><p>According to Thm. 3.1, if ğ‘ has more than one parent, multiple harmonious skeletons exist (note that ğ‘ can connect to any one of its parents). In practice, we connect ğ‘ to the parent node with the lowest cardinality. Given a FD-induced graph, we recursively apply Thm. 3.1 to identify sink nodes and derive the corresponding harmonious skeleton S 2 until all FDs are properly resolved. Then, we can apply the standard skeleton learning algorithm over the remaining nodes. The procedure is shown in lines 1-9 in Alg. 1. Theorem 3.2. The skeleton of Alg. 1 is harmonious.</p><p>Alg. 1 first constructs an empty skeleton S that shares the same nodes as G FD (line 2). At line 3, we topologically sort the G FD nodes (note that G FD is a DAG). In each iteration (lines 5-8), we pick the deepest node and apply Thm. 3.1 to connect ğ‘‹ to one of its parents (in G FD ) ğ‘Œ in the skeleton. We use the parent node with the lowest cardinality as ğ‘Œ (line 6), as it usually aligns with human intuition.</p><p>Example 3.4: Consider the CityInfo dataset in Ex. 2.4. Alg. 1 identifies the correct skeleton as City -State -Country in Fig. <ref type="figure">4(c)</ref>.</p><p>For root nodes, since there are no FDs and thus the faithfulness assumption holds, we employ the standard FCI algorithm (lines 10-12) to infer the PAG G 1 . After S 2 being oriented to G 2 (see Sec. 3.1.2), we concatenate them to form G (line 17). Thm. 3.2 proves that the skeleton of G is also harmonious after the concatenation.</p><p>3.1.2 Orientation (lines 13-16 of Alg. 1). Classical constraint-based causal discovery algorithms decide the direction of edges based on a set of orientation rules. These rules orient undirected edges on skeletons (i.e., â€¢-â€¢) based on a set of criteria, including conditional independence and some graphical structural relations (e.g., discriminating path) <ref type="bibr" target="#b54">[57]</ref>. These rules are applied iteratively until no more orientations can be made. However, we argue that an FD itself reflects a causal relation to a good extent, of which the reason is twofold. ANM Perspective on FD-related Edges. We anticipate incorporating the discrete additive noise model (ANM) <ref type="bibr" target="#b39">[42]</ref> for orienting FD-related edges. The main theory of ANM implies that if an asymmetric ANM ğ‘Œ = ğ‘“ (ğ‘‹ ) + ğ‘ ğ‘Œ exists from ğ‘‹ to ğ‘Œ and ğ‘ ğ‘Œ is independent of ğ‘‹ , then ğ‘‹ causes ğ‘Œ .</p><p>By FD, we note that, if ğ‘‹ FD --â†’ ğ‘Œ in G FD , an ANM construction from X to Y naturally exist with noise term ğ‘ ğ‘Œ = 0. On the other hand, an ANM construction from ğ‘Œ to ğ‘‹ exists only in very rare cases, as determined by the identifiability of the discrete ANM (see Thm. 4.6 in <ref type="bibr" target="#b40">[43]</ref>). In light of this, we hypothesize that ğ‘‹ FD --â†’ ğ‘Œ in G FD implies causation of ğ‘‹ â†’ ğ‘Œ . FCI Perspective on FD-related Edges. The rules in FCI may be unreliable due to the faithfulness violations by FDs. However, an FD itself is generally more reliable, which describes deterministic relations. More importantly, the directions from the FDs are compatible with the result of the FCI on the variables excluding FD-related variables. That is, incorporating ANM would not violate GMP.</p><p>We implement the above hypothesis in our orientation algorithm (lines 13-16 in Alg. 1). We examine, for each FD relation that is also adjacent in S 2 , whether the edge is oriented as â†’ (lines <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>. We note that, by incorporating ANM, the augmented graph is more informative and represents an overcomplete graph w.r.t. the ground-truth MAG's Markov equivalence class, exhibiting greater precision than causal graphs learned only by rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">XTranslator</head><p>A causal graph does not directly reveal if a variable adequately explains a Why Query, nor does it directly reflect if the variable features a causal or non-causal explanation. Bridging this gap requires a translation from causal primitives to XDA semantics. To illustrate, we start with a Why Query under AVG. We then show how to generalize the main result into SUM and other aggregates.</p><p>Principle of Explainability. Given a Why Query Î” where ğ‘ğ‘”ğ‘” = AVG, a variable ğ‘‹ is said to have No Explainability if ğ‘‹ â«« ğ‘€ | ğ¹ âˆª ğ‘©, where ğ‘€ is the target measure, ğ¹ is the foreground variable, and ğ‘© are background variable(s). In the subsequent discussion, we omit ğ‘© for the ease of presentation without loss of generality.</p><p>A Why Query in XDA requires us to observe the difference between aggregates on ğ‘€ within two subspaces. The conditional independence of</p><formula xml:id="formula_9">ğ‘‹ â«« ğ‘€ | ğ¹ implies that E(ğ‘€ | ğ¹, ğ‘‹ ) = E(ğ‘€ | ğ¹ ).</formula><p>Hence, Î”(ğ·) = Î”(ğ· ğ‘‹ =ğ‘¥ ) in the large sample limit for all feasible filters in ğ‘‹ . If ğ‘‹ is conditionally independent of ğ‘€ given ğ¹ , ğ‘‹ is simply impossible to offer explanations to the Why Query. Thus, this principle imposes a restriction on possible variables that have the potential to provide explanations. In particular, we derive the following restriction. Proposition 3.1. If ğ‘‹ has explainability, ğ‘€, ğ‘‹ are not m-separated by ğ¹ in the causal graph ğº. Proposition 3.1 illustrates the chance of pruning variables for which it is impossible to provide explanations. Table <ref type="table" target="#tab_3">3</ref> further depicts the translation from causal primitives to XDA semantics. In XTranslator, a variable ğ‘‹ is first confirmed to have explainability if ğ‘‹, ğ‘€ are not m-separated by ğ¹ in ğº (1st row in Table <ref type="table" target="#tab_3">3</ref>). In addition, XTranslator also categorizes whether ğ‘‹ is causal or non-causal according to Table <ref type="table" target="#tab_3">3</ref>. Overall, ğ‘‹ provides a causal explanation if it is explainable and a cause (â€ and â in Table <ref type="table" target="#tab_3">3</ref>) or a possible cause (â‚ and âƒ rows in Table <ref type="table" target="#tab_3">3</ref>) of ğ‘€. We show how the causal graph identified by XLearner is translated.</p><p>Example 3.5: Given the dataset in Fig. <ref type="figure" target="#fig_2">1(a)</ref>, XLearner identifies the corresponding causal graph in Fig. <ref type="figure" target="#fig_2">1(c</ref>). With the Why Query in Fig. <ref type="figure" target="#fig_2">1(b)</ref>, XTranslator translates the causal graph into the XDA semantics in Fig. <ref type="figure" target="#fig_2">1(d)</ref>. "Smoking" and "Stress Level" can be used to causally explain "Lung Cancer". And, other variables (e.g., "Surgery") are deemed non-causal explanations (last row in Table <ref type="table" target="#tab_3">3</ref>). ). This may be valid for explanations; nevertheless, it is typically inconsistent with the common intuition of data analysis and may not align user expectations regarding explanations (i.e., a variable explains the target). Such COUNT-based explanation is unconventional and is thus less of a concern.</p><p>Semantics Consistency. Following the above discussion, we clarify that a variable may play different roles in various aggregates. However, in our current design, XTranslator focuses primarily on variables with strong connections to ğ‘€, which are more likely to provide desirable explanations. Therefore, the semantics of a variable are consistent across different aggregates. As clarified in Principle of Explainability above, it is appropriate for pruning uninformative variables from general aggregates, and we do not observe notable issues in practice. We leave designing more comprehensive translation rules for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">XPlainer</head><p>XLearner and XTranslator together provide a coarse-grained, variable-level qualitative explanation to a Why Query. For instance, "Smoking" is a causal explanation for the differences in severity of "Lung Cancer" in Locations A and B. To go one step further, XPlainer provides predicate-level quantitative explanations to answer Why Query (e.g., "Smoking=Yes" explains the difference with the responsibility of 0.77 in Fig. <ref type="figure" target="#fig_2">1</ref>(f)). XPlainer is on the basis of a well-establish framework, DB causality <ref type="bibr" target="#b31">[32]</ref> (an extension of actual causality). To ease reading, below we first provide a recap of the notations defined in Sec. 2.1. We then rewrite the formulation of DB causality in the context of XInsight in Sec. 3.3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recap of Notations.</head><p>We refer to a dataset as ğ·, a filter as a lowercase ğ‘, and a set of filters as an uppercase ğ‘ƒ. The subset of ğ· satisfying ğ‘ (or ğ‘ƒ) is represented by ğ· ğ‘ (or ğ· ğ‘ƒ , respectively). We use ğ· -ğ· ğ‘ƒ as the complement of ğ· ğ‘ƒ in ğ·. By default, Î”(ğ·) represents the Why Query over the dataset ğ·. Likewise, for arbitrary ğ· â€² âŠ† ğ·, Î”(ğ· â€² ) represents the difference between the aggregated values of two sibling subspaces inside ğ· â€² . Definition 3.2 (DB Causality <ref type="bibr" target="#b31">[32]</ref>). Given a multi-dimensional data ğ· and Why Query Î”, let ğ‘¡ be a tuple in ğ·. ğ‘¡ is called a counterfactual cause to Î”, if Î”(ğ·) &gt; ğœ– and Î”(ğ· -{ğ‘¡ }) â‰¤ ğœ–, where ğœ– is a user-defined threshold. ğ‘¡ is called an actual cause to Î”, if there exists a contingency Î“ âŠ† ğ· such that ğ‘¡ is a counterfactual cause for ğ· -Î“ (i.e., Î”(ğ· -Î“ -{ğ‘¡ }) â‰¤ ğœ– &lt; Î”(ğ· -Î“)). <ref type="bibr" target="#b31">[32]</ref>). Suppose ğ‘ƒ is an actual cause to Why Query Î” and Î“ ranges over all valid contingencies for ğ‘ƒ. The responsibility of ğ‘ƒ is defined as ğœŒ ğ‘ƒ = 1 1+min Î“ |Î“ | , where |Î“| denotes the number of tuples in the contingency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 3.3 (DB Responsibility</head><p>DB causality is appealing as it offers both a normalized measure (responsibility âˆˆ (0, 1]) and a contingency. First, when the responsibility is close to 1, it implies that the tuple is more accountable for the outcome, and when it hits 1, it is totally responsible. Second, the minimal contingency reflects the additional influential factors that, together with the tuple, are fully responsible for the outcome. The two elements form a quantitative explanation and it is useful for users to understand why the difference exists.</p><p>3.3.1 Adaption. DB causality was originally designed for data provenance. As pointed out in <ref type="bibr" target="#b30">[31]</ref>, tuple-level explanations are usually too fine-grained for data analysis scenarios. An individual tuple usually has too little effect on the highly aggregated outcome of a large dataset. Recalling the example in Fig. <ref type="figure" target="#fig_2">1</ref>, users would expect to know that "Smoking=Yes" causes high "Lung Cancer" severity rather than an individual patient being the cause of the high "Lung Cancer" severity. This necessitates predicate-level explanations which are easier to understand and frequently used in data analysis scenarios, and by many data explanation tools <ref type="bibr" target="#b51">[54,</ref><ref type="bibr" target="#b0">1]</ref>. Motivated by this, we make three adaptions over DB causality (namely, W-Causality, W-Responsibility and conciseness) to support XDA. We formulate W-Causality as follows. Definition 3.4 (W-Causality). Given a multi-dimensional data ğ·, an attribute of interest ğ‘‹ and Why Query Î”, let ğ‘ƒ âŠ† ğ‘ ğ‘– be a predicate in ğ·, where ğ‘ ğ‘– denotes the set of all possible filters on ğ‘‹ .</p><p>ğ‘ƒ is called a counterfactual cause of Î”, if Î”(ğ·) &gt; ğœ– and Î”(ğ· -ğ· ğ‘ƒ ) â‰¤ ğœ–, where ğœ– is a user-defined threshold. ğ‘ƒ is deemed to be an actual cause of Î”, if there is a contingency Î“ âŠ† ğ‘ ğ‘– such that ğ‘ƒ is a counterfactual cause for ğ· -ğ· Î“ (i.e., Î”(ğ·</p><formula xml:id="formula_10">-ğ· Î“ -ğ· ğ‘ƒ ) â‰¤ ğœ– &lt; Î”(ğ· -ğ· Î“ )), where ğ‘ƒ âˆ© Î“ = âˆ….</formula><p>From Tuples to Predicates. Def. 3.4 transforms the tuple and contingency into two predicates. This way, explanations as well as contingencies constitute a form of intervention over the multidimensional data. When a contingency Î“ is applied, it indicates that, if the events related to Î“ do not happen, then the events related to ğ‘ƒ are fully responsible for Î”. This adaption in turn entails another adaption to the responsibility for predicate-level explanations. Definition 3.5 (W-Responsibility). Suppose ğ‘ƒ is an actual cause to Why Query Î” and Î“ range over all valid contingencies for ğ‘ƒ. The responsibility of ğ‘ƒ is defined as</p><formula xml:id="formula_11">ğœŒ ğ‘ƒ = 1 1+min Î“ |Î“ | ğ‘Š , where |Î“| ğ‘Š is defined as max( Î”(ğ· -ğ· ğ‘ƒ ) -Î”(ğ· -ğ· ğ‘ƒ -ğ· Î“ ) Î”(ğ· )</formula><p>, 0). We let ğœŒ ğ‘ƒ = 0 if ğ‘ƒ is not an actual cause.</p><p>W-Responsibility. Instead of using the number of rows in ğ· Î“ as |Î“| ğ‘Š , Def. 3.5 employs the truncated difference in Î“ over Î” to measure the importance of ğ‘ƒ. In particular, Î”(ğ· -ğ· ğ‘ƒ ) -Î”(ğ· -ğ· ğ‘ƒ -ğ· Î“ ) can be deemed as first-order finite backward difference to the function Î”(â€¢) at the point of ğ· -ğ· ğ‘ƒ and Î“ is the step size. This supplies a simple and intuitive way to understand to what extent Î“ plays an important role in reducing the difference. The large difference imposed by Î“ implies a low importance of explanation ğ‘ƒ to Î”; because the reduction in Î” is primarily caused by Î“ instead of ğ‘ƒ itself. Therefore, the responsibility of ğ‘ƒ is measured by a valid contingency Î“ * (such that Î”(ğ· -ğ· ğ‘ƒ -ğ· Î“ ) â‰¤ ğœ– and Î”(ğ· -ğ· Î“ ) &gt; ğœ–) with minimal difference on Î”. Conciseness. Using responsibility as the sole criterion is not sufficient in practical data analysis scenarios <ref type="bibr" target="#b16">[17]</ref>. Typically, a concise explanation is preferable. Therefore, given an attribute of interest ğ‘‹ , we formulate the optimal explanation of ğ‘‹ as follows.</p><p>argmax</p><formula xml:id="formula_12">ğ‘ƒ âŠ† ğ‘ ğ‘– ğœŒ ğ‘ƒ -ğœ |ğ‘ƒ |<label>(4)</label></formula><p>where ğ‘ ğ‘– is the set of all possible filters in ğ‘‹ , |ğ‘ƒ | is the number of filters in ğ‘ƒ, and ğœ |ğ‘ƒ | (ğœ &gt; 0) forms a conciseness regularization. In practice, we would prefer ğœ = 1 /ğ‘š such that when all filters are picked, the score is zero. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Optimization.</head><p>As pointed out in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>, computing responsibility (i.e., ğœŒ ğ‘ƒ ) is intractable. Furthermore, solving the optimization problem in Eqn. 4 is itself difficult given 2 ğ‘š search space (ğ‘š is the number of filters in ğ‘‹ ). We characterize the performance of different solutions in Table <ref type="table" target="#tab_4">4</ref>. First, the brute-force search is the most accurate and general method for arbitrary aggregates, despite being very slow. The explanation discovered by brute-force search is exactly the optimal explanation. In this paper, we design two approximate solutions for SUM and AVG, respectively. In particular, we first show the existence of a linearithmic approximated solution when the aggregation is SUM. This solution also has negligible false negatives, as theoretically guaranteed by a lemma on the completeness. Furthermore, we present a heuristics-based solution for AVG with quadratic complexity. Moreover, this solution should be applicable for other aggregate functions with a mild downgrade in optimality. Our evaluation (Sec. 4.4) shows that both approximations are tight and efficient in comparison to brute-force search. Optimization for SUM. Given the additive property of SUM (i.e., Î”(ğ· ğ‘ƒ 1 + ğ· ğ‘ƒ 2 ) = Î”(ğ· ğ‘ƒ 1 ) + Î”(ğ· ğ‘ƒ 2 )), we obtain the following proposition to prune the search space.</p><p>Proposition 3.2. If ğ‘ƒ * is the optimal explanation of Eqn. 4, âˆ€ğ‘ âˆˆ ğ‘ƒ * , Î”(ğ· ğ‘ ) &gt; 0.</p><p>According to Proposition 3.2, the search algorithm can omit filters with a non-positive Î” ğ‘– (i.e., Î”(ğ· ğ‘ ğ‘– )). Recall that Eqn. 4 seeks the optimal explanation. When the aggregate function is SUM, we only need to focus on filters with a reasonably high Î” ğ‘– without losing optimality and we define such filters as canonical filters. Definition 3.6 (Canonical Filter and Predicate). Without loss of generality (w.l.o.g.), given a Why Query Î” and an attribute of interest ğ‘‹ , let filters</p><formula xml:id="formula_13">{ğ‘ 1 , â€¢ â€¢ â€¢ , ğ‘ ğ‘š } of ğ‘‹ be ordered by Î” ğ‘– (i.e., Î”(ğ· ğ‘ ğ‘– )) such that Î” 1 â‰¥ â€¢ â€¢ â€¢ â‰¥ Î” ğ‘š . We let ğ‘ 1 , â€¢ â€¢ â€¢ , ğ‘ ğ‘— be canonical filters if Î”(ğ·) - ğ‘— âˆ‘ï¸ ğ‘–=1 Î” ğ‘– â‰¤ ğœ– &lt; Î”(ğ·) - ğ‘— -1 âˆ‘ï¸ ğ‘–=1 Î” ğ‘–<label>(5)</label></formula><formula xml:id="formula_14">ğ‘ƒ ğ¶ = {ğ‘ 1 , â€¢ â€¢ â€¢ , ğ‘ ğ‘— } is called a canonical predicate and ğœ = ğ‘— ğ‘–=1 Î” ğ‘– .</formula><p>With canonical filters and a corresponding canonical predicate ğ‘ƒ ğ¶ , we observe that ğ‘ƒ ğ¶ manifests good properties. First, ğ‘ƒ ğ¶ is the minimal counterfactual cause entailed by Eqn. 5. Our construction of canonical predicates guarantees completeness. Proposition 3.3 (Completeness). For SUM, given a Why Query Î”, an attribute of interest ğ‘‹ and corresponding canonical predicate ğ‘ƒ ğ¶ , there exists an optimal explanation ğ‘ƒ * âŠ† ğ‘ƒ ğ¶ .</p><p>The completeness proposition (Proposition 3.3) allows us to only focus on canonical filters when searching for the optimal explanation without loss of optimality. More importantly, the canonical predicate also allows us to efficiently identify actual causes and the corresponding valid contingencies. Theorem 3.3. For SUM, given a Why Query Î”, an attribute of interest ğ‘‹ and corresponding canonical predicate ğ‘ƒ ğ¶ , âˆ€ğ‘ƒ âŠ‚ ğ‘ƒ ğ¶ , ğ‘ƒ is an actual cause and ğ‘ƒ = ğ‘ƒ ğ¶ -ğ‘ƒ is a valid contingency.</p><p>The advantages of Thm. 3.3 are twofold. First, we can directly confirm valid explanations without exhaustive enumerations. Second, by the property of ğ‘ƒ, we bound ğ‘ƒ's responsibility (ğœŒ ğ‘ƒ ). Theorem 3.4. For SUM, given a Why Query Î”, an attribute of interest ğ‘‹ and corresponding canonical predicate ğ‘ƒ ğ¶ , the W-Responsibility ğœŒ ğ‘ƒ of ğ‘ƒ âŠ‚ ğ‘ƒ ğ¶ satisfies</p><formula xml:id="formula_15">1 1 + ğœ -Î”(ğ· ğ‘ƒ ) Î”(ğ· ) â‰¤ ğœŒ ğ‘ƒ â‰¤ 1 2 -Î”(ğ· ğ‘ƒ )+ğœ– Î”(ğ· )<label>(6)</label></formula><p>When Î”(ğ· ğ‘ƒ ) â‰ª ğœ and 0 &lt; ğœ â‰¤ Î”(ğ·),</p><formula xml:id="formula_16">1 1+ğœ -Î”(ğ· ğ‘ƒ ) â‰ˆ 1+ğœ+Î”(ğ· ğ‘ƒ ) (1+ğœ ) 2</formula><p>and the corresponding approximation error rate ğ¸ &lt; 0.25.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Thm. 3.4 provides a way to efficiently approximate responsibility with theoretical guarantees.</head><p>In that sense, we can compute responsibility immediately and alleviate searching the minimal Algorithm 2: XPlainer For AVG Input: Why Query Î”, threshold ğœ–, consiseness parameter ğœ Output: (near) optimal explanation ğ‘ƒ * 1 ğ‘ƒ ğ¶ â† âˆ…; contingency. Let Ïğ‘ƒ = 1+ğœ+Î”(ğ· ğ‘ƒ ) (1+ğœ ) 2 , we can rewrite the objective function in the following form.</p><formula xml:id="formula_17">2 foreach ğ‘Ÿ = 1, â€¢ â€¢ â€¢ , min(ğ‘š,</formula><p>Ïğ‘ƒ</p><formula xml:id="formula_18">-ğœ |ğ‘ƒ | = ğ¶ 1 + ğ¶ 2 Ã— âˆ‘ï¸ ğ‘ ğ‘– âˆˆğ‘ƒ (Î” ğ‘– -ğ¶ 3 )<label>(7)</label></formula><p>Here, ğ¶ 1 , ğ¶ 2 , ğ¶ 3 are constants. Then, the optimal explanation to Eqn. 7 is straightforward:</p><formula xml:id="formula_19">ğ‘ƒ * = {ğ‘ ğ‘– | Î” ğ‘– &gt; ğ¶ 3 }<label>(8)</label></formula><p>where</p><formula xml:id="formula_20">ğ¶ 3 = ğœÎ”(ğ· ) (1+ ğœ Î”(ğ· ) ) 2 .</formula><p>The complexity is O (ğ‘š log(ğ‘š)) (primarily in sorting filters for generating canonical predicates). Optimization for AVG. In terms of AVG, it is generally much more challenging due to the absence of the additive characteristics on Î”(ğ· ğ‘ƒ ). Therefore, the majority of the preceding propositions are not applicable. Having said that, we find the causal graph gives considerable opportunities to prune unnecessary computations. Definition 3.7 (Homogeneous Sibling Subspace). Given sibling subspaces ğ‘  1 , ğ‘  2 (with foreground variable ğ¹ and background variables ğ‘©), an attribute ğ‘‹ and the causal graph ğº, ğ‘  1 , ğ‘  2 are homogeneous on ğ‘‹ if ğ‘‹, ğ¹ are m-separated given ğ‘© on ğº. Proposition 3.4. For a homogeneous AVG, given a Why Query Î”, an attribute of interest ğ‘‹ , a predicate ğ‘ƒ âŠ† ğ‘ ğ‘– and a filter ğ‘ âˆˆ ğ‘ƒ, if Î”(ğ· ğ‘ ) &gt; Î”(ğ· ğ‘ƒ ), then Î”(ğ· ğ‘ƒ -ğ· ğ‘ ) &lt; Î”(ğ· ğ‘ƒ ).</p><p>To practically address the search problem of AVG (Eqn. 4), we rely on greedy-based heuristics with a pruning strategy enabled by Proposition 3.4. The algorithm is outlined in Alg. 2.</p><p>The high-level idea behind Alg. 2 is similar to the one for SUM, which attempts to construct a canonical predicate ğ‘ƒ ğ¶ such that ğ‘ƒ ğ¶ forms a counterfactual cause, each subset ğ‘ƒ âŠ‚ ğ‘ƒ ğ¶ of the canonical predicate constitutes an actual cause, and the complement set ğ‘ƒ ğ¶ -ğ‘ƒ is a valid contingency. Unlike SUM, however, Alg. 2 does not ensure the optimality of the resulting explanation, primarily due to the incompleteness of the canonical predicate (Proposition 3.3) under AVG. Recall that ğœŒ ğ‘ƒ ranges from 0 to 1 in Eqn. 4. The optimal explanation contains at most<ref type="foot" target="#foot_1">foot_1</ref> /ğœ filters (otherwise, ğœŒ ğ‘ƒ -ğœ |ğ‘ƒ | &lt; 0). Hence, the canonical predicate ğ‘ƒ ğ¶ shall contain at most 1 /ğœ or ğ‘š (i.e., the number of filters in the attribute).</p><p>Alg. 2 employs a greedy strategy to construct ğ‘ƒ ğ¶ progressively. It starts with an empty canonical predicate (line 1) and inserts one filter in each iteration (lines 2-13). Before insertion, it checks whether ğ‘ƒ ğ¶ is a canonical predicate (line 3) and terminates the loop if ğ‘ƒ ğ¶ is already valid. Otherwise, it picks the remaining filters that were not chosen in earlier iterations as candidates (line 5) and inserts the filter that minimizes the difference Î”(ğ· -ğ· ğ‘ƒ ğ¶ -ğ· ğ‘ ğ‘– ) at the highest magnitude into ğ‘ƒ ğ¶ (lines 6-12). When homogeneity holds and Î” ğ‘– â‰¤ Î”(ğ· -ğ· ğ‘ƒ ğ¶ ), Alg. 2 prunes ğ‘ ğ‘– according to Proposition 3.4 (lines 7-8). Note that Î” ğ‘– is invariant throughout the loop; thus it only needs to be queried once. In general cases where homogeneity does not hold, Alg. 2 has to enumerate all possible filters in ğ‘ƒ (line 10). If we cannot obtain a valid canonical predicate (i.e., a counterfactual cause to Î”) after the loop, Alg. 2 terminates and outputs âŠ¥, indicating that it fails to find the optimal explanation within the attribute (line 15). Empirically, we do not observe such rare cases. When the canonical predicate</p><formula xml:id="formula_21">ğ‘ƒ ğ¶ is obtained, âˆ€ğ‘˜ = 1, â€¢ â€¢ â€¢ , |ğ‘ƒ ğ¶ | -1, the top-k filters of ğ‘ƒ ğ‘˜ âŠ† ğ‘ƒ ğ¶</formula><p>is a valid actual cause and the complement set Î“ ğ‘˜ = ğ‘ƒ ğ¶ -ğ‘ƒ ğ‘˜ is a valid contingency. According to the termination condition in the above loop (line 3), Î”(ğ· -ğ· ğ‘ƒ ğ‘˜ ) &gt; ğœ–. In addition, according to the definition of canonical predicate Î”(ğ· -ğ· ğ‘ƒ ğ¶ ) = Î”(ğ· -ğ· ğ‘ƒ ğ‘˜ -ğ· Î“ ğ‘˜ ) â‰¤ ğœ–, Î“ ğ‘˜ is a valid contingency to ğ‘ƒ ğ‘˜ . Therefore, we compute the approximated responsibility Ï ğ‘ƒ ğ‘˜ by using its lower bound deduced by Î“ ğ‘˜ (line 19). After enumerating each ğ‘˜, Alg. 2 returns ğ‘ƒ ğ‘˜ such that Ï ğ‘ƒ ğ‘˜ -ğœ |ğ‘ƒ ğ‘˜ | is maximized (line 21). In summary, the first loop (lines 2-14) is of quadratic complexity regardless of homogeneity and the second loop is linear (lines <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>. The total complexity is O (ğ‘š 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION</head><p>In this section, we evaluate XInsight to answer the following three research questions (RQs):</p><p>(1) RQ1: End-To-End Performance. How can XInsight facilitate end users in explainable data analysis? (2) RQ2: XLearner Evaluation. Does XLearner effectively recover causal relations from observational data? (3) RQ3: XPlainer Evaluation. Does XPlainer accurately and efficiently yield explanations? 1   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets &amp; User Study Setup</head><p>To the best of our knowledge, there is no real-world benchmark with manually labeled query/explanation pairs. To deliver a scientific evaluation, we conduct experiments on â‘  public datasets collected from previous works, â‘¡ real-world data collected from a production environment for user study and human evaluation, and â‘¢ synthetic data with ground-truth explanations. The detailed steps for generating synthetic datasets are given in the Supplementary Material. We make necessary preprocessing before feeding to XInsight (e.g., remove missing values). â‘  Flight Delay (FLIGHT). We use the flight delay dataset from <ref type="bibr" target="#b46">[49]</ref> to explore the causes of flight delays in US airports. After preprocessing, the resulting dataset contains 17 variables, including the weather conditions of departure airports (temperature, humidity, visibility, rain, etc.), flight carrier, flight time (month, quarter, year, day of week and hour) and two variables indicating flight delays, DelayMinute (continuous) and Delay&gt;15min (binary). â‘  Hotel Booking (HOTEL). The hotel booking dataset <ref type="bibr" target="#b2">[3]</ref> is frequently used for demonstrating data analysis methods. It contains 119,390 observations from two hotels. Each observation depicts the booking status (e.g., "room type", "reservation status", and "is canceled") of a guest. â‘¡ Web Service Behavior Dataset (WEB). The dataset is collected from a web service's production environment. It contains 29 columns and 764 rows, where each row is a list of binary values. The first 28 columns describe user behaviors on the web service (e.g., whether he clicks a specific button), which are collected by a logging module. The last column indicates whether the user was blocked for publishing malicious content (i.e., "IsBlocked"), which is annotated by cybersecurity experts. These behaviors are known to exhibit strong and clear causal relations, making it appropriate for testing XInsight in real-world scenarios. â‘¢ Synthetic Data A (SYN-A). Ground-truth causal graphs are unattainable in practice and it is common to generate random graphs and then sample observational data from this graphical model. We generate MAGs with 10 to 150 variables (141 distinct scales in total). For each scale, we synthesize five random graphs and the associated datasets, resulting in 705 (141 Ã— 5) datasets. Each dataset is injected with different amount of FDs. â‘¢ Synthetic Data B (SYN-B). We follow the approach in Scorpion <ref type="bibr" target="#b51">[54]</ref> to synthesize datasets for assessing XPlainer. Each dataset includes a valid Why Query and a ground-truth explanation to this difference. We generate 18 datasets with different difficulties.</p><p>User Study Setup. In addition to the experiments that will be launched shortly, we intend to determine the extent to which the results on WEB is correct and reasonable. Nonetheless, rendering professional judgments on explanations and causal claims require sufficient expertise in this domain, which makes gathering a large number of participants difficult. In this study, we recruit six domain experts for the WEB dataset; we confirm each expert can evaluate the explanations and causal claims with professionalism and high confidence. We organize the user study as follows:</p><p>(1) Participant Education. We organize an education session for participants and demonstrate how to discern between causation and correlation. Then, a pilot study is conducted to confirm that participants have an adequate sense of causality. (2) Explanation Assessment. We raise four Why Query and ask XInsight to generate two explanations for each Why Query. We then ask participants to give each explanation a score (between 0 to 5) based on their domain knowledge. (3) Causal Claim Assessment. Following <ref type="bibr" target="#b22">[23]</ref>, we collect eight edges connected to "IsBlocked", transform these causal relations into human-comprehensible causal claims and ask participants to independently evaluate them (by labeling them as "reasonable, " "not reasonable, " or "unsure"). ( <ref type="formula" target="#formula_12">4</ref>) Follow-up Discussion. Participants explain their decision and discuss the aggregated results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">RQ1: End-To-End Performance</head><p>We show that XInsight generates plausible and intuitive explanations for diverse datasets (FLIGHT, HOTEL and WEB) and invite experts to assess the quality of explanations generated for WEB. In this experiment, we manually discover noticeable differences to form Why Query, and ask XInsight to supply the explanations. We also compare XInsight's outputs with naive correlationbased explanations. To ease presentation, we describe a Why Query in human-readable natural language in the following paragraphs. (1) FLIGHT: why AVG(DelayMinute) in May (24.95 min) is notably higher than the one in November (21.28 min)? (2) HOTEL: why AVG(IsCanceled) (cancellation rate) in July (0.37) is notably higher than the one in January (0.30)?</p><p>For the first Why Query, we observe that the duration of flight delay differs by month, particularly for May and November, which motivates us to ask XInsight for explanations -what the cause of the flight delay difference is. XInsight first learns a causal graph from data and identifies "rain" as a direct cause of DelayMinute. Then, XPlainer finds that the difference is reversed (Î” = 3.674 vs. Î” â€² = -2.068) when the condition "rain=Yes" is enforced (Fig. <ref type="figure" target="#fig_6">6</ref>). Thus, it returns "rain=Yes" as an explanation. We interpret the explanation as correct because 1) rain is a typical reason for flight delay, and 2) for most states, monthly precipitation in May is usually higher than in November. Hence, when only counting the rainy cases (by enforcing "rain=Yes"), the difference is eliminated.</p><p>For the second Why Query, we observe that the cancellation rate varies by month of arrival. For instance, the cancellation rate in July is 0.37, which is higher than in January. Thus, we ask XInsight for explanations. XInsight identifies "LeadTime" (number of days between booking data and arrival date) as an indirect cause of "IsCanceled". It also discovers that when enforcing "LeadTimeâ‰¤ 133", the difference is reduced. This is intuitive. A longer "LeadTime" results in greater uncertainty about guests' future schedules, leading to a higher cancellation rate. In January, LeadTime of most reservations is less than 133 days (91%). In contrast, there are far more early reservations (&gt; 133 days) in July (48%), resulting in a higher cancellation rate. When these early reservations are excluded, the difference becomes much smaller. WEB. We report the results of the second phase in the user study (i.e., Explanation Assessment in Sec. 4.1) in Table <ref type="table" target="#tab_6">5</ref>. We view the results as encouraging, since nearly all responses are positive (â‰¥ 3). Moreover, the average scores for seven out of eight explanations are â‰¥ 4. We also investigated the explanation with the lowest score (E2 in Table <ref type="table" target="#tab_6">5</ref>). We find this is counter-intuitive but reasonable in retrospect. In the follow-up session, the discussion among participants also confirmed our finding. During the assessments, experts find many explanations inspiring and insightful, despite their familiarity with the dataset. It continuously increases their knowledge and help them design a better criteria for detecting malicious behavior.</p><p>Answer to RQ1: XInsight shows a promising end-to-end performance in explaining data differences. The user study validates that XInsight achieves a respectable level of agreement with experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">RQ2: XLearner Evaluation</head><p>As a cornerstone of XInsight, XLearner is crucial to the effectiveness of the entire pipeline.</p><p>To answer RQ2, we run XLearner on SYN-A which has ground truth causal graphs and on a real-world dataset WEB. Since WEB does not associate a ground-truth causal graph, we assess the quality of causal relations by the user study. Table <ref type="table" target="#tab_7">6</ref> provides an overall comparison between XLearner and FCI on SYN-A datasets. We find that XLearner is more accurate than FCI in the presence of FDs. In particular, while FCI has comparable precision, XLearner has a much higher recall. This confirms our discussion on the implications of FDs in Sec. 3.1. The faithfulness violations mislead FCI to incorrectly refute true edges (thus yield a lower recall) while XLearner is aware of such faithfulness violations and handles them with the procedure in Sec. 3.1. Since XLearner focuses primarily on FDs as the opposite of FCI, we further study how varying proportions of FDs in the causal graph affect XLearner's performance. We report the superiority in terms of varied amounts of FDs in Fig. <ref type="figure" target="#fig_7">7</ref>. Overall, we observe an increasing trend in XLearner performance (particularly for F1 and recall) as the FD proportion increases. More importantly, we observe that "superiority" increases as FDs increase. Recall, as noted in the caption of Fig. <ref type="figure" target="#fig_7">7</ref>, that the superiority is computed by subtracting the FCI's score from the XLearner's score. Thus, we interpret that XLearner gradually outperforms the FCI algorithm with greater degree as the proportion of FDs grows.</p><p>In addition to the experiments on synthetic datasets, we also evaluate XLearner with the WEB dataset (Sec. 4.1). As aforementioned, this real-world dataset lacks a ground-truth causal graph. Evaluating the accuracy of an estimated causal graph is thus challenging, if not impossible. At this step, we involve human experts to assess the correctness of the identified causal relations in the third phase of our user study (i.e., Causal Claim Assessment in Sec. 4.1).</p><p>We report the results of our user study in Table <ref type="table" target="#tab_8">7</ref>: first, out of 48 responses (6 participants Ã— 8 questions), only three (6.3%) suggest that the causal claims are "Not Reasonable, " while 40 responses (83.3%) mark the causal claims as "Reasonable. " It indicates that the causal relations identified by XLearner correspond with expert knowledge in the majority of instances. Second, we investigate the claims  that have been deemed "Not Reasonable" or "Unsure. " Encouragingly, we find that a notable proportion of causal claims are counter-intuitive yet correct. For instance, one causal claim states that "malicious intent would lead to more frequent configuration changes than benign intent. " In the causal claim assessment phase, one expert deemed it "Not Reasonable" and presumed that malicious users would keep a default configuration. In the follow-up session where they shared the independent assessments, this participant was persuaded and confirmed this causal relation as "Reasonable. "</p><p>Answer to RQ2: As reflected by the carefully-designed quantitative experiments and the user study, XLearner generates plausible causal graphs that are consistent with expert knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">RQ3: XPlainer Evaluation</head><p>Recall the descriptions of SYN-B in which different parameters result in datasets with varying degrees of difficulty. In this experiment, we explore the accuracy of XPlainer on SYN-B.</p><p>Baseline. We compare XPlainer with three baselines, namely, Scorpion <ref type="bibr" target="#b51">[54]</ref>, RSExplain <ref type="bibr" target="#b44">[47]</ref> and BOExplain <ref type="bibr" target="#b26">[27]</ref>, which use predicates as explanations. Scorpion is an explanation engine for explaining outliers. It uses a metric called influence score to rank explanations, which considers the effect of the explanation between the outlier region and the hold-out region. RSExplain uses the concept of intervention to measure the effectiveness of an explanation. BOExplain is originally designed for explaining black-box machine learning models. When explaining Why Query, it employs the inference score and the Bayesian optimization to find the optimal explanation. To launch an apple-to-apple comparison, all baselines are enforced to search over a set of pre-defined causal filters {ğ‘ 1 , â€¢ â€¢ â€¢ , ğ‘ ğ‘š } derived from the generation procedure of SYN-B (see details in Supplementary Material); all these filters have been confirmed to constitute legitimate causal explanations.</p><p>Metric. We use the top-ranked explanation of each baseline as its optimal explanation. We mark a method as "N/A" denoting timeouts (more than one hour to process). We report the F1 Score of filters in the explanation over the ground-truth explanation.</p><p>Different Dataset Sizes. To study the scalability of XPlainer, we generate datasets of varying sizes and report the results in Table <ref type="table" target="#tab_9">8</ref>. Overall, we observe that XPlainer is more accurate and efficient than all baselines across all the studied settings. This is encouraging and also reasonable, as XPlainer uses many distinct characteristics of aggregation functions to optimize the search process, while other methods primarily treat them as a "black-box. " Scorpion and BOExplain often produce incomplete explanations, while RSExplain may frequently find extra spurious filters. We presume that this is because the objective function of Scorpion (and also BOExplain) is for explaining anomalies instead of Why Query, whereas RSExplain is primarily designed for data provenance.</p><p>In contrast, explanations provided by XPlainer are seen as consistent with the ground truth. XPlainer is highly efficient particularly for high cardinality regimes, while both Scorpion and RSExplain run out of time when the cardinality exceeds 30 (see the bottom half of Table <ref type="table" target="#tab_9">8</ref>). BOExplain uses Bayesian optimization to search for explanations, and its accuracy downgrades as cardinality increases. Similarly, when iterating different #Rows (the top half of Table <ref type="table" target="#tab_9">8</ref>), XPlainer also exhibits highly encouraging efficiency: XPlainer takes on average 0.06 seconds to explain Why Query whereas BOExplain (the second best) takes 13.17 seconds. In sum, we interpret from  Different ğœ‡ * -ğœ‡. The difference between ğœ‡ * , ğœ‡ indicates the magnitude of Î”. To study the sensitivity of XPlainer, we study how well XPlainer performs under varying differences and compare it with baselines in Table <ref type="table" target="#tab_11">9</ref>. To clarify, ğœ‡ * -ğœ‡ = 5 and ğœ‡ * -ğœ‡ = 10 denote two relatively more challenging settings in Table <ref type="table" target="#tab_11">9</ref>, given the very subtle differences. On SUM aggregates, we find that all methods have difficulties in identifying explanations in those two challenging settings; still, XPlainer yields the best results for both settings. Even on the most challenging setting (ğœ‡ * -ğœ‡ = 5), XPlainer finds highly accurate explanations whereas RSExplain is less accurate. On AVG aggregates, XPlainer and Scorpion both perform well on identifying the ground-truth explanations; XPlainer is slightly better particularly for the most challenging setting when ğœ‡ * -ğœ‡ = 5. Nevertheless, RSExplain and BOExplain are less accurate on AVG. Overall, we conclude that XPlainer is more robust to subtle data differences while all other methods have difficulties in such challenging settings. We omit reporting the processing time here, since it has already been evidently explored in Table <ref type="table" target="#tab_9">8</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tightness of</head><p>2 ) actual causes from the three filters. In AVG, since the canonical predicate of AVG only supports the first ğ‘˜ filters as actual causes and the rest as contingencies, we pick the top-1 and top-2 filters as two actual causes and repeat the experiments on three datasets (2 Ã— 3 in total). On the six actual causes of SUM aggregates, we find that the brute-force algorithm is 253.3Ã— slower than our approximated solution. More importantly, the approximation error is highly negligible with an average of 0.007. We also observe that the approximation error on AVG is slightly higher (0.066) and that our heuristics-based solution is 27.3Ã— faster. This result is reasonable, as the heuristics-based solution does not provide guarantees of accuracy and requires more queries than SUM.</p><p>Answer to RQ3: XPlainer shows high scalability to large datasets and also accurately generates explanations in very difficult settings. On a mild cost of precision, two approximation solutions of XPlainer substantially improve efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>FD in Noisy Data. XInsight only considers deterministic FDs. As illustrated in Ex. 3.1, taking deterministic FDs into account eliminates faithfulness violations. However, when the data is noisy, the FDs may be stochastic (e.g., probabilistic interpretation of FDs <ref type="bibr" target="#b55">[58]</ref>), which is currently not considered in XInsight. We clarify that considering only deterministic FDs deems a common setup shared by relevant works in this field <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30]</ref>. It remains unclear how noisy FDs may impact faithfulness. We leave this for future exploration.</p><p>Acquiring Causal Knowledge. Inferring causal relations is difficult. Typically, it needs a combination of domain knowledge <ref type="bibr" target="#b1">[2]</ref>, randomized experiments <ref type="bibr" target="#b49">[52]</ref> and causal discovery <ref type="bibr" target="#b48">[51,</ref><ref type="bibr" target="#b54">57,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b9">10]</ref>. XInsight performs causal discovery from observational data due to its simplicity. Nevertheless, we envision users of XInsight can combine additional sources for acquiring more accurate causal knowledge. In this paper, we explain several key obstacles of applying causal discovery to real-world data, including causal insufficiency <ref type="bibr" target="#b54">[57]</ref> and FD-induced faithfulness violations <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30]</ref>. XLearner, for the first time, simultaneously addresses all of them.</p><p>Other Forms of Explanations. Currently, XInsight employs predicates as the content of explanations, which is general enough for common data analysis scenarios. However, in some cases, explanations may be formed by the number of records in a database <ref type="bibr" target="#b12">[13]</ref> or counterbalances <ref type="bibr" target="#b34">[35]</ref>. Furthermore, when explaining changes in a whole time series <ref type="bibr" target="#b8">[9]</ref>, XInsight may be not applicable. We leave integrating XInsight into these scenarios for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORK</head><p>Data Explanation. Explaining an unexpected query outcome in database is a crucial phase in the lifecycle of data analysis. In general, an explanation aims to provide certain forms of patterns that lead to the unexpected query outcome. Such patterns may be a set of predicates <ref type="bibr" target="#b51">[54,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b44">47]</ref>, tuples <ref type="bibr" target="#b30">[31]</ref>, or counterbalances <ref type="bibr" target="#b34">[35]</ref>. Scorpion is the most relevant work for XInsight, which also provides explanations to aggregated queries <ref type="bibr" target="#b51">[54]</ref>. In particular, it employs an influence score to quantify explanations and features a set of optimizations to reduce the cost of explanation search. Recently, many tools have attempted to enhance explanations with additional knowledge (e.g., join tables) about the underlying data. However, such additional knowledge does not imply causation -top ranked explanations could be rated low by human participants due to a lack of causal semantics <ref type="bibr" target="#b23">[24]</ref>. These observations evidently show the necessity of integrating causality into XDA.</p><p>Causality in Database. Most works related to causality analysis in the database is on the basis of Halpern's seminal framework on actual causality <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18]</ref>. It provides an elegant and natural way to reason about input-output relations. Its results not only highlight the output's cause, but also provide a contingency describing how it is triggered. The adaption of actual causality in the database (i.e., DB causality) is widely used for data provenance <ref type="bibr" target="#b32">[33]</ref>, data explanation <ref type="bibr" target="#b44">[47]</ref> and debugging <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b53">56,</ref><ref type="bibr" target="#b19">20]</ref>. However, it has limitations when applied alone. On the one hand, as noted in <ref type="bibr" target="#b16">[17]</ref>, DB causality does not necessarily imply true causation. Indeed, it assumes that causal knowledge is already known, and focuses solely on quantitative explanations. On the other hand, considerable adaptions are required to make it applicable to XDA scenarios, as discussed in Sec. 3.3. We also notice other methods for quantifying explanations, such as sufficient score, necessity score, and average causal effect <ref type="bibr" target="#b45">[48,</ref><ref type="bibr" target="#b50">53]</ref>. Despite their usefulness, we design XPlainer on top of actual causality because it is more understandable and general. Furthermore, without prior causal knowledge, none of these methods can imply true causation.</p><p>XDA vs. XAI. We note that XAI (explainable artificial intelligence) is parallel and complementary to XDA. Through the lens of data analysis, XAI aims to explain a prediction or model <ref type="bibr" target="#b43">[46,</ref><ref type="bibr" target="#b15">16]</ref>, while XDA enhances EDA for understanding data facts. In addition, we also observe a line of research <ref type="bibr" target="#b52">[55,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b24">25]</ref> that identifies a subset of (training) data that is responsible for a prediction. While this line of research shares similar output format with XInsight, it is essentially for explaining how model predictions are influenced by training/test data, a scenario that is orthogonal to our research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>This paper advocates XDA, a concept that ships comprehensive and in-depth explainability toward EDA. XDA offers either causal or non-causal explanations for EDA outcomes, from both quantitative and qualitative perspectives. We have also presented the design of XInsight, a production framework for XDA over databases. Experiments and human evaluations reveal that XInsight manifests highly encouraging explanation capabilities. XPlainer has been integrated into Microsoft Power BI to explain increase/decrease in data.  </p><formula xml:id="formula_23">ğ‘ƒ (ğ‘‹ğ‘Œ ) = ğ‘ƒ (ğ‘‹ )ğ‘ƒ (ğ‘Œ | ğ‘‹ ) = ğ‘ƒ (ğ‘‹ )ğ¼ ğ‘Œ =ğ‘“ (ğ‘‹ ) â‰  ğ‘ƒ (ğ‘‹ )ğ‘ƒ (ğ‘Œ )<label>(9)</label></formula><p>Therefore, ğ‘Œ Ì¸âŠ¥ âŠ¥ ğ‘‹ . Given a variable set ğ‘ , Proof. We first construct a MAG G on the top of the skeleton, by adding an arrowhead from ğ‘‹ 1 to ğ‘ (G 2 ). Because S 1 is learnt from {ğ‘‹ 1 , â€¢ â€¢ â€¢ , ğ‘‹ ğ‘› } where faithfulness assumption holds, this part is harmonious. For ğ‘ , there are two types of m-separation in G. Here, we prove that each type of m-separation satisfies GMP to data distribution ğ‘ƒ ğ‘‰ .</p><formula xml:id="formula_24">ğ‘ƒ (ğ‘Œ ğ‘ | ğ‘‹ ) = ğ‘ƒ (ğ‘‹ğ‘Œ ğ‘ ) ğ‘ƒ (ğ‘‹ ) = ğ‘ƒ (ğ‘‹ğ‘ )ğ¼ ğ‘Œ =ğ‘“ (ğ‘‹ ) ğ‘ƒ (ğ‘‹ ) = ğ‘ƒ (ğ‘ | ğ‘‹ )ğ¼ ğ‘Œ =ğ‘“ (ğ‘‹ ) = ğ‘ƒ (ğ‘ | ğ‘‹ )ğ‘ƒ (ğ‘Œ | ğ‘‹ )<label>(10</label></formula><p>Type 1: Proof. We prove Thm. 3.2 by mathematical induction. In the sense, Alg. 1 returns a harmonious skeleton when G FD has arbitrary number of non-root vertices. Denote the number of non-root vertices as ğ‘  â‰¥ 0.</p><formula xml:id="formula_25">ğ‘ â«« G ğ‘‹ ğ‘—â‰ 1 | ğ‘‹ 1 According to Lemma. 8.3.1, ğ‘‹ 1 FD --â†’ ğ‘ implies that ğ‘ â«« ğ‘‹ ğ‘—â‰ 1 | ğ‘‹ 1 . Type 2: ğ‘ â«« G ğ‘‹ ğ‘— | ğ‘ˆ ( ğ‘— â‰  1, ğ‘ˆ âˆ© {ğ‘‹ 1 , ğ‘‹ ğ‘— } = âˆ…) By Lemma. 8.3.3, ğ‘ â«« G ğ‘‹ ğ‘— | ğ‘ˆ implies that ğ‘‹ 1 â«« G ğ‘‹ ğ‘— | ğ‘ˆ . Because ğ‘† 1 is harmonious, ğ‘‹ 1 â«« G ğ‘‹ ğ‘— | ğ‘ˆ implies that ğ‘‹ 1 â«« ğ‘‹ ğ‘— | ğ‘ˆ .</formula><p>Base Case. When ğ‘  = 0, the skeleton is harmonious because all variables are under faithfulness assumptions.</p><p>Induction. Suppose the returned skeleton is harmonious for G FD when ğ‘  = ğ‘›. Now we prove the skeleton is still harmonious when we add a vertex ğ‘‹ â€² to a vertex set ğ‘¿ âŠ† G FD .ğ‘‰ . Denote the new FD-induced graph as G â€² FD , the skeleton of G FD as S, and the skeleton for G â€² FD as S â€² . According to Alg. 1, S, S â€² share the same vertices and edges (except ğ‘‹ â€² ). Given that S is harmonious, S â€² can be decomposed into two subgraphs, i.e., S 1 , S 2 , where S 1 = S and S 2 corresponds to ğ‘‹ â€² and one edge from ğ‘‹ â€² to one of ğ‘¿ . Since ğ‘‹ â€²â€² FD --â†’ ğ‘‹ â€² , by Thm. 3.1, S â€² is harmonious. By the principle of mathematical induction, Thm. Since we only consider one-to-one and one-to-many FDs, FD-induced vertices only have at most one parent node in G FD . Therefore, it forms tree-structural subgraphs in the skeleton starting from the root vertices of G FD (e.g., the left-hand side skeleton shown in Fig. <ref type="figure" target="#fig_11">8</ref>). Intuitively, it would be ideal if the orientation rules allow us to orient the tree-structural subgraphs in a top-down manner (e.g., the right-hand side of Fig. <ref type="figure" target="#fig_11">8</ref>). In particular, if there is an edge heading to the root node of the tree-structural subgraph, we can assign â†’ (â†’ is defined in Table <ref type="table" target="#tab_0">1</ref>) as the edge from the root node to its child vertices and propagate the directions to the leaf node by applying Rule 1 of FCI recursively. Definition 8.8 (Rule 1 of FCI <ref type="bibr" target="#b54">[57]</ref>). If ğ‘‹ * â†’ğ‘Œ â€¢â†’ğ‘ and ğ‘‹, ğ‘ are non-adjacent, then orient ğ‘Œ â†’ ğ‘ . <ref type="foot" target="#foot_4">3</ref>However, it is not necessarily attainable if we cannot identify the direction on the edge heading to the root node (i.e., ğ‘Œ in Def. 8.8). As a result, we cannot derive any directions on the subgraphs. That is, all edges on the subgraph are â€¢-â€¢, which denote edges with unknown directions. Such ambiguous cases are surely undesirable in XDA scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.6">ANM on FD-related Edges</head><p>We note that, from viewpoint of conditional independence, functional dependency does not imply causal directions in all cases. However, we present that the counterexamples of such cases (i.e., contrasting direction between causal relation and functional dependency) are very rare in practice, if at all possible. Recall the theorem of "Identifiability of discrete ANMs" in <ref type="bibr" target="#b40">[43]</ref>. ğ‘ƒ (ğ‘¥ âˆˆğ¶ 0 ) the probability of another shifted country ğ‘¥ -ğ‘‘ ğ‘– . The conditions together exhibits a very rare scenario. Therefore, we ignore such cases in practice.</p><p>As consistent with <ref type="bibr" target="#b40">[43]</ref>, we consider it reasonable to infer that direction of ANM as causal. Therefore, we hypothesis that functional dependencies in G FD intrinsically imply causal directions.   <ref type="bibr" target="#b16">(17)</ref> The inequality in the above equation is true because ğ´ ğµ &lt; ğ¶ ğ· implies ğ´-ğ¶ ğµ-ğ· &lt; ğ´ ğµ where ğ´, ğµ, ğ¶, ğ· are positive and ğ´ &gt; ğ¶, ğµ &gt; ğ·. â–¡ 8.12 Generating Synthetic Data â‘¢ Synthetic Data A (SYN-A). We use ErdÅ‘s-RÃ©nyi model, a well-established random graph model, to synthesize random causal graphs of different scales and to produce datasets via forward sampling <ref type="bibr" target="#b41">[44]</ref>. To simulate causally insufficient systems, we mask 5% variables at random and return the corresponding PAG (Partial Ancestral Graph) as the ground truth. We construct conditional probability tables based on a Dirichlet prior and generate two additional FD nodes on each leaf node. Afterwards, these functional dependencies are employed to build FD-induced graphs. â‘¢ Synthetic Data B (SYN-B). In particular, we design a data generating process with three variables ğ‘‹, ğ‘Œ , ğ‘ , where ğ‘‹ is a binary variable, ğ‘Œ is a categorical variable, and ğ‘ is a numerical variable. Different values in ğ‘‹ first impact ğ‘Œ and then ğ‘Œ 's values further impact ğ‘ . When ğ‘Œ 's</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Example 2 . 4 :</head><label>24</label><figDesc>Let CityInfo be a dataset with three attributes (i.e., City, State, Country). It has three FDs, namely, City FD --â†’ State, State FD --â†’ Country, and City FD --â†’ Country. FD-Induced Graph. Given a multi-dimensional data ğ· and its functional dependencies, the FDinduced Graph G FD (ğ‘‰ , ğ¸), where ğ‘‰ {ğ‘‹ ğ‘– | âˆ€ğ‘‹ ğ‘– âˆˆ ğ· } and ğ¸ {(ğ‘‹ ğ‘– , ğ‘‹ ğ‘— ) | if ğ‘‹ ğ‘–</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Examples of observable and latent confounders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 (</head><label>1</label><figDesc>c), Smoking is a collider of Location and Stress since "Location â€¢â†’ Smoking â†â€¢ Stress", where â€¢ represents an undetermined edge endpoint.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Workflow of XInsight. Offline phase is marked in blue and online phase is marked in red.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .Example 3 . 1 :</head><label>431</label><figDesc>Fig. 4. Illustration of FD-induced faithfulness violation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Running example of XLearner.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Explanation of Why Query on the FLIGHT dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Comparison by FD Proportion. The x-axis is the proportion of FDs in the causal graph. The y-axis is the superiority (determined by subtracting the FCI's score from the XLearner's score) of XLearner over FCI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>XInsight: eXplainable Data Analysis Through The Lens of Causality 156:21</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Approximation. In Sec. 3.3, we show the approximation of minimal contingency for computing responsibilities under SUM and AVG. In the following, we compare the tightness of the responsibility Ï computed by ğ‘ƒ = ğ‘ƒ ğ¶ -ğ‘ƒ to the true responsibility ğœŒ computed by the minimal contingency ğ‘ƒ min via brute-force search. The approximation error is computed as ğ¸ = | Ï -ğœŒ | ğœŒ . Recall</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>adjacent pair (ğ‘‹, ğ‘Œ ) âˆˆ ğ¹ â€² do 16 if there exists a subset ğ‘º âŠ† Ext-D-SEP(ğ‘‹, ğ‘Œ ) such that ğ‘‹ â«« ğ‘Œ | ğ‘º then 17 delete the edge between ğ‘‹ and ğ‘Œ from ğ¹ â€² ; 18 end 19 end 20 let ğº be the undirected graph of ğ¹ â€² ; 21 return ğº, Sepset Proof. Because ğ‘‹ FD --â†’ ğ‘Œ , ğ‘ƒ (ğ‘Œ | ğ‘‹ ) = ğ¼ ğ‘Œ =ğ‘“ (ğ‘‹ ) . Since |ğ‘‹ |, |ğ‘Œ | &gt; 1, the following inequality holds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Orientation on tree-structural subgraph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Theorem 8 . 1 .</head><label>81</label><figDesc>Assume that a distribution ğ‘ƒ ğ‘‹ ,ğ‘Œ allows for an ANM ğ‘Œ = ğ‘“ (ğ‘‹ ) + ğ‘ ğ‘Œ from ğ‘‹ to ğ‘Œ and that either ğ‘‹ or ğ‘Œ has finite support. ğ‘ƒ ğ‘‹ ,ğ‘Œ allows for an ANM from ğ‘Œ to ğ‘‹ if and only if there exists a disjoint decomposition ğ‘™ ğ‘–=0 ğ¶ ğ‘– = suppğ‘‹ , such that the following conditions a), b), and c) are satisfied: a) The ğ¶ ğ‘– 's are shifted versions of each otherâˆ€ğ‘–âˆƒğ‘‘ ğ‘– &gt; 0 : ğ¶ ğ‘– = ğ¶ 0 + ğ‘‘ ğ‘– (12)and ğ‘“ is piecewise constant: ğ‘“ | ğ¶ ğ‘– â‰¡ ğ‘ ğ‘– âˆ€ğ‘–.b) The probability distributions on the ğ¶ ğ‘– s are shifted and scaled versions of each other with the same shift constant as above: For ğ‘¥ âˆˆ ğ¶ ğ‘– , ğ‘ƒ (ğ‘‹ = ğ‘¥) satisfiesğ‘ƒ (ğ‘‹ = ğ‘¥) = ğ‘ƒ (ğ‘‹ = ğ‘¥ -ğ‘‘ ğ‘– ) â€¢ ğ‘ƒ (ğ‘¥ âˆˆ ğ¶ ğ‘– ) ğ‘ƒ (ğ‘¥ âˆˆ ğ¶ 0 )(13)c) The sets ğ‘ ğ‘– + suppğ‘ ğ‘Œ := {ğ‘ ğ‘– + â„ : ğ‘ƒ (ğ‘ ğ‘Œ = â„) &gt; 0} are disjoint sets.By condition c), since ğ‘ ğ‘Œ = 0 by functional dependency, âˆ„ğ‘¥ ğ‘– âˆˆ ğ¶ ğ‘– , ğ‘¥ ğ‘— âˆˆ ğ¶ ğ‘— s.t. ğ‘“ (ğ‘¥ ğ‘– ) = ğ‘“ (ğ‘¥ ğ‘— ). In other word, ğ‘‹ are decomposed by the value of ğ‘“ (ğ‘¥) and each ğ‘ ğ‘– âˆˆ ğ‘“ (ğ‘‹ ) forms a disjoint subset ğ¶ ğ‘– of ğ‘‹ . To admit condition a), each ğ¶ ğ‘– is a shifted version of others. Therefore, each ğ¶ ğ‘– should at least have an equal cardinality. The above two conditions imply that each ğ‘¦ âˆˆ ğ‘Œ corresponds to equal size of ğ‘¥ âˆˆ ğ‘‹ . Consider the aforementioned example where Country FD --â†’ Continent. To satisfy the condition, each continent must have equal number of countries. Furthermore, by condition b), the probability of a country ğ‘¥ in continent ğ‘ ğ‘– in the database can be exactly scaled by ğ‘ƒ (ğ‘¥ âˆˆğ¶ ğ‘– )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>and we use Î” ğ‘– as a shorthand for Î”(ğ· ğ‘ ğ‘– ). For AVG and Î”(ğ· ğ‘ƒ ) = ğ‘ ğ‘– âˆˆğ‘ƒ Î” ğ‘– , Î”(ğ·) can be represented in the form of ğ‘š 1 ( ğ‘ ğ‘– ğ‘¥ ğ‘– ğ´ ğ· -ğ‘ ğ‘– ğ‘¦ ğ‘– ğµ ğ· ).Proposition 8.1. If a pair of sibling subspaces are homogeneous on ğ‘‹ , then ğ‘ 1 ğ‘ 1 = â€¢ â€¢ â€¢ = ğ‘ ğ‘š ğ‘ ğ‘š . Proof. For homogeneous AVG, ğ‘‹, ğ¹ are m-separated given ğ‘©. Hence, ğ‘‹ â«« ğ¹ | ğ‘© and ğ‘ƒ (ğ‘‹, ğ¹ | ğ‘©) = ğ‘ƒ (ğ‘‹ | ğ‘©)ğ‘ƒ (ğ¹ | ğ‘©). Recall that ğ‘ ğ‘– = ğ‘ƒ (ğ‘‹ = ğ‘¥ ğ‘– , ğ¹ = ğ‘“ 1 | ğ‘© = ğ’ƒ) and ğ‘ ğ‘– = ğ‘ƒ (ğ‘‹ = ğ‘¥ ğ‘– , ğ¹ = ğ‘“ 2 | ğ‘© = ğ’ƒ).We have</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Four types of edges in PAG. Circle represents undetermined edge endpoint (can be either an arrowhead or tail). ğ‘Œ ğ‘‹ is a cause of ğ‘Œ . ğ‘‹ â†” ğ‘Œ neither ğ‘‹ nor ğ‘Œ is a cause of each other but they share a latent common cause. ğ‘‹ â€¢â†’ğ‘Œ 1) ğ‘‹ is a cause of ğ‘Œ ; or 2) neither ğ‘‹ nor ğ‘Œ is a cause of each other but they share a latent common cause. The second condition in Def. 2.8 implies that an edge associates a tail "-" or arrowhead "â†’" endpoint, if and only if it is invariant in all G âˆˆ [G]. Table 1 lists the semantics of edges.</figDesc><table><row><cell cols="2">Edge Causal Semantics</cell></row><row><cell>ğ‘‹ â†’ ğ‘‹ â€¢-â€¢ğ‘Œ</cell><cell>1) ğ‘‹ may be a cause of ğ‘Œ ; or 2) ğ‘Œ may be a cause of ğ‘‹ ; or 3) neither ğ‘‹ nor ğ‘Œ is a cause of each other but they share a latent common cause.</cell></row><row><cell cols="2">Definition 2.8 (Partial Ancestral Graph [57]). Let [G] be a Markov equivalence class of</cell></row><row><cell cols="2">a MAG G. A PAG for [G] is a graph P with three possible edge endpoints (namely, tail, circle and</cell></row><row><cell cols="2">arrowhead; and hence four kinds of edges: â†’, â†”, â€¢â†’, â€¢-â€¢) such that 1) P shares the same adjacencies</cell></row><row><cell cols="2">with G (and any member of [G]), and 2) every non-circle edge endpoint indicates an invariant edge</cell></row><row><cell cols="2">endpoint in [G].</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Comparing different causal discovery algorithms. âœ“ denotes "support" whereas âœ— denotes "no support".</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>stage 1: detect and preclude ğ‘¿ FD (Sec. 3.1.1) 2 S 2 â† (ğ‘‰ , âˆ…); 3 Topologically sorting nodes in G FD and record depth as ğ‘‘ (ğ‘‹ ğ‘– ); 4 while G FD has non-root nodes do 5 ğ‘‹ â† argmax ğ‘‹ âˆˆ G FD .ğ‘‰ ğ‘‘ (ğ‘‹ ); ğ‘Œ â† argmin ğ‘Œ âˆˆğ‘ƒğ‘ ( G FD ,ğ‘‹ ) |ğ‘Œ |; 7 add edge (ğ‘‹, ğ‘Œ ) in S 2 ; 8 remove ğ‘‹ and all connected edges from G FD ; 9 end 10 // stage 2: standard PAG learning 11 S 1 â† FCI-SL(ğ·, G FD .ğ‘‰ ); 12 G 1 â† FCI-Orient(ğ‘† 1 ); 13 // stage 3: orient S 1 and generate G (Sec. 3.1.2)</figDesc><table><row><cell>6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Translating causal primitives to XDA semantics. ğ‘‹ â«« ğ‘€ | ğ¹ . When we enforce ğ‘‹ = ğ‘¥, Î”(ğ· ğ‘‹ =ğ‘¥ ) can merely be affected by the number of rows where ğ‘‹ = ğ‘¥ in two sibling subspaces (namely a COUNT-based explanation) instead of a causal relation between ğ‘‹ and ğ‘€ (see detailed formulation in Supplementary Material</figDesc><table><row><cell>Rule</cell><cell>Path</cell><cell>Causal Primitive</cell><cell>XDA Semantics</cell></row><row><cell>â€</cell><cell>ğ‘‹ â†’ ğ¹ â†’ ğ‘€, â€¢ â€¢ â€¢</cell><cell>m-separated</cell><cell>no explainability</cell></row><row><cell>â</cell><cell>ğ‘‹ â†’ ğ‘€</cell><cell>parent</cell><cell>causal explanation</cell></row><row><cell>â‚</cell><cell>ğ‘‹ â†’ â€¢ â€¢ â€¢ â†’ ğ‘€</cell><cell>ancestor</cell><cell>causal explanation</cell></row><row><cell>âƒ</cell><cell>ğ‘‹ â€¢â†’ğ‘€</cell><cell>almost parent</cell><cell>causal explanation</cell></row><row><cell>â„</cell><cell>ğ‘‹ â€¢â†’ â€¢ â€¢ â€¢ â€¢â†’ğ‘€</cell><cell>almost ancestor</cell><cell>causal explanation</cell></row><row><cell>â…</cell><cell>others</cell><cell>N/A</cell><cell>non-causal explanation</cell></row></table><note><p>Extension to SUM. The above formulation over explainability is established on AVG aggregates. In the following, we discuss the implications of our formulation on SUM aggregates. If ğ‘‹ has no explainability,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Different search solutions in XPlainer. FP is false positive and FN is false negative.</figDesc><table><row><cell>Solution</cell><cell>Complexity</cell><cell>Optimality</cell></row><row><cell>Brute-force Search</cell><cell>ğ‘‚ (2 ğ‘š )</cell><cell>Optimal</cell></row><row><cell cols="3">Approx. Search (SUM) ğ‘‚ (ğ‘š log ğ‘š) Moderated FP; Negligible FN</cell></row><row><cell>Approx. Search (AVG)</cell><cell>ğ‘‚ (ğ‘š 2 )</cell><cell>Moderated FP&amp;FN</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>ğ‘† â† {ğ‘ ğ‘– | ğ‘ ğ‘– âˆˆ ğ‘ƒ, Î” ğ‘– &gt; Î”(ğ· -ğ· ğ‘ƒ ğ¶ )}; â† argmin ğ‘ âˆˆğ‘† Î”(ğ· -ğ· ğ‘ƒ ğ¶ -ğ· ğ‘ ); ğ· ğ‘ƒ ğ¶ ) &gt; ğœ– then return âŠ¥; 16 foreach ğ‘˜ âˆˆ 1, â€¢ â€¢ â€¢ , |ğ‘ƒ ğ¶ | do</figDesc><table><row><cell></cell><cell>1 ğœ ) do</cell></row><row><cell>9</cell><cell>else</cell></row><row><cell cols="2">10 ğ‘  13 end</cell></row><row><cell>14 end</cell><cell></cell></row><row><cell cols="2">15 if Î”(ğ· -</cell></row></table><note><p>3 if Î”(ğ· -ğ· ğ‘ƒ ğ¶ ) â‰¤ ğœ– then break ; 4 else 5 ğ‘ƒ â† {ğ‘ 1 , â€¢ â€¢ â€¢ , ğ‘ ğ‘š } -ğ‘ƒ ğ¶ ; 6 if homogeneous then 7 8 ğ‘ * * â† argmin ğ‘ âˆˆğ‘ƒ Î”(ğ· -ğ· ğ‘ƒ ğ¶ -ğ· ğ‘ ); 11 end 12 ğ‘ƒ ğ¶ â† ğ‘ƒ ğ¶ âˆª {ğ‘ * }; 17 ğ‘ƒ ğ‘˜ â† top-k filters of ğ‘ƒ ğ¶ ; 18 Î“ ğ‘˜ â† ğ‘ƒ ğ¶ -ğ‘ƒ ğ‘˜ ; 19 compute Ï ğ‘ƒ ğ‘˜ with Î“ ğ‘˜ . 20 end 21 return argmax ğ‘˜ Ï ğ‘ƒ ğ‘˜ -ğœ |ğ‘ƒ ğ‘˜ |;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Results of explanation assessment. Eğ‘– and Pğ‘– stand for the ğ‘–th explanation and the ğ‘–th participant, respectively.</figDesc><table><row><cell></cell><cell>E1</cell><cell>E2</cell><cell>E3</cell><cell>E4</cell><cell>E5</cell><cell>E6</cell><cell>E7</cell><cell>E8</cell></row><row><cell>P1</cell><cell>4</cell><cell>4</cell><cell>5</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>5</cell><cell>3</cell></row><row><cell>P2</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>3</cell><cell>4</cell><cell>3</cell><cell>4</cell></row><row><cell>P3</cell><cell>5</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>3</cell><cell>5</cell><cell>5</cell><cell>5</cell></row><row><cell>P4</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>4</cell><cell>4</cell><cell>3</cell><cell>3</cell><cell>4</cell></row><row><cell>P5</cell><cell>4</cell><cell>2</cell><cell>5</cell><cell>3</cell><cell>5</cell><cell>4</cell><cell>3</cell><cell>3</cell></row><row><cell>P6</cell><cell>5</cell><cell>4</cell><cell>5</cell><cell>5</cell><cell>5</cell><cell>4</cell><cell>5</cell><cell>5</cell></row><row><cell cols="9">mean 4.16 3.50 4.67 4.17 4.00 4.00 4.00 4.00</cell></row><row><cell>std</cell><cell cols="8">0.69 0.76 0.47 0.69 0.82 0.58 1.00 0.82</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 .</head><label>6</label><figDesc>Overall comparison between XLearner and FCI.</figDesc><table><row><cell>Algo.</cell><cell>F1-Score Precision</cell><cell>Recall</cell></row><row><cell cols="3">XLearner 0.88 Â± 0.04 0.95 Â± 0.03 0.82 Â± 0.06</cell></row><row><cell>FCI</cell><cell cols="2">0.72 Â± 0.05 0.92 Â± 0.04 0.59 Â± 0.06</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 .</head><label>7</label><figDesc>User study. Cğ‘– stands for the ğ‘–th causal claim.</figDesc><table><row><cell></cell><cell cols="8">C1 C2 C3 C4 C5 C6 C7 C8</cell></row><row><cell># Reasonable</cell><cell>6</cell><cell>4</cell><cell>4</cell><cell>6</cell><cell>6</cell><cell>4</cell><cell>5</cell><cell>5</cell></row><row><cell># Not Sure</cell><cell>0</cell><cell>2</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>1</cell></row><row><cell cols="2"># Not Reasonable 0</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>2</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 .</head><label>8</label><figDesc>XPlainer and baselines under various settings. âœ“ denotes that F1=1.0 and the best metric is highlighted.</figDesc><table><row><cell cols="2">#Rows (Cardinality=10)</cell><cell>10K</cell><cell>20K</cell><cell>50K</cell><cell cols="2">100K 500K</cell><cell>1M</cell></row><row><cell>XPlainer</cell><cell>F1 Score</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell></row><row><cell>(SUM)</cell><cell cols="7">Time (sec.) 0.004 0.005 0.007 0.010 0.017 0.019</cell></row><row><cell>Scorpion</cell><cell>F1 Score</cell><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell><cell>0.8</cell></row><row><cell>(SUM)</cell><cell>Time (sec.)</cell><cell>0.68</cell><cell>0.82</cell><cell>1.25</cell><cell>1.93</cell><cell>2.45</cell><cell>2.93</cell></row><row><cell>RSExplain</cell><cell>F1 Score</cell><cell>0.75</cell><cell>0.75</cell><cell>0.75</cell><cell>0.75</cell><cell>0.75</cell><cell>0.75</cell></row><row><cell>(SUM)</cell><cell>Time (sec.)</cell><cell>0.68</cell><cell>0.83</cell><cell>1.25</cell><cell>1.94</cell><cell>2.44</cell><cell>2.90</cell></row><row><cell>BOExplain</cell><cell>F1 Score</cell><cell>0.8</cell><cell>0.8</cell><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell><cell>0.8</cell></row><row><cell>(SUM)</cell><cell>Time (sec.)</cell><cell>5.24</cell><cell>5.32</cell><cell>5.62</cell><cell>6.38</cell><cell cols="2">9.80 13.53</cell></row><row><cell>XPlainer</cell><cell>F1 Score</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell></row><row><cell>(AVG)</cell><cell cols="7">Time (sec.) 0.016 0.019 0.026 0.038 0.052 0.063</cell></row><row><cell>Scorpion</cell><cell>F1 Score</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell></row><row><cell>(AVG)</cell><cell>Time (sec.)</cell><cell>0.59</cell><cell>0.67</cell><cell>0.90</cell><cell>1.29</cell><cell>1.69</cell><cell>2.01</cell></row><row><cell>RSExplain</cell><cell>F1 Score</cell><cell>0.75</cell><cell>0.75</cell><cell>0.75</cell><cell>0.75</cell><cell>0.75</cell><cell>0.75</cell></row><row><cell>(AVG)</cell><cell>Time (sec.)</cell><cell>0.58</cell><cell>0.66</cell><cell>0.90</cell><cell>1.28</cell><cell>1.68</cell><cell>1.95</cell></row><row><cell>BOExplain</cell><cell>F1 Score</cell><cell>0.86</cell><cell>âœ“</cell><cell>0.86</cell><cell>âœ“</cell><cell>âœ“</cell><cell>0.8</cell></row><row><cell>(AVG)</cell><cell>Time (sec.)</cell><cell>5.33</cell><cell>5.37</cell><cell>5.56</cell><cell>6.56</cell><cell cols="2">8.67 12.62</cell></row><row><cell cols="2">Cardinality (#Rows=100k)</cell><cell>10</cell><cell>15</cell><cell>20</cell><cell>30</cell><cell>50</cell><cell>100</cell></row><row><cell>XPlainer</cell><cell>F1 Score</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>0.8</cell></row><row><cell>(SUM)</cell><cell cols="7">Time (sec.) 0.010 0.014 0.018 0.025 0.040 0.077</cell></row><row><cell>Scorpion</cell><cell>F1 Score</cell><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>(SUM)</cell><cell>Time (sec.)</cell><cell cols="4">1.96 16.50 75.72 N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>RSExplain</cell><cell>F1 Score</cell><cell>0.75</cell><cell>0.75</cell><cell>0.75</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>(SUM)</cell><cell>Time (sec.)</cell><cell cols="4">1.95 16.61 75.82 N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>BOExplain</cell><cell>F1 Score</cell><cell>âœ“</cell><cell>0.86</cell><cell>0.86</cell><cell>0.46</cell><cell>0.27</cell><cell>0.15</cell></row><row><cell>(SUM)</cell><cell>Time (sec.)</cell><cell>6.28</cell><cell cols="5">8.71 11.17 15.44 25.44 48.73</cell></row><row><cell>XPlainer</cell><cell>F1 Score</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell></row><row><cell>(AVG)</cell><cell cols="7">Time (sec.) 0.038 0.060 0.082 0.124 0.211 0.426</cell></row><row><cell>Scorpion</cell><cell>F1 Score</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>(AVG)</cell><cell>Time (sec.)</cell><cell cols="4">1.27 10.58 47.90 N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>RSExplain</cell><cell>F1 Score</cell><cell>0.75</cell><cell>0.75</cell><cell>0.75</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>(AVG)</cell><cell>Time (sec.)</cell><cell cols="4">1.28 10.59 47.91 N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>BOExplain</cell><cell>F1 Score</cell><cell>âœ“</cell><cell>0.86</cell><cell>0.5</cell><cell>0.5</cell><cell>0.27</cell><cell>0.14</cell></row><row><cell>(AVG)</cell><cell>Time (sec.)</cell><cell>5.87</cell><cell cols="5">8.23 10.44 15.00 24.35 46.35</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 that</head><label>8</label><figDesc>XPlainer delivers highly encouraging accuracy and efficiency across different settings in comparison with the baseline methods.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 .</head><label>9</label><figDesc>XPlainer and baselines with different ğœ‡ * -ğœ‡. âœ“ denotes that the result is identical to the ground truth (F1=1.0). that we craft three filters that form the counterfactual cause in each dataset. In SUM, we can craft six (</figDesc><table><row><cell>ğœ‡ -ğœ‡  *</cell><cell>5</cell><cell>10</cell><cell>15</cell><cell>30</cell><cell cols="2">50 100</cell></row><row><cell cols="3">XPlainer (SUM) 0.86 âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell></row><row><cell>Scorpion (SUM)</cell><cell cols="6">0.50 0.50 0.50 0.50 0.50 0.50</cell></row><row><cell cols="7">RSExplain (SUM) 0.75 0.75 0.75 0.75 0.75 0.75</cell></row><row><cell cols="7">BOExplain (SUM) 0.50 0.86 0.80 0.80 0.80 âœ“</cell></row><row><cell>XPlainer (AVG)</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell></row><row><cell>Scorpion (AVG)</cell><cell>0.80</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell><cell>âœ“</cell></row><row><cell cols="7">RSExplain (AVG) 0.75 0.75 0.75 0.75 0.75 0.75</cell></row><row><cell cols="2">BOExplain (AVG) 0.80</cell><cell cols="5">âœ“ 0.86 0.86 0.80 âœ“</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>select an ordered pair of adjacent nodes ğ‘‹, ğ‘Œ such that Neighbor(ğ‘‹ ) \ {ğ‘Œ } has cardinality â‰¥ ğ‘›, and a subset ğ‘º âŠ† Neighbor(ğ‘‹ ) \ {ğ‘Œ } of cardinality ğ‘›, and, if ğ‘‹ â«« ğ‘Œ | ğ‘†, delete the edge between ğ‘‹ and ğ‘Œ from ğ‘„, and record ğ‘º in Sepset(ğ‘‹, ğ‘Œ ) and Sepset(ğ‘Œ , ğ‘‹ ); 6 until all ordered pairs of adjacent nodes ğ‘‹ and ğ‘Œ such that Neighbor(ğ‘‹ ) \ {ğ‘Œ } has cardinality â‰¥ ğ‘› and all subsets ğ‘º in Neighbor(ğ‘‹ ) \ {ğ‘Œ } have been tested for d-separation; until for each ordered pair of adjacent nodes ğ‘‹, ğ‘Œ , Neighbor(ğ‘‹ ) \ {ğ‘Œ } has less than ğ‘› neighbors; 9 let ğ¹ â€² be the undirected graph from the above step and orient each edge as â€¢-â€¢; 10 foreach unshielded triple (ğ‘‹, ğ‘Œ , ğ‘ ) âˆˆ ğ¹ â€² do</figDesc><table><row><cell cols="2">Algorithm 3: FCI-SL</cell></row><row><cell></cell><cell>Input: Data ğ·</cell></row><row><cell></cell><cell>Output: Skeleton ğº</cell></row><row><cell cols="2">1 initialize a complete undirected graph ğ‘„ with ğ‘› nodes;</cell></row><row><cell cols="2">2 ğ‘› â† 0;</cell></row><row><cell cols="2">3 repeat</cell></row><row><cell>4</cell><cell>repeat</cell></row><row><cell>5</cell><cell></cell></row></table><note><p>7 ğ‘› â† ğ‘› + 1; 8 11 if ğ‘Œ is not Sepset(ğ‘‹, ğ‘ ) then 12 orient ğ‘‹ * - * ğ‘Œ * - * ğ‘ as ğ‘‹ * â†’ğ‘Œ â† * ğ‘ ;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>: eXplainable Data Analysis Through The Lens of Causality 156:31 ğ‘‹ ğ‘ â† ğ‘‹ ğ‘  â† ğ‘‹ ğ‘ where ğ‘‹ ğ‘  âˆˆ ğ‘ˆ . 2) there exists ğ‘‹ ğ‘ â†’ ğ‘‹ ğ‘  â† ğ‘‹ ğ‘ where ğ‘‹ ğ‘  or any of its descendants does not belong to ğ‘ˆ . Because ğ‘‹ 1 âˆ‰ ğ‘ˆ , ğ‘‹ 1 â‰  ğ‘‹ ğ‘  . For the first case, ğ‘‹ ğ‘  blocks ğ‘‹ 1 and ğ‘Œ given that there is only one edge connecting to ğ‘‹ 2 For the second case, ğ‘‹ 1 cannot be a collider, because ğ‘‹ 1 â†’ ğ‘‹ 2 . Therefore, ğ‘ˆ also blocks ğ‘‹ 1 and ğ‘Œ on this path. In summary, ğ‘‹ 1 â«« G ğ‘Œ | ğ‘ˆ . â–¡With above lemmas, now we prove Thm. 3.1.</figDesc><table /><note><p><p>) Therefore, ğ‘ â«« ğ‘Œ | ğ‘‹ . â–¡ Lemma 8.3.2. If ğ‘‹ FD --â†’ ğ‘Œ and ğ‘ â«« ğ‘‹ | ğ‘Š , then ğ‘ â«« ğ‘Œ | ğ‘Š , where ğ‘ and ğ‘Š are two disjoint variable set other than ğ‘‹ and ğ‘Œ .</p>XInsight</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>According to Lemma. 8.3.2, ğ‘‹ 1 FD --â†’ ğ‘ and ğ‘‹ 1 â«« ğ‘‹ ğ‘— | ğ‘ˆ imply ğ‘ â«« ğ‘‹ ğ‘— | ğ‘ˆ . Minimality is satisfied, since removing edge from ğ‘‹ 1 to ğ‘ will make ğ‘‹ 1 â«« ğ‘ which contradicts ğ‘ƒ ğ‘‰ . â–¡ 8.4 Proof of Thm. 3.2</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Î”</head><label></label><figDesc>ğ‘ ğ‘– ğ‘ ğ‘– = ğ‘ƒ (ğ¹ =ğ‘“ 1 |ğ‘©=ğ’ƒ ) ğ‘ƒ (ğ¹ =ğ‘“ 2 |ğ‘©=ğ’ƒ ) which is a constant and invariant with respect to ğ‘–. â–¡ Proposition 8.2. If ğ‘ƒ 1 and ğ‘ƒ 2 are two disjoint predicates on the same attribute, for homogeneous AVG, Î”(ğ· ğ‘ƒ 1+ ğ· ğ‘ƒ 2 ) &lt; Î”(ğ· ğ‘ƒ 1 ) + Î”(ğ· ğ‘ƒ 2 ). Proof. For homogeneous AVG, Î”(ğ· ğ‘ƒ 1 ) = ğ‘ ğ‘– âˆˆğ‘ƒ 1 ğ‘ ğ‘– Î” ğ‘– ğ´ ğ‘ƒ 1 , Î”(ğ· ğ‘ƒ 2 ) = ğ‘ ğ‘– âˆˆğ‘ƒ 2 ğ‘ ğ‘– Î” ğ‘– ğ´ ğ‘ƒ 2 and Î”(ğ· ğ‘ƒ 1 + ğ· ğ‘ƒ 2 ) = ğ‘ ğ‘– âˆˆğ‘ƒ 1 âˆªğ‘ƒ 2 ğ‘ ğ‘– Î” ğ‘– ğ´ ğ‘ƒ 1 âˆªğ‘ƒ 2 . Also, ğ´ ğ‘ƒ 1 âˆªğ‘ƒ 2 = ğ´ ğ‘ƒ 1 + ğ´ ğ‘ƒ 2 . Hence, ğ´ ğ‘ƒ 1 &lt; ğ´ ğ‘ƒ 1 âˆªğ‘ƒ 2 and ğ´ ğ‘ƒ 2 &lt; ğ´ ğ‘ƒ 1 âˆªğ‘ƒ 2 . Therefore, Î”(ğ· ğ‘ƒ 1 ) + Î”(ğ· ğ‘ƒ 2 ) = ğ‘ ğ‘– âˆˆğ‘ƒ 1 ğ‘ ğ‘– Î” ğ‘– ğ´ ğ‘ƒ 1 + ğ‘ ğ‘– âˆˆğ‘ƒ 2 ğ‘ ğ‘– Î” ğ‘– ğ´ ğ‘ƒ 2 &gt; ğ‘ ğ‘– âˆˆğ‘ƒ 1 ğ‘ ğ‘– Î” ğ‘– ğ´ ğ‘ƒ 1 âˆªğ‘ƒ 2 + ğ‘ ğ‘– âˆˆğ‘ƒ 2 ğ‘ ğ‘– Î” ğ‘– ğ´ ğ‘ƒ 1 âˆªğ‘ƒ 2 = ğ‘ ğ‘– âˆˆğ‘ƒ 1 âˆªğ‘ƒ 2 ğ‘ ğ‘– Î” ğ‘– ğ´ ğ‘ƒ 1 âˆªğ‘ƒ 2 = Î”(ğ· ğ‘ƒ 1 + ğ· ğ‘ƒ 2 ) ğ· ğ‘ƒ -ğ· ğ‘ ğ‘— = ğ‘ ğ‘– âˆˆğ‘ƒ ğ‘ ğ‘– Î” ğ‘– -ğ‘ ğ‘— Î” ğ‘— ğ´ ğ· -ğ‘ ğ‘— = ğ‘ ğ‘– âˆˆğ‘ƒ ğ‘ ğ‘– Î” ğ‘– -ğ‘ ğ‘— Î” ğ‘— ğ´ ğ· -ğ‘ ğ‘— &lt; ğ‘ ğ‘– âˆˆğ‘ƒ ğ‘ ğ‘– Î” ğ‘– ğ´ ğ· = Î” ğ· ğ‘ƒ</figDesc><table><row><cell>(16)</cell></row><row><cell>â–¡</cell></row><row><cell>Now, we prove Proposition 3.4.</cell></row><row><cell>Proof.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proc. ACM Manag. Data, Vol. 1, No. 2, Article 156. Publication date: June 2023.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>The correctness of XTranslator has been rigorously discussed in Sec. 3.2. Proc. ACM Manag. Data, Vol. 1, No.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>2, Article 156. Publication date: June 2023.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>* denotes a wildcard endpoint; either -(tail), â†’ (arrowhead) or â€¢-(circle) can be matched. Proc. ACM Manag. Data, Vol. 1, No. 2, Article 156. Publication date: June 2023.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_4"><p>" * " is used as a wildcard symbol accepting either â†’, â†”, â€¢â†’. Proc. ACM Manag. Data, Vol. 1, No. 2, Article 156. Publication date: June 2023.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank the anonymous reviewers for their valuable comments and suggestions. The author would also like to thank <rs type="person">Siwen Zhu</rs>, <rs type="person">Haidong Zhang</rs>, <rs type="person">Zhitao Hou</rs>, <rs type="person">Ruming Wang</rs>, <rs type="person">Ziyu Wang</rs>, <rs type="person">Long Ding</rs>, <rs type="person">Kai Zhang</rs>, <rs type="person">Jon Kay</rs>, and <rs type="person">Dingkun Xie</rs> for helpful discussions and all our participants in the user study for their valuable feedback. The authors at HKUST were supported in part by <rs type="funder">RGC RMGS</rs> under the contract <rs type="grantNumber">RMGS22EG02</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_BVh7CQQ">
					<idno type="grant-number">RMGS22EG02</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">SUPPLEMENTARY MATERIAL</head><p>8.1 Fast Causal Inference (FCI) Algorithm <ref type="bibr" target="#b48">[51,</ref><ref type="bibr" target="#b54">57]</ref> We first introduce concepts and notations in addition to the one described in Sec. 2.2. Then, we outline the FCI algorithm in Alg. 3 and Alg. 4. Definition 8.1 (Unshielded Triple). In a graph, a triple (ğ‘‹, ğ‘Œ , ğ‘ ) is an unshielded triple if ğ‘‹ and ğ‘ are non-adjacent, ğ‘‹ and ğ‘ are adjacent, and ğ‘Œ and ğ‘ are adjacent. Definition 8.2 (Possible-D-SEP). In a graph, Possible-D-SEP(ğ‘‹, ğ‘Œ ) is the set of nodes ğ‘ such that there is an undirected path P between ğ‘‹ and ğ‘ and for each subpath ğ‘† * - * ğ‘Š * - * ğ‘‡ of P one of the following conditions holds. 2   (1) ğ‘Š is a collider; or, (2) ğ‘Š is not marked as a non-collider and ğ‘†,ğ‘Š ,ğ‘‡ are a triangle. (A triangle is a set of three nodes all adjacent to one another). (2) ğ‘‰ is a non-endpoint node on P, and is adjacent to ğ‘Œ on P; and (3) ğ‘‹ is not adjacent to ğ‘Œ , and every node between ğ‘‹ and ğ‘‰ is a collider on P and is a parent of ğ‘Œ . Definition 8.5 (Uncovered Path). In a PMG (partial mixed graph), a path P = (ğ‘‰ 0 , â€¢ â€¢ â€¢ , ğ‘‰ ğ‘› ) is said to be uncovered if for every 1 â‰¤ ğ‘– â‰¤ ğ‘› -1, ğ‘‰ ğ‘– -1 and ğ‘‰ ğ‘–+1 are not adjacent, i.e., if every consecutive triple on the path is unshielded. Definition 8.6 (Potentially Directed Path). In a PMG (partial mixed graph), a path P = (ğ‘‰ 0 , â€¢ â€¢ â€¢ , ğ‘‰ ğ‘› ) is said to be potentially directed (abbreviated as p.d.) from ğ‘‰ 0 to ğ‘‰ ğ‘› if for every 0 â‰¤ ğ‘– â‰¤ ğ‘›-1, the edge between ğ‘‰ ğ‘– and ğ‘‰ ğ‘–+1 is not into ğ‘‰ ğ‘– or out of ğ‘‰ ğ‘–+1 . Definition 8.7 (Circle Path). In a PMG (partial mixed graph), a circle path P = (ğ‘‰ 0 , â€¢ â€¢ â€¢ , ğ‘‰ ğ‘› ) is a special case of p.d. path, where each edge on P is â€¢-â€¢.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Principle of Explainability under AVG and SUM</head><p>In AVG, we notice that</p><p>In SUM, we notice that SUM = COUNT Ã— AVG and COUNT ğ‘€ (ğ‘  1 ) = ğ‘ Ã— ğ‘ƒ (ğ¹ = ğ‘“ 1 ), COUNT ğ‘€ (ğ‘  2 ) = ğ‘ Ã— ğ‘ƒ (ğ¹ = ğ‘“ 2 ), where ğ‘ is a constant indicating the number of rows in the data. Then,   Proof. Suppose there exists an optimal explanation ğ‘ƒ * such that âˆƒğ‘ ğ‘– âˆˆ ğ‘ƒ * , Î” ğ‘– â‰¤ 0. Let ğ‘ƒ â€² = {ğ‘ | ğ‘ âˆˆ ğ‘ƒ * , Î” ğ‘ &gt; 0} and Î“ be the minimal contingency of ğ‘ƒ * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Proof of</head><p>For SUM, since Î”(ğ·</p><p>For homogeneous AVG,</p><p>Hence, Î“ is also a valid contingency for ğ‘ƒ â€² . ğœŒ ğ‘ƒ â€² â‰¥ ğœŒ ğ‘ƒ * and |ğ‘ƒ â€² | &lt; |ğ‘ƒ * | contradict the fact that ğ‘ƒ * is optimal. â–¡ 8.8 Proof of Proposition 3.3 Proof. When there are more than one optimal explanations, let ğ‘ƒ â€² be the one with the smallest predicate size (i.e., |ğ‘ƒ |) and Î“ â€² be the corresponding minimal contingency. Otherwise, let ğ‘ƒ â€² and Î“ â€² be the optimal explanation and corresponding minimal contingency, respectively.</p><p>then let ğ‘ƒ â€²â€² be a predicate by replacing all non-canonical filters in ğ‘ƒ â€² with canonical ones. Then,</p><p>at least as optimal as ğ‘ƒ â€² . In summary, there must exist an optimal explanation ğ‘ƒ â€²â€² âŠ† ğ‘ƒ ğ¶ . â–¡ 8.9 Proof of Thm. 3.3 Proof. Let ğ‘š ğ‘˜ = ğ‘˜ ğ‘–=1 ğ‘‘ ğ‘ ğ‘– . According to the definition of canonical predicate, 1 -</p><p>-ğ‘‘ ğ‘ƒ -ğœ– â€² . Thus, we derive the lower and upper bounds of ğœŒ ğ‘ƒ . When assuming ğ‘‘ ğ‘ƒ â‰ª ğ‘š ğ‘— and </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Diff: a relational interface for large-scale data explanation</title>
		<author>
			<persName><forename type="first">Firas</forename><surname>Abuzaid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="70" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the completeness of causal discovery in the presence of latent confounding with tiered background knowledge</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<idno>PMLR. 2020</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="page" from="4002" to="4011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hotel booking demand datasets</title>
		<author>
			<persName><forename type="first">Nuno</forename><surname>Antonio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana</forename><surname>De Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Nunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data in brief</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="41" to="49" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Macrobase: Prioritizing attention in fast data</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bailis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data</title>
		<meeting>the 2017 ACM International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="541" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Controlling selection bias in causal inference</title>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<idno>PMLR. 2012</idno>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="page" from="100" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Score-Based Explanations in Data Management and Machine Learning</title>
		<author>
			<persName><forename type="first">Leopoldo</forename><surname>Bertossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Scalable Uncertainty Management</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="17" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Causality-based explanation of classification outcomes</title>
		<author>
			<persName><forename type="first">Leopoldo</forename><surname>Bertossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Workshop on Data Management for End-to-End Machine Learning</title>
		<meeting>the Fourth International Workshop on Data Management for End-to-End Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Michael</forename><surname>Buckland</surname></persName>
		</author>
		<title level="m">Information and society</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">TSExplain: Surfacing Evolving Explanations for Time Series</title>
		<author>
			<persName><forename type="first">Yiru</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silu</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 International Conference on Management of Data</title>
		<meeting>the 2021 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2686" to="2690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">ML4C: Seeing Causality Through Latent Vicinity</title>
		<author>
			<persName><forename type="first">Haoyue</forename><surname>Dai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.00637</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Quickinsights: Quick and automatic discovery of insights from multidimensional data</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data</title>
		<meeting>the 2019 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="317" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Reliable and Efficient Anytime Skeleton Learning</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="10101" to="10109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<ptr target="https://help.tableau.com/current/pro/desktop/en-us/explain_data.htm.2022" />
	</analytic>
	<monogr>
		<title level="j">Discover Insights Faster with Explain Data</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Causality-guided adaptive interventional debugging</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Fariha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suman</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Meliou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2020 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="431" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Complaint-Driven Training Data Debugging at Interactive Speeds</title>
		<author>
			<persName><forename type="first">Lampros</forename><surname>Flokas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 International Conference on Management of Data</title>
		<meeting>the 2022 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="369" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Explaining black-box algorithms using probabilistic contrastive counterfactuals</title>
		<author>
			<persName><forename type="first">Sainyam</forename><surname>Galhotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Romila</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Salimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 International Conference on Management of Data</title>
		<meeting>the 2021 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="577" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Trends in Explanations: Understanding and Debugging Data-driven Systems</title>
		<author>
			<persName><forename type="first">Boris</forename><surname>Glavic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Meliou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudeepa</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and TrendsÂ® in Databases</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="226" to="318" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Actual causality</title>
		<author>
			<persName><surname>Joseph Y Halpern</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Causes and explanations: A structural-model approach. Part I: Causes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The British journal for the philosophy of science</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="843" to="887" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">PerfCE: Performance Debugging on Databases with Chaos Engineering-Enhanced Causality Analysis</title>
		<author>
			<persName><forename type="first">Zhenlan</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pingchuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.08369</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Explanation and understanding</title>
		<author>
			<persName><forename type="first">Keil</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Psychol</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="227" to="254" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Marc</forename><surname>Lange</surname></persName>
		</author>
		<title level="m">Because Without Cause: Non-Casual Explanations In Science and Mathematics</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Causal Perception in Question-Answering Systems</title>
		<author>
			<persName><forename type="first">Po-Ming</forename><surname>Law</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2021 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Putting Things into Context: Rich Explanations for Query Answers using Join Graphs (extended version)</title>
		<author>
			<persName><forename type="first">Chenjie</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.15797</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Training data debugging for the fairness of machine learning software</title>
		<author>
			<persName><forename type="first">Yanhui</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International Conference on Software Engineering</title>
		<meeting>the 44th International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2215" to="2227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Measuring the Effect of Training Data on Deep Learning Predictions via Randomized Experiments</title>
		<author>
			<persName><forename type="first">Jinkun</forename><surname>Lin</surname></persName>
		</author>
		<idno>PMLR. 2022</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="13468" to="13504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Explaining inference queries with bayesian optimization</title>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Lockhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="2576" to="2585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">MetaInsight: Automatic Discovery of Structured Knowledge for Exploratory Data Analysis</title>
		<author>
			<persName><forename type="first">Pingchuan</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 International Conference on Management of Data</title>
		<meeting>the 2021 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1262" to="1274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">ML4S: Learning Causal Skeleton from Vicinal Graphs</title>
		<author>
			<persName><forename type="first">Pingchuan</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An efficient Bayesian network structure learning algorithm in the presence of deterministic relations</title>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Mabrouk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECAI 2014</title>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="567" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Causality and explanations in databases</title>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Meliou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudeepa</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1715" to="1716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Causality in databases</title>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Meliou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Engineering Bulletin</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="59" to="67" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>ARTI-CLE</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The complexity of causality and responsibility for query answers and non-answers</title>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Meliou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="34" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tracing data errors with view-conditioned causality</title>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Meliou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 ACM SIGMOD International Conference on Management of data</title>
		<meeting>the 2011 ACM SIGMOD International Conference on Management of data</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="505" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Going beyond provenance: Explaining query answers with patternbased counterbalances</title>
		<author>
			<persName><forename type="first">Zhengjie</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data</title>
		<meeting>the 2019 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="485" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Use the Analyze feature to explain fluctuations in report visuals</title>
		<ptr target="https://learn.microsoft.com/en-us/power-bi/consumer/end-user-analyze-visuals.2022" />
		<imprint>
			<publisher>Microsoft</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Automating exploratory data analysis via machine learning: An overview</title>
		<author>
			<persName><forename type="first">Tova</forename><surname>Milo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Somech</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2020 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2617" to="2622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The role of theories in conceptual coherence</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><surname>Medin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page">289</biblScope>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Causal inference in statistics: An overview</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics Surveys</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="96" to="146" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Causal inference on discrete data using additive noise models</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Scholkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2436" to="2450" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Elements of causal inference: foundations and learning algorithms</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Artificial Intelligence: foundations of computational agents</title>
		<author>
			<persName><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">K</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><surname>Mackworth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Povich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><forename type="middle">F</forename><surname>Craver</surname></persName>
		</author>
		<title level="m">Because without Cause: Non-Causal Explanations in Science and Mathematics</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Explainable AI: Foundations, Applications, Opportunities for Data Management Research</title>
		<author>
			<persName><forename type="first">Romila</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 International Conference on Management of Data</title>
		<meeting>the 2022 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2452" to="2457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A formal approach to finding explanations for database queries</title>
		<author>
			<persName><forename type="first">Sudeepa</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2014 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1579" to="1590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Causal relational learning</title>
		<author>
			<persName><forename type="first">Babak</forename><surname>Salimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2020 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="241" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Zaliql: causal inference from observational data at scale</title>
		<author>
			<persName><forename type="first">Babak</forename><surname>Salimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1957" to="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A qualitative approach to causal modeling</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Qualitative simulation modeling and analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="72" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Causation, prediction, and search</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Constraint-based causal discovery from multiple interventions over overlapping variable sets</title>
		<author>
			<persName><forename type="first">Sofia</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Tsamardinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2147" to="2205" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Local explanations via necessity and sufficiency: Unifying theory and practice</title>
		<author>
			<persName><surname>David S Watson</surname></persName>
		</author>
		<idno>PMLR. 2021</idno>
	</analytic>
	<monogr>
		<title level="j">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1382" to="1392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Scorpion: Explaining Away Outliers in Aggregate Queries</title>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Madden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the VLDB Endowment</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Complaint-driven training data debugging for query 2.0</title>
		<author>
			<persName><forename type="first">Weiyuan</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2020 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1317" to="1334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Dbsherlock: A performance diagnostic tool for transactional databases</title>
		<author>
			<persName><forename type="first">Dong</forename><surname>Young Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barzan</forename><surname>Mozafari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Conference on Management of Data</title>
		<meeting>the 2016 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1599" to="1614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">On the completeness of orientation rules for causal discovery in the presence of latent confounders and selection bias</title>
		<author>
			<persName><forename type="first">Jiji</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="1873" to="1896" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A statistical perspective on discovering functional dependencies in noisy data</title>
		<author>
			<persName><forename type="first">Yunjia</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theodoros</forename><surname>Rekatsinas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2020 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="861" to="876" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
