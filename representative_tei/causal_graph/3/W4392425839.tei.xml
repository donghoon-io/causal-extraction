<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent Dynamical Systems</title>
				<funder ref="#_f6PFUdv #_WS7zJp8 #_eakQFNd #_m2sSWUN #_s7G9me7 #_xrngHGh #_ECkzE7m #_qadxYCy">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_rMFRs2g">
					<orgName type="full">NASA</orgName>
				</funder>
				<funder>
					<orgName type="full">NEC</orgName>
				</funder>
				<funder>
					<orgName type="full">Cisco</orgName>
				</funder>
				<funder>
					<orgName type="full">Center</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-02-29">29 Feb 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zijie</forename><surname>Huang</surname></persName>
							<email>zijiehuang@cs.ucla.edu</email>
						</author>
						<author>
							<persName><forename type="first">Jeehyun</forename><surname>Hwang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Junkai</forename><surname>Zhang</surname></persName>
							<email>jkzhang@g.ucla.edu</email>
						</author>
						<author>
							<persName><forename type="first">Jinwoo</forename><surname>Baik</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Weitong</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dominik</forename><surname>Wodarz</surname></persName>
							<email>dwodarz@ucsd.edu</email>
						</author>
						<author>
							<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
							<email>yzsun@cs.ucla.edu</email>
						</author>
						<author>
							<persName><forename type="first">Quanquan</forename><surname>Gu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
							<email>weiwang@cs.ucla.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Department of Ecology, Behavior &amp; Evolution</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>San Diego San Diego</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent Dynamical Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-02-29">29 Feb 2024</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3589334.3648148</idno>
					<idno type="arXiv">arXiv:2403.00178v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Dynamical System</term>
					<term>Neural ODE</term>
					<term>Causal Inference</term>
					<term>Graph Neural Networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Real-world multi-agent systems are often dynamic and continuous, where the agents co-evolve and undergo changes in their trajectories and interactions over time. For example, the COVID-19 transmission in the U.S. can be viewed as a multi-agent system, where states act as agents and daily population movements between them are interactions. Estimating the counterfactual outcomes in such systems enables accurate future predictions and effective decisionmaking, such as formulating COVID-19 policies. However, existing methods fail to model the continuous dynamic effects of treatments on the outcome, especially when multiple treatments (e.g., "stayat-home" and "get-vaccine" policies) are applied simultaneously. To tackle this challenge, we propose Causal Graph Ordinary Differential Equations (CAG-ODE), a novel model that captures the continuous interaction among agents using a Graph Neural Network (GNN) as the ODE function. The key innovation of our model is to learn time-dependent representations of treatments and incorporate them into the ODE function, enabling precise predictions of potential outcomes. To mitigate confounding bias, we further propose two domain adversarial learning-based objectives, which enable our model to learn balanced continuous representations that are not affected by treatments or interference. Experiments on * Equally contributed. â€  Corresponding author.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Many real-world multi-agent systems are dynamic and continuous, where agents (nodes) interact and exhibit complex behaviors over time. This results in time-evolving node trajectories and dynamic interaction edges. An example is the spread of COVID-19 in the U.S., where states act as agents and daily migration patterns across states form interaction edges <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b28">29]</ref>. Estimating the counterfactual outcomes over time in such systems are crucial for various applications, such as formulating effective policies and designing medical treatment plans <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b39">40]</ref>. This can achieve more accurate predictions than non-causal methods by considering the influence of biased confounders. Confounders are variables that have influences on treatments and outcomes. For example, the health status of the residents in each state (confounders) can impact their level of adherence to the state's policies (treatments), which can influence future confirmed cases/deaths (outcomes). Non-causal methods only learn the statistical associations between treatments and outcomes from observational data, which can have non-uniform treatment distributions across confounder values, potentially leading to incorrect predictions such as taking vaccines can increase the number of confirmed cases for each state. Furthermore, causal inference for multi-agent dynamical systems enables effective decision-making by addressing causal questions such as "What if we remove a policy at a specific time" or "What if we change the order of different policies". Therefore, it serves as a promising tool for policymakers.</p><p>Traditionally, the standard approach for causal inference over time is randomized controlled trials (RCTs) <ref type="bibr" target="#b4">[5]</ref>, which can be very costly to obtain and can raise some ethical problems <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b39">40]</ref>. Thus, researchers have turned to using observational data and employed methods like linear regression <ref type="bibr" target="#b34">[35]</ref>, recurrent neural networks (RNNs) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b24">25]</ref>, and Transformers <ref type="bibr" target="#b30">[31]</ref> to estimate counterfactual outcomes with time dependencies. However, causal inference for multi-agent dynamical systems presents unique challenges.</p><p>One is that most existing methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b39">40]</ref> assume that nodes are independent, meaning their trajectories are determined solely by their own treatments. Some <ref type="bibr" target="#b17">[18]</ref> considers the influence of neighboring nodes but only assumes static interactions among them, which fails to capture situations such as daily population travel patterns between states in the context of COVID- <ref type="bibr">19.</ref> In casual terms, influences of neighboring nodes can be categorized into two parts: 1.) time-dependent neighborhood confounding, where a node's treatment and outcome may be confounded by the covariates of its neighbors. For example, if cases in neighboring states rise (covariate), a state may implement a vaccine policy (treatment) that affects future confirmed cases/deaths (outcome). 2.) time-dependent interference, where the outcome of a node can be influenced by the treatments of its neighbors. For example, a state may have reduced future cases/deaths (outcome) if neighboring states have implemented a vaccine policy (covariates), as higher vaccination rates within the population flow network give stronger protection. As the interaction edges evolve along with node trajectories, the challenges lie in predicting the neighbors of each node (edges) and then addressing the time-dependent neighborhood confounding and interference issues.</p><p>Another challenge is that current methods lack the ability to capture the continuous and dynamic effects of multiple treatments on such systems. For instance, the impact of a "stay-at-home" policy may be most significant during its initial implementation, and when a "get-vaccine" policy is subsequently introduced, the combined effect of these policies can result in a different outcome. Existing studies often focus on a single treatment <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b39">40]</ref> or simply append fixed multi-hot treatment representations when a node receives them. These fixed treatment representations fail to differentiate the influences of the same treatment administered at different times.</p><p>To tackle these challenges, we propose a novel causal inference framework: the Causal Graph Ordinary Differential Equations (CAG-ODE) to estimate the continuous counterfactual outcome of a multi-agent dynamical system in the presence of multiple treatments and time-varying confounding and interference. Building upon the recent success of graph ordinary differential equations (ODE) in capturing the continuous interaction among agents <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b26">27]</ref>, our key innovation is to learn time-dependent representations of simultaneous treatments and incorporate them into the ODE function to accurately account for their casual effects on the system. As nodes and edges are jointly evolving, we utilize two coupled treatment-induced ODE functions to account for their respective dynamics. To mitigate confounding bias, we further design two adversarial learning losses, which enable our model to learn balanced continuous trajectory representations unaffected by treatments or interference. Experiments on both real and simulated datasets demonstrate the effectiveness of our proposed model. The primary contributions of this paper can be summarized as follows:</p><p>â€¢ We propose CAG-ODE to estimate continuous counterfactual outcomes in multi-agent systems with evolving interaction edges and multiple treatments. â€¢ CAG-ODE features a novel treatment fusing module that can capture the dynamic effects of treatment over time and the combined effect of multiple treatments. â€¢ Our method achieves the state-of-art results in counterfactual estimation across varying systems, and can serve as a promising tool for policymakers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES AND RELATED WORK 2.1 Graph Neural Networks (GNNs)</head><p>Graph Neural Networks (GNNs) are a class of neural networks that operate on graph-structured data by passing local messages <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref>. They have been extensively employed in various applications such as node classification, link prediction, and recommendation systems <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b15">16]</ref>. GNNs have shown to be efficient for approximating pair-wise node interactions and achieved accurate predictions for multi-agent dynamical systems <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b37">38]</ref>. The majority of existing studies propose discrete GNN-based simulators where they take the node features at time ğ‘¡ as input to predict the node features at time ğ‘¡+1. To further capture the long-term temporal dependency for predicting future trajectories, some work utilizes recurrent neural networks such as RNN, LSTM, or self-attention mechanism to make predictions at time ğ‘¡ +1 based on the historical trajectory sequence <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b38">39]</ref>. However, they restrict themselves to learning a one-step state transition function. Therefore, when we successively apply these one-step simulators to previous predictions in order to generate the rollout trajectories, error accumulates and impairs the prediction accuracy, especially for long-range prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Ordinary Differential Equations for Continuous Multi-agent Dynamical Systems</head><p>The dynamics of a multi-agent system can be captured by a series of nonlinear first-order ordinary differential equations (ODEs) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b35">36]</ref>, which describe how the states of ğ‘ dependent variables co-evolve over continuous time:</p><formula xml:id="formula_0">ğ’› ğ‘¡ ğ‘– := ğ‘‘ğ’› ğ‘¡ ğ‘– ğ‘‘ğ‘¡ = ğ‘” ğ’› ğ‘¡ 1 , ğ’› ğ‘¡ 2 â€¢ â€¢ â€¢ ğ’› ğ‘¡ ğ‘ .</formula><p>Here ğ’› ğ‘¡ ğ‘– âˆˆ R ğ‘‘ denotes the state variable for agent ğ‘– at timestamp ğ‘¡ and ğ‘” denotes the ODE function that drives the system to move forward. Given the initial states ğ’› 0 1 , â€¢ â€¢ â€¢ ğ’› 0 ğ‘ for all agents and the ODE function ğ‘”, a numerical ODE solver such as Runge-Kutta <ref type="bibr" target="#b31">[32]</ref> can be used to evaluate ğ’› ğ‘‡ ğ‘– at any desired time ğ‘‡ using Eqn (1):</p><formula xml:id="formula_1">ğ’› ğ‘‡ ğ‘– = ğ’› 0 ğ‘– + âˆ« ğ‘‡ ğ‘¡ =0 ğ‘” ğ’› ğ‘¡ 1 , ğ’› ğ‘¡ 2 â€¢ â€¢ â€¢ ğ’› ğ‘¡ ğ‘ dğ‘¡ .<label>(1)</label></formula><p>To model the interactions among agents, recent studies <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b43">44]</ref> propose using a GNN as the ODE function ğ‘” which is learned from observational data. Such GraphODE framework follows an encoder-processor-decoder architecture. The encoder computes latent initial states for all agents based on historical observations. The GNN-based ODE function then predicts the latent trajectories starting from the learned initial states. Finally, a decoder extracts the predicted dynamic features. To regularize the generated trajectories, GraphODE frameworks often adopt a variational autoencoder (VAE) structure <ref type="bibr" target="#b20">[21]</ref>, where the encoder samples initial states from approximated posterior distributions. GraphODEs are promising in making long-range predictions and can handle irregularly-sampled observations effectively <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b43">44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Causal Inference Over Time</head><p>Time-dependent causal inference methods mainly differ in how they deal with confounding. They differ from traditional statistical time series analysis <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b44">45]</ref> which we do not discuss in this paper. Traditionally, many statistical tools that are applied, such as marginal structural models (MSMs) <ref type="bibr" target="#b34">[35]</ref> utilize the inverse probability of treatment weighting (IPTW). Recently, representation learning-based balancing approaches are proposed, which learn representations that are not predictable of the treatments to ensure unbiased outcome prediction <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b30">31]</ref>. However, one major limitation is that they are discrete methods, which can offer poor performance on continuous systems such as the spread of COVID-19. There are a series of works <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b39">40]</ref> that estimate the continuous counterfactual outcomes through neural ODEs or neural controlled differential equations (CDEs). Despite their success, they assume that nodes are independent of each other, regardless of their interactions. One recent work <ref type="bibr" target="#b17">[18]</ref> proposed to parameterize the ODE function with a GNN for multi-agent settings. However, this model cannot handle evolving graph structures and the effect of multiple treatments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM DEFINITION</head><p>We consider a dynamical system of ğ‘ agents as an evolving interaction graph</p><formula xml:id="formula_2">G ğ‘¡ = {V, E ğ‘¡ }, where nodes V = {ğ‘£ 1 , ğ‘£ 2 , â€¢ â€¢ â€¢ , ğ‘£ ğ‘ } are</formula><p>agents and E ğ‘¡ are the weighted edges among them, denoting agents' dynamic interaction that changes over time. Each node is associated with time-varying causal characteristics, which we introduce in the following along with the casual inference framework. We follow the longitudinal causal inference setting for predicting future potential outcomes as in <ref type="bibr" target="#b36">[37]</ref>. We denote the observational data at timestamp ğ‘¡ as (X ğ‘¡ , W ğ‘¡ , A ğ‘¡ , Y ğ‘¡ ), where X ğ‘¡ âˆˆ R ğ‘ Ã—ğ‘‘ 1 represents the time-varying covariates (e.g., the health status of residents) of ğ‘ agents. W ğ‘¡ âˆˆ R ğ‘ Ã—ğ‘ represents the weighted adjacency matrix, whose element ğ‘¤ ğ‘–â†’ğ‘— âˆˆ R is the weight of the directed edge that points from node ğ‘– to node ğ‘— and may be asymmetric. A ğ‘¡ âˆˆ {0, 1} ğ‘ Ã—ğ¾ are time-dependent treatments, where A ğ‘¡ ğ‘˜ ğ‘— = 1 denotes the ğ‘˜ ğ‘¡â„ treatment assigned to node ğ‘– at timestamp ğ‘¡, and ğ¾ is the number of heterogeneous treatments. Y ğ‘¡ âˆˆ R ğ‘ Ã—ğ‘‘<ref type="foot" target="#foot_1">foot_1</ref> is the timedependent outcome, such as the number of confirmed cases in each state, which can be part of X ğ‘¡ . The historical observations up to time</p><formula xml:id="formula_3">ğ‘¡ is represented as H ğ‘¡ = X ğ‘¡ , W ğ‘¡ , A ğ‘¡ , Y ğ‘¡ , where X ğ‘¡ , W ğ‘¡ , A ğ‘¡ , Y ğ‘¡ contain all X ğ‘¡ - , W ğ‘¡ - , A ğ‘¡ - , Y ğ‘¡ -(ğ‘¡ -â‰¤ ğ‘¡).</formula><p>We aim to predict the unbiased potential outcomes E Y ğ‘¡ + A ğ‘¡ + = ğ‘ |H ğ‘¡ under any treatment assignment ğ‘ 2 . Here, ğ‘ is the dynamic treatment trajectory (e.g. sequences of state policies). As only one of the potential outcome trajectories is observed for each treatment assignment, we refer to the unobserved potential outcomes as counterfactuals <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b39">40]</ref>.</p><p>To make potential outcomes identifiable from observational data, we follow three standard assumptions <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b39">40]</ref> below:</p><p>Assumption 1: Consistency. The potential outcome is equal to the observed factual outcome if</p><formula xml:id="formula_4">A ğ‘¡ = ğ‘ ğ‘¡ : Y ğ‘¡ + (A ğ‘¡ = ğ‘ ğ‘¡ ) = Y ğ‘¡ +</formula><p>. Assumption 2: Overlap. At any time point ğ‘¡ + , there is some positive probability of treatment assignment regardless of the historical observation: 0</p><formula xml:id="formula_5">&lt; ğ‘ƒ (A ğ‘¡ + = ğ‘ | H ğ‘¡ ) &lt; 1, âˆ€H ğ‘¡ , ğ‘¡ &lt; ğ‘¡ + .</formula><p>The last assumption defines unconfoundedness (strong ignorability) in dynamical systems. We first define the interference effects caused by neighbors' treatments of node ğ‘– as</p><formula xml:id="formula_6">G ğ‘¡ ğ‘– = ğ‘— âˆˆ N ğ‘– 1 |ğ‘ ğ‘– | A ğ‘¡ ğ‘— âˆˆ R ğ¾ ,</formula><p>which is the proportion of treated nodes in node ğ‘–'s neighbors for each treatment type. We refer to G ğ‘¡ ğ‘– as interference summary, which assumes that a node is only influenced by treatments of its immediate neighbors as in previous studies <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>Assumption 3: Strong Ignorability for Multi-Agent Dynamical Systems. Given the historical observations, the potential outcome trajectory is independent of the treatments and interference summary:</p><formula xml:id="formula_7">Y ğ‘¡ + (A ğ‘¡ = ğ‘) âŠ¥ A ğ‘¡ + , G ğ‘¡ + | H ğ‘¡ , âˆ€ğ‘, ğ‘¡.</formula><p>It ensures that it is sufficient to only condition on the historical observations and graph sequences up to ğ‘¡ to block all backdoor paths so as to estimate the potential outcome in the future. With these three assumptions, the potential outcome trajectory can be identified as:</p><formula xml:id="formula_8">E Y ğ‘¡ + (A ğ‘¡ = ğ‘) | H ğ‘¡ = E Y ğ‘¡ + | A ğ‘¡ + , G ğ‘¡ + , H ğ‘¡ .</formula><p>This enables us to estimate the potential outcomes by training a machine learning model using observational data, and to use the same model to predict counterfactual outcomes given new treatment trajectories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE PROPOSED MODEL: CAG-ODE</head><p>In this section, we present Causal Graph ODE (CAG-ODE) to predict continuous counterfactual outcomes for multi-agent dynamical systems with evolving interaction edges and dynamic multi-treatment effects. Following the framework of GraphODEs <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b43">44]</ref>, CAG-ODE adopts the encoder-ODE generative model-decoder architecture described in Sec. 2.2 to capture the continuous interaction among agents. As nodes and edges are jointly evolving, we utilize two coupled ODE functions <ref type="bibr" target="#b13">[14]</ref> for the evolution of nodes and edges respectively. Contrary to GraphODEs, CAG-ODE can perform causal reasoning by injecting treatment effects into the ODE functions, which we call treatment-induced coupled graph ODE. The multi-treatment effects are captured by a novel treatment fusing module that assigns temporal weights to the treatments using an</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Treatments</head><p>Treatment Fusing </p><formula xml:id="formula_9">1 2 K â€¦â€¦ Z t = Z 0 + âˆ« t Ï„=0 GNN(Z Ï„ , A Ï„ , W Ï„ )dÏ„ W Ï„ = f edge (Z Ï„ )</formula><formula xml:id="formula_10">L = L âŸ¨YâŸ© + Î» â‹… L âŸ¨WâŸ© + Î± â‹… L âŸ¨AâŸ© + Î² â‹… L âŸ¨GâŸ© + Î³ â‹… L KL</formula><p>Training Loss: attention mechanism. As time-dependent confounders can result in a biased distribution of treatment assignments and imbalanced interferences due to the evolving graph structure, CAG-ODE utilizes two adversarial learning losses to ensure unbiased estimations of counterfactual outcomes. The overall framework is depicted in Figure <ref type="figure" target="#fig_0">1</ref>. We now discuss each module in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Spatial-Temporal Initial State Encoder</head><p>The encoder of CAG-ODE infers the posterior distributions from the historical observations and then samples the latent initial states from them. It follows the architecture described in <ref type="bibr" target="#b13">[14]</ref>. As the evolution of different nodes is mutually influenced, we calculate the initial states for all nodes simultaneously considering their interactions over time. The initial states of edges are derived from the initial states of nodes. Dynamic Node Representation Learning. We construct a graph to represent the spatial-temporal structure of multi-agent dynamical systems, with each node corresponding to an agent's observation at a particular timestamp. There are two types of edges: spatial edges at the same timestamp and temporal edges across different timestamps. The spatial edges are formed according to the adjacency matrices, denoted as ğ‘¤ ğ‘– (ğ‘¡ )â†’ğ‘— (ğ‘¡ ) . For the temporal edges, we only consider edges from an agent's own previous observations to later observations, denoted as ğ‘¤ ğ‘– (ğ‘¡ )â†’ğ‘– (ğ‘¡ â€² ) , where</p><formula xml:id="formula_11">ğ‘¡ â€² = ğ‘¡ + 1.</formula><p>The latent representations of observations are learned from this spatial-temporal graph through an attention mechanism approach.</p><p>The propagation among ğ¿ GNN layers is depicted in Equation <ref type="bibr" target="#b1">(2)</ref>.</p><formula xml:id="formula_12">ğ’‰ ğ‘™ ğ‘– (ğ‘¡ â€² ) = ğ’‰ ğ‘™ ğ‘– (ğ‘¡ â€² ) + ğœ âˆ‘ï¸ ğ‘— (ğ‘¡ ) âˆˆ N ğ‘– (ğ‘¡ â€² ) ğ‘’ ğ‘™ ğ‘— (ğ‘¡ )â†’ğ‘– (ğ‘¡ â€² ) Ã— ğ‘¾ ğ‘£ ğ’‰ ğ‘™ -1 ğ‘— (ğ‘¡ ) , ğ‘’ ğ‘™ ğ‘— (ğ‘¡ )â†’ğ‘– (ğ‘¡ â€² ) = ğ‘¤ ğ‘— (ğ‘¡ )â†’ğ‘– (ğ‘¡ â€² ) Ã— ğ›¼ ğ‘™ ğ‘— (ğ‘¡ )â†’ğ‘– (ğ‘¡ â€² ) , ğ›¼ ğ‘™ ğ‘— (ğ‘¡ )â†’ğ‘– (ğ‘¡ â€² ) = ğ‘¾ ğ‘˜ ğ’‰ ğ‘™ -1 ğ‘— (ğ‘¡ ) ğ‘‡ ğ‘¾ ğ‘ ğ’‰ ğ‘™ -1 ğ‘– (ğ‘¡ â€² ) â€¢ 1 âˆš ğ‘‘ ,<label>(2)</label></formula><formula xml:id="formula_13">ğ’‰ ğ‘™ -1 ğ‘— (ğ‘¡ ) = ğ’‰ ğ‘™ -1 ğ‘— (ğ‘¡ ) + TE ğ‘¡ -ğ‘¡ â€² , TE(Î”ğ‘¡) 2ğ‘– = sin Î”ğ‘¡ 10000 2ğ‘–/ğ‘‘ , TE(Î”ğ‘¡) 2ğ‘–+1 = cos Î”ğ‘¡ 10000 2ğ‘–/ğ‘‘ .</formula><p>Here, ğ’‰ ğ‘™ ğ‘– (ğ‘¡ ) represents the agent ğ‘– at time ğ‘¡ from layer ğ‘™. The attention score ğ‘’ ğ‘™ ğ‘— (ğ‘¡ )â†’ğ‘– (ğ‘¡ â€² ) is defined as the product of edge weights ğ‘¤ ğ‘— (ğ‘¡ )â†’ğ‘– (ğ‘¡ â€² ) and affinity score ğ›¼ ğ‘™ ğ‘— (ğ‘¡ )â†’ğ‘– (ğ‘¡ â€² ) , which is computed using the representations of the sender and receiver nodes. Additionally, we incorporate temporal embedding, denoted as TE, into the sender node's representation to establish temporal distinction. Then, the final representation is obtained from the ğ¿ layer as ğ’‰ ğ‘– (ğ‘¡ ) = ğ’‰ ğ¿ ğ‘– (ğ‘¡ ) . Sequence Representation Learning. Then, we employ selfattention to compute the sequence representation of observed temporal information for each node, where ğ’‰ ğ‘– (ğ‘¡ ) = ğ’‰ ğ‘– (ğ‘¡ ) + TE(ğ‘¡).</p><formula xml:id="formula_14">ğ’– ğ‘– = 1 ğ‘ ğ‘‡ âˆ‘ï¸ ğ‘¡ =1 (ğ’‚ ğ‘‡ ğ‘– ğ’‰ ğ‘– (ğ‘¡ ) ğ’‰ ğ‘– (ğ‘¡ ) ), ğ’‚ ğ‘– = tanh 1 ğ‘ ğ‘‡ âˆ‘ï¸ ğ‘¡ =1 ğ’‰ ğ‘– (ğ‘¡ ) ğ‘¾ ğ‘ .<label>(3)</label></formula><p>Finally, the mean and variance of the posterior distribution is obtained through a neural network ğ‘“ ddist from the sequence representation ğ’– ğ‘– .</p><formula xml:id="formula_15">ğ’› 0 ğ‘– âˆ¼ ğ‘ ğœ™ (ğ’› 0 ğ‘– |H 0 ) = N (ğ ğ‘§ 0 ğ‘– , ğœ 2 ğ’› 0 ğ‘– ), ğ ğ’› 0 ğ‘– , ğœ ğ’› 0 ğ‘– = ğ‘“ dist (ğ’– ğ‘– ).</formula><p>Next, the latent initial state for an edge is given by ğ’›</p><formula xml:id="formula_16">0 ğ‘–â†’ğ‘— = ğ‘“ edge ( [ğ’› 0 ğ‘– , ğ’› 0 ğ‘— ])</formula><p>, where ğ‘“ edge is parameterized by a neural network and [, ] is concatenation operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Treatment Fusing</head><p>To conduct causal inference with CAG-ODE, we propose to inject the dynamic effects of multiple treatments into the ODE function. Treatments can have time-varying effects in multi-agent dynamical systems and they can occur simultaneously, resulting in a combined effect. To model such complex behaviors, we propose a novel treatment fusing module that assigns temporal weights to multiple treatments through an attention mechanism. The temporal weight of treatment at timestamp ğ‘¡ is dependent on both the start time of each treatment and the occurrence of other treatments as shown in Eqn (4). Let ğ’† ğ‘˜ âˆˆ R ğ¾ be the one-hot representation of treatment ğ‘˜. We first add it with the temporal encoding TE <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b40">41]</ref> to account for the time elapsed since the start of the treatment ğ‘¡ â€² . Here A ğ‘¡ ğ‘–ğ‘˜ âˆˆ {0, 1} is an indicator showing whether treatment ğ‘˜ would be applied to agent ğ‘– at timestamp ğ‘¡. Therefore the computed treatment representation ğ’ ğ‘¡ ğ‘–ğ‘˜ becomes zero when A ğ‘¡ ğ‘–ğ‘˜ = 0, to ensure computational efficiency. A contraction matrix W ğ‘ is then used to transform this sparse representation into a more compact form.</p><formula xml:id="formula_17">ğ’ ğ‘¡ ğ‘–ğ‘˜ = A ğ‘¡ ğ‘–ğ‘˜ ğ’† ğ‘˜ + TE ğ‘¡ -ğ‘¡ â€² 1[A ğ‘¡ ğ‘–ğ‘˜ = 1], ğ’ ğ‘¡ ğ‘–ğ‘˜ = W ğ‘ ğ’ ğ‘¡ ğ‘–ğ‘˜ , TE(Î”ğ‘¡) 2ğ‘– = sin Î”ğ‘¡/ğ‘€ 2ğ‘–/ğ‘‘ , TE(Î”ğ‘¡) 2ğ‘–+1 = cos Î”ğ‘¡/ğ‘€ 2ğ‘–/ğ‘‘ , ğ‘€ = 10000. (4)</formula><p>To account for the combined effect of simultaneous treatments, we compute the combined treatment representation as a weighted sum of all in-effect treatments at timestamp ğ‘¡ (Eqn 5). We first compute an attention vector ğ‘š ğ‘¡ ğ‘– as the tanh-transformed average of all the treatment representations, ğ’ ğ‘¡ ğ‘– ğ‘— . Each treatment's weight is derived from the dot product of its representation and ğ‘š ğ‘¡ ğ‘– , thereby integrating each treatment's influence into ğ’ ğ‘¡ ğ‘– .</p><formula xml:id="formula_18">ğ’ ğ‘¡ ğ‘– = 1 ğ¾ âˆ‘ï¸ ğ‘˜ ğ’ ğ‘¡ ğ‘– âŠ¤ ğ’ ğ‘¡ ğ‘–ğ‘˜ ğ’ ğ‘¡ ğ‘–ğ‘˜ , ğ’ ğ‘¡ ğ‘– = tanh 1 ğ¾ âˆ‘ï¸ ğ‘˜ ğ’ ğ‘¡ ğ‘–ğ‘˜ W ğ‘š .<label>(5)</label></formula><p>The fusing operation has a time complexity of ğ‘‚ (ğ¾) if having K treatments and therefore is able to scale up to larger systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Treatment-Induced GraphODE</head><p>We use two coupled ODEs to predict the latent trajectories for nodes and edges respectively, accounting for their co-evolution <ref type="bibr" target="#b13">[14]</ref>. We incorporate the learned treatment representations into the ODEs to enable counterfactual predictions in the future. Specifically, the coevolution of nodes and edges is depicted in Eqn 6. The co-evolution depends on all historical information implicitly as Z ğ‘¡ embeds the trajectories up to time ğ‘¡. W ğ‘¡ ğ´ = D -1 W ğ‘¡ ğ´ is the normalized adjacency matrix and D is the diagonal degree matrix defined as</p><formula xml:id="formula_19">D ğ‘–ğ‘– = ğ‘— W ğ‘¡</formula><p>ğ´ğ‘– ğ‘— . ğ‘“ ğ‘’ , ğ‘“ self , ğ‘“ edge2value are all implemented as Multi-Layer Perceptrons (MLPs). To incorporate the treatment effect into the function, we use a linear transformation W to merge the latent states of nodes Z ğ‘¡ and the treatment representation ğ‘¶ ğ‘¡ . In this way, the latent trajectories of agents are affected not only by their own past trajectories and treatments but also by the trajectories and treatments of their interacting agents.</p><formula xml:id="formula_20">dZ ğ‘¡ dğ‘¡ = ğœ W ğ‘¡ ğ´ W[Z ğ‘¡ , O ğ‘¡ ] -Z ğ‘¡ + Z 0 , dğ’› ğ‘¡ ğ‘–â†’ğ‘— dğ‘¡ = ğ‘“ ğ‘’ ğ’› ğ‘¡ ğ‘– , ğ’› ğ‘¡ ğ‘— + ğ‘“ self ğ’› ğ‘¡ ğ‘–â†’ğ‘— , W ğ‘¡ ğ´ğ‘– ğ‘— = ğ‘“ edge2value ğ’› ğ‘¡ ğ‘–â†’ğ‘— , W ğ‘¡ ğ´ = D -1 W ğ‘¡ ğ´ .<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Outcome Prediction</head><p>Given the treatment representations, the ODE functions, the latent initial states for nodes and edges, and the latent trajectories for all agents can be determined using any black-box ODE solver. Finally, we compute the predicted trajectories for each agent and their interactions based on the decoding likelihoods in Eqn <ref type="bibr" target="#b6">(7)</ref>, where ğ‘“ decN and ğ‘“ decE are node and edge decoding functions respectively. They output the means of the normal distributions ğ‘ (ğ’š ğ‘¡ ğ‘– |ğ’› ğ‘¡ ğ‘– ) and ğ‘ (ğ’˜ ğ‘¡ ğ‘–â†’ğ‘— |ğ’› ğ‘¡ ğ‘– ), which we treat as the predicted values from our model.</p><formula xml:id="formula_21">ğ’š ğ‘¡ ğ‘– âˆ¼ ğ‘ (ğ’š ğ‘¡ ğ‘– |ğ’› ğ‘¡ ğ‘– ) = ğ‘“ decN (ğ’› ğ‘¡ ğ‘– ), ğ’˜ ğ‘¡ ğ‘–â†’ğ‘— âˆ¼ ğ‘ (ğ’˜ ğ‘¡ ğ‘–â†’ğ‘— |ğ’› ğ‘¡ ğ‘– ) = ğ‘“ decE (ğ’› ğ‘¡ ğ‘– ).<label>(7)</label></formula><p>We implemented all of our decoders using two-layer fully connected neural networks. The node feature decoder's input dimension matches the latent state dimension ğ‘‘, while the output dimension is one, reflecting our outcome of interest. The edge decoder's input dimension is 2ğ‘‘ and the output dimension is 1. The treatment decoder also has an input dimension equal to the latent state's dimension ğ‘‘. However, its output dimension matches the number of distinct treatments, predicting the probability of each treatment being chosen. Lastly, the interference decoder's input dimension is the sum of the latent state dimension and the treatment embedding dimension, i.e. 2ğ‘‘. Its output dimension mirrors the number of treatment options. For all decoders, the latent hidden dimension is half of their respective input dimensions.</p><p>We calculate the reconstruction loss of model predictions for nodes ğ‘Œ ğ‘¡ ğ‘– and edges ğ‘¤ ğ‘¡ ğ‘–â†’ğ‘— as:</p><formula xml:id="formula_22">ğ¿ âŸ¨ğ‘Œ âŸ© = 1 ğ‘ 1 ğ‘‡ âˆ‘ï¸ ğ‘¡ âˆ¥Y ğ‘¡ -Y ğ‘¡ âˆ¥ 2 2 , ğ¿ âŸ¨ğ‘Š âŸ© = 1 ğ‘ 2 1 ğ‘‡ âˆ‘ï¸ ğ‘¡ âˆ¥W ğ‘¡ ğ´ -W ğ‘¡ ğ´ âˆ¥ 2 ğ¹ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Domain Adversarial Learning</head><p>In observational data, treatment assignments are not randomized but are biased based on time-varying confounder values. This can lead to increased variance and bias in counterfactual estimation <ref type="bibr" target="#b39">[40]</ref>.</p><p>In multi-agent dynamical systems, unbalanced interference from neighboring agents further exacerbates this effect and alters the state of each agent. To obtain an unbiased counterfactual prediction, we need to ensure that the distribution of latent representation trajectories is invariant to treatments and interference <ref type="bibr" target="#b17">[18]</ref>. This guarantees that the treatments cannot be inferred from the latent trajectory representations and that the interference is not predictable when the treatment is combined with the latent representation.</p><p>To achieve this, we incorporate two adversarial learning losses into the optimization objective function and use gradient reversal layers for the implementation.</p><p>Treatment Balancing The treatment combinations A ğ‘¡ can be predicted using a decoder from the latent state ğ’› ğ‘¡ ğ‘– . Formally,</p><formula xml:id="formula_23">A ğ‘¡ ğ‘– â€¢ = Î¦ ğ´ (ğ‘Ÿ (ğ’› ğ‘¡ ğ‘– ))</formula><p>, where Î¦ ğ´ is a neural network attempting to recover treatments from the latent state ğ’› ğ‘¡ ğ‘– , and the gradient reversal layer, denoted by ğ‘Ÿ , reverses the sign of gradient during back-propagation. The treatment balancing can be expressed as the maximization of the following loss term through the construction of min-max games:</p><formula xml:id="formula_24">ğ¿ âŸ¨ğ´âŸ© = - 1 ğ‘ 1 ğ‘‡ 1 ğ¾ ğ‘ âˆ‘ï¸ ğ‘–=1 ğ‘‡ âˆ‘ï¸ ğ‘¡ =1 ğ¾ âˆ‘ï¸ ğ‘˜=1 âˆ‘ï¸ ğ‘— âˆˆ {0,1} 1[(A ğ‘¡ ğ‘–ğ‘˜ = ğ‘—)] log(Î¦ ğ‘—,ğ‘˜ ğ´ (ğ‘Ÿ (ğ’› ğ‘¡ ğ‘– ))),</formula><p>where Î¦</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ğ‘—,ğ‘˜</head><p>ğ´ represents the logits of ğ‘‘ ğ´ (â€¢) for predicting ğ‘— on ğ‘˜-th treatment. Note that we achieve treatment balancing by letting the latent representations ğ’› ğ‘¡ ğ‘– not be predictable for each individual treatment. This is because the representation of multiple treatments is essentially a linear combination of individual treatments. If each individual treatment is not predictable based on ğ’› ğ‘¡ ğ‘– , then it is also impossible to use such representation to predict when multiple treatments occur together.</p><p>Interference Balancing Similar to treatment balancing, the interference prediction can be represented as</p><formula xml:id="formula_25">G ğ‘¡ ğ‘– = Î¦ ğº (ğ‘Ÿ ([ğ‘ ğ‘¡ ğ‘– , ğ´ ğ‘¡ ğ‘– ]</formula><p>)), where ğ‘‘ ğº denotes a neural network designed to estimate interference. As interference is a continuous variable, we employ continuous domain adversarial training to accomplish interference balancing. By incorporating a gradient reversal layer, interference balancing can be achieved by minimizing the following loss term:</p><formula xml:id="formula_26">ğ¿ âŸ¨ğº âŸ© = 1 ğ‘ 1 ğ‘‡ 1 ğ¾ ğ‘ âˆ‘ï¸ ğ‘–=1 ğ‘‡ âˆ‘ï¸ ğ‘¡ =1 âˆ¥Î¦ ğº (ğ‘Ÿ ([ğ’› ğ‘¡ ğ‘– , ğ’ ğ‘¡ ğ‘– ])) -G ğ‘¡ ğ‘– âˆ¥ 2 2 .</formula><p>Overall Loss The overall training objective is defined as the weighted summation of node reconstruction loss, edge reconstruction loss, treatment balancing loss, and interference balancing loss. Since we follow the VAE framework, we also incorporate a KL divergence loss to add regularization towards the sampled initial states, which is defined as:</p><formula xml:id="formula_27">ğ¿ ğ¾ğ¿ = KL ğ‘ ğ‘–=1 ğ‘ ğœ™ ğ’› 0 ğ‘– | H 0 âˆ¥ğ‘ Z 0 .</formula><p>Therefore, the overall training loss is formalized as:</p><formula xml:id="formula_28">ğ¿ = ğ¿ âŸ¨ğ‘Œ âŸ© + ğœ†ğ¿ âŸ¨ğ‘Š âŸ© + ğ›¼ğ¿ âŸ¨ğ´âŸ© + ğ›½ğ¿ âŸ¨ğº âŸ© + ğ›¾ğ¿ ğ¾ğ¿ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS 5.1 Experiment Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Datasets and Experiment Configuration.</head><p>We evaluate the performance of our model using two datasets: 1.) The COVID-19 dataset, which captures the daily COVID-19 trends of U.S. states from April.12.2020 to Dec.31.2020. The daily population flows among states are represented as dynamic edges. Treatments are state-level COVID-19 policies. We ask the model to predict the daily confirmed cases in each state. 2.) The Tumor Growth simulation dataset <ref type="bibr" target="#b7">[8]</ref>, which describes the tumor growth dynamics in different regions of patients, where they may receive differing treatments. We aim to predict the tumor volumes in each region. Additional details about the datasets can be found in Appendix A.</p><p>We predict trajectory rollouts across varying lengths and use Root Mean Square Error (RMSE) as the evaluation metric. Specifically, we train our model in a sequence-to-sequence setting where we split the trajectory of each training sample into two parts [ğ‘¡ 1 , ğ‘¡ ğ¾ ] and [ğ‘¡ ğ¾+1 , ğ‘¡ ğ‘‡ ]. We condition the model on the first part of observations and predict the second part. To fully utilize the data points within each trajectory, we generate training and validation samples by splitting each trajectory into several chunks using a sliding window. Details can be found in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Baselines and Model</head><p>Variants. We conduct a comparative analysis of our model with three baseline models: one non-causal continuous multi-agent baseline CG-ODE <ref type="bibr" target="#b13">[14]</ref>, and two causal models: TE-CDE <ref type="bibr" target="#b39">[40]</ref> and COVID-POLICY <ref type="bibr" target="#b28">[29]</ref>. TE-CDE <ref type="bibr" target="#b39">[40]</ref> is a causal model that employs continuous-time differential equations to capture temporal event dependencies. COVID-Policy <ref type="bibr" target="#b28">[29]</ref> is another causal model designed specifically for assessing the impact of public health policies on COVID-19 outcomes. To further analyze the performance of our model, we also compare variants of our model. Each variant excludes a specific component to assess its individual impact on performance. The variants include models without treatment balancing, interference balancing, both components or the attention module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Training Details.</head><p>We employ the AdamW optimizer, as proposed in the study by Loshchilov et al. <ref type="bibr" target="#b25">[26]</ref>, to train our model. The initial learning rate is set at ğœ‚ = 0.005, and the batch size is set as 8 to accommodate memory constraints.</p><p>The Graph Neural Network (GNN) used for the encoder has a singular layer with a hidden dimension of 64. Similarly, the GNN that parameterizes the ODE function is also comprised of a single layer. The dimension of the latent state is set at 20, and the dimension for the embedded treatments is 5. We assign a weight of 10 for both the treatment balancing term ğ›¼ and the interference balancing term ğ›½. Additionally, the weight designated for the edge reconstruction error ğœ† is set at 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance Evaluation</head><p>We evaluate the performance of our model, CAG-ODE, as well as the baselines using Root Mean Square Error (RMSE) across different prediction lengths. The results are shown in Table <ref type="table" target="#tab_1">1</ref> and Table <ref type="table" target="#tab_2">2</ref>, reporting the factual and counterfactual outcomes respectively. As the COVID-19 is a real-world dataset that does not have counterfactual outcomes, we evaluate only the Tumor Growth dataset in Table <ref type="table" target="#tab_2">2</ref>. To ensure consistent comparison, we align the prediction periods of all models with weekly intervals on the COVID-19 dataset, similar to the statistical baselines derived from their official weekly submissions to the CDC, as done in <ref type="bibr" target="#b13">[14]</ref>. To assess the accuracy of short-term and long-term predictions, the prediction lengths for the COVID-19 and Tumor Growth datasets are set to 7, 14, 21 days and 14, 21, and 28 days, respectively. We include longer-range predictions on the Tumor-Growth dataset in Appendix C Factual Outcome Predictions. Table <ref type="table" target="#tab_1">1</ref> shows that our model, CAG-ODE, consistently outperforms the baseline models across Counterfactual Outcome Predictions. In the context of a multi-agent dynamical system, the total number of possible treatments for all nodes is ğ‘¶ (ğ¾ Ã— 2ğ‘ ), making it infeasible to enumerate all treatment combinations. To assess the robustness of each model to counterfactual treatment scenarios, we perform an experiment where we randomly flip a certain percentage of observed treatments. In Table <ref type="table" target="#tab_2">2</ref>, we evaluate the performance when 25%, 50%, and 75% of all observed treatments in each experiment are randomly flipped. The purpose of this experiment is to examine the robustness of the models to counterfactual treatment scenarios, and since CG-ODE does not incorporate causal modeling, it is excluded from this experiment. CAG-ODE outperforms others by a wide margin across all settings. These findings collectively demonstrate the superiority of our proposed model, CAG-ODE, in capturing the dynamics of multi-agent systems and making accurate predictions across different time horizons. We additionally include the visualization of the learned balanced latent representations in Section 5.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Case Study about COVID-19 Policies</head><p>We conduct a case study to show the impact of different treatments, e.g., COVID-19 related policies, on the COVID-19 dataset as shown in Figure <ref type="figure" target="#fig_2">2</ref>. Specifically, we consider four different policy intervention methods and report the resulting average changes in the number of daily confirmed cases across all states in the U.S.</p><p>First, we focus on the removal of policies in three states that have the highest number of announced policies during the time frame of the COVID-19 dataset. By masking out these policies, we observe an increase in the average number of confirmed cases across states in the future. This increase is attributed to both in-state disease spread and population flow to other states. The removal of policies exacerbates the spread of COVID-19 over an extended period, as shown in Figure <ref type="figure" target="#fig_2">2(a)</ref>, indicating that our model captures the dynamic interference resulting from agents' interactions.</p><p>We then explore the effect of changing the starting time of a specific policy for all states. We changed the "No Public Gatherings" policy starting time for each state to be 15 days earlier, 15 and 30 days later respectively. As shown in Figure <ref type="figure" target="#fig_2">2</ref>(b) when announcing the policy earlier, we observe a decrease in the average number of daily confirmed cases in the future, while announcing the policy later leads to an increase. This intuitive outcome highlights the capability of our model to capture the causal relationships between policy interventions and COVID-19 spread.</p><p>Next, we analyze the impact of the top three most frequent policies across all states by removing them separately. As shown in Figure <ref type="figure" target="#fig_2">2(c</ref>), the "Public Gatherings" policy has the largest effect in reducing the spread of COVID-19, even though the most frequent policy is "Emergency Funds". This demonstrates the potential of our model in assisting policymakers to identify the relative importance of each policy over time.</p><p>Finally, we study the effects of different orders in policy announcements, specifically focusing on the simultaneous or closely timed announcements of "No Public Gatherings" and "No Traveler from Outside States" policies. We change the announcement dates for the two policies in each state to mimic three scenarios shown in Figure <ref type="figure" target="#fig_2">2 (d)</ref>. We found that initializing the announcement of "No Public Gatherings" early generally contributes to a reduction in the spread of COVID-19 compared with "No Traveler from Outside States". We further analyzed the daily population flow during the given time frame and found that the majority of population flows are within the same states, indicating that residents of each state pose a high risk of virus transmission compared to people from other states. These insights suggest prioritizing the earlier announcement of the "No Public Gatherings" policy over the "No Traveler from Outside States" policy can better mitigate the spread of COVID-19.</p><p>These case study results demonstrate the effectiveness of our model CAG-ODE in capturing the complex interactions between treatments, disease spread, and population flow, providing valuable insights for policymakers in making informed decisions.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Visualization of Learned Balanced Representations</head><p>To further understand the effect of treatment balancing loss in CAG-ODE, we visualize the 2-D T-SNE projections of the latent representations of nodes on the COVID-19 dataset, i.e. ğ’› ğ‘¡ ğ‘– as shown in Figure <ref type="figure" target="#fig_3">3</ref>. Specifically, we visualize the latent node representations under two different treatments: "State-of-Emergency" and "No-Public-Gathering". Under each treatment (policy), we use different colors to denote whether a node receives such treatment (treated) or not (control). As shown in Figure <ref type="figure" target="#fig_3">3</ref>(a) and (c), the distributions of the learned representations are more distinguishable between the two groups, compared with Figure <ref type="figure" target="#fig_3">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we introduce the causal graph ODE (CAG-ODE) as a model for estimating continuous counterfactual outcomes in multiagent-dynamical systems with evolving interaction edges and dynamic multi-treatment effects. Our model builds upon existing GraphODEs and incorporates causal reasoning for multi-agent dynamical systems. We propose a novel treatment fusing module that captures the dynamic effects of multiple treatments occurring simultaneously. Through extensive experiments on both the real-world and the simulated datasets, we demonstrate the superior performance of our model across various prediction settings, validating its effectiveness. Furthermore, we leverage our model to analyze policy effects analysis on the COVID-19 dataset, providing valuable insights for policymakers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX A DATASET DESCRIPTION A.1 COVID-19 Dataset</head><p>Our experiments used the dataset provided by the Johns Hopkins Coronavirus Resource Center (JHU) <ref type="foot" target="#foot_2">3</ref> from April 12th to December 31st, 2020. That is, we consider 264 time points, with each point representing one day. The dataset contains a comprehensive range of information, but for our experiments, we focus on up to 7 specific features. These features include the daily counts of confirmed cases, deaths, recovered cases, active cases, incident rate (cases per 100,000 people), mortality rate (calculated as the number of recorded deaths multiplied by 100 divided by the number of cases), and testing rate (total test results per 100,000 people). It's worth noting that while the JHU dataset provides cumulative data for confirmed, deaths, recovered, and active cases, our experiments and models specifically consider the daily increases in these features (e.g., the number of new cases reported each day).</p><p>To capture dynamic interaction edges, we use a temporal mobility flow network among a selection of 47 states based on COVID-19 USFlows <ref type="bibr" target="#b19">[20]</ref>.</p><p>The treatments are represented as statewide policies that aim to combat the spread of COVID-19. We identify 58 different statewide policies enacted throughout 2020, from the data given by the Department of Health &amp; Human Services <ref type="foot" target="#foot_3">4</ref> . Each state enacted around 20 of these policies during the time period of April 2020 to December 2020, where the dataset provides the start and end dates of each enacted policy. In our model, treatments are encoded such that for each time point, the value is either 1 or 0 depending on whether the particular policy is enacted (for a given state) at that time or not, respectively.</p><p>Overall, the model receives input data for a total of 264 time points, covering each of the 47 states, and includes 7 features. Alongside this, the model is also provided with treatments and a mobility graph. Prior to being used as input for our models, the data is normalized. However, when calculating the test loss for comparison with other baseline models, the output is unnormalized. Our goal is to predict either the number of confirmed cases or the number of deaths for a future period of 7, 14, or 21 days.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Tumor Growth Dataset</head><p>We extend the state-of-the-art pharmacokinetic-pharmacodynamic (PK-PD) model of tumor growth proposed by <ref type="bibr" target="#b7">[8]</ref> to simulate a more complex scenario where multiple tumor regions within a single patient interact with each other. The original model characterizes patients suffering from non-small cell lung cancer and models the evolution of their tumor under the combined effects of chemotherapy and radiotherapy. For a detailed description of the original model, we refer the readers to the original paper <ref type="bibr" target="#b7">[8]</ref>. In our extended model, we incorporate two new terms: an interference term and a neighborhood covariate term. The volume of the tumor in region ğ‘– at ğ‘¡ + 1 days after diagnosis is modeled as follows: .</p><formula xml:id="formula_29">ğ‘‰ ğ‘– (ğ‘¡ + 1) = 1 + ğœŒ log ğ¾ ğ‘‰ ğ‘– (ğ‘¡ )</formula><p>where the parameters ğ¾, ğœŒ, ğ›½ ğ‘ , ğ›¼ ğ‘Ÿ , ğ›½ ğ‘Ÿ are sampled from the prior distributions described in <ref type="bibr" target="#b7">[8]</ref>, and ğ‘’ ğ‘–ğ‘¡ âˆ¼ ğ‘ (0, 0.012) is a noise term that accounts for randomness in the tumor growth. The prior means for ğ›½ ğ‘ and ğ›¼ ğ‘Ÿ are adjusted to create three patient subgroups ğ‘† (ğ‘–) âˆˆ {1, 2, 3} as described in <ref type="bibr" target="#b2">[3]</ref>. The chemotherapy drug concentration follows an exponential decay with a half-life of 1 day. The time-varying confounding is introduced by modeling chemotherapy and radiotherapy assignment as Bernoulli random variables, with probabilities ğ‘ ğ‘ and ğ‘ ğ‘Ÿ depending on the tumor diameter. For more details, we refer the reader to the paper <ref type="bibr" target="#b2">[3]</ref>. For our newly defined interference and neighborhood covariate terms, we set the hyperparameters ğœ„ ğ‘ and ğœ„ ğ‘Ÿ to 0.01, and ğœ… to 0.001. These values were carefully chosen to reflect the strength of the interference and neighborhood covariates in the dataset. The number of tumors in each patient ğ‘ ğ‘– is fixed to 15, and for each tumor region, the number of edges connected between the tumor regions is defined randomly from the range of 22 to 45. For additional experiments shown in Appendix C, the number of tumor regions for each patient is fixed to 5, and the number of edges ranges from 6 to 10. The dataset is input into our model similar to the COVID-19 dataset.</p><p>Both chemotherapy and radiotherapy are encoded into 0 or 1 value depending on whether it was applied at a specific time point. The input data consists of 60-time points with 4 features, which include tumor volume, patient type, and the two treatments. The data is normalized for model input but unnormalized for test loss calculation. The model's objective is to predict tumor volume for future periods of 14, 21, or 28 days. We also create a longer-range dataset with 120-time points, which is described in C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B DATA SPLITTING</head><p>We train our model in a sequence-to-sequence setting, where we split the trajectory of each training sample into two parts [ğ‘¡ 1 , ğ‘¡ ğ¾ ] and [ğ‘¡ ğ¾+1 , ğ‘¡ ğ‘‡ ]. We condition the model on the first part of observations and predict the second part. To fully utilize the data points within each trajectory, we generate training and validation samples by splitting each trajectory into several chunks using a sliding window with three hyperparameters: the observation length and prediction length for each sample, and the interval between two consecutive chunks (samples). We summarize the procedure in Algorithm 1, where ğ¾ is the number of trajectories and ğ‘‘ is the input feature dimension. For both datasets, we set the observation length to be 7 and the interval to be 3. We ask the model to make predictions at varying lengths for evaluation. In Table <ref type="table" target="#tab_4">3</ref>, we evaluate the performance of our model. An extended version of the simulation dataset with a range of 120 days was used in the experiment. The considered prediction lengths are 35, 49, and 63 days. As anticipated, the prediction errors exhibit a moderate increase with longer prediction lengths, as the added duration poses a greater challenge for accurate predictions. Note that the prediction error remains relatively stable when the treatment flipping ratio is increased from 25% to 75%. This observation suggests that the utilization of treatment balancing and interference balancing techniques effectively mitigates the risk of overfitting to confounding factors, ensuring CAG-ODE's robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D MODEL IMPLEMENTATION DETAILS</head><p>We use the fourth-order Runge-Kutta method from the torchdiffeq python package <ref type="bibr" target="#b5">[6]</ref> as the ODE solver, for solving the ODE systems on a time grid that is five times denser than the observed time points. We also utilize the Adjoint method described in <ref type="bibr" target="#b5">[6]</ref> to reduce memory use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E LIMITATIONS</head><p>One limitation of CAG-ODE is that when inferring the future trajectories of nodes, we simply assume that all nodes are connected and jointly infer such edge evolution. This would bring huge computational costs when generalized to large-scale dynamical systems.</p><p>In the future, we will consider more efficient sampling methods to accelerate the edge inference procedure to scale up our model. Another line of future work would be how to model more complex multiple treatment effects, including competing, hierarchical relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F BROADER IMPACTS</head><p>Our work significantly enhances the performance of causal inference over multi-agent dynamical systems, which can potentially benefit a wide range of fields including public health, biology, physics, and robotics. Our work also advances the recent study of continuous graphODE for modeling multi-agent system dynamics, providing an efficient tool for further research on AI for science.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overall Framework of CAG-ODE. The encoder first computes the latent initial states. Then the treatment-induced coupled ODE functions predict the continuous trajectories over time. Treatment representations learned through the fusing module are incorporated into the ODE functions to enable counterfactual prediction. Finally, the decoder outputs the predicted dynamics. Treatment and interference balancing losses are designed to ensure unbiased counterfactual predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) Remove partial states' policy. (b) Change policy start date. (c) Remove policy across states. (d) Change relative time of policies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Case Study for changing different policies on the COVID-19 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Treatment Balancing Visualization on the COVID-19 Dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(b) and (d) which have the treatment balancing loss. This indicates that CAG-ODE indeed learns balanced latent representations by employing the treatment balancing loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 1 : 6</head><label>16</label><figDesc>Data Splitting Procedure. Input: Original Training trajectories ğ‘‹ input âˆˆ R ğ¾ Ã—ğ‘ Ã—ğ‘‡ Ã—ğ‘‘ ; Observation length ğ‘‚; Prediction length ğ‘€; Interval ğ¼ ; Trajectory length ğ‘‡ . Output: Training samples after splitting ğ‘‹ train . 1 sample_length = ğ‘‚ + ğ‘€; 2 num_chunk = (ğ‘‡ -sample_length )//interval + 1; 3 for i in range (0,K) do 4 for j in range(0,num_chunk,I) do 5 Generate the split training sample as ğ‘‹ input [ğ‘–, :, ğ‘— : ğ‘— + sample_length, :] Add the training sample to the training set ğ‘‹ train .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Root Mean Square Error (RMSE) for factual outcome evaluation across prediction lengths (the duration for which predictions are made). For the COVID-19 dataset, we report the mean and standard deviation accuracy with multiple runs.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>Covid-19</cell><cell></cell><cell></cell><cell>Tumor Growth</cell><cell></cell></row><row><cell>Prediction Length</cell><cell>7-days</cell><cell>14-days</cell><cell>21-days</cell><cell cols="3">14-days 21-days 28-days</cell></row><row><cell>CG-ODE</cell><cell cols="3">4063 Â± 68 4454 Â± 100 4659 Â± 63</cell><cell>18.37</cell><cell>21.00</cell><cell>24.58</cell></row><row><cell>TE-CDE</cell><cell cols="3">7999 Â± 212 7470 Â± 289 6832 Â± 243</cell><cell>55.45</cell><cell>55.38</cell><cell>71.23</cell></row><row><cell>COVID-POLICY</cell><cell>4008 Â± 44</cell><cell>4128 Â± 60</cell><cell>3963 Â± 59</cell><cell>20.07</cell><cell>25.93</cell><cell>29.29</cell></row><row><cell>CAG-ODE</cell><cell cols="3">3710 Â± 29 3925 Â± 44 3933 Â± 40</cell><cell>10.91</cell><cell>10.82</cell><cell>14.84</cell></row><row><cell>w/o ğ¿ âŸ¨ğº âŸ©</cell><cell>3800 Â± 60</cell><cell>3987 Â± 40</cell><cell>3990 Â± 49</cell><cell>15.57</cell><cell>16.28</cell><cell>16.62</cell></row><row><cell>w/o ğ¿ âŸ¨ğ´âŸ©</cell><cell>3840 Â± 35</cell><cell>4100 Â± 53</cell><cell>4069 Â± 49</cell><cell>17.90</cell><cell>14.69</cell><cell>20.19</cell></row><row><cell>w/o ğ¿ âŸ¨ğº âŸ© ,ğ¿ âŸ¨ğ´âŸ©</cell><cell>3793 Â± 23</cell><cell>4089 Â± 79</cell><cell>3953 Â± 38</cell><cell>17.28</cell><cell>16.72</cell><cell>24.36</cell></row><row><cell>w/o attention</cell><cell>3867 Â± 61</cell><cell>3958 Â± 31</cell><cell>4256 Â± 55</cell><cell>18.91</cell><cell>17.55</cell><cell>34.45</cell></row><row><cell cols="3">all prediction lengths for both datasets. This underscores the ef-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">fectiveness of our model in capturing the dynamic interactions</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">among objects, especially over longer time periods. Comparing</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">our model with TE-CDE, we observe a performance gap that high-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">lights the benefits of incorporating interference balancing and spa-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">tial correlation in the model. Additionally, our model outperforms</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">the COVID-POLICY model, indicating its broader generalizability</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">across different types of data due to modeling dynamic interactions.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>Furthermore, our model exhibits proficiency in both short-term and long-term predictions. For instance, it achieves promising results for 21-day predictions on the COVID-19 dataset and 28-day predictions on the Tumor Growth simulation dataset. The analysis of our model variants further emphasizes the importance of each component in the model. Particularly, the model variant excluding the attention module has the weakest performance, indicating the significance of our time-embedding attention module in effectively representing the treatment.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Root Mean Square Error (RMSE) for counterfactual Outcome evaluation on the Tumor Growth dataset with treatment flipping ratio. Treatment F.R. (Treatment Flipping Ratio) represents the ratio of treatments that are flipped.</figDesc><table><row><cell>Prediction Length</cell><cell></cell><cell>14-days</cell><cell></cell><cell></cell><cell>21-days</cell><cell></cell><cell></cell><cell>28-days</cell><cell></cell></row><row><cell>Treatment F.R.</cell><cell>0.25</cell><cell>0.5</cell><cell>0.75</cell><cell>0.25</cell><cell>0.5</cell><cell>0.75</cell><cell>0.25</cell><cell>0.5</cell><cell>0.75</cell></row><row><cell>TE-CDE</cell><cell cols="9">95.61 103.2 100.8 98.65 103.0 97.93 118.3 124.0 121.4</cell></row><row><cell>COVID-POLICY</cell><cell cols="9">21.32 22.37 23.31 26.63 26.83 27.00 32.01 32.16 32.21</cell></row><row><cell>CAG-ODE</cell><cell cols="9">17.23 16.98 16.96 18.64 18.84 18.85 19.91 19.88 19.87</cell></row><row><cell>w/o ğ¿ âŸ¨ğº âŸ©</cell><cell cols="9">20.62 20.53 20.51 19.70 19.60 19.55 21.10 21.41 21.38</cell></row><row><cell>w/o ğ¿ âŸ¨ğ´âŸ©</cell><cell cols="9">22.17 22.35 22.35 20.19 20.10 20.09 20.83 21.14 21.15</cell></row><row><cell>w/o ğ¿ âŸ¨ğº âŸ© , ğ¿ âŸ¨ğ´âŸ©</cell><cell cols="9">19.78 19.75 19.71 19.34 19.29 19.27 21.31 21.40 21.34</cell></row><row><cell>w/o attention</cell><cell cols="9">19.09 18.37 18.13 22.16 21.78 21.65 27.70 27.44 27.38</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>-</head><label></label><figDesc>ğ›½ ğ‘ ğ¶ ğ‘– (ğ‘¡ ) ğ›¼ ğ‘Ÿ ğ‘‘ ğ‘– (ğ‘¡ ) + ğ›½ ğ‘Ÿ ğ‘‘ ğ‘– (ğ‘¡ ) 2 ğœ„ ğ‘Ÿ ğ‘‘ ğ‘— (ğ‘¡ ) + ğœ„ ğ‘Ÿ ğ‘‘ ğ‘— (ğ‘¡ ) 2</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>+ ğ‘’ ğ‘–ğ‘¡</cell><cell>ğ‘‰ ğ‘– (ğ‘¡ )</cell></row><row><cell></cell><cell cols="3">Tumor Growth</cell><cell></cell><cell></cell><cell></cell><cell>Radiotherapy</cell><cell>Noise</cell></row><row><cell>+</cell><cell>1</cell><cell>âˆ‘ï¸</cell><cell>ğœ„ ğ‘ ğ¶ ğ‘— (ğ‘¡ )</cell><cell>+</cell><cell>1</cell><cell cols="2">âˆ‘ï¸</cell></row><row><cell></cell><cell>ğ‘ ğ‘–</cell><cell>ğ‘— âˆˆN ğ‘–</cell><cell></cell><cell></cell><cell>ğ‘ ğ‘–</cell><cell cols="2">ğ‘— âˆˆN ğ‘–</cell></row><row><cell></cell><cell cols="3">Chemotherapy Interference</cell><cell></cell><cell></cell><cell></cell><cell>Radiotherapy Interference</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>+</cell><cell></cell><cell>1</cell><cell>âˆ‘ï¸</cell><cell>ğœ…ğ‘‰ ğ‘— (ğ‘¡ )</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğ‘ ğ‘–</cell><cell>ğ‘— âˆˆN ğ‘–</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Neighborhood Covariates</cell></row></table><note><p><p>Chemotherapy</p>-</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>ODE  35.00 34.68 34.50 34.12 37.92 37.88 46.71 47.28 48.12 Root Mean Square Error (RMSE) for counterfactual outcome evaluation on the longer-range Tumor Growth dataset with treatment flipping ratio: 25%, 50%, 75%.</figDesc><table><row><cell>Prediction Length</cell><cell></cell><cell>35-days</cell><cell></cell><cell></cell><cell>49-days</cell><cell></cell><cell></cell><cell>63-days</cell><cell></cell></row><row><cell>Treatment F.R.</cell><cell>0.25</cell><cell>0.5</cell><cell>0.75</cell><cell>0.25</cell><cell>0.5</cell><cell>0.75</cell><cell>0.25</cell><cell>0.5</cell><cell>0.75</cell></row><row><cell>CAG-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Our code implementation can be found at https://github.com/Jun-Kai-Zhang/CAG-ODE.git.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The potential outcome can also be formalized using do operation<ref type="bibr" target="#b32">[33]</ref> </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://coronavirus.jhu.edu/about/how-to-use-our-data</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://catalog.data.gov/dataset/covid-19-state-and-county-policy-orders-9408a</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">ACKNOWLEDGEMENT</head><p>This work was partially supported by <rs type="funder">NSF</rs> <rs type="grantNumber">2106859</rs>, <rs type="grantNumber">2200274</rs>, <rs type="grantNumber">2312501</rs>, <rs type="funder">NEC</rs> and <rs type="funder">NSF</rs> <rs type="grantNumber">2211557</rs>, <rs type="funder">NSF</rs> <rs type="grantNumber">1937599</rs>, <rs type="funder">NSF</rs> <rs type="grantNumber">2119643</rs>, <rs type="funder">NSF</rs> <rs type="grantNumber">2303037</rs>, <rs type="funder">NSF</rs> <rs type="grantNumber">20232551</rs>, <rs type="funder">NASA</rs>, <rs type="grantNumber">SRC JUMP 2.0</rs> <rs type="funder">Center</rs>, <rs type="funder">Cisco</rs> research grant, <rs type="person">Picsart Gifts</rs>, and <rs type="person">Snapchat Gifts</rs>. We would like to thank <rs type="person">Song Jiang</rs> for his valuable discussion throughout this project.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_f6PFUdv">
					<idno type="grant-number">2106859</idno>
				</org>
				<org type="funding" xml:id="_WS7zJp8">
					<idno type="grant-number">2200274</idno>
				</org>
				<org type="funding" xml:id="_eakQFNd">
					<idno type="grant-number">2312501</idno>
				</org>
				<org type="funding" xml:id="_m2sSWUN">
					<idno type="grant-number">2211557</idno>
				</org>
				<org type="funding" xml:id="_s7G9me7">
					<idno type="grant-number">1937599</idno>
				</org>
				<org type="funding" xml:id="_xrngHGh">
					<idno type="grant-number">2119643</idno>
				</org>
				<org type="funding" xml:id="_ECkzE7m">
					<idno type="grant-number">2303037</idno>
				</org>
				<org type="funding" xml:id="_qadxYCy">
					<idno type="grant-number">20232551</idno>
				</org>
				<org type="funding" xml:id="_rMFRs2g">
					<idno type="grant-number">SRC JUMP 2.0</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Guangji</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.10664</idno>
		<title level="m">Temporal Domain Generalization with Drift-Aware Dynamic Neural Networks</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Policy analysis using synthetic controls in continuous-time</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihaela</forename><surname>Van</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Der</forename><surname>Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="759" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Bica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><forename type="middle">M</forename><surname>Alaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Jordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihaela</forename><surname>Van Der Schaar</surname></persName>
		</author>
		<title level="m">Estimating counterfactual treatment outcomes over time through adversarially balanced representations. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Estimating counterfactual treatment outcomes over time through adversarially balanced representations</title>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Bica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><forename type="middle">M</forename><surname>Alaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Jordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihaela</forename><surname>Van Der Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A method for assessing the quality of a randomized control trial</title>
		<author>
			<persName><forename type="first">Harry</forename><surname>Thomas C Chalmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Smith</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">Bernard</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biruta</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinah</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Reitman</surname></persName>
		</author>
		<author>
			<persName><surname>Ambroz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Controlled clinical trials</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="31" to="49" />
			<date type="published" when="1981">1981. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural Ordinary Differential Equations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">K</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="6571" to="6583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Predicting the impact of treatments over time with uncertainty aware neural differential equations</title>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">De</forename><surname>Brouwer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Hyland</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4705" to="4722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Prediction of treatment response for combined chemo-and radiation therapy for non-small cell lung cancer patients using a bio-mathematical model</title>
		<author>
			<persName><forename type="first">Changran</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harald</forename><surname>Paganetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Grassberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13542</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Daehoon</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gyuhyeon</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Massaroli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.08304</idno>
		<title level="m">Neural ordinary differential equations for intervention modeling</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Variational Graph Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Hajiramezanali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Hasanzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Duffield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoning</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="10701" to="10711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Heterogeneous Graph Transformer</title>
		<author>
			<persName><forename type="first">Ziniu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 World Wide Web Conference</title>
		<meeting>the 2020 World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multilingual Knowledge Graph Completion with Self-Supervised Adaptive Graph Alignment</title>
		<author>
			<persName><forename type="first">Zijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoming</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Subbian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning Continuous System Dynamics from Irregularly-Sampled Partial Observations</title>
		<author>
			<persName><forename type="first">Zijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Coupled graph ode for learning interacting system dynamics</title>
		<author>
			<persName><forename type="first">Zijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 27th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generalizing graph ode for learning complex system dynamics across environments</title>
		<author>
			<persName><forename type="first">Zijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="798" to="809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs</title>
		<author>
			<persName><forename type="first">Zijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binxuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="10105" to="10118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">TANGO: Time-Reversal Latent GraphODE for Multi-Agent Dynamical Systems</title>
		<author>
			<persName><forename type="first">Zijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanjia</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingdong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziniu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yadi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H7R0z6V9fR" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">CF-GODE: Continuous-Time Causal Inference for Multi-Agent Dynamical Systems</title>
		<author>
			<persName><forename type="first">Song</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">29th SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Estimating Causal Effects on Networked Observational Data via Representation Learning</title>
		<author>
			<persName><forename type="first">Song</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 31st ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="852" to="861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Multiscale Dynamic Human Mobility Flow Dataset in the U.S. during the COVID-19 Epidemic</title>
		<author>
			<persName><forename type="first">Yuhao</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunlei</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Kruse</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
	<note>Issue 390</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Fetaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04687</idno>
		<title level="m">Neural Relational Inference for Interacting Systems</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Fetaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04687</idno>
		<title level="m">Neural Relational Inference for Interacting Systems</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<idno>ICLR&apos;17</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Forecasting treatment responses over time using recurrent marginal structural networks. advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Lim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Decoupled Weight Decay Regularization</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">CARE: Modeling Interacting Dynamics Under Temporal Environmental Variation</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiyu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhijeet</forename><surname>Sadashiv Gangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">HOPE: high-order graph ODE for modeling interacting dynamics</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyang</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiyu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifang</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International Conference on Machine Learning (ICML&apos;23)</title>
		<meeting>the 40th International Conference on Machine Learning (ICML&apos;23)</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Assessing the Causal Impact of COVID-19 Related Policies on Outbreak Dynamics: A Case Study in the US</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushun</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Mietchen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Web Conference 2022</title>
		<meeting>the ACM Web Conference 2022</meeting>
		<imprint>
			<publisher>WWW &apos;22</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2678" to="2686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning causal effects on hypergraphs</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengting</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brent</forename><surname>Hecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Teevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1202" to="1212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Causal Transformer for Estimating Counterfactual Outcomes</title>
		<author>
			<persName><forename type="first">Valentyn</forename><surname>Melnychuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dennis</forename><surname>Frauen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Feuerriegel</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<title level="s">Proceedings of Machine Learning Research</title>
		<meeting><address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022-07">2022. 17-23 July 2022</date>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="15293" to="15329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A probabilistic model for the numerical solution of initial value problems</title>
		<author>
			<persName><forename type="first">Schober</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">SÃ¤rkkÃ¤</forename><surname>Simo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Hennig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistics and Computing</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="99" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Causality</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Michael</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Massaroli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atsushi</forename><surname>Yamashita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hajime</forename><surname>Asama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinkyoo</forename><surname>Park</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.07532</idno>
		<title level="m">Graph neural ordinary differential equations</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Marginal structural models and causal inference in epidemiology</title>
		<author>
			<persName><forename type="first">Miguel</forename><surname>James M Robins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babette</forename><surname>Angel Hernan</surname></persName>
		</author>
		<author>
			<persName><surname>Brumback</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="550" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Latent Ordinary Differential Equations for Irregularly-Sampled Time Series</title>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="5320" to="5330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bayesian inference for causal effects: The role of randomization</title>
		<author>
			<persName><surname>Donald B Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Annals of statistics</title>
		<imprint>
			<date type="published" when="1978">1978. 1978</date>
			<biblScope unit="page" from="34" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning to Simulate Complex Physics with Graph Networks</title>
		<author>
			<persName><forename type="first">Alvaro</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Godwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Pfaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">W</forename><surname>Battaglia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning, ICML 2020</title>
		<meeting>the 37th International Conference on Machine Learning, ICML 2020</meeting>
		<imprint>
			<date type="published" when="2020-07">2020. July 2020</date>
			<biblScope unit="page" from="8459" to="8468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">DySAT: Deep Neural Representation Learning on Dynamic Graphs via Self-Attention Networks</title>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanhong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In WSDM&apos;20</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations</title>
		<author>
			<persName><forename type="first">Nabeel</forename><surname>Seedat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fergus</forename><surname>Imrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaozhi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihaela</forename><surname>Van Der Schaar</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="19497" to="19521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Å Ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Petar</forename><surname>VeliÄkoviÄ‡</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>LiÃ²</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graph Attention Networks. ICLR</title>
		<imprint>
			<biblScope unit="page">18</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">How Powerful are Graph Neural Networks?</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ICLR&apos;19</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Neural dynamics on complex networks</title>
		<author>
			<persName><forename type="first">Chengxi</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="892" to="902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting</title>
		<author>
			<persName><forename type="first">Yunhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
