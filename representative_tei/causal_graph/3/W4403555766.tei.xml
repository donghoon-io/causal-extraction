<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Co-Developing Causal Graphs with Domain Experts Guided by Weighted FDR-Adjusted p-values</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-09">September 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Eli</forename><forename type="middle">Y</forename><surname>Kling</surname></persName>
							<email>eli.kling@avanade.com</email>
							<affiliation key="aff0">
								<address>
									<settlement>Avanade London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Co-Developing Causal Graphs with Domain Experts Guided by Weighted FDR-Adjusted p-values</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-09">September 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2409.03126v1[stat.ME]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes an approach facilitating co-design of causal graphs between subject matter experts and statistical modellers. Modern causal analysis starting with formulation of causal graphs provides benefits for robust analysis and well-grounded decision support. Moreover, this process can enrich the discovery and planning phase of data science projects.</p><p>The key premise is that plotting relevant statistical information on a causal graph structure can facilitate an intuitive discussion between domain experts and modellers. Furthermore, Hand-crafting causality graphs, integrating human expertise with robust statistical methodology, enables ensuring responsible AI practices.</p><p>The paper focuses on using multiplicity-adjusted p-values, controlling for the false discovery rate (FDR), as an aid for co-designing the graph. A family of hypotheses relevant to causal graph construction is identified, including assessing correlation strengths, directions of causal effects, and how well an estimated structural causal model induces the observed covariance structure.</p><p>An iterative flow is described where an initial causal graph is drafted based on expert beliefs about likely causal relationships. The subject matter expert's beliefs, communicated as ranked scores could be incorporated into the control of the measure proposed by Benjamini and Kling, the FDCR (False Discovery Cost Rate). The FDCR-adjusted p-values then provide feedback on which parts of the graph are supported or contradicted by the data. This co-design process continues, adding, removing, or revising arcs in the graph, until the expert and modeller converge on a satisfactory causal structure grounded in both domain knowledge and data evidence.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The current common practice for conducting data science development projects is to kick off with a "Discovery" phase, where the problem is defined. This phase is often conducted in a workshop setting, where the data scientist and the subject matter expert work together to specify the target, postulate potential drivers or features and identify the data sources. Many frameworks specify a 'hypothesis workshop' as part of the kick-off and shaping steps. These sessions are usually conducted before the statistical modeller sees the data and are typically meant as a vehicle for identifying and prioritising relevant data sources. This practice encourages blowing up the list of features to "through" at a model. Automatic feature selection and modelling tools have been developed to address the tsunami of features.</p><p>The increasing reliance on complex models and automated data-mining systems raises important questions about interpretability, inference and correct methodology implementation <ref type="bibr" target="#b21">[Pearl and Mackenzie [2018]</ref>]. For example, <ref type="bibr" target="#b0">Anderson-Cook [2001]</ref> voices a paradigm common to statistical modelling and data mining: perform an automatic variable selection and then allow the expert to overlay the business or physical context. This practice results in models that are not easily explained. Thus also posing a challenge to implementing responsible AI guidelines.</p><p>The issues and concerns above are exacerbated when the models are used to drive decisions and actions. The nature of many challenges in the business and manufacturing worlds is such that it is often impossible to design experiments to cleanly assess the impact of decisions and actions on outcomes. For instance, the Market Mix Methodology (MMM) attempts to attribute success to marketing activities in a world of confounding co-activities and poor data <ref type="bibr" target="#b37">[Woodall [2000]</ref>].</p><p>In cases where experimentation is not possible, there is a risk that misspecification and misuse of confounders will not only result in wrong action-to-outcome impact estimates but could also indicate the wrong direction of effect, as demonstrated by Simpson's paradox. As <ref type="bibr" target="#b22">Peters et al. [2017]</ref> state, "The Simpson's paradox is not so much of a paradox but rather a warning of how sensitive causal reasoning can be with respect to model misspecifications." A robust approach to address these situations is to deploy techniques developed in the field of statistical causality analysis <ref type="bibr" target="#b21">[Pearl and Mackenzie [2018]</ref>].</p><p>Modern statistical causal analysis, exemplified by <ref type="bibr" target="#b21">Pearl and Mackenzie Pearl and Mackenzie [2018]</ref>, begins with the formulation of a causal graph. This approach offers several benefits to the quality and robustness of analysis and decision support. The causal graph serves as an intuitive tool that bridges the knowledge and beliefs of a subject matter expert (SME) with the statistical modeller's data-driven insights. More importantly, <ref type="bibr" target="#b20">Pearl Pearl [2014]</ref> emphasises that mapping causal mediating factors illuminates 'intrinsic properties of reality that have tangible policy implications'. <ref type="bibr" target="#b27">Shmueli [2010]</ref> discusses the tension between the two analysis goals explainability and productiveness.Each has a different starting point and nuances of the methodology used. Specifying correctly a causal graph has the benefit of expalianbility and bringing to the for potential introduction of bias that is not compliant with responsible AI guidelines. Once an explainable model is crafted the statistical modeller may proceed to fit a prediction oriented model guided by the insights of the discovery step. This is in contrast to <ref type="bibr" target="#b5">Breiman [2001]</ref> "Using complex predictors may be unpleasant, but the soundest path is to go for predictive accuracy first, then try to understand why"</p><p>A growing body of research explores graphical methods to visualise and communicate the results of causality analysis. For instance, <ref type="bibr" target="#b15">Hoque and Mueller [2022]</ref> discuss supporting lay users with no specific expertise in machine learning, promoting an interactive approach aimed at "emotionally connecting" the subject matter expert.</p><p>While the field of automatically discovering causal graphs is active <ref type="bibr" target="#b17">[Kaiser and Sipos [2021]</ref>], this paper focuses on an approach to aid discussion between the statistical modeler and the subject matter expert while constructing a causality graph. The discussion explores the formation of a causality graph as a tool to be used during the discovery and exploratory data analysis phase.</p><p>This paper posits that plotting relevant information on a causality graph facilitates discussion between the statistical modeller and the subject matter expert. This approach does not argue for setting aside rigour for the sake of simplifying the discussion. The False Discovery Rate (FDR) or False Discovery Cost Rate (FDCR) is an appropriate measure for introducing multiplicity considerations in an intuitive way. Figure <ref type="figure" target="#fig_0">1</ref> demonstrates that this type of presentation is self-explanatory and suitable for both systematic-level discussions with subject matter experts and modelling-level discussions with trained statisticians. This paper proposes an approach to guide the construction of a causality graph that will underpin inference, estimation, and predictions. For simplicity but without loss of generality, the approach describes stepwise crafting of a Structural Equation Model (SEM) or Structural Causal Model (SCM) where the adjustment of the False Discovery Rate (FDR) is deployed as an aid and guide <ref type="bibr" target="#b1">[Benjamini and Hochberg [1995]</ref>].</p><p>The paper starts with discussing which hypotheses are relevant to the codesign of a causality graph (Section 2). Once a family of hypotheses is defined, Section 3 describes the control of the False Discovery Rate (FDR) and its generalisation to FDCR using costs of false alarms. Section 4 demonstrates the use of such adjustment in the construction of a Structural Causal Model (SCM) using a toy example. The paper concludes with Section 5, touching on thoughts not explored here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Identifying the Family of Hypotheses</head><p>This paper follows a paradigm of collaboratively working with subject matter experts (SMEs) to translate their expertise and experience into a hypothesised causality graph. It is natural to transform this process into a set of hypotheses that reflect the SME's beliefs. The next logical step is applying some multiplicity control. The False Discovery Rate (FDR) is a natural multiplicity measure for this setting.</p><p>Before delving into multiplicity error measures and their control, it is important to define the family of hypotheses and understand the co-dependence between the hypotheses, the statistics, and the resulting p-values. <ref type="bibr" target="#b6">[Bromberg et al. [2009]</ref>] discuss using Pearl's theorems on the properties of conditional independence relations <ref type="bibr" target="#b19">[Pearl [1988]</ref>] and avoiding the execution of some statistical tests to reduce the computational load. A note of caution: avoiding calculating the test does not exclude the hypotheses from the family if it is pertinent to structuring the causality graph unless the correlation to another hypothesis to another hypothesis is 1.</p><p>In the context of assessing of a causality graph, hypotheses are postulated based on SME's experience, their prior beliefs, and suggestions derived from explanatory analysis. As <ref type="bibr" target="#b23">Peña [2008]</ref> points out, the hypotheses focus on the discovery of edges in the Directed Acyclic Graph (DAG).</p><p>The identification of the relevant hypothesis is somewhat derived from the typical co-design process. Note how the choice of modelling is incorporated here:</p><p>1. Identify the outcomes of interest and decisions that are likely to affect the outcomes 2. Use the Six Sigma fish-bone diagram to list potential drivers of the outcomes 3. Obtain, clean, and prepare data for the information listed in the fish-bone diagram 4. Calculate the correlations and their corresponding p-values (The null hypothesis for each pair is that there is no correlation or co-dependence)</p><p>5. Assign a causal direction to each pair (could also be 'no causal relationship') 6. Assign a belief score to each postulated causal relationship.  <ref type="formula" target="#formula_5">7</ref>) are the same as seen in ( <ref type="formula">4</ref>). This is in line with the field of structure learning. For example, <ref type="bibr" target="#b11">Gasse et al. [2015]</ref> advise that a DAG should be as close as possible to the global dependence structure</p><p>Step ( <ref type="formula">8</ref>) is linked notionally to the definition of faithfulness. A graph is faithful to some distribution if the graph connectivity represents exactly the dependencies and independences dictated by the distribution (see for instance, <ref type="bibr" target="#b6">Bromberg et al. [2009]</ref>.)</p><p>Moreover, rather than examining the correlations, it makes sense to work with covariances so that the direction is also considered.</p><p>The hypotheses in ( <ref type="formula">8</ref>) are an important feedback to the co-design process as 'unattended' correlations would be highlighted. However, the way (8) is formulated above results in counter-intuitive p-values (big is good) and does not really prove the SCM is reflecting the covariances and variances. Rather, it only shows that there is no evidence to refute that it does. ( <ref type="formula">8</ref>) should be couched similarly to equivalence testing, where the null hypotheses are that the covariances and variances induced by the SCM are different from the observed correlations:</p><formula xml:id="formula_0">H i 0 : |ρ i scm -ρ i data | ≥ δ<label>(1)</label></formula><formula xml:id="formula_1">H i 1 : |ρ i scm -ρ i data | &lt; δ (2)</formula><p>Where, for n variables, ρ i data (i = 1, . . . , n(n+1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>) are the observed correlations in the data. ρ i scm (i = 1, . . . , n(n+1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>) are the matching correlations induced by the SCM and δ is a threshold parameter. It is customary to form the above as two one-sided hypothesis tests with two p-values that should be small if the two measures are similar.</p><p>Examining the p-values in ( <ref type="formula" target="#formula_5">7</ref>) and ( <ref type="formula">8</ref>) informs suggested changes to the causality graph. Steps ( <ref type="formula" target="#formula_5">7</ref>) and ( <ref type="formula">8</ref>) are repeated until the Modeller and the SME are satisfied. Thus, multiplicity of hypothesis control is called for. As the process could be viewed as a screening process where the proportion of true null hypotheses is small, the control of the False Discovery Rate (FDR) is appropriate. I.e., the p-values reviewed during the process should be FDR adjusted. We propose that due to the consistency property of the FDR adjustment, it is sufficient to consider the adjustment for each iteration separately. Moreover, the FDR adjustment provides a mechanism for inclusion of the belief scores where they can define the weights for a weighted FDR adjustment.</p><p>Another source of hypotheses comes from the field of causality structure learning where conditional independence tests underpin a stepwise (forward or backward) causality graph construction. This paper is concerned with "manual" co-design of the causality graph rather than an automated, data-driven algorithm. Thus, the hypotheses in ( <ref type="formula">8</ref>) are sufficient for driving and informing the discussion between the SME and the Statistical Modeller, although not as nuanced as the conditional independence tests.</p><p>It is important to understand the correlation structure among all the p-values used, as some of the procedures for the control of the FDR (e.g. the Bejamini-Hochberg procedure <ref type="bibr" target="#b1">[Benjamini and Hochberg [1995]</ref>]), control the FDR only under independence or under Positive Regression Dependence (PRDS). In cases where complex correlations are suspected, it is possible to use the Benjamini-Yekutieli algorithm <ref type="bibr" target="#b4">[Benjamini and Yekutieli [2001]</ref>] or bootstrap as demonstrated by <ref type="bibr" target="#b38">Yekutieli and Benjamini [1999]</ref> using the foundations laid by <ref type="bibr" target="#b35">Westfall and Young [1992]</ref>.</p><p>A nuance of the above requirement for independence or at least PRDS is that it is sufficient to show it for the true null hypothesis. As the hypotheses pertain to the existence of a causal effect manifested by conditional dependence, the true null hypotheses that could be interdependent are those considering the same edge. Thus, there might be a correlation for the p-values assessing the coefficient for modelling an edge and the p-value for the correlation induced by the SCM for that edge. Arguably, they are measuring overlapping constructs and thus are PRDS. However, the hypotheses in (8) are formulated as an equivalence between the correlation structure induced by the SCM and the observed correlation. For a world where A does not directly cause B, the true causality graph will not have an edge linking nodes A and B (edge AB ). For an SCM containing an edge AB, the hypothesis that the coefficient for the regression of B on A is zero is true. However, the hypothesis that the induced correlation between A and B is equivalent to the observed could be true or false as the correlation may be induced. Simple cases where a null coefficient is fully informative of the existence of the correlation can be constructed. Arguably these are simple cases where a model crafting session is not required. Therefore, the p-values considered here could be treated as independent or PRDS.</p><p>For illustration purpose, consider a simple causality Graph with one mediator T → M; T → O; M → O. Assuming T, M &amp; O are continuous and the functional form linking them is linear, the Structural Equation Model (SEM) could be:</p><formula xml:id="formula_2">M = β 0 + β 1 T + ε 1 (3) Ŷ = β 2 + β 3 T + β 4 M + ε 2 (4)</formula><p>Where</p><formula xml:id="formula_3">ε j ∼ N (0, σ j ); j = 1, 2</formula><p>The hypotheses of interest are:</p><p>(i) H P arms 0,i</p><p>:</p><formula xml:id="formula_4">β i = 0; H P arms 1,i : β i ̸ = 0; ∀i ∈ {0, 1, 2, 3, 4} (ii) H N oise 0,j : ε j ∼ N (0, .); H N oise 1,j : ε j ̸ ∼ N (0, .); ∀j ∈ {1, 2} (iii) H Cov 0,x,y : |SEM induced Cov(x,y) -observed Cov(x,y)| &gt; δ; H Cov 1,x,y : |SEM induced Cov(x, y) -observed Cov(x, y)| ≤ δ; ∀x, y ∈ {T, M, Y } -upper triangle &amp; diagonal</formula><p>(i) asserts that the coefficients are not zero. For simple linear modelling, the p-values could be theoretically derived; (ii) tests the assumption that the noise is Gaussian distributed. This could be tested using a Chi-square test. It could be argued that the roles of H 0 and H 1 should be flipped, posing a challenge of testing for "non-normality".</p><p>The process we describe is iterative. At each step, edges could be added or removed and the coefficients refitted (either backwards or forwards construction). It could be argued that the hypotheses of all the steps should be considered as one family. The consistency property of the FDR (when Number of True null hypotheses: n 0 ≪ Number of false null hypotheses: n 1 ) allows for working within iteration. Thus circumventing confusion due to having several p-values generated for the same hypothesis. Therefore, It is sufficient to control the FDR within each iteration.</p><p>Before providing an example for the process, the FDR and the False Discovery Control Rate (FDCR) and their control are discussed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">False Discovery [Cost] Rate</head><p>This section is based on technical papers by <ref type="bibr" target="#b3">Benjamini and Kling [2005]</ref> and <ref type="bibr" target="#b18">Kling [2005]</ref>.</p><p>When testing several hypotheses simultaneously to reach an overall decision, there is a trade-off between controlling the type I error for per-hypothesis considerations and the overall hypothesis, which is usually their union. This issue of balancing error rates is known as the Multiplicity Problem. This dilemma is encountered almost universally where statistics are applied. Some of the most prominent statisticians have addressed it. However, there is neither a common nor global approach. For instance, <ref type="bibr" target="#b33">Tukey [1994]</ref> discussed a special case of the problem, pairwise comparisons. He continued discussing it as late as 1991 <ref type="bibr" target="#b32">[Tukey [1991]</ref>]. An extensive overview of the research of the Multiplicity problem may be found in <ref type="bibr" target="#b14">Hochberg and Tamhane [1987]</ref>, <ref type="bibr" target="#b35">Westfall and Young [1992]</ref>, <ref type="bibr" target="#b1">Benjamini and Hochberg [1995]</ref>, <ref type="bibr" target="#b16">Hsu [1996]</ref>, and <ref type="bibr" target="#b36">Westfall et al. [1999]</ref>. <ref type="bibr" target="#b35">Westfall and Young [1992]</ref> demonstrated this: "For example, a particular survey may identify a small p-value, say p = .005, and claim that the associated effect is 'statistically significant.' This p-value is interpretable as follows: when there is no causal basis for the effect, there is only a 0.5% probability of observing a result as extreme as the observed result. On the other hand, it is possible that the multiplicity adjusted p-value is .15 (Adj-p = .15), which is not statistically significant. This adjusted p-value incorporates the multiple tests performed and can be interpreted as follows: when there is no causal basis for any effect tested, there is a 15% chance that somewhere in the experiment a result as extreme as the observed result of .005 will appear."</p><p>Classical procedures aim to control the probability of committing at least one type-I error when considering a family of hypotheses simultaneously to control the multiplicity effect. The control of this Familywise Error Rate (FWE, see Equations 5 &amp; 6) is usually required in the strong sense (Equation <ref type="formula">5</ref>), i.e., under all configurations of true and false hypotheses <ref type="bibr" target="#b14">[Hochberg and Tamhane [1987]</ref>]. The main problem with classical methods is that they tend to have low power. Consequently, it has been argued that no special control is needed (e.g.</p><p>[ <ref type="bibr" target="#b24">Rothman [1990]</ref>, <ref type="bibr" target="#b25">Saville [1990]</ref>]).</p><p>An alternative, more powerful measure was introduced by Benjamini and Hochberg <ref type="bibr">[1995]</ref>: the False Discovery Rate (FDR, Equation <ref type="formula" target="#formula_5">7</ref>). It is an appropriate error rate to control in many problems where the (strong) control of the FWE is not needed. The FDR is the expected ratio of the number of erroneous rejections to the number of rejections (discoveries) and is equal to or less than the FWE. The two error rates are equal when the number of true null hypotheses (m 0 ) equals the number of hypotheses under test (m). When m 0 &lt; m, the FDR may be substantially lower than the Familywise Error Rate, so an FDR controlling procedure at conventional levels can be more powerful. <ref type="bibr" target="#b1">Benjamini and Hochberg [1995]</ref> provided a linear step-up procedure (BH) that controls the FDR for independent test statistics. <ref type="bibr" target="#b4">Benjamini and Yekutieli [2001]</ref> showed that when the test statistics are PRDS correlated, the BH procedure controls the FDR. Furthermore, they introduced a resampling-based procedure that controls the FDR <ref type="bibr" target="#b38">[Yekutieli and Benjamini [1999]</ref>].</p><p>A useful aspect of the BH procedure is that it provides quite consistent discoveries when applied to subsets of the family of hypotheses. For example, when evaluating individual hypotheses pertaining to enumeration districts, the family could be the whole of the United States or just a specific state. FWE control procedures usually will provide conflicting individual decisions for the different hypotheses families, whereas the FDR control will generate consistent discoveries when m 0 ≪ m. <ref type="bibr" target="#b8">Efron et al. [2001]</ref>, <ref type="bibr" target="#b7">Efron and Tibshirani [2002]</ref>, <ref type="bibr" target="#b29">Storey [2002]</ref>, and <ref type="bibr">Tang and</ref><ref type="bibr">Zhang [2005, 2007]</ref> frame the control of the FDR using a Bayesian paradigm. This approach allows the discussion of a prior belief on the probability that the null hypothesis is correct. This is somewhat related to the discussion in this paper of assisting experts in mapping out their beliefs on causality. Following the notation used by <ref type="bibr">Benjamini and</ref><ref type="bibr">Hochberg [1995, 1997]</ref> and <ref type="bibr" target="#b3">Benjamini and Kling [2005]</ref>: For a composition of m sub-hypotheses (H 0i ; i = 1, 2, . . . , m) let the intersection hypothesis be H 00 = m i=1 H 0i . Let R i (i = 0, 1, 2, . . . , m) be 1 if H 0i is rejected and zero otherwise; and let V i (i = 0, 1, 2, . . . , m) be 1 if H 0i is erroneously rejected and zero otherwise. Note, if H 0i is true then V i = R i . Furthermore, let the number of rejections ("Discoveries") be R = m i=1 R i , and the number of erroneous rejections be V = m i=1 V i . Note that R and V do not include R 0 and V 0 . Let I R = 1 when R &gt; 0 otherwise I R = 0. Similarly, I V = 1 when V &gt; 0 otherwise I V = 0. To complete the notation used in this paper, define I 0 as the set of indices of the true null sub-hypotheses (I 0 = {j; H 0j is true, 1 ≤ j ≤ m}); and the number of true null sub-hypotheses is m 0 = ||I 0 ||.</p><p>The family error measures could be defined using the above terms:</p><formula xml:id="formula_5">Strong-FWE = P (V &gt; 0) = E[max V j ; 1 ≤ j ≤ m] (5) Weak-FWE = E[V 0 ] = E[V 0 /R 0 ] (6) FDR = E[V /R]<label>(7)</label></formula><formula xml:id="formula_6">Weighted FDR = WFDR = E m i=1 w i V i m i=1 w i R i (8)</formula><p>where V /R and V 0 /R 0 are defined as zero when V = R = 0 and V 0 = R 0 = 0 respectively.</p><p>The FWE is appropriate when even one erroneous discovery is not desired. Procedures such as the Bonferroni procedure, Holm's procedure, Hochberg's Procedure <ref type="bibr" target="#b13">[Hochberg [1988]</ref>], and Tukey's T-method for pairwise comparisons <ref type="bibr" target="#b33">[Tukey [1994]</ref>], all control the FWE in the strong sense (Equation <ref type="formula">5</ref>). This type of control is relevant to situations where any erroneous discovery implies a very high cost. For example, such conservativeness is required when examining the primary end-points during Phase III clinical trials.</p><p>Control of the FWE in the weak sense (Equation <ref type="formula">6</ref>) is achieved by testing directly the intersection null hypothesis (and not controlling the individual hypothesis). For instance, by using the multivariate Hotelling T 2 statistic. Thus, the overall type I error rate is controlled only when all the sub-hypotheses are true (m 0 = m). This situation is very common in Statistical Process Control (SPC); where once an out-of-control signal is given (the intersection hypothesis is rejected) it is assumed that it is no longer necessary to protect from erroneous sub-discoveries, and on the other hand increased power is desired.</p><p>Generally, the use of the FDR (Equations 7 &amp; 8) is appropriate in situations where high power is imperative and a pre-specified percent of the wrongly rejected (individual) hypotheses is tolerable and does not affect the quality of the overall decision. This is usually characterised by the belief that m 0 ≪ m. The FDR may be used in pilot or screening studies, grouping analysis, and situations where many variables are considered such as data-mining and Bioinformatics. In such situations, the error from a single erroneous rejection is not always as crucial for drawing conclusions for the family hypothesis. Thus, we are ready to bear more errors when many hypotheses are rejected, but with less when fewer are rejected. The last notion is reflected by the control of the FDR -for which one must specify the acceptable expected proportion of wrong discoveries. For an example, see <ref type="bibr" target="#b12">Grigg and Spiegelhalter [2008]</ref> for a review of papers that proposed adopting the FDR for multiple CUSUM charts.</p><p>Though widely researched, there are no clear-cut rules for which error measure to use and what multiplicity control procedure to use. <ref type="bibr" target="#b3">Benjamini and Kling [2005]</ref> and <ref type="bibr" target="#b18">Kling [2005]</ref> argued that this decision is part of the modelling process. They show that in situations where costs or weights can be attributed to erroneous discoveries, the weak-FWE and the FDR are special cases of a generic cost-based error measure, the False Discovery Cost Ratio (FDCR, Equations 10). They show that the W-BH procedure <ref type="bibr" target="#b2">[Benjamini and Hochberg [1997]</ref>] keeps its control also when the test statistics are PRDS ON I 0 and propose a procedure for the control of the FDCR when the test statistics are PRDS.</p><p>Assigning variable cost of C i (i = 0, 1, 2, . . . , m) of an individual erroneous discovery (e.g., rejecting H 0i results in stopping machine i for maintenance) and a fixed cost C 0 for the overall discovery (rejecting H 00 results in calling in an engineer), the cost of false discoveries is</p><formula xml:id="formula_7">C 0 I V0 + m i=1 C i V i .</formula><p>In the spirit of the FDR and using the above notation, the expected proportion of the cost of false discoveries is:</p><formula xml:id="formula_8">E C 0 I V0 + m i=1 C i V i C 0 I R0 + m i=1 C i R i ≤ E C 0 I V + m i=1 C i V i C 0 I R + m i=1 C i R i ,<label>(9)</label></formula><p>where the proportion is zero when the denominator is zero and I R = I {R&gt;0} and I V = I {V &gt;0} . <ref type="bibr" target="#b3">Benjamini and Kling [2005]</ref> define the False Discovery Cost Rate as the expected ratio of the cost wasted due to erroneous discoveries to the total cost related to the discoveries:</p><formula xml:id="formula_9">FDCR = E C 0 I V0 + m i=1 C i V i C 0 I R0 + m i=1 C i R i = E m i=0 C i V i m i=0 C i R i ,<label>(10)</label></formula><p>where the proportion is to be defined as zero when the denominator is zero. The Weak FWE, the FDR, and the W-FDR are special cases of this measure obtained by specific structures of the costs. When C 0 = 0 the FDCR is the W-FDR. The FDR is obtained by further assigning equal costs to the m hypotheses. On the other hand, when the cost consists only of C 0 the FDCR is the FWE in the weak sense.</p><p>It is interesting to examine the meaning of controlling the FWE in the strong sense from the viewpoint of the FDCR. Seeking to control the probability of making any false rejection suggests that every erroneous discovery is very costly and perceived as infinite. Thus, the Strong-FWE can be approximated by the FDCR, but it cannot be expressed in the context of additive costs. The Strong-FWE may be expressed in terms of "relative cost", E max (vi)  max(Ri , which does not render itself easily to economic interpretation. <ref type="bibr" target="#b3">Benjamini and Kling [2005]</ref> propose testing simultaneously H 00 and the rest of the sub-hypotheses, using the FDCR to correct for multiplicity. In particular, testing H 00 through Hotelling's T 2 , weighted Simes' statistic (Equation <ref type="formula">11</ref>), and Fisher's statistic (Equation <ref type="formula" target="#formula_11">12</ref>)</p><formula xml:id="formula_10">P ws = min j m i=1 c i j i=1 C (i) P (j) .</formula><p>(11)</p><formula xml:id="formula_11">P F = -2 m i=1 ln p i .<label>(12)</label></formula><p>They showed that an FDCR controlling procedure could be constructed by applying the W-BH procedure to the m + 1 p-values P 0 , P 1 , . . . , P m , where the weighted Simes adjusted p-value for P (corresponding to H 00 ) is used. Thus, the control of the FDCR could be achieved when the p-values associated with the m 0 true hypotheses are independent or PRDS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Constructing a Causality Graph while controlling the FDR</head><p>The process of constructing a causality graph and a statistical model should involve a statistically trained data scientist and a subject matter expert (SME) working through a process similar in spirit to variable selection. They identify the target variables, potential explanatory variables, and assign beliefs to the direction of causality. These beliefs could be expressed as a score. Then the statistician prepares the data for analysis and iteratively constructs the causality graph and models with the SME. Foygel- <ref type="bibr" target="#b9">Barber and Candès [2015]</ref> propose an approach for variable selection in linear models that controls the False Discovery Rate (FDR) where the discoveries are the selected variables to be included in the model. They point out that in many practical situations, there are only a few relevant variables among the many recorded. It makes sense to view the process of constructing the causality graph as a systematic screening of variable selection hypotheses pertaining to strengths of relationships and direct and indirect causality effects.</p><p>To illustrate such a process, a synthetic example was generated. The demonstration will iteratively create a Structural Causality Model where feedback to the SME is a graphical representation overlaid with the False Discovery Cost Rate (FDCR) adjusted p-values. The toy example describes an offshore wind farm operator who decides how fast to allow the turbine to turn. The key causality relationships of interest are "Rotational RPM" → "Energy Yield" and "Rotational RPM" → "Perceived Noise". Appendix A describes the construction of the toy example. The univariate exploratory analysis kicks off the co-design process, facilitating conversations between the statistician and the SME. The next step is to evaluate the pairwise relationships.  <ref type="bibr" target="#b4">[Benjamini and Yekutieli [2001]</ref>].  Reviewing the correlations and the adjusted is a good starting point for designing the first draft causality graph and attributing the SME's belief. For this example, the belief is scored simply: 0. As an SME, I do not believe there is a causal relationship between the two variables -this is implicit by not drawing an arc in the causality graph 1. As an SME, I am not sure whether there is a causal relationship between the two variables 2. As an SME, I believe there is a causal relationship between the two variables 3. As an SME, I am sure there is a causal relationship between the two variables The C i weights for the FDCR are set to 1/(belief + 0.0001). All unprovided weights, such as for the tests for the intercept and C 00 (Weighted Simes), are set to 1.</p><p>Assume the SME provides the following beliefs:   The next iteration takes into account that:</p><p>• The estimate for Strength degradation → Rotational RPM is practically zero, albeit statistically significant.</p><p>• The covariance between sea temperature and Perceived noise generated by the model is not equivalent to the measured relationship.</p><p>• The covariance between wind speed and Perceived noise generated by the model is not equivalent to the measured relationship.</p><p>After several iterations, the model could look as presented in Figures <ref type="figure" target="#fig_5">5</ref> and<ref type="figure">6</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper demonstrated how the FDR and FDCR could be put to use in the context of co-designing a causality graph in the discovery step of an analytical project.</p><p>This approach favours hand crafting the causality graph but does not preclude using concepts and tools developed for automatic causality discovery. The use of FDR control during model discovery has been proposed by several researchers. For example, algorithms such as FDR-IAMB <ref type="bibr" target="#b23">[Peña [2008]</ref>] and FDR-IAPC <ref type="bibr" target="#b10">[Gasse et al. [2014]</ref>] &amp; <ref type="bibr" target="#b11">[Gasse et al. [2015]</ref>] apply techniques for controlling the multiplicity of hypotheses. These algorithms aim to learn the structure of the causality graph from the data and use FDR control as a weighting for a greedy algorithm.</p><p>The primary focus lies in facilitating communication between statistical modellers and subject matter experts (SMEs) by balancing statistical rigour with clear and intuitive presentation of results. One potential improvement would be to replace p-values with e-values as suggested by <ref type="bibr" target="#b26">Shafer [2021]</ref>] and <ref type="bibr" target="#b34">Wang and Ramdas [2022]</ref>.</p><p>While the example used employs linear regression for modelling causal relationships, the discussion is not limited to this specific functional form. Statistical modellers have the flexibility to choose the modelling approach for conditional probabilities and select appropriate measures of variable (parent node) contribution. For instance, a random forest might be used as the functional representation, with variable importance as the contribution measure.</p><p>The hypothesis testing framework described could be generalised. Instead of focusing on a specific parameter value, the null hypothesis could be formulated as: "the parent variable does not contribute to modelling the child." In this case, a nested bootstrap procedure is recommended by <ref type="bibr" target="#b35">Westfall and Young [1992]</ref> and <ref type="bibr" target="#b4">Benjamini and Yekutieli [2001]</ref>:</p><p>1.</p><p>[Outer] Bootstrap a distribution of p-values and performs FDR adjustment.</p><p>2.</p><p>[Inner] Bootstrap a distribution of contribution measures or regression parameters for deriving p-values.</p><p>When using Bootstrap to obtain the distribution of the p-values. Careful thought should be given to ensuring the correlation structures under the appropriate null hypotheses is maintained.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of presenting a causality graph overlaid with parameter estimates and FDR-corrected p-values</figDesc><graphic coords="3,168.14,422.52,274.97,169.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>the causality graph defined by (4) &amp; (5), fit a Structural Causal Model (SCM). This naturally defines a sub-family of hypotheses: (a) The model does not explain the data (tested with a set of fit statistics) (b) The model coefficients are zero (c) The mean of the residuals is zero (could also hypothesise on the variance of the residuals) 8. A further set of hypotheses are based on the assertion that the correlations induced by the SCM in (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2</head><label>2</label><figDesc>Figure 2 sets the legend for the graphical representation of the results. The estimates and FDCR adjusted p-values are presented alongside the edges. The non-significant adjusted p-values are highlighted as those mark where the SME and statistician should focus their discussion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Legend used for presenting the SCM fitting results</figDesc><graphic coords="14,202.51,264.28,206.22,139.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: First modeling iteration -SCM effects</figDesc><graphic coords="14,133.77,501.71,343.70,94.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Model results after a few design iterations -SCM effects</figDesc><graphic coords="15,133.77,507.00,343.71,113.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="16,133.77,124.80,343.71,188.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Table 1 lists the variables the SME suggested could have bearing on the outcome. 20,000 observations were generated. Variables that might have bearing on the 'Financial Outcome'</figDesc><table><row><cell>Variable</cell><cell>Description</cell></row><row><cell>Winter Ind</cell><cell>1 if winter season, 0 otherwise</cell></row><row><cell>Sea Temperature</cell><cell>Water surface temperature</cell></row><row><cell>Wind Speed</cell><cell>Wind speed measured at a specified height &amp; lo-</cell></row><row><cell></cell><cell>cation</cell></row><row><cell>Strength Degradation</cell><cell>Mechanical degradation of the bearings</cell></row><row><cell>Rotational RPM</cell><cell>Action variable -an operational decision</cell></row><row><cell>Energy Yield</cell><cell>Output to maximize</cell></row><row><cell>Perceived Noise</cell><cell>Outcome of interest to keep under a threshold.</cell></row><row><cell></cell><cell>Calculated as per relevant ISO and regulations</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Table 2 lists the Pearson pairwise correlations, and Table 3 lists the FDR adjusted (BH adjusted) p-values obtained through bootstrapping the Pearson R 2</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Pearson pairwise correlations</figDesc><table><row><cell></cell><cell>Winter Ind</cell><cell>Sea Temper-</cell><cell>Wind Speed</cell><cell>Strength</cell><cell>Rotational</cell><cell>Energy</cell><cell>Perceived</cell></row><row><cell></cell><cell></cell><cell>ature</cell><cell></cell><cell>Degrada-</cell><cell>RPM</cell><cell>Yield</cell><cell>Noise</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>tion</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Winter Ind</cell><cell>1.00</cell><cell>-0.92</cell><cell>0.67</cell><cell>-0.00</cell><cell>0.67</cell><cell>0.28</cell><cell>-0.62</cell></row><row><cell>Sea Temper-</cell><cell>-0.92</cell><cell>1.00</cell><cell>-0.62</cell><cell>0.01</cell><cell>-0.61</cell><cell>-0.25</cell><cell>0.57</cell></row><row><cell>ature</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wind Speed</cell><cell>0.67</cell><cell>-0.62</cell><cell>1.00</cell><cell>0.00</cell><cell>0.99</cell><cell>0.41</cell><cell>-0.93</cell></row><row><cell>Strength</cell><cell>-0.00</cell><cell>0.01</cell><cell>0.00</cell><cell>1.00</cell><cell>0.00</cell><cell>-0.01</cell><cell>-0.00</cell></row><row><cell>Degrada-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>tion</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Rotational</cell><cell>0.67</cell><cell>-0.61</cell><cell>0.99</cell><cell>0.00</cell><cell>1.00</cell><cell>0.42</cell><cell>-0.91</cell></row><row><cell>RPM</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Energy</cell><cell>0.28</cell><cell>-0.25</cell><cell>0.41</cell><cell>-0.01</cell><cell>0.42</cell><cell>1.00</cell><cell>-0.38</cell></row><row><cell>Yield</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Perceived</cell><cell>-0.62</cell><cell>0.57</cell><cell>-0.93</cell><cell>-0.00</cell><cell>-0.91</cell><cell>-0.38</cell><cell>1.00</cell></row><row><cell>Noise</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell cols="5">: FDR adjusted bootstrapped p-values for R2</cell><cell></cell></row><row><cell></cell><cell>Sea Tem-</cell><cell>Wind</cell><cell>Strength</cell><cell>Rotational</cell><cell>Energy</cell><cell>Perceived</cell></row><row><cell></cell><cell>perature</cell><cell>Speed</cell><cell>Degrada-</cell><cell>RPM</cell><cell>Yield</cell><cell>Noise</cell></row><row><cell></cell><cell></cell><cell></cell><cell>tion</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Winter</cell><cell>0</cell><cell>0</cell><cell>0.6837</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Ind</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sea Tem-</cell><cell></cell><cell>0</cell><cell>0.5250</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>perature</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wind</cell><cell></cell><cell></cell><cell>0.8323</cell><cell>0</cell><cell>0</cell><cell>0.704</cell></row><row><cell>Speed</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Strength</cell><cell></cell><cell></cell><cell></cell><cell>0.8865</cell><cell>0.575</cell><cell>0.8865</cell></row><row><cell>Degrada-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>tion</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Rotational</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell>0</cell></row><row><cell>RPM</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Energy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell></row><row><cell>Yield</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>I would like to thank <rs type="person">Professor Yoav Benjamini</rs> for his valuable contributions to the original research and for granting permission to use material from our technical paper.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Toy Example Generation</head><p>The data example is deliberately simple, using mainly Gaussian relationships and a variable that is not really participating in the system.</p><p>The example simulates the decision of how fast to turn a wind turbine, where the outcomes are energy produced and perceived noise. It is loosely based on research by <ref type="bibr" target="#b28">Staffell and Green [2014]</ref>, who state: "By accounting for individual site conditions we confirm that load factors do decline with age, at a similar rate to other rotating machinery. Wind turbines are found to lose 1.6 ± 0.2% of their output per year, with average load factors declining from 28.5% when new to 21% at age 19. This trend is consistent for different generations of turbine design and individual wind farms. This level of degradation reduces a wind farm's output by 12% over a twenty year lifetime, increasing the levelised cost of electricity by 9%."</p><p>The variables in the toy example are generated as follows:</p><p>Where N (µ, σ) denotes a normal distribution with mean µ and standard deviation σ.</p><p>Note:</p><p>• Rotational RPM is measured in thousands (i.e., the actual RPM is 1000 times the value used in the model).</p><p>• Energy Yield is measured in Cent/kWh.</p><p>• Perceived Noise is an arbitrary scale.</p><p>The toy example was developed using Python and used capabilities provided by the DoWhy project [<ref type="url" target="https://github.com/py-why/dowhy">https://github.com/py-why/dowhy</ref>].</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Understanding the influence of several factors on a cylindrical response</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Anderson-Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Quality Technology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="180" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate: a practical and powerful approach to multiple testing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="289" to="300" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiple hypotheses testing with weights</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scandinavian Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="407" to="418" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A cost-based approach to multiplicity control</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">E</forename><surname>Kling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Tel Aviv University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The control of the false discovery rate in multiple testing under dependency</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yekutieli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1165" to="1188" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Statistical modelling: The two cultures</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="199" to="215" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient markov network structure discovery using independence tests</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bromberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Margaritis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Honavar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="449" to="484" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Empirical bayes methods and false discovery rates for microarrays</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetic Epidemiology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="70" to="86" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Empirical bayes analysis of a microarray experiment</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Storey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tusher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">456</biblScope>
			<biblScope unit="page" from="1151" to="1160" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate via knockoffs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Foygel-Barber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2055" to="2085" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A hybrid algorithm for Bayesian network structure learning with application to multi-label learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aussem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Elghazel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2014.04.032</idno>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="6755" to="6772" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A hybrid algorithm for bayesian network structure learning with application to multi-label learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aussem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Elghazel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05692</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">An empirical approximation to the null unbounded steady-state distribution of the cumulative sum statistic</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Grigg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="501" to="511" />
		</imprint>
	</monogr>
	<note type="report_type">Technometrics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A sharper bonferroni procedure for multiple tests of significance</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="800" to="802" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Multiple Comparison Procedures</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tamhane</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Outcome-explorer: A causality guided interactive visual interface for interpretable algorithmic decision making</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hoque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Multiple Comparisons: Theory and Methods</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Hsu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Chapman and Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Unsuitability of notears for causal graph discovery</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sipos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.05441</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">E</forename><surname>Kling</surname></persName>
		</author>
		<title level="m">Issues of multiple Hypotheses Testing in Statistical Process Control</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Tel-Aviv University, Faculty of Exact Sciences School of Mathematical Sciences Department of Statistics and Operations Research</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Morgan Kaufmann Publishers, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Interpretation and identification of causal mediation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="459" to="481" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The book of why. Penguin Random House UK</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mackenzie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Elements of Causal Inference -foundations and Learning Algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning gaussian graphical models of gene networks with false discovery rate control</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Peña</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="165" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">No adjustments are needed for multiple comparisons</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Rothman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Epidemiology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="46" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multiple comparison procedures: The practical solution</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Saville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="174" to="180" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Testing by betting: A strategy for statistical and scientific communication</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shafer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series A (Statistics in Society)</title>
		<imprint>
			<biblScope unit="volume">184</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="407" to="431" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">To explain or to predict?</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shmueli</surname></persName>
		</author>
		<idno type="DOI">10.1214/10-STS330</idno>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="289" to="310" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">How does wind farm performance decline with age? Renewable Energy</title>
		<author>
			<persName><forename type="first">Iain</forename><surname>Staffell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Green</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="775" to="786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A direct approach to false discovery rate</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Storey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="479" to="498" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Bayes and empirical bayes approaches to controlling the false discovery rate</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Zhang</surname></persName>
		</author>
		<idno>2005-004</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, Rutgers University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Empirical bayes methods for controlling the false discovery rate with dependent data</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">IMS Lecture Notes-Monograph Series</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="151" to="160" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The philosophy of multiple comparisons</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="100" to="116" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">The problem of multiple comparisons</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1953">1994. 1953</date>
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>published posthumously</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">False discovery rate control with e-values</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramdas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="135" to="159" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Resampling-based multiple testing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Westfall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Young</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Multiple Comparisons and Multiple tests using the SAS Systems</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Westfall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Tobias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Wolfinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<pubPlace>Cary, North Carolina</pubPlace>
		</imprint>
		<respStmt>
			<orgName>SAS Institute</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Controversies and contradictions in statistical process control</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Woodall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Quality Technology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="378" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Resampling-based false discovery rate controlling multiple test procedures for correlated test statistics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yekutieli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Planning and Inference</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="171" to="196" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
