<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Causal Transportability for Visual Recognition</title>
				<funder>
					<orgName type="full">DiDi Faculty Research Award, J.P. Morgan Faculty Research Award</orgName>
				</funder>
				<funder>
					<orgName type="full">ONR</orgName>
				</funder>
				<funder>
					<orgName type="full">DARPA SAIL-ON</orgName>
				</funder>
				<funder>
					<orgName type="full">Amazon Faculty Research Award</orgName>
				</funder>
				<funder>
					<orgName type="full">The Alfred P. Sloan Foundation</orgName>
				</funder>
				<funder ref="#_vDVxFMp">
					<orgName type="full">Accenture Research Award</orgName>
				</funder>
				<funder ref="#_YzrZtEe #_xnUKJbW">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">Amazon</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2022-04-26">26 Apr 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chengzhi</forename><surname>Mao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Equal Contribution</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Xia</surname></persName>
							<email>kevinmxia@cs.columbia.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Equal Contribution</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">James</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Rutgers University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junfeng</forename><surname>Yang</surname></persName>
							<email>junfeng@cs.columbia.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Carl</forename><surname>Vondrick</surname></persName>
							<email>vondrick@cs.columbia.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Causal Transportability for Visual Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-04-26">26 Apr 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2204.12363v1[cs.CV]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Visual representations underlie object recognition tasks, but they often contain both robust and non-robust features. Our main observation is that image classifiers may perform poorly on out-of-distribution samples because spurious correlations between non-robust features and labels can be changed in a new environment. By analyzing procedures for out-of-distribution generalization with a causal graph, we show that standard classifiers fail because the association between images and labels is not transportable across settings. However, we then show that the causal effect, which severs all sources of confounding, remains invariant across domains. This motivates us to develop an algorithm to estimate the causal effect for image classification, which is transportable (i.e., invariant) across source and target environments. Without observing additional variables, we show that we can derive an estimand for the causal effect under empirical assumptions using representations in deep models as proxies. Theoretical analysis, empirical results, and visualizations show that our approach captures causal invariances and improves overall generalization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Visual representations underlie most object recognition systems today <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b16">18,</ref><ref type="bibr" target="#b29">31,</ref><ref type="bibr" target="#b43">46]</ref>. By learning from large image datasets, convolutional networks have been able to create excellent visual representations that improve many downstream image classification tasks <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b16">18,</ref><ref type="bibr" target="#b31">33]</ref>. However, central to this framework is the need to generalize to new visual distributions at inference time <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b24">26,</ref><ref type="bibr" target="#b42">44,</ref><ref type="bibr" target="#b44">47,</ref><ref type="bibr" target="#b58">61]</ref>.</p><p>The most popular technique to use representations is to fine-tune the backbone model or fit a linear model on the target classification task <ref type="bibr" target="#b29">[31]</ref>. Although this approach is effective on in-distribution benchmarks, the resulting classifier also inherits the biases from the target dataset. Given the nature of how data is collected, essentially every realistic image dataset will have spurious features, which will impact the generalization of computer vision systems. Specifically, the learned representation will encode features that correspond to spurious correlations found in the training data.</p><p>In this paper, we investigate visual representations for object recognition through the lenses of causality <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b40">42,</ref><ref type="bibr" target="#b41">43]</ref>. Specifically, we will revisit the out-of-distribution image classification task through causal-transportability language <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b17">19]</ref>, which will allow us to formally model both confounding and structural invariances shared across disparate environments. In our context, we will show how different environments select a distinct set of robust and non-robust features in constructing the input dataset. The training environment may tend to select specific nuisances with the given category, creating spurious correlations between the nuisances and the predicted class. In fact, standard classifiers will tend to use those spurious correlations, which analytically explains why they result in poor generalization performance to novel target distributions <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b46">49,</ref><ref type="bibr" target="#b52">55]</ref>.</p><p>First, we will show that the association between image and label is not in generalizable (in causal language, transportable) across domains. We then note that the causal effect from the input to the output, which severs any spurious correlations, is invariant when the environment changes with respect to the features' distributions. This motivates us to pursue to an image classification strategy that will leverage causal effects, instead of merely the association, and will act as an anchor, providing stability across changing conditions and allowing extrapolation to more likely succeed. Getting the causal effect for natural images is challenging because there are innumerable unobserved confounding factors within realistic data. Under some relatively mild assumptions, we will be able to extract the robust features from observational data through both causal and deep representations <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b32">[34]</ref><ref type="bibr" target="#b33">[35]</ref><ref type="bibr" target="#b34">[36]</ref><ref type="bibr" target="#b45">48]</ref>, and then use the representations as proxies for identifying the causal effect without requiring observations of the confounding factors.</p><p>For both supervised and self-supervised representations, our experimental results show that incorporating the causal structure improves performance when generalizing to new domains. Our method is compatible with many existing representations without requiring re-training, making the approach effective to deploy in practice. Compared to the standard techniques to use representations, our causally motivated approach can obtain significant gain on CM-NIST (up to 40% gain), WaterBird (up to 25% gain), ImageNet-Sketch (up to 8% gain), and ImageNet-Rendition (up to 7%) datasets. Our work illustrates the importance of causal quantities in out-of-distribution image classification and proposes an effective empirical method that allows the learning of a classifier robust to domain change. Our code is available at <ref type="url" target="https://github.com/cvlabcolumbia/CT4Recognition">https://github.com/cvlabcolumbia/CT4Recognition</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Causal Inference and Transportability Theory.</p><p>Causal inference provides a principled framework for modeling structural invariances <ref type="bibr" target="#b40">[42]</ref> and the problem of generalizing, or transporting, across environments and changing conditions <ref type="bibr">[8-11, 14, 19, 20, 36, 48]</ref>. A few image generation works have modeled a causal connection between images and their labels, often assuming the labels are generating the images <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b45">48]</ref>, and some prior work studied the connection between causality and specific types of generalizations <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b55">58]</ref>. Our work studies recognition and reverses this direction, on purpose, since we consider that the images generate the labels through a human-labeling process; this model is detailed in Sec. 3. To estimate arbitrary causal effects, one can construct a proxy causal-neural models <ref type="bibr" target="#b53">[56]</ref>, but in this paper we focus on directly computing and optimizing a specific causal estimand. Existing work on this often assumes one can intervene on the data <ref type="bibr" target="#b27">[29,</ref><ref type="bibr" target="#b36">38]</ref> or observe latent confounding factors <ref type="bibr" target="#b27">[29,</ref><ref type="bibr" target="#b56">59]</ref>. These assumptions are often overly optimistic for natural images, as image data is passive (preventing intervention) and does not allow us to observe additional confounding factors.</p><p>Out of distribution Generalization in Vision. There are two major types of domain generalization(DG): the multi-source DG and the single-source DG. Multi-source domain generalization has been studied <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b50">53,</ref><ref type="bibr" target="#b57">60]</ref>, where the algorithm knows the domain index which the data points are sampled from. A large number of approaches have been proposed to learn classifiers that generalize to out-of-distribution and new environments <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b23">25,</ref><ref type="bibr" target="#b42">44,</ref><ref type="bibr" target="#b52">55,</ref><ref type="bibr" target="#b58">61]</ref>. In practice, however, it is often challenging to collect images with accurate domain labels, such as from the Internet. Single domain generalization <ref type="bibr" target="#b22">[24]</ref> does not require the domain index assumption, where all training data are assumed to be sampled from the same domain. [40], adversarial self-challenging <ref type="bibr" target="#b25">[27]</ref>, and generative data augmentations <ref type="bibr" target="#b36">[38]</ref>. Recently, the attention operation is also shown to be effective for improving robustness <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b39">41]</ref>. However, a principled framework for modeling generalization to new environments is still missing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem Formulation -Image Recognition Through Causal Lenses</head><p>We start by grounding the problem of image recognition in a causal framework to illustrate the key challenges of out-of-distribution generalization compared to its indistribution counterpart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Structural Modeling of the Classification Task</head><p>Let the pair X, Y represent the random variables related to images and their labels, and x, y the specific instantiations of the pixels and label. Given an input image X = x, the goal of the image classification task is to predict its label, Y = y. Taking a probabilistic interpretation, a standard strategy is to train a model to learn P (Y | X) given data points of X = x and Y = y, and then choose a class at inference time via argmax y P (Y = y | X = x).</p><p>We will take a causal approach here, and model the underlying generative process of X and Y using causal semantics. Specifically, we will use a class of generative processes known as a structural causal model (SCM, for short) <ref type="bibr" target="#b40">[42,</ref><ref type="bibr">Ch. 7]</ref>. Each SCM M encodes a 4-tuple</p><formula xml:id="formula_0">V = {X, Y }, U = {U X , U XY }, F = {f X , f Y }, P (U )</formula><p>, where V is the set of observed variables, in this case, the image (X) and its label (Y ); U represents unobserved variables encoding external sources of variation not captured in the image and the label themselves (more details next); F is the set of mechanisms {f X , f Y }, which determine the generative processes of X and Y such that X ← f X (U X , U XY ) and Y ← f Y (X, U XY ); P (U ) represents a probability distribution over the unobserved variables.</p><p>In particular, we call U XY the "concept vector", as it represents all underlying factors that produce both the core features of the object in image x and its label, y. For example, one instantiation of U XY = u XY may encode the concepts of "flippers" and "wing," which are translated into an image of a "waterbird" when passed into f X . U X represents nuisance factors, such as the background, that affect the generation process of the image. Likewise, f Y may represent someone who is labeling image x and will have a conceptual understanding of waterbird through u XY . One natural, albeit critical observation, is that if f X selects the color "flippers" and the background "water" more likely together, there would be a strong association between these two concepts, given the image. Together, the underlying distribution over P (U XY , U X ) combined with functions f X and f Y induce a distribution over P (X, Y ), which is how the data is generated. The SCM M is almost never observable, and it is in general, in a formal sense, impossible to recover the structural functions (F) and probability over the exogenous variables (P (U )) from observational data alone (P (V )) [7, Thm. 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Modeling In vs. Out-of-Distribution Generalization through Transportability</head><p>When training a classifier for in-distribution problems, both training and test data come from the same domain. In the out-of-distribution case, also known as the transportability problem in the causal inference literature <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b17">19]</ref>, training data may come from a domain π that differs from the test domain, π * . We assume that the labeling process and underlying concepts are consistent across domains (i.e. f Y and P (U XY ) remain the same in both settings), but the generative process of the image X may change (i.e. f * X and P * (U X ) may differ from f X and P (U X ), respectively).</p><p>In general, we do not know the true underlying mechanisms f X , f * X , and f Y , nor can we observe the immeasurably large space of P (U X , U XY ). However, we can represent the structural invariances across domains by leveraging a graphical representation shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The disparities across domains π and π * are usually modeled by a transportability node called S <ref type="bibr" target="#b10">[11]</ref>, which can be interpreted as a switch across domains; i.e., f X will be active if S = 0, and f * X otherwise. For concreteness, consider two different categories of birds, the waterbird and the landbird, between which we want to discriminate. Both bird categories have their own underlying features U XY that cause an annotator to label them as a waterbird or landbird. However, while waterbirds are typically paired with water backgrounds in images generated in the source domain (S = 0), this factor may change in the target domain (S = 1), where waterbirds are now commonly shown in land backgrounds. shows that the causal effect is invariant across settings, i.e., P (Y | do(X)) = P * (Y | do(X)). However, Prop. 3 shows that unlike</p><formula xml:id="formula_1">P (Y | X), P (Y | do(X)) is not identifiable from π-data .</formula><p>In the in-distribution case, the more traditional strategy of learning P (Y |X) is logical, in the sense that it leverages all possible information to maximize the chance of predicting the correct label. However, given the way the data generation process is modeled, it is easy to see why this same strategy fails in the out-of-distribution case. Since only data from domain π is given, we can only train a model on P (Y | X), which does not adequately model P * (Y | X). Proposition 1. Let M and M * be the two underlying SCMs representing the source and target domains, π and π * , and compatible with the assumptions represented in the causal graph in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><formula xml:id="formula_2">Then, P * (Y | X) = P (Y | X).</formula><p>In words, the classifier represented by the quantity P (Y | X), in π, is not transportable across settings and cannot be used to make statements about P * (Y | X), even when everything aside from the mechanism of X (f X ) remains invariant (including the labeler f Y ). Intuitively, this is due to the unobserved confounding, or spurious effects, between X and Y through U XY . By conditioning on X, the variables Y and S become d-connected via the path through U XY , i.e. P (Y | X, S = 0) = P (Y | X, S = 1). This result is also shown pictorially in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>In addition to the spurious effects, X and Y still co-vary due to the direct link X → Y . In other words, the labeling process can be seen as moving unobserved co-variation that goes through U xy to the observed link X → Y . These variations are known as the causal effect of X on Y . Intuitively, one can think of the causal effect P (Y | do(X)) as describing the interventional world where arrows towards X can be thought of as removed. This includes the S-node, which no longer has an influence on X when X is forced to take a certain value, say x. This is promising since if a quantity is not affected by S, that implies that it is invariant across domains. As shown next, this is indeed the case with P (Y | do(X)). Regardless of the change in the mechanism of f * X and P * (U X ), it is guaranteed that the causal effect of X on Y will remain invariant across π and π * . In causal language, P * (Y | do(X)) is transportable across settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Identifiability</head><p>Given that the causal effect is invariant across domains, we consider using P (Y | do(X)) as a surrogate for P * (Y | X) for classification purposes (out-of-distribution), instead of the classifier trained in the source, P (Y | X). That leaves the question of how to identify (and then estimate) this quantity given observational data, P (X, Y ). Unfortunately, this is still not possible in the general case. Proposition 3. Let M be the SCM representing domain π and described through the causal diagram G in Fig. <ref type="figure" target="#fig_0">1</ref>. The interventional distribution P (Y | do(X)) is not identifiable from G and the observational distribution P (X, Y ).</p><p>In words, non-identifiability suggests that there are multiple SCMs that are consistent with P (X, Y ) and that induce different distributions P (Y | do(X)). This means that P (X, Y ) is too weak, in some sense, and it is too underspecified to allow one to deduce P (Y | do(X)). Additional assumptions are needed to identify (and then estimate) this causal effect.</p><p>In fact, some prior work has assumed that all back-door variables can be observed <ref type="bibr" target="#b40">[42,</ref><ref type="bibr">Sec. 3.3.1]</ref>, which means that all the variations represented originally in the unobserved confounder U xy are, in some sense, captured by the model. When additional domain index information is available (e.g. styles of the images), prior works such as IRM <ref type="bibr" target="#b3">[4]</ref>, MLLD <ref type="bibr" target="#b38">[40]</ref>, and DANN <ref type="bibr" target="#b0">[1]</ref> have performed adjustment-like operations with the domain index. In most image datasets that contain only images and their labels, the assumption that all back-door variables (and sources of co-variation) are observable is overly stringent. Even when additional data is available, it is unlikely that such data contains all possible variations encapsulated by the concept vector. Our goal now is to identify the effect of X on Y without having knowledge of the back-door variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Neural Representation Approach to Deriving a Causal Estimand</head><p>Following the previous understanding that P (Y | do(X)) is a suitable proxy for the classifier in the target domain, P * (Y |X), we discuss in this section sufficient assumptions that would allow us to estimate such a quantity. Further, we discuss methods that could allow the practical realizability of these assumptions in the context of image recognition. To realize the goal of estimating the target causal effect, we build two neural network models: P (R | X), which generates visual representations R from images X, and P (Y | R, X), which uses both R and X to classify Y . We make the following assumptions about the structure of image X and the properties of these networks: Assumption 1 (Decomposition). Each image X can be decomposed into causal factors Z and spurious factors W (i.e. X = (Z, W )), and the generative process follows the causal graph in Fig. <ref type="figure" target="#fig_3">3</ref>.</p><p>One may be tempted to surmise that this is an innocent assumption, but it does make strong claims about the generative process. The interpretation is that W contains all of the lower level signals or patches of the image, which may contain concepts confounding with Y . On the other hand, Z refines these patches into interpretable factors, which is what is visually used by the labeler. Since Z is a direct function of W , these factors are not confounded. For example, while W might include various pieces of information such as patches of blue in the water or texture of feathers, Z refines all of these signals into factors such as "waterbird shape," which is then used by the labeler to choose "waterbird" for Y . While this assumption may not be true in all settings, we believe that many practical, image settings can be approximated by this assumption.</p><p>Assumption 2 (Sufficient representation). The neural representations R ∼ P (R | Z, W ) are learned such that they do not lose information w.r.t. Z. In words, for two samples r 1 and r 2 from P (R | z 1 , w 1 ) and</p><formula xml:id="formula_3">P (R | z 2 , w 2 ), respectively, r 1 = r 2 if z 1 = z 2 .</formula><p>This is a somewhat more technical assumption, which says that the neural representation has enough capacity to represent unambiguously the causal factors. This assumption should hold in general given a proper choice of model for P (R | X), which we further elaborate in Sec. 4.1.</p><p>Assumption 3 (Selective prediction). Consider two images of X, x = (z, w) and x = (z , w ), with neural output P , and the true labeling probability P . Let R = r be a representation of x, sampled from P (R | x). Then,</p><formula xml:id="formula_4">P (Y = y | R = r, X = x ) = P (y | z, w ).</formula><p>The details on how to select the specific architectural design for constructing P (Y | R, X) that satisfies this assumption is discussed in more detail in Sec. 4.2. Still, in words, the assumption says that once inputted with two images x and x (x in its representation form, r), the network will make the same prediction y as if it were the true labeler when inputted with the causal feature z, from the first image, and the spurious feature w , from the second image.</p><p>Putting all these observations together, we now state one of the main results of the paper: Theorem 1 (Causal Identification). Given the assumptions about the generative process encoded in the causal graph in Fig. <ref type="figure" target="#fig_3">3</ref> together with assumptions 1, 2, 3, the causal effect can be computed using neural representation R via P (Y = y|do(X = x)) = r P (r|x) x P (y|r, x )P (x ).</p><p>Proof. We first derive the following steps. The intuition behind this derivation is that if the image x can be decomposed into causal factors (z) and spurious factors (w), as shown in Fig. <ref type="figure" target="#fig_3">3</ref>, then the causal effect is isolated in z, and w can be ignored. By conditioning on W = w , using another image, all the backdoor paths from Z to Y are blocked, which leads to an identifiable result (i.e., without do-terms). That leaves the question of how to obtain the z component from image x, and w from x . The general idea behind assumptions 2 and 3, and the last two lines of the derivation, is that P (Y | R, X) is able to extract all of the causal information z from the representation r, and  end for 8: end for 9: Calculate the causal effect P (y|do(X = x)) = i P (r i |x) j P (y|r i , x ij )P (x ij ) 10: Output: Class ŷ = argmax y P (y|do(X = x)).</p><p>extract the spurious information w from the second image x , which will happen through the design of the neural net.</p><p>Altogether, Theorem 1 allows us to estimate the causal effect through<ref type="foot" target="#foot_0">foot_0</ref> :</p><formula xml:id="formula_5">P (y|do(X = x)) = r P (r|x) x P (y|r, x )P (x ) (1)</formula><p>To use this formula, we need to construct the neural models to satisfy the three assumptions and properly estimate P (X), P (R|X), and P (Y |X, R). The term P (X) is straightforward to calculate because we can assume it is sampled from a uniform distribution <ref type="bibr" target="#b49">[52]</ref>. The other terms, however, require a more careful construction so as to satisfy the aforementioned assumptions, which are discussed in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test Accuracy In-distribution</head><p>Out-of-distribution Chance 10.0% 10.0% ERM <ref type="bibr" target="#b51">[54]</ref> 99.5% 8.3% IRM* <ref type="bibr" target="#b3">[4]</ref> 87.3% 18.5% RSC <ref type="bibr" target="#b26">[28]</ref> 96.6% 20.6% GenInt <ref type="bibr" target="#b36">[38]</ref> 58.5% 29.6% Ablation 97.4% 38.8% Ours 82.9% 51.4%</p><p>Table <ref type="table">1</ref>. Accuracy on the CMNIST dataset. Our method advances the state-of-the-art GenInt <ref type="bibr" target="#b36">[38]</ref> method by over 20% on the out-ofdistribution test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Constructing P (R|X)</head><p>We discuss some classes of models that are valid ways of estimating P (R|X) while satisfying Assumption 2.</p><p>Variational Auto-Encoder (VAE) <ref type="bibr" target="#b28">[30]</ref> is an unsupervised representation learning approach, which aims to estimate a latent distribution R that can faithfully generate the input distribution. It maximizes the evidence lower bound for the distribution of X:</p><formula xml:id="formula_6">L = -D KL (q E (r|x (i) )||p θ (r))+ E q E (r|x (i) ) [log p θ (x (i) |r)]</formula><p>, where E is the encoder in the VAE. As VAEs are optimized to reconstruct input images via the term E q E (r|x (i) ) [log p θ (x (i) |r)], the representation R should contain all the causal information from the input images, satisfying Assumption 2.</p><p>Constrastive Learning is another unsupervised learning approach that produces representations that can align views of the same image while separating views of different images. Given enough negative examples, contrastive learning will produce representations that are invariant under data augmentation, which still maintains all causal information from the input images, also satisfying Assumption 2.</p><p>Pretrained models from larger dataset. Empirically, deep neural networks show better generalization when pretrained from large datasets. This suggests that their representation R does not drop robust features for classification and keeps the information about Z, satisfying Assumption 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Constructing P (Y |R, X)</head><p>To properly evaluate Eq. 1, we also need to estimate a P (Y |R, X) such that Assumption 3 is satisfied. We discuss some neural network designs to achieve this.</p><p>Model Design for P (Y |R, X). In addition to the representation R, we use as input a bag of patches, which are subsampled from input image X into the branch that takes the input X. A bag of image patches corrupts the global shape information and often contains local features that are spurious, such as color, texture and background <ref type="bibr" target="#b37">[39]</ref>. During training, the causal features Z in the image tend to be ignored by the read-out model. Specifically, we have  representation R are sampled from the same instance. During testing, the image X can be sampled from an arbitrary instance.</p><formula xml:id="formula_7">P (Y |R ∼ P (R | Z, W ), X = (Z, W )) = P (Y |R ∼ P (R | Z, W ), W ).</formula><p>The model P (Y |R, X) has limited capacity. Given that the model has learned the information about W , learning W from R again will not further decrease the empirical loss. Thus, the model will learn Z from the representation R and ignore the W from the representation. In addition, The pretrained representations R, such as the ones from contrastive learning, can reduce the (labeled) sample complexity on classification tasks <ref type="bibr" target="#b4">[5]</ref> than on raw image input, which allows the model to learn Z from R efficiently. This satisfies Assumption 3.</p><p>By limiting the capacity of P (Y |R, X), the model tends to use low-level features from the input images X while using high-level deep features from the latent representation R. Traditional correlation-based approaches only use P (Y |R), which can also include spurious features such as the texture and backgrounds from the representation R. With our approach, the low-level spurious features tend to be learned by the model that conditions on the input X, and the model will discard those features after marginalizing over the variable X.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Algorithm</head><p>We describe our training procedure in Algorithm 1. In the first phase, we estimate P (R|X), where we either train a representation with our proposed VAE or contrastive learning approach, or we use representations from a pretrained deep model. In the second phase, we train P (Y |X, R) where we sample random images X from the same category as the representation R. We describe our inference procedure in Algorithm 2, where we infer the P (y|do(X = x)). We first randomly sample R. Then, for each R, we sample images X from random categories. Finally, we make the prediction through Theorem 1. Table <ref type="table">4</ref>. Robust accuracy on ImageNet-Rendition and ImageNet-Sketch. For contrastive learning based representations, our model achieves improved robustness than standard ERM and the state-of-the-art RSC approach. On superivsed learning representations, the representation may fail to capture all the causal information, where RSC method out-performs ours on two variants on ImageNet Rendition. Overall, our method improves robustness by estimating the causal effect from the representation.  At inference time, by increasing Nj that samples more images X , OOD generalization improve because the spurious correlation is better removed through our approach.</p><p>5. Experiment</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Datasets</head><p>CMNIST. We use the more challenging setup of colored MNIST dataset with 10 categories <ref type="bibr" target="#b36">[38]</ref>. The function F X (U x , U xy ) will combine digits with different background colors from the training domain, creating an out-ofdistribution (OOD) dataset. WaterBird dataset <ref type="bibr" target="#b47">[50]</ref> contains two classes of foreground birds, the waterbird and the landbird, and two types of backgrounds: water and land. The testing is OOD to the training because of the different mechanisms in combining the foreground and background. ImageNet-Rendition <ref type="bibr" target="#b23">[25]</ref> has renditions of 200 ImageNet classes, including art, cartoons, etc, which is an OOD test set for ImageNet. ImageNet-Sketch <ref type="bibr" target="#b52">[55]</ref> contains sketch of 1000 ImageNet classes, which evaluate classifiers' robustness without texture and color clue. ImageNet-9 Backgrounds Challenge <ref type="bibr" target="#b54">[57]</ref> studies the classifier's vulnerability to adversarially chosen backgrounds on ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Baselines</head><p>Our paper studies generalization on the out-ofdistribution test set without domain index for training samples. We compare with the following baselines:</p><p>ERM <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b51">54]</ref> is the standard way to train deep network classifiers. GenInt <ref type="bibr" target="#b36">[38]</ref> learns a causal classifier by steering the generative models to simulate interventions. RSC <ref type="bibr" target="#b26">[28]</ref> uses representation self-challenging to improve generation to the OOD data, where features that are significant in ERM will be punished. We also compare with the popular IRM <ref type="bibr" target="#b3">[4]</ref> which uses domain index information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experimental Settings</head><p>We construct the low capacity network P (Y |X , R) with 3 random convolution layers applied to a bag of patches from X , concatenating the obtained feature with R, and then using 2-layer fully connected network to predict Y . Except for CMNIST where the input is low dimension and we do not use convolution layer. We set N j = 256 and N i = 10 for all experiments and denotes it as Ours. We also conduct a variant with N j = 1 and N i = 1 and denote it as Ablation, where everything is the same as 'Ours' but the inference procedure is a traditional single forward pass. For CMNIST and WaterBird datasets, we select the model with the highest validation accuracy. For ImageNet-Rendition and ImageNet-Sketch, we report the best validation accuracy as there is no validation/test split available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Results on Simulated Datasets</head><p>CMNIST. Our approach uses the latent representation from VAE to construct the representation variable. We report the accuracy in Table <ref type="table">1</ref>. Our method outperforms existing methods including the causal GenInt method by over 20%.</p><p>WaterBird. Following prior work, we use the representation from a pre-trained ResNet50. We train the model for 10 epochs. In Table <ref type="table" target="#tab_0">2</ref>, without using domain index information, our causal approach improves the out-of-distribution test performance by over 25% compared with ERM, and even 1% higher than the state-of-the-art GDRO <ref type="bibr" target="#b47">[50]</ref> method which uses domain index information.</p><p>ImageNet-9 Adversarial Backgrounds. We assess our model's robustness on testing distributions where the foreground and the background are manipulated to be different  from the training distribution. In Table <ref type="table" target="#tab_1">3</ref>, we experiment on three variants of contrastive loss based self-supervised learning approaches, including Moco-v2 <ref type="bibr" target="#b16">[18]</ref>, SWAV <ref type="bibr" target="#b14">[16]</ref>,</p><p>and SimCLR <ref type="bibr" target="#b15">[17]</ref>. Overall, our approach performs better when the foreground object is present even if the background is changed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Real-world Out of Distribution Generalization</head><p>ImageNet-Rendition and ImageNet-Sketch are two OOD test sets for ImageNet. We study the representation from contrastive-loss-based self-supervision learning approaches including SimCLR, MoCo-v2, and SWAV. In addition, we also study the representations from supervised learning, though they may be imperfect representations. We show results in Table <ref type="table">4</ref>. Our algorithm estimates the causal invariance, which improves OOD generalization. The exception is that the supervised trained models, ResNet50 and ResNet152, are not trained with contrastive learning and therefore may lose causal information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.">Analysis</head><p>Importance of Image Sampling. Our approach requires marginalizing over random input images x at inference time. Sampling fewer x can speed up the inference, however, at a cost of not estimating the accurate causal effect. In Figure <ref type="figure" target="#fig_8">4</ref>, we vary the number of samples N j and test the performance on four datasets. In general, We find for datasets with K categories, using N j &gt; K can significantly improve generalization.</p><p>GradCam Visualization. Using the criterion derived in the previous section, we expect our model to attend to the spatial regions corresponding to the object, instead of the spurious context. In Figure <ref type="figure" target="#fig_9">5</ref>, we validate this by visualizing the regions that the models use for classification with the GradCAM <ref type="bibr" target="#b48">[51]</ref>. We examine four datasets, including the WaterBird, ImageNet-9, ImageNet-Rendition, and ImageNet-Sketch. We visualize the ERM model in the 'Baseline' column, the branch that conditions on the variable X of model P (Y |R, X) in the 'Spurious' Column, and our causal method in 'Ours'. By discarding the information in the 'Spurious' model through marginalizing over X , our model focus on the right object for prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>Generalization is a fundamental problem in visual recognition. This paper uses causal transportability theory to revisit and formulate the problem of out-of-distribution classification, since associational relations are not generalizable across domains. Our results demonstrate improved out-ofdistribution robustness on both simulated and real-world datasets. Our findings suggest integrating causal knowledge and tools into visual representations is a promising direction to improve generalization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Causal graph for out-of-distribution image classification (top left). Image X is constructed from nuisance features UX (bottom left) and concept features UXY (bottom right). Label Y is created from X and UXY . S, the transportability node, points to nodes with changes between domains, where X combines 'waterbird' with 'water background' during the training (S = 0) and 'water bird' with 'land background' at testing (S = 1) (top right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Visualization comparing quantities between domains π and π * . Prop. 1 shows that P (Y | X), which contains both causal and spurious information, does not match P * (Y | X). Prop. 2 shows that the causal effect is invariant across settings, i.e., P (Y | do(X)) = P * (Y | do(X)). However, Prop. 3 shows that unlike P (Y | X), P (Y | do(X)) is not identifiable from π-data .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Proposition 2 .</head><label>2</label><figDesc>Let M and M * be the two underlying SCMs representing the source and target domains, π and π * , and compatible with the causal graph in Fig. 1. Then, P * (Y | do(X)) = P (Y | do(X)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Expanded causal model with decomposition of image X and representation R. Gray nodes denote observed variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>PP</head><label></label><figDesc>(y | do(x)) = P (y | do(z, w)) Assumption 1 = P (y | do(z)) Do-Calculus Rule 3 [42] (y | z, w )P (z , w ) Marginalization By Assumptions 2 and 3, the last expression can be rewritten as = x P (y | r, x = (z , w ))P (x ) where r is sampled from P (R | x). Since Assumption 3 applies for any sampled value of R, we can average across samples of R, = r P (r | x) x P (y | r, x )P (x ), concluding the proof.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 1 2 : 3 : 5 : 6 : 4 : 5 :</head><label>1235645</label><figDesc>Causal-Transportability Model Training 1: Input: Training set D over {(X, Y )}. Phase 1: Compute P (R|X) from representation of VAE or pretrained model. Phase 2: 4: for i = 1, ..., K do Sample x i , r i , y i from the joint distribution D = (X, R, Y ) Random sample x i from the same category as x i 7: Train P (Y |X , R) via minimizing the classification loss L through gradient descent. 8: end for 9: Output: Model P (R|X) and P (Y |X, R) Algorithm 2 Causal-Transportability Effect Evaluation 1: Input: Query x, training distribution D over {(X, Y )}, model P (R|X) and P (Y |X , R), the sampling time N i for the representation variable R, and the sampling time N j for X . 2: for i = 1, ..., N i do 3: r i ← P (r|x) for j = 1, ..., N j do Random sample x ij from Training Distribution D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>6 :</head><label>6</label><figDesc>Compute P (Y |x ij , r i ) 7:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Sketch, K = 1000</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. OOD generalization accuracy under different number of Nj. At inference time, by increasing Nj that samples more images X , OOD generalization improve because the spurious correlation is better removed through our approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 .</head><label>5</label><figDesc>Figure5. We visualize the input regions that the models use for prediction. We use GradCAM<ref type="bibr" target="#b48">[51]</ref> and highlight the the discriminative regions that the model relies on with red. The white text shows the model's prediction. The correlation based ERM method often attends to spurious background context. By marginalizing over the spurious features (visualized in the Spurious column), our model captures the right, causal features, which predict the right thing for the right reason.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>During training, the image X and the Accuracy on the WaterBird dataset. Our causal method improves ERM model's worst group OOD generalization significantly. Our approach achieves performance on par with group invariant training (GDRO) without needing the domain index.</figDesc><table><row><cell>Method</cell><cell>Domain ID</cell><cell>Train</cell><cell>I.I.D</cell><cell>OOD</cell></row><row><cell>GDRO* [50]</cell><cell>Yes</cell><cell>100.0%</cell><cell>97.4%</cell><cell>76.9%</cell></row><row><cell>ERM</cell><cell>No</cell><cell>100.0%</cell><cell>97.3%</cell><cell>52.0%</cell></row><row><cell>RSC</cell><cell>No</cell><cell>92.2%</cell><cell>95.6%</cell><cell>49.7%</cell></row><row><cell>Ablation</cell><cell>No</cell><cell>99.4%</cell><cell>96.8%</cell><cell>71.6%</cell></row><row><cell>Ours</cell><cell>No</cell><cell>99.4%</cell><cell>96.8%</cell><cell>77.9%</cell></row><row><cell></cell><cell cols="3">OOD Test Accuracy</cell><cell></cell></row><row><cell></cell><cell>Moco-v2</cell><cell>SWAV</cell><cell cols="2">SimCLR</cell></row><row><cell>ERM [54]</cell><cell>14.59%</cell><cell>20.00%</cell><cell>27.73%</cell><cell></cell></row><row><cell>Ablation</cell><cell>17.04%</cell><cell>20.25%</cell><cell>28.44%</cell><cell></cell></row><row><cell>Ours</cell><cell>18.02%</cell><cell>20.42%</cell><cell>29.41%</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Accuracy on the Imagenet-9 adversarial backgrounds.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Interestingly, the derivation of this expression is somewhat similar to the well-known identification strategy named the front-door criterion<ref type="bibr" target="#b40">[42,</ref>  Sec. 3.3.2]. One of the key assumptions made by the front-door is that there exists a variable M that acts as an (unconfounded) mediator between X and Y . In spirit, R, our deep representation, resembles M . Despite the syntactical appearances, the variable R in the case here is not exactly a mediator, in the original sense, since it acts as a proxy for both X and Z.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments: CM, JW, and CV are partially supported by <rs type="funder">DARPA SAIL-ON</rs> and DARPA GAIL. CM and JF are partially supported by <rs type="funder">DiDi Faculty Research Award, J.P. Morgan Faculty Research Award</rs>, <rs type="funder">Accenture Research Award</rs>, <rs type="grantNumber">ONR N00014-17-1-2788</rs>, and <rs type="funder">NSF</rs> <rs type="grantNumber">CNS-1564055</rs>. EB and KX are partially supported by <rs type="funder">NSF</rs>, <rs type="funder">ONR</rs>, <rs type="funder">Amazon</rs>, <rs type="person">JP Morgan</rs>, and <rs type="funder">The Alfred P. Sloan Foundation</rs>. HW is partially supported by <rs type="funder">NSF</rs> Grant <rs type="grantNumber">IIS-2127918</rs> and an <rs type="funder">Amazon Faculty Research Award</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_vDVxFMp">
					<idno type="grant-number">ONR N00014-17-1-2788</idno>
				</org>
				<org type="funding" xml:id="_YzrZtEe">
					<idno type="grant-number">CNS-1564055</idno>
				</org>
				<org type="funding" xml:id="_xnUKJbW">
					<idno type="grant-number">IIS-2127918</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Domain-adversarial neural networks</title>
		<author>
			<persName><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franccois</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.4446</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Generalizing to unseen domains via distribution matching</title>
		<author>
			<persName><forename type="first">Isabela</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">João</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Darvishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tiago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName><surname>Mitliagkas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Alverio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Gutfreund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Barbu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="9448" to="9458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2020. 2, 4, 6, 7</date>
		</imprint>
	</monogr>
	<note>Invariant risk minimization</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A theoretical analysis of contrastive unsupervised representation learning</title>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrishikesh</forename><surname>Khandeparkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orestis</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09229</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Towards shape biased unsupervised representation learning for domain generalization</title>
		<author>
			<persName><forename type="first">Nader</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehrdad</forename><surname>Sarfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zahra</forename><surname>Hosseinzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahdi</forename><surname>Karimpour</surname></persName>
		</author>
		<author>
			<persName><surname>Eftekhari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On Pearl&apos;s Hierarchy and the Foundations of Causal Inference</title>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">D</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duligur</forename><surname>Ibeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Icard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<pubPlace>NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Transportability from multiple environments with limited experiments</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Honavar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A general algorithm for deciding transportability of experimental results</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Causal Inference</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Transportability from multiple environments with limited experiments: Completeness results</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="280" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Causal inference and the data-fusion problem</title>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">27</biblScope>
			<biblScope unit="page" from="7345" to="7352" />
			<date type="published" when="2016">2016. 1, 2, 3</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2001">05 2010. 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Domain generalization by marginal transfer learning</title>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aniket</forename><surname>Anand Deshmukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urun</forename><surname>Dogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gyemin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clayton</forename><surname>Scott</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.07910</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlucci</forename><surname>Antonio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D'</forename><surname>Innocente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvia</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatiana</forename><surname>Tommasi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2019</date>
			<publisher>Peter Bühlmann. Invariance, causality and robustness</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.09882</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Improved baselines with momentum contrastive learning</title>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">From statistical transportability to estimating the effect of stochastic interventions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Kraus</surname></persName>
		</editor>
		<meeting>the 28th International Joint Conference on Artificial Intelligence<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">General transportability of soft interventions: Completeness results</title>
		<author>
			<persName><forename type="first">Juan</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patricia</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">In search of lost domain generalization</title>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Conditional variance penalties and domain shift robustness</title>
		<author>
			<persName><forename type="first">Christina</forename><surname>Heinze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Deml</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.11469</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The many faces of robustness: A critical analysis of out-of-distribution generalization</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Dorundo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samyak</forename><surname>Parajuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2007">2021. 1, 2, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Self-challenging improves cross-domain generalization</title>
		<author>
			<persName><forename type="first">Zeyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02454</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Self-challenging improves cross-domain generalization</title>
		<author>
			<persName><forename type="first">Zeyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Selecting data augmentation for simulating interventions</title>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Ilse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jakub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><surname>Forré</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Big transfer (bit): General visual representation learning</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">August 23-28, 2020. 2020</date>
			<biblScope unit="page" from="491" to="507" />
		</imprint>
	</monogr>
	<note>Proceedings, Part V 16</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Shoestring: Graph-based semi-supervised classification with severely limited labeled data</title>
		<author>
			<persName><forename type="first">Wanyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaolin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baochun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4174" to="4182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Generative Causal Explanations for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Wanyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baochun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Orphicx: A causality-inspired latent variable model for interpreting graph neural networks</title>
		<author>
			<persName><forename type="first">Wanyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baochun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Domain adaptation by using causal inference to predict invariant conditional distributions</title>
		<author>
			<persName><forename type="first">Sara</forename><surname>Magliacane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Thijs Van Ommen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Claassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Bongers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joris</forename><forename type="middle">M</forename><surname>Versteeg</surname></persName>
		</author>
		<author>
			<persName><surname>Mooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Domain generalization using causal matching</title>
		<author>
			<persName><forename type="first">Divyat</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Tople</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Sharma</surname></persName>
		</author>
		<idno>PMLR, 2021. 2</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="7313" to="7324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Generative interventions for causal learning</title>
		<author>
			<persName><forename type="first">Chengzhi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augustine</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amogh</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Vondrick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Chengzhi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irfan</forename><surname>Essa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.10493</idno>
		<title level="m">Discrete representations strengthen vision transformer robustness</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Domain generalization using a mixture of multiple latent domains</title>
		<author>
			<persName><forename type="first">Toshihiko</forename><surname>Matsuura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Sayak</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pin-Yu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.07581</idno>
		<title level="m">Vision transformers are robust learners</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Causality: Models, reasoning, and inference</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000. 1, 2, 4, 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Mackenzie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>The Book of Why. Basic Books</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Moment matching for multi-source domain adaptation</title>
		<author>
			<persName><forename type="first">Xingchao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinxun</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xide</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wang ; Fengchun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019. 1, 2 [45. 2020</date>
			<biblScope unit="page" from="12556" to="12565" />
		</imprint>
	</monogr>
	<note>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.00020</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Do ImageNet classifiers generalize to Im-ageNet?</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<idno>PMLR. 1</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</editor>
		<meeting>the 36th International Conference on Machine Learning<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06">Jun 2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Invariant models for causal transfer learning</title>
		<author>
			<persName><forename type="first">Mateo</forename><surname>Rojas-Carulla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Distributionally robust neural networks for group shifts: On the importance of regularization for worstcase generalization</title>
		<author>
			<persName><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.08731</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Distributionally robust neural networks for group shifts: On the importance of regularization for worstcase generalization</title>
		<author>
			<persName><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tatsunori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Grad-cam: Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ramprasaath R Selvaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakrishna</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devi</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Advanced data analysis from an elementary point of view</title>
		<author>
			<persName><forename type="first">Cosma</forename><surname>Shalizi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">456</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName><forename type="first">Baochen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Principles of risk minimization for learning theory</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning robust global representations by penalizing local predictive power</title>
		<author>
			<persName><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songwei</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007">2019. 1, 2, 7</date>
			<biblScope unit="page" from="10506" to="10518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The causal-neural connection: Expressiveness, learnability, and inference</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Zhan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Noise or signal: The role of image backgrounds in object recognition</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.09994</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Transporting causal mechanisms for unsupervised domain adaptation</title>
		<author>
			<persName><forename type="first">Zhongqi</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian-Sheng</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Inter-national Conference on Computer Vision</title>
		<meeting>the IEEE/CVF Inter-national Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8599" to="8608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Interventional few-shot learning</title>
		<author>
			<persName><forename type="first">Zhongqi</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian-Sheng</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2734" to="2746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Adaptive risk minimization: A meta-learning approach for tackling group distribution shift</title>
		<author>
			<persName><forename type="first">Marvin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrik</forename><surname>Marklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Dhawan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02931</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Deep domain-adversarial image generation for domain generalisation</title>
		<author>
			<persName><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
