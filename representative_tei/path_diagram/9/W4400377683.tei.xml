<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting Trust Dynamics with Dynamic SEM in Human-AI Cooperation</title>
				<funder ref="#_YtWw2r7">
					<orgName type="full">JST</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sota</forename><surname>Kaneko</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution" key="instit1">The Graduate University for Advanced Studies</orgName>
								<orgName type="institution" key="instit2">SOKENDAI</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Digital Content and Media Sciences Research Division</orgName>
								<orgName type="institution">National Insti- tute of Informatics</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Seiji</forename><surname>Yamada</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution" key="instit1">The Graduate University for Advanced Studies</orgName>
								<orgName type="institution" key="instit2">SOKENDAI</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Digital Content and Media Sciences Research Division</orgName>
								<orgName type="institution">National Insti- tute of Informatics</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Predicting Trust Dynamics with Dynamic SEM in Human-AI Cooperation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Humans' trust in AI constitutes a pivotal element in fostering a synergistic relationship between humans and AI. This is particularly significant in the context of systems that leverage AI technology, such as autonomous driving systems and human-robot interaction. Trust facilitates appropriate utilization of these systems, thereby optimizing their potential benefits. If humans over-trust or under-trust an AI, serious problems such as misuse and accidents occur. To prevent over/under-trust, it is necessary to predict trust dynamics. However, trust is an internal state of humans and hard to directly observe. Therefore, we propose a prediction model for trust dynamics using dynamic structure equation modeling, which extends SEM that can handle time-series data. A path diagram, which shows causalities between variables, is developed in an exploratory way and the resultant path diagram is optimized for effective path structures. Over/under-trust was predicted with 90% accuracy in a drone simulator task,, and it was predicted with 99% accuracy in an autonomous driving task. These results show that our proposed method outperformed the conventional method including an auto regression family.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>AI technologies have been developed in various fields, and its use in everyday situations, such as autonomous driving, autonomous flying drones, and autonomous mobile robots, is rapidly advancing. The development of such technology allows people to delegate tasks to them, reducing their workload. While there are cases where all operations are simply left to autonomous driving or autonomous mobile robots, in many cases, they work together with humans in the same space. In this way, appropriate cooperation between humans and AI is indispensable in the use and development of AI technology, and what becomes important here is trust of humans in AI <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>.</p><p>When humans overestimate the performance of AI beyond its actual capabilities, there is a risk of misuse, such as delegating tasks in situations where they should not be delegated. For example, in the case of autonomous driving, continuing to drive automatically despite a decrease in AI performance due to worsening weather conditions can lead to accidents. This overestimation of AIs performance is referred to as over-trust <ref type="bibr" target="#b2">[3]</ref>. On the other hand, underestimating the performance of AI excessively compared with its original capabilities can result in humans performing tasks that AI can carry out, preventing AI from demonstrating its actual performance. This under-trust, or excessive underestimation, also presents a problem of decreased efficiency in use. Therefore, maintaining appropriate trust in AI is important for proper collaboration with AI.</p><p>Also, in situations where humans and AI collaborate to perform tasks, predicting trust dynamics becomes important. In real-time systems, such as those represented by autonomous driving, the performance of AI and the trust in AI, which is a human's estimate of AIs performance, continue to change as the surrounding situation changes over time. This change in trust is called trust dynamics, and if we can predict trust dynamics, we can also predict overtrust and under-trust. This allows us to prevent falling into over-trust and under-trust before it happens. However, trust in AI is an internal state of humans, so it is impossible to observe it directly from the outside. Therefore, to predict trust dynamics, it is necessary to deal with this latent value.</p><p>Therefore, we construct a prediction model for trust dynamics, which is a change in the internal state of humans called "trust". In this work, we apply dynamic structural equation modeling (DSEM) for modeling trust and predicting over/under trust in a efficient and explainable way <ref type="bibr" target="#b3">[4]</ref>. We consider this work is the original approach which try to predict trust dynamics including direct prediction of over/undertrust by using DSEM. The procedures to construct a prediction model consist of exploratory design of path structure and its simple optimization for the most effective structure. We conducted experiments to evaluate our proposed methods in vision-based object recognition and autonomous driving simulation, and obtained promising results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK A. Trust in HRI</head><p>In research on trust formation in human-robot interaction (HRI), the factors that influence trust are classified as follows <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>: factors related to the robot (agent), factors related to the task and environment, and factors related to humans. The impact on trust formation is greatest in the order of factors related to the robot, factors related to the task and environment, and factors related to humans. Factors related to the performance of the robot include the reliability of the robot, the timing and frequency of task failures, the transparency of the system, etc., which are considered to determine the quality of the robots operation. Factors related to the task and environment include rationality, the danger that the task poses to humans, the load and complexity of the task, etc. Factors related to humans include personality, knowledge about the system, past experiences with robots, etc. Also, in HAI, trust formation can be considered in the same way by replacing factors related to the robot with factors related to the agent, but it is necessary to consider the difference resulting from the presence or absence of a physical entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Trust Dynamics</head><p>In interactions between humans and agents, trust changes over time and with repeated interactions. This changing trust is referred to as trust dynamics. By capturing trust dynamics, it is also possible to more accurately understand the major factors that influence trust formation.</p><p>In Luo's study on trust dynamics in interactions with autonomous vehicles, it is shown that changes in performance due to internal system factors have a greater impact on trust than changes in performance due to external system factors <ref type="bibr" target="#b6">[7]</ref>. Performance degradation due to internal system factors is caused by things like sensor failures, while performance degradation caused by external factors includes detours due to road construction and increased travel time due to traffic congestion.</p><p>Furthermore, it has been shown that by incorporating the mechanism of trust, it is possible to make more accurate trust predictions than models that do not consider these factors <ref type="bibr" target="#b7">[8]</ref>. In addition, there are efforts to develop new modeling methods that use trust dynamics, such as improving the accuracy of trust prediction by clustering based on trust dynamics and forming a suitable trust prediction model for each cluster <ref type="bibr" target="#b8">[9]</ref>.</p><p>Thus, constructing a model that takes into account trust dynamics not only enables accurate prediction of trust, but also enables accurate understanding of the factors that influence trust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Determination of Over/Under-trust by Equation of Inequality</head><p>In Lee study on designing reliance, over-trust is poor calibration in which trust exceeds system capability, and under-trust is trust falls of the system capability <ref type="bibr" target="#b9">[10]</ref>.</p><p>Okamura <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> proposed a framework for determining over/under-trust from a reliance equation involving the relationship between AI performance and human performance. In human-AI cooperative decision-making task that involving image recognition on a drone simulator, over/undertrust is determined from actually monitoring human rational decision-making behaviors based-on the reliance equation. The reliance equation is described like T H A &gt;=&lt; T A , where T H A and T A are AI's task success probabilities estimated by a human and the true value.</p><p>In this formulation, since over/under-trust can be detected only when a sequence of human decision-making behaviors by over/under-trust, it is hard to predict over/under-trust and prevent it. In contrast, our proposed method can predict over/under-trust and prevent it in advance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Trust Prediction</head><p>Fukuchi used a Transformer to predict reliance and performed reliance calibration using a reliance calibration queue <ref type="bibr" target="#b10">[11]</ref>. It should be noted that the reliance used here has a different definition from the trust we use.</p><p>Xu used a dynamic Bayesian network to predict trust dynamics <ref type="bibr" target="#b11">[12]</ref>. A cooperative decision-making task was performed using a drone simulator, where humans intervene in the automatic control of the drone, and trust dynamics were predicted in situations where the environment changed over time. The Bayesian network was constructed using six variables: trust, AI performance, presence or absence of user intervention, changes in external factors, changes in trust, and feedback on trust. Trust at time T = k is predicted from observations at times T = k, k -1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHOD A. Algorithm for Dynamic Path Diagrams</head><p>To predict and construct an explainable model of trust dynamics, which is an internal state that cannot be directly observed from the outside, we use DSEM, which extends structural equation modeling (SEM) to time series data. SEM is a model that estimates causal relationships by performing path analysis between variables, dealing with observed variables that can be directly observed and measured, and latent variables that cannot be measured <ref type="bibr" target="#b12">[13]</ref>. This SEM is extended along the time axis for the purpose of handling time series data and predicting the value at the next time point, which is DSEM <ref type="bibr" target="#b13">[14]</ref>.</p><p>By using DSEM as a prediction model, there are mainly three advantages:</p><p>• It is possible to handle the concept of trust, which is defined as the value of AIs performance estimated by humans and is an internal state of humans, as a variable. • It is possible to handle time series data and predict trust at the next time step. • the edges (paths) spanning between nodes are given topdown on the basis of prior research, so the model has high interpretability. Our proposed method of constructing a prediction model of trust dynamics can be summarized in the following steps.</p><p>1) Exploratory design of path diagrams: A human designs an initial static path diagram for SEM based on domain knowledge containing insights from previous work and designer knowledge, and it is improved until the accuracy reaches a threshold τ . This is done with human-in-the-loop procedures. 2) Optimization of time-series structure: Dynamic path diagrams based on the static path diagram (Step 1) are automatically optimized with edges manually added between the path diagrams with different time steps. Optimization can be done by using a constrained-bruteforce search algorithm which searches for all candidates of partial sequences within a constrained time range η. The objective function is time-series rollingorigin cross-validation <ref type="bibr" target="#b14">[15]</ref>. Since the computational complexity of this search is O(2 n ), the exponential order of time-series length n is extremely large, so we introduced a hyper parameter, that it, the constrained time range η which can be heuristically set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Construction of Dynamic Path Diagrams</head><p>On the basis of previous research, a model was created by Step 1 of Section III A with τ = 0.9. A path diagram of the created model is shown in Fig. <ref type="figure">1</ref>.</p><p>In the figure, the nodes enclosed in squares represent observable variables that can be directly observed, while the circular nodes represent latent variables that cannot be directly observed. The edges drawn between the nodes represent causal relationships between the variables. Additionally, green, blue and pink nodes stand for variables at t -1, t and t + 1, respectively.</p><p>Real values by the edges indicate path coefficients in the first experiment and real values in the brackets indicate them in the second experiment. For the analysis of the model, Mplus 1 version 8.8 was used, and Bayesian estimation was used to estimate path coefficients.</p><p>The variables and their respective ranges are as shown in the following. AI and human performance means the probability of success for each task. Trust in AI is defined as the human-estimated value of the AI's performance. AIP and HP are the performance of the AI (task success probability of AI) [0, 1] and performance of the human (task success probability of the human) [0, 1]. Also, E(AIP ) is the AIP estimated by a human [0, 1], which is the trust of a human in AI.</p><p>Over/U nder T rust is used to determine over-or undertrust, where "-1" represents "under-trust," "0" represents appropriately calibrated trust, and "1" represents "over-trust." Reliance indicates whether the user performed the task themselves, "0," or delegated the task execution to the AI, "1." Calibration cue indicates whether there was no trust calibration cue, "0," or a trust calibration cue was presented to the user, "1." In this model, the edges are drawn, excluding duplicates in the next time step, on the basis of various insights from previous work and our intuition. Note that this model can directly determine over/under trust without the equation for reliance in <ref type="bibr" target="#b0">[1]</ref> by introducing the variable Over/U nder T rust. We consider this to be the originality 1 www.statmodel.com of our work. Furthermore, this Over/U nder T rust can be utilized to efficiently and precisely prevent over/under-trust in our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS A. Exp-1 Predicting Trust in Object Recognition with Drone Simulator</head><p>The path coefficients estimated for this experiment are the values in brackets in Fig. <ref type="figure">1</ref>. This model is the result of applying Step 2 optimization of III A with η = 15 (the maximum length of the time-series data). The edges shown in solid lines represent causal relationships that have a positive effect, while the edges shown in dash-dotted lines represent causal relationships that have a negative effect. The combination of E(AIP ) input to the model as a past time series was selected to be E(AIP ) (t,t-1) as a result of the model estimation for each combination of all subsets of time T . The combination of E(AIP ) corresponding to the combination of time T was selected to be t, t -1, which is the combination that makes the AIC the smallest among all combinations, after estimating the path coefficients of the model corresponding to all subsets of time T .</p><p>For the estimation of the model, we used the experimental data from a cooperative decision-making task involving image recognition on a drone simulator by <ref type="bibr" target="#b0">[1]</ref>. These data were acquired from crowd sourcing-based online experiments with 194 participants, in which humans and AI cooperatively recognize pothole on roads at 30 checkpoints. The snapshot of the simulator is shown in Fig. <ref type="figure" target="#fig_0">2</ref> and these date are completely discrete. The data is consisting two phases: high-performance AI of object recognition in the first 15 checkpoints and lowperformance AI in the remaining 15 checkpoints to cause over-trust. Also, adaptive trust calibration was employed and trust calibration cues were expressed to a human when the over-trust was detected. As a result, the data of 96 participants include trust calibration with cues and that of other 96 participants do not include them. For more detail information on the data, see <ref type="bibr" target="#b0">[1]</ref>.</p><p>The estimated model allows us to infer the following qualitative causal relationship from coefficients of each edge:</p><p>• Cognitive trust has positive causality from AI performance.</p><p>• Over/under trust has negative causality from AI performance and positive causality from human performance and cognitive trust. • Cognitive trust has positive causality from calibration cue, while over/under trust has negative causality from calibration cue. • Reliance has positive causality from cognitive trust.</p><p>• Over/under trust and reliance have positive causality. 1) Results of Predicting Over-trust: The results of overtrust prediction at the next time step using the trust prediction model with our proposed method (PM) are shown below. These results are from an analysis of over-trust prediction at the next time step predicted from the current time observation value by each model. To verify the prediction results, we used the experimental data by <ref type="bibr" target="#b0">[1]</ref> used for model estimation.  The accuracy (ACC) and root mean squared error (RMSE) of each model are as shown in Table <ref type="table" target="#tab_1">I</ref>. In the prediction with PM, the ACC was 90.0%, and the RMSE was 0.28.</p><p>Proportion of users who are actually over-trust and the users who were predicted to be over-trust, step by step are shown in Fig. <ref type="figure" target="#fig_1">3</ref>. The blue solid line represents the proportion of users who actually fell into over-trust, and the orange dashed line represents the proportion of users who were predicted. Data augmentation was performed using Okamura's experimental data <ref type="bibr" target="#b0">[1]</ref> for path analysis and verification of prediction accuracy by DSEM, resulting in a periodic fluctuation of 15 steps.</p><p>The results of a one-way ANOVA statistical test with  In all the experiments of this work. the hyper parameters of base-line methods were adequately set based on domain knowledge. Also, VAR (vector autoregression) was not used as a base-line method because AR needs domain knowledge to prepare input/output vectors. Also, the precision of the over-trust prediction by DSEM is 1.00, and the recall is 0.72.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Exp-2 Predicting on Autonomous Driving Simulator</head><p>Next, we predicted over/under-trust using an autonomous driving simulator as a more continuous-time task in contrast of the previous discrete-time drone simulator. The task involved playing video clips from a car-mounted camera on the web and having a human intervene during playback. The video played as an onboard video of an autonomous vehicle was from the BBD100K driving dataset <ref type="bibr" target="#b15">[16]</ref>. The users were told that the video being played was filmed by an autonomous vehicle. The users played the video on a web browser and indicated their intention to intervene by pressing the space bar on the keyboard when they felt danger while driving. During the experiment, users could continue to monitor the video being played and could intervene as necessary when they felt danger.</p><p>The video was played in 22 scenes, with the AI driving at high performance in the first seven scenes, the performance dropping in the next nine, and the AI's performance increasing again in the final six scenes. In the middle nine scenes, if no intervention was made when the AI's performance was lower than that of a human, it was considered to indicate over-trust. Interventions are recorded as one step within a 10-second window, and a total of four steps are recorded within one scene.</p><p>The web-based autonomous driving simulator used in the experiment is shown in Fig. <ref type="figure" target="#fig_3">5</ref>. When intervention occurs, a red frame appears over the video. While autonomous driving, it becomes a green frame. A color of the handle icon displayed below the video also changes from green to red when user intervention. Additionally, the capability of AI is directly indicated at the bottom in Fig. <ref type="figure" target="#fig_3">5</ref> even though effective representation have been studied <ref type="bibr" target="#b16">[17]</ref>. 50 participants were recruited for 100 JPY through Yahoo! Japan Crowdsourcing 2 . 49 participants (noisy data elimination of two participants) completed the task (11 female, 38 male; aged: 22-66, M = 46.5, S.D. = 9.97).</p><p>1) Results of Predicting Over/Under-trust: The results of over-trust prediction at the next time step using the trust prediction model with PM are shown below.</p><p>The ACC and RMSE of each model are as shown in Table <ref type="table" target="#tab_1">II</ref>. In the prediction with PM, the ACC was 97.8%, and the RMSE was 0.14. The proportion of users who actually engaged in over/under-trust and the users who were predicted to do so, step by step are shown in Fig. <ref type="figure" target="#fig_4">6</ref>. The blue solid line represents the proportion of users who actually fell into over/under-trust, and the orange dashed line represents the users predicted to do so. Over-trust is shown as positive values and under-trust as negative values.</p><p>The results of a one-way ANOVA statistical test with multiple comparisons on the accuracy of the prediction by PM and the conventional methods are shown in Fig. <ref type="figure">7</ref>. The significance level was set to α = 0.05. As a result, there was a significant difference between PM and all of the baseline methods (AR, ARMA, SARIMA). This means that our proposed method completely outperformed the baseline methods.</p><p>Fig. <ref type="figure">7</ref>. Result of prediction accuracy in a drive simulator task.</p><p>V. DISCUSSIONS A. Algorithm for Preventing Over/Under-trust First, in this study, we focused on over-trust, which poses a bigger problem in particular environments when fallen into than distrust, and made predictions of over-trust. However, of course, the model we built is adaptable to both over-trust and under-trust predictions.</p><p>We are currently developing an algorithm for prevention over/under trust with our proposed trust dynamics prediction in this work. The algorithm's basic policy is very simple, that is, to express trust calibration cues to a human just when the over/under-trust is predicted to occur in the next time step.</p><p>However, if a human does not react to these cues, what should the AI do? Repeatedly express the cues until the human executes trust calibration? This is not a simple problem so we need to develop an algorithm for preventing over/under-trust through the design of calibration cues. For effective cues, we should carefully design promising cues and conduct experiments to evaluate them. This is our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison with DNN-based Approaches</head><p>In the experimental comparison with conventional and baseline systems, we did not include deep neural network (DNN)-based time-series prediction including Transformer <ref type="bibr" target="#b17">[18]</ref> and LSTM <ref type="bibr" target="#b18">[19]</ref> as state-of-the-arts methods. Our reasons for not utilizing them are because the task properties like snapshots (captured images) of a task simulator, levels of task difficulty, error significance etc., are hard to described and introduced to a SEM framework as observed variables of high-dimensional vectors. In contrast, DNN-based prediction can easily and fully utilize such task properties with embedded vectors as input.</p><p>Thus, it is difficult to prepare the same input for both our proposed method and DNN-based time-series prediction in a fair way. However, we are trying to develop both DNNbased prediction without task description as its input and our proposed methods with task descriptions using high dimensional vectors as observed variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Explainability, Interpretability, and Utility of Our Proposed Method</head><p>We think that the explainability and ease of interpretability <ref type="bibr" target="#b3">[4]</ref> of our proposed method can be guaranteed because the prediction models can be described with path diagrams as directed graphs. However, explainability and interpretability were not confirmed in the experiments. Thus, we need to conduct experiments with participants to confirm them. This is also our future work.</p><p>We can utilize the same (static) path diagrams in both experiments in human-AI cooperative object recognition and driving. However, the design of path diagrams is basically dependent on the task domains. Clarifying general and common path diagrams in various task domains, and the coverage of the proposed method are also open problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Limitation and Coverage of Our Proposed Method</head><p>Our proposed method has significant limitations. First, the SEM-based approach needs human knowledge because it utilizes an exploratory method with human intuition. This might be a hard limitation depending on the task domain.</p><p>Furthermore, there is no guarantee that precise prediction models will be constructed. Last, our method basically includes a brute-force search with a high computational cost for optimal partial path diagrams. In practice, we can restrict the search space with τ . We are investigating more sophisticated combinatorial optimization algorithms.</p><p>We need to discuss the coverage of our proposed approach with DSEM to apply it to other domains. Basically, we consider our approach to be applicable to any domain in which designers have rich knowledge on factors influencing target variables regardless of prediction accuracy.</p><p>Thus, we plan to apply this approach to human-robot interaction and trustworthy AI including the prevention of human abuse of robots <ref type="bibr" target="#b19">[20]</ref> and robotic trust repair <ref type="bibr" target="#b20">[21]</ref>. In particular, for trust repair, we will develop special trust repair cues <ref type="bibr" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this paper, we proposed a novel method for constructing a prediction model of trust dynamics toward AI in human-AI cooperative decision-making. In our method, first exploratory design is done, and a static path diagram is obtained; then optimization is applied to time-series path diagrams. In this framework, directly predict over/under trust without monitoring the execution of human rational behaviors is quite original and important for preventing over/under-trust. Another advantage of our proposed method is its high explainability due to the path structure. We applied this proposed method to two different task domains involving human-AI cooperative object recognition and autonomous driving. In both domains, we confirmed that our proposed method could outperform conventional methods including AR, ARMA and Seasonal ARMA.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Dron-simulator for human-AI cooperative object recognition [1].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Prediction results of over-trust by DSEM. The blue solid line represents the actual proportion of over-trust, and the orange dashed line represents the predicted proportion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Results of prediction accuracy in a drone simulator task.</figDesc><graphic coords="4,63.01,50.08,226.78,138.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Screen shot of drive simulation while a user was intervening.</figDesc><graphic coords="5,54.51,50.08,243.79,162.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Prediction results of over/under-trust by DSEM. The blue solid line represents the actual proportion of over/under-trust, and the orange dashed line represents the predicted proportion. Positive values represent over-trust, and negative values represent under-trust.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I EXPERIMENTAL</head><label>I</label><figDesc>RESULTS WITH DRONE SIMULATOR TASK.</figDesc><table><row><cell></cell><cell>ACC</cell><cell>RMSE</cell></row><row><cell></cell><cell>Avg(S.D.)</cell><cell>Avg(S.D.)</cell></row><row><cell>PM</cell><cell cols="2">0.90(0.05) 0.28(0.14)</cell></row><row><cell>AR(1)</cell><cell cols="2">0.59(0.19) 0.51(0.19)</cell></row><row><cell>ARMA(1,1)</cell><cell cols="2">0.57(0.19) 0.51(0.19)</cell></row><row><cell cols="3">SARIMA(1,0,1)[15] 0.57(0.19) 0.51(0.19)</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>*This work was supported in part by <rs type="funder">JST</rs> <rs type="grantNumber">CREST JPMJCR21D4</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_YtWw2r7">
					<idno type="grant-number">CREST JPMJCR21D4</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Adaptive trust calibration for human-ai collaboration</title>
		<author>
			<persName><forename type="first">K</forename><surname>Okamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yamada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Empirical evaluations of framework for adaptive trust calibration in human-ai cooperation</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="220" to="335" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards a theory of longitudinal trust calibration in human-robot teams</title>
		<author>
			<persName><forename type="first">E</forename><surname>Visser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Peeters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neerincx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="459" to="478" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Molnar</surname></persName>
		</author>
		<ptr target="https://christophm.github.io/interpretable-ml-book/" />
		<title level="m">Interpretable Machine Learning -A Guide for Making Black Box Models Explainable</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Toward an understanding of trust repair in human-robot interaction: Current research and future directions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Keebler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Interact. Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Modeling trust in human-robot interaction: A survey</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">R</forename><surname>Khavas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Ahmadzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Robinette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Robotics</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="529" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Trust dynamics in human-av (automated vehicle) interaction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EA of the 2020 CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cognitive model of trust dynamics predicts human behavior within and between two games of strategic interaction with computerized confederate agents</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Juvina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Gluck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Clustering human trust dynamics for customized real-time prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Akash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Misu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2021 IEEE International Intelligent Transportation Systems Conference (ITSC&apos;21)</title>
		<meeting>2021 IEEE International Intelligent Transportation Systems Conference (ITSC&apos;21)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1705" to="1712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Trust in automation: Designing for appropriate reliance</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>See</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Factors</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="80" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dynamic selection of reliance calibration cues with ai reliance model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fukuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yamada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">881</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Optimo: Online probabilistic trust inference model for asymmetric human-robot collaborations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dudek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI&apos;15</title>
		<meeting>the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI&apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="221" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Principles and Practice of Structural Equation Modeling</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kline</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>Guilford Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dynamic structural equation models</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L H</forename><surname>Tihomir Asparouhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="359" to="388" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Out-of-sample tests of forecasting accuracy: An analysis and review</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tashman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="437" to="450" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bdd100k: A diverse driving dataset for heterogeneous multitask learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR&apos;20)</title>
		<meeting>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR&apos;20)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A social approach for autonomous vehicles: A robotic object to enhance passengers&apos; sense of safety and trust</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chakravarthi Kumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bechor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Erel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI&apos;24)</title>
		<meeting>the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI&apos;24)</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="86" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS&apos;17)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning to forget: continual prediction with LSTM</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2451" to="2471" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Zero-shot learning to enable error awareness in data-driven hri</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ravishankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Doering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI&apos;24)</title>
		<meeting>the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI&apos;24)</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="592" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Lie, repent, repeat: Exploring apologies after repeated robot deception</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J A</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Gorostiaga</forename><surname>Zubizarreta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI&apos;24)</title>
		<meeting>the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI&apos;24)</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="602" to="610" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
