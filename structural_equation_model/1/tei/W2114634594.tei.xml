<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multiplicity Control in Structural Equation Modeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Robert</forename><forename type="middle">A</forename><surname>Cribbie</surname></persName>
							<email>cribbie@yorku.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">York University</orgName>
								<orgName type="institution" key="instit2">York Uni- versity</orgName>
								<address>
									<postCode>M3J 1P3</postCode>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">York University</orgName>
								<orgName type="institution" key="instit2">York Uni- versity</orgName>
								<address>
									<postCode>M3J 1P3</postCode>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multiplicity Control in Structural Equation Modeling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1080/10705510709336738</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Researchers conducting structural equation modeling analyses rarely, if ever, control for the inflated probability of Type I errors when evaluating the statistical significance of multiple parameters in a model. In this study, the Type I error control, power and true model rates of famsilywise and false discovery rate controlling procedures were compared with rates when no multiplicity control was imposed. The results indicate that Type I error rates become severely inflated with no multiplicity control, but also that familywise error controlling procedures were extremely conservative and had very little power for detecting true relations. False discovery rate controlling procedures provided a compromise between no multiplicity control and strict familywise error control and with large sample sizes provided a high probability of making correct inferences regarding all the parameters in the model.</p><p>Researchers in the educational and behavioral sciences are increasingly turning to structural equation modeling (SEM) to answer complex multivariate hypotheses. This increase has been triggered by advances in SEM software and the availability of Web-and text-based resources for conducting SEM analyses. Although many issues surrounding the application of SEM have received dedicated attention in the literature (e.g., approximate fit indexes, estimation methods, assumption violation), research into the issue of appropriate multiplicity control when testing multiple parameters in SEM has been scarce.</p><p>When researchers are faced with evaluating the adequacy of a particular model, they are often interested in both the overall fit of the model and which of the proposed relations (parameters) in the model are (or are not) important. With respect to determining the importance of individual parameters, two alternatives have dominated the empirical literature, falling under the general categories of exploratory or confirmatory parameter investigations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Exploratory parameter investigations utilize residual statistics and sequential model modification indexes to identify which parameters to remove from or add to the model to improve the fit of the model to the sample data. This option is acceptable when the analysis is designated as exploratory and the goal of the analysis is only to derive or improve a theoretical model for future evaluation. However, researchers should be aware that (a) changes to the model are data driven and do not provide any substantive evidence about the validity of the model, (b) the probability of making decision errors is related to the number of model modifications and the criteria adopted for declaring model modifications statistically significant <ref type="bibr" target="#b11">(Green &amp; Babyak, 1997;</ref><ref type="bibr" target="#b12">Hancock, 1999;</ref><ref type="bibr" target="#b19">MacCallum, 1986;</ref><ref type="bibr" target="#b21">MacCallum, Roznowski, &amp; Necowitz, 1992)</ref>, and (c) specification searches can be unreliable detectors of specification errors (e.g., <ref type="bibr" target="#b15">Hutchinson, 1993;</ref><ref type="bibr" target="#b16">Kaplan, 1988;</ref><ref type="bibr" target="#b19">MacCallum, 1986;</ref><ref type="bibr" target="#b21">MacCallum et al., 1992;</ref><ref type="bibr" target="#b26">Silvia &amp; MacCallum, 1988)</ref>.</p><p>Confirmatory parameter investigations (assuming a satisfactory fit of the model to the sample data) evaluate the significance of each hypothesized parameter at a specified significance level (α), declaring statistically significant parameters important and nonsignificant parameters unimportant, within the framework of the model. This strategy is acceptable only if the researcher is willing to assume that no Type I error inflation will arise when multiple hypotheses are tested.</p><p>The current state of multiplicity control in confirmatory SEM can be summarized very easily: There is no multiplicity control! However, that is not to say that there is no discussion of the issue. A review of the archives of SEMNET, the online SEM network group, produced several comments regarding multiplicity control in SEM. For example:</p><p>• "I am wondering if you should use a Bonferroni correction procedure for in- terpreting critical ratios (also called t tests). For example, if 10 estimates are produced, perhaps you should use a significance level of .005 for any one parameter" <ref type="bibr" target="#b3">(Burns, 1996)</ref>.</p><p>• "Many students regrettably pick out the 'significant' results and report only those. One pragmatic approach is to apply the Bonferroni correction when reporting only N out of M tests applied" <ref type="bibr">(Reese, 2001)</ref>.</p><p>• "My statistics professor on my dissertation committee asked me how does AMOS control for Type I error (likelihood of finding significant relationships when running multiple analyses on the same data). He asked is it doing a Bonferroni adjustment, or what is it doing? I will need to address this in my dissertation revision" <ref type="bibr" target="#b22">(Moynihan, 2002)</ref>.</p><p>• "I was talking to my supervisors (who have never used SEM before) and they argued that you could expect 1 in 20 correlations between variables to be significant and if you have more than 20 paths that you could expect that one of those paths would be significant even if there was no correlation between the variables. They wondered if it makes sense to apply a Bonferroni correction on the p values of your estimated parameters to account for this possibility" ( <ref type="bibr" target="#b30">Van der Heijden, 2005)</ref>.</p><p>Popular responses against multiplicity control in SEM research usually fall under one of two categories: (a) the issues surrounding multiplicity control in SEM are identical to the issues raised in other forms of correlational analysis (where only very rarely is multiplicity control invoked when multiple parameters or correlations are evaluated); or (b) the parameters in SEM models are correlated so multiplicity adjustments would be too conservative (e.g., <ref type="bibr">Mulaik, 2004;</ref><ref type="bibr" target="#b23">Owen, 2004;</ref><ref type="bibr">Ronis, 2002)</ref>. However, the arguments in support of multiplicity control are extremely convincing. First, there have been many (mostly ignored) warnings concerning multiplicity control in correlational research (e.g., <ref type="bibr" target="#b4">Collis &amp; Rosenblood, 1985;</ref><ref type="bibr" target="#b8">Crosbie, 1986;</ref><ref type="bibr" target="#b9">Cudeck &amp; O'Dell, 1994;</ref><ref type="bibr" target="#b18">Larzelere &amp; Mulaik, 1977)</ref> and yes, the same issues apply to SEM research. Second, the hypotheses tested in SEM are often more confirmatory in nature, and regarded as much more definitive, than other correlational analyses and therefore warrant significantly more attention. Third, the fact that parameters in a model are often highly intercorrelated does affect the conservativeness of Type I error controlling procedures, but because researchers are typically unaware of the degree to which parameters within their model are correlated, and the correlations between parameter estimates decrease when a model is well identified, researchers must be conscious of the possible risk of falsely declaring parameters significant. <ref type="bibr" target="#b20">MacCallum (1995)</ref> added that although models with several correlated parameters tend to fit the data well, they are often not disconfirmable and thus make finding a good fit meaningless. Finally, in a preliminary study of the impact of interpreting the significance of several parameters in a structural model on the inflation of Type I errors, <ref type="bibr" target="#b5">Cribbie (2000)</ref> concluded that the Type I error inflation was too extreme to ignore and that some form of multiplicity control was necessary.</p><p>An important issue that frequently arises in the application of multiplicity control is what family or set of parameters in which to apply the control. The goal of specifying a family of hypotheses is to select a set that is not so large that it is impossible to ever reject any hypothesis, yet is not so small that it does not provide adequate control of Type I errors. Further, a family should consist of those tests that are related in terms of their intended use <ref type="bibr" target="#b14">(Hochberg &amp; Tamhane, 1987)</ref>. In this research, Type I error control was applied over all parameters in the structural model, which often represent the important hypotheses within the model. However, there is no reason that multiplicity control could not also be imposed in other parts of the model, and may be extremely relevant in research where the measurement model is of utmost importance (e.g., confirmatory factor analysis).</p><p>With respect to multiplicity control, there are several different units of analysis (i.e., error rates) that have been proposed and that vary in how strictly they control the rate of Type I errors. Although the majority of discussion in the literature has focused on the familywise error rate versus no multiplicity control (e.g., <ref type="bibr" target="#b24">Ryan, 1959;</ref><ref type="bibr" target="#b27">Toothaker, 1991;</ref><ref type="bibr" target="#b29">Tukey, 1953)</ref>, other error rates, such as the false discovery rate (FDR; <ref type="bibr" target="#b0">Benjamini &amp; Hochberg, 1995)</ref>, have also been proposed. When no multiplicity control is imposed, all tests of significance are conducted at α (i.e., the per-test Type I error rate). The advantages of imposing no control include consistency (regardless of the number of tests being conducted, the Type I error rate for each test is held constant) and power, and the disadvantage is that there is a potential increase in the overall Type I error rate when multiple tests of significance are performed. The familywise error rate is defined as the probability of falsely rejecting one or more hypotheses in a family of hypotheses. The main advantage of familywise error control is that the probability of committing a Type I error does not increase as more tests of significance are conducted, whereas the disadvantage is that per-test power can become severely deflated as the number of hypothesis tests increases. Finally, <ref type="bibr" target="#b0">Benjamini and Hochberg (1995)</ref> presented a compromise between no multiplicity control and strict familywise error control, namely the FDR. The FDR is defined as the expected ratio (Q) of the number of erroneous rejections (V) to the total number of rejections (R = V + S), where S represents the number of true rejections <ref type="bibr" target="#b1">(Benjamini, Hochberg, &amp; Kling, 1994)</ref>. Therefore, E (Q) = E (V / (V + S)) = E (V / R). The relation between FDR control and other error rates was summarized by <ref type="bibr" target="#b1">Benjamini et al. (1994)</ref>. If all null hypotheses are true, the FDR equals the familywise error rate. On the other hand, if some of the null hypotheses are false, the FDR is less than the familywise error rate, which can result in a significant increase in power for a procedure that controls the FDR. <ref type="bibr" target="#b17">Keselman, Cribbie, and Holland (2002)</ref> demonstrated that the FDR procedure provides excellent power (relative to familywise error controlling procedures) in experiments with large family sizes (e.g., testing all correlations in a 16 × 16 matrix), while still providing acceptable Type I error control.</p><p>Therefore, the purpose of this investigation is to explore the application of multiplicity control within the framework of SEM and compare available methods for multiplicity control with respect to Type I error control and power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHOD</head><p>A Monte Carlo study was used to compare the Type I error control, per parameter power, and true model rates of the no multiplicity control approach with that of two familywise error controlling procedures and two FDR controlling procedures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple Testing Procedures</head><p>Bonferroni (Bonf). In this well-known procedure, the p values corresponding to the k parameter estimates are compared to an α pp = α/k, where α pp is the per-parameter Type I error rate and α is a predetermined, acceptable, familywise error rate. The Bonferroni method controls the familywise error rate at α by declaring any parameter with p ≤ α pp significant. <ref type="bibr" target="#b13">Hochberg's (1988)</ref> sequentially acceptive step-up Bonferroni (Hoch). In this familywise error controlling procedure, the p values corresponding to the k parameter estimates are ordered from smallest to largest. Then, for any I = k, k -1, … , 1, if p i ≤ α/(k -I + 1), the Hochberg procedure rejects all parameters associated with p i′ (I′ ≤ I). Therefore, one begins by testing the largest p value, p k , and declares all parameters significant if p k ≤ α. If p k &gt; α then the parameter associated with p k is declared nonsignificant and one proceeds to compare p k -1 to α/2. If p k -1 ≤ α/2 then all parameters associated with p i (I = k -1, … , 1) are declared significant, but if p k -1 &gt; α/2 then the parameter associated with p k -1 is declared nonsignificant and one proceeds to compare p k -2 to α/3, and so on. <ref type="bibr" target="#b0">Benjamini and Hochberg's (1995)</ref> false discovery rate controlling step-up Bonferroni (FDR). Like Hochberg's step-up procedure, the p values corresponding to the k parameter estimates are ordered from smallest to largest. Then, for any I = k, k -1, … , 1, if p i ≤ α(I/k), the FDR procedure rejects all parameters associated with p i (I′ ≤ I). Therefore, one begins by testing the largest p value, p k , and declares all parameters significant if p k ≤ α. If p k &gt; α then the parameter associated with p k is declared nonsignificant and one proceeds to compare p k -1 to α(k -1/k). If p k -1 ≤ α(k -1/k) then all parameters associated with p i (I = k -1, … , 1) are declared significant, but if p k -1 &gt; α(k -1/k) then the parameter associated with p k -1 is declared nonsignificant and one proceeds to compare p k -2 to α(k -2/ k), and so on. <ref type="bibr" target="#b2">Benjamini and Yekutieli (2001)</ref> provided evidence that this procedure provides strong FDR control under the type of parameter dependencies encountered in latent variable models.</p><p>Benjamini and Yekutieli's ( <ref type="formula">2001</ref>) FDR (FDR-BY). <ref type="bibr" target="#b2">Benjamini and Yekutieli (2001)</ref> proposed a modification to the original FDR procedure that would be more conservative and control the FDR across any parameter dependence structure (referred to here as the FDR-BY). Like the original FDR procedure, the p values corresponding to the k parameter estimates are ordered from smallest to largest. Then, for any I = k, k -1, … , 1, if p i ≤ α[I / (k Σ r 1/r), r = 1, …, k, the FDR-BY procedure rejects all parameters associated with p i′ (I′ ≤ I).</p><p>The models investigated in this article were derived from studies by Trierweiler, Eid, and Lischetzke (2002, Model A; see Figure <ref type="figure">1</ref>) and <ref type="bibr">Dunkley, Zuroff, and Blankstein (2003, Model B;</ref><ref type="bibr"></ref> see Figure <ref type="figure">2</ref>). In the <ref type="bibr" target="#b28">Trierweiler et al. (2002)</ref> study, the authors were interested in exploring relations between emotional expressions (love, joy, fear, anger, shame, sadness) and the Big Five personality dimensions (extraversion, agreeableness, conscientiousness, neuroticism, intellect). In the <ref type="bibr" target="#b10">Dunkley et al. (2003)</ref> study, the authors were interested in exploring predictors of negative and positive affect, including hassles, avoidant coping, perceived social support, self-critical perfectionism, personal standards perfectionism, event stress, and problem-focused coping. Empirical models were utilized to provide a theoretical framework for exploring issues related to assessing multiple hypotheses, and these particular models were selected because there were a moderate to large number of constructs that would likely be familiar to most readers. Model A had 179 df with 30 hypothesis tests in the structural model and Model B had 150 df with 20 hypothesis tests in the structural model. Type I error control was evaluated with respect to familywise error rates (i.e., the probability of declaring at least one null parameter statistically significant). Per-parameter power was evaluated as the average proportion of nonzero parameters declared statistically significant. The true model rate was evaluated as the proportion of simulations in which the true underlying model configuration was recovered (i.e., all nonzero parameters were declared statistically significant and all null parameters were declared not statisti-FIGURE <ref type="figure">1</ref> The first theoretical model used in the Monte Carlo study (Model A), based on a study by <ref type="bibr" target="#b28">Trierweiler, Eid, and Lischetzke (2002)</ref>. cally significant). <ref type="bibr" target="#b6">Cribbie (2003)</ref> and <ref type="bibr" target="#b7">Cribbie and Keselman (2003)</ref> previously used the true model rate to compare the Type I error control and power of multiple comparison procedures in a mean comparison framework. Although the true model rate is an extremely conservative criterion, it is recommended as a measure of the performance of multiple testing procedures because it simultaneously investigates Type I error control and power.</p><p>Three other variables were investigated in this study: (a) sample size (N = 200 and N = 1,000), (b) type of misspecification, and (c) number of misspecifications in the model (6 or 12 for Model A; 5 or 10 for Model B). The sample sizes were selected to be representative of those encountered by applied researchers. Misspecifications were established by estimating (freeing) paths between variables in the model that are not related in the true model. In addition to a no misspecification condition, two forms of misspecification were investigated in this study: (a) dependent misspecification, where all misspecified paths originate from one (in the case of 5 or 6 misspecifications) or two (in the case of 10 or 12 misspecifications) of the latent variables; or (b) independent misspecification, where the misspecified paths were as unrelated as possible. In deriving an implied covariance matrix, population factor variances were set at 1.0, interfactor covariances were set at .18, factor loadings were set to .80, and error variances were set to .36 (resulting in unit variance for the observed variables). Misspecifications (following the format de-FIGURE <ref type="figure">2</ref> The second theoretical model used in the Monte Carlo study (Model B), based on a study by <ref type="bibr" target="#b10">Dunkley, Zuroff, and Blankstein (2003)</ref>. Note: avoid coping = avoidant coping; per soc sup = perceived social support; slf crt perf = self-critical perfectionism; per stds perf = personal standards perfectionism; prb foc coping = problem-focused coping. scribed earlier) were established by fixing the covariances between observed variables loading on separate, but theoretically correlated, factors to 0 in the model specified covariance matrix. To summarize the design of the study, there are two separate models, two sample size conditions, two types of misspecification (in addition to a case where no misspecifications were present), and two conditions for the number of misspecifications.</p><p>SEM analyses were performed using SAS PROC CALIS (SAS Institute, 1999) and preliminary analyses were conducted to determine the fit of the models to the data using the comparative fit index (CFI) and root mean square error of approximation (RMSEA). One thousand replications were performed for each condition using a nominal significance level of .05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fit Indexes</head><p>The fit indexes under each of the experimental conditions are presented in Table <ref type="table">1</ref>. The fit of the model to the sample data was excellent for both models under all conditions investigated in this study, with mean CFI values greater than .99 and RMSEA values less than .02. An interesting finding was that the fit of the models remained excellent even when several of the parameters in the structural model were misspecified. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Familywise Error Rates</head><p>Familywise error rates for each of the multiple testing procedures, under each of the testing conditions, are presented in Table <ref type="table">2</ref>. As expected, the familywise error rates when no multiplicity control was imposed significantly exceeded the per-parameter alpha of .05, and were larger than the rates for any of the remaining procedures. The familywise rates when no multiplicity control was imposed ranged from .205 for 6 dependent misspecifications and N = 1,000 to .616 for 12 independent misspecifications and N = 200. The familywise error rates for the FDR procedure were greater than for the remaining procedures, with the Bonf approach having the most conservative rates. The FDR-BY procedure was extremely conservative with a small sample size, but had larger rates than Note. NC = no familywise error control; Bonf = Bonferroni; Hoch = Hochberg; FDR = false discovery rate; FDR-BY = Benjamin &amp; Yekutieli's conservative FDR; Dependent = misspecifications from the same latent variable(s); Independent = misspecifications not all from the same latent variable(s).</p><p>the familywise error controlling procedures (Bonf, Hoch) with a large sample size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Per-Parameter Power</head><p>Per-parameter power rates for each of the multiple testing procedures, under each of the testing conditions, are presented in Table <ref type="table">3</ref>. Per-parameter power rates when no multiplicity control was imposed were, as expected, larger than for any of the remaining procedures in any condition, ranging from .242 to .527 for N = 200 and Note. NC = no familywise error control; Bonf = Bonferroni; Hoch = Hochberg; FDR = false discovery rate; FDR-BY = Benjamin &amp; Yekutieli's conservative FDR; Dependent = misspecifications from the same latent variable(s); Independent = misspecifications not all from the same latent variable(s).</p><p>.834 to .996 for N = 1,000. Per-parameter power rates for the FDR procedure, ranging from .100 to .353 for N = 200 and .566 to .996 for N = 1,000, were larger than for the remaining familywise error controlling procedures (Bonf, Hoch), although the differences were less pronounced in the large sample size condition where ceiling effects limited the amount of variability in the rates. The Hoch procedure was slightly more powerful than the Bonf procedure in all conditions investigated. Per-parameter power rates for the FDR-BY procedure were less than those for the FDR, but larger than for the Bonf and Hoch familywise error controlling procedures with a large sample size. For Model A, power rates when there were dependent misspecifications were significantly depressed relative to the rates for independent misspecifications, whereas for Model B (where the parameter structure is less defined) power rates when there were dependent misspecifications were very similar to rates when there were independent misspecifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>True Model Rates</head><p>True model rates for each of the multiple testing procedures for N = 1,000 are presented in Table <ref type="table">4</ref>. The true model rates investigate the performance of multiple testing procedures by simultaneously incorporating both Type I error control and power (in other words to detect the true model means that no Type I or Type II errors were committed). True model rates for N = 200 were 0, regardless of Note. NC = no familywise error control; Bonf = Bonferroni; Hoch = Hochberg; FDR = false discovery rate; FDR-BY = Benjamin &amp; Tekutieli's conservative FDR; Dependent = misspecifications from the same latent variable(s); Independent = misspecifications not all from the same latent variable(s).</p><p>the number or type of misspecifications or the multiple testing procedure utilized and are therefore not presented. For N = 1,000 and no misspecifications, the true model rates of the no multiplicity control, FDR, and Hoch procedures were equal (.874). When misspecifications were present, the true model rates of the FDR procedure were larger than the rates of any of the other procedures across all conditions, with rates ranging from .273 to .636 for Model A and .518 to .637 for Model B. The true model rates in the no multiplicity control condition were slightly less than that of the FDR procedure, and the true model rates of the FDR-BY procedure were larger than that of the Hoch and Bonf procedures. True model rates for the Bonf procedure were extremely low, reaching a maximum of .146.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>Researchers conducting SEM analyses rarely (or possibly never) impose any type of multiplicity control when evaluating the significance of multiple parameters. However, past research has shown that even when dependencies among the parameters exist, familywise error rates are expected to be inflated when multiple null parameters are estimated (e.g., <ref type="bibr" target="#b18">Larzelere &amp; Mulaik, 1977)</ref>. This article looked at the effects of evaluating the statistical significance of multiple parameters in the structural model and the results confirm that Type I error inflation becomes extreme when no multiplicity control is imposed. The Type I error inflation is slightly reduced when dependencies among parameters exist, although the rates still greatly exceed the nominal alpha level. Is the rate of Type I error inflation excessive? That is a difficult question, but I believe the point is that if a researcher believes that his or her probability of erroneously declaring any parameter significant is alpha (say .05), then any inflation of the Type I error rate above .05 would be problematic and for most researchers the .20 to .60 probabilities of erroneously declaring a parameter significant reported in this article would likely be alarming.</p><p>This research confirms that the original FDR procedure <ref type="bibr" target="#b0">(Benjamini &amp; Hochberg, 1995)</ref> provides a compromise position between no multiplicity control and strict familywise error control, providing more power than familywise error controlling procedures but more Type I error control than when no multiplicity control is imposed. Further, the results of this investigation demonstrate the extreme conservativeness of the Bonferroni procedure relative to the remaining procedures. In fact, besides ease of computation, there is no reason to recommend the Bonferroni procedure even if strict Type I error control is desired, given that other familywise error controlling procedures (e.g., the Hochberg procedure used in this study) can provide good Type I error control and can be significantly more powerful than the Bonferroni procedure. The FDR procedure due to <ref type="bibr" target="#b2">Benjamini and Yekutieli (2001)</ref> was extremely conservative with small sample sizes, but provided good Type I error control with larger sample sizes and was more powerful than the Bonferroni or Hochberg procedures. In fact, although the procedure is not designed to control the familywise error rate at alpha, the familywise rates never exceeded .076 in any of the conditions investigated in this study.</p><p>An important component to this investigation was an evaluation of the true model rates of the multiple testing procedures. The true model rates, or the probability of making correct statistical decisions regarding all parameters in the structural model, were largest for the more liberal Type I error controlling strategies. More specifically, the true model rates were highest when the original <ref type="bibr" target="#b0">Benjamini and Hochberg (1995)</ref> FDR procedure was utilized (although in most cases the rates were only slightly greater than that of the no familywise error control approach). The true model rates of the more conservative FDR controlling procedure due to <ref type="bibr" target="#b2">Benjamini and Yekutieli (2001)</ref> were very respectable when sample sizes were large, especially considering the strict Type I error control that was observed. The true model rates also confirm that controlling the familywise error rate with the conservative Bonferroni correction is not recommended and make it highly unlikely that a researcher will uncover all of the true relations in the model.</p><p>An important limitation of this study was that only two models were considered. It will be important in future research to explore how the results of this study extend to other types of models, which can obviously vary considerably in both the nature of the model as well as the number of parameters estimated. A reviewer of this article also pointed out that the reliability of the indicators was not varied, and could possibly affect the results. Future studies should also investigate the effects of indicator reliability on parameter error rates.</p><p>To summarize, the results of this investigation highlight that the Type I error inflation that occurs when multiple parameters are investigated in SEM can become extreme, but also point out that the best methods for maximizing the probability of making correct inferences regarding all parameters in the model are the most liberal methods that result in the highest rates of Type I error. So how does this help in making recommendations to researchers regarding multiplicity control in SEM? First, consider the response of Mulaik ( <ref type="formula">2004</ref>) to a researcher enquiring about whether to adopt Bonferroni control when evaluating the significance of multiple parameters in a model: You do not ordinarily take an alpha level and divide it by the number of dependent tests to perform to get an alpha-per-test. That could be too conservative. What the alpha-per-test should be based on is an initial risk expressed as a probability with which one would be willing to accept making at least one type I error among the series of tests. The alpha-per-test is then the result of dividing alpha familywise by the number k of tests to perform in the family or series. There is no absolute rule by which one would select the alpha familywise. But it should be larger than the usual .05. Given many tests with an alpha-per-test of .05/k, it would be unduly conservative in favor of accepting the null hypothesis over the series.</p><p>Mulaik's response that a Bonferroni correction would be too conservative mirrors the results of this study. Further, Mulaik's suggestion that a familywise error rate should be selected based on a risk with which one would be willing to accept making at least one Type I error over all parameters is in line with the goals of this article, but what familywise rate would we recommend to researchers <ref type="bibr">(.10, .20, etc.)</ref>?</p><p>Given the findings of this research it is recommended that, instead of focusing on selecting an appropriate elevated familywise error rate, that researchers maintain alpha at the desired level (e.g., .05), but adopt control of the FDR. If maximizing power is important then the original FDR procedure due to <ref type="bibr" target="#b0">Benjamini and Hochberg (1995)</ref> would be recommended, but if more strict Type I error control is necessary the more conservative <ref type="bibr" target="#b2">Benjamini and Yekutieli (2001)</ref> FDR controlling procedure would be recommended. Either of these methods will provide researchers with more Type I error control than when no multiplicity control is imposed, but more power than when a familywise error controlling procedure is adopted.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate: A practical and powerful approach to multiple testing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society B</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="289" to="300" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">False discovery rate controlling procedures for pairwise comparisons</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note>Unpublished manuscript</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The control of the false discovery rate in multiple testing under dependency</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yekutieli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1165" to="1188" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A quick question. Message posted to semnet@bama</title>
		<author>
			<persName><forename type="first">D</forename><surname>Burns</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996-04-17">1996. April 17</date>
		</imprint>
	</monogr>
	<note>ua.edu</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The problem of inflated significance when testing individual correlations from a correlation matrix</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Collis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Rosenblood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal for Research in Mathematics Education</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="52" to="55" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Evaluating the importance of individual parameters in structural equation modeling: The need for Type I error control</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Cribbie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personality and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="567" to="577" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pairwise multiple comparisons: New yardstick, new results</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Cribbie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Experimental Education</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="251" to="265" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pairwise multiple comparisons: A model comparison approach versus stepwise procedures</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Cribbie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Keselman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="167" to="182" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Pascal program to perform the Bonferroni multistage multiple-correlation procedure</title>
		<author>
			<persName><forename type="first">J</forename><surname>Crosbie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments and Computers</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="327" to="329" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Applications of standard error estimates in unrestricted factor analysis: Significance tests for factor loadings and correlations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cudeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>O'dell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="475" to="487" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Self-critical perfectionism and daily affect: Dispositional and situational influences on stress and coping</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Dunkley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Zuroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Blankstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="234" to="252" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Control of Type I errors with multiple tests of constraints in structural equation modeling</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Babyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="39" to="51" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A sequential Scheffé-type respecification procedure for controlling Type I error in exploratory structural equation model modification</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="158" to="168" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A sharper Bonferroni procedure for multiple tests of significance</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="800" to="802" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Multiple comparison procedures</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Tamhane</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Univariate and multivariate specification search indices in covariance structure modeling</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Hutchinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Education</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="171" to="181" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The impact of specification error on the estimation, testing, and improvement of structural equation models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="69" to="86" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Controlling the rate of Type I error over a large set of statistical tests</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Keselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Cribbie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Holland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="27" to="39" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Single-sample tests for many correlations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Larzelere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mulaik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="557" to="569" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Specification searches in covariance structure modeling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="107" to="120" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Model specification: Procedure, strategies, and related issues</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural equation modeling: Concepts, issues, and applications</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Hoyle</surname></persName>
		</editor>
		<meeting><address><addrLine>Newbury Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Sage</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="16" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Model modifications in covariance structure analysis: The problem of capitalization on chance</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Roznowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Necowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="490" to="504" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Type I error in path analysis. Message posted to semnet@bama.ua.edu Mulaik, S</title>
		<author>
			<persName><forename type="first">L</forename><surname>Moynihan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002-07-23">2002, July 23. 2004. January 27</date>
		</imprint>
	</monogr>
	<note>Bonferroni tests. Message posted to semnet@bama.ua.edu</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bonferroni tests. Message posted to semnet@bama.ua.edu Reese, R. A</title>
		<author>
			<persName><forename type="first">S</forename><surname>Owen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Type I error in path analysis</title>
		<imprint>
			<date type="published" when="2001-06-01">2004. January 28. 2001. June 1. 2002, July 25</date>
		</imprint>
	</monogr>
	<note>Reporting significance level. Message posted to semnet@bama. ua.edu Ronis, D. L.. Message posted to semnet@bama.ua.edu</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multiple comparisons in psychological research</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Ryan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="26" to="47" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m">SAS/STAT user&apos;s guide</title>
		<meeting><address><addrLine>Cary, NC</addrLine></address></meeting>
		<imprint>
			<publisher>Author</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>SAS Institute.</orgName>
		</respStmt>
	</monogr>
	<note>version 6, 4th ed.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Some factors affecting the success of specification searches in covariance structure modeling</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S M</forename><surname>Silvia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="297" to="326" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Multiple comparisons for researchers</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Toothaker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Sage</publisher>
			<pubPlace>Newbury Park, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The structure of emotional expressivity: Each emotion counts</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Trierweiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lischetzke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="1023" to="1040" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The problem of multiple comparisons. Unpublished manuscript, Princeton University</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1953">1953</date>
			<publisher>Department of Statistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Van Der Heijden</surname></persName>
		</author>
		<title level="m">Bonferroni correction. Message posted to: semnet@bama</title>
		<imprint>
			<date type="published" when="2005-06-08">2005. June 8</date>
		</imprint>
	</monogr>
	<note>ua.edu</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
