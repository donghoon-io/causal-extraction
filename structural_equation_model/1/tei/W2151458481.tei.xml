<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BIC and Alternative Bayesian Information Criteria in the Selection of Structural Equation Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2019-07-29">2019 July 29.</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Kenneth</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
							<email>bollen@unc.edu</email>
						</author>
						<author>
							<persName><forename type="first">Jeffrey</forename><forename type="middle">J</forename><surname>Harden</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Surajit</forename><surname>Ray</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Political Science</orgName>
								<orgName type="laboratory">Senior Lecturer</orgName>
								<orgName type="institution">University of Colorado Boulder</orgName>
								<address>
									<postCode>80309</postCode>
									<settlement>Boulder</settlement>
									<region>CO</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jane</forename><surname>Zavisca</surname></persName>
						</author>
						<author>
							<persName><roleName>Distinguished Professor,</roleName><forename type="first">H</forename><forename type="middle">R</forename><surname>Immerwahr</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Sociology</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<settlement>Chapel Hill</settlement>
									<region>NC</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Mathematics &amp; Statistics</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">Scotland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Sociology</orgName>
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<postCode>85721</postCode>
									<settlement>Tucson</settlement>
									<region>AZ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BIC and Alternative Bayesian Information Criteria in the Selection of Structural Equation Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-07-29">2019 July 29.</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1080/10705511.2014.856691</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayes Factor</term>
					<term>Structural Equation Models</term>
					<term>BIC</term>
					<term>Chi-Square Tests</term>
					<term>Model Fit</term>
					<term>Model Selection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Selecting between competing Structural Equation Models (SEMs) is a common problem. Often selection is based on the chi square test statistic or other fit indices. In other areas of statistical research Bayesian information criteria are commonly used, but they are less frequently used with SEMs compared to other fit indices. This article examines several new and old Information Criteria (IC) that approximate Bayes Factors. We compare these IC measures to common fit indices in a simulation that includes the true and false models. In moderate to large samples, the IC measures outperform the fit indices. In a second simulation we only consider the IC measures and do not include the true model. In moderate to large samples the IC measures favor approximate models that only differ from the true model by having extra parameters. Overall, SPBIC, a new IC measure, performs well relative to the other IC measures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Structural equation models (SEMs) refer to a widely used general class of statistical models. SEMs are well-established in the social and behavioral sciences, and are diffusing to the health and natural sciences (e.g., <ref type="bibr" target="#b1">Bentler and Stein 1992;</ref><ref type="bibr" target="#b27">Shipley 2000;</ref><ref type="bibr" target="#b25">Schnoll et al. 2004;</ref><ref type="bibr" target="#b2">Beran and Violato 2010)</ref>. Key issues in the use of SEMs are determining the fit of the model to the data and comparing the relative fit of two or more models to the same data. An asymptotic chi-square distributed test statistic that tests whether a SEM exactly reproduces the covariance matrix of observed variables was the first test and index of model fit <ref type="bibr" target="#b13">(Jöreskog 1969</ref><ref type="bibr" target="#b14">(Jöreskog , 1973))</ref>. However, given the approximate nature of most models and the enhanced statistical power that generally accompanies a large sample size, the chi-square test statistic routinely rejects models in large samples regardless of their merit as approximations to the underlying process. Starting with <ref type="bibr" target="#b30">Tucker and Lewis (1973)</ref> and <ref type="bibr" target="#b15">Jöreskog and Sörbom (1979)</ref>, a variety of fit indices have been developed to supplement the chi-square test statistic (see <ref type="bibr" target="#b5">Bollen and Long 1993)</ref>. Controversy surrounds these alternative fit indices for several reasons. For example, the sampling distribution of a particular fit index is often not known. Additionally, sometimes the fit index tends to increase as sample size increases <ref type="bibr">(Bollen 1989, 269-281)</ref>. Finally, there is disagreement about the optimal cutoff values for a "well-fitting" model.</p><p>Researchers frequently use the Bayesian Information Criterion (BIC) to compare the fit of models in multiple regression, generalized linear models, and several other areas of statistical modeling <ref type="bibr" target="#b22">(Raftery 1995</ref>). Yet despite this common use, the BIC has received little attention in the SEM literature. <ref type="bibr" target="#b7">Cudeck and Browne (1983)</ref> and <ref type="bibr" target="#b4">Bollen (1989)</ref> give only brief mention to <ref type="bibr" target="#b26">Schwarz's (1978)</ref> BIC as an approximation to the Bayes Factor. <ref type="bibr" target="#b21">Raftery (1993</ref><ref type="bibr" target="#b22">Raftery ( , 1995) )</ref> provides more discussion of the BIC in SEMs, as do <ref type="bibr" target="#b12">Homburg (1991)</ref> and <ref type="bibr" target="#b11">Haughton et al. (1997)</ref>. However, compared to the RMSEA, CFI, or other fit indices, it is less common to see the BIC in applications of SEMs, despite its potential value in comparing the fit of competing models. It is known that asymptotically the BIC should choose the true model structure when it is included among the choices (e.g., <ref type="bibr" target="#b9">Hannan and Quinn 1979)</ref>, but this tells us little about how the BIC works in small to moderate sized samples. Furthermore, we know of no study that examines the BIC in SEM model selection when none of the candidate models is the true model, which is the most common situation in applied research.</p><p>The primary purpose of this article is to examine the performance of different Information Criteria (IC) based on Bayes Factors in model selection in SEM. We compare the BIC, the Haughton Bayesian Information Criterion (HBIC, see <ref type="bibr" target="#b10">Haughton 1988)</ref>, and two new IC measures: the Information Matrix-Based Information Criterion (IBIC) and the Scaled Unit Information Prior Bayesian Information Criterion (SPBIC, see <ref type="bibr" target="#b5">Bollen et al. 2012</ref>). In the course of presenting the IBIC and SPBIC, we explain their potential use in choosing among models. 1  <ref type="bibr" target="#b5">Bollen et al. (2012)</ref> present the theoretical justifications for the IBIC and SPBIC, but they only examine them in a multiple regression context; no one has examined them in the context of SEMs. Our analysis is restricted to IC-based approximations to the Bayes Factor; we do not attempt a fully Bayesian analysis. In so doing, we follow the practice of the vast majority of social and behavioral scientists working with other types of statistical models beyond SEM. 2   Our simulation has two parts: 1) when the true model is among the choices and 2) when all models are approximations. The first simulation compares the success of the BIC, HBIC, IBIC, SPBIC, and more common SEM fit indices in finding the true model across sample 1 The online appendix and complete replication materials for the analyses presented here are available at <ref type="url" target="http://dvn.iq.harvard.edu/dvn/dv/jjharden">http:// dvn.iq.harvard.edu/dvn/dv/jjharden</ref>. 2 A dedicated Bayesian statistician would prefer formal Bayesian analyses, by specifying explicit prior probabilities to develop actual Bayes Factors, which could then be compared to the various IC approximations. Though we recognize the value of this approach as an ideal, social and behavioral scientists in practice rarely work with prior distributions, but instead use IC based measures that do not require prior specifications for model selection. Our goal is to assess the accuracy of such IC measures for selecting the true model or the best approximation to the true model in SEM, an area that has received little attention, and with some IC measures that are new. sizes ranging from 100 to 5000. Asymptotically, the BIC, HBIC, IBIC, and SPBIC should select the true model, but we do not know their behavior in small to moderate sample sizes. In addition, we have no information on which, if any of the IC measures, approach their asymptotic behavior more quickly. The second simulation addresses the behavior of the IC measures when the true model is not in the pool of models.</p><p>The next section introduces the SEM equations and assumptions and reviews the current methods of assessing SEM model fit. Following this is a section in which we present the Bayes Factor, the BIC, and the HBIC, IBIC, and SPBIC. We then describe our Monte Carlo simulation study that examines the behavior of various model selection criteria for a series of models that are either correct, underspecified, or overspecified. An empirical example then illustrates the IC measures in model selection. Finally, we conclude with a discussion of the implications of the results and recommendations for researchers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Structural Equation Models and Fit Indices</head><p>SEMs have two primary components: a latent variable model and a measurement model. We write the latent variable model<ref type="foot" target="#foot_1">foot_1</ref> as:</p><formula xml:id="formula_0">η = α η + Bη + Γξ + ζ . (1)</formula><p>The n vector is m × 1 and contains the m latent endogenous variables. The intercept terms are in the m × 1 vector of α η . The m × m coefficient matrix B gives the effect of the ηs on each other. The n latent exogenous variables are in the n × 1 vector ξ. The m × n coefficient matrix Γ contains the coefficients for ξ's impact on the ηs. An m × 1 vector ζ contains the disturbances for each latent endogenous variable. We assume that E(ζ) = 0, COV (ζ, ξ) = 0, and we assume that the disturbance for each equation is homoscedastic and nonautocorrelated across cases, although the variances of ζs from different equations can differ and these ζs can correlate across equations. The m × m covariance matrix Σ ζζ has the variances of the ζs down the main diagonal and the across equation covariances of the ζs on the off-diagonal. The n × n covariance matrix of ξ is Σ ξξ .</p><p>The measurement model is:</p><formula xml:id="formula_1">y = α y + Λ y η + ε (2) x = α x + Λ x ξ + δ (3)</formula><p>The p × 1 vector y contains the indicators of the ηs. The p × m coefficient matrix Λ y (the "factor loadings") give the impact of the ηs on the ys. The unique factors or errors are in the p × 1 vector ε. We assume that E(ε) = 0 and COV(η, ε) = 0. The covariance matrix for the ε is Σ εε . There are analogous definitions and assumptions for measurement Equation 3 for the q × 1 vector x. We assume that ζ, ε, and δ are uncorrelated with ξ and in most models these disturbances and errors are assumed to be uncorrelated among themselves, though the latter assumption is not essential. <ref type="foot" target="#foot_2">4</ref> We also assume that the errors are homoscedastic and nonautocorrelated across cases.</p><p>In these models, the covariance matrix (Σ) and the mean vector (μ) are functions of the parameters of the model. These are the implied covariance matrix [Σ(θ)] and the implied mean vector [μ(θ)] where θ is a vector that contains all parameters of a model including coefficients, means, variances, and covariances. General expressions for Σ(θ) and μ(θ) are available in several sources (e.g., <ref type="bibr" target="#b4">Bollen 1989)</ref> and by substituting the parameters that apply to a specific model the implied moments are available for this model. If a model is true, then:</p><formula xml:id="formula_2">Σ = Σ(θ) (4) and μ = μ(θ) . (5)</formula><p>The log likelihood of the maximum likelihood (ML) estimator, derived under the assumption that z, which is the combined vector for the data (x and y), comes from a multinormal distribution, is</p><formula xml:id="formula_3">lnL(θ) = K - 1 2 ln Σ(θ) - 1 2 [z -μ(θ)]′Σ -1 (θ)[z -μ(θ)], (<label>6</label></formula><formula xml:id="formula_4">)</formula><p>where K is a constant that has no effect on the values of θ that maximize the log likelihood.</p><p>The chi-square test statistic derives from a likelihood ratio test of the hypothesized model to a saturated model where the covariance matrix and mean vector are exactly reproduced. The null hypothesis of the chi-square test is that Equations 4 and 5 hold exactly. In large samples, the likelihood ratio (LR) test statistic follows a chi-square distribution when the null hypothesis is true. Excess kurtosis can affect the test statistic, though there are various corrections that, among other things, address excess kurtosis <ref type="bibr" target="#b24">(Satorra and Bentler 1988;</ref><ref type="bibr" target="#b6">Bollen and Stine 1992)</ref>. In practice, the typical outcome of this test in large samples is rejection of the null hypothesis that represents the model. This often occurs even when corrections for excess kurtosis are made. At least part of the explanation is that the null hypothesis assumes exact fit whereas in practice we anticipate at least some inaccuracies in our modeling. The significant LR test simply reflects what we know: our model is at best an approximation. If the model is approximately correct and no other assumptions are violated, the large sample distribution of the test statistic is a noncentral chi-square distribution, its shape governed by a noncentrality parameter and the degrees of freedom (for example, see <ref type="bibr" target="#b7">Cudeck and Browne 1983)</ref>.</p><p>In response to the common rejection of the null hypothesis of perfect fit, researchers have proposed and used a variety of fit indices. The Incremental Fit Index (IFI, Bollen 1989), Comparative Fit Index (CFI, Bentler 1990), Tucker-Lewis Index (TLI, <ref type="bibr" target="#b30">Tucker and Lewis 1973)</ref>, Relative Noncentrality Index <ref type="bibr">(RNI, Bentler 1990;</ref><ref type="bibr" target="#b19">McDonald and Marsh 1990)</ref>, and Root Mean Squared Error of Approximation (RMSEA, <ref type="bibr" target="#b28">Steiger and Lind 1980)</ref> are just a few of the many indices of fit that have been proposed. Though the popularity of each has waxed and waned, there are problems characterizing all or most of these. One is that there is ambiguity as to the proper cutoff value to signify that a model has an acceptable fit. Different authors recommend different standards of good fit and in nearly all cases the justification for cutoff values are not well founded. Second, the distributions of most of these fit indices are not given. Thus, with the exception of the RMSEA, confidence intervals for the fit indices are not provided. Third, the fit indices that are based on comparisons to a baseline model (e.g., TLI, IFI, RNI) can behave somewhat differently depending on the fitting function used to estimate a model <ref type="bibr" target="#b29">(Sugawara and MacCallum 1993)</ref>. This suggests that standards of fit should be adjusted depending on the fitting function employed. An additional problem is that the means of the sampling distributions of some measures tend to be larger in bigger samples than in smaller ones even if the identical model is fitted (e.g., <ref type="bibr" target="#b5">Bollen and Long 1993)</ref>. Thus, cutoff values for such indices might need to differ depending on the size of the sample.</p><p>Another set of issues arise when comparing competing models for the same data. If the competing models are nested, then a LR test that is asymptotically chi-square distributed is available. However, in such a case, the issue of statistical power in small samples remains. Furthermore, the LR test is not available for nonnested models. Finally, other factors such as excess kurtosis can impact the LR test. The situation is not made better by employing other fit indices. Though we can take the difference in the fit indices across two or more models, there is little guidance on what to consider as a sufficiently large difference to conclude that one model's fit is better than another. In addition, the standards might need to vary depending on the estimator employed and the size of the sample for some of the fit indices. Nonnested models further complicate these comparisons since the rationale for direct comparisons of nonnested models for most of these fit indices is not well-developed.</p><p>This brief overview of the LR test and the other fit indices in use in SEMs reveals that there are drawbacks to the current methods of assessing the fit of models. It would be desirable to have a method to assess fit that worked for nested and nonnested models and that had a rationale in statistical theory. From a practical point of view, it is desirable to have a measure that is calculable using standard output from SEM software. In the next section, we examine the Bayes Factor and methods to approximate it that address these criteria.</p><p>The Bayes Factor expresses the odds of observing a given set of data under one model versus an alternative model. For any two models 2 and 1, the Bayes Factor, B 21 , is the ratio of P(Y|M k ) for two different models, where P(Y|M k ) is the probability of the data Y given the model, M k . More explicitly, the Bayes Factor, B 21 , is</p><formula xml:id="formula_5">B 21 = P Y M 2 P Y M 1 (7)</formula><p>Conceptually, the Bayes Factor is a relatively straightforward way to compare models, but it can be complex to compute. <ref type="foot" target="#foot_3">5</ref> The marginal likelihoods must be calculated for the competing models. Following Bayes' Theorem, the marginal likelihood (also known as the integrated likelihood) can be expressed as a weighted average of the likelihood of all possible parameter values under a given model. (8)   where θ k is vector of parameters of M k , P(Y | θ k , M k ) is the likelihood under M k , and P(θ k | M k ) is the prior distribution of θ k .</p><formula xml:id="formula_6">P Y M k = ∫ P Y θ k , M k P θ k M k d θ k ,</formula><p>Closed-form analytic expressions of the marginal likelihoods are difficult to obtain, and numeric integration is computationally intensive with high dimensional models. Approximation of this integral via the Laplace method and the use of modern computing technology help solve this problem. Technical details of the Laplace method can be found in many sources, including <ref type="bibr" target="#b17">Kass and Raftery (1995)</ref>. In brief, a second order Taylor expansion of the log P(Y|M k ) around the ML estimator θ k leads to the expression in Equation <ref type="formula" target="#formula_8">9</ref>, where</p><formula xml:id="formula_7">l(θ k ) is the log likelihood function (i.e., logP[Y | θ k , M k ]), I E (θ k )</formula><p>is the expected information matrix, d k is the dimension (number of parameters) of the model, and O(N -1/2 ) is the approximation error, and N is the sample size.</p><formula xml:id="formula_8">logP Y M k = l(θ k ) + logP(θ k | M k ) + d k 2 log(2π) - d k 2 log(N) - 1 2 log I E (θ k ) + O N -1/2 . (<label>9</label></formula><formula xml:id="formula_9">)</formula><p>This equation forms the basis for several approximations to the Bayes Factor. Here we briefly present the equations for several approximations, including Schwarz's BIC,</p><p>Haughton's BIC, IBIC, and SPBIC. Derivations and justifications for these equations can be found in <ref type="bibr" target="#b5">Bollen et al. (2012)</ref>. Here our goal is simply to present the final equations, show their relationships to each other, and explain how they can be calculated for SEM models using standard output from software.</p><p>The Standard Bayesian Information Criterion (BIC) <ref type="bibr" target="#b26">Schwarz's (1978)</ref> BIC drops the second, third, and fifth terms of Equation <ref type="formula" target="#formula_8">9</ref>, on the basis that in large samples, the first and fourth terms will dominate in the order of error. Ignoring these terms gives</p><formula xml:id="formula_10">logP Y M k = l(θ k ) - d k 2 log(N) + O(1) . (<label>10</label></formula><formula xml:id="formula_11">)</formula><p>If we multiply this by 2, the BIC for M 2 and M 1 is calculated as</p><formula xml:id="formula_12">BIC 21 = 2[l(θ 2 ) -l(θ 1 )] -d 2 -d 1 log(N) . (11)</formula><p>In SEMs the usual chi-square test statistic is based on a likelihood ratio test of the hypothesized model (say M 1 ) compared to the saturated model (say M s ). Setting the saturated model to M 2 and the hypothesized model to M 1 , we can write the BIC in terms of the usual chi-square test statistic and its degrees of freedom (df) using equation ( <ref type="formula">11</ref>) as</p><formula xml:id="formula_13">BIC s1 = T ml -d f log(N) . (<label>12</label></formula><formula xml:id="formula_14">)</formula><p>where T ml is the chi-square test statistic using the ML estimator and df is the corresponding degrees of freedom for the model.</p><p>An advantage of the BIC is that it does not require specification of priors and it is readily calculable from standard output of most statistical packages. In the case of SEMs, all that is needed are the chi-square test statistic (T ml ) of the model, its degrees of freedom (df), and the sample size (N) to calculate it. In addition, using equation ( <ref type="formula" target="#formula_13">12</ref>), a value of BIC greater than zero supports the saturated model over the hypothesized model whereas a negative BIC supports the hypothesized model <ref type="bibr" target="#b22">(Raftery, 1995)</ref>. Sometimes the BIC value is calculated without a comparison to a saturated or other model based on equation (10</p><formula xml:id="formula_15">) [l(θ k ) - d k 2 log(N)].</formula><p>If this is done for all of the models to be compared, then the one with the lowest value is the best fitting model.</p><p>For reviews and critiques of the BIC see <ref type="bibr" target="#b32">Winship (1999)</ref> and <ref type="bibr" target="#b31">Weakliem (1999)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Haughton's BIC (HBIC)</head><p>A variant on the BIC retains the third term of Equation 9 <ref type="bibr" target="#b10">(Haughton 1988</ref>). We call this approximation the HBIC (Haughton labels it BIC*).</p><formula xml:id="formula_16">logP Y M k = l(θ k ) + d k 2 log(2π) - d k 2 log(N) + O(1) = l(θ k ) - d k 2 log( N 2π ) + O(1) .<label>(13)</label></formula><p>In comparing models M 2 and M 1 and multiplying by 2 this leads to</p><formula xml:id="formula_17">HBIC = 2[l(θ 2 ) -l(θ 1 )] -d 2 -d 1 log N 2π .<label>(14)</label></formula><p>The HBIC form that compares the hypothesized model to the saturated model using the chisquare test statistic is</p><formula xml:id="formula_18">HBIC s1 = T ml -d f log N 2π .<label>(15)</label></formula><p>The HBIC as with the BIC is straightforward to calculate from the output of SEM programs and using a calculator.</p><p>The HBIC performed well in model selection in a simulation study for SEMs <ref type="bibr" target="#b11">(Haughton et al. 1997)</ref>. Though this IC measure retains more terms in the approximation than does the BIC, this is no guarantee that it is a better approximation of BIC in finite samples. Our simulations will explore this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Information Matrix-Based BIC (IBIC)</head><p>A recent article by <ref type="bibr" target="#b5">Bollen et al. (2012)</ref> proposes IBIC, which retains additional terms from ( <ref type="formula" target="#formula_8">9</ref>). The estimated expected information matrix I E (θ k ) is obtainable with many SEM packages (it can be computed as the inverse of the covariance matrix for parameter estimates). Taking advantage of this, we preserve the fifth term in Equation <ref type="formula" target="#formula_8">9</ref>.</p><formula xml:id="formula_19">6 logP Y M k = l(θ k ) - d k 2 log N 2π - 1 2 log I E (θ k ) + O(1) .</formula><p>For models M 2 and M 1 and multiplying by 2, the Information matrix based Bayesian Information Criterion (IBIC) is given by 6 Note that this is very similar to <ref type="bibr" target="#b16">Kashyap's (1982)</ref> approximation (KBIC), which uses log(N) rather than log N 2π . We compared KBIC to IBIC in our simulation study below and found that IBIC consistently outperformed KBIC, particularly at small sample sizes. Thus, the slightly greater complexity in IBIC appears to be worthwhile. See the online appendix for more details on this comparison (available at <ref type="url" target="http://dvn.iq.harvard.edu/dvn/dv/jjharden">http://dvn.iq.harvard.edu/dvn/dv/jjharden</ref>).</p><formula xml:id="formula_20">IBIC = 2[l(θ 2 ) -l(θ 1 )] -d 2 -d 1 log N 2π -log I E (θ 2 ) + log I E (θ 1 ) .<label>(16)</label></formula><p>The IBIC measure that compares the hypothesized model (M 1 ) to the saturated (M s ) and makes use of the chi-square test statistic and its degrees of freedom is</p><formula xml:id="formula_21">IBIC s1 = T ml -d f log N 2π -log I E (θ s ) + log I E (θ 1 ) . (<label>17</label></formula><formula xml:id="formula_22">)</formula><p>As with the HBIC, we do not know whether the extra terms retained enhance the finite sample performance of the IBIC over the BIC. But we will look at this question in our simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Scaled Unit Information Prior BIC (SPBIC)</head><p>An alternative derivation of Schwarz's BIC makes use of the prior distribution of θ k . It is possible to arrive at Equation 10 by utilizing a unit information prior, which assumes that the prior has approximately the same information as the information contained in a single data point. Critics have argued that the unit information prior is too flat to reflect a realistic prior <ref type="bibr" target="#b23">(Raftery 1999</ref>). This prior also penalizes complex models too heavily, making BIC overly conservative toward the null hypothesis <ref type="bibr" target="#b31">(Weakliem 1999;</ref><ref type="bibr" target="#b18">Kuha 2004;</ref><ref type="bibr" target="#b3">Berger et al. 2006</ref>). Some researchers have proposed centering priors around the MLE (θ) of M k . Alternatively, some researchers have proposed using some form of scaling of the prior by a predefined scale (see <ref type="bibr" target="#b18">Kuha 2004</ref>). In fact, HBIC defined above can also be derived by scaling the prior by a predefined constant. More recently, <ref type="bibr" target="#b5">Bollen et al. (2012)</ref> proposed a Scaled Unit Information Prior BIC (SPBIC). The SPBIC uses a normal prior centered at zero for the parameters in question. As stated above, the BIC has a variance scaled at the level of unit information. The SPBIC differs from the BIC in that it chooses the variance that maximizes the probability density at the ML estimates of the parameters. <ref type="bibr" target="#b5">Bollen et al. (2012)</ref> provide complete details of the SPBIC derivation; we refer readers there for more information. The final analytical expression is as follows, where I o (θ k ) is the observed information matrix evaluated at θ k and θ * is the prior mean for model k.</p><formula xml:id="formula_23">logP Y M k = l(θ k ) - d k 2 1 -log d k θ k -θ k * T I o θ k θ k -θ k * (18)</formula><p>with SPBIC equal to</p><formula xml:id="formula_24">SPBIC = 2(l(θ 2 ) -l(θ 1 )) -d 2 1 -log d 2 θ 2 -θ 2 * T I o θ 2 θ 2 -θ 2 * + d 1 1 -log d 1 θ 1 -θ 1 * T I o θ 1 θ 1 -θ 1 * . (19)</formula><p>When comparing a hypothesized model (M 1 ) to the saturated model (M s ) and making use of the likelihood ratio chi-square, we are led to</p><formula xml:id="formula_25">SPBIC s1 = T ml -d s 1 -log d s θ s -θ s * T I o θ s θ s -θ s * + d 1 1 -log d 1 θ 1 -θ 1 * T I o θ 1 θ 1 -θ 1 * . (<label>20</label></formula><formula xml:id="formula_26">)</formula><p>where d s is the number of parameters from the saturated model or the number of variances, covariances, and means of the observed variables, d 1 is the number of parameters in the hypothesized model, and the other terms have already been defined. The observed information matrix is obtainable from the inverse of the covariance matrix of the parameter estimates when the covariance matrix is based on the observed information matrix (e.g., in Mplus or the sem package in R).</p><p>To evaluate this, we must use a prior mean, θ k *, for the k th model. One possibility is to put all parameters at zero (i.e., θ k * = 0). This seems reasonable for parameters that are coefficients (other than intercepts and means), but is less reasonable for variances, intercepts, means, and covariances that are not of central interest. Therefore, for the models we consider we set θ k * to zero for coefficients and keep the remaining parameters at their estimated values. The end result is that the only nonzero elements in the difference of θ k -θ k * are for the coefficients. If the saturated model is part of the comparison, we need to take a different approach because the parameters of the saturated model are only variances and covariances. If we were to set θ* to the sample variances and covariances, then the denominator in the top line of equation ( <ref type="formula" target="#formula_25">20</ref>) would be zero and undefined. A simple way around this for the saturated model is to have the prior mean be the estimated variances for all observed variables and the prior means for the covariances set to zero. If means and intercepts are part of the model, then the saturated model could set the elements of θ* that correspond to the means equal to the sample means. This would prevent the zero in the denominator.</p><p>For more details on the calculation of the scaling factor (which is model dependent and thus leads to an empirical Bayes prior) and the derivation of the analytical expression below, see <ref type="bibr" target="#b5">Bollen et al. (2012)</ref>. 7 The essential point for the practitioner is that the prior is implicit in the information and does not need to be explicitly calculated. All elements of the SPBIC formula are available from SEM software that uses the observed information matrix to calculate the asymptotic covariance matrix of parameter estimates (e.g., Mplus or the sem package in R). For a basic example of the steps in calculating SPBIC, as well as the other Bayes Factor approximations listed here, see the empirical example section.</p><p>Theoretically, in large samples we expect the IBIC and SPBIC to perform as well as the BIC or the HBIC. But we cannot easily know the finite sample behavior of these measures and whether one or the other has better performance in small to moderate samples. <ref type="bibr" target="#b12">Homburg (1991)</ref> conducted a simulation study of the BIC and compared it to cross-validation techniques. His conclusion was that the BIC performed well in finding the true model for sample sizes greater than 200 and data from multinormal distributions. <ref type="bibr" target="#b11">Haughton et al. (1997)</ref> analyzed the BIC, HBIC, and several fit indices. These authors simulate a three factor model with six indicators and compare minor variants on the true structure to determine how successful the Bayes Factor approximations and several fit indices are in selecting the true model. Their simulation results find that the Bayes Factor approximations as a group are superior to the p-value of the chi-square test and the other fit indices in correctly selecting the true generating model when the true model is among the choices. They find that HBIC does the best among the Bayes Factor approximations. Among the other fit indices and the chi-square p-value, the IFI and RNI have the best correct model selection percentages, though their success is lower than the Bayes Factor approximations.</p><p>The <ref type="bibr" target="#b12">Homburg (1991)</ref> and <ref type="bibr" target="#b11">Haughton et al. (1997)</ref> studies are valuable in several respects, not the least of which is their demonstration of the value of the IC measures. However, it is unclear whether their results extend beyond the models that they examined. Moreover, the structure of most of the models that <ref type="bibr" target="#b11">Haughton et al. (1997)</ref> considered were quite similar to each other. The performance of the IC measures for models with very different structures is unknown. Finally, they did not look at the situation where the true model was not included among the possible models.</p><p>Our simulation analysis seeks to test the generality of the Homburg (1991) <ref type="bibr" target="#b11">Haughton et al. (1997)</ref> results by looking at larger models with alternative models that range from mildly different to very different structures. In addition, we provide the first evidence on the performance of the IBIC and SPBIC in the selection of SEMs. Finally, we provide the first evidence on the performance of the IC measures when all models in the pool are approximations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Simulation Study</head><p>As we mentioned in the introduction, our simulation has two parts. The first part compares the IC measures and a variety of fit indices in their ability to correctly select a true model from among other models. The second part of the simulation focuses on the IC measures and their behavior when choosing from a pool of models that excludes the true structure, that is, 7 Bollen et al. (2012) also discuss an alternative computation of SPBIC when</p><formula xml:id="formula_27">d k ≥ (θ k -θ*) T I O (θ k )(θ k -θ*). As c k = ∞, the</formula><p>prior variance goes to 0, so the prior distribution is a point mass at the mean, θ*. This case never occurs in the simulations or empirical example we discuss below so we do not discuss it further here. Such a case is less studied so that we would caution readers that we have too little experience with the SPBIC to know its behavior under these less common circumstances.</p><p>when all models are approximations. For both parts of the simulation we use models designed by <ref type="bibr" target="#b20">Paxton et al. (2001)</ref>, which has been the basis for several other simulation studies. They chose these models after reviewing a large number of empirical studies using SEM that appeared in several social and behavioral science journals and tried to capture key features of these models in the simulation model. Specifically, we focus on their models with few latent variables with a small to moderate number of indicators per factor.</p><p>This enables comparisons to the results for other fit indices that use the same design, but different fit indices. Standard SEM assumptions hold in these models: exogenous variables and disturbances come from normal distributions and the disturbances follow the assumptions presented in Section 2 above.</p><p>The underlying population model for the first simulation (SIM1) has a latent variable model with three latent variables linked in a chain. This true model is labeled M1. Panel (a) of Figure <ref type="figure" target="#fig_2">1</ref> is a path diagram of this true model. It is the model with both solid and dashed lines included and is equivalent to the model in the preceding equations. The population parameters for this model are as follows: primary factor loadings were set to a standardized value of .70 to represent a communality of 49%, while complex loadings were set to a standardized value of .21. Regression parameters among latent variables were set to a standardized value of .60, to represent multiple R 2 of 36%. For an extended discussion of the rationale for the choice in parameter values see <ref type="bibr" target="#b20">Paxton et al. (2001)</ref>.</p><p>For each simulated data set, we fit a series of misspecified models, which are also depicted in Figure <ref type="figure" target="#fig_2">1</ref>. This range of models tests the ability of the different fit statistics to detect a variety of common errors. Parameters were misspecified so as to introduce error into both the measurement and latent variable components of the models. Some of these errors corresponded to the true model (M1) with extra, unneeded parameters (M6, M8, M9); others dropped necessary parameters (M2, M3, M4, M10), some both added and dropped parameters (M5, M7), while some even changed the number of latent variables in the model (M11, M12). Figure <ref type="figure" target="#fig_2">1</ref>, panels (b) and (c), represent these last two specifications. Table <ref type="table" target="#tab_0">1</ref> lists these models with their modifications.</p><p>The underlying population model for the second simulation (SIM2) uses a generating model that is identical to SIM1 in the latent variable model, but contains an additional two observed indicators for each latent variable. Parameter values were the same except for the addition of two measured variables per factor. The misspecified models used in SIM2 are given in Table <ref type="table" target="#tab_1">2</ref>.</p><p>For each simulation we generated 1000 data sets with each of the following sample sizes: N = 100, N = 250, N = 500, N = 1000, and N = 5000. Note that, following standard practice, samples were discarded if they led to non-converging solutions, and new samples were drawn to replace the "bad" samples until a total of 1000 samples were drawn that had convergent solutions for each of the 12 fitted models.<ref type="foot" target="#foot_4">foot_4</ref> All data were generated in R and analyzed with the sem package <ref type="bibr" target="#b8">(Fox 2006</ref>). 9</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Simulation Part I</head><p>In the first part of the simulation we include all of the models including the true one that generated the data. Our interest is in the ability of the different IC measures and fit indices to choose the true model among the 12 possibilities. The fit statistics included were the BIC, IBIC, SPBIC, HBIC, AIC, chi-square p-value, IFI, CFI, TLI, RNI, and RMSEA.</p><p>For each simulated data set we estimated all 12 models and calculated each fit index including the IC measures. We then determined whether the best fitting model in each sample was the true model. This was repeated for all replication samples at a given N. For the BIC, IBIC, SPBIC, HBIC, AIC, and RMSEA the model with the lowest value has the best fit. 10 For all of the other fit indices, the highest value signifies the best fit. Figure <ref type="figure" target="#fig_3">2</ref> gives the percentage of samples for which the true model was chosen for a given fit measure and given sample size across the 1000 replications. These results are for the first underlying simulation model (SIM1).</p><p>One clear result from these graphs is the dramatic improvement in the performance of the IC measures as the sample size grows. At the smallest N (100), success in choosing the true model among the 12 models was 20% or less. Choosing a model at random would have a success rate of roughly 8%, so the best of the IC measures (SPBIC, HBIC, AIC) are doing better than chance but the BIC and IBIC are not. In contrast, increasing the sample size to 250 has the best IC measures (SPBIC, HBIC, AIC) with success rates of over 40% with SPBIC the best at 50% and the IBIC and BIC once again coming in considerably lower.</p><p>Starting at N = 500, the SPBIC and HBIC break away from the AIC with the SPBIC over 80% success in picking the true model. The BIC comes in next with about 70%, followed by the AIC at a little over 60% and the IBIC a little lower. With a large sample size of 1000 or 5000, all the IC measures except AIC approach 100% success in finding the true model. Among the IC measures the new SPBIC and the HBIC have the best overall performance across sample sizes.</p><p>9 The sem package uses the observed information matrix for the calculation of the asymptotic covariance matrix of the parameter estimates. This provides the output needed for the SPBIC (observed information matrix). The IBIC uses the expected information matrix, which is not available in the sem package in R. We used the observed information matrix in place of the expected information matrix. We did not anticipate much of a difference, but checked this issue in the following way. The expected information matrix is the expected value, or mean, of the observed information matrices. We computed the mean of the 1000 simulated observed information matrices for each model, then replaced each of those means as the expected information matrices for their respective models and reran SIM1, n = 100. If there were any differences between using the observed and expected information matrices, we would expect it at the smallest sample size of 100. The result was an IBIC performance value (true model selection %) within a percent or two to what we got using the observed information. Though we would not anticipate large differences in other cases, we would still recommend that the expected information matrix be used for IBIC when it is available. 10 Selecting the lowest value for the IC is an exact test that does not take into account the magnitude of the difference in the fit statistic from the next best-fitting model. Alternatively, following the guidelines of <ref type="bibr" target="#b22">Raftery (1995)</ref>, we could consider models with differences in fit of less than 2 as essentially tied. Relative performance of the various criteria was similar when we did so; therefore to simplify presentation we assess correct selection in terms of the exact selection based on lowest value.</p><p>For comparison purposes we also included other popular fit indices. At the smallest samples these fit indices perform roughly the same as the IC indices, but starting at an N of 500 the best IC measures are superior to these. Of these common fit indices, the RNI appears best, but its performance never gets much better than 70% success even at the largest sample sizes. The RMSEA overall has the lowest percentage success in choosing the true model from the pool of models.</p><p>When we turn to SIM2 which includes more indicators per latent variables, we find a rather interesting result (not shown to conserve space). At the same smaller sample size, all fit indices are more successful in choosing the true model than they were at the same N in SIM1. For instance, at N = 100 several of these measures are approaching a 40% success rate, something that we did not see until an N of 250 in SIM1. Starting at 250 we have the IC measures pulling away from the other fit indices with the AIC lagging behind the other IC measures. Again the SPBIC and HBIC have the best overall performance in choosing the correct model.</p><p>In sum, our simulation results find that there are differences in the finite sample behavior of the IC measures. The SPBIC and HBIC have the best overall performance, but in large samples all but the AIC among the IC measures have great success in locating the true model. We also find that the IC measures are generally superior to the other fit indices in finding the true model in larger sample sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Simulation Part II</head><p>The second part of the simulation examines model selection when the true model is not among the choices. This reflects more realistic conditions in that we expect researchers to be using an approximate rather than the true structure in practice. We use the same simulation data as Part I, but we remove the true structure from among the choices resulting in 11 alternative models (rather than 12). We restrict our analysis to the IC measures, the primary focus of our article. Contrary to Part I, we cannot list the percentage of times the true model is selected because there is no true model among the choices. Instead, we provide tables that give the median value and Interquartile Range (IQR) for each IC measure for each model. Furthermore, we include the median rank in fit that each model has in each replication at the different sample sizes. Because this analysis generates a lot of tables, we only report three tables in the text for three sample sizes: 100, 500, and 1000 for SIM1. The tables for the remaining sample sizes are in the online appendix along with all of the tables for SIM2 (available at <ref type="url" target="http://dvn.iq.harvard.edu/dvn/dv/jjharden">http://dvn.iq.harvard.edu/dvn/dv/jjharden</ref>). We also report box-and-whisker plots of the values of each IC measure for each of the 11 models in this section. The tables and figures give us comparative fit information. We can see which models tended to have better fit (lower IC values) than the others and whether this varied with sample size.</p><p>We roughly group the remaining 11 models into three categories. The first are models with extra parameters (M6, M8, M9). These are the true generating model with unnecessary parameters added to it. In other words, the extra parameters have a population value of zero.</p><p>The second group are models with dropped parameters (M2, M3, M4). They are the true generating model with one or more parameters incorrectly removed (or set to zero). The third group is a mixture of extra and dropped parameters and includes cases with the wrong number of latent variables. Models M5, M7, M11, and M12 fall into this group. Finally, M10 is in its own group as a model in which only a β parameter is dropped.</p><p>Table <ref type="table" target="#tab_2">3</ref> presents the results from SIM1 for N = 100. Each time through the simulation the IC measure is computed for all the models. Then the IC value for the true model is subtracted from each other model's IC value. This makes the true model value equal to zero. Models that fit worse than the true model get positive values and those that fit better get negative values. Because lower values signify better fit, a negative median value in the table means that the median value on the particular IC measure signifies a better fit than the true model.</p><p>A positive value represents a median value higher than the true model.</p><p>Several bad fitting models (M11, M10, M7) are evident across all of the IC measures when N is 100. For example, M11 has a median SPBIC of 46.20 and an IQR of 19.28. This is far from zero and the IQR suggests considerable variability. The median rank of 11 for M11 means that its central tendency was to be among the worst fitting models of the 11 considered. A similar pattern was found for the other IC measures for the three models M11, M10, and M7. M11 and M7 involve both dropped and added parameters where M10 only drops (sets to zero) the paths between two latent variables in the original (see Figures <ref type="figure" target="#fig_2">1</ref> and<ref type="figure" target="#fig_3">2</ref>). Not all models with dropped parameters fare poorly with the IC measures. M2, M3, and M4 drop one, two, or three cross-loadings, respectively, yet the median for the BIC, HBIC, and IBIC are negative signifying a better median fit than the true model. Lower median ranks for many of these IC measures reflect their tendency to fare well in comparison to the remaining models. This tendency is weaker for SPBIC, whose median fit is close to the true model's value of zero.</p><p>Contrast this with models M6, M8, and M9 all of which have extra, unnecessary parameters included. The median of all IC measures is positive which exhibits a small penalty for the extra parameters. The median rank of fit for these models and IC measures tends to be toward the middle (fifth to seventh). Considering that the model is correct except for the inclusion of unnecessary parameters, this implies that the IC measures are penalizing extra parameters more strongly than they are dropped parameters, at least at the smallest sample size (N = 100). M12, which has a mixture of dropped and excluded parameters through the introduction of an extra latent variable, comes in toward the middle of the rankings for the IC measures with the highest median ranking for SPBIC (median rank = 6). It also is worth noting that the smallest variability (IQR) of the IC measures occurs for the models that add unnecessary parameters (M6, M8, M9).</p><p>Increasing the sample size to 500 (Table <ref type="table" target="#tab_3">4</ref>) leads to a general pattern that is similar with some important differences. The fit of M11, M10, and M7 are even worse than they were with N = 100 and their fit is considerably worse than any of the other models. Another difference compared to N = 100 is that M2, M3, and M4, which drop factor loadings, no longer have negative median values of the IC measures that suggest a better fit than the true model. We might expect that an IC measure that favors parsimony to favor models like M2, M3, and M4. Though we saw this in the smallest sample, it is not evident in this moderate sized sample. The models M6, M8, and M9, which add unnecessary parameters, have positive values and the HBIC and SPBIC have low median ranks for these models. We also note that the models with the extra parameters have the smallest variability as they did with N = 100.</p><p>Table <ref type="table" target="#tab_4">5</ref> gives our results for N = 1000. The results are quite similar to those for N = 500 with noticeably poorer fit for all but the models with the extra parameters (see the online appendix at <ref type="url" target="http://dvn.iq.harvard.edu/dvn/dv/jjharden">http://dvn.iq.harvard.edu/dvn/dv/jjharden</ref> for N = 250 and 5000).</p><p>In Figures <ref type="figure" target="#fig_4">3</ref><ref type="figure" target="#fig_5">4</ref><ref type="figure" target="#fig_6">5</ref><ref type="figure" target="#fig_7">6</ref>we provide the box-and-whiskers plots for each IC measure for individual models for N = 100, 250, 500, and 1000. The figures differ from the tables in that the consistently worst fitting models, M11, M10, and M7, are omitted. We did this because their IC values were so high that to plot them in the figures would necessitate greatly expanding the maximum for the y-axis and make it hard to see the features of the IC measures for the other models which have better fit.</p><p>These figures reinforce the impressions from the tables in displaying the small variability of the IC measures for the models with extra parameters (M6, M8, M9) and the increase in IC measures for the other models as sample size grows. As the sample size increases, the IC measures tend to favor the models that are correct except for extra parameters. What was not evident from the tables are the outlying values for the IC measures for the M2 to M5 models.</p><p>Along with their greater variability in IC measures, they also have more generally high outlier values.</p><p>The SIM2 simulation adds more variables to the model, but otherwise is similar to the SIM1 models that we just reviewed. The online appendix has tables to summarize the median value, IQR, and median rank for each model across N = 100, 250, 500, 1000, and 5000 (available at <ref type="url" target="http://dvn.iq.harvard.edu/dvn/dv/jjharden">http://dvn.iq.harvard.edu/dvn/dv/jjharden</ref>). SIM2 results are similar to those from SIM1 in that the IC measures favor the extra parameter models more as the sample size increases. However, one difference at the smallest sample size (N = 100) is that except for IBIC, the median IC measure values are nearly all positive for the models that drop factor loadings. In SIM1 they tended to be negative and hence favoring these trimmed structures over the true structure. That is not true here. Also the separation in IC measures for the three extra parameters models tends to be larger at the same sample size for SIM2 vs. SIM1. The trend toward favoring the true plus extra parameter models begins at lower sample sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Simulation Summary</head><p>Taken all together, what do we learn from these results using approximate models and excludes the true model? One result is that given the choice of models that drop (set to zero) some parameters versus a model that is true but has extra parameters included, the IC measures tend to favor the extra parameter over the dropped parameters. This trend is most clear in the moderate to large sample sizes. The only evidence that we found for the IC measures tilting toward simpler models with dropped parameters occurred in the smallest sample (N = 100) and in the SIM1 design. Other than that there was not a trend toward choosing a model with fewer parameters.</p><p>What about the relative performance of the different IC measures? In Part I of the simulation study we found that SPBIC and HBIC had the best overall performance in choosing the true model, though the behavior of all IC measures was much more similar in larger samples. In Part II where the true model is not one of the choices, the criterion for best model is less apparent. If we believe that we are better off selecting a model that has all of the parameters in the generating model and its only misspecification is including extra parameters that are zero in the population, then we would favor IC measures that have such models with values closest to zero. The HBIC and SPBIC are generally better on this criterion than the BIC and IBIC, though there are not dramatic differences. Alternatively, suppose a researcher favors IC measures that choose parsimonious models that trim small effects. Here the evidence slightly favors the BIC and IBIC which have lower median values than the SPBIC and HBIC. 11</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Empirical Example</head><p>Next we turn to utilizing these IC measures in an applied setting. We use data drawn from the National Longitudinal Survey of Youth (NLSY) of Labor Market Experience to illustrate the IC measures calculations with SEM. <ref type="bibr" target="#b4">Bollen and Curran (2004)</ref> consider five different longitudinal models of family income. They extracted a subsample of data consisting of N = 3912 individuals with complete data assessed at two year intervals from 1986 to 1994. The repeated measure was the square root of the respondent's report of total net family income for the prior calendar year. The five longitudinal models considered are listed below (for details, see <ref type="bibr" target="#b4">Bollen and Curran 2004)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1.</head><p>Autoregressive:</p><formula xml:id="formula_28">y it = α t + ρ t,t-1 y it-1 + ζ it 2. Latent Growth Curve: y it = α i + β i λ t + ζ it</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>Autoregressive Latent Trajectory (ALT) with ρ free: y it = α i + β i λ t + ρ t,t-1 y it-1 + ζ it</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>ALT with ρ equal: y it = α i + β i λ t + ρy it-1 + ζ it</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>ALT with ρ zero and y i1 predetermined: y it = α i + β i λ t + (0)y it-1 + ζ it Applied researchers are commonly confronted with several choices such as these when modeling data with SEMs. We illustrate the calculation of the IC measures employing the chi-square statistic that compares the hypothesized model to the saturated model. All the IC measures are computable with the following information: (1) the chi square test statistic (T ml ), (2) the degrees of freedom (df), (3) the sample size (N), (4) the number of estimated parameters for the saturated (d s ) and hypothesized (d 1 ) models, (5) the expected or observed information matrix for the saturated [I E (θ s ) or I o (θ s )] and hypothesized models [I E (θ 1 ) or I o (θ 1 )], and (6) the parameter estimates (θ s and θ 1 ). The BIC and HBIC only requires (1) to</p><p>(3); the IBIC requires requires all but (4) and ( <ref type="formula" target="#formula_3">6</ref>), and the SPBIC requires (1) to (6). 12 11 Of course, we remind readers of the limitations of any simulation design and the need to replicate results under diverse conditions. 12 Nearly all SEM software provide all but the information matrices as part of standard output. Many packages permit output of the asymptotic covariance matrix of the parameter estimates. The inverse of this covariance matrix provides an estimate of the information matrix. Whether it is the expected or observed information matrix depends on the SEM software and the option used. The online supplementary materials include a R function that takes output from any software package and computes all of the IC measures.</p><p>The top half of Table <ref type="table" target="#tab_5">6</ref> gives all of the necessary quantities for the five models presented in <ref type="bibr" target="#b4">Bollen and Curran (2004)</ref>. The lower half of Table <ref type="table" target="#tab_5">6</ref> presents the IC measures using those quantities for each model. Note that all of the measures point to the ALT models as better fitting than the autoregressive and latent growth curve models. Among the three ALT models, the one with the autoregressive parameter free has the best fit for BIC, HBIC, and SPBIC. The IBIC points towards the ALT model with equal autoregressive parameters.</p><p>Recall that the IC measures are comparing fit to the saturated model. Though we do not know the true model, the IC measures point toward the ALT model, possibly with the free autoregressive parameter. Even though the BIC, HBIC, and SPBIC all point toward the ALT model with the autoregressive parameters free, only the SPBIC clearly points to this model over the saturated model in that it SPBIC takes a large negative value. According to <ref type="bibr" target="#b22">Raftery (1995)</ref>, a difference of less than 2 provides only weak evidence of a difference in model fit when using IC for model selection; a difference of greater than 10 is considered very strong evidence of superior fit (with the model with the smaller value being preferred).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>As in any statistical analysis, a key issue in the use of SEMs is determining the fit of the model to the data and comparing the relative fit of two or more models to the same data. However, current practice with SEMs commonly employs methods that are problematic for several different reasons. For example, the asymptotic chi-square distributed test statistic that tests whether a SEM exactly reproduces the covariance matrix of observed variables routinely rejects models in large samples regardless of their possible merit as approximations to the underlying process. Several other fit indices have been developed in response, but those measures also have important problems: their sampling distributions are not commonly known, some tend to differ with sample size, and there is disagreement about the optimal cutoff values for a "well-fitting" model.</p><p>Analytic research tells us that the IC measures will choose the true model as the sample size goes to infinity. However, this does not tell us how the IC measures perform in finite samples or in the typical situation when the true model is not among the choices. One part of our article uses simulated data to examine the finite sample behavior of these IC measures and traditional fit indices when the true model is one of the options. We find that these IC measures are better at finding the true model than are other fit indices in our first simulation.</p><p>The SPBIC and HBIC have the best overall performance among the IC measures, though in large samples all but AIC perform well. We also looked at model selection when all models are approximate. Here we found that in moderate to large samples all the IC measures favored the model that had the true structure with extra parameters. Other models with dropped only or a mixture of dropped and extra parameters did not fare as well, though models with dropped parameters with small values looked better than other remaining misspecifications. Of course, neither the ICs or any fit index eliminates the uncertainty of model selection. But, overall, our results suggest that researchers using SEM should take a closer look at these IC measures and their use in model selection.         </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>contains 9 observed variables, 3 of which crossload on more than one latent variable. Scaling is accomplished by fixing λ =1 for a single indicator loading on</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Path Diagrams of the Models in SIM1</figDesc><graphic coords="22,189.84,62.00,292.32,503.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: SIM1 Percentage Selections of the True Model</figDesc><graphic coords="23,84.00,62.00,504.00,377.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: SIM1 IC Box-and-Whisker Plots and Median Ranks with No True Model (N = 100). Boxand-Whisker plots represent each fit statistic for each model over the 1,000 simulations. Numbers below the model names represent the median rank of each fit statistic for each model over the 1000 simulations.</figDesc><graphic coords="24,108.54,62.00,454.92,504.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: SIM1 IC Box-and-Whisker Plots and Median Ranks with No True Model (N = 250). Boxand-Whisker plots represent each fit statistic for each model over the 1,000 simulations. Numbers below the model names represent the median rank of each fit statistic for each model over the 1000 simulations.</figDesc><graphic coords="25,108.54,62.00,454.92,504.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: SIM1 IC Box-and-Whisker Plots and Median Ranks with No True Model (N = 500). Boxand-Whisker plots represent each fit statistic for each model over the 1,000 simulations. Numbers below the model names represent the median rank of each fit statistic for each model over the 1000 simulations.</figDesc><graphic coords="26,108.54,62.00,454.92,504.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: SIM1 IC Box-and-Whisker Plots and Median Ranks with No True Model (N = 1000). Boxand-Whisker plots represent each fit statistic for each model over the 1,000 simulations. Numbers below the model names represent the median rank of each fit statistic for each model over the 1000 simulations.</figDesc><graphic coords="27,108.54,62.00,454.92,504.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Fitted Models for SIM1</figDesc><table><row><cell cols="2">Model Description</cell><cell># Par.</cell><cell>Dropped Parameters</cell><cell>Extra Parameters</cell></row><row><cell cols="2">Correct Model</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M1</cell><cell>Correct model</cell><cell>23</cell><cell></cell><cell></cell></row><row><cell cols="2">Misspecified Measurement Models</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M2</cell><cell>Drop 1 cross loading</cell><cell>22</cell><cell>λ 41</cell><cell></cell></row><row><cell>M3</cell><cell>Drop 2 cross loadings</cell><cell>21</cell><cell>λ 41 , λ 72</cell><cell></cell></row><row><cell>M4</cell><cell>Drop 3 cross loadings</cell><cell>20</cell><cell>λ 41 , λ 72 , λ 63</cell><cell></cell></row><row><cell>M5</cell><cell>Drop cross-loadings; add correlated errors</cell><cell>22</cell><cell>λ 72 , λ 63</cell><cell>θ 67</cell></row><row><cell>M6</cell><cell>Correlated errors</cell><cell>24</cell><cell></cell><cell>θ 67</cell></row><row><cell>M7</cell><cell>Switch factor loadings</cell><cell>23</cell><cell>λ 21 , λ 52</cell><cell>λ 51 , λ 22</cell></row><row><cell cols="2">Misspecified Structural Models</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M8</cell><cell>Add double-lagged effect</cell><cell>24</cell><cell></cell><cell>γ 31</cell></row><row><cell>M9</cell><cell cols="2">Add correlated errors and double-lagged effect 25</cell><cell></cell><cell>θ 67 , β 31</cell></row><row><cell>M10</cell><cell>No relations among η's</cell><cell>21</cell><cell>β 21 , β 32</cell><cell></cell></row><row><cell>M11</cell><cell>Two latent variables (remove η 3 )</cell><cell>19</cell><cell>λ 42 , λ 72 , λ 73 , λ 93 , β 32 , ψ 33</cell><cell>λ 82 , λ 92</cell></row><row><cell>M12</cell><cell>Four latent variables (add η 4 )</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Fitted Models for SIM2</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ψ</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>β 43 ,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>λ 15,4 ,</cell></row><row><cell>Extra Parameters</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>θ 10,11</cell><cell>θ 10,11</cell><cell>λ 71 , λ 22</cell><cell></cell><cell>γ 31</cell><cell>θ 10,11 , γ 31</cell><cell></cell><cell>λ 12,2 , λ 13,2 , λ 14,2 , λ 15,2</cell><cell>λ 12,3 , λ 11,4 , λ 12,4 , λ 14,4 ,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>λ 83 ,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>λ 52 ,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>λ 42 ,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>33</cell><cell></cell></row><row><cell>Dropped Parameters</cell><cell></cell><cell></cell><cell></cell><cell>λ 61</cell><cell>λ 61 , λ 11,2</cell><cell>λ 61 , λ 11,2 , λ 10,3</cell><cell>λ 11,2 , λ 10,3</cell><cell></cell><cell>λ 21 , λ 72</cell><cell></cell><cell></cell><cell></cell><cell>β 21 , β 32</cell><cell>λ 62 , λ 10,3 , λ 11,3 , λ 13,3 , λ 14,3 , λ 15,3 , β 32 , ψ</cell><cell>λ 61 , λ 92 , λ 10,2 , λ 11,2 , λ 13,3 , λ 14,3 , λ 15,3 ,</cell></row><row><cell>Model Description # Par.</cell><cell>Correct Model</cell><cell>M1 Correct model 35</cell><cell>Misspecified Measurement Models</cell><cell>M2 Drop 1 cross loading 34</cell><cell>M3 Drop 2 cross loadings 33</cell><cell>M4 Drop 3 cross loadings 32</cell><cell>M5 Drop cross-loadings; add correlated errors 34</cell><cell>M6 Correlated errors 36</cell><cell>M7 Switch factor loadings 35</cell><cell>Misspecified Structural Models</cell><cell>M8 Add double-lagged effect 36</cell><cell>M9 Add correlated errors and double-lagged effect 37</cell><cell>M10 No relations among η's 33</cell><cell>M11 Two latent variables (remove η 3 ) 31</cell><cell>M12 Four latent variables (add η 4 ) 37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>SIM1 Fit Statistic Quantiles and Median Ranks with No True Model (N = 100) Cells report median and interquartile range (IQR) values of the fit statistics across the simulations, with median model ranks below. Lower numbers indicate better fit.</figDesc><table><row><cell>β Only</cell><cell>M10</cell><cell>33.61</cell><cell>17.55</cell><cell>10</cell><cell>37.28</cell><cell>17.55</cell><cell>10</cell><cell>28.58</cell><cell>17.26</cell><cell>10</cell><cell>32.71</cell><cell>16.44</cell><cell>10</cell></row><row><cell>Dropped</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Extra Parameters Dropped Loadings Dropped and Extra</cell><cell>M6 M8 M9 M2 M3 M4 M5 M7 M11 M12</cell><cell>Median 4.16 4.12 7.76 -1.90 -3.92 -2.74 -1.38 25.04 36.58 4.11</cell><cell>IQR 1.06 1.43 2.29 4.36 6.10 9.13 5.25 13.81 21.37 1.73</cell><cell>Median Rank 6 5 8 3 2 2 3 9 10 6</cell><cell>Median 2.32 2.28 4.09 -0.06 -0.24 2.77 0.45 25.04 43.93 2.27</cell><cell>IQR 1.06 1.43 2.29 4.36 6.10 9.13 5.25 13.81 21.37 1.73</cell><cell>Median Rank 5 4 7 3 3 6 4 9 11 5</cell><cell>Median 8.05 5.48 13.19 -3.20 -6.65 -7.27 0.45 22.08 25.78 6.60</cell><cell>IQR 0.95 1.42 2.17 3.93 5.04 8.07 3.69 12.87 18.56 2.47</cell><cell>Median Rank 7 5 8 3 2 1 4 10 10 6</cell><cell>Median 1.88 2.00 3.35 0.57 0.05 2.95 -0.15 27.46 46.20 13.59</cell><cell>IQR 1.03 1.35 2.37 4.44 5.94 8.75 4.76 15.70 19.28 6.75</cell><cell>Median Rank 4 4 6 4 3 5 3 9 11 8</cell></row><row><cell>Models:</cell><cell>BIC</cell><cell></cell><cell></cell><cell>HBIC</cell><cell></cell><cell></cell><cell>IBIC</cell><cell></cell><cell></cell><cell>SPBIC</cell><cell></cell><cell></cell><cell>Note:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>SIM1 Fit Statistic Quantiles and Median Ranks with No True Model (N = 500) Cells report median and interquartile range (IQR) values of the fit statistics across the simulations, with median model ranks below. Lower numbers indicate better fit.</figDesc><table><row><cell>β Only</cell><cell>M10</cell><cell>195.97</cell><cell>41.10</cell><cell>10</cell><cell>199.65</cell><cell>41.10</cell><cell>10</cell><cell>187.64</cell><cell>41.04</cell><cell>10</cell><cell>195.53</cell><cell>40.75</cell><cell>10</cell></row><row><cell>Dropped</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Extra Parameters Dropped Loadings Dropped and Extra</cell><cell>M6 M8 M9 M2 M3 M4 M5 M7 M11 M12</cell><cell>Median 5.79 5.78 11.14 6.39 9.27 30.01 10.69 129.51 247.79 6.77</cell><cell>IQR 1.18 1.23 2.20 9.58 12.20 19.36 12.32 33.77 49.74 3.37</cell><cell>Median Rank 3 3 6 4 5 8 6 9 11 4</cell><cell>Median 3.95 3.94 7.46 8.23 12.95 35.52 12.52 129.51 255.15 4.94</cell><cell>IQR 1.18 1.23 2.20 9.58 12.20 19.36 12.32 33.77 49.74 3.37</cell><cell>Median Rank 2 2 5 5 6 8 6 9 11 3</cell><cell>Median 11.36 8.84 19.82 3.37 3.20 20.62 10.74 126.82 229.88 11.08</cell><cell>IQR 1.14 1.12 2.15 9.31 12.02 18.76 11.61 33.33 48.66 3.20</cell><cell>Median Rank 5 3 7 2 2 8 5 9 11 5</cell><cell>Median 3.51 3.62 6.64 8.75 13.40 35.74 12.00 132.26 257.60 16.00</cell><cell>IQR 1.18 1.16 2.19 9.33 12.26 19.56 11.92 33.66 48.43 4.69</cell><cell>Median Rank 2 2 3 4 6 8 5 9 11 6</cell></row><row><cell>Models:</cell><cell>BIC</cell><cell></cell><cell></cell><cell>HBIC</cell><cell></cell><cell></cell><cell>IBIC</cell><cell></cell><cell></cell><cell>SPBIC</cell><cell></cell><cell></cell><cell>Note:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>SIM1 Fit Statistic Quantiles and Median Ranks with No True Model (N = 1000) Cells report median and interquartile range (IQR) values of the fit statistics across the simulations, with median model ranks below. Lower numbers indicate better fit.</figDesc><table><row><cell>β Only</cell><cell>M10</cell><cell>405.62</cell><cell>56.23</cell><cell>10</cell><cell>409.29</cell><cell>56.23</cell><cell>10</cell><cell>395.90</cell><cell>56.09</cell><cell>10</cell><cell>404.95</cell><cell>55.43</cell><cell>10</cell></row><row><cell>Dropped</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Extra Parameters Dropped Loadings Dropped and Extra</cell><cell>M6 M8 M9 M2 M3 M4 M5 M7 M11 M12</cell><cell>Median 6.47 6.43 12.44 19.82 30.30 74.58 26.53 262.62 515.62 9.34</cell><cell>IQR 1.14 1.27 2.29 14.31 17.69 26.02 17.52 47.65 66.96 5.05</cell><cell>Median Rank 2 2 4 5 7 8 6 9 11 3</cell><cell>Median 4.64 4.59 8.76 21.66 33.97 80.09 28.36 262.62 522.97 7.50</cell><cell>IQR 1.14 1.27 2.29 14.31 17.69 26.02 17.52 47.65 66.96 5.05</cell><cell>Median Rank 2 2 4 5 7 8 6 9 11 3</cell><cell>Median 12.75 10.23 22.55 16.10 22.75 63.11 26.08 259.65 494.72 14.38</cell><cell>IQR 1.14 1.24 2.17 14.00 17.44 25.78 17.08 47.14 65.86 4.96</cell><cell>Median Rank 3 1 5 4 6 8 6 9 11 3</cell><cell>Median 4.20 4.24 7.97 22.17 34.22 80.31 27.77 265.26 525.28 18.42</cell><cell>IQR 1.12 1.24 2.20 14.06 17.53 25.93 17.41 46.66 66.46 5.40</cell><cell>Median Rank 1 2 3 5 7 8 6 9 11 5</cell></row><row><cell>Models:</cell><cell>BIC</cell><cell></cell><cell></cell><cell>HBIC</cell><cell></cell><cell></cell><cell>IBIC</cell><cell></cell><cell></cell><cell>SPBIC</cell><cell></cell><cell></cell><cell>Note:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Computation of IC Measures for the<ref type="bibr" target="#b4">Bollen and Curran (2004)</ref> Models are used in the computation of SPBIC. Discrepancies in computations may result from rounding error.</figDesc><table><row><cell>ρ zero ρ equal ALT ρ free ALT Autoregressive Latent Growth Curve ALT</cell><cell>203.33 62.44 412.93 26.26 T ml 534.27</cell><cell>3912 3912 3912 3912 N 3912</cell><cell>8.27 8.27 8.27 8.27 log(N) 8.27</cell><cell>6.43 6.43 6.43 6.43 log N 2π 6.43</cell><cell>7 6 10 3 df 6</cell><cell>20 (15) 20 (15) 20(15) 20 (15) d s (SPBIC) 20 (15)</cell><cell>13 (6) 14 (7) 10 (3) 17 (10) d 1 (SPBIC) 14 (9)</cell><cell>134.89 134.89 134.89 134.89 log I E (θ s ) 134.89</cell><cell>94.19 102.77 74.26 130.18 log I E (θ 1 ) 102.61</cell><cell>195428707 195428707 195428707 195428707 (θ s -θ s *) T I o (θ s )(θ s -θ s *) 195428707</cell><cell>189536063 251962808 180774515 214642815 (θ 1 -θ 1 *) T I o (θ 1 )(θ 1 -θ 1 *) 1137006314</cell><cell>145.43 12.81 330.21 1.44 * BIC 484.64</cell><cell>158.29 23.83 348.59 6.95 * HBIC 495.67</cell><cell>117.59 -8.29 * 287.95 2.25 IBIC 463.39</cell><cell>52.20 -69.51 208.93 -55.66 * SPBIC 450.42</cell><cell>Note:</cell><cell>* Fit statistic's minimum value. Values for d s and d 1 in parentheses</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Struct Equ Modeling. Author manuscript; available in PMC 2019 July 29.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>The latent variable model is also called the "structural equation." Because the latent variable and measurement models both have structural parameters we prefer the term "latent variable model" to avoid this confusion.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>We can modify the model to permit such correlations among the errors, but do not do so here.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Of course, advances in computational statistics over the last few decades has eased the burden of this complexity.Bollen et al.  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4"><p>This was most problematic at small sample sizes for SIM1-at N = 100, 168 samples had to be discarded for nonconvergence. The respective SIM1 numbers at other sample sizes are: N = 250: 32, N = 500: 2, N = 1000: 1, and N = 5000: 0. The numbers for SIM2 are: N = 100: 27, N = 250: 3, N = 500: 1, N = 1000: 0, and N = 5000: 0.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>λ 41 , λ 62 , λ 72 , λ 83 , λ 93 λ 32 , λ 53 , λ 74 , λ 94 , β 43 , ψ 44 Struct Equ Modeling. Author manuscript; available in PMC 2019 July 29.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>Refer to Web version on PubMed Central for supplementary material.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Comparative fit indexes in structural models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="238" to="246" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
	<note>PubMed: 2320703</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Structural equation models in medical research</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Methods in Medical Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="181" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note>PubMed: 1341656</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Structural equation modeling in medical research: A primer</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Beran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Violato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Research Notes</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="267" to="277" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>PubMed: 20969789</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Generalization of BIC</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Visser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Bayarri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>University of North Carolina, Duke University, and SAMSI</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Autoregressive latent trajectory (alt) models: A synthesis of two traditions</title>
		<author>
			<persName><forename type="first">Ka</forename><forename type="middle">;</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural Equations with Latent Variables</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1989">1989. 2004</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="336" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A comparison of bayes factor approximation methods including two new methods</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Js ;</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zavisca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Harden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="294" to="324" />
			<date type="published" when="1993">1993. 2012</date>
			<pubPlace>Sage, Newbury Park, CA</pubPlace>
		</imprint>
	</monogr>
	<note>Testing Structural Equation Models</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bootstrapping goodness of fit measures in structural equation models</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Stine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="229" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cross-validation of covariance structures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cudeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="167" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
	<note>PubMed: 26781606</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Structural equation modeling with the sem package in R</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="465" to="486" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The determination of the order of an autoregression</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Hannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quinn</forename><surname>Bg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="190" to="195" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the choice of a model to fit data from an exponential family</title>
		<author>
			<persName><forename type="first">Dma</forename><surname>Haughton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="342" to="355" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Information and other criteria in structural equation model selection</title>
		<author>
			<persName><forename type="first">Dma</forename><surname>Haughton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jhl</forename><surname>Oud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rarg</forename><surname>Jansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Part B -Simulation and Computation</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1477" to="1516" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>Communications in Statistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cross-validation and information criteria in causal modeling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Homburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Marketing Research</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="144" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A general approach to confirmatory maximum likelihood factor analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jöreskog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="202" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Analysis of Covariance Structures</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jöreskog</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<publisher>Academic Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Advances in Factor Analysis and Structural Equation Models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jöreskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sörbom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>Abt Books</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimal choice of ar and ma parts in autoregressive moving average models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Kashyap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="104" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
	<note>PubMed: 21869012</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bayes factors</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">430</biblScope>
			<biblScope unit="page" from="773" to="795" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">AIC and BIC: Comparisons of Assumptions and Performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kuha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="188" to="229" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Choosing a multivariate model: Noncentrality and goodness of fit</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Marsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="247" to="255" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Monte carlo experiments: Design and implementation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Paxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><forename type="middle">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="287" to="312" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bayesian model selection in structural equation models In Bollen</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Testing Structural Equation Models</title>
		<meeting><address><addrLine>Newbury Park, CA. Sage</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="163" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Sociological Methodology, chapter Bayesian Model Selection in Social Research</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="111" to="163" />
			<pubPlace>Blackwell, Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
	<note>with Discussion</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bayes factors and bic: Comment on a critique of the bayesian information criterion for model selection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="411" to="427" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scaling corrections for chi-square statistics in covariance structure analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satorra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASA 1988 Proceedings of the Business and Economic Statistics Section</title>
		<meeting><address><addrLine>Alexandra, VA</addrLine></address></meeting>
		<imprint>
			<publisher>American Statistical Association</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="308" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The application of sem to behavioral research in oncology: Past accomplishments and future opportunities</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Schnoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manne</forename><surname>Sl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="583" to="614" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Cause and Correlation in Biology: A User&apos;s Guide to Path Analysis, Structural Equations, and Causal Inference</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shipley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Statistically based tests for the number of common factors Presented at the annual meeting of the Psychometric Society</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Steiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lind</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<pubPlace>Iowa City, IA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Effect of estimation method on incremental fit indexes for covariance structure models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Sugawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="365" to="377" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A reliability coefficient for maximum likelihood factor analysis</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Critique of the Bayesian Information Criterion for Model Selection</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Weakliem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="359" to="397" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Editor&apos;s Introduction to the Special Issue on the Bayesian Information Criterion</title>
		<author>
			<persName><forename type="first">C</forename><surname>Winship</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="355" to="358" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
